Sun Oct 13 21:16:05 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        On  | 00000000:41:00.0 Off |                  Off |
|  0%   34C    P8              10W / 450W |     54MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   1770066      G   /usr/lib/xorg/Xorg                           44MiB |
+---------------------------------------------------------------------------------------+
wandb: Currently logged in as: abdelrahman-elsayed (dinesh_saggurthi). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/abdelrahman.elsayed/wandb/run-20241013_211619-ef5ojkku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DIAS_modelnone
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dinesh_saggurthi/SVD_exps
wandb: üöÄ View run at https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/ef5ojkku
{'data_transforms': {'a_min': 0, 'a_max': 255, 'img_size': 512, 'use_random_crop': False, 'use_rotation': True, 'rotation_angle': 10, 'use_saturation': False, 'saturation': 2, 'use_brightness': True, 'brightness': 2, 'use_horizontal_flip': True, 'use_random_scale': True}, 'data': {'name': 'ArcadeDataset', 'root_path': '/home/abdelrahman.elsayed/DIAS', 'data_split_csv': '/home/abdelrahman.elsayed/DIAS/data_split.csv', 'fold_num': 0, 'label_list': [0, 1], 'label_names': ['Background', 'Vein'], 'volume_channel': 3, 'negative_to_positive_ratio': -1}}
{'sam': {'img_size': 512, 'num_classes': 2, 'sam_type': 'base'}, 'img_type': 'image', 'arch': 'Prompt Adapted SAM', 'use_fdn': False, 'decoder_training': 'none', 'mlp_transform': False, 'prompts': {'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}, 'training': {'optimizer': 'adamw', 'lr': '1e-4', 'batch_size': 8, 'num_epochs': 200, 'schedule_step': 200, 'schedule_step_factor': 0.2, 'weight_decay': '1e-2', 'loss': 'focal+dice', 'reg_multiplier': 0}}
HERE
Train dataset size: 20
Val dataset size: 10
Train dataset size: 20
Val dataset size: 10
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Total parameters: 242,767,409
Trainable parameters: 1,034,496
Frozen parameters: 241,732,913

Parameters by module:
*************************************************************************************************************
  sam_encoder:
    Total: 87,293,696
    Trainable: 898,048
    Frozen: 86,395,648
*******************************************************************************************
*************************************************************************************************************
  clip_model:
    Total: 151,277,313
    Trainable: 0
    Frozen: 151,277,313
*******************************************************************************************
*************************************************************************************************************
  prompt_encoder:
    Total: 6,220
    Trainable: 0
    Frozen: 6,220
*******************************************************************************************
*************************************************************************************************************
  mask_decoder:
    Total: 4,058,340
    Trainable: 4,608
    Frozen: 4,053,732
*******************************************************************************************
*************************************************************************************************************
  Text_Embedding_Affine:
    Total: 131,840
    Trainable: 131,840
    Frozen: 0
*******************************************************************************************
./svdtuning/DIAS
Training parameters: 
----------
number of trainable parameters:  1034496
batch size:  5
num epochs:  200
Epoch 0/199
----------
train Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 0:   0%|          | 0/4 [00:02<?, ?it/s, loss=0.946, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.89s/it, loss=0.946, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:03<00:08,  2.89s/it, loss=0.968, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.29s/it, loss=0.968, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.29s/it, loss=0.968, dice=tensor(0.0002, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.29it/s, loss=0.968, dice=tensor(0.0002, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.29it/s, loss=0.947, dice=tensor(0.0003, device='cuda:0')]train Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.88it/s, loss=0.947, dice=tensor(0.0003, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.9574 Dice: 0.0001
val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.92, dice=tensor(0.0008, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.92, dice=tensor(0.0008, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.914, dice=tensor(0.0030, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.9169 Dice: 0.0006
Epoch 1/199
----------
train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.914, dice=tensor(0.0173, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.914, dice=tensor(0.0173, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.89, dice=tensor(0.0927, device='cuda:0')] train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.89, dice=tensor(0.0927, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.919, dice=tensor(0.0700, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.919, dice=tensor(0.0700, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.891, dice=tensor(0.0877, device='cuda:0')]train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.891, dice=tensor(0.0877, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                              train Loss: 0.9036 Dice: 0.0175
val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.923, dice=tensor(0.1099, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.923, dice=tensor(0.1099, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.922, dice=tensor(0.0901, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9222 Dice: 0.0180
Epoch 2/199
----------
train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.89, dice=tensor(0.0624, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.89, dice=tensor(0.0624, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.897, dice=tensor(0.0604, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.897, dice=tensor(0.0604, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.91, dice=tensor(0.0989, device='cuda:0')] train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.91, dice=tensor(0.0989, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.897, dice=tensor(0.1765, device='cuda:0')]train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.897, dice=tensor(0.1765, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                              train Loss: 0.8986 Dice: 0.0353
val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.936, dice=tensor(0.1228, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.936, dice=tensor(0.1228, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.909, dice=tensor(0.1543, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9227 Dice: 0.0309
Epoch 3/199
----------
train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.9, dice=tensor(0.1115, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.9, dice=tensor(0.1115, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.882, dice=tensor(0.2468, device='cuda:0')]train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.882, dice=tensor(0.2468, device='cuda:0')]train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.897, dice=tensor(0.2141, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.897, dice=tensor(0.2141, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.917, dice=tensor(0.1789, device='cuda:0')]train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.917, dice=tensor(0.1789, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                              train Loss: 0.8990 Dice: 0.0358
val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.907, dice=tensor(0.2303, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.907, dice=tensor(0.2303, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.935, dice=tensor(0.1796, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.9208 Dice: 0.0359
Epoch 4/199
----------
train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.9, dice=tensor(0.2277, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.9, dice=tensor(0.2277, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.851, dice=tensor(0.3134, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.851, dice=tensor(0.3134, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.923, dice=tensor(0.2922, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.923, dice=tensor(0.2922, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.909, dice=tensor(0.2697, device='cuda:0')]train Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.909, dice=tensor(0.2697, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                              train Loss: 0.8956 Dice: 0.0539
val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.919, dice=tensor(0.2075, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.919, dice=tensor(0.2075, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.911, dice=tensor(0.1909, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.9149 Dice: 0.0382
Epoch 5/199
----------
train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.927, dice=tensor(0.3812, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.927, dice=tensor(0.3812, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.878, dice=tensor(0.2886, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.878, dice=tensor(0.2886, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.895, dice=tensor(0.2500, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.895, dice=tensor(0.2500, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.876, dice=tensor(0.2522, device='cuda:0')]train Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.876, dice=tensor(0.2522, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                              train Loss: 0.8939 Dice: 0.0504
val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.918, dice=tensor(0.2341, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.918, dice=tensor(0.2341, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.904, dice=tensor(0.1927, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.9107 Dice: 0.0385
Epoch 6/199
----------
train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.933, dice=tensor(0.2004, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.933, dice=tensor(0.2004, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.849, dice=tensor(0.3300, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.849, dice=tensor(0.3300, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.883, dice=tensor(0.2938, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.883, dice=tensor(0.2938, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.895, dice=tensor(0.2256, device='cuda:0')]train Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.895, dice=tensor(0.2256, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                              train Loss: 0.8900 Dice: 0.0451
val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.893, dice=tensor(0.1447, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.893, dice=tensor(0.1447, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.921, dice=tensor(0.1854, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.9071 Dice: 0.0371
Epoch 7/199
----------
train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.883, dice=tensor(0.2356, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.883, dice=tensor(0.2356, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.863, dice=tensor(0.2117, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.863, dice=tensor(0.2117, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.875, dice=tensor(0.1671, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.875, dice=tensor(0.1671, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.914, dice=tensor(0.1690, device='cuda:0')]train Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.914, dice=tensor(0.1690, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.8839 Dice: 0.0338
val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.893, dice=tensor(0.1749, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.893, dice=tensor(0.1749, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.914, dice=tensor(0.1854, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.9037 Dice: 0.0371
Epoch 8/199
----------
train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.913, dice=tensor(0.0349, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.40it/s, loss=0.913, dice=tensor(0.0349, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.40it/s, loss=0.88, dice=tensor(0.0195, device='cuda:0')] train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.57it/s, loss=0.88, dice=tensor(0.0195, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.57it/s, loss=0.874, dice=tensor(0.0302, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.51it/s, loss=0.874, dice=tensor(0.0302, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.51it/s, loss=0.866, dice=tensor(0.1363, device='cuda:0')]train Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.23it/s, loss=0.866, dice=tensor(0.1363, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                              train Loss: 0.8833 Dice: 0.0273
val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.891, dice=tensor(0.1706, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.891, dice=tensor(0.1706, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.909, dice=tensor(0.1884, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.9001 Dice: 0.0377
Epoch 9/199
----------
train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.899, dice=tensor(0.0945, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.899, dice=tensor(0.0945, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.881, dice=tensor(0.0490, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.881, dice=tensor(0.0490, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.834, dice=tensor(0.2060, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.834, dice=tensor(0.2060, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.882, dice=tensor(0.2538, device='cuda:0')]train Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.882, dice=tensor(0.2538, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                              train Loss: 0.8740 Dice: 0.0508
val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.887, dice=tensor(0.2003, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.887, dice=tensor(0.2003, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.906, dice=tensor(0.2037, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.8961 Dice: 0.0407
Epoch 10/199
----------
train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.887, dice=tensor(0.0349, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.887, dice=tensor(0.0349, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.86, dice=tensor(0.0329, device='cuda:0')] train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.86, dice=tensor(0.0329, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.904, dice=tensor(0.0236, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.904, dice=tensor(0.0236, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.855, dice=tensor(0.0375, device='cuda:0')]train Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.855, dice=tensor(0.0375, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.8766 Dice: 0.0075
val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.903, dice=tensor(0.3498, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.903, dice=tensor(0.3498, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.876, dice=tensor(0.2453, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.8897 Dice: 0.0491
Epoch 11/199
----------
train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.847, dice=tensor(0.1127, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.847, dice=tensor(0.1127, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.847, dice=tensor(0.1940, device='cuda:0')]train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.847, dice=tensor(0.1940, device='cuda:0')]train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.89, dice=tensor(0.1955, device='cuda:0')] train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.89, dice=tensor(0.1955, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.865, dice=tensor(0.2150, device='cuda:0')]train Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.865, dice=tensor(0.2150, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.8623 Dice: 0.0430
val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.897, dice=tensor(0.2342, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.897, dice=tensor(0.2342, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.882, dice=tensor(0.2618, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.8892 Dice: 0.0524
Epoch 12/199
----------
train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.89, dice=tensor(0.0296, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.89, dice=tensor(0.0296, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.828, dice=tensor(0.0296, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.828, dice=tensor(0.0296, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.869, dice=tensor(0.0615, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.869, dice=tensor(0.0615, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.853, dice=tensor(0.2592, device='cuda:0')]train Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.853, dice=tensor(0.2592, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.8601 Dice: 0.0518
val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.902, dice=tensor(0.2051, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.902, dice=tensor(0.2051, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.87, dice=tensor(0.2289, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.8862 Dice: 0.0458
Epoch 13/199
----------
train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.843, dice=tensor(0.4912, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.843, dice=tensor(0.4912, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.836, dice=tensor(0.2734, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.836, dice=tensor(0.2734, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.852, dice=tensor(0.3954, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.852, dice=tensor(0.3954, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.833, dice=tensor(0.4849, device='cuda:0')]train Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.833, dice=tensor(0.4849, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.8410 Dice: 0.0970
val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.879, dice=tensor(0.1744, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.879, dice=tensor(0.1744, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.888, dice=tensor(0.2454, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.8833 Dice: 0.0491
Epoch 14/199
----------
train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.822, dice=tensor(0.8330, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.822, dice=tensor(0.8330, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.853, dice=tensor(0.5593, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.853, dice=tensor(0.5593, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.871, dice=tensor(0.5898, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.871, dice=tensor(0.5898, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.78, dice=tensor(0.6383, device='cuda:0')] train Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.78, dice=tensor(0.6383, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                              train Loss: 0.8316 Dice: 0.1277
val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.883, dice=tensor(0.4805, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.883, dice=tensor(0.4805, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.878, dice=tensor(0.2611, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.8803 Dice: 0.0522
Epoch 15/199
----------
train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.859, dice=tensor(0.4603, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.84it/s, loss=0.859, dice=tensor(0.4603, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.84it/s, loss=0.772, dice=tensor(1.1536, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.772, dice=tensor(1.1536, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.816, dice=tensor(1.2135, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.05it/s, loss=0.816, dice=tensor(1.2135, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.05it/s, loss=0.777, dice=tensor(1.1637, device='cuda:0')]train Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.69it/s, loss=0.777, dice=tensor(1.1637, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.8061 Dice: 0.2327
val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.889, dice=tensor(0.2219, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.889, dice=tensor(0.2219, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.869, dice=tensor(0.4807, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.8792 Dice: 0.0961
Epoch 16/199
----------
train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.841, dice=tensor(0.8907, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.841, dice=tensor(0.8907, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.798, dice=tensor(0.9667, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.798, dice=tensor(0.9667, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.785, dice=tensor(1.3575, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.785, dice=tensor(1.3575, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.675, dice=tensor(1.3995, device='cuda:0')]train Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.675, dice=tensor(1.3995, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.7748 Dice: 0.2799
val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.918, dice=tensor(0.0127, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.918, dice=tensor(0.0127, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.888, dice=tensor(0.1464, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.9029 Dice: 0.0293
Epoch 17/199
----------
train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.725, dice=tensor(2.1865, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.725, dice=tensor(2.1865, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.798, dice=tensor(2.1890, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.798, dice=tensor(2.1890, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.693, dice=tensor(2.2803, device='cuda:0')]train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.693, dice=tensor(2.2803, device='cuda:0')]train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.699, dice=tensor(2.1878, device='cuda:0')]train Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.699, dice=tensor(2.1878, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.7286 Dice: 0.4376
val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.85, dice=tensor(0.8673, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.85, dice=tensor(0.8673, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.879, dice=tensor(0.6552, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.8644 Dice: 0.1310
Epoch 18/199
----------
train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.783, dice=tensor(2.0440, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.783, dice=tensor(2.0440, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.647, dice=tensor(2.0833, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.647, dice=tensor(2.0833, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.568, dice=tensor(2.3519, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.568, dice=tensor(2.3519, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.664, dice=tensor(2.2702, device='cuda:0')]train Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.664, dice=tensor(2.2702, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.6656 Dice: 0.4540
val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.743, dice=tensor(1.5793, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.743, dice=tensor(1.5793, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.807, dice=tensor(1.1173, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.7749 Dice: 0.2235
Epoch 19/199
----------
train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.664, dice=tensor(2.2528, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.664, dice=tensor(2.2528, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.548, dice=tensor(2.6468, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.548, dice=tensor(2.6468, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.494, dice=tensor(2.6113, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.494, dice=tensor(2.6113, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.655, dice=tensor(2.5580, device='cuda:0')]train Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.655, dice=tensor(2.5580, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.5903 Dice: 0.5116
val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.805, dice=tensor(0.5302, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.805, dice=tensor(0.5302, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.828, dice=tensor(0.6470, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.8166 Dice: 0.1294
Epoch 20/199
----------
train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.592, dice=tensor(1.6021, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.592, dice=tensor(1.6021, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.587, dice=tensor(2.2768, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.587, dice=tensor(2.2768, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.501, dice=tensor(2.4999, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.501, dice=tensor(2.4999, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.47, dice=tensor(2.5637, device='cuda:0')] train Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.47, dice=tensor(2.5637, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.5374 Dice: 0.5127
val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.991, dice=tensor(0.1488, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.991, dice=tensor(0.1488, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.955, dice=tensor(0.2166, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.9733 Dice: 0.0433
Epoch 21/199
----------
train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.481, dice=tensor(2.9549, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.481, dice=tensor(2.9549, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.596, dice=tensor(2.7701, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.596, dice=tensor(2.7701, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.408, dice=tensor(2.8533, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.408, dice=tensor(2.8533, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.548, dice=tensor(2.7502, device='cuda:0')]train Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.548, dice=tensor(2.7502, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.5081 Dice: 0.5500
val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.964, dice=tensor(0.2790, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.964, dice=tensor(0.2790, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.986, dice=tensor(0.2308, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.9750 Dice: 0.0462
Epoch 22/199
----------
train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.412, dice=tensor(2.9819, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.412, dice=tensor(2.9819, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.46, dice=tensor(2.8619, device='cuda:0')] train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.46, dice=tensor(2.8619, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.396, dice=tensor(2.8849, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.396, dice=tensor(2.8849, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.479, dice=tensor(2.7907, device='cuda:0')]train Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.479, dice=tensor(2.7907, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.4368 Dice: 0.5581
val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.996, dice=tensor(0.1406, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.996, dice=tensor(0.1406, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.957, dice=tensor(0.2316, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.9765 Dice: 0.0463
Epoch 23/199
----------
train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.452, dice=tensor(2.7914, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.452, dice=tensor(2.7914, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.354, dice=tensor(3.0566, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.354, dice=tensor(3.0566, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.487, dice=tensor(2.9486, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.487, dice=tensor(2.9486, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.351, dice=tensor(3.0511, device='cuda:0')]train Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.351, dice=tensor(3.0511, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.4112 Dice: 0.6102
val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s, loss=1, dice=tensor(0.1042, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=1, dice=tensor(0.1042, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.964, dice=tensor(0.2054, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.9834 Dice: 0.0411
Epoch 24/199
----------
train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.2435, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.366, dice=tensor(3.2435, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.422, dice=tensor(3.1117, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.422, dice=tensor(3.1117, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.374, dice=tensor(3.1384, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.374, dice=tensor(3.1384, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.376, dice=tensor(3.1357, device='cuda:0')]train Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.376, dice=tensor(3.1357, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3845 Dice: 0.6271
val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.975, dice=tensor(0.2628, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.975, dice=tensor(0.2628, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.981, dice=tensor(0.2257, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.9777 Dice: 0.0451
Epoch 25/199
----------
train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.3943, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.331, dice=tensor(3.3943, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.443, dice=tensor(3.1215, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.443, dice=tensor(3.1215, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.344, dice=tensor(3.2048, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.344, dice=tensor(3.2048, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.379, dice=tensor(3.2125, device='cuda:0')]train Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.379, dice=tensor(3.2125, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3741 Dice: 0.6425
val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.978, dice=tensor(0.2313, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.978, dice=tensor(0.2313, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.961, dice=tensor(0.2615, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.9697 Dice: 0.0523
Epoch 26/199
----------
train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.1290, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.364, dice=tensor(3.1290, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.39, dice=tensor(3.0785, device='cuda:0')] train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.39, dice=tensor(3.0785, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.379, dice=tensor(3.0833, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.379, dice=tensor(3.0833, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.354, dice=tensor(3.1245, device='cuda:0')]train Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.354, dice=tensor(3.1245, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3717 Dice: 0.6249
val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.928, dice=tensor(0.4233, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.928, dice=tensor(0.4233, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.971, dice=tensor(0.3385, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.9494 Dice: 0.0677
Epoch 27/199
----------
train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3315, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.337, dice=tensor(3.3315, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.328, dice=tensor(3.3602, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.328, dice=tensor(3.3602, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.391, dice=tensor(3.2695, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.391, dice=tensor(3.2695, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.425, dice=tensor(3.1226, device='cuda:0')]train Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.425, dice=tensor(3.1226, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3701 Dice: 0.6245
val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.964, dice=tensor(0.3028, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.964, dice=tensor(0.3028, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.889, dice=tensor(0.4376, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.9268 Dice: 0.0875
Epoch 28/199
----------
train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.391, dice=tensor(3.1091, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.391, dice=tensor(3.1091, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.371, dice=tensor(3.0844, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.371, dice=tensor(3.0844, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.394, dice=tensor(3.0729, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.394, dice=tensor(3.0729, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.33, dice=tensor(3.1640, device='cuda:0')] train Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.33, dice=tensor(3.1640, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                              train Loss: 0.3714 Dice: 0.6328
val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.959, dice=tensor(0.3102, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.959, dice=tensor(0.3102, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.881, dice=tensor(0.4565, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.9197 Dice: 0.0913
Epoch 29/199
----------
train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2201, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.345, dice=tensor(3.2201, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.344, dice=tensor(3.2270, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.344, dice=tensor(3.2270, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.425, dice=tensor(3.1269, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.425, dice=tensor(3.1269, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.373, dice=tensor(3.1414, device='cuda:0')]train Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.373, dice=tensor(3.1414, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3719 Dice: 0.6283
val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.953, dice=tensor(0.3086, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.953, dice=tensor(0.3086, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.921, dice=tensor(0.3928, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.9372 Dice: 0.0786
Epoch 30/199
----------
train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.309, dice=tensor(3.5043, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.309, dice=tensor(3.5043, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.376, dice=tensor(3.3138, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.376, dice=tensor(3.3138, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.358, dice=tensor(3.2174, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.358, dice=tensor(3.2174, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.399, dice=tensor(3.1941, device='cuda:0')]train Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.399, dice=tensor(3.1941, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3606 Dice: 0.6388
val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.963, dice=tensor(0.2469, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.963, dice=tensor(0.2469, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.962, dice=tensor(0.2756, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.9627 Dice: 0.0551
Epoch 31/199
----------
train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4484, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.322, dice=tensor(3.4484, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.366, dice=tensor(3.3316, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.366, dice=tensor(3.3316, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.374, dice=tensor(3.2983, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.374, dice=tensor(3.2983, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.364, dice=tensor(3.2503, device='cuda:0')]train Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.364, dice=tensor(3.2503, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3566 Dice: 0.6501
val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.993, dice=tensor(0.1523, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.993, dice=tensor(0.1523, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.994, dice=tensor(0.1334, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.9934 Dice: 0.0267
Epoch 32/199
----------
train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.1732, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.358, dice=tensor(3.1732, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.368, dice=tensor(3.1367, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.368, dice=tensor(3.1367, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.41, dice=tensor(3.0823, device='cuda:0')] train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.02it/s, loss=0.41, dice=tensor(3.0823, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.02it/s, loss=0.332, dice=tensor(3.1578, device='cuda:0')]train Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.332, dice=tensor(3.1578, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3668 Dice: 0.6316
val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s, loss=1, dice=tensor(0.0848, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=1, dice=tensor(0.0848, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=1.01, dice=tensor(0.0811, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 1.0058 Dice: 0.0162
Epoch 33/199
----------
train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3577, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.329, dice=tensor(3.3577, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.397, dice=tensor(3.1904, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.397, dice=tensor(3.1904, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.381, dice=tensor(3.1768, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.381, dice=tensor(3.1768, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.322, dice=tensor(3.2522, device='cuda:0')]train Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.322, dice=tensor(3.2522, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3571 Dice: 0.6504
val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.521, dice=tensor(2.3268, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.521, dice=tensor(2.3268, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.487, dice=tensor(2.5229, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.5038 Dice: 0.5046
Epoch 34/199
----------
train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.0961, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.389, dice=tensor(3.0961, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.399, dice=tensor(2.9857, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.399, dice=tensor(2.9857, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.328, dice=tensor(3.0857, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.328, dice=tensor(3.0857, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.334, dice=tensor(3.1598, device='cuda:0')]train Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.334, dice=tensor(3.1598, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3623 Dice: 0.6320
val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.729, dice=tensor(1.2042, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.729, dice=tensor(1.2042, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.693, dice=tensor(1.3097, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.7112 Dice: 0.2619
Epoch 35/199
----------
train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3806, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.338, dice=tensor(3.3806, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.372, dice=tensor(3.2705, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.372, dice=tensor(3.2705, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.344, dice=tensor(3.2630, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.344, dice=tensor(3.2630, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.363, dice=tensor(3.2336, device='cuda:0')]train Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.363, dice=tensor(3.2336, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3545 Dice: 0.6467
val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.784, dice=tensor(1.2347, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.784, dice=tensor(1.2347, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.733, dice=tensor(1.5583, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.7586 Dice: 0.3117
Epoch 36/199
----------
train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3258, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.335, dice=tensor(3.3258, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.354, dice=tensor(3.3140, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.354, dice=tensor(3.3140, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.336, dice=tensor(3.2952, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.336, dice=tensor(3.2952, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.43, dice=tensor(3.1931, device='cuda:0')] train Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.43, dice=tensor(3.1931, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                              train Loss: 0.3639 Dice: 0.6386
val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.768, dice=tensor(1.3299, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.768, dice=tensor(1.3299, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.805, dice=tensor(1.2685, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.7867 Dice: 0.2537
Epoch 37/199
----------
train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2364, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.356, dice=tensor(3.2364, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.403, dice=tensor(3.1450, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.403, dice=tensor(3.1450, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.379, dice=tensor(3.1492, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.379, dice=tensor(3.1492, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.303, dice=tensor(3.2380, device='cuda:0')]train Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.303, dice=tensor(3.2380, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3602 Dice: 0.6476
val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.755, dice=tensor(1.1076, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.755, dice=tensor(1.1076, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.768, dice=tensor(1.0965, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.7614 Dice: 0.2193
Epoch 38/199
----------
train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2584, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.36, dice=tensor(3.2584, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.34, dice=tensor(3.2469, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.34, dice=tensor(3.2469, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.371, dice=tensor(3.2326, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.371, dice=tensor(3.2326, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.32, dice=tensor(3.2698, device='cuda:0')] train Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.32, dice=tensor(3.2698, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                              train Loss: 0.3478 Dice: 0.6540
val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.489, dice=tensor(3.1128, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.489, dice=tensor(3.1128, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.525, dice=tensor(3.0771, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.5071 Dice: 0.6154
Epoch 39/199
----------
train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.452, dice=tensor(2.8078, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.452, dice=tensor(2.8078, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.295, dice=tensor(3.1793, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.65it/s, loss=0.295, dice=tensor(3.1793, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.65it/s, loss=0.397, dice=tensor(3.1202, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.397, dice=tensor(3.1202, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.37, dice=tensor(3.1403, device='cuda:0')] train Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.37, dice=tensor(3.1403, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                              train Loss: 0.3788 Dice: 0.6281
val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.1528, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.389, dice=tensor(3.1528, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.445, dice=tensor(3.0868, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.4167 Dice: 0.6174
Epoch 40/199
----------
train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3160, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.339, dice=tensor(3.3160, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.399, dice=tensor(3.1368, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.399, dice=tensor(3.1368, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.339, dice=tensor(3.1902, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.339, dice=tensor(3.1902, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.351, dice=tensor(3.2060, device='cuda:0')]train Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.351, dice=tensor(3.2060, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3570 Dice: 0.6412
val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.433, dice=tensor(3.0234, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.33it/s, loss=0.433, dice=tensor(3.0234, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.33it/s, loss=0.413, dice=tensor(3.0846, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4230 Dice: 0.6169
Epoch 41/199
----------
train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4177, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.32, dice=tensor(3.4177, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.443, dice=tensor(3.0886, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.443, dice=tensor(3.0886, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.38, dice=tensor(3.1116, device='cuda:0')] train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.38, dice=tensor(3.1116, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.329, dice=tensor(3.1745, device='cuda:0')]train Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.329, dice=tensor(3.1745, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3680 Dice: 0.6349
val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.558, dice=tensor(2.8503, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.558, dice=tensor(2.8503, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.504, dice=tensor(3.0458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.5314 Dice: 0.6092
Epoch 42/199
----------
train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.299, dice=tensor(3.5543, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.299, dice=tensor(3.5543, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.41, dice=tensor(3.3046, device='cuda:0')] train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.41, dice=tensor(3.3046, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.4, dice=tensor(3.2391, device='cuda:0')] train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.4, dice=tensor(3.2391, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.32, dice=tensor(3.2839, device='cuda:0')]train Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.32, dice=tensor(3.2839, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                              train Loss: 0.3572 Dice: 0.6568
val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.578, dice=tensor(2.4584, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.578, dice=tensor(2.4584, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.569, dice=tensor(2.7314, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.5737 Dice: 0.5463
Epoch 43/199
----------
train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.1123, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.394, dice=tensor(3.1123, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.383, dice=tensor(3.1160, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.383, dice=tensor(3.1160, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.281, dice=tensor(3.2899, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.281, dice=tensor(3.2899, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.339, dice=tensor(3.2999, device='cuda:0')]train Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.339, dice=tensor(3.2999, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3493 Dice: 0.6600
val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.439, dice=tensor(3.3086, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.439, dice=tensor(3.3086, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.53, dice=tensor(3.0844, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                            val Loss: 0.4846 Dice: 0.6169
Epoch 44/199
----------
train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.393, dice=tensor(3.0980, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.393, dice=tensor(3.0980, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.36, dice=tensor(3.1461, device='cuda:0')] train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.36, dice=tensor(3.1461, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.368, dice=tensor(3.1246, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.368, dice=tensor(3.1246, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.322, dice=tensor(3.2041, device='cuda:0')]train Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.322, dice=tensor(3.2041, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3607 Dice: 0.6408
val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.42, dice=tensor(2.9766, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.42, dice=tensor(2.9766, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.387, dice=tensor(3.0871, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.4039 Dice: 0.6174
Epoch 45/199
----------
train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4421, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.93it/s, loss=0.315, dice=tensor(3.4421, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.93it/s, loss=0.332, dice=tensor(3.3863, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.24it/s, loss=0.332, dice=tensor(3.3863, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.24it/s, loss=0.353, dice=tensor(3.3428, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.13it/s, loss=0.353, dice=tensor(3.3428, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.13it/s, loss=0.379, dice=tensor(3.2828, device='cuda:0')]train Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.76it/s, loss=0.379, dice=tensor(3.2828, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3445 Dice: 0.6566
val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.44, dice=tensor(2.8665, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.44, dice=tensor(2.8665, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.478, dice=tensor(2.7834, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.4594 Dice: 0.5567
Epoch 46/199
----------
train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3415, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.322, dice=tensor(3.3415, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.348, dice=tensor(3.3292, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.348, dice=tensor(3.3292, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.405, dice=tensor(3.2245, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.405, dice=tensor(3.2245, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.337, dice=tensor(3.2306, device='cuda:0')]train Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.337, dice=tensor(3.2306, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3530 Dice: 0.6461
val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.486, dice=tensor(2.6554, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.486, dice=tensor(2.6554, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.531, dice=tensor(2.5333, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.5085 Dice: 0.5067
Epoch 47/199
----------
train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3443, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.337, dice=tensor(3.3443, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.365, dice=tensor(3.2948, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.365, dice=tensor(3.2948, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.451, dice=tensor(3.1408, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.451, dice=tensor(3.1408, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.286, dice=tensor(3.2532, device='cuda:0')]train Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.286, dice=tensor(3.2532, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3597 Dice: 0.6506
val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.515, dice=tensor(2.5037, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.515, dice=tensor(2.5037, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.618, dice=tensor(2.2403, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.5663 Dice: 0.4481
Epoch 48/199
----------
train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.279, dice=tensor(3.6499, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.279, dice=tensor(3.6499, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.395, dice=tensor(3.3810, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.395, dice=tensor(3.3810, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.357, dice=tensor(3.3429, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.357, dice=tensor(3.3429, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.354, dice=tensor(3.3113, device='cuda:0')]train Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.354, dice=tensor(3.3113, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3461 Dice: 0.6623
val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.559, dice=tensor(2.2767, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.559, dice=tensor(2.2767, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.639, dice=tensor(2.0527, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.5991 Dice: 0.4105
Epoch 49/199
----------
train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.407, dice=tensor(3.0180, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.407, dice=tensor(3.0180, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.339, dice=tensor(3.1757, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.339, dice=tensor(3.1757, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.315, dice=tensor(3.2688, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.315, dice=tensor(3.2688, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.331, dice=tensor(3.2869, device='cuda:0')]train Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.331, dice=tensor(3.2869, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3478 Dice: 0.6574
val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.597, dice=tensor(2.0855, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.597, dice=tensor(2.0855, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.573, dice=tensor(2.1384, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.5853 Dice: 0.4277
Epoch 50/199
----------
train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3695, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.333, dice=tensor(3.3695, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.314, dice=tensor(3.3998, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.314, dice=tensor(3.3998, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.39, dice=tensor(3.3136, device='cuda:0')] train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.39, dice=tensor(3.3136, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.342, dice=tensor(3.3090, device='cuda:0')]train Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.342, dice=tensor(3.3090, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3447 Dice: 0.6618
val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.561, dice=tensor(2.2479, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.561, dice=tensor(2.2479, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.502, dice=tensor(2.4090, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.5312 Dice: 0.4818
Epoch 51/199
----------
train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3028, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.342, dice=tensor(3.3028, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.322, dice=tensor(3.3186, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.322, dice=tensor(3.3186, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.365, dice=tensor(3.2665, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.61it/s, loss=0.365, dice=tensor(3.2665, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.328, dice=tensor(3.2970, device='cuda:0')]train Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.328, dice=tensor(3.2970, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3392 Dice: 0.6594
val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.499, dice=tensor(2.5688, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.499, dice=tensor(2.5688, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.514, dice=tensor(2.5376, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.5063 Dice: 0.5075
Epoch 52/199
----------
train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2511, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.353, dice=tensor(3.2511, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.383, dice=tensor(3.1395, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.383, dice=tensor(3.1395, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.357, dice=tensor(3.1856, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.357, dice=tensor(3.1856, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.285, dice=tensor(3.2640, device='cuda:0')]train Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.285, dice=tensor(3.2640, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3445 Dice: 0.6528
val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0711, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.39, dice=tensor(3.0711, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.403, dice=tensor(3.0531, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3967 Dice: 0.6106
Epoch 53/199
----------
train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.6125, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.293, dice=tensor(3.6125, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.341, dice=tensor(3.4596, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.341, dice=tensor(3.4596, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.393, dice=tensor(3.3341, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.393, dice=tensor(3.3341, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.406, dice=tensor(3.2355, device='cuda:0')]train Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.406, dice=tensor(3.2355, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3582 Dice: 0.6471
val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2888, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.354, dice=tensor(3.2888, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.417, dice=tensor(3.1106, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3853 Dice: 0.6221
Epoch 54/199
----------
train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.4209, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.329, dice=tensor(3.4209, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.376, dice=tensor(3.2331, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.376, dice=tensor(3.2331, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.306, dice=tensor(3.3070, device='cuda:0')]train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.306, dice=tensor(3.3070, device='cuda:0')]train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.359, dice=tensor(3.2975, device='cuda:0')]train Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.359, dice=tensor(3.2975, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3422 Dice: 0.6595
val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.392, dice=tensor(3.0506, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.392, dice=tensor(3.0506, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.385, dice=tensor(3.1000, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3884 Dice: 0.6200
Epoch 55/199
----------
train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4847, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.305, dice=tensor(3.4847, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.328, dice=tensor(3.4442, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.328, dice=tensor(3.4442, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.431, dice=tensor(3.2413, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.431, dice=tensor(3.2413, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.353, dice=tensor(3.2484, device='cuda:0')]train Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.353, dice=tensor(3.2484, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3544 Dice: 0.6497
val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.399, dice=tensor(3.0001, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.399, dice=tensor(3.0001, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.39, dice=tensor(3.0772, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.3944 Dice: 0.6154
Epoch 56/199
----------
train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.415, dice=tensor(2.9922, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.415, dice=tensor(2.9922, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.313, dice=tensor(3.2292, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.313, dice=tensor(3.2292, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.368, dice=tensor(3.2185, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.368, dice=tensor(3.2185, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.305, dice=tensor(3.2903, device='cuda:0')]train Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.305, dice=tensor(3.2903, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3503 Dice: 0.6581
val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.412, dice=tensor(3.0054, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.412, dice=tensor(3.0054, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.409, dice=tensor(3.0143, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.4102 Dice: 0.6029
Epoch 57/199
----------
train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.399, dice=tensor(2.9909, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.399, dice=tensor(2.9909, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.29, dice=tensor(3.1973, device='cuda:0')] train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.29, dice=tensor(3.1973, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.336, dice=tensor(3.2347, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.336, dice=tensor(3.2347, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.341, dice=tensor(3.2652, device='cuda:0')]train Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.341, dice=tensor(3.2652, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3413 Dice: 0.6530
val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.474, dice=tensor(2.7239, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.474, dice=tensor(2.7239, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.421, dice=tensor(2.8492, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.4472 Dice: 0.5698
Epoch 58/199
----------
train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.2661, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.322, dice=tensor(3.2661, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.379, dice=tensor(3.2196, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.379, dice=tensor(3.2196, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.331, dice=tensor(3.2322, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.331, dice=tensor(3.2322, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.349, dice=tensor(3.2531, device='cuda:0')]train Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.349, dice=tensor(3.2531, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3453 Dice: 0.6506
val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.448, dice=tensor(2.8657, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.448, dice=tensor(2.8657, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.437, dice=tensor(2.8702, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.4425 Dice: 0.5740
Epoch 59/199
----------
train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.2493, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.344, dice=tensor(3.2493, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.397, dice=tensor(3.1570, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.397, dice=tensor(3.1570, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.329, dice=tensor(3.2417, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.329, dice=tensor(3.2417, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.312, dice=tensor(3.2920, device='cuda:0')]train Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.312, dice=tensor(3.2920, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3455 Dice: 0.6584
val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.418, dice=tensor(2.9705, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.418, dice=tensor(2.9705, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.415, dice=tensor(2.9820, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4163 Dice: 0.5964
Epoch 60/199
----------
train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.3088, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.349, dice=tensor(3.3088, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.276, dice=tensor(3.4599, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.276, dice=tensor(3.4599, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.36, dice=tensor(3.3920, device='cuda:0')] train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.36, dice=tensor(3.3920, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.344, dice=tensor(3.3499, device='cuda:0')]train Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.344, dice=tensor(3.3499, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3323 Dice: 0.6700
val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.386, dice=tensor(3.1430, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.386, dice=tensor(3.1430, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.389, dice=tensor(3.1098, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3877 Dice: 0.6220
Epoch 61/199
----------
train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.2893, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.333, dice=tensor(3.2893, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.319, dice=tensor(3.3696, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.319, dice=tensor(3.3696, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.336, dice=tensor(3.3588, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.336, dice=tensor(3.3588, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.35, dice=tensor(3.3430, device='cuda:0')] train Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.35, dice=tensor(3.3430, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                              train Loss: 0.3345 Dice: 0.6686
val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.391, dice=tensor(3.0592, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.391, dice=tensor(3.0592, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.375, dice=tensor(3.1288, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3830 Dice: 0.6258
Epoch 62/199
----------
train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.5445, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.291, dice=tensor(3.5445, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.347, dice=tensor(3.4120, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.65it/s, loss=0.347, dice=tensor(3.4120, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.65it/s, loss=0.393, dice=tensor(3.3123, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.393, dice=tensor(3.3123, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.349, dice=tensor(3.2981, device='cuda:0')]train Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.29it/s, loss=0.349, dice=tensor(3.2981, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3449 Dice: 0.6596
val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.0596, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.384, dice=tensor(3.0596, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.38, dice=tensor(3.1301, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.3819 Dice: 0.6260
Epoch 63/199
----------
train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.1523, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.354, dice=tensor(3.1523, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.371, dice=tensor(3.2086, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.371, dice=tensor(3.2086, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.28, dice=tensor(3.3548, device='cuda:0')] train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.28, dice=tensor(3.3548, device='cuda:0')]train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.376, dice=tensor(3.2666, device='cuda:0')]train Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.376, dice=tensor(3.2666, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3452 Dice: 0.6533
val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4284, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.327, dice=tensor(3.4284, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.444, dice=tensor(3.1272, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3854 Dice: 0.6254
Epoch 64/199
----------
train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.5251, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.303, dice=tensor(3.5251, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.353, dice=tensor(3.3549, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.353, dice=tensor(3.3549, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.353, dice=tensor(3.2784, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.353, dice=tensor(3.2784, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.339, dice=tensor(3.2980, device='cuda:0')]train Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.339, dice=tensor(3.2980, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3371 Dice: 0.6596
val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.1141, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.398, dice=tensor(3.1141, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.366, dice=tensor(3.1301, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3824 Dice: 0.6260
Epoch 65/199
----------
train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.4887, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.293, dice=tensor(3.4887, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.42, dice=tensor(3.2193, device='cuda:0')] train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.42, dice=tensor(3.2193, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.353, dice=tensor(3.2230, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.353, dice=tensor(3.2230, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.37, dice=tensor(3.1916, device='cuda:0')] train Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.37, dice=tensor(3.1916, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                              train Loss: 0.3591 Dice: 0.6383
val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.1634, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.389, dice=tensor(3.1634, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.385, dice=tensor(3.1150, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3870 Dice: 0.6230
Epoch 66/199
----------
train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.3, dice=tensor(3.4642, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.3, dice=tensor(3.4642, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.323, dice=tensor(3.4213, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.323, dice=tensor(3.4213, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.346, dice=tensor(3.3858, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.346, dice=tensor(3.3858, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.382, dice=tensor(3.3171, device='cuda:0')]train Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.382, dice=tensor(3.3171, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3380 Dice: 0.6634
val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.421, dice=tensor(2.9890, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.421, dice=tensor(2.9890, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.341, dice=tensor(3.1236, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3815 Dice: 0.6247
Epoch 67/199
----------
train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.297, dice=tensor(3.5044, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.297, dice=tensor(3.5044, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.353, dice=tensor(3.3546, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.353, dice=tensor(3.3546, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.418, dice=tensor(3.2188, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.418, dice=tensor(3.2188, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.314, dice=tensor(3.2755, device='cuda:0')]train Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.314, dice=tensor(3.2755, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3455 Dice: 0.6551
val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2715, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.359, dice=tensor(3.2715, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.406, dice=tensor(3.1351, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3826 Dice: 0.6270
Epoch 68/199
----------
train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3644, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.328, dice=tensor(3.3644, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.41, dice=tensor(3.1765, device='cuda:0')] train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.41, dice=tensor(3.1765, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.351, dice=tensor(3.1862, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.351, dice=tensor(3.1862, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.316, dice=tensor(3.2470, device='cuda:0')]train Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.316, dice=tensor(3.2470, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3511 Dice: 0.6494
val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.3010, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.17it/s, loss=0.358, dice=tensor(3.3010, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.17it/s, loss=0.437, dice=tensor(3.1134, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3970 Dice: 0.6227
Epoch 69/199
----------
train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.2001, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.321, dice=tensor(3.2001, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.318, dice=tensor(3.3427, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.318, dice=tensor(3.3427, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.367, dice=tensor(3.3000, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.367, dice=tensor(3.3000, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.349, dice=tensor(3.2691, device='cuda:0')]train Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.349, dice=tensor(3.2691, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3387 Dice: 0.6538
val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.442, dice=tensor(2.9529, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.442, dice=tensor(2.9529, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.382, dice=tensor(3.1167, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4122 Dice: 0.6233
Epoch 70/199
----------
train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2597, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.357, dice=tensor(3.2597, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.35, dice=tensor(3.2666, device='cuda:0')] train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.35, dice=tensor(3.2666, device='cuda:0')]train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.319, dice=tensor(3.3146, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.319, dice=tensor(3.3146, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.306, dice=tensor(3.3460, device='cuda:0')]train Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.306, dice=tensor(3.3460, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3330 Dice: 0.6692
val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.399, dice=tensor(3.3308, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.24it/s, loss=0.399, dice=tensor(3.3308, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.24it/s, loss=0.481, dice=tensor(3.1188, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4397 Dice: 0.6238
Epoch 71/199
----------
train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.2858, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.317, dice=tensor(3.2858, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.351, dice=tensor(3.2736, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.351, dice=tensor(3.2736, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.332, dice=tensor(3.3169, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.332, dice=tensor(3.3169, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.351, dice=tensor(3.2833, device='cuda:0')]train Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.351, dice=tensor(3.2833, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3378 Dice: 0.6567
val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.461, dice=tensor(3.0750, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.461, dice=tensor(3.0750, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.429, dice=tensor(3.1104, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4453 Dice: 0.6221
Epoch 72/199
----------
train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.0131, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.366, dice=tensor(3.0131, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.349, dice=tensor(3.1489, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.349, dice=tensor(3.1489, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.358, dice=tensor(3.1991, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.358, dice=tensor(3.1991, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.303, dice=tensor(3.2815, device='cuda:0')]train Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.303, dice=tensor(3.2815, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3441 Dice: 0.6563
val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.431, dice=tensor(3.2556, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.431, dice=tensor(3.2556, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.513, dice=tensor(3.0801, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.4718 Dice: 0.6160
Epoch 73/199
----------
train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.2066, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.355, dice=tensor(3.2066, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.313, dice=tensor(3.3092, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.313, dice=tensor(3.3092, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.366, dice=tensor(3.2745, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.366, dice=tensor(3.2745, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.309, dice=tensor(3.3284, device='cuda:0')]train Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.309, dice=tensor(3.3284, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3356 Dice: 0.6657
val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.47, dice=tensor(3.1028, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.47, dice=tensor(3.1028, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.488, dice=tensor(3.0458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.4792 Dice: 0.6092
Epoch 74/199
----------
train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.2091, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.368, dice=tensor(3.2091, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.311, dice=tensor(3.3459, device='cuda:0')]train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.311, dice=tensor(3.3459, device='cuda:0')]train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.34, dice=tensor(3.3395, device='cuda:0')] train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.34, dice=tensor(3.3395, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.295, dice=tensor(3.3785, device='cuda:0')]train Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.295, dice=tensor(3.3785, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3285 Dice: 0.6757
val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.604, dice=tensor(2.3208, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.604, dice=tensor(2.3208, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.502, dice=tensor(2.7360, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.5529 Dice: 0.5472
Epoch 75/199
----------
train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.0810, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.375, dice=tensor(3.0810, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.301, dice=tensor(3.3052, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.301, dice=tensor(3.3052, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.39, dice=tensor(3.2522, device='cuda:0')] train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.39, dice=tensor(3.2522, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.315, dice=tensor(3.2914, device='cuda:0')]train Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.315, dice=tensor(3.2914, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3452 Dice: 0.6583
val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.537, dice=tensor(2.6763, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.537, dice=tensor(2.6763, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.464, dice=tensor(2.9015, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.5005 Dice: 0.5803
Epoch 76/199
----------
train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4464, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.312, dice=tensor(3.4464, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.286, dice=tensor(3.4961, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.286, dice=tensor(3.4961, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.369, dice=tensor(3.4013, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.369, dice=tensor(3.4013, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.35, dice=tensor(3.3653, device='cuda:0')] train Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.35, dice=tensor(3.3653, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                              train Loss: 0.3289 Dice: 0.6731
val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.605, dice=tensor(2.4855, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.605, dice=tensor(2.4855, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.718, dice=tensor(1.7599, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.6615 Dice: 0.3520
Epoch 77/199
----------
train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3188, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.351, dice=tensor(3.3188, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.316, dice=tensor(3.3470, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.316, dice=tensor(3.3470, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.312, dice=tensor(3.3795, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.312, dice=tensor(3.3795, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.357, dice=tensor(3.3282, device='cuda:0')]train Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.357, dice=tensor(3.3282, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3339 Dice: 0.6656
val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.663, dice=tensor(2.1994, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.663, dice=tensor(2.1994, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.732, dice=tensor(1.4897, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.6973 Dice: 0.2979
Epoch 78/199
----------
train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.4389, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.304, dice=tensor(3.4389, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.359, dice=tensor(3.3329, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.359, dice=tensor(3.3329, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.344, dice=tensor(3.3291, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.344, dice=tensor(3.3291, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.321, dice=tensor(3.3537, device='cuda:0')]train Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.321, dice=tensor(3.3537, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3320 Dice: 0.6707
val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.448, dice=tensor(3.1558, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.448, dice=tensor(3.1558, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.498, dice=tensor(3.0987, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.4729 Dice: 0.6197
Epoch 79/199
----------
train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.1853, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.346, dice=tensor(3.1853, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.28, dice=tensor(3.3848, device='cuda:0')] train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.28, dice=tensor(3.3848, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.364, dice=tensor(3.3383, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.364, dice=tensor(3.3383, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.342, dice=tensor(3.3379, device='cuda:0')]train Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.342, dice=tensor(3.3379, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3332 Dice: 0.6676
val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.469, dice=tensor(2.8826, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.469, dice=tensor(2.8826, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.346, dice=tensor(3.1667, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.4073 Dice: 0.6333
Epoch 80/199
----------
train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2941, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.336, dice=tensor(3.2941, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.356, dice=tensor(3.2975, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.356, dice=tensor(3.2975, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.282, dice=tensor(3.3938, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.282, dice=tensor(3.3938, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.347, dice=tensor(3.3562, device='cuda:0')]train Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.347, dice=tensor(3.3562, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3300 Dice: 0.6712
val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3565, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.351, dice=tensor(3.3565, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.431, dice=tensor(3.1600, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3913 Dice: 0.6320
Epoch 81/199
----------
train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3572, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.324, dice=tensor(3.3572, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.406, dice=tensor(3.2045, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.406, dice=tensor(3.2045, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.326, dice=tensor(3.2603, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.326, dice=tensor(3.2603, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.305, dice=tensor(3.3127, device='cuda:0')]train Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.305, dice=tensor(3.3127, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3405 Dice: 0.6625
val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.42, dice=tensor(2.9269, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.42, dice=tensor(2.9269, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.345, dice=tensor(3.1409, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3827 Dice: 0.6282
Epoch 82/199
----------
train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.1590, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.345, dice=tensor(3.1590, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.326, dice=tensor(3.2372, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.326, dice=tensor(3.2372, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.297, dice=tensor(3.3402, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.297, dice=tensor(3.3402, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.344, dice=tensor(3.3391, device='cuda:0')]train Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.344, dice=tensor(3.3391, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3281 Dice: 0.6678
val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.385, dice=tensor(3.0763, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.385, dice=tensor(3.0763, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.366, dice=tensor(3.1629, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3754 Dice: 0.6326
Epoch 83/199
----------
train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.309, dice=tensor(3.4521, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.309, dice=tensor(3.4521, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.337, dice=tensor(3.4077, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.337, dice=tensor(3.4077, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.304, dice=tensor(3.4342, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.304, dice=tensor(3.4342, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.383, dice=tensor(3.3694, device='cuda:0')]train Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.383, dice=tensor(3.3694, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3333 Dice: 0.6739
val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.2464, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.365, dice=tensor(3.2464, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.38, dice=tensor(3.1712, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.3728 Dice: 0.6342
Epoch 84/199
----------
train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2188, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.359, dice=tensor(3.2188, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.321, dice=tensor(3.3363, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.321, dice=tensor(3.3363, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.333, dice=tensor(3.3139, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.333, dice=tensor(3.3139, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.333, dice=tensor(3.3267, device='cuda:0')]train Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.333, dice=tensor(3.3267, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3365 Dice: 0.6653
val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.421, dice=tensor(3.0911, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.421, dice=tensor(3.0911, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.351, dice=tensor(3.1881, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3859 Dice: 0.6376
Epoch 85/199
----------
train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2883, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.343, dice=tensor(3.2883, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.399, dice=tensor(3.1617, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.399, dice=tensor(3.1617, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.329, dice=tensor(3.2349, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.329, dice=tensor(3.2349, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.303, dice=tensor(3.3075, device='cuda:0')]train Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.303, dice=tensor(3.3075, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3433 Dice: 0.6615
val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2985, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.363, dice=tensor(3.2985, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.404, dice=tensor(3.1789, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3836 Dice: 0.6358
Epoch 86/199
----------
train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3242, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.344, dice=tensor(3.3242, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.325, dice=tensor(3.3689, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.325, dice=tensor(3.3689, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.336, dice=tensor(3.3227, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.336, dice=tensor(3.3227, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.312, dice=tensor(3.3245, device='cuda:0')]train Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.312, dice=tensor(3.3245, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3295 Dice: 0.6649
val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.416, dice=tensor(2.9436, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.416, dice=tensor(2.9436, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.324, dice=tensor(3.1844, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3698 Dice: 0.6369
Epoch 87/199
----------
train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.4543, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.301, dice=tensor(3.4543, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.354, dice=tensor(3.3610, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.354, dice=tensor(3.3610, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.4, dice=tensor(3.2467, device='cuda:0')]  train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.4, dice=tensor(3.2467, device='cuda:0')]train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.289, dice=tensor(3.3359, device='cuda:0')]train Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.289, dice=tensor(3.3359, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3359 Dice: 0.6672
val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.1846, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.357, dice=tensor(3.1846, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.403, dice=tensor(3.1334, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3800 Dice: 0.6267
Epoch 88/199
----------
train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.417, dice=tensor(2.9701, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.417, dice=tensor(2.9701, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.298, dice=tensor(3.2573, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.298, dice=tensor(3.2573, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.306, dice=tensor(3.3311, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.306, dice=tensor(3.3311, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.329, dice=tensor(3.3334, device='cuda:0')]train Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.329, dice=tensor(3.3334, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3378 Dice: 0.6667
val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.413, dice=tensor(2.9750, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.413, dice=tensor(2.9750, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.393, dice=tensor(3.0379, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4033 Dice: 0.6076
Epoch 89/199
----------
train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4428, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.322, dice=tensor(3.4428, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.319, dice=tensor(3.4428, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.319, dice=tensor(3.4428, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.357, dice=tensor(3.3616, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.357, dice=tensor(3.3616, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.321, dice=tensor(3.3630, device='cuda:0')]train Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.321, dice=tensor(3.3630, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3296 Dice: 0.6726
val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.412, dice=tensor(2.9756, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.412, dice=tensor(2.9756, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.385, dice=tensor(3.0664, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3982 Dice: 0.6133
Epoch 90/199
----------
train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.1634, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.357, dice=tensor(3.1634, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.332, dice=tensor(3.2792, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.332, dice=tensor(3.2792, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.345, dice=tensor(3.2941, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.345, dice=tensor(3.2941, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.294, dice=tensor(3.3396, device='cuda:0')]train Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.294, dice=tensor(3.3396, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3319 Dice: 0.6679
val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2672, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.362, dice=tensor(3.2672, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.4, dice=tensor(3.1428, device='cuda:0')]  /home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                           val Loss: 0.3810 Dice: 0.6286
Epoch 91/199
----------
train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2620, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.345, dice=tensor(3.2620, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.34, dice=tensor(3.3052, device='cuda:0')] train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.34, dice=tensor(3.3052, device='cuda:0')]train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.342, dice=tensor(3.3026, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.342, dice=tensor(3.3026, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.281, dice=tensor(3.3766, device='cuda:0')]train Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.281, dice=tensor(3.3766, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3271 Dice: 0.6753
val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1112, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.376, dice=tensor(3.1112, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.361, dice=tensor(3.1879, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3685 Dice: 0.6376
Epoch 92/199
----------
train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.5149, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.301, dice=tensor(3.5149, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.33, dice=tensor(3.3720, device='cuda:0')] train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.33, dice=tensor(3.3720, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.392, dice=tensor(3.2407, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.392, dice=tensor(3.2407, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.352, dice=tensor(3.2521, device='cuda:0')]train Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.352, dice=tensor(3.2521, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3435 Dice: 0.6504
val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3887, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.333, dice=tensor(3.3887, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.407, dice=tensor(3.1880, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3699 Dice: 0.6376
Epoch 93/199
----------
train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.4192, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.324, dice=tensor(3.4192, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.326, dice=tensor(3.3995, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.326, dice=tensor(3.3995, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.323, dice=tensor(3.3850, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.323, dice=tensor(3.3850, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.36, dice=tensor(3.3123, device='cuda:0')] train Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.36, dice=tensor(3.3123, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                              train Loss: 0.3333 Dice: 0.6625
val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.2028, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.376, dice=tensor(3.2028, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.36, dice=tensor(3.1883, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.3680 Dice: 0.6377
Epoch 94/199
----------
train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4942, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.308, dice=tensor(3.4942, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.335, dice=tensor(3.4055, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.335, dice=tensor(3.4055, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.316, dice=tensor(3.4029, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.316, dice=tensor(3.4029, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.347, dice=tensor(3.3748, device='cuda:0')]train Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.347, dice=tensor(3.3748, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3266 Dice: 0.6750
val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.426, dice=tensor(2.9070, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.426, dice=tensor(2.9070, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.315, dice=tensor(3.1934, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3708 Dice: 0.6387
Epoch 95/199
----------
train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.4358, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.301, dice=tensor(3.4358, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.284, dice=tensor(3.5354, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.284, dice=tensor(3.5354, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.415, dice=tensor(3.3471, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.415, dice=tensor(3.3471, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.323, dice=tensor(3.3725, device='cuda:0')]train Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.323, dice=tensor(3.3725, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3307 Dice: 0.6745
val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.397, dice=tensor(3.0053, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.397, dice=tensor(3.0053, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.337, dice=tensor(3.1962, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3669 Dice: 0.6392
Epoch 96/199
----------
train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.3, dice=tensor(3.4785, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.3, dice=tensor(3.4785, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.332, dice=tensor(3.4306, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.332, dice=tensor(3.4306, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.324, dice=tensor(3.4366, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.324, dice=tensor(3.4366, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.366, dice=tensor(3.3653, device='cuda:0')]train Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.366, dice=tensor(3.3653, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3304 Dice: 0.6731
val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.2516, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.342, dice=tensor(3.2516, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.39, dice=tensor(3.1923, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                            val Loss: 0.3657 Dice: 0.6385
Epoch 97/199
----------
train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.5542, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.296, dice=tensor(3.5542, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.322, dice=tensor(3.4797, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.322, dice=tensor(3.4797, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.373, dice=tensor(3.3554, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.373, dice=tensor(3.3554, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.339, dice=tensor(3.3546, device='cuda:0')]train Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.339, dice=tensor(3.3546, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3322 Dice: 0.6709
val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3594, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.337, dice=tensor(3.3594, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.4, dice=tensor(3.1956, device='cuda:0')]  /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                           val Loss: 0.3687 Dice: 0.6391
Epoch 98/199
----------
train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2379, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.354, dice=tensor(3.2379, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.291, dice=tensor(3.4114, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.291, dice=tensor(3.4114, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.364, dice=tensor(3.3396, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.364, dice=tensor(3.3396, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.333, dice=tensor(3.3244, device='cuda:0')]train Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.333, dice=tensor(3.3244, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3357 Dice: 0.6649
val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4557, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.321, dice=tensor(3.4557, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.421, dice=tensor(3.2052, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3710 Dice: 0.6410
Epoch 99/199
----------
train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3001, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.342, dice=tensor(3.3001, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.349, dice=tensor(3.2959, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.349, dice=tensor(3.2959, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.317, dice=tensor(3.3363, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.317, dice=tensor(3.3363, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.3, dice=tensor(3.3821, device='cuda:0')]  train Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.29it/s, loss=0.3, dice=tensor(3.3821, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                             train Loss: 0.3269 Dice: 0.6764
val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.418, dice=tensor(2.9438, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.418, dice=tensor(2.9438, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.319, dice=tensor(3.1959, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3685 Dice: 0.6392
Epoch 100/199
----------
train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4440, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.316, dice=tensor(3.4440, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.333, dice=tensor(3.4222, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.333, dice=tensor(3.4222, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.279, dice=tensor(3.4552, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.279, dice=tensor(3.4552, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.374, dice=tensor(3.3889, device='cuda:0')]train Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.374, dice=tensor(3.3889, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3255 Dice: 0.6778
val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.3030, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.354, dice=tensor(3.3030, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.386, dice=tensor(3.1981, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3696 Dice: 0.6396
Epoch 101/199
----------
train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.4279, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.307, dice=tensor(3.4279, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.36, dice=tensor(3.3173, device='cuda:0')] train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.36, dice=tensor(3.3173, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.325, dice=tensor(3.3389, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.325, dice=tensor(3.3389, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.318, dice=tensor(3.3523, device='cuda:0')]train Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.318, dice=tensor(3.3523, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3277 Dice: 0.6705
val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.2614, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.371, dice=tensor(3.2614, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.369, dice=tensor(3.1985, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3698 Dice: 0.6397
Epoch 102/199
----------
train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.0323, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.394, dice=tensor(3.0323, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.335, dice=tensor(3.2010, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.335, dice=tensor(3.2010, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.31, dice=tensor(3.2871, device='cuda:0')] train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.31, dice=tensor(3.2871, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.302, dice=tensor(3.3094, device='cuda:0')]train Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.302, dice=tensor(3.3094, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3353 Dice: 0.6619
val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.2537, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.344, dice=tensor(3.2537, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.391, dice=tensor(3.2109, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3671 Dice: 0.6422
Epoch 103/199
----------
train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3091, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.333, dice=tensor(3.3091, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.399, dice=tensor(3.1539, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.399, dice=tensor(3.1539, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.287, dice=tensor(3.2741, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.287, dice=tensor(3.2741, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.325, dice=tensor(3.2842, device='cuda:0')]train Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.325, dice=tensor(3.2842, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3361 Dice: 0.6568
val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.0694, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.398, dice=tensor(3.0694, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.342, dice=tensor(3.2117, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3699 Dice: 0.6423
Epoch 104/199
----------
train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4063, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.314, dice=tensor(3.4063, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.381, dice=tensor(3.2818, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.381, dice=tensor(3.2818, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.291, dice=tensor(3.3736, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.291, dice=tensor(3.3736, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.345, dice=tensor(3.3527, device='cuda:0')]train Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.345, dice=tensor(3.3527, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3327 Dice: 0.6705
val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1939, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.38, dice=tensor(3.1939, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.364, dice=tensor(3.1781, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3720 Dice: 0.6356
Epoch 105/199
----------
train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.2158, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.339, dice=tensor(3.2158, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.314, dice=tensor(3.3211, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.314, dice=tensor(3.3211, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.283, dice=tensor(3.4283, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.283, dice=tensor(3.4283, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.375, dice=tensor(3.3726, device='cuda:0')]train Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.375, dice=tensor(3.3726, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3275 Dice: 0.6745
val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.2517, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.368, dice=tensor(3.2517, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.367, dice=tensor(3.2030, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3671 Dice: 0.6406
Epoch 106/199
----------
train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.4635, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.301, dice=tensor(3.4635, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.343, dice=tensor(3.3722, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.64it/s, loss=0.343, dice=tensor(3.3722, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.64it/s, loss=0.344, dice=tensor(3.3058, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.344, dice=tensor(3.3058, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.324, dice=tensor(3.3372, device='cuda:0')]train Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.27it/s, loss=0.324, dice=tensor(3.3372, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3278 Dice: 0.6674
val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.422, dice=tensor(2.9463, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.422, dice=tensor(2.9463, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.32, dice=tensor(3.2050, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3711 Dice: 0.6410
Epoch 107/199
----------
train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4331, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.305, dice=tensor(3.4331, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.356, dice=tensor(3.3635, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.356, dice=tensor(3.3635, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.319, dice=tensor(3.3794, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.319, dice=tensor(3.3794, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.327, dice=tensor(3.3806, device='cuda:0')]train Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.327, dice=tensor(3.3806, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3265 Dice: 0.6761
val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.3450, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.349, dice=tensor(3.3450, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.389, dice=tensor(3.2181, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3686 Dice: 0.6436
Epoch 108/199
----------
train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4438, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.308, dice=tensor(3.4438, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.349, dice=tensor(3.3669, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.349, dice=tensor(3.3669, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.301, dice=tensor(3.4114, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.301, dice=tensor(3.4114, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.323, dice=tensor(3.4065, device='cuda:0')]train Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.323, dice=tensor(3.4065, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3203 Dice: 0.6813
val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.3468, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.35, dice=tensor(3.3468, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.385, dice=tensor(3.2197, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3675 Dice: 0.6439
Epoch 109/199
----------
train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.3589, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.325, dice=tensor(3.3589, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.378, dice=tensor(3.2772, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.378, dice=tensor(3.2772, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.322, dice=tensor(3.3145, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.322, dice=tensor(3.3145, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.308, dice=tensor(3.3404, device='cuda:0')]train Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.308, dice=tensor(3.3404, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3332 Dice: 0.6681
val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4651, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.318, dice=tensor(3.4651, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.418, dice=tensor(3.2159, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3676 Dice: 0.6432
Epoch 110/199
----------
train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.2209, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.37, dice=tensor(3.2209, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.282, dice=tensor(3.4144, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.282, dice=tensor(3.4144, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.317, dice=tensor(3.4038, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.317, dice=tensor(3.4038, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.333, dice=tensor(3.3914, device='cuda:0')]train Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.333, dice=tensor(3.3914, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3256 Dice: 0.6783
val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1439, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.369, dice=tensor(3.1439, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.36, dice=tensor(3.2149, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3644 Dice: 0.6430
Epoch 111/199
----------
train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.2753, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.335, dice=tensor(3.2753, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.277, dice=tensor(3.4660, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.277, dice=tensor(3.4660, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.312, dice=tensor(3.4689, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.312, dice=tensor(3.4689, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.37, dice=tensor(3.4085, device='cuda:0')] train Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.37, dice=tensor(3.4085, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3237 Dice: 0.6817
val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2843, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.336, dice=tensor(3.2843, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.388, dice=tensor(3.2235, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3621 Dice: 0.6447
Epoch 112/199
----------
train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.285, dice=tensor(3.6079, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.285, dice=tensor(3.6079, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.325, dice=tensor(3.4884, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.325, dice=tensor(3.4884, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.343, dice=tensor(3.4322, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.343, dice=tensor(3.4322, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.319, dice=tensor(3.4165, device='cuda:0')]train Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.319, dice=tensor(3.4165, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3181 Dice: 0.6833
val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2703, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.338, dice=tensor(3.2703, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.38, dice=tensor(3.2281, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3591 Dice: 0.6456
Epoch 113/199
----------
train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.3, dice=tensor(3.5376, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.3, dice=tensor(3.5376, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.279, dice=tensor(3.5806, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.279, dice=tensor(3.5806, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.67it/s, loss=0.337, dice=tensor(3.4944, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.337, dice=tensor(3.4944, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.388, dice=tensor(3.4069, device='cuda:0')]train Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.31it/s, loss=0.388, dice=tensor(3.4069, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3258 Dice: 0.6814
val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3081, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.334, dice=tensor(3.3081, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.399, dice=tensor(3.2240, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3669 Dice: 0.6448
Epoch 114/199
----------
train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.274, dice=tensor(3.6646, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.274, dice=tensor(3.6646, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.373, dice=tensor(3.4302, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.373, dice=tensor(3.4302, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.343, dice=tensor(3.4041, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.343, dice=tensor(3.4041, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.319, dice=tensor(3.4038, device='cuda:0')]train Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.319, dice=tensor(3.4038, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3274 Dice: 0.6808
val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.387, dice=tensor(3.1837, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.387, dice=tensor(3.1837, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.397, dice=tensor(3.2331, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3921 Dice: 0.6466
Epoch 115/199
----------
train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4255, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.321, dice=tensor(3.4255, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.383, dice=tensor(3.3010, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.383, dice=tensor(3.3010, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.327, dice=tensor(3.2860, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.327, dice=tensor(3.2860, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.281, dice=tensor(3.3653, device='cuda:0')]train Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.281, dice=tensor(3.3653, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3279 Dice: 0.6731
val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.4481, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.337, dice=tensor(3.4481, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.433, dice=tensor(3.2316, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3849 Dice: 0.6463
Epoch 116/199
----------
train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.4315, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.317, dice=tensor(3.4315, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.275, dice=tensor(3.5463, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.275, dice=tensor(3.5463, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.392, dice=tensor(3.4079, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.392, dice=tensor(3.4079, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.375, dice=tensor(3.3544, device='cuda:0')]train Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.375, dice=tensor(3.3544, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3397 Dice: 0.6709
val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.441, dice=tensor(3.1708, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.441, dice=tensor(3.1708, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.421, dice=tensor(3.1867, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.4313 Dice: 0.6373
Epoch 117/199
----------
train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.269, dice=tensor(3.6552, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.84it/s, loss=0.269, dice=tensor(3.6552, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.84it/s, loss=0.324, dice=tensor(3.5454, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.12it/s, loss=0.324, dice=tensor(3.5454, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.12it/s, loss=0.358, dice=tensor(3.4451, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.358, dice=tensor(3.4451, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.358, dice=tensor(3.3855, device='cuda:0')]train Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.358, dice=tensor(3.3855, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3272 Dice: 0.6771
val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.427, dice=tensor(3.2002, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.427, dice=tensor(3.2002, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.459, dice=tensor(3.1925, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.4427 Dice: 0.6385
Epoch 118/199
----------
train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.3961, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.321, dice=tensor(3.3961, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.331, dice=tensor(3.3821, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.331, dice=tensor(3.3821, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.327, dice=tensor(3.3779, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.327, dice=tensor(3.3779, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.287, dice=tensor(3.4242, device='cuda:0')]train Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.287, dice=tensor(3.4242, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3164 Dice: 0.6848
val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.3359, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.366, dice=tensor(3.3359, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.426, dice=tensor(3.2169, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3957 Dice: 0.6434
Epoch 119/199
----------
train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2444, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.35, dice=tensor(3.2444, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.343, dice=tensor(3.3041, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.343, dice=tensor(3.3041, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.327, dice=tensor(3.3198, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.327, dice=tensor(3.3198, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.26, dice=tensor(3.4154, device='cuda:0')] train Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.26, dice=tensor(3.4154, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3203 Dice: 0.6831
val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.425, dice=tensor(3.2883, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.425, dice=tensor(3.2883, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.453, dice=tensor(3.1935, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.4391 Dice: 0.6387
Epoch 120/199
----------
train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.2085, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.355, dice=tensor(3.2085, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.3, dice=tensor(3.3460, device='cuda:0')]  train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.3, dice=tensor(3.3460, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.353, dice=tensor(3.3197, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.353, dice=tensor(3.3197, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.304, dice=tensor(3.3622, device='cuda:0')]train Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.304, dice=tensor(3.3622, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3280 Dice: 0.6724
val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.649, dice=tensor(3.0364, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.649, dice=tensor(3.0364, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.758, dice=tensor(1.8804, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.7033 Dice: 0.3761
Epoch 121/199
----------
train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.3899, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.323, dice=tensor(3.3899, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.322, dice=tensor(3.4005, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.322, dice=tensor(3.4005, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.309, dice=tensor(3.4252, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.309, dice=tensor(3.4252, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.358, dice=tensor(3.3695, device='cuda:0')]train Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.358, dice=tensor(3.3695, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3280 Dice: 0.6739
val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.789, dice=tensor(1.2002, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.789, dice=tensor(1.2002, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.773, dice=tensor(1.3346, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.7809 Dice: 0.2669
Epoch 122/199
----------
train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.4094, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.319, dice=tensor(3.4094, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.298, dice=tensor(3.4447, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.298, dice=tensor(3.4447, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.344, dice=tensor(3.3986, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.344, dice=tensor(3.3986, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.316, dice=tensor(3.4101, device='cuda:0')]train Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.316, dice=tensor(3.4101, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3192 Dice: 0.6820
val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.782, dice=tensor(1.8185, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.21it/s, loss=0.782, dice=tensor(1.8185, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.21it/s, loss=0.797, dice=tensor(1.6478, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.7895 Dice: 0.3296
Epoch 123/199
----------
train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2586, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.35, dice=tensor(3.2586, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.354, dice=tensor(3.2094, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.354, dice=tensor(3.2094, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.327, dice=tensor(3.2613, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.327, dice=tensor(3.2613, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.284, dice=tensor(3.3458, device='cuda:0')]train Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.284, dice=tensor(3.3458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3288 Dice: 0.6692
val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.73, dice=tensor(2.4870, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.73, dice=tensor(2.4870, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.808, dice=tensor(1.8307, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.7690 Dice: 0.3661
Epoch 124/199
----------
train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.3371, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.325, dice=tensor(3.3371, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.302, dice=tensor(3.4322, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.302, dice=tensor(3.4322, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.287, dice=tensor(3.4875, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.287, dice=tensor(3.4875, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.374, dice=tensor(3.4211, device='cuda:0')]train Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.374, dice=tensor(3.4211, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3219 Dice: 0.6842
val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.651, dice=tensor(2.5394, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.651, dice=tensor(2.5394, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.698, dice=tensor(1.9793, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.6744 Dice: 0.3959
Epoch 125/199
----------
train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2218, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.363, dice=tensor(3.2218, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.305, dice=tensor(3.3320, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.305, dice=tensor(3.3320, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.314, dice=tensor(3.3571, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.314, dice=tensor(3.3571, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.305, dice=tensor(3.3974, device='cuda:0')]train Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.305, dice=tensor(3.3974, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3218 Dice: 0.6795
val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.515, dice=tensor(2.7593, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.01it/s, loss=0.515, dice=tensor(2.7593, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.01it/s, loss=0.596, dice=tensor(2.5439, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.5557 Dice: 0.5088
Epoch 126/199
----------
train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.4387, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.291, dice=tensor(3.4387, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.304, dice=tensor(3.4801, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.304, dice=tensor(3.4801, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.364, dice=tensor(3.3738, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.364, dice=tensor(3.3738, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.328, dice=tensor(3.3806, device='cuda:0')]train Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.328, dice=tensor(3.3806, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3216 Dice: 0.6761
val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.427, dice=tensor(3.1968, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.427, dice=tensor(3.1968, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.459, dice=tensor(3.1757, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.4426 Dice: 0.6351
Epoch 127/199
----------
train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.278, dice=tensor(3.5764, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.278, dice=tensor(3.5764, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.349, dice=tensor(3.4427, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.349, dice=tensor(3.4427, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.334, dice=tensor(3.4045, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.334, dice=tensor(3.4045, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.323, dice=tensor(3.4126, device='cuda:0')]train Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.323, dice=tensor(3.4126, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3213 Dice: 0.6825
val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.383, dice=tensor(3.1964, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.383, dice=tensor(3.1964, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.396, dice=tensor(3.2553, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3896 Dice: 0.6511
Epoch 128/199
----------
train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4060, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.313, dice=tensor(3.4060, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.369, dice=tensor(3.3095, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.369, dice=tensor(3.3095, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.333, dice=tensor(3.3341, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.333, dice=tensor(3.3341, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.273, dice=tensor(3.4177, device='cuda:0')]train Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.273, dice=tensor(3.4177, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3220 Dice: 0.6835
val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.387, dice=tensor(3.2508, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.387, dice=tensor(3.2508, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.359, dice=tensor(3.2544, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3729 Dice: 0.6509
Epoch 129/199
----------
train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4070, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.323, dice=tensor(3.4070, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.311, dice=tensor(3.4315, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.311, dice=tensor(3.4315, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.347, dice=tensor(3.3755, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.347, dice=tensor(3.3755, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.302, dice=tensor(3.3907, device='cuda:0')]train Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.302, dice=tensor(3.3907, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3208 Dice: 0.6781
val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.1806, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.37, dice=tensor(3.1806, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.364, dice=tensor(3.2514, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3669 Dice: 0.6503
Epoch 130/199
----------
train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.1706, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.371, dice=tensor(3.1706, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.323, dice=tensor(3.2961, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.323, dice=tensor(3.2961, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.309, dice=tensor(3.3622, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.309, dice=tensor(3.3622, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.272, dice=tensor(3.4297, device='cuda:0')]train Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.272, dice=tensor(3.4297, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3186 Dice: 0.6859
val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.3135, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.37, dice=tensor(3.3135, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.364, dice=tensor(3.2589, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3668 Dice: 0.6518
Epoch 131/199
----------
train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2564, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.351, dice=tensor(3.2564, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.302, dice=tensor(3.3663, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.302, dice=tensor(3.3663, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.328, dice=tensor(3.3462, device='cuda:0')]train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.328, dice=tensor(3.3462, device='cuda:0')]train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.287, dice=tensor(3.4078, device='cuda:0')]train Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.287, dice=tensor(3.4078, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3169 Dice: 0.6816
val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0704, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.39, dice=tensor(3.0704, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.323, dice=tensor(3.2534, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3566 Dice: 0.6507
Epoch 132/199
----------
train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.299, dice=tensor(3.5129, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.299, dice=tensor(3.5129, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.32, dice=tensor(3.4516, device='cuda:0')] train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.62it/s, loss=0.32, dice=tensor(3.4516, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.62it/s, loss=0.326, dice=tensor(3.4378, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.55it/s, loss=0.326, dice=tensor(3.4378, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.55it/s, loss=0.343, dice=tensor(3.4047, device='cuda:0')]train Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.26it/s, loss=0.343, dice=tensor(3.4047, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3219 Dice: 0.6809
val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.5091, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.304, dice=tensor(3.5091, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.4, dice=tensor(3.2627, device='cuda:0')]  /home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.3520 Dice: 0.6525
Epoch 133/199
----------
train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3792, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.339, dice=tensor(3.3792, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.352, dice=tensor(3.3250, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.352, dice=tensor(3.3250, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.279, dice=tensor(3.4395, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.279, dice=tensor(3.4395, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.313, dice=tensor(3.4458, device='cuda:0')]train Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.313, dice=tensor(3.4458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3206 Dice: 0.6892
val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4339, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.327, dice=tensor(3.4339, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.378, dice=tensor(3.2678, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3524 Dice: 0.6536
Epoch 134/199
----------
train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.2501, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.364, dice=tensor(3.2501, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.289, dice=tensor(3.4143, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.289, dice=tensor(3.4143, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.291, dice=tensor(3.4593, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.291, dice=tensor(3.4593, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.337, dice=tensor(3.4129, device='cuda:0')]train Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.337, dice=tensor(3.4129, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3202 Dice: 0.6826
val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.3057, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.353, dice=tensor(3.3057, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.351, dice=tensor(3.2659, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3521 Dice: 0.6532
Epoch 135/199
----------
train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3654, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.332, dice=tensor(3.3654, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.316, dice=tensor(3.4008, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.316, dice=tensor(3.4008, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.298, dice=tensor(3.4202, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.298, dice=tensor(3.4202, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.342, dice=tensor(3.3952, device='cuda:0')]train Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.342, dice=tensor(3.3952, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3222 Dice: 0.6790
val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3875, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.335, dice=tensor(3.3875, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.371, dice=tensor(3.2643, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3531 Dice: 0.6529
Epoch 136/199
----------
train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4719, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.306, dice=tensor(3.4719, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.323, dice=tensor(3.4386, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.323, dice=tensor(3.4386, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.287, dice=tensor(3.4838, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.287, dice=tensor(3.4838, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.34, dice=tensor(3.4330, device='cuda:0')] train Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.34, dice=tensor(3.4330, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3142 Dice: 0.6866
val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.1934, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.361, dice=tensor(3.1934, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.346, dice=tensor(3.2636, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3533 Dice: 0.6527
Epoch 137/199
----------
train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3292, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.337, dice=tensor(3.3292, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.292, dice=tensor(3.4508, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.292, dice=tensor(3.4508, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.35, dice=tensor(3.3913, device='cuda:0')] train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.35, dice=tensor(3.3913, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.296, dice=tensor(3.4325, device='cuda:0')]train Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.296, dice=tensor(3.4325, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3189 Dice: 0.6865
val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.1521, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.374, dice=tensor(3.1521, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.336, dice=tensor(3.2624, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3548 Dice: 0.6525
Epoch 138/199
----------
train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.285, dice=tensor(3.5680, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.285, dice=tensor(3.5680, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.345, dice=tensor(3.4557, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.345, dice=tensor(3.4557, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.318, dice=tensor(3.4388, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.318, dice=tensor(3.4388, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.326, dice=tensor(3.4030, device='cuda:0')]train Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.326, dice=tensor(3.4030, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3189 Dice: 0.6806
val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4503, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.321, dice=tensor(3.4503, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.387, dice=tensor(3.2672, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3542 Dice: 0.6534
Epoch 139/199
----------
train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.28, dice=tensor(3.6187, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.28, dice=tensor(3.6187, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.336, dice=tensor(3.4523, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.336, dice=tensor(3.4523, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.289, dice=tensor(3.4888, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.289, dice=tensor(3.4888, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.386, dice=tensor(3.3685, device='cuda:0')]train Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.386, dice=tensor(3.3685, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3228 Dice: 0.6737
val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.1880, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.364, dice=tensor(3.1880, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.341, dice=tensor(3.2714, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3524 Dice: 0.6543
Epoch 140/199
----------
train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.3237, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.318, dice=tensor(3.3237, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.308, dice=tensor(3.3966, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.308, dice=tensor(3.3966, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.39, dice=tensor(3.2831, device='cuda:0')] train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.39, dice=tensor(3.2831, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.305, dice=tensor(3.3340, device='cuda:0')]train Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.305, dice=tensor(3.3340, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3302 Dice: 0.6668
val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.302, dice=tensor(3.5175, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.302, dice=tensor(3.5175, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.397, dice=tensor(3.2738, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3497 Dice: 0.6548
Epoch 141/199
----------
train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.5292, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.304, dice=tensor(3.5292, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.295, dice=tensor(3.4956, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.295, dice=tensor(3.4956, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.323, dice=tensor(3.4435, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.323, dice=tensor(3.4435, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.372, dice=tensor(3.3781, device='cuda:0')]train Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.372, dice=tensor(3.3781, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3235 Dice: 0.6756
val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2200, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.352, dice=tensor(3.2200, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.347, dice=tensor(3.2751, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3498 Dice: 0.6550
Epoch 142/199
----------
train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.2291, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.367, dice=tensor(3.2291, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.306, dice=tensor(3.3172, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.306, dice=tensor(3.3172, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.344, dice=tensor(3.3194, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.344, dice=tensor(3.3194, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.266, dice=tensor(3.4034, device='cuda:0')]train Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.266, dice=tensor(3.4034, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3208 Dice: 0.6807
val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.3306, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.325, dice=tensor(3.3306, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.374, dice=tensor(3.2726, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3494 Dice: 0.6545
Epoch 143/199
----------
train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4389, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.313, dice=tensor(3.4389, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.365, dice=tensor(3.3103, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.365, dice=tensor(3.3103, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.3, dice=tensor(3.3804, device='cuda:0')]  train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.3, dice=tensor(3.3804, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.313, dice=tensor(3.3971, device='cuda:0')]train Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.313, dice=tensor(3.3971, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3225 Dice: 0.6794
val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.4070, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.332, dice=tensor(3.4070, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.369, dice=tensor(3.2746, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3504 Dice: 0.6549
Epoch 144/199
----------
train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3454, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.327, dice=tensor(3.3454, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.33, dice=tensor(3.3801, device='cuda:0')] train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.33, dice=tensor(3.3801, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.333, dice=tensor(3.3732, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.333, dice=tensor(3.3732, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.281, dice=tensor(3.4185, device='cuda:0')]train Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.281, dice=tensor(3.4185, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3181 Dice: 0.6837
val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2069, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.356, dice=tensor(3.2069, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.345, dice=tensor(3.2767, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3501 Dice: 0.6553
Epoch 145/199
----------
train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3030, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.336, dice=tensor(3.3030, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.399, dice=tensor(3.1847, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.399, dice=tensor(3.1847, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.281, dice=tensor(3.3076, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.281, dice=tensor(3.3076, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.291, dice=tensor(3.3712, device='cuda:0')]train Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.291, dice=tensor(3.3712, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3268 Dice: 0.6742
val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4163, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.326, dice=tensor(3.4163, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.389, dice=tensor(3.2585, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3579 Dice: 0.6517
Epoch 146/199
----------
train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4774, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.312, dice=tensor(3.4774, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.324, dice=tensor(3.4167, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.324, dice=tensor(3.4167, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.347, dice=tensor(3.3747, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.347, dice=tensor(3.3747, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.303, dice=tensor(3.3850, device='cuda:0')]train Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.303, dice=tensor(3.3850, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3217 Dice: 0.6770
val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.4, dice=tensor(3.0272, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.4, dice=tensor(3.0272, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.315, dice=tensor(3.2437, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3576 Dice: 0.6487
Epoch 147/199
----------
train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2712, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.354, dice=tensor(3.2712, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.3, dice=tensor(3.3854, device='cuda:0')]  train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.3, dice=tensor(3.3854, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.333, dice=tensor(3.3718, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.333, dice=tensor(3.3718, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.293, dice=tensor(3.4243, device='cuda:0')]train Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.293, dice=tensor(3.4243, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3197 Dice: 0.6849
val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.1470, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.368, dice=tensor(3.1470, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.331, dice=tensor(3.2769, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3496 Dice: 0.6554
Epoch 148/199
----------
train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3513, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.343, dice=tensor(3.3513, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.323, dice=tensor(3.3710, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.323, dice=tensor(3.3710, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.306, dice=tensor(3.3788, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.306, dice=tensor(3.3788, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.289, dice=tensor(3.4259, device='cuda:0')]train Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.289, dice=tensor(3.4259, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3153 Dice: 0.6852
val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4826, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.313, dice=tensor(3.4826, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.395, dice=tensor(3.2729, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3539 Dice: 0.6546
Epoch 149/199
----------
train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3863, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.336, dice=tensor(3.3863, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.272, dice=tensor(3.5106, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.272, dice=tensor(3.5106, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.331, dice=tensor(3.4530, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.331, dice=tensor(3.4530, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.338, dice=tensor(3.4279, device='cuda:0')]train Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.338, dice=tensor(3.4279, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3194 Dice: 0.6856
val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2746, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.338, dice=tensor(3.2746, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.364, dice=tensor(3.2708, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3512 Dice: 0.6542
Epoch 150/199
----------
train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.4092, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.324, dice=tensor(3.4092, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.285, dice=tensor(3.4999, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.285, dice=tensor(3.4999, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.307, dice=tensor(3.4750, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.307, dice=tensor(3.4750, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.338, dice=tensor(3.4366, device='cuda:0')]train Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.338, dice=tensor(3.4366, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3134 Dice: 0.6873
val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.4, dice=tensor(3.0483, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.4, dice=tensor(3.0483, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.31, dice=tensor(3.2787, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3545 Dice: 0.6557
Epoch 151/199
----------
train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3610, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.327, dice=tensor(3.3610, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.3, dice=tensor(3.4251, device='cuda:0')]  train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.3, dice=tensor(3.4251, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.317, dice=tensor(3.4304, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.317, dice=tensor(3.4304, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.332, dice=tensor(3.4071, device='cuda:0')]train Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.332, dice=tensor(3.4071, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3190 Dice: 0.6814
val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.2222, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.355, dice=tensor(3.2222, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.344, dice=tensor(3.2798, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3495 Dice: 0.6560
Epoch 152/199
----------
train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.385, dice=tensor(3.1563, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.385, dice=tensor(3.1563, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.295, dice=tensor(3.3587, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.295, dice=tensor(3.3587, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.309, dice=tensor(3.4097, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.309, dice=tensor(3.4097, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.289, dice=tensor(3.4270, device='cuda:0')]train Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.289, dice=tensor(3.4270, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3194 Dice: 0.6854
val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3898, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.334, dice=tensor(3.3898, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.365, dice=tensor(3.2789, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3498 Dice: 0.6558
Epoch 153/199
----------
train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.5794, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.291, dice=tensor(3.5794, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.323, dice=tensor(3.4970, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.323, dice=tensor(3.4970, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.343, dice=tensor(3.4475, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.343, dice=tensor(3.4475, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.316, dice=tensor(3.4219, device='cuda:0')]train Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.316, dice=tensor(3.4219, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3185 Dice: 0.6844
val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3852, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.333, dice=tensor(3.3852, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.368, dice=tensor(3.2787, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3502 Dice: 0.6557
Epoch 154/199
----------
train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.3671, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.301, dice=tensor(3.3671, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.301, dice=tensor(3.4524, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.301, dice=tensor(3.4524, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.348, dice=tensor(3.4092, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.348, dice=tensor(3.4092, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.311, dice=tensor(3.4217, device='cuda:0')]train Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.311, dice=tensor(3.4217, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3150 Dice: 0.6843
val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.4030, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.331, dice=tensor(3.4030, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.368, dice=tensor(3.2753, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3496 Dice: 0.6551
Epoch 155/199
----------
train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.275, dice=tensor(3.6151, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.275, dice=tensor(3.6151, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.334, dice=tensor(3.4656, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.334, dice=tensor(3.4656, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.312, dice=tensor(3.4670, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.312, dice=tensor(3.4670, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.367, dice=tensor(3.4079, device='cuda:0')]train Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.367, dice=tensor(3.4079, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3221 Dice: 0.6816
val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3367, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.345, dice=tensor(3.3367, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.359, dice=tensor(3.2627, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3521 Dice: 0.6525
Epoch 156/199
----------
train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4077, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.326, dice=tensor(3.4077, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.311, dice=tensor(3.4102, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.311, dice=tensor(3.4102, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.333, dice=tensor(3.3778, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.333, dice=tensor(3.3778, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.285, dice=tensor(3.4383, device='cuda:0')]train Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.285, dice=tensor(3.4383, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3137 Dice: 0.6877
val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.1009, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.384, dice=tensor(3.1009, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.326, dice=tensor(3.2588, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3548 Dice: 0.6518
Epoch 157/199
----------
train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3152, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.338, dice=tensor(3.3152, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.335, dice=tensor(3.3101, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.335, dice=tensor(3.3101, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.283, dice=tensor(3.4027, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.283, dice=tensor(3.4027, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.286, dice=tensor(3.4504, device='cuda:0')]train Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.286, dice=tensor(3.4504, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3105 Dice: 0.6901
val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3118, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.351, dice=tensor(3.3118, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.352, dice=tensor(3.2651, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3516 Dice: 0.6530
Epoch 158/199
----------
train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3532, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.328, dice=tensor(3.3532, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.297, dice=tensor(3.4280, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.297, dice=tensor(3.4280, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.319, dice=tensor(3.4228, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.319, dice=tensor(3.4228, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.298, dice=tensor(3.4547, device='cuda:0')]train Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.298, dice=tensor(3.4547, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3104 Dice: 0.6909
val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2770, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.358, dice=tensor(3.2770, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.341, dice=tensor(3.2750, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3495 Dice: 0.6550
Epoch 159/199
----------
train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4756, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.305, dice=tensor(3.4756, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.331, dice=tensor(3.4173, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.331, dice=tensor(3.4173, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.292, dice=tensor(3.4601, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.292, dice=tensor(3.4601, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.314, dice=tensor(3.4550, device='cuda:0')]train Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.314, dice=tensor(3.4550, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3103 Dice: 0.6910
val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2421, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.345, dice=tensor(3.2421, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.35, dice=tensor(3.2870, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3474 Dice: 0.6574
Epoch 160/199
----------
train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.3636, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.323, dice=tensor(3.3636, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.299, dice=tensor(3.4207, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.299, dice=tensor(3.4207, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.299, dice=tensor(3.4595, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.299, dice=tensor(3.4595, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.329, dice=tensor(3.4404, device='cuda:0')]train Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.329, dice=tensor(3.4404, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3125 Dice: 0.6881
val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.2356, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.371, dice=tensor(3.2356, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.326, dice=tensor(3.2865, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3484 Dice: 0.6573
Epoch 161/199
----------
train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.295, dice=tensor(3.5540, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.295, dice=tensor(3.5540, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.319, dice=tensor(3.4936, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.319, dice=tensor(3.4936, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.35, dice=tensor(3.4214, device='cuda:0')] train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.35, dice=tensor(3.4214, device='cuda:0')]train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.291, dice=tensor(3.4458, device='cuda:0')]train Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.291, dice=tensor(3.4458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3135 Dice: 0.6892
val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.5288, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.304, dice=tensor(3.5288, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.396, dice=tensor(3.2895, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3497 Dice: 0.6579
Epoch 162/199
----------
train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.4398, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.92it/s, loss=0.324, dice=tensor(3.4398, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.92it/s, loss=0.313, dice=tensor(3.4394, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.22it/s, loss=0.313, dice=tensor(3.4394, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.22it/s, loss=0.33, dice=tensor(3.4301, device='cuda:0')] train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.11it/s, loss=0.33, dice=tensor(3.4301, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.11it/s, loss=0.286, dice=tensor(3.4525, device='cuda:0')]train Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.73it/s, loss=0.286, dice=tensor(3.4525, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3131 Dice: 0.6905
val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3365, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.348, dice=tensor(3.3365, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.344, dice=tensor(3.2923, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3462 Dice: 0.6585
Epoch 163/199
----------
train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.4850, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.304, dice=tensor(3.4850, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.319, dice=tensor(3.4329, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.319, dice=tensor(3.4329, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.315, dice=tensor(3.4275, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.315, dice=tensor(3.4275, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.351, dice=tensor(3.3974, device='cuda:0')]train Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.351, dice=tensor(3.3974, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3222 Dice: 0.6795
val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3203, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.351, dice=tensor(3.3203, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.343, dice=tensor(3.2898, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3468 Dice: 0.6580
Epoch 164/199
----------
train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.5079, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.304, dice=tensor(3.5079, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.322, dice=tensor(3.4237, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.322, dice=tensor(3.4237, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.369, dice=tensor(3.3480, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.369, dice=tensor(3.3480, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.296, dice=tensor(3.3903, device='cuda:0')]train Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.296, dice=tensor(3.3903, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3225 Dice: 0.6781
val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2867, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.336, dice=tensor(3.2867, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.356, dice=tensor(3.2905, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3464 Dice: 0.6581
Epoch 165/199
----------
train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4018, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.327, dice=tensor(3.4018, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.288, dice=tensor(3.4438, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.288, dice=tensor(3.4438, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.283, dice=tensor(3.4980, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.283, dice=tensor(3.4980, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.367, dice=tensor(3.4245, device='cuda:0')]train Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.367, dice=tensor(3.4245, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3160 Dice: 0.6849
val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4250, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.327, dice=tensor(3.4250, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.366, dice=tensor(3.2921, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3468 Dice: 0.6584
Epoch 166/199
----------
train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3455, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.334, dice=tensor(3.3455, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.322, dice=tensor(3.4005, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.322, dice=tensor(3.4005, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.34, dice=tensor(3.3843, device='cuda:0')] train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.34, dice=tensor(3.3843, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.265, dice=tensor(3.4583, device='cuda:0')]train Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.265, dice=tensor(3.4583, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3155 Dice: 0.6917
val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3478, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.346, dice=tensor(3.3478, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.346, dice=tensor(3.2960, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3459 Dice: 0.6592
Epoch 167/199
----------
train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.4412, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.317, dice=tensor(3.4412, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.309, dice=tensor(3.4363, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.309, dice=tensor(3.4363, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.305, dice=tensor(3.4489, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.305, dice=tensor(3.4489, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.302, dice=tensor(3.4624, device='cuda:0')]train Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.302, dice=tensor(3.4624, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3083 Dice: 0.6925
val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3064, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.333, dice=tensor(3.3064, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.357, dice=tensor(3.3001, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3449 Dice: 0.6600
Epoch 168/199
----------
train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4470, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.308, dice=tensor(3.4470, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.331, dice=tensor(3.3667, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.331, dice=tensor(3.3667, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.315, dice=tensor(3.3868, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.315, dice=tensor(3.3868, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.325, dice=tensor(3.3971, device='cuda:0')]train Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.325, dice=tensor(3.3971, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3200 Dice: 0.6794
val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.4075, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.332, dice=tensor(3.4075, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.357, dice=tensor(3.3016, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3445 Dice: 0.6603
Epoch 169/199
----------
train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3616, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.332, dice=tensor(3.3616, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.297, dice=tensor(3.4475, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.297, dice=tensor(3.4475, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.368, dice=tensor(3.3784, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.368, dice=tensor(3.3784, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.257, dice=tensor(3.4619, device='cuda:0')]train Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.257, dice=tensor(3.4619, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3133 Dice: 0.6924
val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2894, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.338, dice=tensor(3.2894, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.351, dice=tensor(3.3025, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3446 Dice: 0.6605
Epoch 170/199
----------
train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4244, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.308, dice=tensor(3.4244, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.353, dice=tensor(3.3487, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.353, dice=tensor(3.3487, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.309, dice=tensor(3.3963, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.309, dice=tensor(3.3963, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.307, dice=tensor(3.4057, device='cuda:0')]train Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.307, dice=tensor(3.4057, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3191 Dice: 0.6811
val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.2418, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.368, dice=tensor(3.2418, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.322, dice=tensor(3.3046, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3448 Dice: 0.6609
Epoch 171/199
----------
train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.4009, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.301, dice=tensor(3.4009, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.32, dice=tensor(3.3983, device='cuda:0')] train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.32, dice=tensor(3.3983, device='cuda:0')]train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.318, dice=tensor(3.4167, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.318, dice=tensor(3.4167, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.318, dice=tensor(3.4189, device='cuda:0')]train Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.318, dice=tensor(3.4189, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3144 Dice: 0.6838
val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.3021, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.356, dice=tensor(3.3021, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.332, dice=tensor(3.3064, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3440 Dice: 0.6613
Epoch 172/199
----------
train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.276, dice=tensor(3.6039, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.276, dice=tensor(3.6039, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.332, dice=tensor(3.4894, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.332, dice=tensor(3.4894, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.305, dice=tensor(3.4982, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.305, dice=tensor(3.4982, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.329, dice=tensor(3.4605, device='cuda:0')]train Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.329, dice=tensor(3.4605, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3105 Dice: 0.6921
val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3454, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.346, dice=tensor(3.3454, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.343, dice=tensor(3.3043, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3442 Dice: 0.6609
Epoch 173/199
----------
train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3734, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.328, dice=tensor(3.3734, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.28, dice=tensor(3.4803, device='cuda:0')] train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.28, dice=tensor(3.4803, device='cuda:0')]train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.32, dice=tensor(3.4579, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.32, dice=tensor(3.4579, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.317, dice=tensor(3.4332, device='cuda:0')]train Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.317, dice=tensor(3.4332, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3112 Dice: 0.6866
val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.3840, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.317, dice=tensor(3.3840, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.369, dice=tensor(3.3071, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3428 Dice: 0.6614
Epoch 174/199
----------
train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.267, dice=tensor(3.6599, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.267, dice=tensor(3.6599, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.393, dice=tensor(3.3752, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.63it/s, loss=0.393, dice=tensor(3.3752, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.63it/s, loss=0.294, dice=tensor(3.4374, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.294, dice=tensor(3.4374, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.341, dice=tensor(3.4150, device='cuda:0')]train Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.27it/s, loss=0.341, dice=tensor(3.4150, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3237 Dice: 0.6830
val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2850, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.338, dice=tensor(3.2850, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.349, dice=tensor(3.3069, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3434 Dice: 0.6614
Epoch 175/199
----------
train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.273, dice=tensor(3.6493, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.273, dice=tensor(3.6493, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.33, dice=tensor(3.5351, device='cuda:0')] train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.33, dice=tensor(3.5351, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.309, dice=tensor(3.5000, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.309, dice=tensor(3.5000, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.34, dice=tensor(3.4494, device='cuda:0')] train Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.34, dice=tensor(3.4494, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3130 Dice: 0.6899
val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.4026, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.332, dice=tensor(3.4026, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.356, dice=tensor(3.3043, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3441 Dice: 0.6609
Epoch 176/199
----------
train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.4867, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.296, dice=tensor(3.4867, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.284, dice=tensor(3.5491, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.284, dice=tensor(3.5491, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.319, dice=tensor(3.4974, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.319, dice=tensor(3.4974, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.338, dice=tensor(3.4627, device='cuda:0')]train Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.338, dice=tensor(3.4627, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3089 Dice: 0.6925
val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.347, dice=tensor(3.2374, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.347, dice=tensor(3.2374, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.345, dice=tensor(3.2954, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3458 Dice: 0.6591
Epoch 177/199
----------
train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4190, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.318, dice=tensor(3.4190, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.33, dice=tensor(3.4083, device='cuda:0')] train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.33, dice=tensor(3.4083, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.288, dice=tensor(3.4461, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.288, dice=tensor(3.4461, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.313, dice=tensor(3.4402, device='cuda:0')]train Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.313, dice=tensor(3.4402, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3122 Dice: 0.6880
val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.2501, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.346, dice=tensor(3.2501, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.346, dice=tensor(3.2942, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3461 Dice: 0.6588
Epoch 178/199
----------
train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4319, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.322, dice=tensor(3.4319, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.331, dice=tensor(3.3764, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.331, dice=tensor(3.3764, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.305, dice=tensor(3.4113, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.305, dice=tensor(3.4113, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.286, dice=tensor(3.4578, device='cuda:0')]train Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.286, dice=tensor(3.4578, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3112 Dice: 0.6916
val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3048, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.332, dice=tensor(3.3048, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.355, dice=tensor(3.3052, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3437 Dice: 0.6610
Epoch 179/199
----------
train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2063, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.363, dice=tensor(3.2063, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.329, dice=tensor(3.2954, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.329, dice=tensor(3.2954, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.292, dice=tensor(3.3792, device='cuda:0')]train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.292, dice=tensor(3.3792, device='cuda:0')]train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.271, dice=tensor(3.4393, device='cuda:0')]train Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.271, dice=tensor(3.4393, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3137 Dice: 0.6879
val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.1899, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.25it/s, loss=0.364, dice=tensor(3.1899, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.25it/s, loss=0.322, dice=tensor(3.3110, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3434 Dice: 0.6622
Epoch 180/199
----------
train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.5022, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.296, dice=tensor(3.5022, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.313, dice=tensor(3.4909, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.313, dice=tensor(3.4909, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.292, dice=tensor(3.4977, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.292, dice=tensor(3.4977, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.346, dice=tensor(3.4581, device='cuda:0')]train Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.346, dice=tensor(3.4581, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3117 Dice: 0.6916
val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.3628, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.321, dice=tensor(3.3628, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.363, dice=tensor(3.3111, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3421 Dice: 0.6622
Epoch 181/199
----------
train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.276, dice=tensor(3.6453, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.276, dice=tensor(3.6453, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.337, dice=tensor(3.4693, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.337, dice=tensor(3.4693, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.346, dice=tensor(3.4223, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.346, dice=tensor(3.4223, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.273, dice=tensor(3.4749, device='cuda:0')]train Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.273, dice=tensor(3.4749, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3080 Dice: 0.6950
val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4782, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.314, dice=tensor(3.4782, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.375, dice=tensor(3.3142, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3445 Dice: 0.6628
Epoch 182/199
----------
train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.401, dice=tensor(3.0735, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.401, dice=tensor(3.0735, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.298, dice=tensor(3.2805, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.298, dice=tensor(3.2805, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.279, dice=tensor(3.3831, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.279, dice=tensor(3.3831, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.339, dice=tensor(3.3795, device='cuda:0')]train Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.339, dice=tensor(3.3795, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3292 Dice: 0.6759
val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2642, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.363, dice=tensor(3.2642, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.324, dice=tensor(3.3105, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3432 Dice: 0.6621
Epoch 183/199
----------
train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.286, dice=tensor(3.5689, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.286, dice=tensor(3.5689, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.28, dice=tensor(3.6127, device='cuda:0')] train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.28, dice=tensor(3.6127, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.347, dice=tensor(3.5230, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.347, dice=tensor(3.5230, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.322, dice=tensor(3.4793, device='cuda:0')]train Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.322, dice=tensor(3.4793, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3087 Dice: 0.6959
val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.1969, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.364, dice=tensor(3.1969, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.324, dice=tensor(3.3089, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3438 Dice: 0.6618
Epoch 184/199
----------
train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3128, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.334, dice=tensor(3.3128, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.289, dice=tensor(3.4306, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.289, dice=tensor(3.4306, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.28, dice=tensor(3.4983, device='cuda:0')] train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.28, dice=tensor(3.4983, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.323, dice=tensor(3.4821, device='cuda:0')]train Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.323, dice=tensor(3.4821, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3064 Dice: 0.6964
val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.3675, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.318, dice=tensor(3.3675, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.362, dice=tensor(3.3155, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3398 Dice: 0.6631
Epoch 185/199
----------
train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.31, dice=tensor(3.4495, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.31, dice=tensor(3.4495, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.289, dice=tensor(3.5082, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.289, dice=tensor(3.5082, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.302, dice=tensor(3.4934, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.302, dice=tensor(3.4934, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.327, dice=tensor(3.4821, device='cuda:0')]train Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.327, dice=tensor(3.4821, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3070 Dice: 0.6964
val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.2931, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.34, dice=tensor(3.2931, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.343, dice=tensor(3.3157, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3418 Dice: 0.6631
Epoch 186/199
----------
train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.5216, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.303, dice=tensor(3.5216, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.316, dice=tensor(3.4574, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.316, dice=tensor(3.4574, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.308, dice=tensor(3.4738, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.62it/s, loss=0.308, dice=tensor(3.4738, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.62it/s, loss=0.308, dice=tensor(3.4636, device='cuda:0')]train Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.308, dice=tensor(3.4636, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3088 Dice: 0.6927
val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2296, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.354, dice=tensor(3.2296, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.335, dice=tensor(3.3078, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3448 Dice: 0.6616
Epoch 187/199
----------
train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.5204, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.90it/s, loss=0.301, dice=tensor(3.5204, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.90it/s, loss=0.295, dice=tensor(3.5348, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.20it/s, loss=0.295, dice=tensor(3.5348, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.20it/s, loss=0.347, dice=tensor(3.4496, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.10it/s, loss=0.347, dice=tensor(3.4496, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.10it/s, loss=0.297, dice=tensor(3.4638, device='cuda:0')]train Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.72it/s, loss=0.297, dice=tensor(3.4638, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3100 Dice: 0.6928
val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1918, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.363, dice=tensor(3.1918, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.331, dice=tensor(3.3030, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3471 Dice: 0.6606
Epoch 188/199
----------
train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.4970, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.293, dice=tensor(3.4970, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.298, dice=tensor(3.4884, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.298, dice=tensor(3.4884, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.343, dice=tensor(3.4127, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.343, dice=tensor(3.4127, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.317, dice=tensor(3.4141, device='cuda:0')]train Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.317, dice=tensor(3.4141, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3127 Dice: 0.6828
val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2260, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.356, dice=tensor(3.2260, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.327, dice=tensor(3.3202, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3416 Dice: 0.6640
Epoch 189/199
----------
train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3385, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.348, dice=tensor(3.3385, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.312, dice=tensor(3.3732, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.312, dice=tensor(3.3732, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.293, dice=tensor(3.4342, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.293, dice=tensor(3.4342, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.3, dice=tensor(3.4526, device='cuda:0')]  train Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.3, dice=tensor(3.4526, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                              train Loss: 0.3130 Dice: 0.6905
val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.4049, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.33, dice=tensor(3.4049, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.354, dice=tensor(3.3239, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3423 Dice: 0.6648
Epoch 190/199
----------
train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1143, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.369, dice=tensor(3.1143, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.303, dice=tensor(3.3027, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.303, dice=tensor(3.3027, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.289, dice=tensor(3.3896, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.289, dice=tensor(3.3896, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.327, dice=tensor(3.3681, device='cuda:0')]train Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.327, dice=tensor(3.3681, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3220 Dice: 0.6736
val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2817, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.29it/s, loss=0.338, dice=tensor(3.2817, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.29it/s, loss=0.342, dice=tensor(3.3242, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3402 Dice: 0.6648
Epoch 191/199
----------
train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.4382, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.324, dice=tensor(3.4382, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.302, dice=tensor(3.4714, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.302, dice=tensor(3.4714, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.276, dice=tensor(3.5127, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.276, dice=tensor(3.5127, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.329, dice=tensor(3.4766, device='cuda:0')]train Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.329, dice=tensor(3.4766, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3076 Dice: 0.6953
val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2761, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.359, dice=tensor(3.2761, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.32, dice=tensor(3.3243, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3399 Dice: 0.6649
Epoch 192/199
----------
train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3281, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.322, dice=tensor(3.3281, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.322, dice=tensor(3.3788, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.322, dice=tensor(3.3788, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.264, dice=tensor(3.4678, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.264, dice=tensor(3.4678, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.339, dice=tensor(3.4348, device='cuda:0')]train Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.339, dice=tensor(3.4348, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3116 Dice: 0.6870
val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3512, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.343, dice=tensor(3.3512, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.338, dice=tensor(3.3204, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3406 Dice: 0.6641
Epoch 193/199
----------
train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.255, dice=tensor(3.7679, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.255, dice=tensor(3.7679, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.309, dice=tensor(3.6345, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.309, dice=tensor(3.6345, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.356, dice=tensor(3.5041, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.356, dice=tensor(3.5041, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.323, dice=tensor(3.4815, device='cuda:0')]train Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.323, dice=tensor(3.4815, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3107 Dice: 0.6963
val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.382, dice=tensor(3.1148, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.382, dice=tensor(3.1148, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.306, dice=tensor(3.3195, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3440 Dice: 0.6639
Epoch 194/199
----------
train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3416, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.322, dice=tensor(3.3416, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.299, dice=tensor(3.4076, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.299, dice=tensor(3.4076, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.312, dice=tensor(3.4288, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.312, dice=tensor(3.4288, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.306, dice=tensor(3.4520, device='cuda:0')]train Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.306, dice=tensor(3.4520, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3096 Dice: 0.6904
val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.3550, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.32, dice=tensor(3.3550, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.358, dice=tensor(3.3189, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3394 Dice: 0.6638
Epoch 195/199
----------
train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4925, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.312, dice=tensor(3.4925, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.276, dice=tensor(3.5600, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.276, dice=tensor(3.5600, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.354, dice=tensor(3.4708, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.354, dice=tensor(3.4708, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.291, dice=tensor(3.4897, device='cuda:0')]train Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.291, dice=tensor(3.4897, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3083 Dice: 0.6979
val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2676, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.363, dice=tensor(3.2676, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.319, dice=tensor(3.3223, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3408 Dice: 0.6645
Epoch 196/199
----------
train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3523, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.322, dice=tensor(3.3523, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.283, dice=tensor(3.4805, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.283, dice=tensor(3.4805, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.314, dice=tensor(3.4779, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.314, dice=tensor(3.4779, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.302, dice=tensor(3.4729, device='cuda:0')]train Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.302, dice=tensor(3.4729, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3055 Dice: 0.6946
val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4719, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.315, dice=tensor(3.4719, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.366, dice=tensor(3.3242, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3407 Dice: 0.6648
Epoch 197/199
----------
train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4772, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.315, dice=tensor(3.4772, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.313, dice=tensor(3.4626, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.313, dice=tensor(3.4626, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.309, dice=tensor(3.4495, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.309, dice=tensor(3.4495, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.28, dice=tensor(3.4863, device='cuda:0')] train Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.28, dice=tensor(3.4863, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3039 Dice: 0.6973
val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3970, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.335, dice=tensor(3.3970, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.344, dice=tensor(3.3267, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3398 Dice: 0.6653
Epoch 198/199
----------
train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4426, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.323, dice=tensor(3.4426, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.332, dice=tensor(3.4042, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.332, dice=tensor(3.4042, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.317, dice=tensor(3.3945, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.317, dice=tensor(3.3945, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.261, dice=tensor(3.4797, device='cuda:0')]train Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.261, dice=tensor(3.4797, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3081 Dice: 0.6959
val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2997, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.35, dice=tensor(3.2997, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.326, dice=tensor(3.3282, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3382 Dice: 0.6656
Epoch 199/199
----------
train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.373, dice=tensor(3.1219, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.373, dice=tensor(3.1219, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.306, dice=tensor(3.3137, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.306, dice=tensor(3.3137, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.272, dice=tensor(3.4131, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.272, dice=tensor(3.4131, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.322, dice=tensor(3.4098, device='cuda:0')]train Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.322, dice=tensor(3.4098, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3183 Dice: 0.6820
val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2994, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.35, dice=tensor(3.2994, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.326, dice=tensor(3.3276, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.038 MB of 0.042 MB uploaded (0.000 MB deduped)wandb: / 0.038 MB of 0.042 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: train_dice ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   val_dice ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   val_loss ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: best_val_dice 0.66552
wandb: best_val_loss 0.33813
wandb:         epoch 199
wandb:    train_dice 0.68197
wandb:    train_loss 0.3183
wandb:      val_dice 0.66552
wandb:      val_loss 0.33813
wandb: 
wandb: üöÄ View run DIAS_modelnone at: https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/ef5ojkku
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241013_211619-ef5ojkku/logs
val Loss: 0.3381 Dice: 0.6655
Best val loss: 0.338126, best val dice: 0.665515
Model saved at: ./modelsDIAS/final_model.pth
Starting RLHF fine-tuning...
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Epoch 0/39
----------
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/3 [00:02<?, ?it/s, loss=-69.3]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:05,  2.55s/it, loss=-69.3]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:05,  2.55s/it, loss=-69.7]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.26s/it, loss=-69.7]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:03<00:01,  1.26s/it, loss=-69.6]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.27it/s, loss=-69.6]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07662854343652725

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07662854343652725

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07331562042236328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.39365917444229126

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07660245895385742

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07331562042236328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.86586380004883
Max value: 94.15384674072266
Mean value: 69.25480651855469

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07662854343652725

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07662854343652725

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07662854343652725

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.39365917444229126

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.86586380004883
Max value: 94.15384674072266
Mean value: 69.25480651855469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.25489044189453
Max value: -69.25489044189453
Mean value: -69.25489044189453

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10304094851016998

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10304094851016998

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0974879264831543

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.5003883242607117

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10310745239257812

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0974879264831543

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 64.74002075195312
Max value: 78.1087875366211
Mean value: 70.10137939453125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10304094851016998

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10304094851016998

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10304094851016998

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.5003883242607117

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 64.74002075195312
Max value: 78.1087875366211
Mean value: 70.10137939453125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.10150146484375
Max value: -70.10150146484375
Mean value: -70.10150146484375
sam_encoder.pos_embed grad: 2.549193141021533e-07
sam_encoder.blocks.0.norm1.weight grad: -0.012380576692521572
sam_encoder.blocks.0.norm1.bias grad: 0.01862182468175888
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0014330715639516711
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00023129579494707286
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00010938184277620167
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.079421837057453e-06
sam_encoder.blocks.0.norm2.weight grad: 0.006764919962733984
sam_encoder.blocks.0.norm2.bias grad: 0.0005760164931416512
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0003136217128485441
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0006951983086764812
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.00466448487713933
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0003115133149549365
sam_encoder.blocks.1.norm1.weight grad: -0.00461615901440382
sam_encoder.blocks.1.norm1.bias grad: -0.0004530490259639919
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0002002324181376025
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.4966464479803108e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00033833313500508666
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002955312666017562
sam_encoder.blocks.1.norm2.weight grad: 0.004273766651749611
sam_encoder.blocks.1.norm2.bias grad: 0.002167011145502329
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0010172047186642885
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.816815923433751e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0007196666556410491
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.972994692157954e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0027079335413873196
sam_encoder.blocks.2.norm1.bias grad: -0.001816141651943326
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0009896843694150448
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.099608536809683e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0010364039335399866
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.001498652040027082
sam_encoder.blocks.2.norm2.weight grad: 0.00101296731736511
sam_encoder.blocks.2.norm2.bias grad: -0.0019127074629068375
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0009639760246500373
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0002127574261976406
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.868558168411255e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0005020424141548574
sam_encoder.blocks.3.norm1.weight grad: 1.1517046004883014e-05
sam_encoder.blocks.3.norm1.bias grad: -0.0026567818131297827
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0005991442012600601
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0002953456714749336
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0002907367888838053
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0007935153553262353
sam_encoder.blocks.3.norm2.weight grad: 0.005487091839313507
sam_encoder.blocks.3.norm2.bias grad: 0.002613568212836981
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0045913709327578545
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0015111221000552177
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.001567201572470367
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00017928375746123493
sam_encoder.blocks.4.norm1.weight grad: -0.002379117999225855
sam_encoder.blocks.4.norm1.bias grad: -0.0012621743371710181
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0012795374495908618
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0003391047939658165
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.5285290778119816e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0009900610893964767
sam_encoder.blocks.4.norm2.weight grad: -0.004416552372276783
sam_encoder.blocks.4.norm2.bias grad: -0.0012248757993802428
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.002952996641397476
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0007674868102185428
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0005219971644692123
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0002606509660836309
sam_encoder.blocks.5.norm1.weight grad: -0.004545480944216251
sam_encoder.blocks.5.norm1.bias grad: -0.0005379329668357968
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0035258233547210693
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0012708401773124933
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00048433843767270446
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0010828071972355247
sam_encoder.blocks.5.norm2.weight grad: -0.0011057673254981637
sam_encoder.blocks.5.norm2.bias grad: -1.008304207061883e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00041581859113648534
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00017846253467723727
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001558084913995117
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0002829990698955953
sam_encoder.blocks.6.norm1.weight grad: 0.00017616059631109238
sam_encoder.blocks.6.norm1.bias grad: 0.0008061527623794973
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -7.30117826606147e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00014926939911674708
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00041211332427337766
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00015419686678797007
sam_encoder.blocks.6.norm2.weight grad: 0.0014101009583100677
sam_encoder.blocks.6.norm2.bias grad: 0.0008051557233557105
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0010069224517792463
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0005089958431199193
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0004506767727434635
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0002469723694957793
sam_encoder.blocks.7.norm1.weight grad: -0.0004899674677290022
sam_encoder.blocks.7.norm1.bias grad: 0.0006653891759924591
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -9.433359082322568e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.48149647936225e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00026344676734879613
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0004825553623959422
sam_encoder.blocks.7.norm2.weight grad: 0.00018291815649718046
sam_encoder.blocks.7.norm2.bias grad: 0.00011720656038960442
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00027339067310094833
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.4720287405652925e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.849227404221892e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00019516234169714153
sam_encoder.blocks.8.norm1.weight grad: -0.0010112840682268143
sam_encoder.blocks.8.norm1.bias grad: 0.0010456880554556847
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0012022205628454685
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0007575743366032839
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 7.565071427961811e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0002995248360093683
sam_encoder.blocks.8.norm2.weight grad: 0.00021155402646400034
sam_encoder.blocks.8.norm2.bias grad: -0.0007252427749335766
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00019768350466620177
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00029558566166087985
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0004900293424725533
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.000166588113643229
sam_encoder.blocks.9.norm1.weight grad: 0.0001331359671894461
sam_encoder.blocks.9.norm1.bias grad: -0.0003952148254029453
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0003356889355927706
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0003294121415819973
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00019522625370882452
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0004957334604114294
sam_encoder.blocks.9.norm2.weight grad: -3.6451190226216568e-06
sam_encoder.blocks.9.norm2.bias grad: -0.0007122347597032785
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.413745384430513e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.400084723485634e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.281678229745012e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00024269201094284654
sam_encoder.blocks.10.norm1.weight grad: 0.00043727768934331834
sam_encoder.blocks.10.norm1.bias grad: -0.0005763734225183725
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0010840315371751785
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0004189551982562989
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0003576416929718107
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00022103234368842095
sam_encoder.blocks.10.norm2.weight grad: -0.0017135420348495245
sam_encoder.blocks.10.norm2.bias grad: -0.0018864693120121956
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.171474812319502e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0007423422648571432
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0005548775661736727
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00030569464433938265
sam_encoder.blocks.11.norm1.weight grad: -0.0034616459161043167
sam_encoder.blocks.11.norm1.bias grad: 0.0003026955237146467
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.909282870357856e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001162690605269745
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0002833631879184395
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.682170113781467e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0010423356434330344
sam_encoder.blocks.11.norm2.bias grad: -0.0019498774781823158
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0006954827695153654
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0003506698121782392
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00035940352245233953
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.508578422246501e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.0003069760277867317
sam_encoder.neck.conv1.trainable_shift grad: -0.00721720838919282
sam_encoder.neck.conv2.trainable_scale grad: -0.00047133746556937695
sam_encoder.neck.conv2.trainable_shift grad: 0.002531229518353939
mask_decoder.transformer.layers.0.norm1.weight grad: -0.10181315988302231
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0005530789494514465
mask_decoder.transformer.layers.0.norm2.weight grad: -1.5022238492965698
mask_decoder.transformer.layers.0.norm2.bias grad: -0.06045711040496826
mask_decoder.transformer.layers.0.norm3.weight grad: 0.04443939030170441
mask_decoder.transformer.layers.0.norm3.bias grad: 0.005120083689689636
mask_decoder.transformer.layers.0.norm4.weight grad: 0.043996818363666534
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0003071422688663006
mask_decoder.transformer.layers.1.norm1.weight grad: 0.03873871639370918
mask_decoder.transformer.layers.1.norm1.bias grad: -0.001546340063214302
mask_decoder.transformer.layers.1.norm2.weight grad: -0.007010560482740402
mask_decoder.transformer.layers.1.norm2.bias grad: 0.03713089972734451
mask_decoder.transformer.layers.1.norm3.weight grad: 0.02355564385652542
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0410919114947319
mask_decoder.transformer.layers.1.norm4.weight grad: 0.01873842068016529
mask_decoder.transformer.layers.1.norm4.bias grad: -0.023411357775330544
mask_decoder.transformer.norm_final_attn.weight grad: 0.009882653132081032
mask_decoder.transformer.norm_final_attn.bias grad: 0.0056354450061917305
Text_Embedding_Affine.0.weight grad: 5.971429573037312e-09
Text_Embedding_Affine.0.bias grad: 2.1245796233415604e-07
Text_Embedding_Affine.2.weight grad: 5.2723486021477584e-08
Text_Embedding_Affine.2.bias grad: 0.0024241264909505844

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08744604885578156

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08744604885578156

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07760906219482422

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.42900902032852173

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08759784698486328

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07760906219482422

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.88749313354492
Max value: 82.17305755615234
Mean value: 69.52425384521484

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08744604885578156

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08744604885578156

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08744604885578156

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.42900902032852173

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.88749313354492
Max value: 82.17305755615234
Mean value: 69.52425384521484

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.52438354492188
Max value: -69.52438354492188
Mean value: -69.52438354492188
sam_encoder.pos_embed grad: 2.0649481484724674e-06
sam_encoder.blocks.0.norm1.weight grad: -0.011960094794631004
sam_encoder.blocks.0.norm1.bias grad: -0.005672643892467022
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0007964801043272018
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.967391578247771e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0012765848077833652
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00031225901329889894
sam_encoder.blocks.0.norm2.weight grad: -0.015525063499808311
sam_encoder.blocks.0.norm2.bias grad: -0.004449066706001759
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0008779859053902328
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.001984118018299341
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.005336329340934753
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00040602253284305334
sam_encoder.blocks.1.norm1.weight grad: -0.005999439861625433
sam_encoder.blocks.1.norm1.bias grad: -0.005898009054362774
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0005298716714605689
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0004480433417484164
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0023465545382350683
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0011637011775746942
sam_encoder.blocks.1.norm2.weight grad: -0.0012460527941584587
sam_encoder.blocks.1.norm2.bias grad: 0.0017772202845662832
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.004879309330135584
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0006770362379029393
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0028777983970940113
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0007945207762531936
sam_encoder.blocks.2.norm1.weight grad: 0.0015917065320536494
sam_encoder.blocks.2.norm1.bias grad: -0.00064411002676934
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.001655252417549491
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00023299995518755168
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0006594541482627392
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0004361646715551615
sam_encoder.blocks.2.norm2.weight grad: 0.005241274368017912
sam_encoder.blocks.2.norm2.bias grad: 0.0025304213631898165
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.004023322835564613
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0008622655877843499
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006884653121232986
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0001423870853614062
sam_encoder.blocks.3.norm1.weight grad: -0.009003573097288609
sam_encoder.blocks.3.norm1.bias grad: 0.0015531227691099048
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0016586551209911704
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00034386804327368736
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0004387987428344786
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00025967005058191717
sam_encoder.blocks.3.norm2.weight grad: 0.007753185462206602
sam_encoder.blocks.3.norm2.bias grad: 0.006786087527871132
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.005341432988643646
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.001796573749743402
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0005557888653129339
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00039716792525723577
sam_encoder.blocks.4.norm1.weight grad: -0.012896865606307983
sam_encoder.blocks.4.norm1.bias grad: 0.002861684886738658
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.007714009843766689
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0024579446762800217
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.002570169745013118
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0015802995767444372
sam_encoder.blocks.4.norm2.weight grad: 0.0002658950979821384
sam_encoder.blocks.4.norm2.bias grad: 0.005696709267795086
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0011654294794425368
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0012053863611072302
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0008574786479584873
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00014311324048321694
sam_encoder.blocks.5.norm1.weight grad: -0.0064228675328195095
sam_encoder.blocks.5.norm1.bias grad: 0.005563295911997557
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.003398163942620158
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00039012214983813465
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00010976831981679425
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0020498016383498907
sam_encoder.blocks.5.norm2.weight grad: -0.0007507880218327045
sam_encoder.blocks.5.norm2.bias grad: 0.003699885681271553
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0016020460752770305
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0004058480844832957
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0004585071001201868
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.308490290190093e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00033793284092098475
sam_encoder.blocks.6.norm1.bias grad: 0.0010769797954708338
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00017693724657874554
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00043679174268618226
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0005041402764618397
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0605746865621768e-05
sam_encoder.blocks.6.norm2.weight grad: 0.004391003865748644
sam_encoder.blocks.6.norm2.bias grad: 0.0020365833770483732
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.004652205388993025
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00221260916441679
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0008324324153363705
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0004789411905221641
sam_encoder.blocks.7.norm1.weight grad: -0.0013897884637117386
sam_encoder.blocks.7.norm1.bias grad: 0.0010978230275213718
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.844538100063801e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.86614519811701e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0006639178609475493
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00013337709242478013
sam_encoder.blocks.7.norm2.weight grad: -0.0003788664180319756
sam_encoder.blocks.7.norm2.bias grad: 3.7455116398632526e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0012860866263508797
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00016224774299189448
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0003909787046723068
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0005680787726305425
sam_encoder.blocks.8.norm1.weight grad: -0.0023446299601346254
sam_encoder.blocks.8.norm1.bias grad: 0.0028742048889398575
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.003954642452299595
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0015549561940133572
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0009017742704600096
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0013581955572590232
sam_encoder.blocks.8.norm2.weight grad: 0.0017360327765345573
sam_encoder.blocks.8.norm2.bias grad: -0.00038422708166763186
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0011757672764360905
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0009286447311751544
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0006236603367142379
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0001693761150818318
sam_encoder.blocks.9.norm1.weight grad: -0.0014053643681108952
sam_encoder.blocks.9.norm1.bias grad: -8.286866068374366e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0007947154226712883
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00018354451458435506
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00013535772450268269
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.000572423217818141
sam_encoder.blocks.9.norm2.weight grad: 0.0007952098967507482
sam_encoder.blocks.9.norm2.bias grad: -0.0006382384453900158
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0011356512550264597
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0006806757301092148
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.4477637857198715e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00029523225384764373
sam_encoder.blocks.10.norm1.weight grad: -0.0005429817829281092
sam_encoder.blocks.10.norm1.bias grad: -0.0005964862648397684
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0005741458153352141
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.000266429124167189
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00043365772580727935
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0003243465907871723
sam_encoder.blocks.10.norm2.weight grad: -0.0017379913479089737
sam_encoder.blocks.10.norm2.bias grad: -0.002057062927633524
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.002296090126038e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0006461096927523613
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0009244752582162619
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00042898813262581825
sam_encoder.blocks.11.norm1.weight grad: -0.004575825296342373
sam_encoder.blocks.11.norm1.bias grad: 0.0007197476807050407
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0009065106860361993
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00018527294741943479
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00022736864048056304
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.0001635070366319269
sam_encoder.blocks.11.norm2.weight grad: 0.0007542353123426437
sam_encoder.blocks.11.norm2.bias grad: -0.0011704631615430117
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0009920953307300806
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.6174893719144166e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0003835918032564223
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.763814599253237e-05
sam_encoder.neck.conv1.trainable_scale grad: -7.122848182916641e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.011348276399075985
sam_encoder.neck.conv2.trainable_scale grad: -8.175801485776901e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.004767295904457569
mask_decoder.transformer.layers.0.norm1.weight grad: -0.12027857452630997
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00046250224113464355
mask_decoder.transformer.layers.0.norm2.weight grad: -1.339461088180542
mask_decoder.transformer.layers.0.norm2.bias grad: -0.04716050624847412
mask_decoder.transformer.layers.0.norm3.weight grad: 0.04739098995923996
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0008540228009223938
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0594763420522213
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0017056073993444443
mask_decoder.transformer.layers.1.norm1.weight grad: 0.05521639436483383
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0018435940146446228
mask_decoder.transformer.layers.1.norm2.weight grad: 0.016867974773049355
mask_decoder.transformer.layers.1.norm2.bias grad: 0.049297988414764404
mask_decoder.transformer.layers.1.norm3.weight grad: 0.02835134044289589
mask_decoder.transformer.layers.1.norm3.bias grad: 0.05875732749700546
mask_decoder.transformer.layers.1.norm4.weight grad: 0.029674457386136055
mask_decoder.transformer.layers.1.norm4.bias grad: -0.026521069929003716
mask_decoder.transformer.norm_final_attn.weight grad: 0.013172774575650692
mask_decoder.transformer.norm_final_attn.bias grad: 0.0072005391120910645
Text_Embedding_Affine.0.weight grad: 2.5471047493397236e-09
Text_Embedding_Affine.0.bias grad: 4.912726581096649e-08
Text_Embedding_Affine.2.weight grad: -2.409680277537518e-08
Text_Embedding_Affine.2.bias grad: -0.0037864763289690018
Epoch 0 finished with average loss: -69.6269
Epoch 1/39
----------
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, loss=-67.5]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-67.5]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-68.3]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-68.3]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-68.3]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.20it/s, loss=-68.3]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09062940627336502

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09062940627336502

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08586406707763672

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.45116472244262695

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0906972885131836

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08586406707763672

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.03136444091797
Max value: 83.4219741821289
Mean value: 67.49850463867188

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09062940627336502

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09062940627336502

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09062940627336502

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.45116472244262695

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.03136444091797
Max value: 83.4219741821289
Mean value: 67.49850463867188

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.49864959716797
Max value: -67.49864959716797
Mean value: -67.49864959716797
sam_encoder.pos_embed grad: 5.456863618746866e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0027039730921387672
sam_encoder.blocks.0.norm1.bias grad: 0.008796978741884232
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0007549787405878305
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.0008096519159153104
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.002346443710848689
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0005959731643088162
sam_encoder.blocks.0.norm2.weight grad: 0.003829788416624069
sam_encoder.blocks.0.norm2.bias grad: 0.007098299916833639
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000269758835202083
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0019939038902521133
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.215817797463387e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006456836708821356
sam_encoder.blocks.1.norm1.weight grad: -0.00046486733481287956
sam_encoder.blocks.1.norm1.bias grad: -7.521982297475915e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0011926745064556599
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0006920675514265895
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0014060515677556396
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0006850482313893735
sam_encoder.blocks.1.norm2.weight grad: 0.002835221355780959
sam_encoder.blocks.1.norm2.bias grad: 0.0004636865924112499
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.005617906805127859
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0011499584652483463
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00014107271272223443
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00047948211431503296
sam_encoder.blocks.2.norm1.weight grad: -0.002312455093488097
sam_encoder.blocks.2.norm1.bias grad: -0.0011894283816218376
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008387977140955627
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0005178169813007116
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0025899026077240705
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.002487115329131484
sam_encoder.blocks.2.norm2.weight grad: 0.0005737065221183002
sam_encoder.blocks.2.norm2.bias grad: 0.002057223115116358
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.001494409516453743
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00013835942081641406
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.001329793594777584
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004997880896553397
sam_encoder.blocks.3.norm1.weight grad: -0.0012377757811918855
sam_encoder.blocks.3.norm1.bias grad: -0.0007140549714677036
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4027154065843206e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003182960208505392
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0003749947063624859
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0006804935401305556
sam_encoder.blocks.3.norm2.weight grad: 0.0030766017735004425
sam_encoder.blocks.3.norm2.bias grad: 0.010647274553775787
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0023835408501327038
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0009501070599071681
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00036990875378251076
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0002822898677550256
sam_encoder.blocks.4.norm1.weight grad: -0.009885117411613464
sam_encoder.blocks.4.norm1.bias grad: -0.00029986229492351413
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00783486943691969
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0018576330039650202
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0029463223181664944
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.001821300946176052
sam_encoder.blocks.4.norm2.weight grad: -0.0015241842484101653
sam_encoder.blocks.4.norm2.bias grad: 0.007694701664149761
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.001977518666535616
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0004421280464157462
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00031084459624253213
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0005170407239347696
sam_encoder.blocks.5.norm1.weight grad: -0.00954028032720089
sam_encoder.blocks.5.norm1.bias grad: -0.0045578014105558395
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.005682994611561298
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0001476516481488943
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0008439859375357628
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.002240716479718685
sam_encoder.blocks.5.norm2.weight grad: 0.003801928833127022
sam_encoder.blocks.5.norm2.bias grad: 0.005564757622778416
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0015159717295318842
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0009104617638513446
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.000517692998982966
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.951633935794234e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0007185066933743656
sam_encoder.blocks.6.norm1.bias grad: -0.0007909815758466721
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00023352168500423431
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00028058275347575545
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00031254655914381146
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.363610737025738e-06
sam_encoder.blocks.6.norm2.weight grad: 0.00028821610612794757
sam_encoder.blocks.6.norm2.bias grad: 0.0016044009244069457
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0015000372659415007
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0009603248909115791
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0003468093927949667
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0003252768365200609
sam_encoder.blocks.7.norm1.weight grad: 0.00085798668442294
sam_encoder.blocks.7.norm1.bias grad: 0.0005524576990865171
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0012045613257214427
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0007497958722524345
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0010827126679942012
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.559107325505465e-05
sam_encoder.blocks.7.norm2.weight grad: 0.002256076317280531
sam_encoder.blocks.7.norm2.bias grad: -7.175219707278302e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00049117166781798
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0014142183354124427
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00046340524568222463
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0001747206406434998
sam_encoder.blocks.8.norm1.weight grad: -0.0016939257038757205
sam_encoder.blocks.8.norm1.bias grad: 0.0023833054583519697
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0020656660199165344
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00037246529245749116
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00017353535804431885
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00027034684899263084
sam_encoder.blocks.8.norm2.weight grad: 0.0021135350689291954
sam_encoder.blocks.8.norm2.bias grad: -0.0003935132990591228
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0023549555335193872
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.001490182476118207
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0014731152914464474
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00047854447620920837
sam_encoder.blocks.9.norm1.weight grad: -0.0006533401319757104
sam_encoder.blocks.9.norm1.bias grad: 0.00010075047612190247
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.975391781656072e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0006571011617779732
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0002938698453363031
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0003054713015444577
sam_encoder.blocks.9.norm2.weight grad: 0.0012686115223914385
sam_encoder.blocks.9.norm2.bias grad: -0.00047595842625014484
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0014542213175445795
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0006526314537040889
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00010562533134361729
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00035672978265210986
sam_encoder.blocks.10.norm1.weight grad: 0.0006693443283438683
sam_encoder.blocks.10.norm1.bias grad: -0.0003569014370441437
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0015135437715798616
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0005842373939231038
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00044356525177136064
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00032632530201226473
sam_encoder.blocks.10.norm2.weight grad: 0.0009437081753276289
sam_encoder.blocks.10.norm2.bias grad: -0.001698689884506166
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.002024844754487276
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.699362787301652e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00037865893682464957
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00022884286590851843
sam_encoder.blocks.11.norm1.weight grad: -0.004003254696726799
sam_encoder.blocks.11.norm1.bias grad: 0.0004253853112459183
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0023753042332828045
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00020653600222431123
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0006217060144990683
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00037491112016141415
sam_encoder.blocks.11.norm2.weight grad: 0.002035641809925437
sam_encoder.blocks.11.norm2.bias grad: -0.0012379017425701022
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.001910123392008245
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0004079038626514375
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0005390056176111102
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.2141815609065816e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.00024749618023633957
sam_encoder.neck.conv1.trainable_shift grad: -0.006377480458468199
sam_encoder.neck.conv2.trainable_scale grad: -0.0004148348234593868
sam_encoder.neck.conv2.trainable_shift grad: 2.2180844098329544e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.11397318542003632
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00035744160413742065
mask_decoder.transformer.layers.0.norm2.weight grad: -2.5281882286071777
mask_decoder.transformer.layers.0.norm2.bias grad: -0.06910836696624756
mask_decoder.transformer.layers.0.norm3.weight grad: 0.03251326084136963
mask_decoder.transformer.layers.0.norm3.bias grad: 0.022974401712417603
mask_decoder.transformer.layers.0.norm4.weight grad: 0.057988569140434265
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0017430847510695457
mask_decoder.transformer.layers.1.norm1.weight grad: 0.06857244670391083
mask_decoder.transformer.layers.1.norm1.bias grad: -0.003353940322995186
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0035018324851989746
mask_decoder.transformer.layers.1.norm2.bias grad: 0.06948892772197723
mask_decoder.transformer.layers.1.norm3.weight grad: 0.03207683563232422
mask_decoder.transformer.layers.1.norm3.bias grad: 0.05984025076031685
mask_decoder.transformer.layers.1.norm4.weight grad: 0.028948914259672165
mask_decoder.transformer.layers.1.norm4.bias grad: -0.03768204152584076
mask_decoder.transformer.norm_final_attn.weight grad: 0.012705313041806221
mask_decoder.transformer.norm_final_attn.bias grad: 0.007803434040397406
Text_Embedding_Affine.0.weight grad: 4.975422740471913e-09
Text_Embedding_Affine.0.bias grad: 1.8632272258400917e-07
Text_Embedding_Affine.2.weight grad: -6.4170011526698545e-09
Text_Embedding_Affine.2.bias grad: -0.014484595507383347

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07371367514133453

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07371367514133453

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07362031936645508

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3212885856628418

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07372283935546875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07362031936645508

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.51360321044922
Max value: 91.695068359375
Mean value: 69.11453247070312

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07371367514133453

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07371367514133453

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07371367514133453

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3212885856628418

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.51360321044922
Max value: 91.695068359375
Mean value: 69.11453247070312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.11465454101562
Max value: -69.11465454101562
Mean value: -69.11465454101562
sam_encoder.pos_embed grad: -7.908476504780992e-07
sam_encoder.blocks.0.norm1.weight grad: -0.006490233354270458
sam_encoder.blocks.0.norm1.bias grad: 0.0099678635597229
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.002164185279980302
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.0001766729837981984
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0004082613158971071
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0005583387101069093
sam_encoder.blocks.0.norm2.weight grad: 0.007379587739706039
sam_encoder.blocks.0.norm2.bias grad: 0.014734162949025631
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0023004626855254173
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.001500588608905673
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.003168347757309675
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0010033195139840245
sam_encoder.blocks.1.norm1.weight grad: -0.00368972634896636
sam_encoder.blocks.1.norm1.bias grad: -0.002636533696204424
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.001604009885340929
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0008573166560381651
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.002558598294854164
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.001173309632577002
sam_encoder.blocks.1.norm2.weight grad: 0.005174783989787102
sam_encoder.blocks.1.norm2.bias grad: -0.0018131824908778071
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.007206471636891365
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0015169427497312427
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.002890967531129718
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0007012252463027835
sam_encoder.blocks.2.norm1.weight grad: 0.0015798360109329224
sam_encoder.blocks.2.norm1.bias grad: -0.0013205511495471
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0017689451342448592
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.000968627049587667
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003371031198184937
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0012857853434979916
sam_encoder.blocks.2.norm2.weight grad: 0.007530315779149532
sam_encoder.blocks.2.norm2.bias grad: -0.0003875605179928243
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.005092843435704708
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0009455093531869352
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0003373764338903129
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.34090930968523e-05
sam_encoder.blocks.3.norm1.weight grad: -0.005830038338899612
sam_encoder.blocks.3.norm1.bias grad: -0.0005388079443946481
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0019677761010825634
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0005549980560317636
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00080057792365551
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0005142759764567018
sam_encoder.blocks.3.norm2.weight grad: 0.007188309915363789
sam_encoder.blocks.3.norm2.bias grad: 0.007142402231693268
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.005690151359885931
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0018076885025948286
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0003338959068059921
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00018723629182204604
sam_encoder.blocks.4.norm1.weight grad: -0.006458680145442486
sam_encoder.blocks.4.norm1.bias grad: 0.0008202795870602131
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.004574253223836422
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0008282923954539001
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0013342034071683884
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.000575773068703711
sam_encoder.blocks.4.norm2.weight grad: -0.001003512181341648
sam_encoder.blocks.4.norm2.bias grad: 0.002770767081528902
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0016171121969819069
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00024176329316105694
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0004402785561978817
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0001645844167796895
sam_encoder.blocks.5.norm1.weight grad: -0.0056136492639780045
sam_encoder.blocks.5.norm1.bias grad: -0.001992295030504465
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.003355989931151271
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00011667289072647691
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0004902144428342581
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0010036695748567581
sam_encoder.blocks.5.norm2.weight grad: 0.00038001849316060543
sam_encoder.blocks.5.norm2.bias grad: 0.0031333628576248884
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0006396290846168995
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0004782398173119873
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.309389861300588e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00029218694544397295
sam_encoder.blocks.6.norm1.weight grad: -0.0013005966320633888
sam_encoder.blocks.6.norm1.bias grad: 0.001194391050375998
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0016019113827496767
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0008588725468143821
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.016040712594986e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0001515484182164073
sam_encoder.blocks.6.norm2.weight grad: -0.0002914196811616421
sam_encoder.blocks.6.norm2.bias grad: 0.0007015381706878543
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0010409899987280369
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00044667714973911643
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00039967973134480417
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.101427763700485e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0010296249529346824
sam_encoder.blocks.7.norm1.bias grad: 0.0012833131477236748
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0004244356823619455
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.742472760379314e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0006366278976202011
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00020713455160148442
sam_encoder.blocks.7.norm2.weight grad: 0.0016558009665459394
sam_encoder.blocks.7.norm2.bias grad: -0.00024512759409844875
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.519126767059788e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0004365584463812411
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0005174276884645224
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0006455722032114863
sam_encoder.blocks.8.norm1.weight grad: -0.003240808844566345
sam_encoder.blocks.8.norm1.bias grad: 0.001814966439269483
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.004216659348458052
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0014682039618492126
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00046089873649179935
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00018817644740920514
sam_encoder.blocks.8.norm2.weight grad: 0.0018233824521303177
sam_encoder.blocks.8.norm2.bias grad: -0.0002821548259817064
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0016920663183555007
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0010669910116121173
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0006902567110955715
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.892592111602426e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0018382819835096598
sam_encoder.blocks.9.norm1.bias grad: 0.00015685691323596984
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0012660622596740723
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00011904996063094586
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00013358138676267117
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00075061823008582
sam_encoder.blocks.9.norm2.weight grad: 0.0014275836292654276
sam_encoder.blocks.9.norm2.bias grad: -0.0006178101757541299
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0016848603263497353
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0005435831262730062
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00030975922709330916
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0004398635355755687
sam_encoder.blocks.10.norm1.weight grad: 0.0009213840821757913
sam_encoder.blocks.10.norm1.bias grad: -0.00021969852969050407
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0013691342901438475
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0006285225390456617
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.000637945078779012
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0004112884635105729
sam_encoder.blocks.10.norm2.weight grad: -9.739849338075146e-05
sam_encoder.blocks.10.norm2.bias grad: -0.0017051579197868705
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0016825416823849082
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0002201936877099797
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0008059842512011528
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.000385753286536783
sam_encoder.blocks.11.norm1.weight grad: 0.00039470428600907326
sam_encoder.blocks.11.norm1.bias grad: -0.00011194450780749321
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.000599415972828865
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00012230388529133052
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00021103919425513595
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0001512370363343507
sam_encoder.blocks.11.norm2.weight grad: 0.0022975774481892586
sam_encoder.blocks.11.norm2.bias grad: -0.0007003849605098367
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.002267455216497183
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0002464517601765692
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0006648429553024471
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.92759858793579e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.00038764718919992447
sam_encoder.neck.conv1.trainable_shift grad: -0.005071884021162987
sam_encoder.neck.conv2.trainable_scale grad: -0.0004185289144515991
sam_encoder.neck.conv2.trainable_shift grad: 0.017234820872545242
mask_decoder.transformer.layers.0.norm1.weight grad: -0.1257655769586563
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00019898265600204468
mask_decoder.transformer.layers.0.norm2.weight grad: -4.524187088012695
mask_decoder.transformer.layers.0.norm2.bias grad: -0.031768202781677246
mask_decoder.transformer.layers.0.norm3.weight grad: 0.052069924771785736
mask_decoder.transformer.layers.0.norm3.bias grad: 0.022862207144498825
mask_decoder.transformer.layers.0.norm4.weight grad: 0.059096306562423706
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0009818598628044128
mask_decoder.transformer.layers.1.norm1.weight grad: 0.06770773231983185
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0019418885931372643
mask_decoder.transformer.layers.1.norm2.weight grad: -0.02435573749244213
mask_decoder.transformer.layers.1.norm2.bias grad: 0.06448962539434433
mask_decoder.transformer.layers.1.norm3.weight grad: 0.027996404096484184
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0592203326523304
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0006617899052798748
mask_decoder.transformer.layers.1.norm4.bias grad: -0.07047483325004578
mask_decoder.transformer.norm_final_attn.weight grad: 0.011760503053665161
mask_decoder.transformer.norm_final_attn.bias grad: 0.007462339475750923
Text_Embedding_Affine.0.weight grad: -1.285322070998518e-08
Text_Embedding_Affine.0.bias grad: -4.713074304163456e-07
Text_Embedding_Affine.2.weight grad: 5.789384616150528e-08
Text_Embedding_Affine.2.bias grad: -0.0104613546282053

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1070953905582428

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1070953905582428

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10051441192626953

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4248846769332886

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10706615447998047

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10051441192626953

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.064674377441406
Max value: 78.511962890625
Mean value: 68.33997344970703

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1070953905582428

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1070953905582428

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1070953905582428

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4248846769332886

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.064674377441406
Max value: 78.511962890625
Mean value: 68.33997344970703

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.34010314941406
Max value: -68.34010314941406
Mean value: -68.34010314941406
sam_encoder.pos_embed grad: -2.7243963813816663e-06
sam_encoder.blocks.0.norm1.weight grad: -0.024144455790519714
sam_encoder.blocks.0.norm1.bias grad: 0.01641555316746235
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.006004956550896168
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.099012999678962e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0012562279589474201
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.000940765137784183
sam_encoder.blocks.0.norm2.weight grad: 0.018816418945789337
sam_encoder.blocks.0.norm2.bias grad: 0.02119896188378334
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0018404315924271941
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0015634060837328434
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.004252383019775152
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0014776166062802076
sam_encoder.blocks.1.norm1.weight grad: -0.0070434208028018475
sam_encoder.blocks.1.norm1.bias grad: -0.0006021945737302303
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0022457032464444637
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.001347913290373981
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0022558835335075855
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0013024242362007499
sam_encoder.blocks.1.norm2.weight grad: 0.01050612237304449
sam_encoder.blocks.1.norm2.bias grad: -0.0036856995429843664
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.006781835108995438
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0013864038046449423
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0047750286757946014
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0006663747481070459
sam_encoder.blocks.2.norm1.weight grad: -0.0020267609506845474
sam_encoder.blocks.2.norm1.bias grad: -0.0021106444764882326
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0004566511488519609
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0002463281562086195
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.001206747256219387
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0018061783630400896
sam_encoder.blocks.2.norm2.weight grad: 9.969397069653496e-05
sam_encoder.blocks.2.norm2.bias grad: -0.0015251680742949247
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0006658313795924187
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.000592448515817523
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0014434305485337973
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.728421769570559e-05
sam_encoder.blocks.3.norm1.weight grad: -0.006357974372804165
sam_encoder.blocks.3.norm1.bias grad: -0.0003745003486983478
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0026670440565794706
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.6224644734138565e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00039040669798851013
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.000512334459926933
sam_encoder.blocks.3.norm2.weight grad: 0.004234181717038155
sam_encoder.blocks.3.norm2.bias grad: 0.002478162758052349
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.003255461808294058
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0010170136811211705
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0019226630683988333
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00028181314701214433
sam_encoder.blocks.4.norm1.weight grad: 0.0017343626823276281
sam_encoder.blocks.4.norm1.bias grad: -8.112099021673203e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0007839714526198804
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002944112056866288
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0011210576631128788
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0018170415423810482
sam_encoder.blocks.4.norm2.weight grad: -0.00820815097540617
sam_encoder.blocks.4.norm2.bias grad: -0.00460355170071125
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.006381973624229431
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00218776217661798
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0010214755311608315
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00016754456737544388
sam_encoder.blocks.5.norm1.weight grad: 0.0001307452330365777
sam_encoder.blocks.5.norm1.bias grad: -0.00026782479835674167
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0004576838982757181
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.729212615638971e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002952885115519166
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0005444201524369419
sam_encoder.blocks.5.norm2.weight grad: -0.0004146545543335378
sam_encoder.blocks.5.norm2.bias grad: -0.0016509895212948322
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0007570612942799926
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00021754272165708244
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00032558763632550836
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00036008720053359866
sam_encoder.blocks.6.norm1.weight grad: -0.0008095367229543626
sam_encoder.blocks.6.norm1.bias grad: 0.0015478020068258047
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0009521580650471151
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0005523610161617398
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.95917044847738e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0005364830722101033
sam_encoder.blocks.6.norm2.weight grad: 0.0006458267453126609
sam_encoder.blocks.6.norm2.bias grad: -0.0002654045820236206
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0006086855428293347
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00010514936002437025
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00014488757005892694
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00014634440594818443
sam_encoder.blocks.7.norm1.weight grad: 0.0001501627266407013
sam_encoder.blocks.7.norm1.bias grad: 0.0009057248826138675
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0008290412370115519
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0007988277357071638
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0007759790751151741
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.000281016604276374
sam_encoder.blocks.7.norm2.weight grad: 0.004978855140507221
sam_encoder.blocks.7.norm2.bias grad: 0.0001518973003840074
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.003112711012363434
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0011148597113788128
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00014692815602757037
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00026398285990580916
sam_encoder.blocks.8.norm1.weight grad: -0.0033318246714770794
sam_encoder.blocks.8.norm1.bias grad: 0.0005385306430980563
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.003574737813323736
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0016194627387449145
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0003782026469707489
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0003195080207660794
sam_encoder.blocks.8.norm2.weight grad: 0.00139121082611382
sam_encoder.blocks.8.norm2.bias grad: -9.629258420318365e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0009466467890888453
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00039474546792916954
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.668293356895447e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.24452324397862e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0006782448617741466
sam_encoder.blocks.9.norm1.bias grad: 0.0001631360501050949
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0001720503205433488
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0004226451274007559
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0003225971886422485
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0007470541168004274
sam_encoder.blocks.9.norm2.weight grad: 0.0022069462575018406
sam_encoder.blocks.9.norm2.bias grad: -0.0003171877469867468
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0018459598068147898
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0007065007230266929
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0005236415890976787
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00045547596528194845
sam_encoder.blocks.10.norm1.weight grad: 0.0011730178957805037
sam_encoder.blocks.10.norm1.bias grad: 3.4639226214494556e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0016576112248003483
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0006693456089124084
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0006012534722685814
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00034860725281760097
sam_encoder.blocks.10.norm2.weight grad: 0.0006523891352117062
sam_encoder.blocks.10.norm2.bias grad: -0.0009870041394606233
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0015157987363636494
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.320403190329671e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0011259533930569887
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00039971337537281215
sam_encoder.blocks.11.norm1.weight grad: 0.007258608937263489
sam_encoder.blocks.11.norm1.bias grad: 9.693725587567315e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0001522864622529596
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00018162906053476036
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0005763999652117491
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00028805885813198984
sam_encoder.blocks.11.norm2.weight grad: 0.003840574761852622
sam_encoder.blocks.11.norm2.bias grad: 0.0007281553698703647
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0024471015203744173
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00018908843048848212
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0006823820294812322
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00017203736933879554
sam_encoder.neck.conv1.trainable_scale grad: -0.00012910319492220879
sam_encoder.neck.conv1.trainable_shift grad: -0.007087560370564461
sam_encoder.neck.conv2.trainable_scale grad: -0.00029374659061431885
sam_encoder.neck.conv2.trainable_shift grad: 0.031004246324300766
mask_decoder.transformer.layers.0.norm1.weight grad: -0.12104444950819016
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0012713298201560974
mask_decoder.transformer.layers.0.norm2.weight grad: -4.278468132019043
mask_decoder.transformer.layers.0.norm2.bias grad: 0.23127251863479614
mask_decoder.transformer.layers.0.norm3.weight grad: 0.01733512431383133
mask_decoder.transformer.layers.0.norm3.bias grad: 0.013105694204568863
mask_decoder.transformer.layers.0.norm4.weight grad: 0.049148622900247574
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0005207564681768417
mask_decoder.transformer.layers.1.norm1.weight grad: 0.05361052602529526
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0014217868447303772
mask_decoder.transformer.layers.1.norm2.weight grad: -0.06125955656170845
mask_decoder.transformer.layers.1.norm2.bias grad: 0.078333780169487
mask_decoder.transformer.layers.1.norm3.weight grad: 0.02327512763440609
mask_decoder.transformer.layers.1.norm3.bias grad: 0.04544699192047119
mask_decoder.transformer.layers.1.norm4.weight grad: -0.02685084193944931
mask_decoder.transformer.layers.1.norm4.bias grad: -0.10103978216648102
mask_decoder.transformer.norm_final_attn.weight grad: 0.009065410122275352
mask_decoder.transformer.norm_final_attn.bias grad: 0.006581990979611874
Text_Embedding_Affine.0.weight grad: -1.2666109938663794e-08
Text_Embedding_Affine.0.bias grad: -3.966270014643669e-07
Text_Embedding_Affine.2.weight grad: -1.7931034435036963e-08
Text_Embedding_Affine.2.bias grad: 0.003343133255839348
Epoch 1 finished with average loss: -68.3178
Epoch 2/39
----------
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, loss=-63.7]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-63.7]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-66.2]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-66.2]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-66.9]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.25it/s, loss=-66.9]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08218790590763092

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08218790590763092

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08618831634521484

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.39605802297592163

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08219194412231445

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08618831634521484

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.04655838012695
Max value: 77.54916381835938
Mean value: 63.7442626953125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08218790590763092

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08218790590763092

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08218790590763092

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.39605802297592163

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.04655838012695
Max value: 77.54916381835938
Mean value: 63.7442626953125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.744441986083984
Max value: -63.744441986083984
Mean value: -63.744441986083984
sam_encoder.pos_embed grad: 9.252870540876756e-07
sam_encoder.blocks.0.norm1.weight grad: 0.021404385566711426
sam_encoder.blocks.0.norm1.bias grad: 0.013687588274478912
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0018643460934981704
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.0005132426740601659
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.001015339745208621
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.12139338045381e-05
sam_encoder.blocks.0.norm2.weight grad: 0.004312645643949509
sam_encoder.blocks.0.norm2.bias grad: -0.009625418111681938
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0020793850999325514
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0010663617867976427
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.008092999458312988
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0024803136475384235
sam_encoder.blocks.1.norm1.weight grad: -0.002409295877441764
sam_encoder.blocks.1.norm1.bias grad: 0.00536351790651679
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.003092873375862837
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0008699977188371122
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.002166630467399955
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0016219483222812414
sam_encoder.blocks.1.norm2.weight grad: -0.0018836657982319593
sam_encoder.blocks.1.norm2.bias grad: 0.001460134400986135
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.001105528324842453
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001121661625802517
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.004349754191935062
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.000845298869535327
sam_encoder.blocks.2.norm1.weight grad: 0.008911628276109695
sam_encoder.blocks.2.norm1.bias grad: 0.004383555613458157
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0028338897973299026
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0008359466446563601
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0010393124539405107
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0001423036155756563
sam_encoder.blocks.2.norm2.weight grad: 0.0012566999066621065
sam_encoder.blocks.2.norm2.bias grad: -0.0011844797991216183
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.001588284969329834
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00013173310435377061
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.004666739609092474
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0014488708693534136
sam_encoder.blocks.3.norm1.weight grad: -0.005926224403083324
sam_encoder.blocks.3.norm1.bias grad: -0.002138842362910509
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0024751273449510336
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0004876838647760451
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.002004653215408325
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0005053759086877108
sam_encoder.blocks.3.norm2.weight grad: 0.0036353354807943106
sam_encoder.blocks.3.norm2.bias grad: 0.005688258912414312
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0035335742868483067
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0015170108526945114
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0012120172614231706
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00035427830880507827
sam_encoder.blocks.4.norm1.weight grad: -0.010809067636728287
sam_encoder.blocks.4.norm1.bias grad: -0.0006797891110181808
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0061759185045957565
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.002213753294199705
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0019635362550616264
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0017557814717292786
sam_encoder.blocks.4.norm2.weight grad: -0.012797567993402481
sam_encoder.blocks.4.norm2.bias grad: 0.0027156034484505653
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.008286558091640472
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0017847394337877631
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0006754599744454026
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0008903190027922392
sam_encoder.blocks.5.norm1.weight grad: -0.009397919289767742
sam_encoder.blocks.5.norm1.bias grad: 0.003203539876267314
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.004877834115177393
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0009132504928857088
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00045557564590126276
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.001856677932664752
sam_encoder.blocks.5.norm2.weight grad: -0.00923583097755909
sam_encoder.blocks.5.norm2.bias grad: 0.0027251250576227903
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00621195649728179
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0020127545576542616
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00023082496772985905
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0004285612958483398
sam_encoder.blocks.6.norm1.weight grad: -0.0018090646481141448
sam_encoder.blocks.6.norm1.bias grad: 8.1124366261065e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0015396715607494116
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.001013684319332242
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0340319931856357e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0007594798225909472
sam_encoder.blocks.6.norm2.weight grad: 0.004426530562341213
sam_encoder.blocks.6.norm2.bias grad: 0.0019322617445141077
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.003957610577344894
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0016483869403600693
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0015710701700299978
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0008940198458731174
sam_encoder.blocks.7.norm1.weight grad: -0.002621653489768505
sam_encoder.blocks.7.norm1.bias grad: 0.002103489823639393
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0010668737813830376
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00021353473130147904
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.699491056380793e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0008989986963570118
sam_encoder.blocks.7.norm2.weight grad: 0.0005383851821534336
sam_encoder.blocks.7.norm2.bias grad: 0.0010562132811173797
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0007586734718643129
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00014916334475856274
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00015290523879230022
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00046735836076550186
sam_encoder.blocks.8.norm1.weight grad: -0.0008394048782065511
sam_encoder.blocks.8.norm1.bias grad: 0.002092942362651229
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0031931584235280752
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0016639305977150798
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.001680480083450675
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0022904861252754927
sam_encoder.blocks.8.norm2.weight grad: 0.0015537296421825886
sam_encoder.blocks.8.norm2.bias grad: -0.0008377250051125884
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.001534322276711464
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0008335599559359252
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0005250971880741417
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00019775389228016138
sam_encoder.blocks.9.norm1.weight grad: -0.0029888153076171875
sam_encoder.blocks.9.norm1.bias grad: 0.0002186124911531806
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0022788294591009617
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.000308854941977188
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.000606158806476742
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0013348606880754232
sam_encoder.blocks.9.norm2.weight grad: 0.0006315181963145733
sam_encoder.blocks.9.norm2.bias grad: -0.0008791158907115459
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0012243639212101698
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.871422864496708e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.34543427824974e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00024187439703382552
sam_encoder.blocks.10.norm1.weight grad: -0.00010336481500416994
sam_encoder.blocks.10.norm1.bias grad: -0.00017208109784405679
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0006529409438371658
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00040160882053896785
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00037716218503192067
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0003388942568562925
sam_encoder.blocks.10.norm2.weight grad: -0.003073030849918723
sam_encoder.blocks.10.norm2.bias grad: -0.0022452783305197954
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00011715809523593634
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0011569011257961392
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0015674964524805546
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0005734221776947379
sam_encoder.blocks.11.norm1.weight grad: -0.0016961306100711226
sam_encoder.blocks.11.norm1.bias grad: 0.0007376553257927299
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002911362680606544
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0005562620935961604
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00010950650175800547
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00017460498202126473
sam_encoder.blocks.11.norm2.weight grad: -0.0030917327385395765
sam_encoder.blocks.11.norm2.bias grad: -0.0019580647349357605
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0012886201729997993
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.000722099095582962
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0012126497458666563
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00036548153730109334
sam_encoder.neck.conv1.trainable_scale grad: -0.0005276924930512905
sam_encoder.neck.conv1.trainable_shift grad: -0.018558457493782043
sam_encoder.neck.conv2.trainable_scale grad: -0.00016543222591280937
sam_encoder.neck.conv2.trainable_shift grad: 0.013961607590317726
mask_decoder.transformer.layers.0.norm1.weight grad: -0.17262135446071625
mask_decoder.transformer.layers.0.norm1.bias grad: -1.8123537302017212e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -3.501777172088623
mask_decoder.transformer.layers.0.norm2.bias grad: 0.15711283683776855
mask_decoder.transformer.layers.0.norm3.weight grad: -0.004607394337654114
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0299379862844944
mask_decoder.transformer.layers.0.norm4.weight grad: 0.03360920399427414
mask_decoder.transformer.layers.0.norm4.bias grad: -0.005461742170155048
mask_decoder.transformer.layers.1.norm1.weight grad: 0.07085321843624115
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0018024928867816925
mask_decoder.transformer.layers.1.norm2.weight grad: 0.05144578590989113
mask_decoder.transformer.layers.1.norm2.bias grad: 0.05779562145471573
mask_decoder.transformer.layers.1.norm3.weight grad: 0.04717228561639786
mask_decoder.transformer.layers.1.norm3.bias grad: 0.07490649819374084
mask_decoder.transformer.layers.1.norm4.weight grad: 0.003601482603698969
mask_decoder.transformer.layers.1.norm4.bias grad: -0.061333950608968735
mask_decoder.transformer.norm_final_attn.weight grad: 0.011930372565984726
mask_decoder.transformer.norm_final_attn.bias grad: 0.006813282147049904
Text_Embedding_Affine.0.weight grad: 4.298203570840542e-09
Text_Embedding_Affine.0.bias grad: 9.589712135493755e-08
Text_Embedding_Affine.2.weight grad: 1.006067833486668e-07
Text_Embedding_Affine.2.bias grad: -0.010970782488584518

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08093570917844772

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08093570917844772

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07783699035644531

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3259665071964264

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0808720588684082

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07783699035644531

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 62.0369758605957
Max value: 80.77448272705078
Mean value: 68.64399719238281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08093570917844772

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08093570917844772

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08093570917844772

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3259665071964264

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 62.0369758605957
Max value: 80.77448272705078
Mean value: 68.64399719238281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.64417266845703
Max value: -68.64417266845703
Mean value: -68.64417266845703
sam_encoder.pos_embed grad: -3.5594612199929543e-06
sam_encoder.blocks.0.norm1.weight grad: -0.005990700330585241
sam_encoder.blocks.0.norm1.bias grad: 0.0275653637945652
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.005570311099290848
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.0003244478430133313
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0014305429067462683
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.001088217250071466
sam_encoder.blocks.0.norm2.weight grad: 0.027671998366713524
sam_encoder.blocks.0.norm2.bias grad: 0.011323543265461922
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0050184596329927444
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0004836407897528261
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0026882062666118145
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0013151302700862288
sam_encoder.blocks.1.norm1.weight grad: -0.005401474889367819
sam_encoder.blocks.1.norm1.bias grad: -0.0014234008267521858
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0024847323074936867
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.00133451446890831
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.002493265550583601
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0014188125496730208
sam_encoder.blocks.1.norm2.weight grad: 0.009044608101248741
sam_encoder.blocks.1.norm2.bias grad: -0.002826838521286845
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.004416381474584341
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0010698828846216202
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.003549357643350959
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00039797642966732383
sam_encoder.blocks.2.norm1.weight grad: -0.0013193297199904919
sam_encoder.blocks.2.norm1.bias grad: -0.0020090430043637753
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.001029142877086997
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0005523526924662292
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0009207811090163887
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0017189638456329703
sam_encoder.blocks.2.norm2.weight grad: -0.0008062184788286686
sam_encoder.blocks.2.norm2.bias grad: -0.0019352741073817015
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00014459792873822153
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0007971609011292458
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0006624312372878194
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00014900056703481823
sam_encoder.blocks.3.norm1.weight grad: -0.004786381032317877
sam_encoder.blocks.3.norm1.bias grad: 0.0001673653459874913
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.001986350165680051
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00018718000501394272
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0006389456102624536
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0008652419201098382
sam_encoder.blocks.3.norm2.weight grad: 0.004274339415132999
sam_encoder.blocks.3.norm2.bias grad: 0.003202177584171295
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.003750669537112117
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0010861626360565424
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0018141031032428145
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0003106009098701179
sam_encoder.blocks.4.norm1.weight grad: 0.0009896836709231138
sam_encoder.blocks.4.norm1.bias grad: 0.003363390453159809
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0006813920917920768
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.2347277738153934e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0007302196463569999
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0009798515820875764
sam_encoder.blocks.4.norm2.weight grad: -0.009237688966095448
sam_encoder.blocks.4.norm2.bias grad: -0.0034079011529684067
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.007370126899331808
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0025930460542440414
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0005655650747939944
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0006890882505103946
sam_encoder.blocks.5.norm1.weight grad: -0.0033860651310533285
sam_encoder.blocks.5.norm1.bias grad: 0.0006576476152986288
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0023288694210350513
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00089202297385782
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0001305029436480254
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00047654658555984497
sam_encoder.blocks.5.norm2.weight grad: -0.005233376752585173
sam_encoder.blocks.5.norm2.bias grad: -0.0018451021751388907
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0018444990273565054
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0006102319457568228
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0010919442865997553
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0009379629045724869
sam_encoder.blocks.6.norm1.weight grad: 0.0011898231459781528
sam_encoder.blocks.6.norm1.bias grad: 0.001897220266982913
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00018306139099877328
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0005226240027695894
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0007839659228920937
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00020108655735384673
sam_encoder.blocks.6.norm2.weight grad: -0.00025585622643120587
sam_encoder.blocks.6.norm2.bias grad: -0.00010231773921987042
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00043194074532948434
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00022008676023688167
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0002649725356604904
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.660799954261165e-06
sam_encoder.blocks.7.norm1.weight grad: 0.00032468303106725216
sam_encoder.blocks.7.norm1.bias grad: 0.001756870886310935
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0010259561240673065
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0006309021264314651
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0009093221160583198
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0004397144657559693
sam_encoder.blocks.7.norm2.weight grad: 0.005534452851861715
sam_encoder.blocks.7.norm2.bias grad: 4.865438677370548e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.003143112640827894
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0014013051986694336
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0006031620432622731
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0005289585678838193
sam_encoder.blocks.8.norm1.weight grad: -0.0034715502988547087
sam_encoder.blocks.8.norm1.bias grad: 0.0006841504364274442
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.004256435204297304
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.001999492757022381
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0008459186065010726
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00018547323998063803
sam_encoder.blocks.8.norm2.weight grad: 0.002380149206146598
sam_encoder.blocks.8.norm2.bias grad: -8.833078754832968e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0018481649458408356
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0009614829905331135
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.574454891961068e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0002096683601848781
sam_encoder.blocks.9.norm1.weight grad: -0.0013173751067370176
sam_encoder.blocks.9.norm1.bias grad: 0.0004712346417363733
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0008547115139663219
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0005009805900044739
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0003122489433735609
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0010365487542003393
sam_encoder.blocks.9.norm2.weight grad: 0.003325154772028327
sam_encoder.blocks.9.norm2.bias grad: -0.0005577693227678537
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0032491409219801426
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.001121346140280366
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00030526830232702196
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0005499161197803915
sam_encoder.blocks.10.norm1.weight grad: 0.001353719038888812
sam_encoder.blocks.10.norm1.bias grad: 0.00028648957959376276
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0017790405545383692
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0008529567858204246
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0008260712493211031
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.000519780907779932
sam_encoder.blocks.10.norm2.weight grad: 0.001425218186341226
sam_encoder.blocks.10.norm2.bias grad: -0.0019013145938515663
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0031313232611864805
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0002802492817863822
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.001067067263647914
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0004306735936552286
sam_encoder.blocks.11.norm1.weight grad: 0.008212188258767128
sam_encoder.blocks.11.norm1.bias grad: -0.0001577076909597963
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.588564504752867e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.275866614188999e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0006987532833591104
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0003843983868137002
sam_encoder.blocks.11.norm2.weight grad: 0.002899238606914878
sam_encoder.blocks.11.norm2.bias grad: -6.281724199652672e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0035699917934834957
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00015555693244095892
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0012637176550924778
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0004141646786592901
sam_encoder.neck.conv1.trainable_scale grad: -0.000430193729698658
sam_encoder.neck.conv1.trainable_shift grad: -0.008494032546877861
sam_encoder.neck.conv2.trainable_scale grad: -0.0007048528641462326
sam_encoder.neck.conv2.trainable_shift grad: 0.04046381264925003
mask_decoder.transformer.layers.0.norm1.weight grad: -0.1930750161409378
mask_decoder.transformer.layers.0.norm1.bias grad: -0.002348862588405609
mask_decoder.transformer.layers.0.norm2.weight grad: -5.5386061668396
mask_decoder.transformer.layers.0.norm2.bias grad: 0.471526563167572
mask_decoder.transformer.layers.0.norm3.weight grad: 0.019269734621047974
mask_decoder.transformer.layers.0.norm3.bias grad: 0.02379286289215088
mask_decoder.transformer.layers.0.norm4.weight grad: 0.05570795014500618
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000588487833738327
mask_decoder.transformer.layers.1.norm1.weight grad: 0.06586770713329315
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0017363158985972404
mask_decoder.transformer.layers.1.norm2.weight grad: -0.061022061854600906
mask_decoder.transformer.layers.1.norm2.bias grad: 0.07477309554815292
mask_decoder.transformer.layers.1.norm3.weight grad: 0.029071658849716187
mask_decoder.transformer.layers.1.norm3.bias grad: 0.05410845950245857
mask_decoder.transformer.layers.1.norm4.weight grad: -0.03326549753546715
mask_decoder.transformer.layers.1.norm4.bias grad: -0.13890117406845093
mask_decoder.transformer.norm_final_attn.weight grad: 0.010058443993330002
mask_decoder.transformer.norm_final_attn.bias grad: 0.007430975325405598
Text_Embedding_Affine.0.weight grad: 7.088346798411749e-09
Text_Embedding_Affine.0.bias grad: 2.8545036911964417e-07
Text_Embedding_Affine.2.weight grad: 2.4299300349639452e-08
Text_Embedding_Affine.2.bias grad: 0.007693788036704063

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0864948183298111

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0864948183298111

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09077262878417969

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.30688297748565674

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08642578125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09077262878417969

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 41.83778381347656
Max value: 92.15959930419922
Mean value: 68.34695434570312

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0864948183298111

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0864948183298111

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0864948183298111

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.30688297748565674

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 41.83778381347656
Max value: 92.15959930419922
Mean value: 68.34695434570312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.34712982177734
Max value: -68.34712982177734
Mean value: -68.34712982177734
sam_encoder.pos_embed grad: 3.171756759456912e-07
sam_encoder.blocks.0.norm1.weight grad: -0.00853780098259449
sam_encoder.blocks.0.norm1.bias grad: 0.04113335162401199
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.004758127499371767
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00012432112998794764
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0022093947045505047
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0012509042862802744
sam_encoder.blocks.0.norm2.weight grad: 0.00832889974117279
sam_encoder.blocks.0.norm2.bias grad: 0.007697979919612408
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0003903911856468767
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0030234400182962418
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.005414776038378477
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0016397777944803238
sam_encoder.blocks.1.norm1.weight grad: -0.003428058233112097
sam_encoder.blocks.1.norm1.bias grad: 0.001389289041981101
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0019768208730965853
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0013642183039337397
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0028032376430928707
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.001370911835692823
sam_encoder.blocks.1.norm2.weight grad: 0.007974325679242611
sam_encoder.blocks.1.norm2.bias grad: -0.005517712794244289
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.007288141176104546
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0015311071183532476
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.005218579433858395
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0004996374482288957
sam_encoder.blocks.2.norm1.weight grad: 0.004857341758906841
sam_encoder.blocks.2.norm1.bias grad: -0.00024633979774080217
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.003788907779380679
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0011115330271422863
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0012718257494270802
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0009150355472229421
sam_encoder.blocks.2.norm2.weight grad: 0.005196725018322468
sam_encoder.blocks.2.norm2.bias grad: -0.0025917505845427513
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.003780221566557884
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00029802994686178863
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00021263181406538934
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.8161203924100846e-05
sam_encoder.blocks.3.norm1.weight grad: -0.009314033202826977
sam_encoder.blocks.3.norm1.bias grad: 0.0003316725487820804
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.005039372481405735
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003874882240779698
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0019096797332167625
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0006763458950445056
sam_encoder.blocks.3.norm2.weight grad: 0.005229823291301727
sam_encoder.blocks.3.norm2.bias grad: 0.0019737202674150467
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.004337603226304054
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0013108367566019297
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.000818626198451966
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0004027160757686943
sam_encoder.blocks.4.norm1.weight grad: -0.005977208726108074
sam_encoder.blocks.4.norm1.bias grad: 0.004009751603007317
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.004538967274129391
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.001115789171308279
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0012119743041694164
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00022654204803984612
sam_encoder.blocks.4.norm2.weight grad: -0.0029604313895106316
sam_encoder.blocks.4.norm2.bias grad: -0.0021003354340791702
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0035581570118665695
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0012724590487778187
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0009268107824027538
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0010518340859562159
sam_encoder.blocks.5.norm1.weight grad: -0.005208025220781565
sam_encoder.blocks.5.norm1.bias grad: -0.0015606414526700974
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.003204085398465395
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0005812069866806269
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.214561052620411e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0009603418875485659
sam_encoder.blocks.5.norm2.weight grad: -0.00014851285959593952
sam_encoder.blocks.5.norm2.bias grad: -0.0029081066604703665
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0012392968637868762
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00037165413959883153
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.353793727001175e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0005933239008300006
sam_encoder.blocks.6.norm1.weight grad: -0.0008585389005020261
sam_encoder.blocks.6.norm1.bias grad: 0.001728232717141509
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0014807663392275572
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0009518539882265031
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0002439445088384673
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0008425934938713908
sam_encoder.blocks.6.norm2.weight grad: 0.004002693574875593
sam_encoder.blocks.6.norm2.bias grad: -0.0007435479201376438
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.003516516415402293
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0011927285231649876
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.000853814126458019
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0004729225765913725
sam_encoder.blocks.7.norm1.weight grad: -0.0012285851407796144
sam_encoder.blocks.7.norm1.bias grad: 0.0013976804912090302
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00022413730039261281
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00033685483504086733
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0003848038031719625
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.000799964414909482
sam_encoder.blocks.7.norm2.weight grad: 0.006768220104277134
sam_encoder.blocks.7.norm2.bias grad: -0.00126834015827626
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.004249126650393009
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0017804803792387247
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.786355465417728e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00010660347470548004
sam_encoder.blocks.8.norm1.weight grad: -0.0016030794940888882
sam_encoder.blocks.8.norm1.bias grad: 0.0010909907286986709
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0023440560325980186
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0011904553975909948
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0002092188660753891
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0001922504452522844
sam_encoder.blocks.8.norm2.weight grad: 0.001364764291793108
sam_encoder.blocks.8.norm2.bias grad: 1.8581825997898704e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0009686177945695817
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0006516549619846046
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0007511719013564289
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0005478753009811044
sam_encoder.blocks.9.norm1.weight grad: -0.00326325255446136
sam_encoder.blocks.9.norm1.bias grad: 0.00028674176428467035
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0021656686440110207
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00013598718214780092
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00037324713775888085
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0015233391895890236
sam_encoder.blocks.9.norm2.weight grad: 0.0002805160766001791
sam_encoder.blocks.9.norm2.bias grad: -0.0013439327012747526
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0007703750743530691
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.8563837986439466e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0013149407459422946
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0007247662870213389
sam_encoder.blocks.10.norm1.weight grad: -0.0007738039130344987
sam_encoder.blocks.10.norm1.bias grad: -1.7401956938556395e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00034006935311481357
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0002678663586266339
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00037197204073891044
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00017874051991384476
sam_encoder.blocks.10.norm2.weight grad: -0.0033016919624060392
sam_encoder.blocks.10.norm2.bias grad: -0.0029316009022295475
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0004258023982401937
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0008495228830724955
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00177562958560884
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0005242475308477879
sam_encoder.blocks.11.norm1.weight grad: 0.007919689640402794
sam_encoder.blocks.11.norm1.bias grad: -4.759399962495081e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0004922241205349565
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001312209788011387
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0004905616515316069
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00025282136630266905
sam_encoder.blocks.11.norm2.weight grad: -0.0013445446966215968
sam_encoder.blocks.11.norm2.bias grad: -0.00020208684145472944
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0011844341643154621
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0005627223290503025
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.001569552579894662
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0005029214080423117
sam_encoder.neck.conv1.trainable_scale grad: -0.0006345789879560471
sam_encoder.neck.conv1.trainable_shift grad: -0.01716076210141182
sam_encoder.neck.conv2.trainable_scale grad: -0.0007169507443904877
sam_encoder.neck.conv2.trainable_shift grad: 0.06824566423892975
mask_decoder.transformer.layers.0.norm1.weight grad: -0.17543484270572662
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0010138340294361115
mask_decoder.transformer.layers.0.norm2.weight grad: -4.212347030639648
mask_decoder.transformer.layers.0.norm2.bias grad: 0.6275330185890198
mask_decoder.transformer.layers.0.norm3.weight grad: 0.002566389739513397
mask_decoder.transformer.layers.0.norm3.bias grad: 0.03593618422746658
mask_decoder.transformer.layers.0.norm4.weight grad: 0.05081087350845337
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0010388204827904701
mask_decoder.transformer.layers.1.norm1.weight grad: 0.06746657192707062
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00245672557502985
mask_decoder.transformer.layers.1.norm2.weight grad: 0.008019490167498589
mask_decoder.transformer.layers.1.norm2.bias grad: 0.06747236847877502
mask_decoder.transformer.layers.1.norm3.weight grad: 0.040783122181892395
mask_decoder.transformer.layers.1.norm3.bias grad: 0.06023208796977997
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0031595411710441113
mask_decoder.transformer.layers.1.norm4.bias grad: -0.08317892998456955
mask_decoder.transformer.norm_final_attn.weight grad: 0.009843360632658005
mask_decoder.transformer.norm_final_attn.bias grad: 0.007338779978454113
Text_Embedding_Affine.0.weight grad: 4.4724255410244496e-09
Text_Embedding_Affine.0.bias grad: 1.7974525690078735e-07
Text_Embedding_Affine.2.weight grad: 8.285105224103972e-08
Text_Embedding_Affine.2.bias grad: 0.006763633340597153
Epoch 2 finished with average loss: -66.9119
Epoch 3/39
----------
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.8]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-58.8]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-64.2]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-64.2]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-62.4]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-62.4]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798103988170624

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798103988170624

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07855939865112305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.27729302644729614

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07761669158935547

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07855939865112305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 30.828880310058594
Max value: 76.2398910522461
Mean value: 58.80075454711914

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798103988170624

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798103988170624

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798103988170624

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.27729302644729614

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 30.828880310058594
Max value: 76.2398910522461
Mean value: 58.80075454711914

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.801055908203125
Max value: -58.801055908203125
Mean value: -58.801055908203125
sam_encoder.pos_embed grad: -1.5929081200738437e-06
sam_encoder.blocks.0.norm1.weight grad: 0.013336466625332832
sam_encoder.blocks.0.norm1.bias grad: 0.02992427349090576
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0023936801590025425
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.0002992736117448658
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0029430703725665808
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0009015020914375782
sam_encoder.blocks.0.norm2.weight grad: 0.020987002179026604
sam_encoder.blocks.0.norm2.bias grad: 0.02135891281068325
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.004123253282159567
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.002437655348330736
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.005381962284445763
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0016815526178106666
sam_encoder.blocks.1.norm1.weight grad: -0.002494474407285452
sam_encoder.blocks.1.norm1.bias grad: -0.0037441193126142025
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00023393600713461637
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.000624467502348125
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 7.16173235559836e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0007075837347656488
sam_encoder.blocks.1.norm2.weight grad: 0.01789376325905323
sam_encoder.blocks.1.norm2.bias grad: -0.0028309524059295654
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00328798103146255
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0003843469312414527
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.006209764629602432
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0008552104118280113
sam_encoder.blocks.2.norm1.weight grad: -0.0017314963042736053
sam_encoder.blocks.2.norm1.bias grad: -0.0017123332945629954
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00023976372904144228
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00034972053254023194
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00023091315233614296
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00020092978957109153
sam_encoder.blocks.2.norm2.weight grad: -0.004204034339636564
sam_encoder.blocks.2.norm2.bias grad: 0.005436629056930542
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0020480435341596603
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0007375868735834956
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.003966376185417175
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00031001129536889493
sam_encoder.blocks.3.norm1.weight grad: -0.0032973531633615494
sam_encoder.blocks.3.norm1.bias grad: -0.00256764586083591
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0004591536708176136
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0005626960773952305
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0009212845470756292
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0013383501209318638
sam_encoder.blocks.3.norm2.weight grad: 0.005258135497570038
sam_encoder.blocks.3.norm2.bias grad: 0.0017679273150861263
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.005182870663702488
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0016325605101883411
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.002709491178393364
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0006641469663009048
sam_encoder.blocks.4.norm1.weight grad: -0.005107637029141188
sam_encoder.blocks.4.norm1.bias grad: 0.0024619747418910265
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.002608779352158308
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0008992475341074169
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0011062960838899016
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0010821920586749911
sam_encoder.blocks.4.norm2.weight grad: -0.004531926475465298
sam_encoder.blocks.4.norm2.bias grad: -0.008262831717729568
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0033821172546595335
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0012655206955969334
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0008084994042292237
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00032412842847406864
sam_encoder.blocks.5.norm1.weight grad: -0.012308279983699322
sam_encoder.blocks.5.norm1.bias grad: 0.006129528395831585
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.010054556652903557
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0035721901804208755
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.001531426329165697
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0015911988448351622
sam_encoder.blocks.5.norm2.weight grad: -0.005465051159262657
sam_encoder.blocks.5.norm2.bias grad: -0.0019782769959419966
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.002101755701005459
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0003715713392011821
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0012636024039238691
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0011690800311043859
sam_encoder.blocks.6.norm1.weight grad: -0.0008506568847224116
sam_encoder.blocks.6.norm1.bias grad: 0.003890383755788207
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0007895901799201965
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.000928320805542171
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.713388625532389e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0008478768868371844
sam_encoder.blocks.6.norm2.weight grad: 0.000693164300173521
sam_encoder.blocks.6.norm2.bias grad: -0.0005941581912338734
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.001287398161366582
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0005728363757953048
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0010194678325206041
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.0007371767424046993
sam_encoder.blocks.7.norm1.weight grad: -0.0002650022506713867
sam_encoder.blocks.7.norm1.bias grad: 0.0006485374178737402
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00041012460133060813
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00011154316598549485
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0006854910752736032
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0007192743360064924
sam_encoder.blocks.7.norm2.weight grad: 0.005051235668361187
sam_encoder.blocks.7.norm2.bias grad: -0.0001073643215931952
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0036304094828665257
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0015678994823247194
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0005189056973904371
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0007745582843199372
sam_encoder.blocks.8.norm1.weight grad: -0.001985345035791397
sam_encoder.blocks.8.norm1.bias grad: 0.0008620981825515628
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.002857157029211521
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0011702365009114146
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0005228958325460553
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00019806358614005148
sam_encoder.blocks.8.norm2.weight grad: 0.0024463781155645847
sam_encoder.blocks.8.norm2.bias grad: -0.00028827786445617676
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.002489591483026743
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.001285312813706696
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0003728065639734268
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0003297534422017634
sam_encoder.blocks.9.norm1.weight grad: -0.0017370698042213917
sam_encoder.blocks.9.norm1.bias grad: 0.0007110917940735817
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0011949543841183186
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0005151386721991003
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00013262429274618626
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0010531400330364704
sam_encoder.blocks.9.norm2.weight grad: 0.003482274478301406
sam_encoder.blocks.9.norm2.bias grad: -0.0006700302474200726
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0032793148420751095
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.001095360959880054
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00010189608292421326
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00047039714991115034
sam_encoder.blocks.10.norm1.weight grad: 0.001496388460509479
sam_encoder.blocks.10.norm1.bias grad: 0.0004235275264363736
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0020768214017152786
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0010934242745861411
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00088855205103755
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0007508284179493785
sam_encoder.blocks.10.norm2.weight grad: 0.000750223349314183
sam_encoder.blocks.10.norm2.bias grad: -0.0018755248747766018
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0017564871814101934
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.3696534299233463e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0012265635887160897
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0005316423485055566
sam_encoder.blocks.11.norm1.weight grad: 0.005324061959981918
sam_encoder.blocks.11.norm1.bias grad: 0.0003135525621473789
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.001828465610742569
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.156246334081516e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00028237610240466893
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00011963855649810284
sam_encoder.blocks.11.norm2.weight grad: -0.00010657128586899489
sam_encoder.blocks.11.norm2.bias grad: -0.0019829925149679184
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0026260081212967634
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0002094342780765146
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0014054824132472277
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0003657102060969919
sam_encoder.neck.conv1.trainable_scale grad: -0.00047689396888017654
sam_encoder.neck.conv1.trainable_shift grad: -0.013017960824072361
sam_encoder.neck.conv2.trainable_scale grad: -0.0006664209067821503
sam_encoder.neck.conv2.trainable_shift grad: 0.036944035440683365
mask_decoder.transformer.layers.0.norm1.weight grad: -0.21734005212783813
mask_decoder.transformer.layers.0.norm1.bias grad: -0.003230571746826172
mask_decoder.transformer.layers.0.norm2.weight grad: -5.091006278991699
mask_decoder.transformer.layers.0.norm2.bias grad: 0.2945604920387268
mask_decoder.transformer.layers.0.norm3.weight grad: -0.01987433433532715
mask_decoder.transformer.layers.0.norm3.bias grad: 0.023279257118701935
mask_decoder.transformer.layers.0.norm4.weight grad: 0.07278167456388474
mask_decoder.transformer.layers.0.norm4.bias grad: 0.004261685535311699
mask_decoder.transformer.layers.1.norm1.weight grad: 0.06679538637399673
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0019539501518011093
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0544964000582695
mask_decoder.transformer.layers.1.norm2.bias grad: 0.07388133555650711
mask_decoder.transformer.layers.1.norm3.weight grad: 0.03431648015975952
mask_decoder.transformer.layers.1.norm3.bias grad: 0.049002181738615036
mask_decoder.transformer.layers.1.norm4.weight grad: -0.029514657333493233
mask_decoder.transformer.layers.1.norm4.bias grad: -0.16756781935691833
mask_decoder.transformer.norm_final_attn.weight grad: 0.008599446155130863
mask_decoder.transformer.norm_final_attn.bias grad: 0.007604769431054592
Text_Embedding_Affine.0.weight grad: 7.342547458932813e-09
Text_Embedding_Affine.0.bias grad: 2.306042006239295e-07
Text_Embedding_Affine.2.weight grad: 6.272897223880136e-08
Text_Embedding_Affine.2.bias grad: 0.01578042283654213

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09009396284818649

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09009396284818649

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08782386779785156

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2852380871772766

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09005117416381836

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08782386779785156

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 56.65554428100586
Max value: 88.89657592773438
Mean value: 69.6164321899414

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09009396284818649

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09009396284818649

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09009396284818649

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2852380871772766

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 56.65554428100586
Max value: 88.89657592773438
Mean value: 69.6164321899414

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.61666870117188
Max value: -69.61666870117188
Mean value: -69.61666870117188
sam_encoder.pos_embed grad: -1.9268209143774584e-06
sam_encoder.blocks.0.norm1.weight grad: -0.005864394828677177
sam_encoder.blocks.0.norm1.bias grad: 0.042879365384578705
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.007113163359463215
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.0006683468818664551
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.002639468526467681
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0010815841378644109
sam_encoder.blocks.0.norm2.weight grad: 0.04669470712542534
sam_encoder.blocks.0.norm2.bias grad: -0.00010609130549710244
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0027437915559858084
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0025763390585780144
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0055554891005158424
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0006191082648001611
sam_encoder.blocks.1.norm1.weight grad: 0.0007308723870664835
sam_encoder.blocks.1.norm1.bias grad: 0.0004699490964412689
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00228160060942173
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0016583241522312164
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.002555534243583679
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0015714485198259354
sam_encoder.blocks.1.norm2.weight grad: 0.005043369717895985
sam_encoder.blocks.1.norm2.bias grad: -0.0015175454318523407
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0038192342035472393
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0010781183373183012
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.003013456705957651
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0002718375762924552
sam_encoder.blocks.2.norm1.weight grad: 0.0014711306430399418
sam_encoder.blocks.2.norm1.bias grad: 0.0004073049349244684
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0014908027369529009
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.319898915942758e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0001513080787844956
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0014172759838402271
sam_encoder.blocks.2.norm2.weight grad: -0.0034263581037521362
sam_encoder.blocks.2.norm2.bias grad: -0.0013474886072799563
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.002832552418112755
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0015531117096543312
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0007350924424827099
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00016367992793675512
sam_encoder.blocks.3.norm1.weight grad: -0.014389707706868649
sam_encoder.blocks.3.norm1.bias grad: 0.0005543327424675226
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.006255229003727436
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0006452574743889272
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0019467816455289721
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.001077989931218326
sam_encoder.blocks.3.norm2.weight grad: 0.004967913962900639
sam_encoder.blocks.3.norm2.bias grad: 0.0050561511889100075
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0040270015597343445
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0014441302046179771
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00014118137187324464
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0003690107841975987
sam_encoder.blocks.4.norm1.weight grad: -0.0015572307165712118
sam_encoder.blocks.4.norm1.bias grad: 0.006208547856658697
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.002589264651760459
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.000859922613017261
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00031858967849984765
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003466053167358041
sam_encoder.blocks.4.norm2.weight grad: -0.010732665657997131
sam_encoder.blocks.4.norm2.bias grad: -0.008368659764528275
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.008659688755869865
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0032547852024435997
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.001954309642314911
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0015811481280252337
sam_encoder.blocks.5.norm1.weight grad: -6.625460082432255e-05
sam_encoder.blocks.5.norm1.bias grad: 0.0015108291991055012
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.236609649728052e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0008015527273528278
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.281577225308865e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0005676447181031108
sam_encoder.blocks.5.norm2.weight grad: -0.006126316264271736
sam_encoder.blocks.5.norm2.bias grad: -0.0027097738347947598
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0024929807987064123
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0009836027165874839
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00125236832536757
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0011704323114827275
sam_encoder.blocks.6.norm1.weight grad: -3.211417788406834e-05
sam_encoder.blocks.6.norm1.bias grad: 0.0023593250662088394
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.465187430469086e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0002673335839062929
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00022877741139382124
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0007927842671051621
sam_encoder.blocks.6.norm2.weight grad: 0.0028431254904717207
sam_encoder.blocks.6.norm2.bias grad: 0.0005527088651433587
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0015410061459988356
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0005120019195601344
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0001389069075230509
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.147094318478594e-08
sam_encoder.blocks.7.norm1.weight grad: 0.0007135290652513504
sam_encoder.blocks.7.norm1.bias grad: 0.0017779865302145481
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.001655370811931789
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0009644265519455075
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0007989280275069177
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0010039517655968666
sam_encoder.blocks.7.norm2.weight grad: 0.008631723001599312
sam_encoder.blocks.7.norm2.bias grad: -0.0007987337885424495
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.005998534150421619
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0024641365744173527
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.0003071599639952183
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0001749493821989745
sam_encoder.blocks.8.norm1.weight grad: -0.00024921874864958227
sam_encoder.blocks.8.norm1.bias grad: 0.00015605645603500307
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0005244428757578135
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0009183296351693571
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0009793341159820557
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0008398193749599159
sam_encoder.blocks.8.norm2.weight grad: 0.0013824955094605684
sam_encoder.blocks.8.norm2.bias grad: 7.334623660426587e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0008941606502048671
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0004028111870866269
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0013419559691101313
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.000891437754034996
sam_encoder.blocks.9.norm1.weight grad: -0.0024981051683425903
sam_encoder.blocks.9.norm1.bias grad: 0.0006677773781120777
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0018373094499111176
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.873890818795189e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0002059998660115525
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0014635706320405006
sam_encoder.blocks.9.norm2.weight grad: 0.0011878638761118054
sam_encoder.blocks.9.norm2.bias grad: -0.0014889754820615053
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0018037429545074701
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0002713253197725862
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0015687288250774145
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00107593834400177
sam_encoder.blocks.10.norm1.weight grad: 0.0001743622124195099
sam_encoder.blocks.10.norm1.bias grad: 0.000270538468612358
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0009469486540183425
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0005454813363030553
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0008406336419284344
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0004182480915915221
sam_encoder.blocks.10.norm2.weight grad: -0.0007027450483292341
sam_encoder.blocks.10.norm2.bias grad: -0.0023640370927751064
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0021758582442998886
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0003089588135480881
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0017421003431081772
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0005156727856956422
sam_encoder.blocks.11.norm1.weight grad: 0.010056525468826294
sam_encoder.blocks.11.norm1.bias grad: -0.0009840605780482292
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0006164924707263708
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0001692512014415115
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0009828476468101144
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0006689965957775712
sam_encoder.blocks.11.norm2.weight grad: -0.0014248782536014915
sam_encoder.blocks.11.norm2.bias grad: 0.0004549225268419832
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.001695142826065421
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0006147451349534094
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0023043332621455193
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0008735950104892254
sam_encoder.neck.conv1.trainable_scale grad: -0.0007163425907492638
sam_encoder.neck.conv1.trainable_shift grad: -0.014473366551101208
sam_encoder.neck.conv2.trainable_scale grad: -0.0007448494434356689
sam_encoder.neck.conv2.trainable_shift grad: 0.08228781819343567
mask_decoder.transformer.layers.0.norm1.weight grad: -0.2246820032596588
mask_decoder.transformer.layers.0.norm1.bias grad: -0.004419863224029541
mask_decoder.transformer.layers.0.norm2.weight grad: -5.998257160186768
mask_decoder.transformer.layers.0.norm2.bias grad: 0.9369126558303833
mask_decoder.transformer.layers.0.norm3.weight grad: -0.01989804580807686
mask_decoder.transformer.layers.0.norm3.bias grad: 0.031800348311662674
mask_decoder.transformer.layers.0.norm4.weight grad: 0.06025903671979904
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00047241151332855225
mask_decoder.transformer.layers.1.norm1.weight grad: 0.05323086306452751
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0018935427069664001
mask_decoder.transformer.layers.1.norm2.weight grad: -0.039564348757267
mask_decoder.transformer.layers.1.norm2.bias grad: 0.05138968676328659
mask_decoder.transformer.layers.1.norm3.weight grad: 0.031763702630996704
mask_decoder.transformer.layers.1.norm3.bias grad: 0.044067639857530594
mask_decoder.transformer.layers.1.norm4.weight grad: -0.02858390472829342
mask_decoder.transformer.layers.1.norm4.bias grad: -0.13343417644500732
mask_decoder.transformer.norm_final_attn.weight grad: 0.007104633376002312
mask_decoder.transformer.norm_final_attn.bias grad: 0.0067505622282624245
Text_Embedding_Affine.0.weight grad: 1.6556317206095628e-08
Text_Embedding_Affine.0.bias grad: 6.139161996543407e-07
Text_Embedding_Affine.2.weight grad: 1.3300035561769619e-07
Text_Embedding_Affine.2.bias grad: 0.03941778838634491

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07947613298892975

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07947613298892975

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0859212875366211

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2673870027065277

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07925224304199219

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0859212875366211

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 38.13998031616211
Max value: 70.67213439941406
Mean value: 58.82530975341797

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07947613298892975

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07947613298892975

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07947613298892975

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2673870027065277

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 38.13998031616211
Max value: 70.67213439941406
Mean value: 58.82530975341797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.82559585571289
Max value: -58.82559585571289
Mean value: -58.82559585571289
sam_encoder.pos_embed grad: -1.105912815546617e-06
sam_encoder.blocks.0.norm1.weight grad: 0.02539578080177307
sam_encoder.blocks.0.norm1.bias grad: 0.033033933490514755
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0017477342626079917
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00011521457781782374
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0011167082702741027
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0008446729625575244
sam_encoder.blocks.0.norm2.weight grad: 0.006346113979816437
sam_encoder.blocks.0.norm2.bias grad: 0.004926962312310934
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.006309445947408676
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003736060461960733
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.00042518414556980133
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0003195802855771035
sam_encoder.blocks.1.norm1.weight grad: -0.004196217283606529
sam_encoder.blocks.1.norm1.bias grad: 0.0020521082915365696
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0014383079251274467
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0005211083916947246
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0016334911342710257
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0013048008549958467
sam_encoder.blocks.1.norm2.weight grad: 0.0033110431395471096
sam_encoder.blocks.1.norm2.bias grad: -0.0023867925629019737
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0026381080970168114
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0003035858680959791
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0002517353277653456
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00038074853364378214
sam_encoder.blocks.2.norm1.weight grad: -0.0006182374199852347
sam_encoder.blocks.2.norm1.bias grad: -0.004553315695375204
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0009579936740919948
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0006581199704669416
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00010030907287728041
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0010738057317212224
sam_encoder.blocks.2.norm2.weight grad: -0.0011620635632425547
sam_encoder.blocks.2.norm2.bias grad: -0.0017118630930781364
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0006627779803238809
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.000603086780756712
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00224894261918962
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0008350324351340532
sam_encoder.blocks.3.norm1.weight grad: -0.0003412398509681225
sam_encoder.blocks.3.norm1.bias grad: -0.0012943890178576112
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0015608584508299828
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00018349033780395985
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0008541945717297494
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0005479371757246554
sam_encoder.blocks.3.norm2.weight grad: 0.002360118553042412
sam_encoder.blocks.3.norm2.bias grad: 0.0026636957190930843
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0024426497984677553
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0009065528865903616
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0006349285831674933
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.757284376770258e-06
sam_encoder.blocks.4.norm1.weight grad: -0.006473212968558073
sam_encoder.blocks.4.norm1.bias grad: 0.00252833915874362
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0032855989411473274
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0010205504950135946
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.330789569299668e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00022275818628259003
sam_encoder.blocks.4.norm2.weight grad: -0.008366080932319164
sam_encoder.blocks.4.norm2.bias grad: -0.0007405077922157943
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.004422695841640234
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0007625460857525468
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0016078472835943103
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0008006083662621677
sam_encoder.blocks.5.norm1.weight grad: -0.012491653673350811
sam_encoder.blocks.5.norm1.bias grad: 0.00041147967567667365
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.009210178628563881
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.004015573300421238
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0007955239852890372
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0012486170744523406
sam_encoder.blocks.5.norm2.weight grad: -0.007739492692053318
sam_encoder.blocks.5.norm2.bias grad: -0.0026777624152600765
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.002910365117713809
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0007453907164745033
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.002239286433905363
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0011529005132615566
sam_encoder.blocks.6.norm1.weight grad: -0.0017475684871897101
sam_encoder.blocks.6.norm1.bias grad: 0.0018543335609138012
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0022368282079696655
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.001772435731254518
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00010661996202543378
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00043980329064652324
sam_encoder.blocks.6.norm2.weight grad: -0.000512762344442308
sam_encoder.blocks.6.norm2.bias grad: 0.00019318595877848566
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.001388354692608118
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0006288274889811873
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00015654595335945487
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.1287434719852172e-05
sam_encoder.blocks.7.norm1.weight grad: -0.001071200706064701
sam_encoder.blocks.7.norm1.bias grad: 0.001198331592604518
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.338348561665043e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00027645204681903124
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0005760567146353424
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0008711883565410972
sam_encoder.blocks.7.norm2.weight grad: 0.0039655473083257675
sam_encoder.blocks.7.norm2.bias grad: 0.0009946441277861595
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0016974769532680511
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0008840499795041978
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0007786768837831914
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0008176778792403638
sam_encoder.blocks.8.norm1.weight grad: -0.003319704905152321
sam_encoder.blocks.8.norm1.bias grad: 0.0008845068514347076
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0053860703483223915
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0023734576534479856
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0005085245938971639
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.8277368983253837e-05
sam_encoder.blocks.8.norm2.weight grad: 0.001983461668714881
sam_encoder.blocks.8.norm2.bias grad: -5.862912439624779e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0013648675521835685
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0007945771794766188
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00021740577358286828
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00030543722095899284
sam_encoder.blocks.9.norm1.weight grad: -0.0020666136406362057
sam_encoder.blocks.9.norm1.bias grad: 0.00048469635657966137
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0012285393895581365
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00012825592420995235
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0001283616293221712
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0012145995860919356
sam_encoder.blocks.9.norm2.weight grad: 0.0031447927467525005
sam_encoder.blocks.9.norm2.bias grad: -0.0009053642279468477
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.003071879968047142
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0010956027545034885
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0001888643018901348
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0003723781555891037
sam_encoder.blocks.10.norm1.weight grad: 0.0014685119967907667
sam_encoder.blocks.10.norm1.bias grad: 0.00031781906727701426
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0019122769590467215
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0009259338257834315
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0009445552132092416
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0006671275477856398
sam_encoder.blocks.10.norm2.weight grad: 0.00027763628168031573
sam_encoder.blocks.10.norm2.bias grad: -0.0021963261533528566
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.001993145328015089
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.447934538300615e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.000852621509693563
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0004393609706312418
sam_encoder.blocks.11.norm1.weight grad: 0.0022736398968845606
sam_encoder.blocks.11.norm1.bias grad: 0.00022831186652183533
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0005195427220314741
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00010356580605730414
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0009754413622431457
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00047726937918923795
sam_encoder.blocks.11.norm2.weight grad: 0.0012228660052642226
sam_encoder.blocks.11.norm2.bias grad: -0.0016880691982805729
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0030631953850388527
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.766388545045629e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.000841352972202003
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0002793284656945616
sam_encoder.neck.conv1.trainable_scale grad: -0.0006874501705169678
sam_encoder.neck.conv1.trainable_shift grad: -0.008324678987264633
sam_encoder.neck.conv2.trainable_scale grad: -0.0005891867913305759
sam_encoder.neck.conv2.trainable_shift grad: 0.01601722091436386
mask_decoder.transformer.layers.0.norm1.weight grad: -0.16563552618026733
mask_decoder.transformer.layers.0.norm1.bias grad: -0.001892823725938797
mask_decoder.transformer.layers.0.norm2.weight grad: -6.335474014282227
mask_decoder.transformer.layers.0.norm2.bias grad: 0.3919718563556671
mask_decoder.transformer.layers.0.norm3.weight grad: -0.019966959953308105
mask_decoder.transformer.layers.0.norm3.bias grad: 0.026757799088954926
mask_decoder.transformer.layers.0.norm4.weight grad: 0.04501378536224365
mask_decoder.transformer.layers.0.norm4.bias grad: -0.004811933264136314
mask_decoder.transformer.layers.1.norm1.weight grad: 0.07493611425161362
mask_decoder.transformer.layers.1.norm1.bias grad: -0.002966056577861309
mask_decoder.transformer.layers.1.norm2.weight grad: 0.06488987058401108
mask_decoder.transformer.layers.1.norm2.bias grad: 0.08427125215530396
mask_decoder.transformer.layers.1.norm3.weight grad: 0.049259282648563385
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0687677413225174
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0010057361796498299
mask_decoder.transformer.layers.1.norm4.bias grad: -0.10922698676586151
mask_decoder.transformer.norm_final_attn.weight grad: 0.008791780099272728
mask_decoder.transformer.norm_final_attn.bias grad: 0.006779758259654045
Text_Embedding_Affine.0.weight grad: 1.84571860017968e-08
Text_Embedding_Affine.0.bias grad: 5.710171535611153e-07
Text_Embedding_Affine.2.weight grad: 2.2960735179822223e-07
Text_Embedding_Affine.2.bias grad: 0.005269691348075867
Epoch 3 finished with average loss: -62.4144
Epoch 4/39
----------
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62.4]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-62.4]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-63.8]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-63.8]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-64]  Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.16it/s, loss=-64]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07453027367591858

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07453027367591858

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07308387756347656

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19534197449684143

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07340431213378906

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07308387756347656

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 58.03154373168945
Max value: 69.11458587646484
Mean value: 62.43049240112305

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07453027367591858

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07453027367591858

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07453027367591858

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19534197449684143

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 58.03154373168945
Max value: 69.11458587646484
Mean value: 62.43049240112305

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.430908203125
Max value: -62.430908203125
Mean value: -62.430908203125
sam_encoder.pos_embed grad: -2.617287464090623e-06
sam_encoder.blocks.0.norm1.weight grad: 0.018315013498067856
sam_encoder.blocks.0.norm1.bias grad: 0.03300398588180542
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0015859473496675491
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.0003146780072711408
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.004631513264030218
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.002445016987621784
sam_encoder.blocks.0.norm2.weight grad: 0.02240721881389618
sam_encoder.blocks.0.norm2.bias grad: -0.020910760387778282
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.010266738012433052
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0034210304729640484
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0014848684659227729
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00021906298934482038
sam_encoder.blocks.1.norm1.weight grad: 0.00429566903039813
sam_encoder.blocks.1.norm1.bias grad: 0.0034161508083343506
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00026940865791402757
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0006589712575078011
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00011967190948780626
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00016744955792091787
sam_encoder.blocks.1.norm2.weight grad: 0.008378586731851101
sam_encoder.blocks.1.norm2.bias grad: -0.00038275992847047746
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.003205448156222701
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0009632554720155895
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0016997236525639892
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0005328691331669688
sam_encoder.blocks.2.norm1.weight grad: -0.004959895275533199
sam_encoder.blocks.2.norm1.bias grad: 0.0007481090724468231
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0032735667191445827
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0006437558913603425
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0024398465175181627
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0015967159997671843
sam_encoder.blocks.2.norm2.weight grad: -0.0006918665021657944
sam_encoder.blocks.2.norm2.bias grad: 0.00010046611714642495
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0021176927257329226
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0008922933484427631
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00046257348731160164
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.224438402568921e-05
sam_encoder.blocks.3.norm1.weight grad: -0.00851006992161274
sam_encoder.blocks.3.norm1.bias grad: 0.0001390554680256173
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.004400608129799366
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.000539968372322619
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0020288231316953897
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.118657645653002e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0041467114351689816
sam_encoder.blocks.3.norm2.bias grad: 0.005100618582218885
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.004773332271724939
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0017262378241866827
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.002620174316689372
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0008641110616736114
sam_encoder.blocks.4.norm1.weight grad: -0.0018954500555992126
sam_encoder.blocks.4.norm1.bias grad: 0.0044067660346627235
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.002064415719360113
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0005762607324868441
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0001733772223815322
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003197300829924643
sam_encoder.blocks.4.norm2.weight grad: -0.00800635851919651
sam_encoder.blocks.4.norm2.bias grad: -0.012676852755248547
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.008158011361956596
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0028664623387157917
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0004269273194950074
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0007685174932703376
sam_encoder.blocks.5.norm1.weight grad: -0.005686957389116287
sam_encoder.blocks.5.norm1.bias grad: 0.0024599505122750998
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.006618971936404705
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.003274679183959961
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0005443551926873624
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0011883177794516087
sam_encoder.blocks.5.norm2.weight grad: -0.007749982178211212
sam_encoder.blocks.5.norm2.bias grad: -0.004389219451695681
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00265713082626462
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.000630574650131166
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0005449302261695266
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0006999030592851341
sam_encoder.blocks.6.norm1.weight grad: -0.00033850851468741894
sam_encoder.blocks.6.norm1.bias grad: 0.0038822151254862547
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0004807607620023191
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0008700287435203791
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0005501118139363825
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.371325434884056e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0003200275241397321
sam_encoder.blocks.6.norm2.bias grad: -0.00115635572001338
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.309648364956956e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0002899381215684116
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.001348998281173408
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.0007529769791290164
sam_encoder.blocks.7.norm1.weight grad: 0.0008343187510035932
sam_encoder.blocks.7.norm1.bias grad: 0.001351810758933425
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0008057402446866035
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.7004476831061766e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0006134401774033904
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00039525580359622836
sam_encoder.blocks.7.norm2.weight grad: 0.005797485820949078
sam_encoder.blocks.7.norm2.bias grad: -0.0008034538477659225
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0032955859787762165
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0012786051956936717
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.001773338532075286
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0011596579570323229
sam_encoder.blocks.8.norm1.weight grad: -0.001707406248897314
sam_encoder.blocks.8.norm1.bias grad: -0.000537642277777195
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.002729112282395363
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.001755809411406517
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0015170627739280462
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0011672283289954066
sam_encoder.blocks.8.norm2.weight grad: 0.0029950719326734543
sam_encoder.blocks.8.norm2.bias grad: -0.00010122879029950127
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0025903754867613316
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0012130204122513533
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0007734405808150768
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0008210376836359501
sam_encoder.blocks.9.norm1.weight grad: -0.003489390481263399
sam_encoder.blocks.9.norm1.bias grad: 0.0008321187924593687
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.002952621318399906
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.021607547765598e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00031957938335835934
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0010865434305742383
sam_encoder.blocks.9.norm2.weight grad: 0.0027068783529102802
sam_encoder.blocks.9.norm2.bias grad: -0.001228652778081596
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0029763139318674803
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0010796054266393185
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00055868667550385
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0005957389366813004
sam_encoder.blocks.10.norm1.weight grad: -0.00035450252471491694
sam_encoder.blocks.10.norm1.bias grad: 0.0004961613449268043
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00041206422611139715
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0005276331212371588
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0007617386872880161
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0004952521994709969
sam_encoder.blocks.10.norm2.weight grad: 0.00082309206482023
sam_encoder.blocks.10.norm2.bias grad: -0.0017831515287980437
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0026374661829322577
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00011162091686856002
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0007102640229277313
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.000286775641143322
sam_encoder.blocks.11.norm1.weight grad: 0.0070097013376653194
sam_encoder.blocks.11.norm1.bias grad: -0.00026138126850128174
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002810535370372236
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001370531099382788
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0011557737598195672
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0005161497974768281
sam_encoder.blocks.11.norm2.weight grad: 0.0010692467913031578
sam_encoder.blocks.11.norm2.bias grad: 9.465862240176648e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0022873282432556152
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00026108225574716926
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0016342065064236522
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0006280547240749002
sam_encoder.neck.conv1.trainable_scale grad: -0.0009948648512363434
sam_encoder.neck.conv1.trainable_shift grad: -0.0058654253371059895
sam_encoder.neck.conv2.trainable_scale grad: -0.0006217565387487411
sam_encoder.neck.conv2.trainable_shift grad: 0.057541072368621826
mask_decoder.transformer.layers.0.norm1.weight grad: -0.14235132932662964
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0021650344133377075
mask_decoder.transformer.layers.0.norm2.weight grad: -6.115889549255371
mask_decoder.transformer.layers.0.norm2.bias grad: 0.5183715224266052
mask_decoder.transformer.layers.0.norm3.weight grad: -0.02552860602736473
mask_decoder.transformer.layers.0.norm3.bias grad: 0.02682405710220337
mask_decoder.transformer.layers.0.norm4.weight grad: 0.05467350408434868
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0032269982621073723
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0524047426879406
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0007933033630251884
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00509953498840332
mask_decoder.transformer.layers.1.norm2.bias grad: 0.04310941696166992
mask_decoder.transformer.layers.1.norm3.weight grad: 0.03321128338575363
mask_decoder.transformer.layers.1.norm3.bias grad: 0.04157070070505142
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0019251666963100433
mask_decoder.transformer.layers.1.norm4.bias grad: -0.12523454427719116
mask_decoder.transformer.norm_final_attn.weight grad: 0.006043054163455963
mask_decoder.transformer.norm_final_attn.bias grad: 0.005864394828677177
Text_Embedding_Affine.0.weight grad: 2.505379903539051e-09
Text_Embedding_Affine.0.bias grad: 9.12696123123169e-08
Text_Embedding_Affine.2.weight grad: 1.211614915064274e-07
Text_Embedding_Affine.2.bias grad: 0.019213158637285233

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07229942083358765

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07229942083358765

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08261632919311523

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.22651724517345428

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07179880142211914

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08261632919311523

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.259944915771484
Max value: 88.65971374511719
Mean value: 65.26750946044922

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07229942083358765

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07229942083358765

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07229942083358765

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.22651724517345428

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.259944915771484
Max value: 88.65971374511719
Mean value: 65.26750946044922

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.26780700683594
Max value: -65.26780700683594
Mean value: -65.26780700683594
sam_encoder.pos_embed grad: 3.216131005956413e-07
sam_encoder.blocks.0.norm1.weight grad: 0.023738494142889977
sam_encoder.blocks.0.norm1.bias grad: 0.055944375693798065
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0018940053414553404
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.0004941231454722583
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0015675987815484405
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.002380708698183298
sam_encoder.blocks.0.norm2.weight grad: 0.02773979865014553
sam_encoder.blocks.0.norm2.bias grad: -0.00919242575764656
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.003725646063685417
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0024536969140172005
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.006159033626317978
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0011577511904761195
sam_encoder.blocks.1.norm1.weight grad: 0.0026685171760618687
sam_encoder.blocks.1.norm1.bias grad: 0.0011187068885192275
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0009792650816962123
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0012121506733819842
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0013769858051091433
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0008147096959874034
sam_encoder.blocks.1.norm2.weight grad: 0.007198953535407782
sam_encoder.blocks.1.norm2.bias grad: 0.002017198596149683
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0013482293579727411
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.2235548133030534e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0017041083192452788
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0004781050083693117
sam_encoder.blocks.2.norm1.weight grad: -0.006676660384982824
sam_encoder.blocks.2.norm1.bias grad: 0.0018069315701723099
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.002939315978437662
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0005530471680685878
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00013016397133469582
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.001967805903404951
sam_encoder.blocks.2.norm2.weight grad: -0.000836342922411859
sam_encoder.blocks.2.norm2.bias grad: 0.0006682894891127944
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0022963802330195904
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0006979430327191949
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 9.390603372594342e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.0001815056602936238
sam_encoder.blocks.3.norm1.weight grad: -0.007957356050610542
sam_encoder.blocks.3.norm1.bias grad: 0.0021181125193834305
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.003796954173594713
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00015325131244026124
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0013971116859465837
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0013233644422143698
sam_encoder.blocks.3.norm2.weight grad: -0.0003265729174017906
sam_encoder.blocks.3.norm2.bias grad: 0.0049664913676679134
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0006354462238959968
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.1329189874231815e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0013285772874951363
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0008218997390940785
sam_encoder.blocks.4.norm1.weight grad: -0.00048687122762203217
sam_encoder.blocks.4.norm1.bias grad: 0.008567685261368752
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0009661924559623003
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00033455691300332546
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0004104773688595742
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00017254716658499092
sam_encoder.blocks.4.norm2.weight grad: 0.0007345178164541721
sam_encoder.blocks.4.norm2.bias grad: -0.001454178593121469
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0015976791037246585
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0010734768584370613
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.003507393877953291
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0017936292570084333
sam_encoder.blocks.5.norm1.weight grad: -0.009385146200656891
sam_encoder.blocks.5.norm1.bias grad: -0.000549802090972662
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.007022069301456213
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0031474786810576916
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0017706272192299366
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.001964189112186432
sam_encoder.blocks.5.norm2.weight grad: -0.0014286841033026576
sam_encoder.blocks.5.norm2.bias grad: -0.002053371397778392
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00036151002859696746
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00030964025063440204
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0007669981569051743
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.001118502113968134
sam_encoder.blocks.6.norm1.weight grad: -8.198036812245846e-05
sam_encoder.blocks.6.norm1.bias grad: -9.724641859065741e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00022692163474857807
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00016134229372255504
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0003332331543788314
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0003177759936079383
sam_encoder.blocks.6.norm2.weight grad: 0.006613485515117645
sam_encoder.blocks.6.norm2.bias grad: 0.001157832914032042
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0035615551751106977
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0013774711405858397
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0004872914869338274
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00022033524874132127
sam_encoder.blocks.7.norm1.weight grad: -0.000609876646194607
sam_encoder.blocks.7.norm1.bias grad: 0.0011539593106135726
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0006056361598894
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3725735698244534e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0002265505027025938
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0010381436441093683
sam_encoder.blocks.7.norm2.weight grad: 0.006687638815492392
sam_encoder.blocks.7.norm2.bias grad: -0.0008371683652512729
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.003378080204129219
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.001546657644212246
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002775768225546926
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0003505260683596134
sam_encoder.blocks.8.norm1.weight grad: -0.0005081350682303309
sam_encoder.blocks.8.norm1.bias grad: -0.00036176032153889537
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0002131100045517087
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0011607599444687366
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0015932824462652206
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0012080566957592964
sam_encoder.blocks.8.norm2.weight grad: 0.0008858264773152769
sam_encoder.blocks.8.norm2.bias grad: 0.0007140642264857888
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.208474223967642e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00014471383474301547
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0013480472844094038
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0008844956755638123
sam_encoder.blocks.9.norm1.weight grad: -0.0026186276227235794
sam_encoder.blocks.9.norm1.bias grad: 0.0004431001143530011
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00189175084233284
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0001082818052964285
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00047382136108353734
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0012377144303172827
sam_encoder.blocks.9.norm2.weight grad: 0.0005012144683860242
sam_encoder.blocks.9.norm2.bias grad: -0.0011483319103717804
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0007330706575885415
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.000217474065721035
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0011509268078953028
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0008036663639359176
sam_encoder.blocks.10.norm1.weight grad: -0.0025769046042114496
sam_encoder.blocks.10.norm1.bias grad: 8.272582635981962e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0006678171339444816
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.833091977867298e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.4909811802208424e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.665837407927029e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0030323495157063007
sam_encoder.blocks.10.norm2.bias grad: -0.0027032438665628433
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0003254494513384998
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0007757277926430106
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0015924950130283833
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0004775068664457649
sam_encoder.blocks.11.norm1.weight grad: 0.007958132773637772
sam_encoder.blocks.11.norm1.bias grad: -0.00065192038891837
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0021497842390090227
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00017245096387341619
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.001101483590900898
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0005527666653506458
sam_encoder.blocks.11.norm2.weight grad: -0.004831245169043541
sam_encoder.blocks.11.norm2.bias grad: -0.0008801945368759334
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00041906931437551975
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0010910825803875923
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.002292882651090622
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0008415933698415756
sam_encoder.neck.conv1.trainable_scale grad: -0.0008574929088354111
sam_encoder.neck.conv1.trainable_shift grad: -0.015842556953430176
sam_encoder.neck.conv2.trainable_scale grad: -0.0007640756666660309
sam_encoder.neck.conv2.trainable_shift grad: 0.08838494122028351
mask_decoder.transformer.layers.0.norm1.weight grad: -0.20281332731246948
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00309792160987854
mask_decoder.transformer.layers.0.norm2.weight grad: -3.365722417831421
mask_decoder.transformer.layers.0.norm2.bias grad: 0.8935801386833191
mask_decoder.transformer.layers.0.norm3.weight grad: -0.014462079852819443
mask_decoder.transformer.layers.0.norm3.bias grad: 0.013186592608690262
mask_decoder.transformer.layers.0.norm4.weight grad: 0.04050394147634506
mask_decoder.transformer.layers.0.norm4.bias grad: -0.000853964127600193
mask_decoder.transformer.layers.1.norm1.weight grad: 0.03723444044589996
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0025407588109374046
mask_decoder.transformer.layers.1.norm2.weight grad: 0.020657293498516083
mask_decoder.transformer.layers.1.norm2.bias grad: 0.03520067781209946
mask_decoder.transformer.layers.1.norm3.weight grad: 0.029170243069529533
mask_decoder.transformer.layers.1.norm3.bias grad: 0.035777583718299866
mask_decoder.transformer.layers.1.norm4.weight grad: -0.010167253203690052
mask_decoder.transformer.layers.1.norm4.bias grad: -0.10393157601356506
mask_decoder.transformer.norm_final_attn.weight grad: 0.004949622787535191
mask_decoder.transformer.norm_final_attn.bias grad: 0.00560939684510231
Text_Embedding_Affine.0.weight grad: -1.3695364842192248e-08
Text_Embedding_Affine.0.bias grad: -3.6368146538734436e-07
Text_Embedding_Affine.2.weight grad: 1.484422362807436e-08
Text_Embedding_Affine.2.bias grad: 0.04107814282178879

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11587671935558319

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11587671935558319

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10693073272705078

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20851030945777893

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10969352722167969

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10693073272705078

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 42.883419036865234
Max value: 77.46503448486328
Mean value: 64.15109252929688

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11587671935558319

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11587671935558319

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11587671935558319

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20851030945777893

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 42.883419036865234
Max value: 77.46503448486328
Mean value: 64.15109252929688

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.1518783569336
Max value: -64.1518783569336
Mean value: -64.1518783569336
sam_encoder.pos_embed grad: -2.979106056955061e-06
sam_encoder.blocks.0.norm1.weight grad: 0.0024901058059185743
sam_encoder.blocks.0.norm1.bias grad: 0.024157537147402763
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0006096269935369492
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00019418417650740594
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0031623614486306906
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0009484525653533638
sam_encoder.blocks.0.norm2.weight grad: 0.01958071067929268
sam_encoder.blocks.0.norm2.bias grad: -0.009088165126740932
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.003880138276144862
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.819191138314636e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.010340663604438305
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0017149902414530516
sam_encoder.blocks.1.norm1.weight grad: 0.0007774794939905405
sam_encoder.blocks.1.norm1.bias grad: 0.0014100037515163422
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.001980574568733573
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.000653381459414959
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0014796378090977669
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.000833213678561151
sam_encoder.blocks.1.norm2.weight grad: 0.00368369254283607
sam_encoder.blocks.1.norm2.bias grad: -0.001128528150729835
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0008762506768107414
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0002963088045362383
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.002270845463499427
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0008552412036806345
sam_encoder.blocks.2.norm1.weight grad: 0.003421379253268242
sam_encoder.blocks.2.norm1.bias grad: -0.0038112930487841368
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.002066577784717083
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00021816007210873067
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.000958546414040029
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0008901515975594521
sam_encoder.blocks.2.norm2.weight grad: -0.002101366873830557
sam_encoder.blocks.2.norm2.bias grad: -0.005016678012907505
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0012952551478520036
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0010313004022464156
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00116624403744936
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004047746770083904
sam_encoder.blocks.3.norm1.weight grad: 0.000711707107257098
sam_encoder.blocks.3.norm1.bias grad: -0.0033361325040459633
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.002054053358733654
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.109546277206391e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0008712347480468452
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0002751694992184639
sam_encoder.blocks.3.norm2.weight grad: 0.0021155427675694227
sam_encoder.blocks.3.norm2.bias grad: 0.0020376548636704683
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0026979611720889807
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00147467281203717
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0017312944401055574
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.662325252662413e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0021734205074608326
sam_encoder.blocks.4.norm1.bias grad: 0.0014319296460598707
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0003428329946473241
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00013591014430858195
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.001340974122285843
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0008566360920667648
sam_encoder.blocks.4.norm2.weight grad: -0.017551492899656296
sam_encoder.blocks.4.norm2.bias grad: -0.007837439887225628
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.011264292523264885
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0034699018578976393
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0009632612345740199
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0009069480001926422
sam_encoder.blocks.5.norm1.weight grad: -0.003537363838404417
sam_encoder.blocks.5.norm1.bias grad: 0.00023496686480939388
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0029535088688135147
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0020474325865507126
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0007040135096758604
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00013147713616490364
sam_encoder.blocks.5.norm2.weight grad: -0.01209268532693386
sam_encoder.blocks.5.norm2.bias grad: -0.005371959879994392
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.005320227704942226
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0015605322550982237
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0007793157128617167
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0009639933705329895
sam_encoder.blocks.6.norm1.weight grad: -0.0010308236815035343
sam_encoder.blocks.6.norm1.bias grad: 0.0022892067208886147
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.001462070271372795
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00111927161924541
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0003148404066450894
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.000460047391243279
sam_encoder.blocks.6.norm2.weight grad: -0.003388105658814311
sam_encoder.blocks.6.norm2.bias grad: -0.0005955460364930332
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0019166909623891115
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0008248644880950451
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0004210135084576905
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00018511107191443443
sam_encoder.blocks.7.norm1.weight grad: 0.0001143200061051175
sam_encoder.blocks.7.norm1.bias grad: 0.0010513730812817812
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.732173980912194e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00024819065583869815
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0004959851503372192
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0007202927954494953
sam_encoder.blocks.7.norm2.weight grad: 0.002972458256408572
sam_encoder.blocks.7.norm2.bias grad: 0.0010659679537639022
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00181574746966362
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0004813690611626953
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0004909883136861026
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0007887128740549088
sam_encoder.blocks.8.norm1.weight grad: 0.00010164716513827443
sam_encoder.blocks.8.norm1.bias grad: -0.0004853971186093986
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0012543469201773405
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0009584039216861129
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0010095633333548903
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 7.350262603722513e-05
sam_encoder.blocks.8.norm2.weight grad: 9.857041004579514e-05
sam_encoder.blocks.8.norm2.bias grad: -0.0001954418112291023
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00022053827706258744
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.389681508764625e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00017393629241269082
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0006062607280910015
sam_encoder.blocks.9.norm1.weight grad: -0.001918893656693399
sam_encoder.blocks.9.norm1.bias grad: 0.0006023689056746662
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.001583652920089662
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.719884575228207e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00012255029287189245
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0010375084821134806
sam_encoder.blocks.9.norm2.weight grad: 0.0025130342692136765
sam_encoder.blocks.9.norm2.bias grad: -0.0010005742078647017
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0028792032971978188
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0008952698553912342
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0005830518784932792
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00020705517090391368
sam_encoder.blocks.10.norm1.weight grad: 0.0032203285954892635
sam_encoder.blocks.10.norm1.bias grad: 0.00064944161567837
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.002310103503987193
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0011211226228624582
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.001210356829687953
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0006865011528134346
sam_encoder.blocks.10.norm2.weight grad: 0.0008993226801976562
sam_encoder.blocks.10.norm2.bias grad: -0.0014166566543281078
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0021406335290521383
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0001906456018332392
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0006215586327016354
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0003358395479153842
sam_encoder.blocks.11.norm1.weight grad: 0.006354290526360273
sam_encoder.blocks.11.norm1.bias grad: 0.00021948953508399427
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0005551587091758847
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0003205054090358317
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0013100787764415145
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0006681983359158039
sam_encoder.blocks.11.norm2.weight grad: 0.002765140263363719
sam_encoder.blocks.11.norm2.bias grad: -0.000612028525210917
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0031958501785993576
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00030465456075035036
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00038917752681300044
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00022971541329752654
sam_encoder.neck.conv1.trainable_scale grad: -0.0007166657596826553
sam_encoder.neck.conv1.trainable_shift grad: -0.011110508814454079
sam_encoder.neck.conv2.trainable_scale grad: -0.0007547768764197826
sam_encoder.neck.conv2.trainable_shift grad: 0.01752409338951111
mask_decoder.transformer.layers.0.norm1.weight grad: -0.14464500546455383
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0011469125747680664
mask_decoder.transformer.layers.0.norm2.weight grad: -4.915474891662598
mask_decoder.transformer.layers.0.norm2.bias grad: 0.3652985692024231
mask_decoder.transformer.layers.0.norm3.weight grad: -0.029031114652752876
mask_decoder.transformer.layers.0.norm3.bias grad: 0.023142263293266296
mask_decoder.transformer.layers.0.norm4.weight grad: 0.05646207556128502
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0037096692249178886
mask_decoder.transformer.layers.1.norm1.weight grad: 0.04752831533551216
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00034058280289173126
mask_decoder.transformer.layers.1.norm2.weight grad: 0.024608073756098747
mask_decoder.transformer.layers.1.norm2.bias grad: 0.032379474490880966
mask_decoder.transformer.layers.1.norm3.weight grad: 0.04008397459983826
mask_decoder.transformer.layers.1.norm3.bias grad: 0.04120733588933945
mask_decoder.transformer.layers.1.norm4.weight grad: 0.005081702955067158
mask_decoder.transformer.layers.1.norm4.bias grad: -0.11234890669584274
mask_decoder.transformer.norm_final_attn.weight grad: 0.0064577022567391396
mask_decoder.transformer.norm_final_attn.bias grad: 0.006662198342382908
Text_Embedding_Affine.0.weight grad: -8.691861452803096e-09
Text_Embedding_Affine.0.bias grad: -3.052409738302231e-07
Text_Embedding_Affine.2.weight grad: 1.0226193225548741e-08
Text_Embedding_Affine.2.bias grad: 0.01841825060546398
Epoch 4 finished with average loss: -63.9502
Epoch 5/39
----------
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.1]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-55.1]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-56.2]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-56.2]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-58.8]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.30it/s, loss=-58.8]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.821125911406248e-28
Max value: 1.0
Mean value: 0.07301734387874603

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.821125911406248e-28
Max value: 1.0
Mean value: 0.07301734387874603

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07875776290893555

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17922288179397583

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06345272064208984

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07875776290893555

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.41265106201172
Max value: 63.32558822631836
Mean value: 55.118377685546875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.821125911406248e-28
Max value: 1.0
Mean value: 0.07301734387874603

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.821125911406248e-28
Max value: 1.0
Mean value: 0.07301734387874603

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.821125911406248e-28
Max value: 1.0
Mean value: 0.07301734387874603

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17922288179397583

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.41265106201172
Max value: 63.32558822631836
Mean value: 55.118377685546875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.11918258666992
Max value: -55.11918258666992
Mean value: -55.11918258666992
sam_encoder.pos_embed grad: 7.069018010952277e-07
sam_encoder.blocks.0.norm1.weight grad: 0.03152065724134445
sam_encoder.blocks.0.norm1.bias grad: 0.014463964849710464
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00028026255313307047
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00013169930025469512
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0023162532597780228
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0004407111555337906
sam_encoder.blocks.0.norm2.weight grad: 0.0037281420081853867
sam_encoder.blocks.0.norm2.bias grad: -0.018746038898825645
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.00306412554346025
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00021357634977903217
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0005472855409607291
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0020765038207173347
sam_encoder.blocks.1.norm1.weight grad: 0.0007239884580485523
sam_encoder.blocks.1.norm1.bias grad: -0.00044869002886116505
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0008437982760369778
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0006612210418097675
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0007590671884827316
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0004636470112018287
sam_encoder.blocks.1.norm2.weight grad: -0.0016105324029922485
sam_encoder.blocks.1.norm2.bias grad: 0.0031072888523340225
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0010976202320307493
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0004498817434068769
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0021767416037619114
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.555634611984715e-05
sam_encoder.blocks.2.norm1.weight grad: 0.000965096231084317
sam_encoder.blocks.2.norm1.bias grad: -0.00020207930356264114
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0016931066056713462
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0008762892102822661
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0002470151230227202
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0008092218777164817
sam_encoder.blocks.2.norm2.weight grad: -0.0006462292512878776
sam_encoder.blocks.2.norm2.bias grad: -0.0013326029293239117
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0006036440609022975
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0003494339471217245
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0015270013827830553
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0006445122417062521
sam_encoder.blocks.3.norm1.weight grad: -0.003151930635794997
sam_encoder.blocks.3.norm1.bias grad: 0.0004762382886838168
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0013733329251408577
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 8.570442150812596e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0004387559019960463
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0001799829042283818
sam_encoder.blocks.3.norm2.weight grad: -0.004305840469896793
sam_encoder.blocks.3.norm2.bias grad: 0.0053504453971982
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0035658066626638174
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0007868417305871844
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0007125105476006866
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0005275416187942028
sam_encoder.blocks.4.norm1.weight grad: -0.0011173536768183112
sam_encoder.blocks.4.norm1.bias grad: 0.0042884862050414085
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0008207231294363737
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00021944874606560916
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0003618878254201263
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0012636985629796982
sam_encoder.blocks.4.norm2.weight grad: -0.002688083564862609
sam_encoder.blocks.4.norm2.bias grad: 0.004227634519338608
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0016563059762120247
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00012837874237447977
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0015735903289169073
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0007179708918556571
sam_encoder.blocks.5.norm1.weight grad: -0.009851162321865559
sam_encoder.blocks.5.norm1.bias grad: 0.0037024831399321556
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.006451507098972797
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.002300563734024763
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.002597368322312832
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.002122513484209776
sam_encoder.blocks.5.norm2.weight grad: -0.00678971316665411
sam_encoder.blocks.5.norm2.bias grad: 0.0007612550398334861
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.004408574663102627
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0014740275219082832
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0012472622329369187
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0007170438766479492
sam_encoder.blocks.6.norm1.weight grad: 0.00034747691825032234
sam_encoder.blocks.6.norm1.bias grad: 8.199558214982972e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.969688497018069e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0006975745782256126
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00037367301410995424
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.8196004829369485e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0012309434823691845
sam_encoder.blocks.6.norm2.bias grad: 0.0022594393230974674
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.002284666057676077
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0010196671355515718
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00010430374823044986
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.0001328693178948015
sam_encoder.blocks.7.norm1.weight grad: -0.0023310272954404354
sam_encoder.blocks.7.norm1.bias grad: 0.0012529435334727168
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.001616824185475707
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.001022692653350532
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0005411907914094627
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.001330971485003829
sam_encoder.blocks.7.norm2.weight grad: 0.0005967288743704557
sam_encoder.blocks.7.norm2.bias grad: 0.0002551113720983267
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0003920840099453926
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.462346967353369e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00013903502258472145
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00021959564764983952
sam_encoder.blocks.8.norm1.weight grad: -0.001065906137228012
sam_encoder.blocks.8.norm1.bias grad: 0.0013119219802320004
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.002711421577259898
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.001336336019448936
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0009321707184426486
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.001013355329632759
sam_encoder.blocks.8.norm2.weight grad: 0.0008455788483843207
sam_encoder.blocks.8.norm2.bias grad: -0.0003060903982259333
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.000538793858140707
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.000275520229479298
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0002676616422832012
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.077939825539943e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0032590734772384167
sam_encoder.blocks.9.norm1.bias grad: 0.0003835415409412235
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.002258359920233488
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0002906685695052147
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0004107421264052391
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0012334950733929873
sam_encoder.blocks.9.norm2.weight grad: 0.0010705682216212153
sam_encoder.blocks.9.norm2.bias grad: -0.0010177996009588242
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.001730885822325945
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0004946069093421102
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0011469278251752257
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00010522835509618744
sam_encoder.blocks.10.norm1.weight grad: 9.733624756336212e-05
sam_encoder.blocks.10.norm1.bias grad: 0.0003315730136819184
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0007990135345607996
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00046542088966816664
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0004745351034216583
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00044310124940238893
sam_encoder.blocks.10.norm2.weight grad: -0.0017613095697015524
sam_encoder.blocks.10.norm2.bias grad: -0.0025882194750010967
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00021961424499750137
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0009306109277531505
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0007085081888362765
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0004298252461012453
sam_encoder.blocks.11.norm1.weight grad: -0.00448797969147563
sam_encoder.blocks.11.norm1.bias grad: 0.00042619588202796876
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0007491714786738157
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00015293536125682294
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00015010006609372795
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.34469592012465e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0010594998020678759
sam_encoder.blocks.11.norm2.bias grad: -0.0011769294505938888
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0013517008628696203
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.621455784421414e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0002496811794117093
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00022223008272703737
sam_encoder.neck.conv1.trainable_scale grad: -0.0007343408651649952
sam_encoder.neck.conv1.trainable_shift grad: -0.009699171409010887
sam_encoder.neck.conv2.trainable_scale grad: -0.0007449383847415447
sam_encoder.neck.conv2.trainable_shift grad: 0.009235890582203865
mask_decoder.transformer.layers.0.norm1.weight grad: -0.23233920335769653
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00244009867310524
mask_decoder.transformer.layers.0.norm2.weight grad: -2.253974437713623
mask_decoder.transformer.layers.0.norm2.bias grad: 0.8420820236206055
mask_decoder.transformer.layers.0.norm3.weight grad: -0.026148729026317596
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0060728974640369415
mask_decoder.transformer.layers.0.norm4.weight grad: 0.029648803174495697
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0013772686943411827
mask_decoder.transformer.layers.1.norm1.weight grad: 0.03558892756700516
mask_decoder.transformer.layers.1.norm1.bias grad: -0.002308553084731102
mask_decoder.transformer.layers.1.norm2.weight grad: 0.10538776218891144
mask_decoder.transformer.layers.1.norm2.bias grad: 0.02585093304514885
mask_decoder.transformer.layers.1.norm3.weight grad: 0.03238195925951004
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0430542528629303
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0005489103496074677
mask_decoder.transformer.layers.1.norm4.bias grad: -0.09562592208385468
mask_decoder.transformer.norm_final_attn.weight grad: 0.00489167682826519
mask_decoder.transformer.norm_final_attn.bias grad: 0.004958559293299913
Text_Embedding_Affine.0.weight grad: -6.294033738640792e-09
Text_Embedding_Affine.0.bias grad: -1.701992005109787e-07
Text_Embedding_Affine.2.weight grad: 1.0547122286652666e-07
Text_Embedding_Affine.2.bias grad: 0.03216135501861572

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.521601791566261e-34
Max value: 1.0
Mean value: 0.0926651656627655

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.521601791566261e-34
Max value: 1.0
Mean value: 0.0926651656627655

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09432458877563477

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19029510021209717

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08439922332763672

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09432458877563477

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.030914306640625
Max value: 72.36729431152344
Mean value: 57.286991119384766

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.521601791566261e-34
Max value: 1.0
Mean value: 0.0926651656627655

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.521601791566261e-34
Max value: 1.0
Mean value: 0.0926651656627655

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.521601791566261e-34
Max value: 1.0
Mean value: 0.0926651656627655

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19029510021209717

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.030914306640625
Max value: 72.36729431152344
Mean value: 57.286991119384766

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.287837982177734
Max value: -57.287837982177734
Mean value: -57.287837982177734
sam_encoder.pos_embed grad: -2.9094167075527366e-06
sam_encoder.blocks.0.norm1.weight grad: 0.01934533752501011
sam_encoder.blocks.0.norm1.bias grad: 0.020626677200198174
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0005782723310403526
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00043289799941703677
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.004160113632678986
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0005794678581878543
sam_encoder.blocks.0.norm2.weight grad: 0.022718019783496857
sam_encoder.blocks.0.norm2.bias grad: 0.003764963708817959
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0008299303590320051
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00115290773101151
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0038603395223617554
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.8418336771428585e-05
sam_encoder.blocks.1.norm1.weight grad: 0.00018181814812123775
sam_encoder.blocks.1.norm1.bias grad: -0.003028175327926874
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.001261937664821744
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00043633891618810594
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0007162776309996843
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0003475164994597435
sam_encoder.blocks.1.norm2.weight grad: 0.005851360037922859
sam_encoder.blocks.1.norm2.bias grad: -0.0003151788841933012
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0006348297465592623
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00029416396864689887
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0007716221734881401
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00015753436309751123
sam_encoder.blocks.2.norm1.weight grad: -0.002125188708305359
sam_encoder.blocks.2.norm1.bias grad: -0.0007056668400764465
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00037139185587875545
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.000476215936942026
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0012086480855941772
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0010910489363595843
sam_encoder.blocks.2.norm2.weight grad: 0.0022334116511046886
sam_encoder.blocks.2.norm2.bias grad: -0.0002921331615652889
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0012293490581214428
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.732026718556881e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0003954076091758907
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.076982779428363e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0035621924325823784
sam_encoder.blocks.3.norm1.bias grad: -0.002346270252019167
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0032100535463541746
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0006843117298558354
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0009648238192312419
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0007312564994208515
sam_encoder.blocks.3.norm2.weight grad: 0.0023073696065694094
sam_encoder.blocks.3.norm2.bias grad: 0.0008397686178795993
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0025370800867676735
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0017115315422415733
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0012586282100528479
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00012964515190105885
sam_encoder.blocks.4.norm1.weight grad: 0.00479474663734436
sam_encoder.blocks.4.norm1.bias grad: -0.0003935194981750101
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0024874121882021427
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0010303723393008113
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0014367266558110714
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0014309859834611416
sam_encoder.blocks.4.norm2.weight grad: -0.008390014991164207
sam_encoder.blocks.4.norm2.bias grad: -0.004268346354365349
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0054384032264351845
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0016664651921018958
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0011973034124821424
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0005050523323006928
sam_encoder.blocks.5.norm1.weight grad: -0.0031769981142133474
sam_encoder.blocks.5.norm1.bias grad: -4.6039738663239405e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0030457889661192894
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0021470095962285995
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0008102305000647902
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0005590149667114019
sam_encoder.blocks.5.norm2.weight grad: -0.008195262402296066
sam_encoder.blocks.5.norm2.bias grad: -0.0035352117847651243
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0036048474721610546
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0008494333596900105
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0005738235777243972
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00045065651647746563
sam_encoder.blocks.6.norm1.weight grad: -0.00018860625277739018
sam_encoder.blocks.6.norm1.bias grad: 0.0006178116309456527
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0007399317692033947
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0005719860782846808
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0003614861925598234
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0002832831523846835
sam_encoder.blocks.6.norm2.weight grad: -0.003964616917073727
sam_encoder.blocks.6.norm2.bias grad: 0.0003528045490384102
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0026122666895389557
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.001064854208379984
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0003424806927796453
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00023945303109940141
sam_encoder.blocks.7.norm1.weight grad: 0.0023725845385342836
sam_encoder.blocks.7.norm1.bias grad: 0.00041836744640022516
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0017568373586982489
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0007530921138823032
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0009029653738252819
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0004683827864937484
sam_encoder.blocks.7.norm2.weight grad: 0.001786408363841474
sam_encoder.blocks.7.norm2.bias grad: 0.0003989214892499149
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0008049242896959186
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.00023929576855152845
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.7812164262286387e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0002443339617457241
sam_encoder.blocks.8.norm1.weight grad: 0.0007449975237250328
sam_encoder.blocks.8.norm1.bias grad: 9.401602437719703e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0003477540740277618
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0004031243734061718
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0006493813125416636
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00031197164207696915
sam_encoder.blocks.8.norm2.weight grad: 0.0007942227530293167
sam_encoder.blocks.8.norm2.bias grad: -0.00019844164489768445
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0005348687409423292
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00036993910907767713
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00020335835870355368
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00029892928432673216
sam_encoder.blocks.9.norm1.weight grad: -0.002385550644248724
sam_encoder.blocks.9.norm1.bias grad: 0.0006098967278376222
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00236004707403481
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00045380028313957155
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0004716537077911198
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0007311961380764842
sam_encoder.blocks.9.norm2.weight grad: 0.0018944060429930687
sam_encoder.blocks.9.norm2.bias grad: -0.00041385035729035735
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.002144286874681711
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.000715913949534297
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0005474763456732035
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.8471491279779e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0014822075609117746
sam_encoder.blocks.10.norm1.bias grad: 0.0007153436308726668
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0009848480112850666
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0005951700150035322
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0004132464528083801
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00038815877633169293
sam_encoder.blocks.10.norm2.weight grad: 0.0021423357538878918
sam_encoder.blocks.10.norm2.bias grad: -0.0004146586870774627
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.002080666832625866
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0007072893204167485
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00015962810721248388
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.103778287069872e-05
sam_encoder.blocks.11.norm1.weight grad: 0.002486096927896142
sam_encoder.blocks.11.norm1.bias grad: 0.00011878216173499823
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.001722843386232853
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00035941562964580953
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.0029003028175794e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.076802310417406e-05
sam_encoder.blocks.11.norm2.weight grad: 0.004756736569106579
sam_encoder.blocks.11.norm2.bias grad: 0.0001600325049366802
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0029768513049930334
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.000652517075650394
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00030606292420998216
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.861265940940939e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.0004264446906745434
sam_encoder.neck.conv1.trainable_shift grad: -0.004485021345317364
sam_encoder.neck.conv2.trainable_scale grad: -0.00037465128116309643
sam_encoder.neck.conv2.trainable_shift grad: 0.0013650835026055574
mask_decoder.transformer.layers.0.norm1.weight grad: -0.04657919704914093
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00045131146907806396
mask_decoder.transformer.layers.0.norm2.weight grad: -3.254687786102295
mask_decoder.transformer.layers.0.norm2.bias grad: 0.2457740306854248
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0037973634898662567
mask_decoder.transformer.layers.0.norm3.bias grad: 0.01735701784491539
mask_decoder.transformer.layers.0.norm4.weight grad: 0.03208959847688675
mask_decoder.transformer.layers.0.norm4.bias grad: -0.00025372719392180443
mask_decoder.transformer.layers.1.norm1.weight grad: 0.02911115437746048
mask_decoder.transformer.layers.1.norm1.bias grad: -0.002660430036485195
mask_decoder.transformer.layers.1.norm2.weight grad: 0.06029805913567543
mask_decoder.transformer.layers.1.norm2.bias grad: 0.039456404745578766
mask_decoder.transformer.layers.1.norm3.weight grad: 0.03211992606520653
mask_decoder.transformer.layers.1.norm3.bias grad: 0.027581142261624336
mask_decoder.transformer.layers.1.norm4.weight grad: -0.005043042823672295
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0950976237654686
mask_decoder.transformer.norm_final_attn.weight grad: 0.0026800220366567373
mask_decoder.transformer.norm_final_attn.bias grad: 0.004236143082380295
Text_Embedding_Affine.0.weight grad: 7.347053188055952e-09
Text_Embedding_Affine.0.bias grad: 3.4365803003311157e-07
Text_Embedding_Affine.2.weight grad: 8.40382767819392e-08
Text_Embedding_Affine.2.bias grad: 0.00717140780761838

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0917287001189625e-27
Max value: 1.0
Mean value: 0.09038455784320831

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0917287001189625e-27
Max value: 1.0
Mean value: 0.09038455784320831

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07271385192871094

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13631242513656616

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07063102722167969

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07271385192871094

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.997840881347656
Max value: 79.6866455078125
Mean value: 63.86017608642578

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0917287001189625e-27
Max value: 1.0
Mean value: 0.09038455784320831

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0917287001189625e-27
Max value: 1.0
Mean value: 0.09038455784320831

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0917287001189625e-27
Max value: 1.0
Mean value: 0.09038455784320831

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13631242513656616

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.997840881347656
Max value: 79.6866455078125
Mean value: 63.86017608642578

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.86125946044922
Max value: -63.86125946044922
Mean value: -63.86125946044922
sam_encoder.pos_embed grad: -6.943837433937006e-07
sam_encoder.blocks.0.norm1.weight grad: 0.008836023509502411
sam_encoder.blocks.0.norm1.bias grad: 0.011860954575240612
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0008447804721072316
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.418226985260844e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.001905844546854496
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.1422281861305237e-05
sam_encoder.blocks.0.norm2.weight grad: -0.004086419008672237
sam_encoder.blocks.0.norm2.bias grad: -0.0022855743300169706
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.005900616757571697
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0024046297185122967
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.008076528087258339
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0011116943787783384
sam_encoder.blocks.1.norm1.weight grad: 0.0018199542537331581
sam_encoder.blocks.1.norm1.bias grad: -0.0005469980533234775
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0032609356567263603
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.0008743520593270659
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0021046071778982878
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0011198502033948898
sam_encoder.blocks.1.norm2.weight grad: 0.0049379002302885056
sam_encoder.blocks.1.norm2.bias grad: 0.002622931031510234
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00042259832844138145
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00024227422545664012
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0001596242655068636
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0002259607135783881
sam_encoder.blocks.2.norm1.weight grad: 0.007614308502525091
sam_encoder.blocks.2.norm1.bias grad: -0.002144665690138936
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.004774739500135183
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0007471571443602443
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.000595049699768424
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.445753827691078e-05
sam_encoder.blocks.2.norm2.weight grad: -0.000681576319038868
sam_encoder.blocks.2.norm2.bias grad: -0.0024796889629215
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.699823956703767e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0005446876748465002
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006083223852328956
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0008361022919416428
sam_encoder.blocks.3.norm1.weight grad: -0.003954934421926737
sam_encoder.blocks.3.norm1.bias grad: -0.0013668397441506386
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.003563054371625185
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.000479568843729794
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0010045281378552318
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0005924459546804428
sam_encoder.blocks.3.norm2.weight grad: -0.00216388376429677
sam_encoder.blocks.3.norm2.bias grad: 0.0023306654766201973
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.001432720571756363
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00040120279300026596
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0008813737658783793
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0003810982161667198
sam_encoder.blocks.4.norm1.weight grad: 0.003842793172225356
sam_encoder.blocks.4.norm1.bias grad: 0.001215989119373262
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0025432677939534187
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00039351926534436643
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0016842628829181194
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.000627193134278059
sam_encoder.blocks.4.norm2.weight grad: -0.013258382678031921
sam_encoder.blocks.4.norm2.bias grad: -0.005632319953292608
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0077887531369924545
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.002741184551268816
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0008868462173268199
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00045558353303931653
sam_encoder.blocks.5.norm1.weight grad: -0.003095753025263548
sam_encoder.blocks.5.norm1.bias grad: -7.596239447593689e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0021233479492366314
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0016263768775388598
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0008445157436653972
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00014217015996109694
sam_encoder.blocks.5.norm2.weight grad: -0.008630640804767609
sam_encoder.blocks.5.norm2.bias grad: -0.0032768603414297104
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0038930154405534267
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0012833188520744443
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0002735569723881781
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.000297438440611586
sam_encoder.blocks.6.norm1.weight grad: 0.001101017463952303
sam_encoder.blocks.6.norm1.bias grad: 0.0014990824274718761
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0005812612362205982
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0002185051271226257
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0007450123666785657
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.0001179662358481437
sam_encoder.blocks.6.norm2.weight grad: -0.003485480323433876
sam_encoder.blocks.6.norm2.bias grad: -0.0006519173621200025
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0022034654393792152
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0007855892181396484
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00029276165878400207
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.3425319492816925e-06
sam_encoder.blocks.7.norm1.weight grad: 0.001157473772764206
sam_encoder.blocks.7.norm1.bias grad: 0.0003781089326366782
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007857953896746039
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0004950648872181773
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0006488519720733166
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0005039991810917854
sam_encoder.blocks.7.norm2.weight grad: 0.0005738476756960154
sam_encoder.blocks.7.norm2.bias grad: 0.0012441296130418777
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0006625335663557053
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.00011929687752854079
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00012382054410409182
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00027866396703757346
sam_encoder.blocks.8.norm1.weight grad: 0.0008233664557337761
sam_encoder.blocks.8.norm1.bias grad: -0.00032933655893430114
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0005769457202404737
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0005058762617409229
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.679209476104006e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00046888733049854636
sam_encoder.blocks.8.norm2.weight grad: -0.0012468883069232106
sam_encoder.blocks.8.norm2.bias grad: -0.0007122503593564034
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0006624142988584936
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0005521156126633286
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00013291678624227643
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00011106366582680494
sam_encoder.blocks.9.norm1.weight grad: -0.001807536231353879
sam_encoder.blocks.9.norm1.bias grad: 0.0002379864308750257
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.001379466149955988
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00031259702518582344
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0001955688203452155
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0007755637634545565
sam_encoder.blocks.9.norm2.weight grad: -0.00020501992548815906
sam_encoder.blocks.9.norm2.bias grad: -0.0008091097697615623
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0004249857156537473
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.123428415274248e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0007235289085656404
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.392369348555803e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0011626796331256628
sam_encoder.blocks.10.norm1.bias grad: 0.00016522291116416454
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0010094044264405966
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0004053243901580572
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0008281291811726987
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00045390293234959245
sam_encoder.blocks.10.norm2.weight grad: -0.001893079373985529
sam_encoder.blocks.10.norm2.bias grad: -0.0015419810079038143
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00038183858850970864
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0006318199448287487
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0003760753897950053
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00031311105703935027
sam_encoder.blocks.11.norm1.weight grad: -3.71495661966037e-05
sam_encoder.blocks.11.norm1.bias grad: 0.00045948682236485183
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00020230526570230722
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.122055932180956e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0006638087215833366
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.892664583167061e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0010444215731695294
sam_encoder.blocks.11.norm2.bias grad: -0.001456989673897624
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0008599270367994905
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0003766839799936861
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0003035356057807803
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0002873609773814678
sam_encoder.neck.conv1.trainable_scale grad: -0.0004126625135540962
sam_encoder.neck.conv1.trainable_shift grad: -0.010798733681440353
sam_encoder.neck.conv2.trainable_scale grad: -0.0005337479524314404
sam_encoder.neck.conv2.trainable_shift grad: 0.00751040643081069
mask_decoder.transformer.layers.0.norm1.weight grad: -0.12503086030483246
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0007115676999092102
mask_decoder.transformer.layers.0.norm2.weight grad: -1.91563880443573
mask_decoder.transformer.layers.0.norm2.bias grad: 0.3886280059814453
mask_decoder.transformer.layers.0.norm3.weight grad: -0.013487275689840317
mask_decoder.transformer.layers.0.norm3.bias grad: 0.006805328652262688
mask_decoder.transformer.layers.0.norm4.weight grad: 0.033702995628118515
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0017735220026224852
mask_decoder.transformer.layers.1.norm1.weight grad: 0.02237381786108017
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0006698668003082275
mask_decoder.transformer.layers.1.norm2.weight grad: 0.073483407497406
mask_decoder.transformer.layers.1.norm2.bias grad: 0.019016075879335403
mask_decoder.transformer.layers.1.norm3.weight grad: 0.040053416043519974
mask_decoder.transformer.layers.1.norm3.bias grad: 0.029483022168278694
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0010691555216908455
mask_decoder.transformer.layers.1.norm4.bias grad: -0.08202606439590454
mask_decoder.transformer.norm_final_attn.weight grad: 0.003568315412849188
mask_decoder.transformer.norm_final_attn.bias grad: 0.004624458029866219
Text_Embedding_Affine.0.weight grad: 3.516356761323891e-09
Text_Embedding_Affine.0.bias grad: 4.912726581096649e-08
Text_Embedding_Affine.2.weight grad: 4.880933879292115e-09
Text_Embedding_Affine.2.bias grad: 0.015362299978733063
Epoch 5 finished with average loss: -58.7561
Epoch 6/39
----------
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, loss=-52.3]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-52.3]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-55]  Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-55]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-56.3]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.30it/s, loss=-56.3]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08452515304088593

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08452515304088593

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08018112182617188

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1591612994670868

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06906938552856445

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08018112182617188

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.53444290161133
Max value: 75.01138305664062
Mean value: 52.33637237548828

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08452515304088593

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08452515304088593

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08452515304088593

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1591612994670868

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.53444290161133
Max value: 75.01138305664062
Mean value: 52.33637237548828

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.33740234375
Max value: -52.33740234375
Mean value: -52.33740234375
sam_encoder.pos_embed grad: 1.5539511650786153e-06
sam_encoder.blocks.0.norm1.weight grad: 0.021602895110845566
sam_encoder.blocks.0.norm1.bias grad: 0.0015762116527184844
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0012787343002855778
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.896040137391537e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0010262459982186556
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.000249737553531304
sam_encoder.blocks.0.norm2.weight grad: -0.0028153553139418364
sam_encoder.blocks.0.norm2.bias grad: -0.02792303077876568
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0006321898545138538
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00036014043143950403
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0014647826319560409
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0034823797177523375
sam_encoder.blocks.1.norm1.weight grad: 0.008812131360173225
sam_encoder.blocks.1.norm1.bias grad: -0.001477131969295442
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00040662099490873516
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00027665874222293496
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0016576079651713371
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0006713792681694031
sam_encoder.blocks.1.norm2.weight grad: -0.005229745991528034
sam_encoder.blocks.1.norm2.bias grad: 0.002597215585410595
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.005419949069619179
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0010274299420416355
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.006124742329120636
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0005815880140289664
sam_encoder.blocks.2.norm1.weight grad: -0.001759926788508892
sam_encoder.blocks.2.norm1.bias grad: -0.0009061374585144222
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0007992321625351906
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00031983142253011465
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0022172965109348297
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0014365303795784712
sam_encoder.blocks.2.norm2.weight grad: -0.005077451933175325
sam_encoder.blocks.2.norm2.bias grad: -0.001195276970975101
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.003256776137277484
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0008757999166846275
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.003792145987972617
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0010220271069556475
sam_encoder.blocks.3.norm1.weight grad: -0.0038827103562653065
sam_encoder.blocks.3.norm1.bias grad: 0.0016542552039027214
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.005779774393886328
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.001527249813079834
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0036088451743125916
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.002417684067040682
sam_encoder.blocks.3.norm2.weight grad: -0.006855141371488571
sam_encoder.blocks.3.norm2.bias grad: -0.0005736524472013116
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.005856595002114773
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.001583731733262539
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0011131366482004523
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00017448011203669012
sam_encoder.blocks.4.norm1.weight grad: -0.002163624856621027
sam_encoder.blocks.4.norm1.bias grad: -0.00038232578663155437
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0016124281100928783
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0005356614710763097
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0011247193906456232
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.002241985173895955
sam_encoder.blocks.4.norm2.weight grad: -0.00957300141453743
sam_encoder.blocks.4.norm2.bias grad: 0.003208389040082693
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.005496177822351456
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0012631984427571297
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0017389818094670773
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0006163962534628808
sam_encoder.blocks.5.norm1.weight grad: -0.009167971089482307
sam_encoder.blocks.5.norm1.bias grad: 0.0015842311549931765
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.004604794085025787
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0009288454311899841
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0029621634166687727
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0009340847609564662
sam_encoder.blocks.5.norm2.weight grad: -0.008255011402070522
sam_encoder.blocks.5.norm2.bias grad: 0.0006599519401788712
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.005423561669886112
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0018995311111211777
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.444612078368664e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.159283945336938e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0007936704205349088
sam_encoder.blocks.6.norm1.bias grad: -0.001954661449417472
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0010545956902205944
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.9608367438195273e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.40704165562056e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00043796811951324344
sam_encoder.blocks.6.norm2.weight grad: -0.0008427849388681352
sam_encoder.blocks.6.norm2.bias grad: 0.002478203270584345
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0005819215439260006
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00030385074205696583
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0006480489391833544
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0004513055318966508
sam_encoder.blocks.7.norm1.weight grad: -0.0031719168182462454
sam_encoder.blocks.7.norm1.bias grad: -0.00011516271479194984
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.002501944312825799
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0008859012159518898
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0011405160184949636
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.001710702432319522
sam_encoder.blocks.7.norm2.weight grad: -0.002160429023206234
sam_encoder.blocks.7.norm2.bias grad: 0.0008916581864468753
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.001301652635447681
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0008817575871944427
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0575342457741499e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00030199249158613384
sam_encoder.blocks.8.norm1.weight grad: -0.0014077223604544997
sam_encoder.blocks.8.norm1.bias grad: 0.0008482880657538772
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0020987808238714933
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0005400270456448197
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.002726346254348755
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.002009876538068056
sam_encoder.blocks.8.norm2.weight grad: -0.0031492612324655056
sam_encoder.blocks.8.norm2.bias grad: -0.0009518663282506168
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0026306293439120054
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.002012841636314988
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00035142479464411736
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.568550477619283e-05
sam_encoder.blocks.9.norm1.weight grad: -0.002076315926387906
sam_encoder.blocks.9.norm1.bias grad: 0.00010714474774431437
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0018804374849423766
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0006359675899147987
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0005714123253710568
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0005889725289307535
sam_encoder.blocks.9.norm2.weight grad: -0.0027968480717390776
sam_encoder.blocks.9.norm2.bias grad: -0.0009657543851062655
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.001685924595221877
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0011778170010074973
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0007700023707002401
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00029857910703867674
sam_encoder.blocks.10.norm1.weight grad: 0.0002074529038509354
sam_encoder.blocks.10.norm1.bias grad: 2.863378540496342e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00010944760288111866
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00011752855789382011
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00014560052659362555
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00018521884339861572
sam_encoder.blocks.10.norm2.weight grad: -0.005691441707313061
sam_encoder.blocks.10.norm2.bias grad: -0.0016042556380853057
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00230007735081017
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0016038701869547367
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00044487707782536745
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00016233032511081547
sam_encoder.blocks.11.norm1.weight grad: -0.013870022259652615
sam_encoder.blocks.11.norm1.bias grad: 0.0008196972194127738
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.002180060837417841
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00027317891363054514
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.000651684938929975
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.0004181927943136543
sam_encoder.blocks.11.norm2.weight grad: -0.00388084864243865
sam_encoder.blocks.11.norm2.bias grad: -0.0015129446983337402
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0011136268731206656
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0008816925110295415
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.310455061495304e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00021853117505088449
sam_encoder.neck.conv1.trainable_scale grad: -0.00032117171213030815
sam_encoder.neck.conv1.trainable_shift grad: -0.004079895094037056
sam_encoder.neck.conv2.trainable_scale grad: -0.0003253929316997528
sam_encoder.neck.conv2.trainable_shift grad: -0.03301582857966423
mask_decoder.transformer.layers.0.norm1.weight grad: -0.11050882190465927
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0003848075866699219
mask_decoder.transformer.layers.0.norm2.weight grad: -0.6129505634307861
mask_decoder.transformer.layers.0.norm2.bias grad: 0.8506407737731934
mask_decoder.transformer.layers.0.norm3.weight grad: 0.014423839747905731
mask_decoder.transformer.layers.0.norm3.bias grad: 0.02344326674938202
mask_decoder.transformer.layers.0.norm4.weight grad: 0.019583769142627716
mask_decoder.transformer.layers.0.norm4.bias grad: 0.003534367773681879
mask_decoder.transformer.layers.1.norm1.weight grad: 0.009757570922374725
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0038013658486306667
mask_decoder.transformer.layers.1.norm2.weight grad: 0.1559620499610901
mask_decoder.transformer.layers.1.norm2.bias grad: 0.04457433149218559
mask_decoder.transformer.layers.1.norm3.weight grad: 0.022479642182588577
mask_decoder.transformer.layers.1.norm3.bias grad: 0.021540645509958267
mask_decoder.transformer.layers.1.norm4.weight grad: 0.01216680184006691
mask_decoder.transformer.layers.1.norm4.bias grad: -0.024839146062731743
mask_decoder.transformer.norm_final_attn.weight grad: 0.002551040379330516
mask_decoder.transformer.norm_final_attn.bias grad: 0.0006705560954287648
Text_Embedding_Affine.0.weight grad: -2.7453528339549393e-09
Text_Embedding_Affine.0.bias grad: -1.1920928955078125e-07
Text_Embedding_Affine.2.weight grad: -4.579182366626355e-09
Text_Embedding_Affine.2.bias grad: 0.021901775151491165

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.189854724088876e-15
Max value: 0.9999963045120239
Mean value: 0.08332638442516327

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.189854724088876e-15
Max value: 0.9999963045120239
Mean value: 0.08332638442516327

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09090137481689453

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1489867866039276

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07347297668457031

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09090137481689453

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.57902526855469
Max value: 77.56243896484375
Mean value: 57.73848342895508

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.189854724088876e-15
Max value: 0.9999963045120239
Mean value: 0.08332638442516327

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.189854724088876e-15
Max value: 0.9999963045120239
Mean value: 0.08332638442516327

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.189854724088876e-15
Max value: 0.9999963045120239
Mean value: 0.08332638442516327

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1489867866039276

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.57902526855469
Max value: 77.56243896484375
Mean value: 57.73848342895508

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.7393684387207
Max value: -57.7393684387207
Mean value: -57.7393684387207
sam_encoder.pos_embed grad: -1.7755651242623571e-06
sam_encoder.blocks.0.norm1.weight grad: -0.001514016417786479
sam_encoder.blocks.0.norm1.bias grad: 0.011948155239224434
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0018802512204274535
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.688334668870084e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0024871479254215956
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0007630196632817388
sam_encoder.blocks.0.norm2.weight grad: 0.011168005876243114
sam_encoder.blocks.0.norm2.bias grad: -0.012832063250243664
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0023812863510102034
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003510446986183524
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.003325418336316943
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0003387384058441967
sam_encoder.blocks.1.norm1.weight grad: 0.0037170383147895336
sam_encoder.blocks.1.norm1.bias grad: -0.0005165934562683105
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0016986568225547671
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.00010484641825314611
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.000830375007353723
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0005801299121230841
sam_encoder.blocks.1.norm2.weight grad: -0.0021425841841846704
sam_encoder.blocks.1.norm2.bias grad: 0.004357785917818546
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.002068170579150319
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0007922625518403947
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.001656720181927085
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00023253983817994595
sam_encoder.blocks.2.norm1.weight grad: -0.0005972008220851421
sam_encoder.blocks.2.norm1.bias grad: 0.0004246433963999152
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00014410106814466417
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0003706229035742581
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00041679953574202955
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00057933758944273
sam_encoder.blocks.2.norm2.weight grad: -0.00036796805215999484
sam_encoder.blocks.2.norm2.bias grad: -0.003493980038911104
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00027504641911946237
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00042636715807020664
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0009980349568650126
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00023795754532329738
sam_encoder.blocks.3.norm1.weight grad: -0.002128130290657282
sam_encoder.blocks.3.norm1.bias grad: -0.0002977093681693077
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0027058832347393036
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0005154928658157587
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0009543942287564278
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0008637186838313937
sam_encoder.blocks.3.norm2.weight grad: 1.4338758774101734e-05
sam_encoder.blocks.3.norm2.bias grad: 0.0018157069571316242
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0002862203400582075
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00012935725681018084
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0013050346169620752
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00021857614046894014
sam_encoder.blocks.4.norm1.weight grad: 0.0018230888526886702
sam_encoder.blocks.4.norm1.bias grad: 0.0005017839139327407
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005727473180741072
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00021174833818804473
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00017296892474405468
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002332485601073131
sam_encoder.blocks.4.norm2.weight grad: -0.008797639980912209
sam_encoder.blocks.4.norm2.bias grad: -0.004180064890533686
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0058516571298241615
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.002069811336696148
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0009796519298106432
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00047849593102000654
sam_encoder.blocks.5.norm1.weight grad: -0.000891337578650564
sam_encoder.blocks.5.norm1.bias grad: 0.0007189086172729731
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00030916137620806694
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.001153899123892188
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0011278055608272552
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0009320786921307445
sam_encoder.blocks.5.norm2.weight grad: -0.005908194929361343
sam_encoder.blocks.5.norm2.bias grad: -0.003757946193218231
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0038281481247395277
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.001438767067156732
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00022477281163446605
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.047164348885417e-05
sam_encoder.blocks.6.norm1.weight grad: 0.001765887951478362
sam_encoder.blocks.6.norm1.bias grad: 0.0006287132855504751
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0011314155999571085
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0002826275012921542
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0005093459039926529
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.914103631861508e-05
sam_encoder.blocks.6.norm2.weight grad: -0.001956457272171974
sam_encoder.blocks.6.norm2.bias grad: -0.0005512646166607738
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0016662676353007555
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0006968255620449781
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0008262862684205174
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00020740389300044626
sam_encoder.blocks.7.norm1.weight grad: 0.002785836346447468
sam_encoder.blocks.7.norm1.bias grad: 0.00029354426078498363
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.001978814834728837
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0008664365159347653
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0008507401216775179
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00020685151685029268
sam_encoder.blocks.7.norm2.weight grad: -0.0012121007312089205
sam_encoder.blocks.7.norm2.bias grad: 0.001119927503168583
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.001218387740664184
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0007240679115056992
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00024397885135840625
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00019852063269354403
sam_encoder.blocks.8.norm1.weight grad: 0.003744663204997778
sam_encoder.blocks.8.norm1.bias grad: 0.00011184340110048652
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.002688133157789707
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0008153448579832911
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.000564323621802032
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.837828499963507e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0010412493720650673
sam_encoder.blocks.8.norm2.bias grad: -0.0006490568048320711
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0006241864757612348
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00043365274905227125
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.0824925741180778e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00022033104323782027
sam_encoder.blocks.9.norm1.weight grad: 0.00016370831872336566
sam_encoder.blocks.9.norm1.bias grad: 9.342654084321111e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0001188670503324829
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.612796616740525e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.0430208425968885e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00017807446420192719
sam_encoder.blocks.9.norm2.weight grad: 0.0008574711391702294
sam_encoder.blocks.9.norm2.bias grad: -0.00041686807526275516
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.001014858833514154
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0003271395689807832
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0007967784767970443
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00015080726006999612
sam_encoder.blocks.10.norm1.weight grad: 0.0016215512296184897
sam_encoder.blocks.10.norm1.bias grad: 0.00022307367180474102
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0009779285173863173
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00041354523273184896
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0004938782658427954
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0002625343040563166
sam_encoder.blocks.10.norm2.weight grad: 0.0006929587107151747
sam_encoder.blocks.10.norm2.bias grad: -0.0007348114158958197
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0006667914567515254
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.927063077455387e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00018296913185622543
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.985049129871186e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0007790785166434944
sam_encoder.blocks.11.norm1.bias grad: 0.0007660436676815152
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00016848716768436134
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00010037064203061163
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0005072689382359385
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.3404055506689474e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0015915324911475182
sam_encoder.blocks.11.norm2.bias grad: -0.0007793797412887216
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0013144881231710315
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00011352967703714967
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00010428721725475043
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.515793625614606e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.00023558177053928375
sam_encoder.neck.conv1.trainable_shift grad: -0.0036291275173425674
sam_encoder.neck.conv2.trainable_scale grad: -0.00031669624149799347
sam_encoder.neck.conv2.trainable_shift grad: -0.0016608182340860367
mask_decoder.transformer.layers.0.norm1.weight grad: -0.04845556989312172
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00022505037486553192
mask_decoder.transformer.layers.0.norm2.weight grad: -1.572270154953003
mask_decoder.transformer.layers.0.norm2.bias grad: 0.14418429136276245
mask_decoder.transformer.layers.0.norm3.weight grad: -0.002433713059872389
mask_decoder.transformer.layers.0.norm3.bias grad: 0.010612236335873604
mask_decoder.transformer.layers.0.norm4.weight grad: 0.018374424427747726
mask_decoder.transformer.layers.0.norm4.bias grad: -0.00059649592731148
mask_decoder.transformer.layers.1.norm1.weight grad: 0.01106717623770237
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0004741889424622059
mask_decoder.transformer.layers.1.norm2.weight grad: 0.030179958790540695
mask_decoder.transformer.layers.1.norm2.bias grad: 0.011936282739043236
mask_decoder.transformer.layers.1.norm3.weight grad: 0.01903025433421135
mask_decoder.transformer.layers.1.norm3.bias grad: 0.013572869822382927
mask_decoder.transformer.layers.1.norm4.weight grad: -0.007624100893735886
mask_decoder.transformer.layers.1.norm4.bias grad: -0.04783548787236214
mask_decoder.transformer.norm_final_attn.weight grad: 0.0019059752812609076
mask_decoder.transformer.norm_final_attn.bias grad: 0.0025293880607932806
Text_Embedding_Affine.0.weight grad: 4.8209414238442605e-09
Text_Embedding_Affine.0.bias grad: 6.356276571750641e-08
Text_Embedding_Affine.2.weight grad: 5.771844335811238e-09
Text_Embedding_Affine.2.bias grad: 0.009437205269932747

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.0781014851324394e-18
Max value: 0.9999812841415405
Mean value: 0.08222777396440506

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.0781014851324394e-18
Max value: 0.9999812841415405
Mean value: 0.08222777396440506

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798385620117188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13396483659744263

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07422447204589844

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07798385620117188

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 53.07742691040039
Max value: 67.31502532958984
Mean value: 58.88322067260742

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.0781014851324394e-18
Max value: 0.9999812841415405
Mean value: 0.08222777396440506

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.0781014851324394e-18
Max value: 0.9999812841415405
Mean value: 0.08222777396440506

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.0781014851324394e-18
Max value: 0.9999812841415405
Mean value: 0.08222777396440506

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13396483659744263

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 53.07742691040039
Max value: 67.31502532958984
Mean value: 58.88322067260742

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.884239196777344
Max value: -58.884239196777344
Mean value: -58.884239196777344
sam_encoder.pos_embed grad: 1.760076884238515e-08
sam_encoder.blocks.0.norm1.weight grad: 0.016648588702082634
sam_encoder.blocks.0.norm1.bias grad: 0.007327195256948471
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0011197228450328112
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00011843543325085193
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.001076076994650066
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.207378227263689e-05
sam_encoder.blocks.0.norm2.weight grad: -0.005002072546631098
sam_encoder.blocks.0.norm2.bias grad: 0.0010930964490398765
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0029146033339202404
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0011227999348193407
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.002900257706642151
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00024505480541847646
sam_encoder.blocks.1.norm1.weight grad: 0.0031454830896109343
sam_encoder.blocks.1.norm1.bias grad: -0.0009099027374759316
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0015406524762511253
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.00040706744766794145
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0005305965314619243
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.000454617606010288
sam_encoder.blocks.1.norm2.weight grad: 0.004427064210176468
sam_encoder.blocks.1.norm2.bias grad: 0.00046854137326590717
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0005691084079444408
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0003016393166035414
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0017847036942839622
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00014055015344638377
sam_encoder.blocks.2.norm1.weight grad: 0.0036892592906951904
sam_encoder.blocks.2.norm1.bias grad: -0.0008378111524507403
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0022536995820701122
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00047079380601644516
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0004154428606852889
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0001768746878951788
sam_encoder.blocks.2.norm2.weight grad: 0.0017803148366510868
sam_encoder.blocks.2.norm2.bias grad: -0.0009781522676348686
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0010615182109177113
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001548693689983338
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0007946540135890245
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00031298783142119646
sam_encoder.blocks.3.norm1.weight grad: -0.0012742290273308754
sam_encoder.blocks.3.norm1.bias grad: -0.0009189131669700146
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0022197433281689882
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.000351735798176378
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0009551988332532346
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00039861054392531514
sam_encoder.blocks.3.norm2.weight grad: 0.0011808391427621245
sam_encoder.blocks.3.norm2.bias grad: -0.0016458252212032676
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0011607951018959284
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0006006198818795383
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0011874655028805137
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.087963300960837e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0010528353741392493
sam_encoder.blocks.4.norm1.bias grad: 0.0007646047743037343
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0009444238967262208
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002599339932203293
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0006201806245371699
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.847006261523347e-06
sam_encoder.blocks.4.norm2.weight grad: -0.009777428582310677
sam_encoder.blocks.4.norm2.bias grad: -0.004188773222267628
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.005565098486840725
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0020812605507671833
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.001499688602052629
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0007458326872438192
sam_encoder.blocks.5.norm1.weight grad: -0.003797684796154499
sam_encoder.blocks.5.norm1.bias grad: 7.492824079236016e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0037517333403229713
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0014905849238857627
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0007187024457380176
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0001745564950397238
sam_encoder.blocks.5.norm2.weight grad: -0.0045272791758179665
sam_encoder.blocks.5.norm2.bias grad: -0.002235674997791648
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0016287078615278006
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.000607034657150507
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00012551870895549655
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00015951719251461327
sam_encoder.blocks.6.norm1.weight grad: 0.0009770483011379838
sam_encoder.blocks.6.norm1.bias grad: 0.00048333857557736337
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00020719417079817504
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00018156411533709615
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0003346397425048053
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.357220551464707e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0006598641630262136
sam_encoder.blocks.6.norm2.bias grad: -0.00026620595599524677
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.612904300913215e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.557100565871224e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0004012642311863601
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.311816782224923e-05
sam_encoder.blocks.7.norm1.weight grad: -0.00035036721965298057
sam_encoder.blocks.7.norm1.bias grad: -0.00014120686682872474
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00031598054920323193
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0001477944024372846
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.1063660824438557e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0004602827539201826
sam_encoder.blocks.7.norm2.weight grad: 0.0006840724381618202
sam_encoder.blocks.7.norm2.bias grad: 0.00013785201008431613
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0009702045936137438
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.000286098918877542
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.0002793934545479715
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.450054934248328e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0010192394256591797
sam_encoder.blocks.8.norm1.bias grad: -0.00032358162570744753
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.002004839014261961
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0009929469088092446
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0007138707442209125
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0002832080936059356
sam_encoder.blocks.8.norm2.weight grad: -7.651197665836662e-05
sam_encoder.blocks.8.norm2.bias grad: -0.0006197365000844002
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0002140926371794194
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00015403752331621945
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.929115625098348e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.523490057792515e-05
sam_encoder.blocks.9.norm1.weight grad: -0.002766802441328764
sam_encoder.blocks.9.norm1.bias grad: 0.00018221125355921686
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0021004120353609324
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0005594526301138103
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00039663384086452425
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.000588507391512394
sam_encoder.blocks.9.norm2.weight grad: -0.0003473298856988549
sam_encoder.blocks.9.norm2.bias grad: -0.0007230790797621012
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0003487376670818776
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.7526064766570926e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0004066135734319687
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0001048163539962843
sam_encoder.blocks.10.norm1.weight grad: -0.00038871332071721554
sam_encoder.blocks.10.norm1.bias grad: 0.00038556428626179695
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.9481711206026375e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.939570110058412e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0004073922464158386
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0003125369257759303
sam_encoder.blocks.10.norm2.weight grad: -0.002281834604218602
sam_encoder.blocks.10.norm2.bias grad: -0.0011563273146748543
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.000732665357645601
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0006132986163720489
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0005684811621904373
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0002658321463968605
sam_encoder.blocks.11.norm1.weight grad: -0.004051876254379749
sam_encoder.blocks.11.norm1.bias grad: 0.0004170421452727169
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0019402186153456569
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0004170952597633004
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.139794312621234e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00010580696107354015
sam_encoder.blocks.11.norm2.weight grad: -0.002130222273990512
sam_encoder.blocks.11.norm2.bias grad: -0.0009069071966223419
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00010690737690310925
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0003730494063347578
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0002317011822015047
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00030195628642104566
sam_encoder.neck.conv1.trainable_scale grad: -0.0007300376892089844
sam_encoder.neck.conv1.trainable_shift grad: -0.0015175300650298595
sam_encoder.neck.conv2.trainable_scale grad: -0.000748329795897007
sam_encoder.neck.conv2.trainable_shift grad: 0.005685337353497744
mask_decoder.transformer.layers.0.norm1.weight grad: -0.1247309073805809
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0024038292467594147
mask_decoder.transformer.layers.0.norm2.weight grad: -1.3160533905029297
mask_decoder.transformer.layers.0.norm2.bias grad: 0.6532529592514038
mask_decoder.transformer.layers.0.norm3.weight grad: -0.018782634288072586
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0034147296100854874
mask_decoder.transformer.layers.0.norm4.weight grad: 0.030792271718382835
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0017370402347296476
mask_decoder.transformer.layers.1.norm1.weight grad: 0.008990778587758541
mask_decoder.transformer.layers.1.norm1.bias grad: -6.356602534651756e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.03816365823149681
mask_decoder.transformer.layers.1.norm2.bias grad: 0.005970407277345657
mask_decoder.transformer.layers.1.norm3.weight grad: 0.020871436223387718
mask_decoder.transformer.layers.1.norm3.bias grad: 0.010392907075583935
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0067859492264688015
mask_decoder.transformer.layers.1.norm4.bias grad: -0.06383700668811798
mask_decoder.transformer.norm_final_attn.weight grad: 0.001679099164903164
mask_decoder.transformer.norm_final_attn.bias grad: 0.003400614717975259
Text_Embedding_Affine.0.weight grad: 2.5349406129748786e-08
Text_Embedding_Affine.0.bias grad: 7.895287126302719e-07
Text_Embedding_Affine.2.weight grad: 9.055399630142347e-08
Text_Embedding_Affine.2.bias grad: 0.03607993572950363
Epoch 6 finished with average loss: -56.3203
Epoch 7/39
----------
Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, loss=-53.6]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-53.6]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-50.6]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-50.6]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-43.7]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-43.7]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.537132200980884e-15
Max value: 0.9999964237213135
Mean value: 0.13105599582195282

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.537132200980884e-15
Max value: 0.9999964237213135
Mean value: 0.13105599582195282

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0940999984741211

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18054865300655365

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08749866485595703

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0940999984741211

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.75430679321289
Max value: 80.89202880859375
Mean value: 53.641334533691406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.537132200980884e-15
Max value: 0.9999964237213135
Mean value: 0.13105599582195282

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.537132200980884e-15
Max value: 0.9999964237213135
Mean value: 0.13105599582195282

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.537132200980884e-15
Max value: 0.9999964237213135
Mean value: 0.13105599582195282

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18054865300655365

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.75430679321289
Max value: 80.89202880859375
Mean value: 53.641334533691406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.643402099609375
Max value: -53.643402099609375
Mean value: -53.643402099609375
sam_encoder.pos_embed grad: 9.625958909964538e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0038347772788256407
sam_encoder.blocks.0.norm1.bias grad: -0.015788231045007706
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.002112486632540822
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.414413004065864e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0015985163627192378
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.250581645872444e-05
sam_encoder.blocks.0.norm2.weight grad: 0.006266005337238312
sam_encoder.blocks.0.norm2.bias grad: -0.01963028311729431
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0029698405414819717
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00020381684589665383
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0018289482686668634
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.001498290104791522
sam_encoder.blocks.1.norm1.weight grad: 0.004444071091711521
sam_encoder.blocks.1.norm1.bias grad: -0.0024186251685023308
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.37176519073546e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00015330062888097018
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0004803440533578396
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0003277546202298254
sam_encoder.blocks.1.norm2.weight grad: -0.0009754844941198826
sam_encoder.blocks.1.norm2.bias grad: 0.002963509876281023
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.003304973943158984
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0005582307931035757
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0033482143189758062
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00021160126198083162
sam_encoder.blocks.2.norm1.weight grad: -0.0016953099984675646
sam_encoder.blocks.2.norm1.bias grad: -0.000508200260810554
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.625821020454168e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00022555507894139737
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.001164883840829134
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0008632743265479803
sam_encoder.blocks.2.norm2.weight grad: -0.0022748128976672888
sam_encoder.blocks.2.norm2.bias grad: -1.9090639398200437e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.001377852982841432
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00020002841483801603
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0026012910529971123
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0007011195993982255
sam_encoder.blocks.3.norm1.weight grad: -0.003588116727769375
sam_encoder.blocks.3.norm1.bias grad: -0.00034742074785754085
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.004121195524930954
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0011458322405815125
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0018145315116271377
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.001940257614478469
sam_encoder.blocks.3.norm2.weight grad: -0.0015832583885639906
sam_encoder.blocks.3.norm2.bias grad: 0.0025939014740288258
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0016959392232820392
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.283546099439263e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0004566566494759172
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.505478813778609e-05
sam_encoder.blocks.4.norm1.weight grad: 0.002479913178831339
sam_encoder.blocks.4.norm1.bias grad: -0.0010414300486445427
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0015233117155730724
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0006083379848860204
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.295127488760045e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0006679575308226049
sam_encoder.blocks.4.norm2.weight grad: -0.005643021315336227
sam_encoder.blocks.4.norm2.bias grad: 0.0034313981886953115
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0037373534869402647
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0009343877318315208
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0006442299927584827
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.9976875490974635e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0022921760100871325
sam_encoder.blocks.5.norm1.bias grad: 0.00027532497188076377
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00037166132824495435
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0002884495770558715
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0012672865996137261
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00014381424989551306
sam_encoder.blocks.5.norm2.weight grad: -0.0052769421599805355
sam_encoder.blocks.5.norm2.bias grad: 0.0005113267106935382
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.003706126008182764
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.001268186024390161
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0001068932906491682
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00016260170377790928
sam_encoder.blocks.6.norm1.weight grad: 0.0005962966242805123
sam_encoder.blocks.6.norm1.bias grad: -0.0013205631403252482
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0007765367045067251
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003987538511864841
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.065036672633141e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00012856557441409677
sam_encoder.blocks.6.norm2.weight grad: -0.0013483809307217598
sam_encoder.blocks.6.norm2.bias grad: 0.0014339168556034565
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.001042516902089119
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0002782731899060309
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00026893281028606
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0004807771183550358
sam_encoder.blocks.7.norm1.weight grad: -0.0011195405386388302
sam_encoder.blocks.7.norm1.bias grad: -0.000276643258985132
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0013777771964669228
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0005670200916938484
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0006430467474274337
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0009984690696001053
sam_encoder.blocks.7.norm2.weight grad: -0.0020080634858459234
sam_encoder.blocks.7.norm2.bias grad: 0.0012456073891371489
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0014327799435704947
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0006447885534726083
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00034853024408221245
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0005252023111097515
sam_encoder.blocks.8.norm1.weight grad: -0.00021280725195538253
sam_encoder.blocks.8.norm1.bias grad: 7.534155156463385e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00030307701672427356
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.289475615834817e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.001063276082277298
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0009542605257593095
sam_encoder.blocks.8.norm2.weight grad: -0.0030388357117772102
sam_encoder.blocks.8.norm2.bias grad: -0.0005878531374037266
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.002516708802431822
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.001562856137752533
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00043026491766795516
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0596588253974915e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0006819061236456037
sam_encoder.blocks.9.norm1.bias grad: -0.00015824685397092253
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0005605965270660818
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0003620226343628019
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00021013265359215438
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.424523598980159e-05
sam_encoder.blocks.9.norm2.weight grad: -0.002628576708957553
sam_encoder.blocks.9.norm2.bias grad: -0.0006590040866285563
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.001692193909548223
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0010609091259539127
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00019810434605460614
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0001395902072545141
sam_encoder.blocks.10.norm1.weight grad: 0.00017527499585412443
sam_encoder.blocks.10.norm1.bias grad: -0.0001398394670104608
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.091713319416158e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.4451483366428874e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.899789125076495e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.465325663564727e-05
sam_encoder.blocks.10.norm2.weight grad: -0.004137849900871515
sam_encoder.blocks.10.norm2.bias grad: -0.0008756923489272594
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0016976867336779833
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.001101556234061718
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00025532772997394204
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.0001189727772725746
sam_encoder.blocks.11.norm1.weight grad: -0.00802228506654501
sam_encoder.blocks.11.norm1.bias grad: -7.505703251808882e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0008572032675147057
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00014583245501853526
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0003719319065567106
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00011897389777004719
sam_encoder.blocks.11.norm2.weight grad: -0.003351951017975807
sam_encoder.blocks.11.norm2.bias grad: -0.0011026299325749278
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0010656833183020353
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0005915253423154354
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0002741507487371564
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0002240912290289998
sam_encoder.neck.conv1.trainable_scale grad: -0.0001808644738048315
sam_encoder.neck.conv1.trainable_shift grad: -0.004963972605764866
sam_encoder.neck.conv2.trainable_scale grad: -0.00017281156033277512
sam_encoder.neck.conv2.trainable_shift grad: -0.01679546758532524
mask_decoder.transformer.layers.0.norm1.weight grad: -0.05475078895688057
mask_decoder.transformer.layers.0.norm1.bias grad: 9.509176015853882e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.19081325829029083
mask_decoder.transformer.layers.0.norm2.bias grad: 0.4013155698776245
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0011024028062820435
mask_decoder.transformer.layers.0.norm3.bias grad: 0.015443914569914341
mask_decoder.transformer.layers.0.norm4.weight grad: 0.007581161800771952
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0024922494776546955
mask_decoder.transformer.layers.1.norm1.weight grad: 0.00562458299100399
mask_decoder.transformer.layers.1.norm1.bias grad: -0.001424278598278761
mask_decoder.transformer.layers.1.norm2.weight grad: 0.07573029398918152
mask_decoder.transformer.layers.1.norm2.bias grad: 0.025624491274356842
mask_decoder.transformer.layers.1.norm3.weight grad: 0.016520127654075623
mask_decoder.transformer.layers.1.norm3.bias grad: 0.013865155167877674
mask_decoder.transformer.layers.1.norm4.weight grad: 0.007239129859954119
mask_decoder.transformer.layers.1.norm4.bias grad: -0.008466447703540325
mask_decoder.transformer.norm_final_attn.weight grad: 0.0013527238043025136
mask_decoder.transformer.norm_final_attn.bias grad: -1.8001446733251214e-05
Text_Embedding_Affine.0.weight grad: -1.0278064621616068e-08
Text_Embedding_Affine.0.bias grad: -4.906905815005302e-07
Text_Embedding_Affine.2.weight grad: 4.173362810888648e-08
Text_Embedding_Affine.2.bias grad: 0.007346869446337223

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6750383170391802e-20
Max value: 0.9999998807907104
Mean value: 0.07857044786214828

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6750383170391802e-20
Max value: 0.9999998807907104
Mean value: 0.07857044786214828

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07928752899169922

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14164474606513977

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.059986114501953125

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07928752899169922

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 7.965689182281494
Max value: 72.1842041015625
Mean value: 47.56358337402344

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6750383170391802e-20
Max value: 0.9999998807907104
Mean value: 0.07857044786214828

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6750383170391802e-20
Max value: 0.9999998807907104
Mean value: 0.07857044786214828

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6750383170391802e-20
Max value: 0.9999998807907104
Mean value: 0.07857044786214828

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14164474606513977

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 7.965689182281494
Max value: 72.1842041015625
Mean value: 47.56358337402344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -47.56479263305664
Max value: -47.56479263305664
Mean value: -47.56479263305664
sam_encoder.pos_embed grad: 2.4338885395991383e-06
sam_encoder.blocks.0.norm1.weight grad: -0.018284833058714867
sam_encoder.blocks.0.norm1.bias grad: -0.005437142215669155
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0027719177305698395
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00025850822567008436
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.004313256591558456
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.002331885974854231
sam_encoder.blocks.0.norm2.weight grad: 0.009013709612190723
sam_encoder.blocks.0.norm2.bias grad: -0.012225760146975517
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.00027217407478019595
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0012435574317350984
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.003411463927477598
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00017763988580554724
sam_encoder.blocks.1.norm1.weight grad: -0.007789058145135641
sam_encoder.blocks.1.norm1.bias grad: -0.007229282986372709
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.001014453126117587
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0005831099115312099
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.77573326457059e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00034342322032898664
sam_encoder.blocks.1.norm2.weight grad: -0.008074698969721794
sam_encoder.blocks.1.norm2.bias grad: 0.0006686747074127197
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0027942839078605175
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0005741204950027168
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.004019337706267834
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0012440073769539595
sam_encoder.blocks.2.norm1.weight grad: 0.005164552479982376
sam_encoder.blocks.2.norm1.bias grad: 0.0007676533423364162
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.003057952970266342
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00029287231154739857
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003863036399707198
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0004377736186143011
sam_encoder.blocks.2.norm2.weight grad: -4.695185270975344e-05
sam_encoder.blocks.2.norm2.bias grad: -0.0026408578269183636
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.720218566944823e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0006492923712357879
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.003684533527120948
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0008587638731114566
sam_encoder.blocks.3.norm1.weight grad: -0.0069594597443938255
sam_encoder.blocks.3.norm1.bias grad: 0.0025527793914079666
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.007652835454791784
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.002195038367062807
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.003328061429783702
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0026888693682849407
sam_encoder.blocks.3.norm2.weight grad: -0.0027192761190235615
sam_encoder.blocks.3.norm2.bias grad: -0.005301833152770996
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0030690948478877544
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0010900142369791865
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0011030460009351373
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00017180257418658584
sam_encoder.blocks.4.norm1.weight grad: 0.005539402365684509
sam_encoder.blocks.4.norm1.bias grad: 0.0006761720287613571
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0029178746044635773
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0006760698743164539
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0005879548261873424
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003163604997098446
sam_encoder.blocks.4.norm2.weight grad: -0.00980347953736782
sam_encoder.blocks.4.norm2.bias grad: -0.004717512056231499
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.005880225449800491
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0017782107461243868
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0012706276029348373
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00030306505504995584
sam_encoder.blocks.5.norm1.weight grad: 0.005100798327475786
sam_encoder.blocks.5.norm1.bias grad: -0.0015866095200181007
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.005591297056525946
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0012225992977619171
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.001086605479940772
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0014505097642540932
sam_encoder.blocks.5.norm2.weight grad: -0.00690549798309803
sam_encoder.blocks.5.norm2.bias grad: -0.002821357687935233
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.003669481724500656
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.001296419301070273
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0003729555173777044
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00033100921427831054
sam_encoder.blocks.6.norm1.weight grad: -0.0008988549816422164
sam_encoder.blocks.6.norm1.bias grad: -6.544699135702103e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0009545098291710019
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00037645892007276416
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0008789051207713783
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0012850535567849874
sam_encoder.blocks.6.norm2.weight grad: -0.005675359629094601
sam_encoder.blocks.6.norm2.bias grad: -0.00019317927944939584
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0036037645768374205
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.001352018560282886
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0004240883863531053
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0003685803967528045
sam_encoder.blocks.7.norm1.weight grad: 0.00046556396409869194
sam_encoder.blocks.7.norm1.bias grad: -0.0003853550588246435
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00011230337986489758
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0005336319445632398
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00035653170198202133
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0006753277266398072
sam_encoder.blocks.7.norm2.weight grad: -0.003226451575756073
sam_encoder.blocks.7.norm2.bias grad: 0.00017128221224993467
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0016560070216655731
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.001071285572834313
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.831740625377279e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0002490819897502661
sam_encoder.blocks.8.norm1.weight grad: 0.0032896604388952255
sam_encoder.blocks.8.norm1.bias grad: -0.0006498103030025959
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.002851627767086029
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0014151454670354724
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.001517346827313304
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0013538709608837962
sam_encoder.blocks.8.norm2.weight grad: -0.003764547174796462
sam_encoder.blocks.8.norm2.bias grad: -2.7255096938461065e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.003434787504374981
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0018449353519827127
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00042792496969923377
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.889397188089788e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0009793094359338284
sam_encoder.blocks.9.norm1.bias grad: -0.0006197550101205707
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0008931406773626804
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0007605516584590077
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0002703724894672632
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00033222546335309744
sam_encoder.blocks.9.norm2.weight grad: -0.0032702586613595486
sam_encoder.blocks.9.norm2.bias grad: -6.863744783913717e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0031350196804851294
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0012163175269961357
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00047977568465285003
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0002828832948580384
sam_encoder.blocks.10.norm1.weight grad: 0.00031850062077865005
sam_encoder.blocks.10.norm1.bias grad: -0.0005135327810421586
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.522108843550086e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0001004360310616903
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00029679524595849216
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0001984936825465411
sam_encoder.blocks.10.norm2.weight grad: -0.005923599936068058
sam_encoder.blocks.10.norm2.bias grad: -0.0013224234571680427
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.002957916585728526
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0014812087174504995
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00032645961618982255
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.00013549861614592373
sam_encoder.blocks.11.norm1.weight grad: -0.006651879753917456
sam_encoder.blocks.11.norm1.bias grad: 0.0008617033017799258
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0007528888527303934
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00028803356690332294
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.126344619086012e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00011803470260929316
sam_encoder.blocks.11.norm2.weight grad: -0.0036638062447309494
sam_encoder.blocks.11.norm2.bias grad: -0.000453489541541785
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0022538991179317236
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0009278954239562154
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00028269566246308386
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00015457792324014008
sam_encoder.neck.conv1.trainable_scale grad: 0.0004670532653108239
sam_encoder.neck.conv1.trainable_shift grad: -0.0058635082095861435
sam_encoder.neck.conv2.trainable_scale grad: 0.0003244960680603981
sam_encoder.neck.conv2.trainable_shift grad: -0.005841086618602276
mask_decoder.transformer.layers.0.norm1.weight grad: 0.011484910733997822
mask_decoder.transformer.layers.0.norm1.bias grad: 0.002351386472582817
mask_decoder.transformer.layers.0.norm2.weight grad: -0.07907170057296753
mask_decoder.transformer.layers.0.norm2.bias grad: 0.11634546518325806
mask_decoder.transformer.layers.0.norm3.weight grad: 0.034880381077528
mask_decoder.transformer.layers.0.norm3.bias grad: 0.018511731177568436
mask_decoder.transformer.layers.0.norm4.weight grad: -0.008381439372897148
mask_decoder.transformer.layers.0.norm4.bias grad: 0.006401659455150366
mask_decoder.transformer.layers.1.norm1.weight grad: 0.000787100289016962
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0033547822386026382
mask_decoder.transformer.layers.1.norm2.weight grad: 0.1692957580089569
mask_decoder.transformer.layers.1.norm2.bias grad: 0.04246169328689575
mask_decoder.transformer.layers.1.norm3.weight grad: 0.024873696267604828
mask_decoder.transformer.layers.1.norm3.bias grad: 0.01503722183406353
mask_decoder.transformer.layers.1.norm4.weight grad: 0.014291031286120415
mask_decoder.transformer.layers.1.norm4.bias grad: 0.029843494296073914
mask_decoder.transformer.norm_final_attn.weight grad: 0.0013315322576090693
mask_decoder.transformer.norm_final_attn.bias grad: -0.004975402727723122
Text_Embedding_Affine.0.weight grad: 2.750249805671956e-09
Text_Embedding_Affine.0.bias grad: 1.6135163605213165e-07
Text_Embedding_Affine.2.weight grad: -1.4021875216485569e-08
Text_Embedding_Affine.2.bias grad: -0.007159290835261345

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.727420315793097e-09
Max value: 0.9847991466522217
Mean value: 0.07157665491104126

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.727420315793097e-09
Max value: 0.9847991466522217
Mean value: 0.07157665491104126

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07231616973876953

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.682783126831055
Max value: -1.1920928244535389e-07
Mean value: -0.14498251676559448

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.025392532348632812

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07231616973876953

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 21.41152572631836
Max value: 36.65353775024414
Mean value: 29.982250213623047

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.727420315793097e-09
Max value: 0.9847991466522217
Mean value: 0.07157665491104126

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.727420315793097e-09
Max value: 0.9847991466522217
Mean value: 0.07157665491104126

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.727420315793097e-09
Max value: 0.9847991466522217
Mean value: 0.07157665491104126

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.682783126831055
Max value: -1.1920928244535389e-07
Mean value: -0.14498251676559448

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 21.41152572631836
Max value: 36.65353775024414
Mean value: 29.982250213623047

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -29.983943939208984
Max value: -29.983943939208984
Mean value: -29.983943939208984
sam_encoder.pos_embed grad: 3.6503374190033355e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0019489815458655357
sam_encoder.blocks.0.norm1.bias grad: 0.01648489385843277
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0013746428303420544
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.022762242238969e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.3458763937233016e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.100467049283907e-05
sam_encoder.blocks.0.norm2.weight grad: 0.010205422528088093
sam_encoder.blocks.0.norm2.bias grad: -0.0011089009931311011
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.001838769530877471
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0002580941654741764
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0018303925171494484
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0009295277995988727
sam_encoder.blocks.1.norm1.weight grad: -0.0028036488220095634
sam_encoder.blocks.1.norm1.bias grad: -0.0007369072991423309
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.2004136553732678e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.100520451785997e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0004673340590670705
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0002237973822047934
sam_encoder.blocks.1.norm2.weight grad: 0.000421863398514688
sam_encoder.blocks.1.norm2.bias grad: 0.00048465438885614276
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.8959184419363737e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.342177271610126e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.00035039844806306064
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00018392612400930375
sam_encoder.blocks.2.norm1.weight grad: 0.0019970526918768883
sam_encoder.blocks.2.norm1.bias grad: 0.0008539819973520935
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0010005687363445759
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00019824417540803552
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.508768223691732e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000732862506993115
sam_encoder.blocks.2.norm2.weight grad: 0.0016140930820256472
sam_encoder.blocks.2.norm2.bias grad: -0.002527945674955845
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0006889425567351282
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001661656133364886
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006925630732439458
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00038339925231412053
sam_encoder.blocks.3.norm1.weight grad: -0.0024552932009100914
sam_encoder.blocks.3.norm1.bias grad: 0.0007143013062886894
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0027568587101995945
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0005465184804052114
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.001132708741351962
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00039019202813506126
sam_encoder.blocks.3.norm2.weight grad: 0.0007965032709762454
sam_encoder.blocks.3.norm2.bias grad: -0.0020796225871890783
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.000693226873409003
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00025865744100883603
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0008482881239615381
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.3082807678729296e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0014038755325600505
sam_encoder.blocks.4.norm1.bias grad: 0.0005880002281628549
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0009841639548540115
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00014050178288016468
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00035792210837826133
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00018320025992579758
sam_encoder.blocks.4.norm2.weight grad: -0.004633905366063118
sam_encoder.blocks.4.norm2.bias grad: -0.003171833697706461
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.003090621903538704
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0010344597976654768
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.000766920275054872
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00044025524402968585
sam_encoder.blocks.5.norm1.weight grad: 0.000589601811952889
sam_encoder.blocks.5.norm1.bias grad: 0.0003824414452537894
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.140481415670365e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0004232179489918053
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0003629189159255475
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00026682415045797825
sam_encoder.blocks.5.norm2.weight grad: -0.0025483225472271442
sam_encoder.blocks.5.norm2.bias grad: -0.001903695985674858
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.000927830464206636
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0004091195878572762
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.699663208564743e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.95191709685605e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00030956475529819727
sam_encoder.blocks.6.norm1.bias grad: 0.00048273062566295266
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0006197790498845279
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00047073402674868703
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00027061745640821755
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.000408974417950958
sam_encoder.blocks.6.norm2.weight grad: -0.000361792859621346
sam_encoder.blocks.6.norm2.bias grad: -0.0007069557905197144
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00022411362442653626
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.73737667966634e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0005124033195897937
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00016472818970214576
sam_encoder.blocks.7.norm1.weight grad: -0.0002880847896449268
sam_encoder.blocks.7.norm1.bias grad: 0.00025045525399036705
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00032958746305666864
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.6958471127945813e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0002427992003504187
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0002852465258911252
sam_encoder.blocks.7.norm2.weight grad: 0.0007461146451532841
sam_encoder.blocks.7.norm2.bias grad: 0.00013548872084356844
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0002924822620116174
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.076480637304485e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.860639895312488e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.681433102225128e-07
sam_encoder.blocks.8.norm1.weight grad: 3.0118022550595924e-05
sam_encoder.blocks.8.norm1.bias grad: 9.345978469355032e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0007977549685165286
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00035797187592834234
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0006591730052605271
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0005592792294919491
sam_encoder.blocks.8.norm2.weight grad: -0.0003210948780179024
sam_encoder.blocks.8.norm2.bias grad: -0.0003731813048943877
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000335120566887781
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00018734170589596033
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.545113087166101e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.7868506953818724e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00153203250374645
sam_encoder.blocks.9.norm1.bias grad: -0.0001256026152987033
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0012534565757960081
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0004057349287904799
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0003826929605565965
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0007145601557567716
sam_encoder.blocks.9.norm2.weight grad: 0.0002817212953232229
sam_encoder.blocks.9.norm2.bias grad: -0.00039425044087693095
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0002312547730980441
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00012255743786226958
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00022222340339794755
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.14279992482625e-05
sam_encoder.blocks.10.norm1.weight grad: -3.516618744470179e-05
sam_encoder.blocks.10.norm1.bias grad: -5.171935117687099e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0001042813528329134
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.30188878858462e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00013473330182023346
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.582790279528126e-05
sam_encoder.blocks.10.norm2.weight grad: -0.000539842527359724
sam_encoder.blocks.10.norm2.bias grad: -0.0007544331019744277
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00010024530638474971
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00020753656281158328
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.130377081106417e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.420534540055087e-06
sam_encoder.blocks.11.norm1.weight grad: -0.0014036849606782198
sam_encoder.blocks.11.norm1.bias grad: 0.0004091160371899605
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0004806692013517022
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.872148464433849e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00012528838124126196
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.0124315748689696e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0004320979060139507
sam_encoder.blocks.11.norm2.bias grad: -0.00020373883307911456
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.361311872955412e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00020593786030076444
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.3803515685140155e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.126987187191844e-05
sam_encoder.neck.conv1.trainable_scale grad: -6.910180673003197e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0018865007441490889
sam_encoder.neck.conv2.trainable_scale grad: -9.107287041842937e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.003572132671251893
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0178830549120903
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00013146735727787018
mask_decoder.transformer.layers.0.norm2.weight grad: -0.9076224565505981
mask_decoder.transformer.layers.0.norm2.bias grad: 0.11736352741718292
mask_decoder.transformer.layers.0.norm3.weight grad: 0.013956044800579548
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0132943419739604
mask_decoder.transformer.layers.0.norm4.weight grad: 0.010648724623024464
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0003085362259298563
mask_decoder.transformer.layers.1.norm1.weight grad: 0.011006232351064682
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0007313948590308428
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0669538825750351
mask_decoder.transformer.layers.1.norm2.bias grad: 0.023054728284478188
mask_decoder.transformer.layers.1.norm3.weight grad: 0.016654640436172485
mask_decoder.transformer.layers.1.norm3.bias grad: 0.014138656668365002
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0064367554150521755
mask_decoder.transformer.layers.1.norm4.bias grad: -0.009649399667978287
mask_decoder.transformer.norm_final_attn.weight grad: 0.0008407481946051121
mask_decoder.transformer.norm_final_attn.bias grad: 0.00033343821996822953
Text_Embedding_Affine.0.weight grad: -5.630596877637117e-09
Text_Embedding_Affine.0.bias grad: -2.0558945834636688e-07
Text_Embedding_Affine.2.weight grad: 1.064114663051896e-08
Text_Embedding_Affine.2.bias grad: -0.0007586588617414236
Epoch 7 finished with average loss: -43.7307
Epoch 8/39
----------
Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.3]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.02it/s, loss=-59.3]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.02it/s, loss=-43.7]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-43.7]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-41]  Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-41]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.018750164400345e-12
Max value: 0.9987379908561707
Mean value: 0.11640804260969162

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.018750164400345e-12
Max value: 0.9987379908561707
Mean value: 0.11640804260969162

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1009979248046875

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1565435230731964

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08613300323486328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1009979248046875

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.00014114379883
Max value: 79.82440185546875
Mean value: 59.28517150878906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.018750164400345e-12
Max value: 0.9987379908561707
Mean value: 0.11640804260969162

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.018750164400345e-12
Max value: 0.9987379908561707
Mean value: 0.11640804260969162

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.018750164400345e-12
Max value: 0.9987379908561707
Mean value: 0.11640804260969162

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1565435230731964

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.00014114379883
Max value: 79.82440185546875
Mean value: 59.28517150878906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.28709411621094
Max value: -59.28709411621094
Mean value: -59.28709411621094
sam_encoder.pos_embed grad: 1.3376429706113413e-06
sam_encoder.blocks.0.norm1.weight grad: 0.0006112480768933892
sam_encoder.blocks.0.norm1.bias grad: 0.0012923255562782288
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.001398779801093042
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.1861829079862218e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.000982140889391303
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0005070552579127252
sam_encoder.blocks.0.norm2.weight grad: 0.00563801359385252
sam_encoder.blocks.0.norm2.bias grad: -0.0030918268021196127
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0024920101277530193
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0004634849610738456
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0013481624191626906
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0003538932651281357
sam_encoder.blocks.1.norm1.weight grad: 1.8348742742091417e-05
sam_encoder.blocks.1.norm1.bias grad: 0.0025564609095454216
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0010410880204290152
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0002935604134108871
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0012477985583245754
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0006593453581444919
sam_encoder.blocks.1.norm2.weight grad: -0.0013097093906253576
sam_encoder.blocks.1.norm2.bias grad: -0.00026340901968069375
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0014204474864527583
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00024073726672213525
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0019757766276597977
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0005001556128263474
sam_encoder.blocks.2.norm1.weight grad: -0.00048203355981968343
sam_encoder.blocks.2.norm1.bias grad: 0.0011673469562083483
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00044352427357807755
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00018878860282711685
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0006608435651287436
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0005474563222378492
sam_encoder.blocks.2.norm2.weight grad: 1.53744676936185e-05
sam_encoder.blocks.2.norm2.bias grad: -0.001648511621169746
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00018320951494388282
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.4255006792373024e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0009581082849763334
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004885268863290548
sam_encoder.blocks.3.norm1.weight grad: 0.0006835392559878528
sam_encoder.blocks.3.norm1.bias grad: 0.0005224546766839921
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0008321729837916791
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0002250928955618292
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005044837016612291
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00035530407330952585
sam_encoder.blocks.3.norm2.weight grad: -0.0021166885271668434
sam_encoder.blocks.3.norm2.bias grad: -0.0015892346855252981
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0015164937358349562
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0003946448559872806
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.00017146355821751058
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.000254154292633757
sam_encoder.blocks.4.norm1.weight grad: 0.0026256858836859465
sam_encoder.blocks.4.norm1.bias grad: -0.0010647429153323174
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0016623381525278091
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005633308901451528
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0004061891813762486
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00012102772598154843
sam_encoder.blocks.4.norm2.weight grad: -0.003326036036014557
sam_encoder.blocks.4.norm2.bias grad: -0.0007911440916359425
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0020533110946416855
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0004988041473552585
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00047649379121139646
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0003240925434511155
sam_encoder.blocks.5.norm1.weight grad: 0.0011011473834514618
sam_encoder.blocks.5.norm1.bias grad: -0.0005351721774786711
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0012871255166828632
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00027428229805082083
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00016710271302144974
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0006006761104799807
sam_encoder.blocks.5.norm2.weight grad: -0.0034193878527730703
sam_encoder.blocks.5.norm2.bias grad: 0.00014235961134545505
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0020392886362969875
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0007387915393337607
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -4.915971294394694e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00010473813745193183
sam_encoder.blocks.6.norm1.weight grad: 0.0008116797544062138
sam_encoder.blocks.6.norm1.bias grad: -0.0002666180662345141
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00042613010737113655
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0002798201167024672
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.1258342055953108e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00015632534632459283
sam_encoder.blocks.6.norm2.weight grad: -0.00041120313107967377
sam_encoder.blocks.6.norm2.bias grad: 0.0003636826004367322
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00034499086905270815
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00011577294208109379
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00011761672794818878
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00013953750021755695
sam_encoder.blocks.7.norm1.weight grad: -6.169721018522978e-05
sam_encoder.blocks.7.norm1.bias grad: -0.000293099059490487
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00019394738774280995
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.47721821628511e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0003273214097134769
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003737368097063154
sam_encoder.blocks.7.norm2.weight grad: -0.0006931042298674583
sam_encoder.blocks.7.norm2.bias grad: 0.0002331310388399288
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.000408324965974316
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00021011120406910777
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00019106511899735779
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0002498129033483565
sam_encoder.blocks.8.norm1.weight grad: 0.00015010495553724468
sam_encoder.blocks.8.norm1.bias grad: -4.990998422726989e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.908394551719539e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0001181253173854202
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.000602726882789284
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0003894867259077728
sam_encoder.blocks.8.norm2.weight grad: -0.0015259282663464546
sam_encoder.blocks.8.norm2.bias grad: 7.091740553732961e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.001170026371255517
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0005994616076350212
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00016481734928674996
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.1912545637169387e-06
sam_encoder.blocks.9.norm1.weight grad: -0.00040881879976950586
sam_encoder.blocks.9.norm1.bias grad: -0.00014675233978778124
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0003829094930551946
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00027909051277674735
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00029278255533427
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00012916524428874254
sam_encoder.blocks.9.norm2.weight grad: -0.0015714829787611961
sam_encoder.blocks.9.norm2.bias grad: -4.540063673630357e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0011668035294860601
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0005419908557087183
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.66750711388886e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.031371751509141e-06
sam_encoder.blocks.10.norm1.weight grad: -0.00020926467550452799
sam_encoder.blocks.10.norm1.bias grad: -8.69050418259576e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00019638834055513144
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.393144187517464e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00010804184421431273
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00011827005073428154
sam_encoder.blocks.10.norm2.weight grad: -0.002779897302389145
sam_encoder.blocks.10.norm2.bias grad: -0.00038737431168556213
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0012584354262799025
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0006042445311322808
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.616359991719946e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.071924584219232e-05
sam_encoder.blocks.11.norm1.weight grad: -0.003434167942032218
sam_encoder.blocks.11.norm1.bias grad: 0.00013644980208482593
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00023685819178353995
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.5991827240213752e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00016598889487795532
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.386756235267967e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0024868492037057877
sam_encoder.blocks.11.norm2.bias grad: -7.262782310135663e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0010269812773913145
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00043594231829047203
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00017796398606151342
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00012098652950953692
sam_encoder.neck.conv1.trainable_scale grad: 8.435617201030254e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0032561728730797768
sam_encoder.neck.conv2.trainable_scale grad: 0.00015108694788068533
sam_encoder.neck.conv2.trainable_shift grad: -0.000975605973508209
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00911122839897871
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00015322305262088776
mask_decoder.transformer.layers.0.norm2.weight grad: 0.18573367595672607
mask_decoder.transformer.layers.0.norm2.bias grad: 0.10189209878444672
mask_decoder.transformer.layers.0.norm3.weight grad: 0.019374722614884377
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00903090089559555
mask_decoder.transformer.layers.0.norm4.weight grad: 0.007210899144411087
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0015974598936736584
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0025234404020011425
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00019726145546883345
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0447513684630394
mask_decoder.transformer.layers.1.norm2.bias grad: 0.020010657608509064
mask_decoder.transformer.layers.1.norm3.weight grad: 0.010539829730987549
mask_decoder.transformer.layers.1.norm3.bias grad: 0.005362692289054394
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0022962267976254225
mask_decoder.transformer.layers.1.norm4.bias grad: 0.004800918512046337
mask_decoder.transformer.norm_final_attn.weight grad: -0.00018186155648436397
mask_decoder.transformer.norm_final_attn.bias grad: -0.0016632843762636185
Text_Embedding_Affine.0.weight grad: 1.1882188566403329e-09
Text_Embedding_Affine.0.bias grad: -8.119968697428703e-09
Text_Embedding_Affine.2.weight grad: 4.052983726410275e-09
Text_Embedding_Affine.2.bias grad: -0.0022275946103036404

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8458007691735112e-11
Max value: 0.9969648718833923
Mean value: 0.06727606058120728

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8458007691735112e-11
Max value: 0.9969648718833923
Mean value: 0.06727606058120728

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06529474258422852

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.129938125610352
Max value: -1.1920928244535389e-07
Mean value: -0.14344309270381927

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.022812366485595703

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06529474258422852

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 5.45972204208374
Max value: 44.2818603515625
Mean value: 28.045045852661133

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8458007691735112e-11
Max value: 0.9969648718833923
Mean value: 0.06727606058120728

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8458007691735112e-11
Max value: 0.9969648718833923
Mean value: 0.06727606058120728

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8458007691735112e-11
Max value: 0.9969648718833923
Mean value: 0.06727606058120728

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.129938125610352
Max value: -1.1920928244535389e-07
Mean value: -0.14344309270381927

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 5.45972204208374
Max value: 44.2818603515625
Mean value: 28.045045852661133

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -28.046550750732422
Max value: -28.046550750732422
Mean value: -28.046550750732422
sam_encoder.pos_embed grad: 2.3021862034511287e-06
sam_encoder.blocks.0.norm1.weight grad: 0.016018075868487358
sam_encoder.blocks.0.norm1.bias grad: 0.0038126748986542225
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0001556711213197559
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.224445026717149e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.001578702125698328
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0004830590623896569
sam_encoder.blocks.0.norm2.weight grad: 0.015507022850215435
sam_encoder.blocks.0.norm2.bias grad: 0.003519713878631592
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0034923297353088856
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00034043725463561714
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0058339666575193405
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.004294596146792173
sam_encoder.blocks.1.norm1.weight grad: -0.0019269114127382636
sam_encoder.blocks.1.norm1.bias grad: 0.0016938199987635016
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.001617609290406108
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0006810907507315278
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.002085512038320303
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0006827027536928654
sam_encoder.blocks.1.norm2.weight grad: -0.005373080726712942
sam_encoder.blocks.1.norm2.bias grad: -0.00239309249445796
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0026286127977073193
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00033793452894315124
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.002915647579357028
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0003189935814589262
sam_encoder.blocks.2.norm1.weight grad: -0.002253310289233923
sam_encoder.blocks.2.norm1.bias grad: 0.00047476933104917407
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0015622624196112156
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0003578528994694352
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0013817104045301676
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0011277827434241772
sam_encoder.blocks.2.norm2.weight grad: 0.0013757807901129127
sam_encoder.blocks.2.norm2.bias grad: -0.0006337445229291916
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0007754623657092452
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0005113153019919991
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0019592945463955402
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00034841522574424744
sam_encoder.blocks.3.norm1.weight grad: 0.001642139395698905
sam_encoder.blocks.3.norm1.bias grad: 0.00021405347797553986
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0007692500366829336
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003695432678796351
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00031422037864103913
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0011469607707113028
sam_encoder.blocks.3.norm2.weight grad: 0.0005828097346238792
sam_encoder.blocks.3.norm2.bias grad: -0.002300472464412451
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0012322216061875224
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0011496271472424269
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0013326210901141167
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.7373898774385452e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0045265513472259045
sam_encoder.blocks.4.norm1.bias grad: -0.0016715973615646362
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0017491773469373584
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005987237091176212
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0002885854337364435
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.9911614041775465e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0013580675004050136
sam_encoder.blocks.4.norm2.bias grad: 0.0023999279364943504
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0006343995919451118
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00033149326918646693
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.001235186355188489
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.791295552626252e-05
sam_encoder.blocks.5.norm1.weight grad: 0.004179244861006737
sam_encoder.blocks.5.norm1.bias grad: -0.005910814739763737
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.005225899629294872
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.004027239046990871
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0005616007838398218
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0014998973347246647
sam_encoder.blocks.5.norm2.weight grad: 0.0004411810077726841
sam_encoder.blocks.5.norm2.bias grad: 0.0018753147451207042
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0004892380675300956
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.45855611260049e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0005679167225025594
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.0003246330306865275
sam_encoder.blocks.6.norm1.weight grad: 0.003578492207452655
sam_encoder.blocks.6.norm1.bias grad: -0.0017002066597342491
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.002295993035659194
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0012151901610195637
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00024750508600845933
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00047627335879951715
sam_encoder.blocks.6.norm2.weight grad: -0.004566605668514967
sam_encoder.blocks.6.norm2.bias grad: -0.0007759813452139497
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0035022031515836716
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0014440681552514434
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.000665675092022866
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.329524927015882e-06
sam_encoder.blocks.7.norm1.weight grad: -0.0024296478368341923
sam_encoder.blocks.7.norm1.bias grad: 0.000435230991570279
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0024363917764276266
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0008917555096559227
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0008480171672999859
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0001688449119683355
sam_encoder.blocks.7.norm2.weight grad: -0.0017907076980918646
sam_encoder.blocks.7.norm2.bias grad: 0.00020801633945666254
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0027109067887067795
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0010098852217197418
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.71444577164948e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0004097196215298027
sam_encoder.blocks.8.norm1.weight grad: 0.00042957928963005543
sam_encoder.blocks.8.norm1.bias grad: -0.0005472766933962703
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.002283452544361353
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0018854709342122078
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0007128503057174385
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.8130396711057983e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0013856105506420135
sam_encoder.blocks.8.norm2.bias grad: 0.0003329225583001971
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0009843993466347456
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0008810769650153816
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0005391339072957635
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0005486686713993549
sam_encoder.blocks.9.norm1.weight grad: -0.0006347874295897782
sam_encoder.blocks.9.norm1.bias grad: 9.515804413240403e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0010217849630862474
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0006249007419683039
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0006640583742409945
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00023569734185002744
sam_encoder.blocks.9.norm2.weight grad: -0.0033180820755660534
sam_encoder.blocks.9.norm2.bias grad: 1.474369037168799e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.002785074058920145
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0015404592268168926
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0002461237309034914
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00023449827858712524
sam_encoder.blocks.10.norm1.weight grad: -0.0015473011881113052
sam_encoder.blocks.10.norm1.bias grad: -0.0006476393318735063
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0011407322017475963
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00048323714872822165
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0007213880307972431
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.0003311638720333576
sam_encoder.blocks.10.norm2.weight grad: -0.0052665951661765575
sam_encoder.blocks.10.norm2.bias grad: -0.0002543230075389147
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0026403963565826416
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0013968771090731025
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00013136837515048683
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.648610673844814e-05
sam_encoder.blocks.11.norm1.weight grad: -0.010812412947416306
sam_encoder.blocks.11.norm1.bias grad: -0.0006106598302721977
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00027875712839886546
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0002988644118886441
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0007308622589334846
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00020367352408356965
sam_encoder.blocks.11.norm2.weight grad: -0.005255790427327156
sam_encoder.blocks.11.norm2.bias grad: -0.0012906871270388365
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0019281301647424698
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.000952297355979681
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0003175351885147393
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.971798186190426e-05
sam_encoder.neck.conv1.trainable_scale grad: 0.0002704095095396042
sam_encoder.neck.conv1.trainable_shift grad: -3.5641249269247055e-05
sam_encoder.neck.conv2.trainable_scale grad: 0.0005349884741008282
sam_encoder.neck.conv2.trainable_shift grad: 5.87111571803689e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.044451236724853516
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0022724345326423645
mask_decoder.transformer.layers.0.norm2.weight grad: 1.374316930770874
mask_decoder.transformer.layers.0.norm2.bias grad: 0.23091068863868713
mask_decoder.transformer.layers.0.norm3.weight grad: 0.04720237851142883
mask_decoder.transformer.layers.0.norm3.bias grad: 0.03082963451743126
mask_decoder.transformer.layers.0.norm4.weight grad: -0.03465116024017334
mask_decoder.transformer.layers.0.norm4.bias grad: 0.008493507280945778
mask_decoder.transformer.layers.1.norm1.weight grad: 0.002997367177158594
mask_decoder.transformer.layers.1.norm1.bias grad: -0.004481346346437931
mask_decoder.transformer.layers.1.norm2.weight grad: 0.1960294544696808
mask_decoder.transformer.layers.1.norm2.bias grad: 0.06052868813276291
mask_decoder.transformer.layers.1.norm3.weight grad: 0.02215222269296646
mask_decoder.transformer.layers.1.norm3.bias grad: 0.018755748867988586
mask_decoder.transformer.layers.1.norm4.weight grad: 0.024943750351667404
mask_decoder.transformer.layers.1.norm4.bias grad: 0.07799306511878967
mask_decoder.transformer.norm_final_attn.weight grad: 0.0011434598127380013
mask_decoder.transformer.norm_final_attn.bias grad: -0.0063405828550457954
Text_Embedding_Affine.0.weight grad: -2.2790895837232483e-09
Text_Embedding_Affine.0.bias grad: -3.562308847904205e-08
Text_Embedding_Affine.2.weight grad: -4.66974690027655e-08
Text_Embedding_Affine.2.bias grad: -0.01375237014144659

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.6280846416048007e-06
Max value: 0.9938527345657349
Mean value: 0.11012128740549088

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.6280846416048007e-06
Max value: 0.9938527345657349
Mean value: 0.11012128740549088

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08572196960449219

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -9.241792678833008
Max value: -3.576272320060525e-06
Mean value: -0.1669520139694214

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05022144317626953

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08572196960449219

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 2.0399999618530273
Max value: 64.16035461425781
Mean value: 35.74589920043945

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.6280846416048007e-06
Max value: 0.9938527345657349
Mean value: 0.11012128740549088

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.6280846416048007e-06
Max value: 0.9938527345657349
Mean value: 0.11012128740549088

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.6280846416048007e-06
Max value: 0.9938527345657349
Mean value: 0.11012128740549088

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -9.241792678833008
Max value: -3.576272320060525e-06
Mean value: -0.1669520139694214

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 2.0399999618530273
Max value: 64.16035461425781
Mean value: 35.74589920043945

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -35.748268127441406
Max value: -35.748268127441406
Mean value: -35.748268127441406
sam_encoder.pos_embed grad: 1.7263989775528898e-06
sam_encoder.blocks.0.norm1.weight grad: -0.013737446628510952
sam_encoder.blocks.0.norm1.bias grad: -0.004405147396028042
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0010670064948499203
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.55570625490509e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.002638618228957057
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0006070384988561273
sam_encoder.blocks.0.norm2.weight grad: 0.010680926963686943
sam_encoder.blocks.0.norm2.bias grad: -0.016676269471645355
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.007472175173461437
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.002048088237643242
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0009373429929837584
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0007262498838827014
sam_encoder.blocks.1.norm1.weight grad: 0.003524771658703685
sam_encoder.blocks.1.norm1.bias grad: 0.003583885496482253
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0018705150578171015
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0007319877622649074
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00218137726187706
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.001268515596166253
sam_encoder.blocks.1.norm2.weight grad: 2.66428105533123e-05
sam_encoder.blocks.1.norm2.bias grad: -0.0018971730023622513
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0012565333163365722
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.6031029594596475e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.004271917510777712
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0007393306586891413
sam_encoder.blocks.2.norm1.weight grad: -0.0007225533481687307
sam_encoder.blocks.2.norm1.bias grad: 0.0005193605902604759
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0011878510704264045
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0005266386433504522
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0014493436319753528
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0012911041267216206
sam_encoder.blocks.2.norm2.weight grad: -0.0014825927792117
sam_encoder.blocks.2.norm2.bias grad: 0.001040195464156568
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0019141780212521553
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00044808880193158984
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0025472822599112988
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0007525754044763744
sam_encoder.blocks.3.norm1.weight grad: -0.0013534436002373695
sam_encoder.blocks.3.norm1.bias grad: 0.0009035144466906786
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0027783275581896305
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.000543616886716336
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0020861199591308832
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0009873065864667296
sam_encoder.blocks.3.norm2.weight grad: -0.0006359049584716558
sam_encoder.blocks.3.norm2.bias grad: -0.0010640687542036176
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0002276967716170475
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00030876725213602185
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0008773139561526477
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00040851254016160965
sam_encoder.blocks.4.norm1.weight grad: 0.0020630727522075176
sam_encoder.blocks.4.norm1.bias grad: 3.1060433229868067e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0006549851968884468
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002417458890704438
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0003043952747248113
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0006482208846136928
sam_encoder.blocks.4.norm2.weight grad: -0.005719669163227081
sam_encoder.blocks.4.norm2.bias grad: -0.0022692191414535046
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.004105105996131897
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0012961982283741236
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0007611035834997892
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0004503037198446691
sam_encoder.blocks.5.norm1.weight grad: 0.0007048575207591057
sam_encoder.blocks.5.norm1.bias grad: -0.001780310645699501
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0005673764972016215
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00022334267850965261
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0002207532525062561
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0006750614265911281
sam_encoder.blocks.5.norm2.weight grad: -0.0049984208308160305
sam_encoder.blocks.5.norm2.bias grad: -2.339482307434082e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0027433261275291443
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0008669588714838028
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00017345898959320039
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.4680650312802754e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0002428986190352589
sam_encoder.blocks.6.norm1.bias grad: -0.00036803900729864836
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00022107861877884716
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00015238784544635564
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.558340101037174e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00014807164552621543
sam_encoder.blocks.6.norm2.weight grad: -0.001904132543131709
sam_encoder.blocks.6.norm2.bias grad: 9.270649024983868e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0017046401044353843
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.000698001473210752
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0001916418259497732
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.403655763482675e-05
sam_encoder.blocks.7.norm1.weight grad: 3.804052175837569e-05
sam_encoder.blocks.7.norm1.bias grad: 0.0001872587454272434
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0003254468319937587
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00017019137158058584
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00040739739779382944
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0004909177660010755
sam_encoder.blocks.7.norm2.weight grad: -0.0001050989594659768
sam_encoder.blocks.7.norm2.bias grad: 5.227273140917532e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0001148903975263238
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0001965506817214191
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00015292468015104532
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0002370339643675834
sam_encoder.blocks.8.norm1.weight grad: 0.0004251992213539779
sam_encoder.blocks.8.norm1.bias grad: -0.0003796503588091582
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00033349922159686685
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0001247821346623823
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0005205505876801908
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00010678544640541077
sam_encoder.blocks.8.norm2.weight grad: -0.0014814406167715788
sam_encoder.blocks.8.norm2.bias grad: -0.0001598900998942554
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.001140620093792677
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0007390470709651709
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0003982766065746546
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00015227746916934848
sam_encoder.blocks.9.norm1.weight grad: -0.0010765150655061007
sam_encoder.blocks.9.norm1.bias grad: -9.034512186190113e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.000981173012405634
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00043362920405343175
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0004884151858277619
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0003551206027623266
sam_encoder.blocks.9.norm2.weight grad: -0.002316294237971306
sam_encoder.blocks.9.norm2.bias grad: -0.00042876237421296537
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0014769688714295626
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0008537665707990527
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00037383459857665
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00016931173740886152
sam_encoder.blocks.10.norm1.weight grad: 2.853553269233089e-05
sam_encoder.blocks.10.norm1.bias grad: -0.00011921510304091498
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.506758573872503e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1126716344733723e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.771611904492602e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.6784650142653845e-05
sam_encoder.blocks.10.norm2.weight grad: -0.003898118156939745
sam_encoder.blocks.10.norm2.bias grad: -0.0010233049979433417
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0015785449650138617
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0008663006010465324
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00033030216582119465
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.499425606103614e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0034167056437581778
sam_encoder.blocks.11.norm1.bias grad: 0.0002998762938659638
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00028253349591977894
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.670898387208581e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.741268877405673e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.127974923700094e-05
sam_encoder.blocks.11.norm2.weight grad: -0.004571942612528801
sam_encoder.blocks.11.norm2.bias grad: -0.000313399126753211
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.001647433964535594
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0008301056805066764
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0008229466038756073
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00037353840889409184
sam_encoder.neck.conv1.trainable_scale grad: -6.205961108207703e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0071217771619558334
sam_encoder.neck.conv2.trainable_scale grad: 8.550751954317093e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0002712598070502281
mask_decoder.transformer.layers.0.norm1.weight grad: 0.004076482728123665
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0009374618530273438
mask_decoder.transformer.layers.0.norm2.weight grad: -0.17084239423274994
mask_decoder.transformer.layers.0.norm2.bias grad: 0.2524842321872711
mask_decoder.transformer.layers.0.norm3.weight grad: 0.015981441363692284
mask_decoder.transformer.layers.0.norm3.bias grad: 0.01560547947883606
mask_decoder.transformer.layers.0.norm4.weight grad: 0.016559336334466934
mask_decoder.transformer.layers.0.norm4.bias grad: 0.002541610039770603
mask_decoder.transformer.layers.1.norm1.weight grad: 0.00737726828083396
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0005232469411566854
mask_decoder.transformer.layers.1.norm2.weight grad: 0.09673575311899185
mask_decoder.transformer.layers.1.norm2.bias grad: 0.03041153959929943
mask_decoder.transformer.layers.1.norm3.weight grad: 0.022951804101467133
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0132867731153965
mask_decoder.transformer.layers.1.norm4.weight grad: 0.015030242502689362
mask_decoder.transformer.layers.1.norm4.bias grad: 0.008069684728980064
mask_decoder.transformer.norm_final_attn.weight grad: 0.0007270216010510921
mask_decoder.transformer.norm_final_attn.bias grad: -3.2707175705581903e-05
Text_Embedding_Affine.0.weight grad: 4.920683860376585e-10
Text_Embedding_Affine.0.bias grad: -3.3527612686157227e-08
Text_Embedding_Affine.2.weight grad: 1.0938245864622331e-08
Text_Embedding_Affine.2.bias grad: 0.0019455468282103539
Epoch 8 finished with average loss: -41.0273
Epoch 9/39
----------
Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, loss=-33.4]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-33.4]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-34.6]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-34.6]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-39.9]Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-39.9]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.601767383289769e-10
Max value: 0.9996647834777832
Mean value: 0.08774608373641968

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.601767383289769e-10
Max value: 0.9996647834777832
Mean value: 0.08774608373641968

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0899810791015625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.497701644897461
Max value: -1.1920928244535389e-07
Mean value: -0.16376540064811707

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04441976547241211

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0899810791015625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 2.583955764770508
Max value: 63.12167739868164
Mean value: 33.39115905761719

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.601767383289769e-10
Max value: 0.9996647834777832
Mean value: 0.08774608373641968

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.601767383289769e-10
Max value: 0.9996647834777832
Mean value: 0.08774608373641968

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.601767383289769e-10
Max value: 0.9996647834777832
Mean value: 0.08774608373641968

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.497701644897461
Max value: -1.1920928244535389e-07
Mean value: -0.16376540064811707

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 2.583955764770508
Max value: 63.12167739868164
Mean value: 33.39115905761719

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -33.39305114746094
Max value: -33.39305114746094
Mean value: -33.39305114746094
sam_encoder.pos_embed grad: 3.069047522785695e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0011732595739886165
sam_encoder.blocks.0.norm1.bias grad: -0.002196257933974266
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0010839340975508094
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00020129889890085906
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0008067050948739052
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0012452317168936133
sam_encoder.blocks.0.norm2.weight grad: 0.006418018601834774
sam_encoder.blocks.0.norm2.bias grad: -0.005054469220340252
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0004887678660452366
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0005798466154374182
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0016871675616130233
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006893872050568461
sam_encoder.blocks.1.norm1.weight grad: -0.006142264232039452
sam_encoder.blocks.1.norm1.bias grad: 0.0005915851215831935
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004999039229005575
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0004898432525806129
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.23932212672662e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.0375787244120147e-06
sam_encoder.blocks.1.norm2.weight grad: -0.010481416247785091
sam_encoder.blocks.1.norm2.bias grad: 0.002829666016623378
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.003723462577909231
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0007269415073096752
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.005353860091418028
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00098899204749614
sam_encoder.blocks.2.norm1.weight grad: -0.0027902848087251186
sam_encoder.blocks.2.norm1.bias grad: 0.000827353447675705
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0020289712119847536
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0001663505972828716
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0008771955035626888
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003450558870099485
sam_encoder.blocks.2.norm2.weight grad: -0.0010592438047751784
sam_encoder.blocks.2.norm2.bias grad: -0.004157257732003927
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00023433593742083758
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00039409048622474074
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0030867806635797024
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004280881257727742
sam_encoder.blocks.3.norm1.weight grad: 0.0035661670845001936
sam_encoder.blocks.3.norm1.bias grad: 0.0007105643744580448
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0007757311104796827
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.691764009592589e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005066056037321687
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0007287724292837083
sam_encoder.blocks.3.norm2.weight grad: -0.0012947013601660728
sam_encoder.blocks.3.norm2.bias grad: 0.0007675276137888432
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0021402982529252768
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0008493610075674951
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00012035924009978771
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.934926881920546e-05
sam_encoder.blocks.4.norm1.weight grad: 0.004926833789795637
sam_encoder.blocks.4.norm1.bias grad: -0.0027205422520637512
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0034854707773774862
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0008044749265536666
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0001314926630584523
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0001227213942911476
sam_encoder.blocks.4.norm2.weight grad: -0.0008493022760376334
sam_encoder.blocks.4.norm2.bias grad: 0.0035438109189271927
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0015351328765973449
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.7986632883548737e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0010305176256224513
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.896527389064431e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0050460463389754295
sam_encoder.blocks.5.norm1.bias grad: -0.0009702930110506713
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.005196713376790285
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0023266104981303215
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0005629818188026547
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0007512724259868264
sam_encoder.blocks.5.norm2.weight grad: -0.0030944652389734983
sam_encoder.blocks.5.norm2.bias grad: -0.0003504650667309761
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0021973825059831142
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0007628604071214795
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00042265799129381776
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00012009985221084207
sam_encoder.blocks.6.norm1.weight grad: -0.0006468858919106424
sam_encoder.blocks.6.norm1.bias grad: -0.0007286501349881291
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00043696322245523334
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00011765141971409321
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0007858127355575562
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0007014613365754485
sam_encoder.blocks.6.norm2.weight grad: -0.003630836261436343
sam_encoder.blocks.6.norm2.bias grad: -0.0007639736868441105
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0028306078165769577
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0011771467979997396
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00012021783913951367
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00019679919932968915
sam_encoder.blocks.7.norm1.weight grad: -0.0017265600617974997
sam_encoder.blocks.7.norm1.bias grad: 0.00029715505661442876
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0015087658539414406
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0004340369487181306
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0004601461114361882
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.375850352924317e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0022658698726445436
sam_encoder.blocks.7.norm2.bias grad: 0.0007299308199435472
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0032290879171341658
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0015607844106853008
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00030770906596444547
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0003379312693141401
sam_encoder.blocks.8.norm1.weight grad: 0.0017207530327141285
sam_encoder.blocks.8.norm1.bias grad: 0.00045741521171294153
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.002186528407037258
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.001505207153968513
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.000536993786226958
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0008532159845344722
sam_encoder.blocks.8.norm2.weight grad: -0.001613605534657836
sam_encoder.blocks.8.norm2.bias grad: 0.00039230621769092977
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0023468779399991035
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0013212808407843113
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0006603891961276531
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0003126318333670497
sam_encoder.blocks.9.norm1.weight grad: 0.0013027507811784744
sam_encoder.blocks.9.norm1.bias grad: -0.00039554666727781296
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0006140549085102975
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00020888540893793106
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00014468849985860288
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.166211096569896e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0006738502415828407
sam_encoder.blocks.9.norm2.bias grad: 0.00024992640828713775
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00128774787299335
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00020651932572945952
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.000591450312640518
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0003385430609341711
sam_encoder.blocks.10.norm1.weight grad: 0.0010033248690888286
sam_encoder.blocks.10.norm1.bias grad: -0.0005281390622258186
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00024914645473472774
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.778914444614202e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0004064971290063113
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00039616465801373124
sam_encoder.blocks.10.norm2.weight grad: -0.000703232828527689
sam_encoder.blocks.10.norm2.bias grad: -8.547256584279239e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0004977352800779045
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00017076141375582665
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0006501807365566492
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.00030193233396857977
sam_encoder.blocks.11.norm1.weight grad: -0.0043528201058506966
sam_encoder.blocks.11.norm1.bias grad: 0.00011159938003402203
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.003869193373247981
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.001034552464261651
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00043497822480276227
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00020910629245918244
sam_encoder.blocks.11.norm2.weight grad: 0.0015693891327828169
sam_encoder.blocks.11.norm2.bias grad: -4.063895903527737e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0003836434334516525
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00020437210332602262
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0005748036201111972
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00034474616404622793
sam_encoder.neck.conv1.trainable_scale grad: 0.0006041605956852436
sam_encoder.neck.conv1.trainable_shift grad: 0.0009332855697721243
sam_encoder.neck.conv2.trainable_scale grad: 0.0009081251919269562
sam_encoder.neck.conv2.trainable_shift grad: -0.011752554215490818
mask_decoder.transformer.layers.0.norm1.weight grad: 0.07187101244926453
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0028479285538196564
mask_decoder.transformer.layers.0.norm2.weight grad: 1.1441656351089478
mask_decoder.transformer.layers.0.norm2.bias grad: -0.13745702803134918
mask_decoder.transformer.layers.0.norm3.weight grad: 0.06929408758878708
mask_decoder.transformer.layers.0.norm3.bias grad: 0.03607819974422455
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0321476012468338
mask_decoder.transformer.layers.0.norm4.bias grad: 0.007913772016763687
mask_decoder.transformer.layers.1.norm1.weight grad: -0.004926769062876701
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0031299609690904617
mask_decoder.transformer.layers.1.norm2.weight grad: 0.1396646797657013
mask_decoder.transformer.layers.1.norm2.bias grad: 0.04412370175123215
mask_decoder.transformer.layers.1.norm3.weight grad: -0.004096811171621084
mask_decoder.transformer.layers.1.norm3.bias grad: 0.004088590852916241
mask_decoder.transformer.layers.1.norm4.weight grad: 0.008070302195847034
mask_decoder.transformer.layers.1.norm4.bias grad: 0.06808003783226013
mask_decoder.transformer.norm_final_attn.weight grad: 0.00021887262118980289
mask_decoder.transformer.norm_final_attn.bias grad: -0.007021535653620958
Text_Embedding_Affine.0.weight grad: 2.7141588976320463e-09
Text_Embedding_Affine.0.bias grad: 9.21427272260189e-08
Text_Embedding_Affine.2.weight grad: 8.463708844885787e-09
Text_Embedding_Affine.2.bias grad: -0.02439059503376484

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6042338898264452e-12
Max value: 0.9990189075469971
Mean value: 0.08101330697536469

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6042338898264452e-12
Max value: 0.9990189075469971
Mean value: 0.08101330697536469

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07309865951538086

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13874945044517517

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.03821229934692383

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07309865951538086

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 2.188333511352539
Max value: 72.24406433105469
Mean value: 35.89091873168945

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6042338898264452e-12
Max value: 0.9990189075469971
Mean value: 0.08101330697536469

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6042338898264452e-12
Max value: 0.9990189075469971
Mean value: 0.08101330697536469

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6042338898264452e-12
Max value: 0.9990189075469971
Mean value: 0.08101330697536469

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13874945044517517

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 2.188333511352539
Max value: 72.24406433105469
Mean value: 35.89091873168945

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -35.892642974853516
Max value: -35.892642974853516
Mean value: -35.892642974853516
sam_encoder.pos_embed grad: -8.599487841820519e-07
sam_encoder.blocks.0.norm1.weight grad: -0.007850202731788158
sam_encoder.blocks.0.norm1.bias grad: -0.0016618685331195593
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.891348700970411e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00011276354780420661
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.754704862833023e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00038536227657459676
sam_encoder.blocks.0.norm2.weight grad: 0.005001950077712536
sam_encoder.blocks.0.norm2.bias grad: 0.002603786764666438
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.001751953037455678
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0002649144735187292
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0018848673207685351
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00031440937891602516
sam_encoder.blocks.1.norm1.weight grad: -0.006930085830390453
sam_encoder.blocks.1.norm1.bias grad: -0.0022575794719159603
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0006448240019381046
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00045262795174494386
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0007884331280365586
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0003208302368875593
sam_encoder.blocks.1.norm2.weight grad: -0.0009340224787592888
sam_encoder.blocks.1.norm2.bias grad: -0.0008325310191139579
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.7473393604159355e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00020105508156120777
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0004467126855161041
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.959830403095111e-05
sam_encoder.blocks.2.norm1.weight grad: 0.002956616459414363
sam_encoder.blocks.2.norm1.bias grad: 0.001611419953405857
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0015444493619725108
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00034875827259384096
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00013079916243441403
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00025685562286525965
sam_encoder.blocks.2.norm2.weight grad: 0.0017587661277502775
sam_encoder.blocks.2.norm2.bias grad: -0.004334370605647564
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.002435076981782913
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.000443691125838086
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 8.049033203860745e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.173060683067888e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0001667877659201622
sam_encoder.blocks.3.norm1.bias grad: 0.0015180011978372931
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0005660273600369692
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00047233840450644493
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.912632746505551e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0009894556133076549
sam_encoder.blocks.3.norm2.weight grad: 0.005697939544916153
sam_encoder.blocks.3.norm2.bias grad: -0.0014281428884714842
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0032070667948573828
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0009026883635669947
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0009974839631468058
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0005042996490374207
sam_encoder.blocks.4.norm1.weight grad: 0.004104974679648876
sam_encoder.blocks.4.norm1.bias grad: -0.0047740996815264225
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.003265335923060775
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0012267472920939326
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0005397687782533467
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0005117471446283162
sam_encoder.blocks.4.norm2.weight grad: -0.0001567006402183324
sam_encoder.blocks.4.norm2.bias grad: -0.0003184849047102034
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0003728160518221557
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00020240340381860733
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0005663156043738127
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0007477339240722358
sam_encoder.blocks.5.norm1.weight grad: 0.0028711422346532345
sam_encoder.blocks.5.norm1.bias grad: -0.00490553816780448
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0033400997053831816
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0015288412105292082
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0009788298048079014
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00045467750169336796
sam_encoder.blocks.5.norm2.weight grad: 0.0003684350522235036
sam_encoder.blocks.5.norm2.bias grad: -0.002049932023510337
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0006039038416929543
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00020752350974362344
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00046289199963212013
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00036004604771733284
sam_encoder.blocks.6.norm1.weight grad: -0.0005247241933830082
sam_encoder.blocks.6.norm1.bias grad: 0.0001764240732882172
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0010555516928434372
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00027324570692144334
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0008025226998142898
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0006934523116797209
sam_encoder.blocks.6.norm2.weight grad: -0.002845517359673977
sam_encoder.blocks.6.norm2.bias grad: -0.0013950004940852523
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0027934182435274124
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00134031823836267
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0004185282741673291
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0004098494246136397
sam_encoder.blocks.7.norm1.weight grad: 0.0006835709209553897
sam_encoder.blocks.7.norm1.bias grad: -0.000342810177244246
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.4998286032059696e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0006073330878280103
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0003616624453570694
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0006341768312267959
sam_encoder.blocks.7.norm2.weight grad: -0.0020732812117785215
sam_encoder.blocks.7.norm2.bias grad: 0.0006411049980670214
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0021009654738008976
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0009960599709302187
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.7752394089475274e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00029840398929081857
sam_encoder.blocks.8.norm1.weight grad: -0.0008559058187529445
sam_encoder.blocks.8.norm1.bias grad: -1.5172331586654764e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0007489979034289718
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.000432335160439834
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0008108947658911347
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0008009496959857643
sam_encoder.blocks.8.norm2.weight grad: -0.0005344263627193868
sam_encoder.blocks.8.norm2.bias grad: 9.364575089421123e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0003346434677951038
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00034547591349110007
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0009284125990234315
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.000459259666968137
sam_encoder.blocks.9.norm1.weight grad: 0.000785591546446085
sam_encoder.blocks.9.norm1.bias grad: -0.00014808017294853926
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0002835371997207403
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00028831971576437354
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.790192517451942e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00011281613114988431
sam_encoder.blocks.9.norm2.weight grad: 0.0002982242440339178
sam_encoder.blocks.9.norm2.bias grad: 0.00023107696324586868
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.1970404961612076e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00012471043737605214
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0008367403643205762
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0004047167021781206
sam_encoder.blocks.10.norm1.weight grad: 0.0013022702187299728
sam_encoder.blocks.10.norm1.bias grad: -0.00026836569304578006
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0007318882271647453
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00020401913207024336
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0001350780948996544
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.669723345316015e-06
sam_encoder.blocks.10.norm2.weight grad: 0.00032056350028142333
sam_encoder.blocks.10.norm2.bias grad: 0.00032580364495515823
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0002790487778838724
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.398739398922771e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0006221442599780858
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.0001394545688526705
sam_encoder.blocks.11.norm1.weight grad: -0.0043763769790530205
sam_encoder.blocks.11.norm1.bias grad: 0.0002934359945356846
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0001561788230901584
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00023911974858492613
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0005109341582283378
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00023270861129276454
sam_encoder.blocks.11.norm2.weight grad: 0.0017167513724416494
sam_encoder.blocks.11.norm2.bias grad: -0.0008855386404320598
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0009607336833141744
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0003036747802980244
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.000909374444745481
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.0004057309706695378
sam_encoder.neck.conv1.trainable_scale grad: 0.0003278788644820452
sam_encoder.neck.conv1.trainable_shift grad: 0.00012804311700165272
sam_encoder.neck.conv2.trainable_scale grad: 0.00017524976283311844
sam_encoder.neck.conv2.trainable_shift grad: -0.01902059093117714
mask_decoder.transformer.layers.0.norm1.weight grad: 0.05622153729200363
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0030547576025128365
mask_decoder.transformer.layers.0.norm2.weight grad: 0.1706915646791458
mask_decoder.transformer.layers.0.norm2.bias grad: -0.34183576703071594
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0340137705206871
mask_decoder.transformer.layers.0.norm3.bias grad: 0.004128815606236458
mask_decoder.transformer.layers.0.norm4.weight grad: -0.003612030763179064
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0029400116764009
mask_decoder.transformer.layers.1.norm1.weight grad: -0.00028756645042449236
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0008854850893840194
mask_decoder.transformer.layers.1.norm2.weight grad: 0.06853453814983368
mask_decoder.transformer.layers.1.norm2.bias grad: 0.024739906191825867
mask_decoder.transformer.layers.1.norm3.weight grad: 0.012564823031425476
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0049018869176507
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0037387502379715443
mask_decoder.transformer.layers.1.norm4.bias grad: 0.011442034505307674
mask_decoder.transformer.norm_final_attn.weight grad: -0.00030731892911717296
mask_decoder.transformer.norm_final_attn.bias grad: -0.0029109094757586718
Text_Embedding_Affine.0.weight grad: 5.860761653764257e-09
Text_Embedding_Affine.0.bias grad: 2.439483068883419e-07
Text_Embedding_Affine.2.weight grad: -3.5314307922362786e-08
Text_Embedding_Affine.2.bias grad: -0.016906611621379852

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7688656095415922e-09
Max value: 0.999195396900177
Mean value: 0.09138032793998718

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7688656095415922e-09
Max value: 0.999195396900177
Mean value: 0.09138032793998718

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09270000457763672

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.531671524047852
Max value: -1.1920928244535389e-07
Mean value: -0.13566091656684875

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07074260711669922

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09270000457763672

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 26.062543869018555
Max value: 83.07655334472656
Mean value: 50.449501037597656

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7688656095415922e-09
Max value: 0.999195396900177
Mean value: 0.09138032793998718

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7688656095415922e-09
Max value: 0.999195396900177
Mean value: 0.09138032793998718

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7688656095415922e-09
Max value: 0.999195396900177
Mean value: 0.09138032793998718

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.531671524047852
Max value: -1.1920928244535389e-07
Mean value: -0.13566091656684875

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 26.062543869018555
Max value: 83.07655334472656
Mean value: 50.449501037597656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.4510383605957
Max value: -50.4510383605957
Mean value: -50.4510383605957
sam_encoder.pos_embed grad: 2.0242191567376722e-07
sam_encoder.blocks.0.norm1.weight grad: 0.00036320037906989455
sam_encoder.blocks.0.norm1.bias grad: 0.0038973584305495024
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.2508729696492082e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.075721178902313e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00076238380279392
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0001740934676490724
sam_encoder.blocks.0.norm2.weight grad: 0.0033424373250454664
sam_encoder.blocks.0.norm2.bias grad: -0.00123495701700449
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0009166452800855041
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.715371222933754e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0002261564222862944
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.966768993763253e-05
sam_encoder.blocks.1.norm1.weight grad: -0.0006252673338167369
sam_encoder.blocks.1.norm1.bias grad: 0.00034162215888500214
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004087405977770686
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00016075671010185033
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00040903742774389684
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00024147766816895455
sam_encoder.blocks.1.norm2.weight grad: 0.00033399974927306175
sam_encoder.blocks.1.norm2.bias grad: 6.654148455709219e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.751530938548967e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.6791441832283454e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0008504790021106601
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00024161514011211693
sam_encoder.blocks.2.norm1.weight grad: -0.0008648385992273688
sam_encoder.blocks.2.norm1.bias grad: 0.00026216317201033235
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0006900390144437551
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00011515773076098412
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0004372808034531772
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00035942369140684605
sam_encoder.blocks.2.norm2.weight grad: 0.0004252264625392854
sam_encoder.blocks.2.norm2.bias grad: -0.0015728222206234932
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00019704170699696988
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.7313315260689706e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005019643576815724
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0001230195484822616
sam_encoder.blocks.3.norm1.weight grad: 0.00044488103594630957
sam_encoder.blocks.3.norm1.bias grad: 0.0002271773264510557
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0006312155746854842
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00021023282897658646
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0004893463919870555
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00024041192955337465
sam_encoder.blocks.3.norm2.weight grad: -1.8811397239915095e-05
sam_encoder.blocks.3.norm2.bias grad: -0.00031506005325354636
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.00018745899433270097
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.8338152585783973e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.69591938983649e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.284827835159376e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0005515710217878222
sam_encoder.blocks.4.norm1.bias grad: -0.00018459942657500505
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00013137083442416042
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.5741892689839e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.551300950581208e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -7.396978617180139e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0020403582602739334
sam_encoder.blocks.4.norm2.bias grad: -0.0009490844677202404
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0014426298439502716
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0004369478556327522
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0001241758291143924
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.009742694208398e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0004292632802389562
sam_encoder.blocks.5.norm1.bias grad: -0.00032760988688096404
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.747395284241065e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00012501460150815547
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.503875480731949e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.442691978416406e-06
sam_encoder.blocks.5.norm2.weight grad: -0.0014198524877429008
sam_encoder.blocks.5.norm2.bias grad: -0.00038070272421464324
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0007549200090579689
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0002859517699107528
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001590072497492656
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.8255067263671663e-06
sam_encoder.blocks.6.norm1.weight grad: 0.0002812777820508927
sam_encoder.blocks.6.norm1.bias grad: -7.763368193991482e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.279020453803241e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.1748022845713422e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.190337105887011e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.5125995560083538e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0006975514115765691
sam_encoder.blocks.6.norm2.bias grad: 1.371927464788314e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0005278153112158179
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00020100129768252373
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.65024485392496e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.935123509611003e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0005868552252650261
sam_encoder.blocks.7.norm1.bias grad: 0.00013781314191874117
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00028564990498125553
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00013899404439143836
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9285223970655352e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.270791785325855e-05
sam_encoder.blocks.7.norm2.weight grad: 1.123293441196438e-05
sam_encoder.blocks.7.norm2.bias grad: -4.098371573491022e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0001341325551038608
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00010763137834146619
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.810686616314342e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.494964615441859e-06
sam_encoder.blocks.8.norm1.weight grad: 0.0010781394084915519
sam_encoder.blocks.8.norm1.bias grad: -2.1693351300200447e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.000861360807903111
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00030206513474695385
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00010636905790306628
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.0327511669602245e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0002196612040279433
sam_encoder.blocks.8.norm2.bias grad: 9.846530156210065e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00021417494281195104
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.277135591721162e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.934822284965776e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.278014628449455e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00014445015403907746
sam_encoder.blocks.9.norm1.bias grad: -1.862655881268438e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0001535840128781274
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.205712608993053e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00012065186456311494
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00014101732813287526
sam_encoder.blocks.9.norm2.weight grad: -6.242108793230727e-05
sam_encoder.blocks.9.norm2.bias grad: 7.679064583498985e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00011974095832556486
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.1000296227575745e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.805951514048502e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.137519211624749e-05
sam_encoder.blocks.10.norm1.weight grad: 6.761129770893604e-05
sam_encoder.blocks.10.norm1.bias grad: -8.304724906338379e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.5079305234830827e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.6923700968618505e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1273018571955618e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.735458838287741e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0007548317080363631
sam_encoder.blocks.10.norm2.bias grad: -0.00018457361147738993
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00027650006813928485
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00018032710067927837
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.835923704784364e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.21705847454723e-05
sam_encoder.blocks.11.norm1.weight grad: 4.97711225762032e-05
sam_encoder.blocks.11.norm1.bias grad: -7.93840990809258e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0004633125790860504
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.6567088146694e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.308046118239872e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.5850825952365994e-05
sam_encoder.blocks.11.norm2.weight grad: -0.00034050815156660974
sam_encoder.blocks.11.norm2.bias grad: 3.1640018278267235e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00018122872279491276
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00010108006972586736
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.403588824672624e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.9737768272752874e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.703380934894085e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0010689261835068464
sam_encoder.neck.conv2.trainable_scale grad: 4.46716439910233e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.00218749837949872
mask_decoder.transformer.layers.0.norm1.weight grad: 0.009399010799825191
mask_decoder.transformer.layers.0.norm1.bias grad: 0.000307622947730124
mask_decoder.transformer.layers.0.norm2.weight grad: -0.09480449557304382
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005378611385822296
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0085068354383111
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00424873037263751
mask_decoder.transformer.layers.0.norm4.weight grad: 0.002762686461210251
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0007589058950543404
mask_decoder.transformer.layers.1.norm1.weight grad: 6.0398480854928493e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0004014274454675615
mask_decoder.transformer.layers.1.norm2.weight grad: 0.02650219202041626
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00863330252468586
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004843410104513168
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0032001023646444082
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00023402838269248605
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0014165129978209734
mask_decoder.transformer.norm_final_attn.weight grad: 2.7739493816625327e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0006382674910128117
Text_Embedding_Affine.0.weight grad: 1.4890609856266224e-09
Text_Embedding_Affine.0.bias grad: 8.003553375601768e-09
Text_Embedding_Affine.2.weight grad: -5.293153471086498e-09
Text_Embedding_Affine.2.bias grad: -0.002197262365370989
Epoch 9 finished with average loss: -39.9122
Epoch 10/39
----------
Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, loss=-48.6]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-48.6]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-33.4]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-33.4]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-29.2]Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.30it/s, loss=-29.2]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.75717970466394e-09
Max value: 0.9972429275512695
Mean value: 0.09921564161777496

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.75717970466394e-09
Max value: 0.9972429275512695
Mean value: 0.09921564161777496

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08771562576293945

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.134434700012207
Max value: -1.1920928244535389e-07
Mean value: -0.13401460647583008

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07086181640625

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08771562576293945

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 5.526315689086914
Max value: 75.53601837158203
Mean value: 48.555999755859375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.75717970466394e-09
Max value: 0.9972429275512695
Mean value: 0.09921564161777496

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.75717970466394e-09
Max value: 0.9972429275512695
Mean value: 0.09921564161777496

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.75717970466394e-09
Max value: 0.9972429275512695
Mean value: 0.09921564161777496

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.134434700012207
Max value: -1.1920928244535389e-07
Mean value: -0.13401460647583008

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 5.526315689086914
Max value: 75.53601837158203
Mean value: 48.555999755859375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -48.55775833129883
Max value: -48.55775833129883
Mean value: -48.55775833129883
sam_encoder.pos_embed grad: -1.2591576705744956e-06
sam_encoder.blocks.0.norm1.weight grad: -0.00682496465742588
sam_encoder.blocks.0.norm1.bias grad: -0.007944277487695217
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0010684311855584383
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00015576614532619715
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0013308469206094742
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0005879281088709831
sam_encoder.blocks.0.norm2.weight grad: 0.005743092857301235
sam_encoder.blocks.0.norm2.bias grad: 0.012829157523810863
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0013619394740089774
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0016397777944803238
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0018695960752665997
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0022457123268395662
sam_encoder.blocks.1.norm1.weight grad: -0.007398049812763929
sam_encoder.blocks.1.norm1.bias grad: 0.0039324043318629265
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0011634890688583255
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0007249474874697626
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.000609893468208611
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.000473944004625082
sam_encoder.blocks.1.norm2.weight grad: 0.002953669987618923
sam_encoder.blocks.1.norm2.bias grad: -0.0034722217824310064
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00232092197984457
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0009549105307087302
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0007204259163700044
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00033630302641540766
sam_encoder.blocks.2.norm1.weight grad: 0.001343357376754284
sam_encoder.blocks.2.norm1.bias grad: 0.0023196712136268616
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.136640200158581e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0002610132796689868
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00045570588554255664
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00012018801498925313
sam_encoder.blocks.2.norm2.weight grad: 0.004057775717228651
sam_encoder.blocks.2.norm2.bias grad: -0.0019812900573015213
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.002757654059678316
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.001042668940499425
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.000388260290492326
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.650690920650959e-06
sam_encoder.blocks.3.norm1.weight grad: 0.001876720692962408
sam_encoder.blocks.3.norm1.bias grad: 0.0009570533875375986
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0016229975735768676
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00015793752390891314
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0010502387303858995
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0006169461994431913
sam_encoder.blocks.3.norm2.weight grad: 0.00228698062710464
sam_encoder.blocks.3.norm2.bias grad: -0.0010523336241021752
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0016955200117081404
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.3691572247771546e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00013460777699947357
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0001586687722010538
sam_encoder.blocks.4.norm1.weight grad: 0.0037221722304821014
sam_encoder.blocks.4.norm1.bias grad: -0.0019561881199479103
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0018822760321199894
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.000667577376589179
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0002755305031314492
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0011952714994549751
sam_encoder.blocks.4.norm2.weight grad: 0.007844597101211548
sam_encoder.blocks.4.norm2.bias grad: -0.0024732379242777824
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.003974318038672209
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0012265648692846298
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0013412400148808956
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0008658863371238112
sam_encoder.blocks.5.norm1.weight grad: 0.007496183272451162
sam_encoder.blocks.5.norm1.bias grad: -0.003471256233751774
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.004679539706557989
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0015055964468047023
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0009777680970728397
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0010930525604635477
sam_encoder.blocks.5.norm2.weight grad: 0.005397071596235037
sam_encoder.blocks.5.norm2.bias grad: 0.0010850141989067197
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0030619706958532333
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0012147234519943595
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0006839411216787994
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.0003702807880472392
sam_encoder.blocks.6.norm1.weight grad: -0.0014545483281835914
sam_encoder.blocks.6.norm1.bias grad: 0.0005199661827646196
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0011823386885225773
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00014232180546969175
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00048120348947122693
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0002941796265076846
sam_encoder.blocks.6.norm2.weight grad: -0.002025775145739317
sam_encoder.blocks.6.norm2.bias grad: -0.00030703283846378326
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.002671754453331232
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0013092923909425735
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0005238676676526666
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.000287950097117573
sam_encoder.blocks.7.norm1.weight grad: 0.0010783013422042131
sam_encoder.blocks.7.norm1.bias grad: 0.00015068764332681894
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0005062170675955713
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00033994190744124353
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0002452769549563527
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0008068416500464082
sam_encoder.blocks.7.norm2.weight grad: 0.0006599216721951962
sam_encoder.blocks.7.norm2.bias grad: -0.00012212728324811906
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00033189530950039625
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.0499286114936695e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.55164068727754e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.4682344044558704e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0020531362388283014
sam_encoder.blocks.8.norm1.bias grad: -0.00014372155419550836
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0026599587872624397
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0010153519688174129
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0010790879605337977
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.000191921106306836
sam_encoder.blocks.8.norm2.weight grad: 0.0019766269251704216
sam_encoder.blocks.8.norm2.bias grad: 0.0011632376117631793
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0007684965967200696
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0007017647731117904
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0006333610508590937
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0001785983331501484
sam_encoder.blocks.9.norm1.weight grad: 0.0017377017065882683
sam_encoder.blocks.9.norm1.bias grad: -8.742485078983009e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0012899597641080618
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0002828352153301239
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00037730549229308963
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0003749396128114313
sam_encoder.blocks.9.norm2.weight grad: 0.0008412705501541495
sam_encoder.blocks.9.norm2.bias grad: 0.0009306007414124906
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.98719993326813e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00027032376965507865
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0004958751378580928
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.0001632516214158386
sam_encoder.blocks.10.norm1.weight grad: 0.000797638320364058
sam_encoder.blocks.10.norm1.bias grad: -0.00029034039471298456
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0005564295570366085
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00014118829858489335
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0001695255923550576
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.0001561991812195629
sam_encoder.blocks.10.norm2.weight grad: 0.002614448545500636
sam_encoder.blocks.10.norm2.bias grad: 0.0015451479703187943
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.000805836811196059
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0006907630013301969
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0003447258786763996
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.100715785985813e-05
sam_encoder.blocks.11.norm1.weight grad: 0.005296815186738968
sam_encoder.blocks.11.norm1.bias grad: -0.00021903228480368853
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0031483944039791822
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0007796281715855002
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0009113062988035381
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0005952759529463947
sam_encoder.blocks.11.norm2.weight grad: 0.0023101235274225473
sam_encoder.blocks.11.norm2.bias grad: 0.0002071987109957263
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.000722344673704356
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0004972614115104079
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0002660857862792909
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.0003113238781224936
sam_encoder.neck.conv1.trainable_scale grad: 0.0004264563322067261
sam_encoder.neck.conv1.trainable_shift grad: 0.00305364653468132
sam_encoder.neck.conv2.trainable_scale grad: 0.000463258707895875
sam_encoder.neck.conv2.trainable_shift grad: 0.00537653686478734
mask_decoder.transformer.layers.0.norm1.weight grad: 0.09421852231025696
mask_decoder.transformer.layers.0.norm1.bias grad: 0.002227241173386574
mask_decoder.transformer.layers.0.norm2.weight grad: 0.49095287919044495
mask_decoder.transformer.layers.0.norm2.bias grad: -0.601190984249115
mask_decoder.transformer.layers.0.norm3.weight grad: 0.04040644317865372
mask_decoder.transformer.layers.0.norm3.bias grad: 0.009173786267638206
mask_decoder.transformer.layers.0.norm4.weight grad: -0.022284390404820442
mask_decoder.transformer.layers.0.norm4.bias grad: 0.001957463566213846
mask_decoder.transformer.layers.1.norm1.weight grad: -0.005490259267389774
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00030768377473577857
mask_decoder.transformer.layers.1.norm2.weight grad: -0.011774801649153233
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0005502691492438316
mask_decoder.transformer.layers.1.norm3.weight grad: -0.01573745720088482
mask_decoder.transformer.layers.1.norm3.bias grad: -0.009808916598558426
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002078397199511528
mask_decoder.transformer.layers.1.norm4.bias grad: 0.02914130873978138
mask_decoder.transformer.norm_final_attn.weight grad: -0.0001713302917778492
mask_decoder.transformer.norm_final_attn.bias grad: -0.0034286617301404476
Text_Embedding_Affine.0.weight grad: 7.555534864422953e-09
Text_Embedding_Affine.0.bias grad: 4.258617991581559e-07
Text_Embedding_Affine.2.weight grad: -1.1339623995354486e-07
Text_Embedding_Affine.2.bias grad: -0.031306516379117966

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.2776581448956676e-09
Max value: 0.9949285984039307
Mean value: 0.064093217253685

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.2776581448956676e-09
Max value: 0.9949285984039307
Mean value: 0.064093217253685

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08827781677246094

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.67835807800293
Max value: -1.1920928244535389e-07
Mean value: -0.16782212257385254

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.025608539581298828

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08827781677246094

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 1.1367902755737305
Max value: 60.640499114990234
Mean value: 18.228784561157227

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.2776581448956676e-09
Max value: 0.9949285984039307
Mean value: 0.064093217253685

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.2776581448956676e-09
Max value: 0.9949285984039307
Mean value: 0.064093217253685

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.2776581448956676e-09
Max value: 0.9949285984039307
Mean value: 0.064093217253685

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.67835807800293
Max value: -1.1920928244535389e-07
Mean value: -0.16782212257385254

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 1.1367902755737305
Max value: 60.640499114990234
Mean value: 18.228784561157227

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -18.230234146118164
Max value: -18.230234146118164
Mean value: -18.230234146118164
sam_encoder.pos_embed grad: 5.007716481486568e-07
sam_encoder.blocks.0.norm1.weight grad: 0.00021929728973191231
sam_encoder.blocks.0.norm1.bias grad: -0.007313364651054144
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0010523550445213914
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.2260504415025935e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00014296485460363328
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00035331383696757257
sam_encoder.blocks.0.norm2.weight grad: 0.0017577726393938065
sam_encoder.blocks.0.norm2.bias grad: 0.0010096419136971235
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.003650856902822852
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.497278369963169e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0032321286853402853
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0008471995824947953
sam_encoder.blocks.1.norm1.weight grad: -0.004868744872510433
sam_encoder.blocks.1.norm1.bias grad: 0.0010908815311267972
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0013311449438333511
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0005604451871477067
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0007970252772793174
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.000495895161293447
sam_encoder.blocks.1.norm2.weight grad: -0.003296868409961462
sam_encoder.blocks.1.norm2.bias grad: -0.0014060612302273512
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0006248762365430593
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.619892438815441e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0005197841674089432
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.1035972167737782e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0034187380224466324
sam_encoder.blocks.2.norm1.bias grad: 0.00035032181767746806
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0017749377293512225
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0003428283962421119
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.014679689134937e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.831637903000228e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0020462782122194767
sam_encoder.blocks.2.norm2.bias grad: 0.000514201121404767
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0015289400471374393
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0009354526991955936
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0008986206958070397
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00011208168871235102
sam_encoder.blocks.3.norm1.weight grad: -0.0007223355351015925
sam_encoder.blocks.3.norm1.bias grad: 0.0008824149845167994
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0013969283318147063
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00022068395628593862
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0005953589570708573
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.8791080694645643e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0021575698629021645
sam_encoder.blocks.3.norm2.bias grad: -0.00013957111514173448
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.001008524326607585
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7768263205653057e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.001327818026766181
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5250834621838294e-05
sam_encoder.blocks.4.norm1.weight grad: 0.001914994209073484
sam_encoder.blocks.4.norm1.bias grad: -0.0017315770965069532
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.000326292822137475
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001930226426338777
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0006544970674440265
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003465701302047819
sam_encoder.blocks.4.norm2.weight grad: 0.011182120069861412
sam_encoder.blocks.4.norm2.bias grad: 0.003608263097703457
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.005742218345403671
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0019806502386927605
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0009469869546592236
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.000775438267737627
sam_encoder.blocks.5.norm1.weight grad: 0.004676078911870718
sam_encoder.blocks.5.norm1.bias grad: -0.004161694552749395
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.003958744928240776
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0020763538777828217
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0005324463709257543
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.001095217070542276
sam_encoder.blocks.5.norm2.weight grad: 0.006647911854088306
sam_encoder.blocks.5.norm2.bias grad: 0.0024860689882189035
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0027951530646532774
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0010455435840412974
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0004367996589280665
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00031514550209976733
sam_encoder.blocks.6.norm1.weight grad: -0.000276690669124946
sam_encoder.blocks.6.norm1.bias grad: -0.0006640746723860502
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0002980052959173918
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0002706179511733353
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00036379863740876317
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.326782699441537e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0011535650119185448
sam_encoder.blocks.6.norm2.bias grad: -0.0004296902916394174
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.209903899114579e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0001519514771644026
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0004831322585232556
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.428345270454884e-05
sam_encoder.blocks.7.norm1.weight grad: -0.002153280656784773
sam_encoder.blocks.7.norm1.bias grad: 0.00035649057826958597
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.001609178027138114
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0006638558115810156
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00042735738679766655
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0004732109955511987
sam_encoder.blocks.7.norm2.weight grad: -0.00034108778345398605
sam_encoder.blocks.7.norm2.bias grad: -0.0002827696444001049
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0017962781712412834
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.000618880323600024
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.73019715375267e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00023497894289903343
sam_encoder.blocks.8.norm1.weight grad: -0.0009603187791071832
sam_encoder.blocks.8.norm1.bias grad: -0.00010343197209294885
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0002462103730067611
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0005113893421366811
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00023705660714767873
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.7895526222418994e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0009291458409279585
sam_encoder.blocks.8.norm2.bias grad: 0.0009380168048664927
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.56198288500309e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00030880511621944606
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0004638812388293445
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0003657554916571826
sam_encoder.blocks.9.norm1.weight grad: 0.0006082031759433448
sam_encoder.blocks.9.norm1.bias grad: -0.00010686105815693736
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00019200069073121995
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0001587675797054544
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.104629624634981e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0004652197821997106
sam_encoder.blocks.9.norm2.weight grad: -0.0003755396173801273
sam_encoder.blocks.9.norm2.bias grad: 0.0006075989222154021
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0011592586524784565
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0002582089218776673
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.000546503288205713
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.10744032706134e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0008316760649904609
sam_encoder.blocks.10.norm1.bias grad: -0.0004140692763030529
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0006153138820081949
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00031287773163057864
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0005904521676711738
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00028852798277512193
sam_encoder.blocks.10.norm2.weight grad: -0.0007174283964559436
sam_encoder.blocks.10.norm2.bias grad: 0.0006905024638399482
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.000828184827696532
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00034655522904358804
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.4919787645339966e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.00010732556984294206
sam_encoder.blocks.11.norm1.weight grad: -0.004567556083202362
sam_encoder.blocks.11.norm1.bias grad: -0.0002918253594543785
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00023405533283948898
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0001392739941366017
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00024112683604471385
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.875264544854872e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0008256749133579433
sam_encoder.blocks.11.norm2.bias grad: -0.0004477599577512592
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0005980394198559225
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.671296872198582e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00013113109162077308
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00020121810666751117
sam_encoder.neck.conv1.trainable_scale grad: 0.0005176663398742676
sam_encoder.neck.conv1.trainable_shift grad: 0.0011929068714380264
sam_encoder.neck.conv2.trainable_scale grad: 0.0006135532166808844
sam_encoder.neck.conv2.trainable_shift grad: 0.0003184268716722727
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0780213475227356
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0022553829476237297
mask_decoder.transformer.layers.0.norm2.weight grad: 1.4016176462173462
mask_decoder.transformer.layers.0.norm2.bias grad: -0.25542378425598145
mask_decoder.transformer.layers.0.norm3.weight grad: 0.031057175248861313
mask_decoder.transformer.layers.0.norm3.bias grad: 0.021301668137311935
mask_decoder.transformer.layers.0.norm4.weight grad: -0.038260653614997864
mask_decoder.transformer.layers.0.norm4.bias grad: 0.006317871622741222
mask_decoder.transformer.layers.1.norm1.weight grad: -0.001949384924955666
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0018291729502379894
mask_decoder.transformer.layers.1.norm2.weight grad: 0.05399543419480324
mask_decoder.transformer.layers.1.norm2.bias grad: 0.01803387701511383
mask_decoder.transformer.layers.1.norm3.weight grad: -0.007073613349348307
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0009336960501968861
mask_decoder.transformer.layers.1.norm4.weight grad: 0.010627818293869495
mask_decoder.transformer.layers.1.norm4.bias grad: 0.06526662409305573
mask_decoder.transformer.norm_final_attn.weight grad: 0.00043245049891993403
mask_decoder.transformer.norm_final_attn.bias grad: -0.00562680559232831
Text_Embedding_Affine.0.weight grad: 6.9038641470342554e-09
Text_Embedding_Affine.0.bias grad: 1.7136335372924805e-07
Text_Embedding_Affine.2.weight grad: -1.1791034637553821e-07
Text_Embedding_Affine.2.bias grad: -0.02775443345308304

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.9285359087461984e-07
Max value: 0.9603707194328308
Mean value: 0.05550109222531319

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9285359087461984e-07
Max value: 0.9603707194328308
Mean value: 0.05550109222531319

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0663309097290039

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -9.772149085998535
Max value: -2.3841855067985307e-07
Mean value: -0.1361677646636963

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.01430511474609375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0663309097290039

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 9.078638076782227
Max value: 26.42231559753418
Mean value: 20.67612075805664

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.9285359087461984e-07
Max value: 0.9603707194328308
Mean value: 0.05550109222531319

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9285359087461984e-07
Max value: 0.9603707194328308
Mean value: 0.05550109222531319

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9285359087461984e-07
Max value: 0.9603707194328308
Mean value: 0.05550109222531319

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -9.772149085998535
Max value: -2.3841855067985307e-07
Mean value: -0.1361677646636963

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 9.078638076782227
Max value: 26.42231559753418
Mean value: 20.67612075805664

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -20.67755699157715
Max value: -20.67755699157715
Mean value: -20.67755699157715
sam_encoder.pos_embed grad: -7.442896787779318e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0043978383764624596
sam_encoder.blocks.0.norm1.bias grad: 0.00024248698900919408
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0001736769627314061
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8157417798647657e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0001840664481278509
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.3870852096006274e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0018469443311914802
sam_encoder.blocks.0.norm2.bias grad: 0.00191326008643955
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.00042953933007083833
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.804919444723055e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0008624140173196793
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0005480658728629351
sam_encoder.blocks.1.norm1.weight grad: -0.0009469207725487649
sam_encoder.blocks.1.norm1.bias grad: -0.0004394033458083868
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0003483294858597219
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00017537272651679814
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0002017799997702241
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0001443870714865625
sam_encoder.blocks.1.norm2.weight grad: 0.0004138315562158823
sam_encoder.blocks.1.norm2.bias grad: -0.0005167709896340966
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.045082833836204e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.348905374878086e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.9123587561771274e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00012823910219594836
sam_encoder.blocks.2.norm1.weight grad: 0.0003611879365053028
sam_encoder.blocks.2.norm1.bias grad: 0.00022039350005798042
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.449471402447671e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.5095798516995274e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 9.407522156834602e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.15305723133497e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0008753659203648567
sam_encoder.blocks.2.norm2.bias grad: -0.0006914125988259912
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0006502947653643787
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0002366997505305335
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.7680653147399426e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6181976863881573e-05
sam_encoder.blocks.3.norm1.weight grad: 0.00019907169917132705
sam_encoder.blocks.3.norm1.bias grad: 0.00028952606953680515
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00013150843733455986
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.054739449406043e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.368173515307717e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.201266281394055e-06
sam_encoder.blocks.3.norm2.weight grad: 0.0006116530857980251
sam_encoder.blocks.3.norm2.bias grad: 0.0001850078406278044
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.000407032755902037
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0001454173179809004
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0003815374511759728
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.202130003250204e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0008853026083670557
sam_encoder.blocks.4.norm1.bias grad: -0.00016287612379528582
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005495111108757555
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00016355937987100333
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00024890556233003736
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.000165906545589678
sam_encoder.blocks.4.norm2.weight grad: -0.0008471172186546028
sam_encoder.blocks.4.norm2.bias grad: -0.0007921908400021493
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0005753902951255441
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00020507595036178827
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00012352815247140825
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.2624883311218582e-05
sam_encoder.blocks.5.norm1.weight grad: 0.001443532295525074
sam_encoder.blocks.5.norm1.bias grad: -0.0001543730468256399
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0009371209307573736
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0001806163345463574
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00019994840840809047
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0002303963847225532
sam_encoder.blocks.5.norm2.weight grad: -0.0004940639482811093
sam_encoder.blocks.5.norm2.bias grad: 0.00013451439735945314
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00032406733953393996
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00012071874516550452
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.000132028988446109
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.4691587239212822e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00010460187331773341
sam_encoder.blocks.6.norm1.bias grad: 0.00023603664885740727
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00024371757172048092
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.58798302942887e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.937094051158056e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00012046549090882763
sam_encoder.blocks.6.norm2.weight grad: -0.0001025372403091751
sam_encoder.blocks.6.norm2.bias grad: 0.00010038838809123263
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00027823762502521276
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00015960424207150936
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00013208040036261082
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0292376373399748e-06
sam_encoder.blocks.7.norm1.weight grad: 0.0005494270008057356
sam_encoder.blocks.7.norm1.bias grad: 4.5118700654711574e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0003412840305827558
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00017904062406159937
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.51851694076322e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0117006240761839e-05
sam_encoder.blocks.7.norm2.weight grad: -0.00014418666251003742
sam_encoder.blocks.7.norm2.bias grad: -7.175437349360436e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.183046207297593e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.864227179903537e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.976085230940953e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.9851551769534126e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00037512555718421936
sam_encoder.blocks.8.norm1.bias grad: 3.5532219044398516e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00021718625794164836
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.831504677189514e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.462265107780695e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00014467790606431663
sam_encoder.blocks.8.norm2.weight grad: -1.5479648709515459e-06
sam_encoder.blocks.8.norm2.bias grad: -2.10550642805174e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.129968096502125e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.073614763910882e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.73752510920167e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.8016206013271585e-05
sam_encoder.blocks.9.norm1.weight grad: 0.00022351798543240875
sam_encoder.blocks.9.norm1.bias grad: -3.480376835796051e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0002031722542596981
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.7701884391717613e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.460816176608205e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.5868688428308815e-06
sam_encoder.blocks.9.norm2.weight grad: 0.0001611955522093922
sam_encoder.blocks.9.norm2.bias grad: 9.052302630152553e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.687027052976191e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00011829871073132381
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.417402907274663e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.415367458132096e-06
sam_encoder.blocks.10.norm1.weight grad: 0.00013389464584179223
sam_encoder.blocks.10.norm1.bias grad: 7.514168100897223e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0001338955626124516
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.521295290440321e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.845566657721065e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.8549633750808425e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0001818760356400162
sam_encoder.blocks.10.norm2.bias grad: 0.00010876310989260674
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.302248377527576e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.602002344559878e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.912970952223986e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 9.051851520780474e-06
sam_encoder.blocks.11.norm1.weight grad: 0.00040218705544248223
sam_encoder.blocks.11.norm1.bias grad: 0.0001908412523334846
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002081136335618794
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.933853076887317e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00011355333117535338
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.788694498827681e-05
sam_encoder.blocks.11.norm2.weight grad: -0.00023719805176369846
sam_encoder.blocks.11.norm2.bias grad: -2.2563759557669982e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.744537237565964e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.8041784642264247e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.690963007509708e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.140697142749559e-05
sam_encoder.neck.conv1.trainable_scale grad: 5.251506809145212e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0010431725531816483
sam_encoder.neck.conv2.trainable_scale grad: -2.819439396262169e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.002784215146675706
mask_decoder.transformer.layers.0.norm1.weight grad: 0.01423135306686163
mask_decoder.transformer.layers.0.norm1.bias grad: 5.3987838327884674e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.09059101343154907
mask_decoder.transformer.layers.0.norm2.bias grad: -0.11161251366138458
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0056442273780703545
mask_decoder.transformer.layers.0.norm3.bias grad: -0.002243878785520792
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0025694044306874275
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0003745369613170624
mask_decoder.transformer.layers.1.norm1.weight grad: -0.00013138086069375277
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0003157674509566277
mask_decoder.transformer.layers.1.norm2.weight grad: -0.007692271843552589
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0005386749980971217
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0008288358803838491
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0026822437066584826
mask_decoder.transformer.layers.1.norm4.weight grad: -0.003539037425071001
mask_decoder.transformer.layers.1.norm4.bias grad: -0.009097946807742119
mask_decoder.transformer.norm_final_attn.weight grad: -0.0002814781037159264
mask_decoder.transformer.norm_final_attn.bias grad: 6.436583498725668e-05
Text_Embedding_Affine.0.weight grad: -3.1511055986754855e-09
Text_Embedding_Affine.0.bias grad: -8.923234418034554e-08
Text_Embedding_Affine.2.weight grad: 1.3337198012663976e-08
Text_Embedding_Affine.2.bias grad: -0.0034807343035936356
Epoch 10 finished with average loss: -29.1552
Epoch 11/39
----------
Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/3 [00:01<?, ?it/s, loss=-27.7]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.03s/it, loss=-27.7]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.03s/it, loss=-35.9]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.52it/s, loss=-35.9]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.52it/s, loss=-28.4]Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.13it/s, loss=-28.4]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.429434927847979e-10
Max value: 0.9959153532981873
Mean value: 0.058652568608522415

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.429434927847979e-10
Max value: 0.9959153532981873
Mean value: 0.058652568608522415

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0821371078491211

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.964203834533691
Max value: -1.1920928244535389e-07
Mean value: -0.17511491477489471

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04155731201171875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0821371078491211

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.13421936333179474
Max value: 65.58533477783203
Mean value: 27.651437759399414

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.429434927847979e-10
Max value: 0.9959153532981873
Mean value: 0.058652568608522415

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.429434927847979e-10
Max value: 0.9959153532981873
Mean value: 0.058652568608522415

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.429434927847979e-10
Max value: 0.9959153532981873
Mean value: 0.058652568608522415

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.964203834533691
Max value: -1.1920928244535389e-07
Mean value: -0.17511491477489471

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.13421936333179474
Max value: 65.58533477783203
Mean value: 27.651437759399414

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -27.652568817138672
Max value: -27.652568817138672
Mean value: -27.652568817138672
sam_encoder.pos_embed grad: -3.524596081661002e-07
sam_encoder.blocks.0.norm1.weight grad: -0.011289311572909355
sam_encoder.blocks.0.norm1.bias grad: -0.0007127433782443404
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0008717612363398075
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.543576455442235e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00020626417244784534
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00019506900571286678
sam_encoder.blocks.0.norm2.weight grad: 0.0006417686818167567
sam_encoder.blocks.0.norm2.bias grad: 0.005254791118204594
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.00042003937414847314
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00016945073730312288
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0014348080148920417
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00045817659702152014
sam_encoder.blocks.1.norm1.weight grad: -0.0023155007511377335
sam_encoder.blocks.1.norm1.bias grad: 0.0006884449976496398
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005010315217077732
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00022736027312930673
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00035142828710377216
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.600148092024028e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0015059267170727253
sam_encoder.blocks.1.norm2.bias grad: -0.0012538759037852287
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00026089706807397306
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001652344799367711
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.00011230596282985061
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0001915143511723727
sam_encoder.blocks.2.norm1.weight grad: 0.0013519530184566975
sam_encoder.blocks.2.norm1.bias grad: -0.0004502320662140846
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0007210129406303167
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00025731921778060496
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 8.211936801671982e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00015096209244802594
sam_encoder.blocks.2.norm2.weight grad: 0.0026419255882501602
sam_encoder.blocks.2.norm2.bias grad: -0.0006006431649439037
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0012565493816509843
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00037526217056438327
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00019714533118531108
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.2529969757888466e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0008725707302801311
sam_encoder.blocks.3.norm1.bias grad: -0.0009493903489783406
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0004155577044002712
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.451034692465328e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00028879716410301626
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.000170910672750324
sam_encoder.blocks.3.norm2.weight grad: 0.0010982629610225558
sam_encoder.blocks.3.norm2.bias grad: -0.00022941408678889275
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.000828998105134815
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.000283111265162006
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0002345892135053873
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00015444858581759036
sam_encoder.blocks.4.norm1.weight grad: 0.0009439423447474837
sam_encoder.blocks.4.norm1.bias grad: -0.0013436130248010159
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0008054031059145927
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002586185873951763
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.000391353911254555
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0004028109833598137
sam_encoder.blocks.4.norm2.weight grad: -0.000437870214227587
sam_encoder.blocks.4.norm2.bias grad: -0.0019725593738257885
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0003685285337269306
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00013023873907513916
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0003427411138545722
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.771211625775322e-05
sam_encoder.blocks.5.norm1.weight grad: 0.00033410347532480955
sam_encoder.blocks.5.norm1.bias grad: -0.0005938632530160248
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.000185248427442275
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00020130157645326108
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0003072495455853641
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00012789831089321524
sam_encoder.blocks.5.norm2.weight grad: 6.145394581835717e-05
sam_encoder.blocks.5.norm2.bias grad: -0.00045060072443448007
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00029399985214695334
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0001344866759609431
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001925571559695527
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.762243431992829e-05
sam_encoder.blocks.6.norm1.weight grad: -9.184853115584701e-05
sam_encoder.blocks.6.norm1.bias grad: 0.00045449205208569765
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00017258062143810093
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.012323552160524e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.2609804950188845e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00013613997725769877
sam_encoder.blocks.6.norm2.weight grad: -0.0008363540982827544
sam_encoder.blocks.6.norm2.bias grad: -0.00038771063555032015
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0005350644933059812
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00024237189791165292
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.4305007173097692e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.091784209478647e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0007052444270811975
sam_encoder.blocks.7.norm1.bias grad: -3.369018668308854e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00047179218381643295
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00029377659666351974
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00015420922136399895
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00017190467042382807
sam_encoder.blocks.7.norm2.weight grad: -0.0002454977948218584
sam_encoder.blocks.7.norm2.bias grad: 0.00012759037781506777
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00012012175284326077
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.360119004966691e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.028704905882478e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.514077100902796e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00033873700886033475
sam_encoder.blocks.8.norm1.bias grad: -7.107264536898583e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00017483756528235972
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.033986624563113e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00016920237976592034
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.010007619901444e-06
sam_encoder.blocks.8.norm2.weight grad: 0.0005026315338909626
sam_encoder.blocks.8.norm2.bias grad: 0.00010128546273335814
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0004789337399415672
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00031242435215972364
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0003522514016367495
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0001286140613956377
sam_encoder.blocks.9.norm1.weight grad: -7.583791739307344e-05
sam_encoder.blocks.9.norm1.bias grad: 1.6688660252839327e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.323347381316125e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.3694461055565625e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.904910358367488e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.7375859897583723e-06
sam_encoder.blocks.9.norm2.weight grad: 0.0006402389262802899
sam_encoder.blocks.9.norm2.bias grad: 0.00028560819919221103
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0003434095997363329
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00036694196751341224
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00013887298700865358
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.9296028515091166e-05
sam_encoder.blocks.10.norm1.weight grad: -4.569082739180885e-05
sam_encoder.blocks.10.norm1.bias grad: -3.890521475113928e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00010667830792954192
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00010937861952697858
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.7915952412295155e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.776557084871456e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0008679952006787062
sam_encoder.blocks.10.norm2.bias grad: 0.00033842812990769744
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00029873778112232685
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0002629342197906226
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0002896175137721002
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.407784530892968e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0003835017269011587
sam_encoder.blocks.11.norm1.bias grad: 4.9847130867419764e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.1358332812960725e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.043159085791558e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.5646073734387755e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.664583194535226e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0010153827024623752
sam_encoder.blocks.11.norm2.bias grad: 0.00018326856661587954
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00022805834305472672
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00015636003809049726
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00017638082499615848
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.0001487094268668443
sam_encoder.neck.conv1.trainable_scale grad: 0.00016873347340151668
sam_encoder.neck.conv1.trainable_shift grad: 0.0006042335880920291
sam_encoder.neck.conv2.trainable_scale grad: 0.00011106953024864197
sam_encoder.neck.conv2.trainable_shift grad: -0.0009957144502550364
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0224713534116745
mask_decoder.transformer.layers.0.norm1.bias grad: 0.000715126283466816
mask_decoder.transformer.layers.0.norm2.weight grad: -0.23042604327201843
mask_decoder.transformer.layers.0.norm2.bias grad: -0.22740866243839264
mask_decoder.transformer.layers.0.norm3.weight grad: 0.008645888417959213
mask_decoder.transformer.layers.0.norm3.bias grad: -0.003440086729824543
mask_decoder.transformer.layers.0.norm4.weight grad: 0.005724085494875908
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0005910261534154415
mask_decoder.transformer.layers.1.norm1.weight grad: -0.000641959544736892
mask_decoder.transformer.layers.1.norm1.bias grad: 0.00018891936633735895
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0037718075327575207
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00170808844268322
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0007623287383466959
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0009833327494561672
mask_decoder.transformer.layers.1.norm4.weight grad: -0.006404305808246136
mask_decoder.transformer.layers.1.norm4.bias grad: -0.012406476773321629
mask_decoder.transformer.norm_final_attn.weight grad: -0.00036305160028859973
mask_decoder.transformer.norm_final_attn.bias grad: -7.292999362107366e-05
Text_Embedding_Affine.0.weight grad: -9.035732717599387e-10
Text_Embedding_Affine.0.bias grad: -1.798616722226143e-08
Text_Embedding_Affine.2.weight grad: 3.5645746354617813e-09
Text_Embedding_Affine.2.bias grad: -0.008269676007330418

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.304621186752456e-09
Max value: 0.9977534413337708
Mean value: 0.0886894017457962

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.304621186752456e-09
Max value: 0.9977534413337708
Mean value: 0.0886894017457962

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09434318542480469

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.541725158691406
Max value: -1.1920928244535389e-07
Mean value: -0.13501997292041779

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.062079429626464844

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09434318542480469

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 3.9629409313201904
Max value: 82.68949890136719
Mean value: 44.08344268798828

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.304621186752456e-09
Max value: 0.9977534413337708
Mean value: 0.0886894017457962

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.304621186752456e-09
Max value: 0.9977534413337708
Mean value: 0.0886894017457962

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.304621186752456e-09
Max value: 0.9977534413337708
Mean value: 0.0886894017457962

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.541725158691406
Max value: -1.1920928244535389e-07
Mean value: -0.13501997292041779

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 3.9629409313201904
Max value: 82.68949890136719
Mean value: 44.08344268798828

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -44.08502960205078
Max value: -44.08502960205078
Mean value: -44.08502960205078
sam_encoder.pos_embed grad: -3.068006151352165e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0028938259929418564
sam_encoder.blocks.0.norm1.bias grad: -0.008650332689285278
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0010534253669902682
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.7532418243936263e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0010311842197552323
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.124247814412229e-05
sam_encoder.blocks.0.norm2.weight grad: 0.00753436703234911
sam_encoder.blocks.0.norm2.bias grad: 0.011847013607621193
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0005247941007837653
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0001263576268684119
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.001327018457232e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0007148440345190465
sam_encoder.blocks.1.norm1.weight grad: -0.0007708437042310834
sam_encoder.blocks.1.norm1.bias grad: 0.0003510509559419006
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005031374748796225
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0001591356995049864
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0008723902283236384
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00016889689140953124
sam_encoder.blocks.1.norm2.weight grad: 0.001611592946574092
sam_encoder.blocks.1.norm2.bias grad: -0.0014121781568974257
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0004903806839138269
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00032869758433662355
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0015085077611729503
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.000338938640197739
sam_encoder.blocks.2.norm1.weight grad: 0.0004775864945258945
sam_encoder.blocks.2.norm1.bias grad: 0.0018599294126033783
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00027173664420843124
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.130357046960853e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00034897433943115175
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0004605614230968058
sam_encoder.blocks.2.norm2.weight grad: 0.00013468111865222454
sam_encoder.blocks.2.norm2.bias grad: 0.00036844771238975227
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0005604905309155583
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00017195969121530652
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0012066455092281103
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.0002758830669336021
sam_encoder.blocks.3.norm1.weight grad: 0.0010965176625177264
sam_encoder.blocks.3.norm1.bias grad: -0.00033343344694003463
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0016184670384973288
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0002855375059880316
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0012992838164791465
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0005102248396724463
sam_encoder.blocks.3.norm2.weight grad: 0.0025312406942248344
sam_encoder.blocks.3.norm2.bias grad: 0.0010861930204555392
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.002015891019254923
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0007063184748403728
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0004559297813102603
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.070913514122367e-05
sam_encoder.blocks.4.norm1.weight grad: -0.0010222462005913258
sam_encoder.blocks.4.norm1.bias grad: -0.0018797777593135834
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00029802994686178863
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00014153988740872592
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.934327343013138e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00046463447506539524
sam_encoder.blocks.4.norm2.weight grad: 0.0031399186700582504
sam_encoder.blocks.4.norm2.bias grad: 0.00032715644920244813
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0019480986520648003
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0006153016001917422
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0007691401406191289
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0004292376106604934
sam_encoder.blocks.5.norm1.weight grad: 0.00017576731625013053
sam_encoder.blocks.5.norm1.bias grad: -0.0010497915791347623
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00010179651144426316
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00031158849014900625
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00034692007466219366
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0002670817484613508
sam_encoder.blocks.5.norm2.weight grad: 0.003060112474486232
sam_encoder.blocks.5.norm2.bias grad: 6.0394562751753256e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0015127293299883604
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0006101694889366627
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00024250055139418691
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00015558973245788366
sam_encoder.blocks.6.norm1.weight grad: -0.0005483075510710478
sam_encoder.blocks.6.norm1.bias grad: 0.0001507316919742152
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00048129225615411997
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.7318525351583958e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0002827296848408878
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0002460456744302064
sam_encoder.blocks.6.norm2.weight grad: -0.0005987279582768679
sam_encoder.blocks.6.norm2.bias grad: -3.9184855268104e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0008011896861717105
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00027328659780323505
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0005010526510886848
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.8413576981402002e-05
sam_encoder.blocks.7.norm1.weight grad: 6.396153185050935e-05
sam_encoder.blocks.7.norm1.bias grad: 7.859525067033246e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.317348844371736e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00021854275837540627
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0004019641492050141
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0005879513919353485
sam_encoder.blocks.7.norm2.weight grad: -0.0004978051874786615
sam_encoder.blocks.7.norm2.bias grad: 0.00017335612210445106
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0005462864646688104
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00016124642570503056
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00017195814871229231
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.6630688807927072e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0013543324312195182
sam_encoder.blocks.8.norm1.bias grad: 0.00032122209086082876
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.001399112632498145
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0004666207532864064
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00041275389958173037
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00019246910233050585
sam_encoder.blocks.8.norm2.weight grad: 0.0005159845459274948
sam_encoder.blocks.8.norm2.bias grad: 4.872633144259453e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0003726175636984408
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00022404646733775735
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00040591158904135227
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00024270002904813737
sam_encoder.blocks.9.norm1.weight grad: 0.00043753761565312743
sam_encoder.blocks.9.norm1.bias grad: -3.784587897825986e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00026503438130021095
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.58265086915344e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00016412767581641674
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00031805364415049553
sam_encoder.blocks.9.norm2.weight grad: 0.0002457004156894982
sam_encoder.blocks.9.norm2.bias grad: 0.00021649859263561666
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.315304876305163e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.184939876315184e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.936080171726644e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.1930813090875745e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0005672356346622109
sam_encoder.blocks.10.norm1.bias grad: -0.00023214238171931356
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00041848173714242876
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0001511625450802967
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.752378350123763e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.035800935118459e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0006814414518885314
sam_encoder.blocks.10.norm2.bias grad: 0.0004997529904358089
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.6175908967852592e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00027440302073955536
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0001632898347452283
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.237363322725287e-06
sam_encoder.blocks.11.norm1.weight grad: -0.0017942333361133933
sam_encoder.blocks.11.norm1.bias grad: 0.00016148792929016054
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0010071417782455683
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0001563100377097726
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.9716582503169775e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.755401020403951e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0003748814051505178
sam_encoder.blocks.11.norm2.bias grad: -0.0003225861000828445
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00010895157174672931
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.7519565517432056e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.261622623540461e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.476396033074707e-05
sam_encoder.neck.conv1.trainable_scale grad: 0.00024237995967268944
sam_encoder.neck.conv1.trainable_shift grad: -0.002800030866637826
sam_encoder.neck.conv2.trainable_scale grad: -1.1139549314975739e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.01047026738524437
mask_decoder.transformer.layers.0.norm1.weight grad: 0.026949182152748108
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0007227156311273575
mask_decoder.transformer.layers.0.norm2.weight grad: -0.4590822160243988
mask_decoder.transformer.layers.0.norm2.bias grad: -0.2792946696281433
mask_decoder.transformer.layers.0.norm3.weight grad: -0.004793945699930191
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00493268296122551
mask_decoder.transformer.layers.0.norm4.weight grad: -0.002028966322541237
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0007310408400371671
mask_decoder.transformer.layers.1.norm1.weight grad: 0.002864934504032135
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00012169661931693554
mask_decoder.transformer.layers.1.norm2.weight grad: -0.007461404427886009
mask_decoder.transformer.layers.1.norm2.bias grad: 0.003660469548776746
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00363524304702878
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0008034536149352789
mask_decoder.transformer.layers.1.norm4.weight grad: -0.004130541812628508
mask_decoder.transformer.layers.1.norm4.bias grad: -0.012151340022683144
mask_decoder.transformer.norm_final_attn.weight grad: -6.221622606972232e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.570073411334306e-05
Text_Embedding_Affine.0.weight grad: -3.863518394098264e-09
Text_Embedding_Affine.0.bias grad: -6.85686245560646e-08
Text_Embedding_Affine.2.weight grad: -4.837319522721373e-08
Text_Embedding_Affine.2.bias grad: -0.011846384033560753

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.782699626280305e-09
Max value: 0.9809417724609375
Mean value: 0.03247392922639847

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.782699626280305e-09
Max value: 0.9809417724609375
Mean value: 0.03247392922639847

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06504249572753906

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.010915756225586
Max value: -1.1920928244535389e-07
Mean value: -0.1392425298690796

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.00835418701171875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06504249572753906

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 0.5414012670516968
Max value: 23.30838394165039
Mean value: 13.580018997192383

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.782699626280305e-09
Max value: 0.9809417724609375
Mean value: 0.03247392922639847

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.782699626280305e-09
Max value: 0.9809417724609375
Mean value: 0.03247392922639847

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.782699626280305e-09
Max value: 0.9809417724609375
Mean value: 0.03247392922639847

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.010915756225586
Max value: -1.1920928244535389e-07
Mean value: -0.1392425298690796

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 0.5414012670516968
Max value: 23.30838394165039
Mean value: 13.580018997192383

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -13.580852508544922
Max value: -13.580852508544922
Mean value: -13.580852508544922
sam_encoder.pos_embed grad: -1.0249277693219483e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0032173646613955498
sam_encoder.blocks.0.norm1.bias grad: -0.0046624718233942986
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00042853341437876225
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.3664600778138265e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0016418187879025936
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0003488179063424468
sam_encoder.blocks.0.norm2.weight grad: -0.00450860196724534
sam_encoder.blocks.0.norm2.bias grad: 0.011864593252539635
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.00413371529430151
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.001087454380467534
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.842050839215517e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.6622750536043895e-06
sam_encoder.blocks.1.norm1.weight grad: -0.003757501719519496
sam_encoder.blocks.1.norm1.bias grad: 0.0004234920197632164
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0006568531389348209
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.000335881719365716
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00036795949563384056
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.59282086417079e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0008374598110094666
sam_encoder.blocks.1.norm2.bias grad: -0.0012263467069715261
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00023283634800463915
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.000183412543265149
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0010893084108829498
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.3286654797848314e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0006101005128584802
sam_encoder.blocks.2.norm1.bias grad: 0.00021900897263549268
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00030905933817848563
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.919776205904782e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00034012386458925903
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 6.261897215154022e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0027515075635164976
sam_encoder.blocks.2.norm2.bias grad: -0.0010766783962026238
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.002215823158621788
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.000888291688170284
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0004971453454345465
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00014188523346092552
sam_encoder.blocks.3.norm1.weight grad: 3.0336746931425296e-05
sam_encoder.blocks.3.norm1.bias grad: 0.0008479037205688655
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.000927732209675014
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00024988685618154705
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0008900294778868556
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0002946229069493711
sam_encoder.blocks.3.norm2.weight grad: 0.0014680258464068174
sam_encoder.blocks.3.norm2.bias grad: -0.0014032514300197363
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0008659883751533926
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.000311363663058728
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0006476802518591285
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0003643454983830452
sam_encoder.blocks.4.norm1.weight grad: 0.0003050658851861954
sam_encoder.blocks.4.norm1.bias grad: -0.0014412335585802794
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.935943798045628e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002414994960417971
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00013678031973540783
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00033994473051279783
sam_encoder.blocks.4.norm2.weight grad: 0.0036579943262040615
sam_encoder.blocks.4.norm2.bias grad: 0.0030224097426980734
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0020503809209913015
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0007284833118319511
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0006176067399792373
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00038502513780258596
sam_encoder.blocks.5.norm1.weight grad: 0.0024319207295775414
sam_encoder.blocks.5.norm1.bias grad: -0.002688019536435604
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0017455078195780516
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0009277663193643093
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.967471275245771e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0005211930256336927
sam_encoder.blocks.5.norm2.weight grad: 0.005149616859853268
sam_encoder.blocks.5.norm2.bias grad: 0.0025839798618108034
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.002401786856353283
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0009931153617799282
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0003279875381849706
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00015616673044860363
sam_encoder.blocks.6.norm1.weight grad: 0.001055659493431449
sam_encoder.blocks.6.norm1.bias grad: -0.0006389734335243702
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0004468727274797857
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003021884767804295
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.526805918838363e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.647747356211767e-05
sam_encoder.blocks.6.norm2.weight grad: 0.000992097775451839
sam_encoder.blocks.6.norm2.bias grad: 0.0002155149995815009
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0004717958508990705
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.761216743849218e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.1203445764258504e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00011854057083837688
sam_encoder.blocks.7.norm1.weight grad: -0.0003691845340654254
sam_encoder.blocks.7.norm1.bias grad: -0.00012817290553357452
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00038623163709416986
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00010279740672558546
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00010967619891744107
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00019624922424554825
sam_encoder.blocks.7.norm2.weight grad: -0.00020685148774646223
sam_encoder.blocks.7.norm2.bias grad: -0.00028500918415375054
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0004526017582975328
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002692965790629387
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.170893513830379e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00010290077625541016
sam_encoder.blocks.8.norm1.weight grad: -0.0006108389934524894
sam_encoder.blocks.8.norm1.bias grad: 0.00013843848137184978
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0004985883133485913
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.707315823296085e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00027602852787822485
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00017787422984838486
sam_encoder.blocks.8.norm2.weight grad: 0.0010721076978370547
sam_encoder.blocks.8.norm2.bias grad: 0.00030651138513348997
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0005194828845560551
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0004891134449280798
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0005265476647764444
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0002666336658876389
sam_encoder.blocks.9.norm1.weight grad: 0.0005611873930320144
sam_encoder.blocks.9.norm1.bias grad: -1.7115226000896655e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00048450700705870986
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.557152952766046e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00013300850696396083
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00030112540116533637
sam_encoder.blocks.9.norm2.weight grad: 0.0008826252887956798
sam_encoder.blocks.9.norm2.bias grad: 0.0007415571599267423
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0001111027886508964
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0004875542945228517
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0003040917217731476
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.000127595427329652
sam_encoder.blocks.10.norm1.weight grad: -0.00030443124705925584
sam_encoder.blocks.10.norm1.bias grad: 5.135456012794748e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00010285926691722125
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.188448656350374e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00024538260186091065
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00016549148131161928
sam_encoder.blocks.10.norm2.weight grad: 0.0006900345324538648
sam_encoder.blocks.10.norm2.bias grad: 0.0008401029626838863
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0002665711217559874
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0001744661567499861
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0001577158400323242
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.9955583158880472e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0013745593605563045
sam_encoder.blocks.11.norm1.bias grad: 0.00037886653444729745
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00024228512484114617
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.067681053740671e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.976310346042737e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.528171797981486e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0005307410610839725
sam_encoder.blocks.11.norm2.bias grad: 0.00010499226482352242
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00021662833751179278
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00019361174781806767
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00029784999787807465
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00018099404405802488
sam_encoder.neck.conv1.trainable_scale grad: 0.0003194175660610199
sam_encoder.neck.conv1.trainable_shift grad: 0.00106535863596946
sam_encoder.neck.conv2.trainable_scale grad: 0.00022287247702479362
sam_encoder.neck.conv2.trainable_shift grad: -0.015461210161447525
mask_decoder.transformer.layers.0.norm1.weight grad: 0.043006572872400284
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0002469755709171295
mask_decoder.transformer.layers.0.norm2.weight grad: 0.7213490009307861
mask_decoder.transformer.layers.0.norm2.bias grad: -0.26375889778137207
mask_decoder.transformer.layers.0.norm3.weight grad: 0.013446655124425888
mask_decoder.transformer.layers.0.norm3.bias grad: -0.004816431552171707
mask_decoder.transformer.layers.0.norm4.weight grad: -0.011933651752769947
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0008510029874742031
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0036015601363033056
mask_decoder.transformer.layers.1.norm1.bias grad: 7.165828719735146e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.03675571829080582
mask_decoder.transformer.layers.1.norm2.bias grad: -0.010598389431834221
mask_decoder.transformer.layers.1.norm3.weight grad: -0.012490404769778252
mask_decoder.transformer.layers.1.norm3.bias grad: -0.009409056045114994
mask_decoder.transformer.layers.1.norm4.weight grad: -0.000505638075992465
mask_decoder.transformer.layers.1.norm4.bias grad: 0.016255073249340057
mask_decoder.transformer.norm_final_attn.weight grad: -0.000480111688375473
mask_decoder.transformer.norm_final_attn.bias grad: -0.0019201149698346853
Text_Embedding_Affine.0.weight grad: 6.655398010479985e-09
Text_Embedding_Affine.0.bias grad: 2.443557605147362e-07
Text_Embedding_Affine.2.weight grad: -1.7532130414110725e-08
Text_Embedding_Affine.2.bias grad: -0.0136504415422678
Epoch 11 finished with average loss: -28.4395
Epoch 12/39
----------
Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, loss=-30.4]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.02it/s, loss=-30.4]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.02it/s, loss=-27.3]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-27.3]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-36.8]Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-36.8]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0748600898224936e-09
Max value: 0.991538941860199
Mean value: 0.07242268323898315

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0748600898224936e-09
Max value: 0.991538941860199
Mean value: 0.07242268323898315

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0929412841796875

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.821946144104004
Max value: -1.1920928244535389e-07
Mean value: -0.16475623846054077

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04526233673095703

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0929412841796875

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 4.2681884765625
Max value: 66.75081634521484
Mean value: 30.447046279907227

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0748600898224936e-09
Max value: 0.991538941860199
Mean value: 0.07242268323898315

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0748600898224936e-09
Max value: 0.991538941860199
Mean value: 0.07242268323898315

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0748600898224936e-09
Max value: 0.991538941860199
Mean value: 0.07242268323898315

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.821946144104004
Max value: -1.1920928244535389e-07
Mean value: -0.16475623846054077

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 4.2681884765625
Max value: 66.75081634521484
Mean value: 30.447046279907227

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -30.44849967956543
Max value: -30.44849967956543
Mean value: -30.44849967956543
sam_encoder.pos_embed grad: -1.8877076399803627e-06
sam_encoder.blocks.0.norm1.weight grad: -0.00731928925961256
sam_encoder.blocks.0.norm1.bias grad: -0.006046516355127096
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0006446188781410456
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.919789378414862e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0011151616927236319
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0006238226196728647
sam_encoder.blocks.0.norm2.weight grad: 0.0002484886790625751
sam_encoder.blocks.0.norm2.bias grad: 0.010674482211470604
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.003332191612571478
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0019313243683427572
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.002444927580654621
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0013123180251568556
sam_encoder.blocks.1.norm1.weight grad: -0.0018412403296679258
sam_encoder.blocks.1.norm1.bias grad: -0.0019361467566341162
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0007119100773707032
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.356300870422274e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0005167265189811587
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00034858513390645385
sam_encoder.blocks.1.norm2.weight grad: 0.0009767054580152035
sam_encoder.blocks.1.norm2.bias grad: -0.00020592115470208228
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00030706095276400447
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.69840951054357e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0019035134464502335
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00020855374168604612
sam_encoder.blocks.2.norm1.weight grad: 0.0020470768213272095
sam_encoder.blocks.2.norm1.bias grad: -0.0014148952905088663
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0013815144775435328
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00033161439932882786
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0003058310830965638
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.565325308358297e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0005056235240772367
sam_encoder.blocks.2.norm2.bias grad: 0.0003979190660174936
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0008224453777074814
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.917429057764821e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0012153503485023975
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00019097419863101095
sam_encoder.blocks.3.norm1.weight grad: 0.001309003448113799
sam_encoder.blocks.3.norm1.bias grad: -0.002019102219492197
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0011294956784695387
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00018807454034686089
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0008413696195930243
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00029242929304018617
sam_encoder.blocks.3.norm2.weight grad: 0.0022590868175029755
sam_encoder.blocks.3.norm2.bias grad: 0.000758100941311568
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0018945559859275818
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0005841559614054859
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0013732269871979952
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0004843134665861726
sam_encoder.blocks.4.norm1.weight grad: 0.0011484205024316907
sam_encoder.blocks.4.norm1.bias grad: -0.0010633462807163596
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0010560101363807917
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0003122026100754738
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0009310742607340217
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0007432911079376936
sam_encoder.blocks.4.norm2.weight grad: -0.00267851073294878
sam_encoder.blocks.4.norm2.bias grad: -0.0020783175714313984
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0013585053384304047
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.000597637495957315
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0007001417106948793
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00024281220976263285
sam_encoder.blocks.5.norm1.weight grad: 0.0021173839922994375
sam_encoder.blocks.5.norm1.bias grad: -0.00013033526192884892
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0013207646552473307
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0004463522636797279
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0007216222584247589
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00032170669874176383
sam_encoder.blocks.5.norm2.weight grad: 0.00021178380120545626
sam_encoder.blocks.5.norm2.bias grad: -0.0008149265195243061
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0003956145083066076
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00018766317225527018
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00031033263076096773
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00018136888684239239
sam_encoder.blocks.6.norm1.weight grad: 0.0006656522746197879
sam_encoder.blocks.6.norm1.bias grad: 0.0008940705447457731
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00037301069824025035
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00012881681323051453
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0002578261191956699
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00015254467143677175
sam_encoder.blocks.6.norm2.weight grad: -0.0016426903894171119
sam_encoder.blocks.6.norm2.bias grad: -0.001036730594933033
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0012183397775515914
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00048179630539380014
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00014949309115763754
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.970875983824953e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0008436831412836909
sam_encoder.blocks.7.norm1.bias grad: 0.00011467615695437416
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007513839518651366
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0005041707772761583
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0006021868321113288
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0006147072999738157
sam_encoder.blocks.7.norm2.weight grad: -0.0012009076308459044
sam_encoder.blocks.7.norm2.bias grad: 0.00028752483194693923
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0007618878735229373
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002898064849432558
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.4596591477748e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0001291817898163572
sam_encoder.blocks.8.norm1.weight grad: 0.0004776708665303886
sam_encoder.blocks.8.norm1.bias grad: 5.261074329609983e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00010548964201007038
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.237883932655677e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00022749257914256305
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.7702498452272266e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0005685733049176633
sam_encoder.blocks.8.norm2.bias grad: -0.00027688159025274217
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0006680419901385903
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0004174171481281519
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0005895688664168119
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00017725562793202698
sam_encoder.blocks.9.norm1.weight grad: 0.0006725204875692725
sam_encoder.blocks.9.norm1.bias grad: 6.015533290337771e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0005641735624521971
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0001288975909119472
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00022117901244200766
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00020179699640721083
sam_encoder.blocks.9.norm2.weight grad: 0.0015904263127595186
sam_encoder.blocks.9.norm2.bias grad: 0.00026653354871086776
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0010258420370519161
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0006310803582891822
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00037296186201274395
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.653066182276234e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0011465454008430243
sam_encoder.blocks.10.norm1.bias grad: 0.00022248004097491503
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0007054841844365001
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0002774962631519884
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0002621434396132827
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00014706584624946117
sam_encoder.blocks.10.norm2.weight grad: 0.0033203221391886473
sam_encoder.blocks.10.norm2.bias grad: 0.0007413413259200752
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0013327839551493526
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0007928410777822137
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0004103289684280753
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.790895713493228e-05
sam_encoder.blocks.11.norm1.weight grad: 0.000976902898401022
sam_encoder.blocks.11.norm1.bias grad: 9.031698573380709e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00036848726449534297
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.92857073165942e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0002661107573658228
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.825350621715188e-06
sam_encoder.blocks.11.norm2.weight grad: 0.0032219854183495045
sam_encoder.blocks.11.norm2.bias grad: -0.00010301264410372823
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.001258084550499916
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0005718505708500743
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0004200205148663372
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00022260290279518813
sam_encoder.neck.conv1.trainable_scale grad: 8.558784611523151e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0025568371638655663
sam_encoder.neck.conv2.trainable_scale grad: -0.00010730698704719543
sam_encoder.neck.conv2.trainable_shift grad: -0.018740221858024597
mask_decoder.transformer.layers.0.norm1.weight grad: 0.013253727927803993
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0007449127733707428
mask_decoder.transformer.layers.0.norm2.weight grad: -0.5535842776298523
mask_decoder.transformer.layers.0.norm2.bias grad: -0.3250621557235718
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0063389018177986145
mask_decoder.transformer.layers.0.norm3.bias grad: -0.010224999859929085
mask_decoder.transformer.layers.0.norm4.weight grad: 0.007962046191096306
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0020601786673069
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0008789271232672036
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0010308590717613697
mask_decoder.transformer.layers.1.norm2.weight grad: -0.03542280197143555
mask_decoder.transformer.layers.1.norm2.bias grad: -0.010223627090454102
mask_decoder.transformer.layers.1.norm3.weight grad: -0.002593837445601821
mask_decoder.transformer.layers.1.norm3.bias grad: -0.005203334614634514
mask_decoder.transformer.layers.1.norm4.weight grad: -0.012911656871438026
mask_decoder.transformer.layers.1.norm4.bias grad: -0.031469959765672684
mask_decoder.transformer.norm_final_attn.weight grad: -0.00027417519595474005
mask_decoder.transformer.norm_final_attn.bias grad: 0.001530259265564382
Text_Embedding_Affine.0.weight grad: -1.550846007170037e-09
Text_Embedding_Affine.0.bias grad: -4.339381121098995e-08
Text_Embedding_Affine.2.weight grad: -1.1836017499433638e-08
Text_Embedding_Affine.2.bias grad: -0.004140641540288925

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.408315272685375e-12
Max value: 0.9945975542068481
Mean value: 0.053053732961416245

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.408315272685375e-12
Max value: 0.9945975542068481
Mean value: 0.053053732961416245

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06725549697875977

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.354312896728516
Max value: -1.1920928244535389e-07
Mean value: -0.13612455129623413

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.024054527282714844

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06725549697875977

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.0
Max value: 51.28136444091797
Mean value: 24.05842399597168

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.408315272685375e-12
Max value: 0.9945975542068481
Mean value: 0.053053732961416245

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.408315272685375e-12
Max value: 0.9945975542068481
Mean value: 0.053053732961416245

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.408315272685375e-12
Max value: 0.9945975542068481
Mean value: 0.053053732961416245

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.354312896728516
Max value: -1.1920928244535389e-07
Mean value: -0.13612455129623413

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.0
Max value: 51.28136444091797
Mean value: 24.05842399597168

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -24.059669494628906
Max value: -24.059669494628906
Mean value: -24.059669494628906
sam_encoder.pos_embed grad: -7.988032280081825e-07
sam_encoder.blocks.0.norm1.weight grad: -0.007095954846590757
sam_encoder.blocks.0.norm1.bias grad: -0.004020958207547665
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0008865296258591115
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.397036223555915e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0005841137608513236
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00028771418146789074
sam_encoder.blocks.0.norm2.weight grad: 0.0027273602318018675
sam_encoder.blocks.0.norm2.bias grad: 0.007303919177502394
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00020106657757423818
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.866954648401588e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00048304369556717575
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00018455069221090525
sam_encoder.blocks.1.norm1.weight grad: -0.002092634327709675
sam_encoder.blocks.1.norm1.bias grad: 0.000900947256013751
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.001343019655905664
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0004085571854375303
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0013557038037106395
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0005117197870276868
sam_encoder.blocks.1.norm2.weight grad: 0.002174707595258951
sam_encoder.blocks.1.norm2.bias grad: -0.00031104549998417497
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00015354820061475039
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001932057784870267
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0004050580319017172
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.058375144377351e-05
sam_encoder.blocks.2.norm1.weight grad: -0.002462538657709956
sam_encoder.blocks.2.norm1.bias grad: 0.001406742027029395
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00178853131365031
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00033479579724371433
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0009297092328779399
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00044495699694380164
sam_encoder.blocks.2.norm2.weight grad: -0.000357960001565516
sam_encoder.blocks.2.norm2.bias grad: -0.00011302738857921213
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00026217318372800946
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.53733324422501e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00044986180728301406
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.787877408787608e-05
sam_encoder.blocks.3.norm1.weight grad: 0.00015522554167546332
sam_encoder.blocks.3.norm1.bias grad: -7.626360456924886e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0007436723681166768
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00019422092009335756
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0006321633700281382
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.909055809956044e-05
sam_encoder.blocks.3.norm2.weight grad: 0.003284911159425974
sam_encoder.blocks.3.norm2.bias grad: 0.0014035747153684497
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0023153568617999554
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0009337330120615661
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0003911164531018585
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00010398852464277297
sam_encoder.blocks.4.norm1.weight grad: 0.002436844864860177
sam_encoder.blocks.4.norm1.bias grad: -0.002028815448284149
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0020161266438663006
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0007215323857963085
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0005535283125936985
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0004845852963626385
sam_encoder.blocks.4.norm2.weight grad: 0.0009452749509364367
sam_encoder.blocks.4.norm2.bias grad: -0.000246131035964936
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00017730215040501207
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.313627010153141e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0005860266974195838
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.000319825456244871
sam_encoder.blocks.5.norm1.weight grad: 0.0019971709698438644
sam_encoder.blocks.5.norm1.bias grad: -0.0007518735947087407
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0013876338489353657
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00039992338861338794
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00015283265383914113
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.909652489004657e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0011968337930738926
sam_encoder.blocks.5.norm2.bias grad: -8.551213250029832e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00011696451110765338
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.986222721636295e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0002058726386167109
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.0695030697388574e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00017477545770816505
sam_encoder.blocks.6.norm1.bias grad: 0.00029273354448378086
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00012615651939995587
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00011532484495546669
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00020564084115903825
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00018691213335841894
sam_encoder.blocks.6.norm2.weight grad: -0.00022960687056183815
sam_encoder.blocks.6.norm2.bias grad: 0.00028245753492228687
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0008120097918435931
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00035162194399163127
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.614338882267475e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.398009721422568e-05
sam_encoder.blocks.7.norm1.weight grad: 8.15142848296091e-05
sam_encoder.blocks.7.norm1.bias grad: -0.00011688574886647984
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.7269197239074856e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.9513539377367124e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.182167948689312e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.75403610127978e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0003609810664784163
sam_encoder.blocks.7.norm2.bias grad: 0.0003119830507785082
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0004969352739863098
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002368783752899617
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.0005556507385336e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.377088877547067e-06
sam_encoder.blocks.8.norm1.weight grad: 0.00013493170263245702
sam_encoder.blocks.8.norm1.bias grad: -4.2996834963560104e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00012317273649387062
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.58081997546833e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.529899029468652e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00023104115098249167
sam_encoder.blocks.8.norm2.weight grad: 0.0007676486857235432
sam_encoder.blocks.8.norm2.bias grad: 3.05110115732532e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.000497188710141927
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00034899188904091716
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0003838608681689948
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00010591811587801203
sam_encoder.blocks.9.norm1.weight grad: 0.0011282757623121142
sam_encoder.blocks.9.norm1.bias grad: -5.0306400225963444e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.001042854506522417
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00029310560785233974
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00024646357633173466
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0001867998216766864
sam_encoder.blocks.9.norm2.weight grad: 0.001003825105726719
sam_encoder.blocks.9.norm2.bias grad: 0.0002575499820522964
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.000608482863754034
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00043007807107642293
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00018532376270741224
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.9534006696630968e-06
sam_encoder.blocks.10.norm1.weight grad: 0.0007656190427951515
sam_encoder.blocks.10.norm1.bias grad: 4.601385444402695e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0005621529999189079
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00022856953728478402
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.173910176381469e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.108919529244304e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0022644000127911568
sam_encoder.blocks.10.norm2.bias grad: 0.000695032300427556
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0009399428963661194
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0006501014577224851
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0004544429248198867
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.695060387253761e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0013547539710998535
sam_encoder.blocks.11.norm1.bias grad: 0.0001581716351211071
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0009307152940891683
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0003881267621181905
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00040021128370426595
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00010219414252787828
sam_encoder.blocks.11.norm2.weight grad: 0.0016598233487457037
sam_encoder.blocks.11.norm2.bias grad: 0.0001789916423149407
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00043230061419308186
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0003304357815068215
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00023951250477693975
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00016649240569677204
sam_encoder.neck.conv1.trainable_scale grad: 0.00022366316989064217
sam_encoder.neck.conv1.trainable_shift grad: -0.0023495699279010296
sam_encoder.neck.conv2.trainable_scale grad: 8.394615724682808e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.013079440221190453
mask_decoder.transformer.layers.0.norm1.weight grad: 0.041831254959106445
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0005751233547925949
mask_decoder.transformer.layers.0.norm2.weight grad: 0.14084690809249878
mask_decoder.transformer.layers.0.norm2.bias grad: -0.3705958425998688
mask_decoder.transformer.layers.0.norm3.weight grad: 0.014607397839426994
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0036189230158925056
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00015972740948200226
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0007720913272351027
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0002067608293145895
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0005703982897102833
mask_decoder.transformer.layers.1.norm2.weight grad: -0.027545733377337456
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0050206962041556835
mask_decoder.transformer.layers.1.norm3.weight grad: -0.005657080560922623
mask_decoder.transformer.layers.1.norm3.bias grad: -0.006826550699770451
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002971281763166189
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00570222083479166
mask_decoder.transformer.norm_final_attn.weight grad: -0.0005608078790828586
mask_decoder.transformer.norm_final_attn.bias grad: -0.00033798383083194494
Text_Embedding_Affine.0.weight grad: -2.8182527422870862e-09
Text_Embedding_Affine.0.bias grad: -4.9476511776447296e-08
Text_Embedding_Affine.2.weight grad: -2.6369079364485515e-08
Text_Embedding_Affine.2.bias grad: -0.012777920812368393

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.412832014885851e-10
Max value: 0.9997692704200745
Mean value: 0.11194545775651932

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.412832014885851e-10
Max value: 0.9997692704200745
Mean value: 0.11194545775651932

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09783172607421875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.572404861450195
Max value: -1.1920928244535389e-07
Mean value: -0.15459421277046204

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07023906707763672

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09783172607421875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 29.743650436401367
Max value: 87.16504669189453
Mean value: 55.851768493652344

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.412832014885851e-10
Max value: 0.9997692704200745
Mean value: 0.11194545775651932

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.412832014885851e-10
Max value: 0.9997692704200745
Mean value: 0.11194545775651932

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.412832014885851e-10
Max value: 0.9997692704200745
Mean value: 0.11194545775651932

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.572404861450195
Max value: -1.1920928244535389e-07
Mean value: -0.15459421277046204

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 29.743650436401367
Max value: 87.16504669189453
Mean value: 55.851768493652344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.85387420654297
Max value: -55.85387420654297
Mean value: -55.85387420654297
sam_encoder.pos_embed grad: 7.772298715735815e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0008434946648776531
sam_encoder.blocks.0.norm1.bias grad: -0.003760622814297676
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0005839160876348615
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.0001221369457198307
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0013214629143476486
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.303450623410754e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0012697225902229548
sam_encoder.blocks.0.norm2.bias grad: 0.0012572887353599072
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0003781042469199747
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0009155694278888404
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0007263016887009144
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0002108189946739003
sam_encoder.blocks.1.norm1.weight grad: -0.0005777563783340156
sam_encoder.blocks.1.norm1.bias grad: 0.0020760484039783478
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0007074424065649509
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.000405602011596784
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0008010299643501639
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.000574533361941576
sam_encoder.blocks.1.norm2.weight grad: 0.0002404663828201592
sam_encoder.blocks.1.norm2.bias grad: -0.0011444350238889456
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0002573379024397582
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.894750236417167e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0021700849756598473
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0005381302908062935
sam_encoder.blocks.2.norm1.weight grad: -0.0003405122261028737
sam_encoder.blocks.2.norm1.bias grad: 0.00047716934932395816
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0007734849932603538
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00010636041406542063
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0004989769659005105
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003767604357562959
sam_encoder.blocks.2.norm2.weight grad: -0.0006948717636987567
sam_encoder.blocks.2.norm2.bias grad: -0.0020703887566924095
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0004527617711573839
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001524978142697364
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0013250862248241901
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004156300565227866
sam_encoder.blocks.3.norm1.weight grad: 0.0007544807158410549
sam_encoder.blocks.3.norm1.bias grad: 0.00033782003447413445
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.000726026832126081
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0001582827535457909
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0008471330511383712
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00035739943268708885
sam_encoder.blocks.3.norm2.weight grad: -0.00045597919961437583
sam_encoder.blocks.3.norm2.bias grad: -0.0010176240466535091
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.00031325288000516593
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.361991548445076e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0002388608845649287
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.7004367186455056e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0009541967301629484
sam_encoder.blocks.4.norm1.bias grad: 0.0003595723246689886
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.000369192857760936
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00016653220518492162
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0379022569395602e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002223135670647025
sam_encoder.blocks.4.norm2.weight grad: -0.0038590736221522093
sam_encoder.blocks.4.norm2.bias grad: -0.0012779667740687728
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0025066654197871685
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0007437033345922828
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.5770430006086826e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.25394706428051e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0009552645497024059
sam_encoder.blocks.5.norm1.bias grad: -0.0003711623139679432
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.000418064184486866
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0001361375325359404
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00013696464884560555
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00021294420002959669
sam_encoder.blocks.5.norm2.weight grad: -0.003019933123141527
sam_encoder.blocks.5.norm2.bias grad: -0.0004436230519786477
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0016925627132877707
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0006514025153592229
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.699275218124967e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.810054088011384e-05
sam_encoder.blocks.6.norm1.weight grad: -3.557325544534251e-05
sam_encoder.blocks.6.norm1.bias grad: -9.08694855752401e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00021175754955038428
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.571659079985693e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -9.60633042268455e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.86778623983264e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0010090478463098407
sam_encoder.blocks.6.norm2.bias grad: -5.5095959396567196e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0008481885306537151
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0003973669954575598
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00018342833209317178
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.6083960872492753e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00047812442062422633
sam_encoder.blocks.7.norm1.bias grad: 0.00010074266901938245
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0002475099463481456
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00018176923913415521
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9646369764814153e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0002221462200395763
sam_encoder.blocks.7.norm2.weight grad: -0.0009202751098200679
sam_encoder.blocks.7.norm2.bias grad: 0.00013915629824623466
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0007941380026750267
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0004939413047395647
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0001300106814596802
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.571907968260348e-05
sam_encoder.blocks.8.norm1.weight grad: 0.001080536050722003
sam_encoder.blocks.8.norm1.bias grad: -0.00010941261280095205
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0009906102204695344
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00023899145890027285
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.169724575651344e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00020325829973444343
sam_encoder.blocks.8.norm2.weight grad: -0.0007363897166214883
sam_encoder.blocks.8.norm2.bias grad: -0.000124973215861246
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0006737624062225223
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00039525877218693495
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.1524049922591075e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.262869283091277e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0004540518275462091
sam_encoder.blocks.9.norm1.bias grad: -0.00023365816741716117
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0004821296315640211
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00010125125118065625
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.5685889340820722e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.89332601823844e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0001298870047321543
sam_encoder.blocks.9.norm2.bias grad: -0.00012642540968954563
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00010599489905871451
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.399341585463844e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00017030896560754627
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.9712588255060837e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00029457808705046773
sam_encoder.blocks.10.norm1.bias grad: 7.277490567503264e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00014483873383142054
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.117767482763156e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.045913424808532e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.137867265148088e-05
sam_encoder.blocks.10.norm2.weight grad: -0.000123174671898596
sam_encoder.blocks.10.norm2.bias grad: -0.00020422274246811867
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0001122911271522753
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.850598194636405e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00016297001275233924
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.924978955183178e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0006010595825500786
sam_encoder.blocks.11.norm1.bias grad: 0.00040871044620871544
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0006805071607232094
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001754168188199401
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00012985389912500978
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.432687299209647e-05
sam_encoder.blocks.11.norm2.weight grad: -0.00010587750875856727
sam_encoder.blocks.11.norm2.bias grad: -0.00021037102851551026
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.752779442351311e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.3453691028407775e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.277920430060476e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.000314584118314e-05
sam_encoder.neck.conv1.trainable_scale grad: 9.400886483490467e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0030240975320339203
sam_encoder.neck.conv2.trainable_scale grad: 4.4931890442967415e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0022788953501731157
mask_decoder.transformer.layers.0.norm1.weight grad: 0.014978557825088501
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00017468654550611973
mask_decoder.transformer.layers.0.norm2.weight grad: 0.04259340465068817
mask_decoder.transformer.layers.0.norm2.bias grad: -0.061234913766384125
mask_decoder.transformer.layers.0.norm3.weight grad: 0.016798995435237885
mask_decoder.transformer.layers.0.norm3.bias grad: 0.005391295533627272
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0063085430301725864
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0006224850658327341
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0002584871253930032
mask_decoder.transformer.layers.1.norm1.bias grad: 7.412594277411699e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.01236841268837452
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0015080878511071205
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0028574634343385696
mask_decoder.transformer.layers.1.norm3.bias grad: -8.718209573999047e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.273586329072714e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00404698122292757
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003989452961832285
mask_decoder.transformer.norm_final_attn.bias grad: 0.00013257606769911945
Text_Embedding_Affine.0.weight grad: -8.770061343810198e-10
Text_Embedding_Affine.0.bias grad: 2.444721758365631e-09
Text_Embedding_Affine.2.weight grad: -1.91140281380342e-09
Text_Embedding_Affine.2.bias grad: -0.0022164375986903906
Epoch 12 finished with average loss: -36.7873
Epoch 13/39
----------
Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, loss=-41.7]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-41.7]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-33.9]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.47it/s, loss=-33.9]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.47it/s, loss=-35]  Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.07it/s, loss=-35]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.572666606999064e-10
Max value: 0.9997890591621399
Mean value: 0.07745139300823212

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.572666606999064e-10
Max value: 0.9997890591621399
Mean value: 0.07745139300823212

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09738922119140625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.136152267456055
Max value: -1.1920928244535389e-07
Mean value: -0.1571911871433258

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.051514625549316406

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09738922119140625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 4.701125144958496
Max value: 67.51445770263672
Mean value: 41.73004913330078

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.572666606999064e-10
Max value: 0.9997890591621399
Mean value: 0.07745139300823212

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.572666606999064e-10
Max value: 0.9997890591621399
Mean value: 0.07745139300823212

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.572666606999064e-10
Max value: 0.9997890591621399
Mean value: 0.07745139300823212

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.136152267456055
Max value: -1.1920928244535389e-07
Mean value: -0.1571911871433258

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 4.701125144958496
Max value: 67.51445770263672
Mean value: 41.73004913330078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -41.731483459472656
Max value: -41.731483459472656
Mean value: -41.731483459472656
sam_encoder.pos_embed grad: 6.0723968999809586e-06
sam_encoder.blocks.0.norm1.weight grad: 0.012615758925676346
sam_encoder.blocks.0.norm1.bias grad: 0.024767253547906876
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.005590402986854315
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00010577783541521057
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.01022442989051342
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0029579992406070232
sam_encoder.blocks.0.norm2.weight grad: 0.011388739570975304
sam_encoder.blocks.0.norm2.bias grad: -0.07146120071411133
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.02049831673502922
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.005424532573670149
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.001377904787659645
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0016151111340150237
sam_encoder.blocks.1.norm1.weight grad: 0.0018490510992705822
sam_encoder.blocks.1.norm1.bias grad: 0.0058881863951683044
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0027895313687622547
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0008842122624628246
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.003330404404550791
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00270518334582448
sam_encoder.blocks.1.norm2.weight grad: -0.006038404069840908
sam_encoder.blocks.1.norm2.bias grad: 0.005192155949771404
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00474086869508028
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0005871106404811144
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.01232182513922453
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.002095046453177929
sam_encoder.blocks.2.norm1.weight grad: -0.011339201591908932
sam_encoder.blocks.2.norm1.bias grad: 0.004838386084884405
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00670233741402626
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0019468236714601517
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.003349351231008768
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.002990215551108122
sam_encoder.blocks.2.norm2.weight grad: -0.0038941730745136738
sam_encoder.blocks.2.norm2.bias grad: -0.00396348349750042
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.004622241016477346
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00019803392933681607
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.007069622166454792
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0013256906531751156
sam_encoder.blocks.3.norm1.weight grad: 0.0010480917990207672
sam_encoder.blocks.3.norm1.bias grad: 0.006902155466377735
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00632557412609458
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.001953022088855505
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.005117282271385193
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.003067869460210204
sam_encoder.blocks.3.norm2.weight grad: -0.00533673819154501
sam_encoder.blocks.3.norm2.bias grad: -0.0025246636942029
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.004398109391331673
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0006158901378512383
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0039000902324914932
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0015676848124712706
sam_encoder.blocks.4.norm1.weight grad: 0.004169625695794821
sam_encoder.blocks.4.norm1.bias grad: -0.00025804791948758066
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0011830148287117481
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.000277618964901194
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.002009638585150242
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.002265126910060644
sam_encoder.blocks.4.norm2.weight grad: -0.008265133015811443
sam_encoder.blocks.4.norm2.bias grad: -0.002969830995425582
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.007362586446106434
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.001979962456971407
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.002622681437060237
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.000830087810754776
sam_encoder.blocks.5.norm1.weight grad: 0.0004522314702626318
sam_encoder.blocks.5.norm1.bias grad: -0.005733211990445852
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.002425855491310358
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0003850592183880508
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0013644266873598099
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0017880294471979141
sam_encoder.blocks.5.norm2.weight grad: -0.011476263403892517
sam_encoder.blocks.5.norm2.bias grad: -0.0005778169143013656
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.006934308912605047
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0025961382780224085
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00011782775254687294
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.4205771953566e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0013238019309937954
sam_encoder.blocks.6.norm1.bias grad: -0.0020438467618077993
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0016179997473955154
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.000704816309735179
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.169709326466545e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00035676220431923866
sam_encoder.blocks.6.norm2.weight grad: -0.003555505070835352
sam_encoder.blocks.6.norm2.bias grad: 0.0008519247057847679
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.004012292250990868
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0017165865283459425
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.736885239253752e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0004026584792882204
sam_encoder.blocks.7.norm1.weight grad: -0.0018416382372379303
sam_encoder.blocks.7.norm1.bias grad: -0.0007020122720859945
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.001715119811706245
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.001101481495425105
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.001523293904028833
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0015748990699648857
sam_encoder.blocks.7.norm2.weight grad: -0.0017225733026862144
sam_encoder.blocks.7.norm2.bias grad: -0.0004100530641153455
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0013586157001554966
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.000876753474585712
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002616633428260684
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0006368857575580478
sam_encoder.blocks.8.norm1.weight grad: 0.002940097590908408
sam_encoder.blocks.8.norm1.bias grad: -0.0012846685713157058
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.004405648447573185
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0019232593476772308
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0013057701289653778
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.000168532133102417
sam_encoder.blocks.8.norm2.weight grad: -0.006452040281146765
sam_encoder.blocks.8.norm2.bias grad: 0.001027207705192268
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.005938342772424221
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0032987669110298157
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.002084982581436634
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0005735531449317932
sam_encoder.blocks.9.norm1.weight grad: -0.0003996452724095434
sam_encoder.blocks.9.norm1.bias grad: -0.0007499695639126003
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0009144676732830703
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0010000178590416908
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0008682003244757652
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00031526637030765414
sam_encoder.blocks.9.norm2.weight grad: -0.008949496783316135
sam_encoder.blocks.9.norm2.bias grad: -0.0008487015729770064
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.006988312117755413
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.003649699268862605
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0012790319742634892
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00025889358948916197
sam_encoder.blocks.10.norm1.weight grad: -0.0018040584400296211
sam_encoder.blocks.10.norm1.bias grad: -0.0008376959594897926
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.001580709358677268
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0008270320831798017
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0008841187227517366
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.0005529900081455708
sam_encoder.blocks.10.norm2.weight grad: -0.015033472329378128
sam_encoder.blocks.10.norm2.bias grad: -0.0031031034886837006
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.006789427250623703
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.003786596469581127
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0010258315596729517
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00024067520280368626
sam_encoder.blocks.11.norm1.weight grad: -0.014439552091062069
sam_encoder.blocks.11.norm1.bias grad: 0.00026954044005833566
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0005701160989701748
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0004182181437499821
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0004950264701619744
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0002255383151350543
sam_encoder.blocks.11.norm2.weight grad: -0.018702350556850433
sam_encoder.blocks.11.norm2.bias grad: -0.0033646090887486935
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.006131434813141823
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0033194280695170164
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0017739895265549421
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.0009407986653968692
sam_encoder.neck.conv1.trainable_scale grad: -0.00035431189462542534
sam_encoder.neck.conv1.trainable_shift grad: -0.009487700648605824
sam_encoder.neck.conv2.trainable_scale grad: -0.00010419311001896858
sam_encoder.neck.conv2.trainable_shift grad: 0.02436385117471218
mask_decoder.transformer.layers.0.norm1.weight grad: 0.042978689074516296
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0011691153049468994
mask_decoder.transformer.layers.0.norm2.weight grad: 1.952187418937683
mask_decoder.transformer.layers.0.norm2.bias grad: 0.6940898895263672
mask_decoder.transformer.layers.0.norm3.weight grad: 0.07279658317565918
mask_decoder.transformer.layers.0.norm3.bias grad: 0.04433474317193031
mask_decoder.transformer.layers.0.norm4.weight grad: -0.03581816703081131
mask_decoder.transformer.layers.0.norm4.bias grad: 0.011328624561429024
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0071287984028458595
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0034168772399425507
mask_decoder.transformer.layers.1.norm2.weight grad: 0.2917040288448334
mask_decoder.transformer.layers.1.norm2.bias grad: 0.08876271545886993
mask_decoder.transformer.layers.1.norm3.weight grad: 0.03450470045208931
mask_decoder.transformer.layers.1.norm3.bias grad: 0.020440997555851936
mask_decoder.transformer.layers.1.norm4.weight grad: 0.04354197531938553
mask_decoder.transformer.layers.1.norm4.bias grad: 0.09390808641910553
mask_decoder.transformer.norm_final_attn.weight grad: 0.0011074657086282969
mask_decoder.transformer.norm_final_attn.bias grad: -0.008347309194505215
Text_Embedding_Affine.0.weight grad: -7.18937132049291e-09
Text_Embedding_Affine.0.bias grad: -2.3614848032593727e-07
Text_Embedding_Affine.2.weight grad: 4.692028454655883e-08
Text_Embedding_Affine.2.bias grad: -0.006532902363687754

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.379663688323319e-10
Max value: 0.9879986047744751
Mean value: 0.05700495094060898

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.379663688323319e-10
Max value: 0.9879986047744751
Mean value: 0.05700495094060898

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0741720199584961

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.572896003723145
Max value: -1.1920928244535389e-07
Mean value: -0.15111392736434937

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.025548934936523438

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0741720199584961

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.0
Max value: 58.652252197265625
Mean value: 26.094614028930664

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.379663688323319e-10
Max value: 0.9879986047744751
Mean value: 0.05700495094060898

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.379663688323319e-10
Max value: 0.9879986047744751
Mean value: 0.05700495094060898

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.379663688323319e-10
Max value: 0.9879986047744751
Mean value: 0.05700495094060898

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.572896003723145
Max value: -1.1920928244535389e-07
Mean value: -0.15111392736434937

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.0
Max value: 58.652252197265625
Mean value: 26.094614028930664

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -26.095905303955078
Max value: -26.095905303955078
Mean value: -26.095905303955078
sam_encoder.pos_embed grad: -1.8895070752478205e-06
sam_encoder.blocks.0.norm1.weight grad: -0.013872119598090649
sam_encoder.blocks.0.norm1.bias grad: -0.0026073220651596785
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.000793707906268537
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.808208465576172e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00034571648575365543
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00010779731383081526
sam_encoder.blocks.0.norm2.weight grad: 0.001002234173938632
sam_encoder.blocks.0.norm2.bias grad: 0.005751126911491156
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0026499712839722633
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0010941065847873688
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0020745303481817245
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0014194766990840435
sam_encoder.blocks.1.norm1.weight grad: -0.002548022661358118
sam_encoder.blocks.1.norm1.bias grad: 0.00019342152518220246
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0007145183044485748
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00033053787774406374
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0005693938583135605
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00025605078553780913
sam_encoder.blocks.1.norm2.weight grad: 0.0025101550854742527
sam_encoder.blocks.1.norm2.bias grad: -0.0004551417368929833
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0015652048168703914
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00037113064900040627
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.00016381584282498807
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.88204701570794e-05
sam_encoder.blocks.2.norm1.weight grad: -0.00012710853479802608
sam_encoder.blocks.2.norm1.bias grad: 0.00218633352778852
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0005687092198058963
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.244912295485847e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0006201382493600249
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000476162153063342
sam_encoder.blocks.2.norm2.weight grad: -2.4851567559380783e-06
sam_encoder.blocks.2.norm2.bias grad: -0.0004120694356970489
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0003472294774837792
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.883540769806132e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0008493586210533977
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 9.641327051213011e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0006246371776796877
sam_encoder.blocks.3.norm1.bias grad: 0.0008552343351766467
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.527760665951064e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00016596254135947675
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.000425467238528654
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.5090339477173984e-05
sam_encoder.blocks.3.norm2.weight grad: 0.002138454932719469
sam_encoder.blocks.3.norm2.bias grad: 0.0012671196600422263
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0014851506566628814
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00030251604039222
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0007992265745997429
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00029045355040580034
sam_encoder.blocks.4.norm1.weight grad: 0.002789432881399989
sam_encoder.blocks.4.norm1.bias grad: -0.0009612025460228324
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.002047433517873287
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005164736066944897
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0007649771869182587
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0007540254155173898
sam_encoder.blocks.4.norm2.weight grad: -0.0036851949989795685
sam_encoder.blocks.4.norm2.bias grad: -0.004338122438639402
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0023137626703828573
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0010184569982811809
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.001110939192585647
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0004991765599697828
sam_encoder.blocks.5.norm1.weight grad: 0.0019007751252502203
sam_encoder.blocks.5.norm1.bias grad: 0.000232253922149539
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0008935523219406605
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0001576591021148488
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00026031333254650235
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.1662225006148219e-05
sam_encoder.blocks.5.norm2.weight grad: -0.0006838770350441337
sam_encoder.blocks.5.norm2.bias grad: -0.0024189865216612816
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0007162808906286955
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00024684570962563157
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0003750307369045913
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00010219270916422829
sam_encoder.blocks.6.norm1.weight grad: -0.00034289283212274313
sam_encoder.blocks.6.norm1.bias grad: 0.0011143399169668555
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00045502634020522237
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0001710822689346969
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00010219643445452675
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00015443397569470108
sam_encoder.blocks.6.norm2.weight grad: -0.0019141256343573332
sam_encoder.blocks.6.norm2.bias grad: -0.0007009994005784392
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0017653938848525286
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0007425061194226146
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0001467269321437925
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00012467279157135636
sam_encoder.blocks.7.norm1.weight grad: 0.00219868216663599
sam_encoder.blocks.7.norm1.bias grad: -0.0003369480837136507
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.001498601632192731
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0007165751303546131
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0008763493387959898
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0003651722799986601
sam_encoder.blocks.7.norm2.weight grad: -0.0008593389648012817
sam_encoder.blocks.7.norm2.bias grad: 0.0002927211462520063
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0006349857430905104
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00045152404345571995
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0003844605234917253
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00027036337996833026
sam_encoder.blocks.8.norm1.weight grad: 0.0009677457856014371
sam_encoder.blocks.8.norm1.bias grad: 9.724350820761174e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0004179716925136745
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00018639143672771752
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00032136039226315916
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0001208063549711369
sam_encoder.blocks.8.norm2.weight grad: 0.0006065028719604015
sam_encoder.blocks.8.norm2.bias grad: -0.00019654839707072824
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0005803029052913189
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00026935330242849886
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00038280044100247324
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.1447633369243704e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0018487646011635661
sam_encoder.blocks.9.norm1.bias grad: -5.753237201133743e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.001652007456868887
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0005373782478272915
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0005427349824458361
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00028327456675469875
sam_encoder.blocks.9.norm2.weight grad: 0.0019230297766625881
sam_encoder.blocks.9.norm2.bias grad: 0.00014378537889569998
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0014434329932555556
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0008448711014352739
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0005084659205749631
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.30909383087419e-05
sam_encoder.blocks.10.norm1.weight grad: 0.002147959778085351
sam_encoder.blocks.10.norm1.bias grad: 0.0002508325269445777
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.001451837713830173
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0005101010319776833
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0004398999735713005
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0002129196363966912
sam_encoder.blocks.10.norm2.weight grad: 0.0030619055032730103
sam_encoder.blocks.10.norm2.bias grad: 0.0004572985926643014
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0015328964218497276
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0009145282092504203
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0004922152729704976
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.47872147965245e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0027418360114097595
sam_encoder.blocks.11.norm1.bias grad: 0.0006475778063759208
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0005793088348582387
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00030723490635864437
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0004923517117276788
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00017329960246570408
sam_encoder.blocks.11.norm2.weight grad: 0.0028850201051682234
sam_encoder.blocks.11.norm2.bias grad: -4.07899497076869e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.001425393857061863
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0005379657377488911
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00045185029739513993
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00022307805193122476
sam_encoder.neck.conv1.trainable_scale grad: 0.00019644200801849365
sam_encoder.neck.conv1.trainable_shift grad: 0.00017412053421139717
sam_encoder.neck.conv2.trainable_scale grad: -2.1258369088172913e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.015121357515454292
mask_decoder.transformer.layers.0.norm1.weight grad: 0.03647400066256523
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0005563013255596161
mask_decoder.transformer.layers.0.norm2.weight grad: -0.5992861986160278
mask_decoder.transformer.layers.0.norm2.bias grad: -0.42116087675094604
mask_decoder.transformer.layers.0.norm3.weight grad: 0.010906841605901718
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0070699723437428474
mask_decoder.transformer.layers.0.norm4.weight grad: 0.006428349297493696
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0017536788946017623
mask_decoder.transformer.layers.1.norm1.weight grad: 0.00019418925512582064
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0011206429917365313
mask_decoder.transformer.layers.1.norm2.weight grad: -0.026088617742061615
mask_decoder.transformer.layers.1.norm2.bias grad: -0.005690657999366522
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0013894995208829641
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0069688051007688046
mask_decoder.transformer.layers.1.norm4.weight grad: -0.010708803310990334
mask_decoder.transformer.layers.1.norm4.bias grad: -0.02753520756959915
mask_decoder.transformer.norm_final_attn.weight grad: -0.0006230492144823074
mask_decoder.transformer.norm_final_attn.bias grad: 0.0005610150401480496
Text_Embedding_Affine.0.weight grad: 2.3289037365259446e-10
Text_Embedding_Affine.0.bias grad: 3.026798367500305e-08
Text_Embedding_Affine.2.weight grad: 8.942591556149182e-09
Text_Embedding_Affine.2.bias grad: -0.008973019197583199

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.204223801375974e-10
Max value: 0.9939872026443481
Mean value: 0.0675874575972557

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.204223801375974e-10
Max value: 0.9939872026443481
Mean value: 0.0675874575972557

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07538414001464844

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.953968048095703
Max value: -1.1920928244535389e-07
Mean value: -0.13024604320526123

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.03630352020263672

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07538414001464844

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 12.955206871032715
Max value: 81.46843719482422
Mean value: 37.25029754638672

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.204223801375974e-10
Max value: 0.9939872026443481
Mean value: 0.0675874575972557

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.204223801375974e-10
Max value: 0.9939872026443481
Mean value: 0.0675874575972557

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.204223801375974e-10
Max value: 0.9939872026443481
Mean value: 0.0675874575972557

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.953968048095703
Max value: -1.1920928244535389e-07
Mean value: -0.13024604320526123

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 12.955206871032715
Max value: 81.46843719482422
Mean value: 37.25029754638672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -37.25160217285156
Max value: -37.25160217285156
Mean value: -37.25160217285156
sam_encoder.pos_embed grad: 1.2305551990721142e-06
sam_encoder.blocks.0.norm1.weight grad: 0.015056408941745758
sam_encoder.blocks.0.norm1.bias grad: 0.005021485034376383
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.001899546361528337
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00014217663556337357
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0024720998480916023
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0003471983363851905
sam_encoder.blocks.0.norm2.weight grad: 0.0023439989890903234
sam_encoder.blocks.0.norm2.bias grad: -0.008297258988022804
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00368356890976429
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.208817699691281e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0008569242199882865
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0007570079760625958
sam_encoder.blocks.1.norm1.weight grad: -0.00040419618017040193
sam_encoder.blocks.1.norm1.bias grad: 0.002992758061736822
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0006559642497450113
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0004197703383397311
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0011331195710226893
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0007938530761748552
sam_encoder.blocks.1.norm2.weight grad: 0.000186544144526124
sam_encoder.blocks.1.norm2.bias grad: -0.00033104544854722917
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0010930814314633608
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00024302680685650557
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0025364751927554607
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0007357922731898725
sam_encoder.blocks.2.norm1.weight grad: -0.004315221682190895
sam_encoder.blocks.2.norm1.bias grad: 0.0009165400406345725
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0027789361774921417
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0005952583160251379
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0014526669401675463
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0012187556130811572
sam_encoder.blocks.2.norm2.weight grad: -0.0015196310123428702
sam_encoder.blocks.2.norm2.bias grad: -0.0029483730904757977
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0014904278796166182
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00025133934104815125
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0012555550783872604
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0002179547882406041
sam_encoder.blocks.3.norm1.weight grad: 0.0011891580652445555
sam_encoder.blocks.3.norm1.bias grad: 0.0012651358265429735
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0009358040988445282
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003497251309454441
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0008177586714737117
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0005271269474178553
sam_encoder.blocks.3.norm2.weight grad: 0.000786626129411161
sam_encoder.blocks.3.norm2.bias grad: -0.00025453901616856456
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.7070283219218254e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0003714082995429635
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0008278407040052116
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00046064978232607245
sam_encoder.blocks.4.norm1.weight grad: 0.0038774507120251656
sam_encoder.blocks.4.norm1.bias grad: -0.0009041003650054336
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0019635548815131187
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0003360901609994471
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0002652471303008497
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.390165511518717e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0036063771694898605
sam_encoder.blocks.4.norm2.bias grad: -0.0023075444623827934
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.003172368509694934
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0009604153456166387
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0004996639909222722
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0002464725694153458
sam_encoder.blocks.5.norm1.weight grad: 0.0024494733661413193
sam_encoder.blocks.5.norm1.bias grad: -0.0022938174661248922
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0015732882311567664
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00022581961820833385
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002508301695343107
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0009818881517276168
sam_encoder.blocks.5.norm2.weight grad: -0.0035129159223288298
sam_encoder.blocks.5.norm2.bias grad: -3.772582203964703e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0016744280001148582
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0005401297239586711
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.117978435009718e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.7947982996702194e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0008745566010475159
sam_encoder.blocks.6.norm1.bias grad: -0.0009140159818343818
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0005287976819090545
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00017297067097388208
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.080407522153109e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00014108548930380493
sam_encoder.blocks.6.norm2.weight grad: -0.0023304405622184277
sam_encoder.blocks.6.norm2.bias grad: 3.057151843677275e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0016006053192541003
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0007932860753498971
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.080953896045685e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.885096420068294e-05
sam_encoder.blocks.7.norm1.weight grad: -0.000679065880831331
sam_encoder.blocks.7.norm1.bias grad: 0.00010142900282517076
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0005848700529895723
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0003128953685518354
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00047692254884168506
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00031644542468711734
sam_encoder.blocks.7.norm2.weight grad: -0.001823551720008254
sam_encoder.blocks.7.norm2.bias grad: -0.0001621548435650766
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0012934202095493674
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0006418912671506405
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002860498789232224
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.241547377314419e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00028047498199157417
sam_encoder.blocks.8.norm1.bias grad: -0.0003521119651850313
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00036230782279744744
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0003086638171225786
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0004333597607910633
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00012256269110366702
sam_encoder.blocks.8.norm2.weight grad: -0.001379542052745819
sam_encoder.blocks.8.norm2.bias grad: 0.00017766933888196945
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0013909753179177642
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0006906106136739254
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.379434050060809e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.600463530048728e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00037731765769422054
sam_encoder.blocks.9.norm1.bias grad: -0.00016974794561974704
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0006191668217070401
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00041204318404197693
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0003770223120227456
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00016954481543507427
sam_encoder.blocks.9.norm2.weight grad: -0.0017740888288244605
sam_encoder.blocks.9.norm2.bias grad: -0.0001163807901320979
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.001735091209411621
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0007107098354026675
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0001318167196586728
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.8642116629052907e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0007514473982155323
sam_encoder.blocks.10.norm1.bias grad: -0.0001661778660491109
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0006016265833750367
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00021514692343771458
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0002879850217141211
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00014587953046429902
sam_encoder.blocks.10.norm2.weight grad: -0.002866126596927643
sam_encoder.blocks.10.norm2.bias grad: -0.0005163935129530728
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0016701051499694586
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0006684667314402759
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.544676868245006e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.2361425837734714e-05
sam_encoder.blocks.11.norm1.weight grad: -0.005155767314136028
sam_encoder.blocks.11.norm1.bias grad: 8.616915147285908e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0003102343180216849
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00018184298824053258
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00023584677546750754
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.693891630973667e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0031341444700956345
sam_encoder.blocks.11.norm2.bias grad: -0.0006904010660946369
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.001167939743027091
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0005586805636994541
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00010590418241918087
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.969851478468627e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.65676824003458e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.003362362738698721
sam_encoder.neck.conv2.trainable_scale grad: -5.862442776560783e-06
sam_encoder.neck.conv2.trainable_shift grad: 0.0011648961808532476
mask_decoder.transformer.layers.0.norm1.weight grad: 0.046913594007492065
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0006658118218183517
mask_decoder.transformer.layers.0.norm2.weight grad: 0.1513393223285675
mask_decoder.transformer.layers.0.norm2.bias grad: -0.03904977813363075
mask_decoder.transformer.layers.0.norm3.weight grad: 0.035895925015211105
mask_decoder.transformer.layers.0.norm3.bias grad: 0.014561377465724945
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00645454041659832
mask_decoder.transformer.layers.0.norm4.bias grad: 0.002572307363152504
mask_decoder.transformer.layers.1.norm1.weight grad: 0.002663790015503764
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0009172111749649048
mask_decoder.transformer.layers.1.norm2.weight grad: 0.08393454551696777
mask_decoder.transformer.layers.1.norm2.bias grad: 0.03768768534064293
mask_decoder.transformer.layers.1.norm3.weight grad: 0.010821191594004631
mask_decoder.transformer.layers.1.norm3.bias grad: 0.004931003320962191
mask_decoder.transformer.layers.1.norm4.weight grad: 0.009528540074825287
mask_decoder.transformer.layers.1.norm4.bias grad: 0.01616901531815529
mask_decoder.transformer.norm_final_attn.weight grad: 0.00022601854288950562
mask_decoder.transformer.norm_final_attn.bias grad: -0.001958257518708706
Text_Embedding_Affine.0.weight grad: 2.899934514744018e-09
Text_Embedding_Affine.0.bias grad: 1.4837132766842842e-07
Text_Embedding_Affine.2.weight grad: -9.528067224096048e-09
Text_Embedding_Affine.2.bias grad: -0.012514638714492321
Epoch 13 finished with average loss: -35.0263
Epoch 14/39
----------
Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, loss=-37.9]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-37.9]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-36.3]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-36.3]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-38]  Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.26it/s, loss=-38]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.4322808211962865e-09
Max value: 0.9937204122543335
Mean value: 0.09060825407505035

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4322808211962865e-09
Max value: 0.9937204122543335
Mean value: 0.09060825407505035

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0973825454711914

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.413961410522461
Max value: -1.1920928244535389e-07
Mean value: -0.15500301122665405

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06219673156738281

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0973825454711914

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.8648256063461304
Max value: 74.33096313476562
Mean value: 37.85662078857422

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.4322808211962865e-09
Max value: 0.9937204122543335
Mean value: 0.09060825407505035

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4322808211962865e-09
Max value: 0.9937204122543335
Mean value: 0.09060825407505035

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4322808211962865e-09
Max value: 0.9937204122543335
Mean value: 0.09060825407505035

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.413961410522461
Max value: -1.1920928244535389e-07
Mean value: -0.15500301122665405

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.8648256063461304
Max value: 74.33096313476562
Mean value: 37.85662078857422

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -37.858280181884766
Max value: -37.858280181884766
Mean value: -37.858280181884766
sam_encoder.pos_embed grad: 1.2376813174341805e-06
sam_encoder.blocks.0.norm1.weight grad: -0.006031809374690056
sam_encoder.blocks.0.norm1.bias grad: -0.0039892434142529964
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0005891930777579546
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00017468477017246187
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0006893179379403591
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.8662947695702314e-05
sam_encoder.blocks.0.norm2.weight grad: 0.008273279294371605
sam_encoder.blocks.0.norm2.bias grad: 0.001467795460484922
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.094784915447235e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0002198020665673539
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.001973276026546955
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00010039493645308539
sam_encoder.blocks.1.norm1.weight grad: -0.002331825438886881
sam_encoder.blocks.1.norm1.bias grad: -0.0007452657446265221
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0012775236973538995
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00048396256170235574
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0006444082246161997
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00022758037084713578
sam_encoder.blocks.1.norm2.weight grad: 0.0014560993295162916
sam_encoder.blocks.1.norm2.bias grad: -0.0005943654105067253
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0007379179587587714
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00017844401008915156
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.002017655409872532
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0007060106727294624
sam_encoder.blocks.2.norm1.weight grad: 0.001016078400425613
sam_encoder.blocks.2.norm1.bias grad: 0.0019125668331980705
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0001438036561012268
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.8980237402720377e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.000569427851587534
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0004899609484709799
sam_encoder.blocks.2.norm2.weight grad: 0.005403324496001005
sam_encoder.blocks.2.norm2.bias grad: -0.0011251382529735565
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0018856036476790905
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00035676415427587926
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00168209383264184
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00040370755596086383
sam_encoder.blocks.3.norm1.weight grad: 2.3300450266106054e-05
sam_encoder.blocks.3.norm1.bias grad: 0.0008735879091545939
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0016540831420570612
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0007018079049885273
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0015906825428828597
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0008811258594505489
sam_encoder.blocks.3.norm2.weight grad: -0.002655127551406622
sam_encoder.blocks.3.norm2.bias grad: -0.0019031257834285498
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0023175394162535667
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0005324582452885807
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0006044925539754331
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0003085479256696999
sam_encoder.blocks.4.norm1.weight grad: 0.0030287117697298527
sam_encoder.blocks.4.norm1.bias grad: -0.0014147533802315593
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.001282950397580862
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00025893072597682476
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.3635918953223154e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00013287176261655986
sam_encoder.blocks.4.norm2.weight grad: -0.003874704008921981
sam_encoder.blocks.4.norm2.bias grad: -0.0016878938768059015
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0030110476072877645
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0007049260893836617
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0005253165727481246
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00033102137967944145
sam_encoder.blocks.5.norm1.weight grad: 0.00017548189498484135
sam_encoder.blocks.5.norm1.bias grad: -0.004100685007870197
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0007194917416200042
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0003091006074100733
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002345528919249773
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0006120805046521127
sam_encoder.blocks.5.norm2.weight grad: -0.005315443500876427
sam_encoder.blocks.5.norm2.bias grad: 1.4049738638277631e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.003501330967992544
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0012410846538841724
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.3948457308288198e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00013892777496948838
sam_encoder.blocks.6.norm1.weight grad: 0.0014147432520985603
sam_encoder.blocks.6.norm1.bias grad: -0.0012098033912479877
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0005665813805535436
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003228813293389976
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.487211066996679e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.694960832945071e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0024364283308386803
sam_encoder.blocks.6.norm2.bias grad: 0.0004672524519264698
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0017488040030002594
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0007658106624148786
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00033291662111878395
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.696326115867123e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0006737746298313141
sam_encoder.blocks.7.norm1.bias grad: -0.0001993887563003227
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.12489675404504e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.534626587992534e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00042326116818003356
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00019398448057472706
sam_encoder.blocks.7.norm2.weight grad: -0.0008901182445697486
sam_encoder.blocks.7.norm2.bias grad: -7.358468428719789e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0008781814249232411
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0004140363016631454
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4047274817130528e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.7336005587130785e-05
sam_encoder.blocks.8.norm1.weight grad: 0.003061516210436821
sam_encoder.blocks.8.norm1.bias grad: -0.00011670932872220874
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00279342383146286
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0012084185145795345
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.0074770115315914e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00015471297956537455
sam_encoder.blocks.8.norm2.weight grad: -0.0005591366207227111
sam_encoder.blocks.8.norm2.bias grad: 0.00040267696022056043
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000641948776319623
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0002636792487464845
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00013130236766301095
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.131664849817753e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0010150400921702385
sam_encoder.blocks.9.norm1.bias grad: 8.33783415146172e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0010743560269474983
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0004134253831580281
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0005587146151810884
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00029584328876808286
sam_encoder.blocks.9.norm2.weight grad: -0.0013107159174978733
sam_encoder.blocks.9.norm2.bias grad: 0.00016342951857950538
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0012746388092637062
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00044940871885046363
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.1563339032582007e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.042753789690323e-05
sam_encoder.blocks.10.norm1.weight grad: -0.000448812497779727
sam_encoder.blocks.10.norm1.bias grad: -4.358382284408435e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0003362427232787013
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.944534783950076e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00022558378987014294
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00010006408410845324
sam_encoder.blocks.10.norm2.weight grad: -0.0027185152284801006
sam_encoder.blocks.10.norm2.bias grad: -3.965158248320222e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0016533869784325361
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.000609348644502461
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00021873970399610698
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.3714237108360976e-05
sam_encoder.blocks.11.norm1.weight grad: -0.005937111563980579
sam_encoder.blocks.11.norm1.bias grad: 0.00027247885009273887
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0010986070847138762
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0003579673357307911
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0006156237795948982
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00031677467632107437
sam_encoder.blocks.11.norm2.weight grad: -0.0039069196209311485
sam_encoder.blocks.11.norm2.bias grad: -0.0006413871888071299
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0014485077699646354
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0005969300400465727
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00037799030542373657
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.347191422013566e-05
sam_encoder.neck.conv1.trainable_scale grad: 0.00026486138813197613
sam_encoder.neck.conv1.trainable_shift grad: -0.003461503190919757
sam_encoder.neck.conv2.trainable_scale grad: 6.847293116152287e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.003036526497453451
mask_decoder.transformer.layers.0.norm1.weight grad: 0.03994147852063179
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0007112415041774511
mask_decoder.transformer.layers.0.norm2.weight grad: 0.21515418589115143
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0468905046582222
mask_decoder.transformer.layers.0.norm3.weight grad: 0.04083685204386711
mask_decoder.transformer.layers.0.norm3.bias grad: 0.013603916391730309
mask_decoder.transformer.layers.0.norm4.weight grad: 0.012107282876968384
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0005781110376119614
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0014415283221751451
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0014583705924451351
mask_decoder.transformer.layers.1.norm2.weight grad: 0.07203014940023422
mask_decoder.transformer.layers.1.norm2.bias grad: 0.026400823146104813
mask_decoder.transformer.layers.1.norm3.weight grad: 0.008484138175845146
mask_decoder.transformer.layers.1.norm3.bias grad: 0.005281602963805199
mask_decoder.transformer.layers.1.norm4.weight grad: 0.008991125971078873
mask_decoder.transformer.layers.1.norm4.bias grad: 0.015250817872583866
mask_decoder.transformer.norm_final_attn.weight grad: 1.8148450180888176e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0010999887017533183
Text_Embedding_Affine.0.weight grad: 1.960489548480382e-10
Text_Embedding_Affine.0.bias grad: -1.6298145055770874e-09
Text_Embedding_Affine.2.weight grad: 2.5666086145292866e-08
Text_Embedding_Affine.2.bias grad: -0.01169527042657137

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.007843105202595e-15
Max value: 0.9997383952140808
Mean value: 0.04883443936705589

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.007843105202595e-15
Max value: 0.9997383952140808
Mean value: 0.04883443936705589

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07363462448120117

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15068545937538147

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.03888988494873047

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07363462448120117

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.0
Max value: 79.21319580078125
Mean value: 34.68357467651367

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.007843105202595e-15
Max value: 0.9997383952140808
Mean value: 0.04883443936705589

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.007843105202595e-15
Max value: 0.9997383952140808
Mean value: 0.04883443936705589

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.007843105202595e-15
Max value: 0.9997383952140808
Mean value: 0.04883443936705589

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15068545937538147

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.0
Max value: 79.21319580078125
Mean value: 34.68357467651367

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -34.6843147277832
Max value: -34.6843147277832
Mean value: -34.6843147277832
sam_encoder.pos_embed grad: 8.737107464185101e-07
sam_encoder.blocks.0.norm1.weight grad: 0.005916706286370754
sam_encoder.blocks.0.norm1.bias grad: -9.324541315436363e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0010561741655692458
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.416481093969196e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0019054531585425138
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00039983796887099743
sam_encoder.blocks.0.norm2.weight grad: -9.950436651706696e-05
sam_encoder.blocks.0.norm2.bias grad: 0.004961028229445219
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0012424018932506442
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.723800182342529e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.004968507215380669
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.002090602181851864
sam_encoder.blocks.1.norm1.weight grad: -0.0009188521653413773
sam_encoder.blocks.1.norm1.bias grad: 0.0005978873814456165
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00048233720008283854
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0002078316465485841
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00017642839520704
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00017858733190223575
sam_encoder.blocks.1.norm2.weight grad: -0.002408046741038561
sam_encoder.blocks.1.norm2.bias grad: -0.0002462229167576879
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0013232649071142077
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0002673194685485214
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0007871665293350816
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00034189887810498476
sam_encoder.blocks.2.norm1.weight grad: -2.4184275389416143e-05
sam_encoder.blocks.2.norm1.bias grad: -0.00015046533371787518
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00030617607990279794
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00018603642820380628
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.000737627618946135
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0002612615644466132
sam_encoder.blocks.2.norm2.weight grad: 0.000985226477496326
sam_encoder.blocks.2.norm2.bias grad: -0.001524595427326858
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.000721307413186878
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0005338583723641932
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0007730385987088084
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00014999830455053598
sam_encoder.blocks.3.norm1.weight grad: -0.0014450636226683855
sam_encoder.blocks.3.norm1.bias grad: -0.0002948623150587082
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.00026390625862404704
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00010744093742687255
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00031149943242780864
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00014997419202700257
sam_encoder.blocks.3.norm2.weight grad: -0.0003519682213664055
sam_encoder.blocks.3.norm2.bias grad: -0.0006972606061026454
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005633639520965517
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0003215531469322741
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0009397296234965324
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00013398745795711875
sam_encoder.blocks.4.norm1.weight grad: -0.00081052997848019
sam_encoder.blocks.4.norm1.bias grad: -0.0018709739670157433
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0008313460275530815
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.099395199678838e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0004906723042950034
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002899172541219741
sam_encoder.blocks.4.norm2.weight grad: 0.008129159919917583
sam_encoder.blocks.4.norm2.bias grad: 0.004207140766084194
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.004645955748856068
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0015730196610093117
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.0357177820405923e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00024316417693626136
sam_encoder.blocks.5.norm1.weight grad: 0.00154424412176013
sam_encoder.blocks.5.norm1.bias grad: -0.0028371706139296293
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0022596437484025955
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0016847503138706088
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00010227641178062186
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00011911254841834307
sam_encoder.blocks.5.norm2.weight grad: 0.004518277011811733
sam_encoder.blocks.5.norm2.bias grad: 0.0029585654847323895
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0018761189421638846
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0007655639201402664
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00020718036103062332
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.602623787126504e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0005634367698803544
sam_encoder.blocks.6.norm1.bias grad: -0.0011711111292243004
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00027964654145762324
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00020866298291366547
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0003602019278332591
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.829440386965871e-05
sam_encoder.blocks.6.norm2.weight grad: 0.00123592559248209
sam_encoder.blocks.6.norm2.bias grad: 0.0006932889809831977
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0006080479361116886
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00022766033362131566
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.976409688126296e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00010141433449462056
sam_encoder.blocks.7.norm1.weight grad: -0.001131377648562193
sam_encoder.blocks.7.norm1.bias grad: 8.175442781066522e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0007794143166393042
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0003761352854780853
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0005236288998275995
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00010874582221731544
sam_encoder.blocks.7.norm2.weight grad: 7.86262535257265e-05
sam_encoder.blocks.7.norm2.bias grad: -6.455877883126959e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0008457707008346915
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00014826258120592684
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.131429108791053e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.0001966814452316612
sam_encoder.blocks.8.norm1.weight grad: -0.0005177340353839099
sam_encoder.blocks.8.norm1.bias grad: -3.230501533835195e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00023944499844219536
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00038052056333981454
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0004755408444907516
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00020681234309449792
sam_encoder.blocks.8.norm2.weight grad: 0.00018259676289744675
sam_encoder.blocks.8.norm2.bias grad: 0.0005746261449530721
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0002709404507186264
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.791458872612566e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00015602359781041741
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00024839278194122016
sam_encoder.blocks.9.norm1.weight grad: -0.00028251652838662267
sam_encoder.blocks.9.norm1.bias grad: 4.409634857438505e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0004271954530850053
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00028956131427548826
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00018614702275954187
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00016560053336434066
sam_encoder.blocks.9.norm2.weight grad: -0.0007648344035260379
sam_encoder.blocks.9.norm2.bias grad: 0.00044755422277376056
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0010008150711655617
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00030648912070319057
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00018739413644652814
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00011927814921364188
sam_encoder.blocks.10.norm1.weight grad: -0.0016572067979723215
sam_encoder.blocks.10.norm1.bias grad: -0.00014655185805168003
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0010973569005727768
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.000439983035903424
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0005739511689171195
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.0003106436342932284
sam_encoder.blocks.10.norm2.weight grad: -0.0013513121521100402
sam_encoder.blocks.10.norm2.bias grad: 0.0003365547163411975
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0010481936624273658
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00038284630863927305
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.85082665970549e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.586380186490715e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0033200010657310486
sam_encoder.blocks.11.norm1.bias grad: -7.178254600148648e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0005253457347862422
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00016964151291176677
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00046806735917925835
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00021416356321424246
sam_encoder.blocks.11.norm2.weight grad: -0.0016862249467521906
sam_encoder.blocks.11.norm2.bias grad: -0.00021177319285925478
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0008196757989935577
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00017288564413320273
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.535090506076813e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.5649975214037113e-05
sam_encoder.neck.conv1.trainable_scale grad: 0.0001696450635790825
sam_encoder.neck.conv1.trainable_shift grad: 0.0006667512934654951
sam_encoder.neck.conv2.trainable_scale grad: 0.00027092546224594116
sam_encoder.neck.conv2.trainable_shift grad: 0.0032345065847039223
mask_decoder.transformer.layers.0.norm1.weight grad: 0.02533011883497238
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0005085757002234459
mask_decoder.transformer.layers.0.norm2.weight grad: 1.1143989562988281
mask_decoder.transformer.layers.0.norm2.bias grad: -0.018838778138160706
mask_decoder.transformer.layers.0.norm3.weight grad: 0.009294447489082813
mask_decoder.transformer.layers.0.norm3.bias grad: 0.005687211640179157
mask_decoder.transformer.layers.0.norm4.weight grad: -0.022525381296873093
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0029699800070375204
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0008294150466099381
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0007917871698737144
mask_decoder.transformer.layers.1.norm2.weight grad: 0.015380682423710823
mask_decoder.transformer.layers.1.norm2.bias grad: 0.006642397027462721
mask_decoder.transformer.layers.1.norm3.weight grad: -0.007779707666486502
mask_decoder.transformer.layers.1.norm3.bias grad: -0.002382404636591673
mask_decoder.transformer.layers.1.norm4.weight grad: 0.003155302722007036
mask_decoder.transformer.layers.1.norm4.bias grad: 0.035285770893096924
mask_decoder.transformer.norm_final_attn.weight grad: -0.00029336183797568083
mask_decoder.transformer.norm_final_attn.bias grad: -0.003124780720099807
Text_Embedding_Affine.0.weight grad: 1.032414598256537e-09
Text_Embedding_Affine.0.bias grad: 3.9872247725725174e-08
Text_Embedding_Affine.2.weight grad: -2.227229289886168e-09
Text_Embedding_Affine.2.bias grad: -0.010038861073553562

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.014386971370714e-13
Max value: 0.9978795051574707
Mean value: 0.07076738029718399

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.014386971370714e-13
Max value: 0.9978795051574707
Mean value: 0.07076738029718399

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07682514190673828

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13568153977394104

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.042354583740234375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07682514190673828

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 13.34946060180664
Max value: 54.945133209228516
Mean value: 41.56351852416992

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.014386971370714e-13
Max value: 0.9978795051574707
Mean value: 0.07076738029718399

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.014386971370714e-13
Max value: 0.9978795051574707
Mean value: 0.07076738029718399

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.014386971370714e-13
Max value: 0.9978795051574707
Mean value: 0.07076738029718399

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13568153977394104

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 13.34946060180664
Max value: 54.945133209228516
Mean value: 41.56351852416992

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -41.56494140625
Max value: -41.56494140625
Mean value: -41.56494140625
sam_encoder.pos_embed grad: -1.6032126382015122e-07
sam_encoder.blocks.0.norm1.weight grad: -0.002114764181897044
sam_encoder.blocks.0.norm1.bias grad: 0.00475081754848361
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.083566065877676e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.5976766007952392e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00040977372555062175
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00019314081873744726
sam_encoder.blocks.0.norm2.weight grad: 0.005292703863233328
sam_encoder.blocks.0.norm2.bias grad: 0.001704561524093151
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.00037815046380274
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0007352092652581632
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0025716507807374
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0011096508242189884
sam_encoder.blocks.1.norm1.weight grad: 0.0001225111773237586
sam_encoder.blocks.1.norm1.bias grad: 0.000419365125708282
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.084442480234429e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.25954928889405e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00016109790885820985
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.6323083400493488e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0023946550209075212
sam_encoder.blocks.1.norm2.bias grad: -0.00023556067026220262
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.4453445298131555e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.787513898918405e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.765771791426232e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00022908500977791846
sam_encoder.blocks.2.norm1.weight grad: 0.00023300635803025216
sam_encoder.blocks.2.norm1.bias grad: 0.00011588736379053444
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.001969788689166e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00011646880011539906
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003901938907802105
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00036438682582229376
sam_encoder.blocks.2.norm2.weight grad: -0.00024143827613443136
sam_encoder.blocks.2.norm2.bias grad: -0.0015793483471497893
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0001666691096033901
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00021947346976958215
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.788209192454815e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00024969413061626256
sam_encoder.blocks.3.norm1.weight grad: -0.00047864994849078357
sam_encoder.blocks.3.norm1.bias grad: -0.00010005771036958322
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0012610562844201922
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00031754898373037577
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005455509526655078
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0002250012184958905
sam_encoder.blocks.3.norm2.weight grad: 0.0008299471810460091
sam_encoder.blocks.3.norm2.bias grad: -0.0006186925456859171
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0008067150483839214
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.000450496154371649
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0005049840547144413
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.013809954514727e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0012865567114204168
sam_encoder.blocks.4.norm1.bias grad: -9.157151907857042e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0009792987257242203
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00019544977112673223
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0004971274174749851
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003215254982933402
sam_encoder.blocks.4.norm2.weight grad: -0.0045647588558495045
sam_encoder.blocks.4.norm2.bias grad: -0.002639676444232464
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0028616823256015778
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0010402182815596461
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0002664008643478155
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0002564976457506418
sam_encoder.blocks.5.norm1.weight grad: 0.0010165598941966891
sam_encoder.blocks.5.norm1.bias grad: -0.0005693743005394936
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0006903549074195325
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00022719064145348966
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.798618490691297e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.65270240965765e-05
sam_encoder.blocks.5.norm2.weight grad: -0.00274666678160429
sam_encoder.blocks.5.norm2.bias grad: -0.001532257068902254
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0011988086625933647
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0004494911408983171
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00017611205112189054
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.050486288382672e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0002798591158352792
sam_encoder.blocks.6.norm1.bias grad: 0.0004985467530786991
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0002642213075887412
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0001092646416509524
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.9675722796819173e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.000215564708923921
sam_encoder.blocks.6.norm2.weight grad: -0.0016265574377030134
sam_encoder.blocks.6.norm2.bias grad: -0.00012515424168668687
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0011938613606616855
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0004709962522611022
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00011613166134338826
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.685028473730199e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0010478226467967033
sam_encoder.blocks.7.norm1.bias grad: 6.838061381131411e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.000650015368591994
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.000377246382413432
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00012501480523496866
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0001580420503159985
sam_encoder.blocks.7.norm2.weight grad: -0.0004992826143279672
sam_encoder.blocks.7.norm2.bias grad: 0.00011300864571239799
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00010902910435106605
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.237169145606458e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.982864993507974e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.544097151258029e-05
sam_encoder.blocks.8.norm1.weight grad: 0.001340205199085176
sam_encoder.blocks.8.norm1.bias grad: -0.00014326762175187469
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0008149337954819202
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00010050693526864052
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00014257754082791507
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00012545751815196127
sam_encoder.blocks.8.norm2.weight grad: -0.0005225226050242782
sam_encoder.blocks.8.norm2.bias grad: -0.00033070085919462144
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00028903785278089345
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0001947954879142344
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0001237036194652319
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00010366175411036238
sam_encoder.blocks.9.norm1.weight grad: -8.081227861111984e-05
sam_encoder.blocks.9.norm1.bias grad: -9.288216824643314e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.950439193227794e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.1422848880756646e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.001851241104305e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0001870188134489581
sam_encoder.blocks.9.norm2.weight grad: -0.00015025492757558823
sam_encoder.blocks.9.norm2.bias grad: -0.00017649270012043417
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.9623315893113613e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.440800330485217e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.8901811674586497e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.600483124610037e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0006905168993398547
sam_encoder.blocks.10.norm1.bias grad: 4.207721940474585e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0004475672612898052
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00016397456056438386
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00020957703236490488
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00010976220801239833
sam_encoder.blocks.10.norm2.weight grad: 6.746411963831633e-05
sam_encoder.blocks.10.norm2.bias grad: -0.0001246635802090168
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.775687324989121e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.6851310142083094e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.099926006048918e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.6270404709503055e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0013646961888298392
sam_encoder.blocks.11.norm1.bias grad: 0.00031366836628876626
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.000514086103066802
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00010485580423846841
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00022685012663714588
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.574069266207516e-05
sam_encoder.blocks.11.norm2.weight grad: -0.000323980551911518
sam_encoder.blocks.11.norm2.bias grad: 3.354592990945093e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.322360498714261e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00010227064194623381
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.6180055253207684e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.193535904865712e-05
sam_encoder.neck.conv1.trainable_scale grad: -2.9148533940315247e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.004687446169555187
sam_encoder.neck.conv2.trainable_scale grad: -0.00018288404680788517
sam_encoder.neck.conv2.trainable_shift grad: -0.0020531865302473307
mask_decoder.transformer.layers.0.norm1.weight grad: -0.009477335028350353
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0004808129742741585
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3645327687263489
mask_decoder.transformer.layers.0.norm2.bias grad: -0.02891876921057701
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0014575679088011384
mask_decoder.transformer.layers.0.norm3.bias grad: -0.005495251622051001
mask_decoder.transformer.layers.0.norm4.weight grad: 0.012012009508907795
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0007179925451055169
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0012665677350014448
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0005567196058109403
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0012264735996723175
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0003383709117770195
mask_decoder.transformer.layers.1.norm3.weight grad: 0.006281794048845768
mask_decoder.transformer.layers.1.norm3.bias grad: 4.869280382990837e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -0.005442261695861816
mask_decoder.transformer.layers.1.norm4.bias grad: -0.02840125747025013
mask_decoder.transformer.norm_final_attn.weight grad: 1.769978553056717e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0012424192391335964
Text_Embedding_Affine.0.weight grad: -1.6308513428597848e-09
Text_Embedding_Affine.0.bias grad: -5.422043614089489e-08
Text_Embedding_Affine.2.weight grad: 6.2729643701686655e-09
Text_Embedding_Affine.2.bias grad: 0.0018397392705082893
Epoch 14 finished with average loss: -38.0358
Epoch 15/39
----------
Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, loss=-40.1]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-40.1]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-38.2]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-38.2]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-38.1]Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-38.1]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8858595240978104e-12
Max value: 0.9976198077201843
Mean value: 0.06897331029176712

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8858595240978104e-12
Max value: 0.9976198077201843
Mean value: 0.06897331029176712

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08922386169433594

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1566542685031891

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04694938659667969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08922386169433594

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.0
Max value: 82.38375854492188
Mean value: 40.070953369140625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8858595240978104e-12
Max value: 0.9976198077201843
Mean value: 0.06897331029176712

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8858595240978104e-12
Max value: 0.9976198077201843
Mean value: 0.06897331029176712

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8858595240978104e-12
Max value: 0.9976198077201843
Mean value: 0.06897331029176712

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1566542685031891

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.0
Max value: 82.38375854492188
Mean value: 40.070953369140625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -40.07222366333008
Max value: -40.07222366333008
Mean value: -40.07222366333008
sam_encoder.pos_embed grad: 3.064356945969848e-08
sam_encoder.blocks.0.norm1.weight grad: 0.0008479919051751494
sam_encoder.blocks.0.norm1.bias grad: -0.0028958998154848814
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.3823376977816224e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.763104465790093e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00020782188221346587
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.3615407523466274e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0038052161689847708
sam_encoder.blocks.0.norm2.bias grad: 0.0010183366248384118
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0007625045254826546
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00017924774147104472
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0007010879926383495
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0002343631349503994
sam_encoder.blocks.1.norm1.weight grad: -0.0015402527060359716
sam_encoder.blocks.1.norm1.bias grad: 1.7903590560308658e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005539843696169555
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00015096421702764928
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00040827327757142484
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00024262195802293718
sam_encoder.blocks.1.norm2.weight grad: 3.658458354038885e-06
sam_encoder.blocks.1.norm2.bias grad: -0.0002920401457231492
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0002843786496669054
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.226862802170217e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0003801191342063248
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.54037285130471e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0001503071835031733
sam_encoder.blocks.2.norm1.bias grad: 0.0006218869239091873
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.9261783462716267e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.990224629684235e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00027857886743731797
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00021406871383078396
sam_encoder.blocks.2.norm2.weight grad: 0.0005386814009398222
sam_encoder.blocks.2.norm2.bias grad: -0.00036989719956181943
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00029866426484659314
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.1064340621232986e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00023568072356283665
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.207048575859517e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0001807862863643095
sam_encoder.blocks.3.norm1.bias grad: -0.0005694390274584293
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0002643989573698491
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00015885887842159718
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00017395660688634962
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00031676588696427643
sam_encoder.blocks.3.norm2.weight grad: -0.0003110806574113667
sam_encoder.blocks.3.norm2.bias grad: -1.9353272364242002e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0003565020742826164
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.891835826332681e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0004326092021074146
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.072882049717009e-05
sam_encoder.blocks.4.norm1.weight grad: 0.002022341126576066
sam_encoder.blocks.4.norm1.bias grad: -0.00012011333456030115
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0011520314728841186
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002487126912456006
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00028951652348041534
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00014502668636851013
sam_encoder.blocks.4.norm2.weight grad: -0.001332953805103898
sam_encoder.blocks.4.norm2.bias grad: -0.0003541045298334211
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.001018150825984776
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00029476790223270655
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.606614912627265e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.683271511865314e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0019192484905943274
sam_encoder.blocks.5.norm1.bias grad: -0.00016611607861705124
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0015319016529247165
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0004217427340336144
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.569669782649726e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0002414592308923602
sam_encoder.blocks.5.norm2.weight grad: -0.0012611171696335077
sam_encoder.blocks.5.norm2.bias grad: 0.00011445432028267533
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0009660464711487293
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00039133624522946775
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -4.043225635541603e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.80791015131399e-06
sam_encoder.blocks.6.norm1.weight grad: 0.00032688159262761474
sam_encoder.blocks.6.norm1.bias grad: -0.0002460513496771455
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00024684483651071787
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0001591438485775143
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.1693146007019095e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.227794751292095e-05
sam_encoder.blocks.6.norm2.weight grad: -0.00014152149378787726
sam_encoder.blocks.6.norm2.bias grad: 0.00027638213941827416
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0002957659016828984
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.926904850639403e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0001306563790421933
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.569935456151143e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00039973948150873184
sam_encoder.blocks.7.norm1.bias grad: 8.693584095453843e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.9296108045382425e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.442130724171875e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.3207696105819196e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.184916436614003e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0005710149416700006
sam_encoder.blocks.7.norm2.bias grad: 0.00016561857773922384
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0006789749022573233
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0003260212833993137
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002990963403135538
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.6589672415866517e-05
sam_encoder.blocks.8.norm1.weight grad: 0.000769181817304343
sam_encoder.blocks.8.norm1.bias grad: 0.00015976125723682344
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.000517489155754447
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00026098533999174833
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00018091143283527344
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.05005435924977e-05
sam_encoder.blocks.8.norm2.weight grad: -7.733621168881655e-05
sam_encoder.blocks.8.norm2.bias grad: 0.00011194750550203025
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00014134537195786834
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.24660640116781e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.06258904049173e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.993249265477061e-05
sam_encoder.blocks.9.norm1.weight grad: 6.129439134383574e-05
sam_encoder.blocks.9.norm1.bias grad: -5.002065790904453e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.602766658645123e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.419035632163286e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0001073961248039268
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.016078310087323e-05
sam_encoder.blocks.9.norm2.weight grad: -2.555008450144669e-06
sam_encoder.blocks.9.norm2.bias grad: 0.00019041766063310206
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00018230678688269109
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.619089173094835e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0001431673881597817
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.611446926603094e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00026868784334510565
sam_encoder.blocks.10.norm1.bias grad: 5.1463342970237136e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0001439844781998545
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.96099928568583e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.890845502814045e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.974827293655835e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0005151205696165562
sam_encoder.blocks.10.norm2.bias grad: 1.3519427739083767e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00037033832632005215
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0001497873745393008
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.099418245255947e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.212709659943357e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0004900032072328031
sam_encoder.blocks.11.norm1.bias grad: 0.00010679990373319015
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.8434517187415622e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.9738946472643875e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.012491550995037e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7816597392084077e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0005545152234844863
sam_encoder.blocks.11.norm2.bias grad: -0.00026000503567047417
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00012629495176952332
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.049733878578991e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.916131289675832e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.5394121621502563e-05
sam_encoder.neck.conv1.trainable_scale grad: 6.958167068660259e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0007741071749478579
sam_encoder.neck.conv2.trainable_scale grad: 3.96376708522439e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.005661101546138525
mask_decoder.transformer.layers.0.norm1.weight grad: 0.005698384251445532
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00013209856115281582
mask_decoder.transformer.layers.0.norm2.weight grad: 0.09589153528213501
mask_decoder.transformer.layers.0.norm2.bias grad: 0.004857361316680908
mask_decoder.transformer.layers.0.norm3.weight grad: 0.005865809507668018
mask_decoder.transformer.layers.0.norm3.bias grad: 0.004499759059399366
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0015086147468537092
mask_decoder.transformer.layers.0.norm4.bias grad: 4.355679266154766e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0006950583774596453
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0002857721410691738
mask_decoder.transformer.layers.1.norm2.weight grad: 0.013128614984452724
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0029397199396044016
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0010928141418844461
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0006759355310350657
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0007173474878072739
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0039931535720825195
mask_decoder.transformer.norm_final_attn.weight grad: -7.03390542184934e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0006264190888032317
Text_Embedding_Affine.0.weight grad: 8.823480834863062e-10
Text_Embedding_Affine.0.bias grad: 6.170012056827545e-09
Text_Embedding_Affine.2.weight grad: 3.2927280901873246e-09
Text_Embedding_Affine.2.bias grad: -0.003363849828019738

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.17898998737106e-14
Max value: 0.9965576529502869
Mean value: 0.07042350620031357

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.17898998737106e-14
Max value: 0.9965576529502869
Mean value: 0.07042350620031357

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08484268188476562

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1367185115814209

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.055933475494384766

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08484268188476562

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.7196613550186157
Max value: 68.434814453125
Mean value: 36.368896484375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.17898998737106e-14
Max value: 0.9965576529502869
Mean value: 0.07042350620031357

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.17898998737106e-14
Max value: 0.9965576529502869
Mean value: 0.07042350620031357

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.17898998737106e-14
Max value: 0.9965576529502869
Mean value: 0.07042350620031357

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1367185115814209

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.7196613550186157
Max value: 68.434814453125
Mean value: 36.368896484375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -36.3699951171875
Max value: -36.3699951171875
Mean value: -36.3699951171875
sam_encoder.pos_embed grad: -8.225653687077283e-07
sam_encoder.blocks.0.norm1.weight grad: 0.01152462512254715
sam_encoder.blocks.0.norm1.bias grad: 0.0010439655743539333
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0008245170465670526
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.246196335268905e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0026102622505277395
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0004944228567183018
sam_encoder.blocks.0.norm2.weight grad: 0.002943559316918254
sam_encoder.blocks.0.norm2.bias grad: 0.015837693586945534
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.004859043285250664
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0018757069483399391
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0018228370463475585
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0012441566213965416
sam_encoder.blocks.1.norm1.weight grad: 8.074466313701123e-05
sam_encoder.blocks.1.norm1.bias grad: -0.0005285478546284139
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.013483339804225e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00016200558457057923
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00023698771838098764
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00011852614989038557
sam_encoder.blocks.1.norm2.weight grad: 0.0005508497124537826
sam_encoder.blocks.1.norm2.bias grad: 0.00044593814527615905
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0010878783650696278
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0001426728122169152
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0009184961090795696
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00017362952348776162
sam_encoder.blocks.2.norm1.weight grad: 0.0014400631189346313
sam_encoder.blocks.2.norm1.bias grad: -4.606437869369984e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0007615098729729652
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0003842259175144136
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.000327070418279618
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.258144614752382e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0012543818447738886
sam_encoder.blocks.2.norm2.bias grad: -0.0012161266058683395
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0008988165063783526
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0004385052598081529
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00012681595399044454
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.174458394525573e-05
sam_encoder.blocks.3.norm1.weight grad: 0.00044677010737359524
sam_encoder.blocks.3.norm1.bias grad: 3.896983616868965e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0007570100715383887
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.275382237508893e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0007405267097055912
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00020544443395920098
sam_encoder.blocks.3.norm2.weight grad: 0.0018429190386086702
sam_encoder.blocks.3.norm2.bias grad: 0.0009608682012185454
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0014248898951336741
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00022121856454759836
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00028285011649131775
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.565913256257772e-05
sam_encoder.blocks.4.norm1.weight grad: 0.002159279538318515
sam_encoder.blocks.4.norm1.bias grad: -0.0023000212386250496
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.001225786516442895
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005973320221528411
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0003062024188693613
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0002773759770207107
sam_encoder.blocks.4.norm2.weight grad: 0.003445838578045368
sam_encoder.blocks.4.norm2.bias grad: 0.0024479632265865803
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0016270224004983902
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0003035718691535294
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0003620695788413286
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.86888675368391e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0030629076063632965
sam_encoder.blocks.5.norm1.bias grad: -0.003818175755441189
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.002913836156949401
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.001747102476656437
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002503860159777105
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0003803260042332113
sam_encoder.blocks.5.norm2.weight grad: 0.0022619038354605436
sam_encoder.blocks.5.norm2.bias grad: 0.001971780089661479
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0008693102281540632
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0003677305649034679
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.712391041219234e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.146065864712e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0006418620469048619
sam_encoder.blocks.6.norm1.bias grad: -0.00074723333818838
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0002751395804807544
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003067767829634249
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00013379935990087688
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00010852037667063996
sam_encoder.blocks.6.norm2.weight grad: -0.0005395670305006206
sam_encoder.blocks.6.norm2.bias grad: -0.000299714389257133
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0007113049505278468
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0003650319413281977
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0001160160027211532
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.208083611156326e-06
sam_encoder.blocks.7.norm1.weight grad: 2.767696787486784e-05
sam_encoder.blocks.7.norm1.bias grad: 0.00026530437753535807
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00014194587129168212
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00015512335812672973
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.987772500608116e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0006333396886475384
sam_encoder.blocks.7.norm2.weight grad: -0.0009977290173992515
sam_encoder.blocks.7.norm2.bias grad: -1.3374490663409233e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.001415491453371942
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.000495577638503164
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00020294796559028327
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.23817026684992e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0004635320510715246
sam_encoder.blocks.8.norm1.bias grad: -0.00013442695490084589
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0003123232163488865
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.34982027602382e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00024691782891750336
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.226964615052566e-05
sam_encoder.blocks.8.norm2.weight grad: 0.000609642593190074
sam_encoder.blocks.8.norm2.bias grad: 0.00015031499788165092
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00024949925136752427
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0002684188075363636
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0005917878588661551
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0003472554381005466
sam_encoder.blocks.9.norm1.weight grad: 0.0002082411083392799
sam_encoder.blocks.9.norm1.bias grad: 0.00016078412591014057
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.511487946321722e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.8657883629202843e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.680260149645619e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0002932320348918438
sam_encoder.blocks.9.norm2.weight grad: 0.0007197335362434387
sam_encoder.blocks.9.norm2.bias grad: 0.00033069850178435445
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00012109139788663015
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0003025387122761458
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0003347510355524719
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0002658782759681344
sam_encoder.blocks.10.norm1.weight grad: -0.0004948820569552481
sam_encoder.blocks.10.norm1.bias grad: 0.00019471216364763677
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0003459538274910301
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.4673822382465e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0002110353671014309
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.207125261425972e-05
sam_encoder.blocks.10.norm2.weight grad: 0.001364073483273387
sam_encoder.blocks.10.norm2.bias grad: 0.000734947738237679
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0001433135475963354
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00033096771221607924
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00023329925897996873
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.00011344788799760863
sam_encoder.blocks.11.norm1.weight grad: 0.00026033524773083627
sam_encoder.blocks.11.norm1.bias grad: 0.0001828770327847451
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00042800826486200094
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.6743800844997168e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0001198133613797836
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00016214544302783906
sam_encoder.blocks.11.norm2.weight grad: 0.001026141457259655
sam_encoder.blocks.11.norm2.bias grad: -0.00013904430670663714
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00030981539748609066
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0002938422258011997
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00028527231188490987
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00015217126929201186
sam_encoder.neck.conv1.trainable_scale grad: 0.0002077661920338869
sam_encoder.neck.conv1.trainable_shift grad: 0.0013711703941226006
sam_encoder.neck.conv2.trainable_scale grad: 0.0001231054775416851
sam_encoder.neck.conv2.trainable_shift grad: -0.008903289213776588
mask_decoder.transformer.layers.0.norm1.weight grad: 0.032557807862758636
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0007726019248366356
mask_decoder.transformer.layers.0.norm2.weight grad: 0.2906545102596283
mask_decoder.transformer.layers.0.norm2.bias grad: -0.2633616626262665
mask_decoder.transformer.layers.0.norm3.weight grad: 0.014632582664489746
mask_decoder.transformer.layers.0.norm3.bias grad: -0.005103811621665955
mask_decoder.transformer.layers.0.norm4.weight grad: -0.007232366129755974
mask_decoder.transformer.layers.0.norm4.bias grad: -9.207869879901409e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0011233729310333729
mask_decoder.transformer.layers.1.norm1.bias grad: 6.198685150593519e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.01853509247303009
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0028134910389781
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0064072152599692345
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0051018232479691505
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0049885897897183895
mask_decoder.transformer.layers.1.norm4.bias grad: 0.001159077975898981
mask_decoder.transformer.norm_final_attn.weight grad: -0.0005444114794954658
mask_decoder.transformer.norm_final_attn.bias grad: -0.0009100736351683736
Text_Embedding_Affine.0.weight grad: 2.0674812972742984e-09
Text_Embedding_Affine.0.bias grad: 8.09086486697197e-08
Text_Embedding_Affine.2.weight grad: -2.153277334215886e-09
Text_Embedding_Affine.2.bias grad: -0.010319300927221775

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.033315001428228e-11
Max value: 0.9967353940010071
Mean value: 0.050611712038517

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.033315001428228e-11
Max value: 0.9967353940010071
Mean value: 0.050611712038517

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07035255432128906

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.439942359924316
Max value: -1.1920928244535389e-07
Mean value: -0.12162161618471146

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.03513813018798828

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07035255432128906

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 7.974413871765137
Max value: 69.79178619384766
Mean value: 37.85832977294922

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.033315001428228e-11
Max value: 0.9967353940010071
Mean value: 0.050611712038517

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.033315001428228e-11
Max value: 0.9967353940010071
Mean value: 0.050611712038517

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.033315001428228e-11
Max value: 0.9967353940010071
Mean value: 0.050611712038517

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.439942359924316
Max value: -1.1920928244535389e-07
Mean value: -0.12162161618471146

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 7.974413871765137
Max value: 69.79178619384766
Mean value: 37.85832977294922

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -37.859256744384766
Max value: -37.859256744384766
Mean value: -37.859256744384766
sam_encoder.pos_embed grad: -4.7006767545099137e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0015280371299013495
sam_encoder.blocks.0.norm1.bias grad: 0.0023938934318721294
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0005421468522399664
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.643206011678558e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0008874036138877273
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0002749798004515469
sam_encoder.blocks.0.norm2.weight grad: 0.0005447691073641181
sam_encoder.blocks.0.norm2.bias grad: 0.006415414623916149
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0012252115411683917
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0006562006892636418
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0002388639550190419
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00041157484520226717
sam_encoder.blocks.1.norm1.weight grad: -0.001110343262553215
sam_encoder.blocks.1.norm1.bias grad: -0.0006696360069327056
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00012070522643625736
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00010602484690025449
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.543200576445088e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.015843657612095e-08
sam_encoder.blocks.1.norm2.weight grad: 0.0010091313160955906
sam_encoder.blocks.1.norm2.bias grad: 9.934321496984921e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.000223277005716227
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.805961649864912e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0006046349299140275
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3856023542757612e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0003961764741688967
sam_encoder.blocks.2.norm1.bias grad: 3.290137829026207e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.000196342560229823
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00012512828106991947
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.0918326451210305e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00013051158748567104
sam_encoder.blocks.2.norm2.weight grad: 0.000908688991330564
sam_encoder.blocks.2.norm2.bias grad: -0.00046144588850438595
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0006334356730803847
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0001907911355374381
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0005713436403311789
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 4.428101237863302e-05
sam_encoder.blocks.3.norm1.weight grad: 7.122650276869535e-05
sam_encoder.blocks.3.norm1.bias grad: -0.00038711208617314696
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0003876474220305681
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.160206455911975e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0004115861374884844
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00021151061810087413
sam_encoder.blocks.3.norm2.weight grad: 0.001612578285858035
sam_encoder.blocks.3.norm2.bias grad: 0.00044514655019156635
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0011320649646222591
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0002972433576360345
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0002457287919241935
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.581672252854332e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0015227964613586664
sam_encoder.blocks.4.norm1.bias grad: -0.0007542941602878273
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.000920852820854634
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00029250478837639093
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00039024229045026004
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00047203549183905125
sam_encoder.blocks.4.norm2.weight grad: -5.6749424402369186e-05
sam_encoder.blocks.4.norm2.bias grad: -0.0011498348321765661
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1268809430475812e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.712276369100437e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00030114472610875964
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00010606527212075889
sam_encoder.blocks.5.norm1.weight grad: 0.001831337227486074
sam_encoder.blocks.5.norm1.bias grad: -0.000421831791754812
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.001226869411766529
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00036573217948898673
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0003770766779780388
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0002293385041411966
sam_encoder.blocks.5.norm2.weight grad: 0.0005069179460406303
sam_encoder.blocks.5.norm2.bias grad: -0.00035555835347622633
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0003609294071793556
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00012895974214188755
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0002438840747345239
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.525077383732423e-05
sam_encoder.blocks.6.norm1.weight grad: -3.854637543554418e-05
sam_encoder.blocks.6.norm1.bias grad: 0.00026827261899597943
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.351948594674468e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.79855326982215e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.4601547920610756e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.542386017827084e-06
sam_encoder.blocks.6.norm2.weight grad: -0.000490799720864743
sam_encoder.blocks.6.norm2.bias grad: -0.00019414577400311828
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00045753404265269637
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00022671026817988604
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.886235157959163e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.417438660515472e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0005492950440384448
sam_encoder.blocks.7.norm1.bias grad: -5.247770604910329e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00046214237227104604
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00019832269754260778
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00022060514311306179
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00030864914879202843
sam_encoder.blocks.7.norm2.weight grad: -0.00013265429879538715
sam_encoder.blocks.7.norm2.bias grad: -2.8567392291733995e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00016061076894402504
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00010919134365394711
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.391121132764965e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.56862316140905e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0001517740311101079
sam_encoder.blocks.8.norm1.bias grad: -3.959149580623489e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00018064862524624914
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.29668216384016e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00012509096995927393
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.297373066539876e-05
sam_encoder.blocks.8.norm2.weight grad: 0.00029048504075035453
sam_encoder.blocks.8.norm2.bias grad: 4.405000709084561e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0001594924251548946
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.212284203385934e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.000107835658127442
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.407841722946614e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0003116065636277199
sam_encoder.blocks.9.norm1.bias grad: -6.974414191063261e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00024306790146511048
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.166310802451335e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.744146569166332e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.622937846463174e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0006464043399319053
sam_encoder.blocks.9.norm2.bias grad: 0.00017281532927881926
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00029171135975047946
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0002473620406817645
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.580878445878625e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.7358215700369328e-06
sam_encoder.blocks.10.norm1.weight grad: 0.00016484285879414529
sam_encoder.blocks.10.norm1.bias grad: 8.355217869393528e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0001495261094532907
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.989001536159776e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.7459622288006358e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.1067902707727626e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0011450923047959805
sam_encoder.blocks.10.norm2.bias grad: 0.00032683482277207077
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00032505986746400595
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00027760936063714325
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00015524665650445968
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.8897495212731883e-05
sam_encoder.blocks.11.norm1.weight grad: 0.000956247968133539
sam_encoder.blocks.11.norm1.bias grad: 6.347279122564942e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0003150364791508764
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.960632840171456e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0001181448096758686
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.644275915983599e-06
sam_encoder.blocks.11.norm2.weight grad: 0.0009184827795252204
sam_encoder.blocks.11.norm2.bias grad: 2.45706378336763e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00029321969486773014
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00016627387958578765
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00014690439275000244
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00010358309373259544
sam_encoder.neck.conv1.trainable_scale grad: 5.496758967638016e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.000781654380261898
sam_encoder.neck.conv2.trainable_scale grad: 3.101630136370659e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0026574288494884968
mask_decoder.transformer.layers.0.norm1.weight grad: 0.015917373821139336
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0003444105386734009
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0009891577064990997
mask_decoder.transformer.layers.0.norm2.bias grad: -0.19161531329154968
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0060508656315505505
mask_decoder.transformer.layers.0.norm3.bias grad: -0.002257992047816515
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0009728632867336273
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0006679156213067472
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0008235214627347887
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0003823178121820092
mask_decoder.transformer.layers.1.norm2.weight grad: -0.018297411501407623
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00517030106857419
mask_decoder.transformer.layers.1.norm3.weight grad: -0.004519466310739517
mask_decoder.transformer.layers.1.norm3.bias grad: -0.003816226962953806
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0021961680613458157
mask_decoder.transformer.layers.1.norm4.bias grad: -0.003760279156267643
mask_decoder.transformer.norm_final_attn.weight grad: -7.937570626381785e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.00037070101825520396
Text_Embedding_Affine.0.weight grad: 2.632712048367125e-09
Text_Embedding_Affine.0.bias grad: 1.2130476534366608e-07
Text_Embedding_Affine.2.weight grad: 5.6072750886926315e-09
Text_Embedding_Affine.2.bias grad: -0.004556093364953995
Epoch 15 finished with average loss: -38.1005
Epoch 16/39
----------
Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s, loss=-33.1]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-33.1]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-36.7]Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-36.7]Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-36.8]Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-36.8]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9102618098454371e-10
Max value: 0.9786893725395203
Mean value: 0.06768029928207397

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9102618098454371e-10
Max value: 0.9786893725395203
Mean value: 0.06768029928207397

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08533287048339844

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.936132431030273
Max value: -1.1920928244535389e-07
Mean value: -0.142429381608963

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0416407585144043

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08533287048339844

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 11.466838836669922
Max value: 81.31251525878906
Mean value: 33.11503982543945

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9102618098454371e-10
Max value: 0.9786893725395203
Mean value: 0.06768029928207397

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9102618098454371e-10
Max value: 0.9786893725395203
Mean value: 0.06768029928207397

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9102618098454371e-10
Max value: 0.9786893725395203
Mean value: 0.06768029928207397

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.936132431030273
Max value: -1.1920928244535389e-07
Mean value: -0.142429381608963

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 11.466838836669922
Max value: 81.31251525878906
Mean value: 33.11503982543945

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -33.11636734008789
Max value: -33.11636734008789
Mean value: -33.11636734008789
sam_encoder.pos_embed grad: -1.6570909338042838e-06
sam_encoder.blocks.0.norm1.weight grad: -0.011457303538918495
sam_encoder.blocks.0.norm1.bias grad: -0.0037652719765901566
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0005362658994272351
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.9363164028618485e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0003600022755563259
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00039638610905967653
sam_encoder.blocks.0.norm2.weight grad: -0.0007148301228880882
sam_encoder.blocks.0.norm2.bias grad: 0.006052487995475531
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0018139028688892722
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0011377781629562378
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.003449553158134222
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0014554867520928383
sam_encoder.blocks.1.norm1.weight grad: -0.0012278034118935466
sam_encoder.blocks.1.norm1.bias grad: -0.0009035751572810113
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.7976307541830465e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00011419859947636724
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.627056038472801e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.49921052576974e-05
sam_encoder.blocks.1.norm2.weight grad: 0.002547925803810358
sam_encoder.blocks.1.norm2.bias grad: -0.00011924361751880497
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0010242769494652748
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00031514489091932774
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0006665405235253274
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.161610847106203e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0018193551804870367
sam_encoder.blocks.2.norm1.bias grad: -0.00027951941592618823
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0006233104504644871
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00013474839215632528
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00015227540279738605
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00014622058370150626
sam_encoder.blocks.2.norm2.weight grad: 0.0010500353528186679
sam_encoder.blocks.2.norm2.bias grad: -0.0005793283926323056
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0007504835957661271
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.4674873202457093e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0009487501229159534
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00013653132191393524
sam_encoder.blocks.3.norm1.weight grad: 0.0006848071934655309
sam_encoder.blocks.3.norm1.bias grad: -0.000846262089908123
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0001119852822739631
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.24833558301907e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00042263063369318843
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0001860527991084382
sam_encoder.blocks.3.norm2.weight grad: 0.0020176235120743513
sam_encoder.blocks.3.norm2.bias grad: -4.386288856039755e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0017493509221822023
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0006644834647886455
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0011878208024427295
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00041486043483018875
sam_encoder.blocks.4.norm1.weight grad: 0.0010531581938266754
sam_encoder.blocks.4.norm1.bias grad: -0.0006979461759328842
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0008152414811775088
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002475568908266723
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0007148392032831907
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0005301379133015871
sam_encoder.blocks.4.norm2.weight grad: -0.003940929658710957
sam_encoder.blocks.4.norm2.bias grad: -0.002340244362130761
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0022269324399530888
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.000844334252178669
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00040549872210249305
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00016333931125700474
sam_encoder.blocks.5.norm1.weight grad: 0.0023270021192729473
sam_encoder.blocks.5.norm1.bias grad: -5.881686229258776e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0013663694262504578
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0002640308521222323
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0006831098580732942
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0003047844802495092
sam_encoder.blocks.5.norm2.weight grad: -0.0015654530143365264
sam_encoder.blocks.5.norm2.bias grad: -0.0015241423388943076
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0005794067401438951
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00021007393661420792
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00016217600204981863
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.0089405704056844e-05
sam_encoder.blocks.6.norm1.weight grad: 2.3353617507382296e-05
sam_encoder.blocks.6.norm1.bias grad: 0.0008274188730865717
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00016099178174044937
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00010274552914779633
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.134678652510047e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.386026067659259e-05
sam_encoder.blocks.6.norm2.weight grad: -0.000981210032477975
sam_encoder.blocks.6.norm2.bias grad: -0.0006085021886974573
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0009032412199303508
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0003844657330773771
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00035941990790888667
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.174873952753842e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0012010051868855953
sam_encoder.blocks.7.norm1.bias grad: 2.6395511667942628e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007989085279405117
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0004628256137948483
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00042049295734614134
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00023466259881388396
sam_encoder.blocks.7.norm2.weight grad: -0.00016571051673963666
sam_encoder.blocks.7.norm2.bias grad: 0.00022108558914624155
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.8896082919090986e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.618787064217031e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00011717606685124338
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.871956116403453e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0004951535374857485
sam_encoder.blocks.8.norm1.bias grad: -4.7904381062835455e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.177867519203573e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00011742032074835151
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00018445274326950312
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.7956754163606092e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0004712082154583186
sam_encoder.blocks.8.norm2.bias grad: -0.0002845990820787847
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0005092555074952543
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0002396955678705126
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0002774044405668974
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.7471181713044643e-06
sam_encoder.blocks.9.norm1.weight grad: 0.000757441099267453
sam_encoder.blocks.9.norm1.bias grad: 5.183755638427101e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.000680304307024926
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0002231768157798797
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00021752298926003277
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.622350727207959e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00135638692881912
sam_encoder.blocks.9.norm2.bias grad: 1.5444433643097e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.001004137797281146
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0005263581988401711
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00023839225468691438
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.5724336814600974e-06
sam_encoder.blocks.10.norm1.weight grad: 0.0012792999623343349
sam_encoder.blocks.10.norm1.bias grad: 0.00027949403738602996
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0007844308274798095
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0003022400487679988
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00031098336330614984
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00014273152919486165
sam_encoder.blocks.10.norm2.weight grad: 0.0025674235075712204
sam_encoder.blocks.10.norm2.bias grad: 0.0004027820541523397
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0012852721847593784
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0006807023892179132
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00029088702285662293
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.083177580265328e-05
sam_encoder.blocks.11.norm1.weight grad: 0.003299165517091751
sam_encoder.blocks.11.norm1.bias grad: 0.00015218998305499554
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00033220238401554525
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00022086621902417392
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.000485347758512944
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0001682463043835014
sam_encoder.blocks.11.norm2.weight grad: 0.002749904990196228
sam_encoder.blocks.11.norm2.bias grad: 0.00017379030759911984
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0010987361893057823
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00047402209020219743
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00026148901088163257
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00010787170322146267
sam_encoder.neck.conv1.trainable_scale grad: 4.369858652353287e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0006646509282290936
sam_encoder.neck.conv2.trainable_scale grad: -0.00014432473108172417
sam_encoder.neck.conv2.trainable_shift grad: -0.010598795488476753
mask_decoder.transformer.layers.0.norm1.weight grad: 0.008576799184083939
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0003606155514717102
mask_decoder.transformer.layers.0.norm2.weight grad: -0.6438866257667542
mask_decoder.transformer.layers.0.norm2.bias grad: -0.23396660387516022
mask_decoder.transformer.layers.0.norm3.weight grad: 0.004583016037940979
mask_decoder.transformer.layers.0.norm3.bias grad: -0.006292392499744892
mask_decoder.transformer.layers.0.norm4.weight grad: 0.011506926268339157
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0019142089877277613
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0004003996145911515
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0011194958351552486
mask_decoder.transformer.layers.1.norm2.weight grad: -0.02187330462038517
mask_decoder.transformer.layers.1.norm2.bias grad: -0.008008391596376896
mask_decoder.transformer.layers.1.norm3.weight grad: 0.001160013722255826
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0033571296371519566
mask_decoder.transformer.layers.1.norm4.weight grad: -0.006801963318139315
mask_decoder.transformer.layers.1.norm4.bias grad: -0.03023378923535347
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003029561194125563
mask_decoder.transformer.norm_final_attn.bias grad: 0.0016992447199299932
Text_Embedding_Affine.0.weight grad: 8.331721423893157e-10
Text_Embedding_Affine.0.bias grad: 2.0016841517644934e-08
Text_Embedding_Affine.2.weight grad: -4.590286373229446e-09
Text_Embedding_Affine.2.bias grad: -0.0009855213575065136

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.1182834202485018e-16
Max value: 0.9996873140335083
Mean value: 0.0661851167678833

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.1182834202485018e-16
Max value: 0.9996873140335083
Mean value: 0.0661851167678833

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0793766975402832

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13904635608196259

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.047598838806152344

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0793766975402832

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.3063369691371918
Max value: 73.96688842773438
Mean value: 40.30019760131836

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.1182834202485018e-16
Max value: 0.9996873140335083
Mean value: 0.0661851167678833

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.1182834202485018e-16
Max value: 0.9996873140335083
Mean value: 0.0661851167678833

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.1182834202485018e-16
Max value: 0.9996873140335083
Mean value: 0.0661851167678833

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13904635608196259

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.3063369691371918
Max value: 73.96688842773438
Mean value: 40.30019760131836

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -40.30131912231445
Max value: -40.30131912231445
Mean value: -40.30131912231445
sam_encoder.pos_embed grad: -8.681454346515238e-07
sam_encoder.blocks.0.norm1.weight grad: -0.001512827118858695
sam_encoder.blocks.0.norm1.bias grad: 0.003939489834010601
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0017130187479779124
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.978376768529415e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0016526193358004093
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0006768356543034315
sam_encoder.blocks.0.norm2.weight grad: 0.0032317598816007376
sam_encoder.blocks.0.norm2.bias grad: 0.0160414706915617
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.004368027672171593
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0017794922459870577
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0005428767763078213
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0006272373721003532
sam_encoder.blocks.1.norm1.weight grad: -0.0015869343187659979
sam_encoder.blocks.1.norm1.bias grad: -0.0006891299854032695
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00034153982414864004
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00012993063137400895
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0002418302174191922
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0002295955055160448
sam_encoder.blocks.1.norm2.weight grad: 0.0024482938461005688
sam_encoder.blocks.1.norm2.bias grad: -0.0006271560559980571
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0011847512796521187
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00039183476474136114
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0014082466950640082
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.6786874514073133e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0014451997121796012
sam_encoder.blocks.2.norm1.bias grad: -0.000474661763291806
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0005790874129161239
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00015430740313604474
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00010032449790742248
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003545562503859401
sam_encoder.blocks.2.norm2.weight grad: 6.570345431100577e-05
sam_encoder.blocks.2.norm2.bias grad: -0.0007261541904881597
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00023115810472518206
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.485498225723859e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0007450777338817716
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00013911016867496073
sam_encoder.blocks.3.norm1.weight grad: -0.0004958835197612643
sam_encoder.blocks.3.norm1.bias grad: -0.0003645949764177203
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0006094201817177236
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0001044614618876949
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0009039724245667458
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0004259459674358368
sam_encoder.blocks.3.norm2.weight grad: 0.00296274246647954
sam_encoder.blocks.3.norm2.bias grad: 0.0006003746530041099
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0019010556861758232
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0005909225437790155
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0006415751413442194
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0001940699148690328
sam_encoder.blocks.4.norm1.weight grad: 0.002990433946251869
sam_encoder.blocks.4.norm1.bias grad: -0.0012403795262798667
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0016155274352058768
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005218595615588129
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0006814687512814999
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0008048630552366376
sam_encoder.blocks.4.norm2.weight grad: 0.00010176228533964604
sam_encoder.blocks.4.norm2.bias grad: -0.0012958272127434611
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0001694722886895761
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00029970158357173204
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0002981825964525342
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00012364311260171235
sam_encoder.blocks.5.norm1.weight grad: 0.004750756546854973
sam_encoder.blocks.5.norm1.bias grad: -0.001528208958916366
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0037530302070081234
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0015525533817708492
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0010033480357378721
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0006383231375366449
sam_encoder.blocks.5.norm2.weight grad: 0.001931983046233654
sam_encoder.blocks.5.norm2.bias grad: 0.0008812714368104935
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0009475614642724395
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00030927767511457205
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0002932760398834944
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.904792538378388e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0007236157543957233
sam_encoder.blocks.6.norm1.bias grad: 0.0004976540803909302
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0004572493489831686
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00030594150302931666
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00019896545563824475
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.716133354231715e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0007145530544221401
sam_encoder.blocks.6.norm2.bias grad: -0.0005558945704251528
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0006999545730650425
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0003996844170615077
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00012125032662879676
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00010562873649178073
sam_encoder.blocks.7.norm1.weight grad: 0.0007499274797737598
sam_encoder.blocks.7.norm1.bias grad: 5.3696763643529266e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007546754786744714
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00048089073970913887
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00045304972445592284
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0006872876547276974
sam_encoder.blocks.7.norm2.weight grad: -0.0006956227007322013
sam_encoder.blocks.7.norm2.bias grad: -0.00014446862041950226
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00057973776711151
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00033268050174228847
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002503393334336579
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0001095105690183118
sam_encoder.blocks.8.norm1.weight grad: 0.0004048687405884266
sam_encoder.blocks.8.norm1.bias grad: 0.00010770790686365217
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0005033172201365232
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00029167989850975573
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0002833574253600091
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5272196833393537e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0008451173780485988
sam_encoder.blocks.8.norm2.bias grad: 0.00016244295693468302
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.000460432464024052
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0004001209163106978
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0004120314843021333
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00019724760204553604
sam_encoder.blocks.9.norm1.weight grad: 0.0008206576458178461
sam_encoder.blocks.9.norm1.bias grad: 2.884118293877691e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0006664100801572204
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00022279517725110054
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00018797970551531762
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0002455902867950499
sam_encoder.blocks.9.norm2.weight grad: 0.001049112412147224
sam_encoder.blocks.9.norm2.bias grad: 0.0005190528463572264
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00039899314288049936
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0004226120072416961
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00022426160285249352
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0001300487929256633
sam_encoder.blocks.10.norm1.weight grad: 3.594449663069099e-05
sam_encoder.blocks.10.norm1.bias grad: 0.00012410804629325867
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.1819569459185e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.650969640351832e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.444154885481112e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.0081648472114466e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0018569485982879996
sam_encoder.blocks.10.norm2.bias grad: 0.0007795668207108974
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00043524563079699874
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0004712048394139856
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00038660597056150436
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.00012098361912649125
sam_encoder.blocks.11.norm1.weight grad: 0.0020643144380301237
sam_encoder.blocks.11.norm1.bias grad: 0.0002303752553416416
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00025567851844243705
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.801869651302695e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.878033228626009e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.456271461909637e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0017723189666867256
sam_encoder.blocks.11.norm2.bias grad: 0.00022375483240466565
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.000446945836301893
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0003720414824783802
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00041719767614267766
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00024400341499131173
sam_encoder.neck.conv1.trainable_scale grad: 0.0002777779009193182
sam_encoder.neck.conv1.trainable_shift grad: 0.0013042972423136234
sam_encoder.neck.conv2.trainable_scale grad: 0.0001553038600832224
sam_encoder.neck.conv2.trainable_shift grad: -0.0033710584975779057
mask_decoder.transformer.layers.0.norm1.weight grad: 0.03477377071976662
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0010149385780096054
mask_decoder.transformer.layers.0.norm2.weight grad: 0.22661523520946503
mask_decoder.transformer.layers.0.norm2.bias grad: -0.3820902109146118
mask_decoder.transformer.layers.0.norm3.weight grad: 0.017031973227858543
mask_decoder.transformer.layers.0.norm3.bias grad: -0.008840677328407764
mask_decoder.transformer.layers.0.norm4.weight grad: -0.003856065683066845
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0008666892535984516
mask_decoder.transformer.layers.1.norm1.weight grad: -0.005586259998381138
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0004803999327123165
mask_decoder.transformer.layers.1.norm2.weight grad: -0.04118883237242699
mask_decoder.transformer.layers.1.norm2.bias grad: -0.013575844466686249
mask_decoder.transformer.layers.1.norm3.weight grad: -0.012710893526673317
mask_decoder.transformer.layers.1.norm3.bias grad: -0.010106752626597881
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0059811389073729515
mask_decoder.transformer.layers.1.norm4.bias grad: -0.002636989112943411
mask_decoder.transformer.norm_final_attn.weight grad: -0.0005587826599366963
mask_decoder.transformer.norm_final_attn.bias grad: -0.0003820759884547442
Text_Embedding_Affine.0.weight grad: 3.997165265445801e-09
Text_Embedding_Affine.0.bias grad: 1.1851079761981964e-07
Text_Embedding_Affine.2.weight grad: -1.506502833592549e-08
Text_Embedding_Affine.2.bias grad: -0.010907614603638649

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.119662554482375e-10
Max value: 0.9896893501281738
Mean value: 0.07341388612985611

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.119662554482375e-10
Max value: 0.9896893501281738
Mean value: 0.07341388612985611

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0887918472290039

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.179024696350098
Max value: -1.1920928244535389e-07
Mean value: -0.1411426067352295

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05929279327392578

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0887918472290039

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 12.1560640335083
Max value: 66.82433319091797
Mean value: 36.9072151184082

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.119662554482375e-10
Max value: 0.9896893501281738
Mean value: 0.07341388612985611

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.119662554482375e-10
Max value: 0.9896893501281738
Mean value: 0.07341388612985611

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.119662554482375e-10
Max value: 0.9896893501281738
Mean value: 0.07341388612985611

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.179024696350098
Max value: -1.1920928244535389e-07
Mean value: -0.1411426067352295

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 12.1560640335083
Max value: 66.82433319091797
Mean value: 36.9072151184082

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -36.90842056274414
Max value: -36.90842056274414
Mean value: -36.90842056274414
sam_encoder.pos_embed grad: -1.510639208390785e-06
sam_encoder.blocks.0.norm1.weight grad: -0.0014406945556402206
sam_encoder.blocks.0.norm1.bias grad: -0.005298459902405739
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0009368474129587412
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.9364533475018106e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.002140545751899481
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0006356037920340896
sam_encoder.blocks.0.norm2.weight grad: -0.0031416937708854675
sam_encoder.blocks.0.norm2.bias grad: 0.01835946924984455
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.005646314471960068
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0019771214574575424
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.267545151989907e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.000273694284260273
sam_encoder.blocks.1.norm1.weight grad: -0.0034177727065980434
sam_encoder.blocks.1.norm1.bias grad: -0.001099762856028974
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004600686370395124
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00022538949269801378
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00013732322258874774
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00011798761988757178
sam_encoder.blocks.1.norm2.weight grad: -0.00018400388944428414
sam_encoder.blocks.1.norm2.bias grad: -0.0005958063993602991
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0001660380803514272
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.340919127163943e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0008330208947882056
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.66415790974861e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0009647018159739673
sam_encoder.blocks.2.norm1.bias grad: -0.0002499611000530422
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00034700334072113037
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0003670456353574991
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00024005094019230455
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.0107853894587606e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0033042938448488712
sam_encoder.blocks.2.norm2.bias grad: -0.0014606141485273838
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.002146756974980235
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0007497518672607839
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.001029726816341281
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.000232351798331365
sam_encoder.blocks.3.norm1.weight grad: 0.0018399718683212996
sam_encoder.blocks.3.norm1.bias grad: -0.00058645976241678
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0013043321669101715
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00020261501776985824
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0009385375306010246
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0003755598736461252
sam_encoder.blocks.3.norm2.weight grad: 0.0031390078365802765
sam_encoder.blocks.3.norm2.bias grad: 0.0002958860422950238
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00217853719368577
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00070525286719203
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0005946916644461453
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0003298055089544505
sam_encoder.blocks.4.norm1.weight grad: 0.0004570439923554659
sam_encoder.blocks.4.norm1.bias grad: -0.0020628911443054676
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0006253019673749804
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0003376901149749756
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0005110284546390176
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.000720747746527195
sam_encoder.blocks.4.norm2.weight grad: 0.0013983622193336487
sam_encoder.blocks.4.norm2.bias grad: 0.00043115392327308655
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.000818289932794869
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0002991607179865241
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.000656937132589519
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00035454551107250154
sam_encoder.blocks.5.norm1.weight grad: 0.0022436557337641716
sam_encoder.blocks.5.norm1.bias grad: -0.001770197763107717
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.001316846115514636
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0006847906624898314
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0005852414760738611
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00017826465773396194
sam_encoder.blocks.5.norm2.weight grad: 0.0021760212257504463
sam_encoder.blocks.5.norm2.bias grad: 0.0007779218140058219
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0010488958796486259
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0004131860041525215
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0004131521563977003
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00015911154332570732
sam_encoder.blocks.6.norm1.weight grad: -0.0007468211697414517
sam_encoder.blocks.6.norm1.bias grad: 0.00017096153169404715
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.001008681021630764
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0003719048108905554
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00022434545098803937
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.44072419567965e-05
sam_encoder.blocks.6.norm2.weight grad: -6.901250162627548e-05
sam_encoder.blocks.6.norm2.bias grad: -0.0004299319116398692
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0001491941511631012
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0001161390682682395
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00012730815797112882
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.8997765184612945e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0008410185109823942
sam_encoder.blocks.7.norm1.bias grad: 0.00010215627116849646
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0006237186025828123
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0004658779944293201
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00035092944744974375
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0005152820376679301
sam_encoder.blocks.7.norm2.weight grad: -0.0005642889882437885
sam_encoder.blocks.7.norm2.bias grad: 0.00025277354870922863
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0006754486239515245
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00022265913139563054
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.2227653719019145e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.413222541188588e-06
sam_encoder.blocks.8.norm1.weight grad: -0.00047631317283958197
sam_encoder.blocks.8.norm1.bias grad: 0.0004802798794116825
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0010250478517264128
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0003612006548792124
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00013652449706569314
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0002037908270722255
sam_encoder.blocks.8.norm2.weight grad: 0.0016398172592744231
sam_encoder.blocks.8.norm2.bias grad: 9.34294075705111e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.001255424227565527
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0008469419553875923
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.000764705881010741
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0003122397465631366
sam_encoder.blocks.9.norm1.weight grad: 0.0006525623030029237
sam_encoder.blocks.9.norm1.bias grad: 0.00011866056593134999
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.000491492566652596
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00019996310584247112
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0001770357193890959
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00024117890279740095
sam_encoder.blocks.9.norm2.weight grad: 0.0024145678617060184
sam_encoder.blocks.9.norm2.bias grad: 0.0006450812215916812
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0014432778116315603
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0011326972162351012
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0005144528113305569
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0002233886916656047
sam_encoder.blocks.10.norm1.weight grad: 0.0005828954163007438
sam_encoder.blocks.10.norm1.bias grad: 0.0002017586666624993
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0004038972547277808
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0001693650847300887
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.50127047568094e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.2116086256573908e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0032503283582627773
sam_encoder.blocks.10.norm2.bias grad: 0.0010023957584053278
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0011599622666835785
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0008924206485971808
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0004269125056453049
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.0001393419224768877
sam_encoder.blocks.11.norm1.weight grad: 6.972688424866647e-05
sam_encoder.blocks.11.norm1.bias grad: 0.0002614499826449901
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0007718181586824358
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.5020101272966713e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -6.897230923641473e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00015763954434078187
sam_encoder.blocks.11.norm2.weight grad: 0.0032439425121992826
sam_encoder.blocks.11.norm2.bias grad: 0.00019888793758582324
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.001113868784159422
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0006580858025699854
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0005362598458305001
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00032499164808541536
sam_encoder.neck.conv1.trainable_scale grad: 0.00031800055876374245
sam_encoder.neck.conv1.trainable_shift grad: 0.002454286441206932
sam_encoder.neck.conv2.trainable_scale grad: 9.05962660908699e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.015964405611157417
mask_decoder.transformer.layers.0.norm1.weight grad: 0.033799171447753906
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0006549805402755737
mask_decoder.transformer.layers.0.norm2.weight grad: -0.22084102034568787
mask_decoder.transformer.layers.0.norm2.bias grad: -0.4517001211643219
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0018104123882949352
mask_decoder.transformer.layers.0.norm3.bias grad: -0.007009985391050577
mask_decoder.transformer.layers.0.norm4.weight grad: 0.002659955993294716
mask_decoder.transformer.layers.0.norm4.bias grad: -0.001378135522827506
mask_decoder.transformer.layers.1.norm1.weight grad: -0.00138919148594141
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0007923932862468064
mask_decoder.transformer.layers.1.norm2.weight grad: -0.04531482607126236
mask_decoder.transformer.layers.1.norm2.bias grad: -0.010295267216861248
mask_decoder.transformer.layers.1.norm3.weight grad: -0.009636828675866127
mask_decoder.transformer.layers.1.norm3.bias grad: -0.007003797683864832
mask_decoder.transformer.layers.1.norm4.weight grad: -0.012946365401148796
mask_decoder.transformer.layers.1.norm4.bias grad: -0.018589969724416733
mask_decoder.transformer.norm_final_attn.weight grad: -5.004039849154651e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0007653489010408521
Text_Embedding_Affine.0.weight grad: 2.3369095547565166e-10
Text_Embedding_Affine.0.bias grad: 1.3969838619232178e-08
Text_Embedding_Affine.2.weight grad: -4.0954233782031224e-08
Text_Embedding_Affine.2.bias grad: -0.011258973740041256
Epoch 16 finished with average loss: -36.7754
Epoch 17/39
----------
Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s, loss=-42.9]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-42.9]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-43.5]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-43.5]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-47.1]Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-47.1]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.7839482348417325e-14
Max value: 0.9972819089889526
Mean value: 0.07249445468187332

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.7839482348417325e-14
Max value: 0.9972819089889526
Mean value: 0.07249445468187332

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0928030014038086

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14994162321090698

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05699920654296875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0928030014038086

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 7.192261219024658
Max value: 71.6241683959961
Mean value: 42.85797119140625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.7839482348417325e-14
Max value: 0.9972819089889526
Mean value: 0.07249445468187332

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.7839482348417325e-14
Max value: 0.9972819089889526
Mean value: 0.07249445468187332

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.7839482348417325e-14
Max value: 0.9972819089889526
Mean value: 0.07249445468187332

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14994162321090698

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 7.192261219024658
Max value: 71.6241683959961
Mean value: 42.85797119140625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -42.859153747558594
Max value: -42.859153747558594
Mean value: -42.859153747558594
sam_encoder.pos_embed grad: -9.985959650293807e-07
sam_encoder.blocks.0.norm1.weight grad: -0.007142884191125631
sam_encoder.blocks.0.norm1.bias grad: -0.0002907377202063799
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0009804724249988794
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.20687852561241e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0006194267189130187
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0005124501185491681
sam_encoder.blocks.0.norm2.weight grad: 0.004914587363600731
sam_encoder.blocks.0.norm2.bias grad: 0.0028884676285088062
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0010458510369062424
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003045431221835315
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00021616846788674593
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00036886296584270895
sam_encoder.blocks.1.norm1.weight grad: -0.0012871208600699902
sam_encoder.blocks.1.norm1.bias grad: 0.00035963684786111116
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0008781803189776838
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00026707787765190005
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0008584586903452873
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00044881412759423256
sam_encoder.blocks.1.norm2.weight grad: -0.0008935196092352271
sam_encoder.blocks.1.norm2.bias grad: 0.0007024495862424374
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0010241029085591435
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00011297919263597578
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.000976625713519752
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0002799977082759142
sam_encoder.blocks.2.norm1.weight grad: -0.00028160656802356243
sam_encoder.blocks.2.norm1.bias grad: -0.00032558030216023326
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0006809947080910206
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00019538478227332234
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0009674315224401653
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0006034051766619086
sam_encoder.blocks.2.norm2.weight grad: -0.0010529020801186562
sam_encoder.blocks.2.norm2.bias grad: -0.0009400054113939404
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0005936531815677881
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001380199391860515
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.4311673112388235e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 7.796160934958607e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0006692755268886685
sam_encoder.blocks.3.norm1.bias grad: -0.0004971189191564918
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0003955286811105907
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00012647805851884186
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0004866232047788799
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.0077393350657076e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0021063394378870726
sam_encoder.blocks.3.norm2.bias grad: 0.0005424703704193234
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0014730062102898955
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0005643797921948135
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.000531501485966146
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00021504302276298404
sam_encoder.blocks.4.norm1.weight grad: 0.002813547383993864
sam_encoder.blocks.4.norm1.bias grad: -0.0018235945608466864
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0011074962094426155
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00047818885650485754
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00031259626848623157
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00042739463970065117
sam_encoder.blocks.4.norm2.weight grad: 0.0013926334213465452
sam_encoder.blocks.4.norm2.bias grad: -3.3619580790400505e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00032735263812355697
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.919249426573515e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0007157797808758914
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0003312435874249786
sam_encoder.blocks.5.norm1.weight grad: 0.003809694666415453
sam_encoder.blocks.5.norm1.bias grad: -0.00210778322070837
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0029537612572312355
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0012573781423270702
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0006831944338046014
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00048524857265874743
sam_encoder.blocks.5.norm2.weight grad: 0.0025279393885284662
sam_encoder.blocks.5.norm2.bias grad: 0.0002911920309998095
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0009122072951868176
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0002865383867174387
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00048548163613304496
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.645244426792488e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00018246615945827216
sam_encoder.blocks.6.norm1.bias grad: 0.0003501241444610059
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00020253699040040374
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003177706676069647
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.8269856304395944e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.876893217442557e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0006053979741409421
sam_encoder.blocks.6.norm2.bias grad: -0.0003866293700411916
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00023354330915026367
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00013631203910335898
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.588448766502552e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.922086372971535e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00023022344976197928
sam_encoder.blocks.7.norm1.bias grad: -3.492063842713833e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0003959125024266541
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00025472085690125823
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00024716596817597747
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0005313963047228754
sam_encoder.blocks.7.norm2.weight grad: -0.00021132302936166525
sam_encoder.blocks.7.norm2.bias grad: -0.00018419322441332042
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00046766764717176557
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00019479547336231917
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.934649718459696e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.256119296362158e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0013846035581082106
sam_encoder.blocks.8.norm1.bias grad: -6.374478107318282e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.001776049379259348
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0006944264750927687
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00028467763331718743
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.128448436968029e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0004496559267863631
sam_encoder.blocks.8.norm2.bias grad: 0.00029855920001864433
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.616366252070293e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.157255145604722e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00017931520415004343
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.125057840719819e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0007477781618945301
sam_encoder.blocks.9.norm1.bias grad: 1.9876315491274e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0005489407340064645
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00011368982814019546
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00013043753278907388
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00021679469500668347
sam_encoder.blocks.9.norm2.weight grad: 0.0008298797765746713
sam_encoder.blocks.9.norm2.bias grad: 0.0003746704605873674
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00023398874327540398
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0002041854604613036
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.640911306021735e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.588557956391014e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0004762004828080535
sam_encoder.blocks.10.norm1.bias grad: 5.973723455099389e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00030699948547407985
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0001034886809065938
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.085949629166862e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.4916600775904953e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0013196923537179828
sam_encoder.blocks.10.norm2.bias grad: 0.0006977429147809744
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0005077237728983164
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0002617659920360893
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.459792636334896e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.3652994059375487e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0022544271778315306
sam_encoder.blocks.11.norm1.bias grad: 2.6956578949466348e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002220158785348758
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00011211339733563364
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00011430167069192976
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.764206384308636e-05
sam_encoder.blocks.11.norm2.weight grad: 0.001158134313300252
sam_encoder.blocks.11.norm2.bias grad: 0.00016533971938770264
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0005785917164757848
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0002612064708955586
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00022931704006623477
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00012827700993511826
sam_encoder.neck.conv1.trainable_scale grad: 7.145979907363653e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0012613448780030012
sam_encoder.neck.conv2.trainable_scale grad: 0.00014230352826416492
sam_encoder.neck.conv2.trainable_shift grad: -0.007414672989398241
mask_decoder.transformer.layers.0.norm1.weight grad: 0.029176978394389153
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0005043409764766693
mask_decoder.transformer.layers.0.norm2.weight grad: 0.25587138533592224
mask_decoder.transformer.layers.0.norm2.bias grad: -0.26144108176231384
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0061936285346746445
mask_decoder.transformer.layers.0.norm3.bias grad: -0.003953125327825546
mask_decoder.transformer.layers.0.norm4.weight grad: -0.009471233934164047
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0003992941929027438
mask_decoder.transformer.layers.1.norm1.weight grad: -0.004170805215835571
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0005417797947302461
mask_decoder.transformer.layers.1.norm2.weight grad: -0.03689906746149063
mask_decoder.transformer.layers.1.norm2.bias grad: -0.013898122124373913
mask_decoder.transformer.layers.1.norm3.weight grad: -0.011576846241950989
mask_decoder.transformer.layers.1.norm3.bias grad: -0.010229330509901047
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0027106222696602345
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0007357916329056025
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003441701701376587
mask_decoder.transformer.norm_final_attn.bias grad: -0.0005557232070714235
Text_Embedding_Affine.0.weight grad: 1.1731609017573419e-09
Text_Embedding_Affine.0.bias grad: 4.279718268662691e-08
Text_Embedding_Affine.2.weight grad: -3.224122480105507e-08
Text_Embedding_Affine.2.bias grad: -0.005816938355565071

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.675121665325243e-11
Max value: 0.9984769225120544
Mean value: 0.0641484260559082

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.675121665325243e-11
Max value: 0.9984769225120544
Mean value: 0.0641484260559082

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07579374313354492

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.220775604248047
Max value: -1.1920928244535389e-07
Mean value: -0.11565029621124268

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.043819427490234375

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07579374313354492

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 22.818912506103516
Max value: 78.23942565917969
Mean value: 44.05683517456055

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.675121665325243e-11
Max value: 0.9984769225120544
Mean value: 0.0641484260559082

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.675121665325243e-11
Max value: 0.9984769225120544
Mean value: 0.0641484260559082

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.675121665325243e-11
Max value: 0.9984769225120544
Mean value: 0.0641484260559082

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.220775604248047
Max value: -1.1920928244535389e-07
Mean value: -0.11565029621124268

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 22.818912506103516
Max value: 78.23942565917969
Mean value: 44.05683517456055

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -44.05793762207031
Max value: -44.05793762207031
Mean value: -44.05793762207031
sam_encoder.pos_embed grad: -1.629528355806542e-06
sam_encoder.blocks.0.norm1.weight grad: -0.014554875902831554
sam_encoder.blocks.0.norm1.bias grad: 0.002548774005845189
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0016649430617690086
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00012168148532509804
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0006273933686316013
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00014418642967939377
sam_encoder.blocks.0.norm2.weight grad: 0.0006916559068486094
sam_encoder.blocks.0.norm2.bias grad: 0.013425788842141628
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0023840847425162792
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0008553738589398563
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0027133277617394924
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0018212110735476017
sam_encoder.blocks.1.norm1.weight grad: -0.003449411829933524
sam_encoder.blocks.1.norm1.bias grad: 0.0003527617081999779
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0003528044035192579
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.8819387555122375e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.00043614854803308845
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0002227788500022143
sam_encoder.blocks.1.norm2.weight grad: 0.003076128661632538
sam_encoder.blocks.1.norm2.bias grad: -0.0017097484087571502
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0018021899741142988
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00042270388803444803
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0023473561741411686
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.2830889065517113e-05
sam_encoder.blocks.2.norm1.weight grad: 0.002875473815947771
sam_encoder.blocks.2.norm1.bias grad: -0.0007900921627879143
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0013759713619947433
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0003655249602161348
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0008229238446801901
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0002139191929018125
sam_encoder.blocks.2.norm2.weight grad: 0.003283341182395816
sam_encoder.blocks.2.norm2.bias grad: -0.0016816782299429178
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0023321916814893484
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0004545935080386698
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0017825595568865538
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.0003788561443798244
sam_encoder.blocks.3.norm1.weight grad: 0.0012942519970238209
sam_encoder.blocks.3.norm1.bias grad: -0.0011339945485815406
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0012844569282606244
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0003879614523611963
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0011942127021029592
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0006759953685104847
sam_encoder.blocks.3.norm2.weight grad: 0.0025694321375340223
sam_encoder.blocks.3.norm2.bias grad: 0.0015782343689352274
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0022046060767024755
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0005477340891957283
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0003173481090925634
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00016644923016428947
sam_encoder.blocks.4.norm1.weight grad: 0.0013394849374890327
sam_encoder.blocks.4.norm1.bias grad: -0.0008402236271649599
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.001164051005616784
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00036535761319100857
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.001019814400933683
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0009242889354936779
sam_encoder.blocks.4.norm2.weight grad: -0.0005908816820010543
sam_encoder.blocks.4.norm2.bias grad: -0.0031320347916334867
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0003189693088643253
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00029468105640262365
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0005057782400399446
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00011292375711491331
sam_encoder.blocks.5.norm1.weight grad: 0.0032116069924086332
sam_encoder.blocks.5.norm1.bias grad: -0.0009428078774362803
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0018986699869856238
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00044143362902104855
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0011317678727209568
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0003669350116979331
sam_encoder.blocks.5.norm2.weight grad: -0.00012706557754427195
sam_encoder.blocks.5.norm2.bias grad: -0.0012726960703730583
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0005465496797114611
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00019824979244731367
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001030190906021744
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.4209671614225954e-05
sam_encoder.blocks.6.norm1.weight grad: 8.220341987907887e-05
sam_encoder.blocks.6.norm1.bias grad: 0.0007166967261582613
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00022571728914044797
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.745448915055022e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0001141909378929995
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.2565074939629994e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0008335111197084188
sam_encoder.blocks.6.norm2.bias grad: -0.0011283087078481913
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0006942766485735774
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0003352356725372374
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00015501781308557838
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.002651495393366e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0015482524177059531
sam_encoder.blocks.7.norm1.bias grad: 0.00032687425846233964
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.001045525074005127
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0005940471892245114
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0005216812714934349
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0005102208815515041
sam_encoder.blocks.7.norm2.weight grad: 0.00016041967319324613
sam_encoder.blocks.7.norm2.bias grad: -0.0002994985261466354
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0001504132233094424
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.434290066361427e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00016215312643907964
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00022096766042523086
sam_encoder.blocks.8.norm1.weight grad: 0.0005024642450734973
sam_encoder.blocks.8.norm1.bias grad: 6.336845399346203e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00010625772847561166
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.000204345618840307
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0004694130620919168
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00014949931937735528
sam_encoder.blocks.8.norm2.weight grad: 0.0010157970245927572
sam_encoder.blocks.8.norm2.bias grad: -0.00014686091162730008
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0009605246596038342
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0006736548384651542
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.000364568637451157
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.914177796104923e-05
sam_encoder.blocks.9.norm1.weight grad: 0.00034368381602689624
sam_encoder.blocks.9.norm1.bias grad: 7.382864714600146e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.000266076996922493
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00010187248699367046
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.330202839104459e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.9710015951422974e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0016382066532969475
sam_encoder.blocks.9.norm2.bias grad: 0.00014719742466695607
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0011953453067690134
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0007493029115721583
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00025278711109422147
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.2901980880997144e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0007211124757304788
sam_encoder.blocks.10.norm1.bias grad: 0.00023656286066398025
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0005258145974949002
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00024035584647208452
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0001822100457502529
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.741996134631336e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0025628486182540655
sam_encoder.blocks.10.norm2.bias grad: 0.00027369806775823236
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0012015411630272865
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0007345159538090229
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.000314874981995672
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.162183540756814e-05
sam_encoder.blocks.11.norm1.weight grad: 0.004326026886701584
sam_encoder.blocks.11.norm1.bias grad: 0.00017387172556482255
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0006287916330620646
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001392879494233057
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00041607534512877464
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.890310320770368e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0023570870980620384
sam_encoder.blocks.11.norm2.bias grad: 0.00015571362746413797
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0010413344716653228
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00043443142203614116
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00019926621462218463
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00015395274385809898
sam_encoder.neck.conv1.trainable_scale grad: 0.00012749340385198593
sam_encoder.neck.conv1.trainable_shift grad: 0.001216298551298678
sam_encoder.neck.conv2.trainable_scale grad: -2.2715888917446136e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0006693679606541991
mask_decoder.transformer.layers.0.norm1.weight grad: 0.01832641288638115
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0003265533596277237
mask_decoder.transformer.layers.0.norm2.weight grad: -0.9107797145843506
mask_decoder.transformer.layers.0.norm2.bias grad: -0.34657904505729675
mask_decoder.transformer.layers.0.norm3.weight grad: -0.002919116523116827
mask_decoder.transformer.layers.0.norm3.bias grad: -0.007908452302217484
mask_decoder.transformer.layers.0.norm4.weight grad: 0.009953441098332405
mask_decoder.transformer.layers.0.norm4.bias grad: -0.002320420928299427
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0008162909653037786
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0015071183443069458
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0493781752884388
mask_decoder.transformer.layers.1.norm2.bias grad: -0.008838471956551075
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0042009903118014336
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00558514054864645
mask_decoder.transformer.layers.1.norm4.weight grad: -0.012323940172791481
mask_decoder.transformer.layers.1.norm4.bias grad: -0.03168478608131409
mask_decoder.transformer.norm_final_attn.weight grad: -0.00042984081665053964
mask_decoder.transformer.norm_final_attn.bias grad: 0.001921763177961111
Text_Embedding_Affine.0.weight grad: -3.893108058150574e-12
Text_Embedding_Affine.0.bias grad: -2.7765054255723953e-08
Text_Embedding_Affine.2.weight grad: 6.619913506256125e-10
Text_Embedding_Affine.2.bias grad: -0.0062093306332826614

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.399084573278923e-23
Max value: 0.9999951124191284
Mean value: 0.07363195717334747

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.399084573278923e-23
Max value: 0.9999951124191284
Mean value: 0.07363195717334747

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08135795593261719

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1470942199230194

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06835556030273438

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08135795593261719

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 24.258508682250977
Max value: 74.22356414794922
Mean value: 54.30824661254883

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.399084573278923e-23
Max value: 0.9999951124191284
Mean value: 0.07363195717334747

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.399084573278923e-23
Max value: 0.9999951124191284
Mean value: 0.07363195717334747

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.399084573278923e-23
Max value: 0.9999951124191284
Mean value: 0.07363195717334747

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1470942199230194

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 24.258508682250977
Max value: 74.22356414794922
Mean value: 54.30824661254883

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.30897903442383
Max value: -54.30897903442383
Mean value: -54.30897903442383
sam_encoder.pos_embed grad: -1.615809651411837e-06
sam_encoder.blocks.0.norm1.weight grad: -0.0042399209924042225
sam_encoder.blocks.0.norm1.bias grad: -0.002975420095026493
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0009093086118809879
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.692732889248873e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0016080256318673491
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0006605293601751328
sam_encoder.blocks.0.norm2.weight grad: 0.00012383113789837807
sam_encoder.blocks.0.norm2.bias grad: 0.011731749400496483
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.003224679036065936
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.001649281708523631
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0025638656225055456
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0011942624114453793
sam_encoder.blocks.1.norm1.weight grad: -0.0025638567749410868
sam_encoder.blocks.1.norm1.bias grad: -0.0025279473047703505
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0005799358477815986
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.5895478756865487e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0004913058364763856
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00032212931546382606
sam_encoder.blocks.1.norm2.weight grad: 0.001586545491591096
sam_encoder.blocks.1.norm2.bias grad: 0.00025067810202017426
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0005399653455242515
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00013695709640160203
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0013265996240079403
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.801965431193821e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0023096126969903708
sam_encoder.blocks.2.norm1.bias grad: -0.0011145370081067085
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.001405313378199935
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0003738683881238103
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00015854362573008984
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.607541531091556e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0009070484666153789
sam_encoder.blocks.2.norm2.bias grad: -0.00030089053325355053
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0010425876826047897
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0001282682060264051
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0014523542486131191
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00022410272504203022
sam_encoder.blocks.3.norm1.weight grad: 0.0014058076776564121
sam_encoder.blocks.3.norm1.bias grad: -0.001308328821323812
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0012152590788900852
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00021724836551584303
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0008936447557061911
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00018137221923097968
sam_encoder.blocks.3.norm2.weight grad: 0.0018964086193591356
sam_encoder.blocks.3.norm2.bias grad: -0.0001631693885428831
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0016344208270311356
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0003219539066776633
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0012570457765832543
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00044314615661278367
sam_encoder.blocks.4.norm1.weight grad: 0.0018877405673265457
sam_encoder.blocks.4.norm1.bias grad: -0.0014303786447271705
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0014658881118521094
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0004109033616259694
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0008670423994772136
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0007641247939318419
sam_encoder.blocks.4.norm2.weight grad: -0.0016230389010161161
sam_encoder.blocks.4.norm2.bias grad: -0.0017834941390901804
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0006740604876540601
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00034792092628777027
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0008865366107784212
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0003923822077922523
sam_encoder.blocks.5.norm1.weight grad: 0.0024852906353771687
sam_encoder.blocks.5.norm1.bias grad: 0.0001413718273397535
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0014823765959590673
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00043267960427328944
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0006546644726768136
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.000255715218372643
sam_encoder.blocks.5.norm2.weight grad: 0.0003701583482325077
sam_encoder.blocks.5.norm2.bias grad: -0.0007438174216076732
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00043711968464776874
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00018016199464909732
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00042577239219099283
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00020249778754077852
sam_encoder.blocks.6.norm1.weight grad: 0.0004611366312019527
sam_encoder.blocks.6.norm1.bias grad: 0.0009382256539538503
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00018735459889285266
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.439246448688209e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00010713438678067178
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.5309022273868322e-05
sam_encoder.blocks.6.norm2.weight grad: -0.001161370426416397
sam_encoder.blocks.6.norm2.bias grad: -0.0008605336188338697
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0007029632106423378
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00024589430540800095
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00012523046461865306
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.159358938224614e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0009377141250297427
sam_encoder.blocks.7.norm1.bias grad: 1.0579591616988182e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007794381817802787
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00048530552885495126
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.000506032258272171
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0006477578426711261
sam_encoder.blocks.7.norm2.weight grad: -0.00031006778590381145
sam_encoder.blocks.7.norm2.bias grad: 0.00032075989292934537
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00022694654762744904
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.618356125429273e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1876230928464793e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00010420849866932258
sam_encoder.blocks.8.norm1.weight grad: 8.012205216800794e-05
sam_encoder.blocks.8.norm1.bias grad: 0.00011074050416937098
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00030719576170668006
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.725111547391862e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.246161526883952e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00013007635425310582
sam_encoder.blocks.8.norm2.weight grad: 0.0011345109669491649
sam_encoder.blocks.8.norm2.bias grad: -0.00014704547356814146
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0009304351406171918
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0005389025900512934
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0006980185280553997
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00023021454398985952
sam_encoder.blocks.9.norm1.weight grad: 0.0006598166073672473
sam_encoder.blocks.9.norm1.bias grad: 3.544942592270672e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0005356803885661066
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00017628655768930912
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00019040133338421583
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.000158920549438335
sam_encoder.blocks.9.norm2.weight grad: 0.0020228249486535788
sam_encoder.blocks.9.norm2.bias grad: 0.0004431804991327226
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0012114106211811304
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0008230245439335704
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0004909940762445331
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00019092763250228018
sam_encoder.blocks.10.norm1.weight grad: 0.000753232860006392
sam_encoder.blocks.10.norm1.bias grad: 0.00022316304966807365
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0005244497442618012
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00022972786973696202
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00015202962094917893
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.24252313375473e-05
sam_encoder.blocks.10.norm2.weight grad: 0.003184732049703598
sam_encoder.blocks.10.norm2.bias grad: 0.0007664170116186142
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0012773586204275489
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.000783695257268846
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0004121750534977764
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 9.643934026826173e-05
sam_encoder.blocks.11.norm1.weight grad: 0.001812734641134739
sam_encoder.blocks.11.norm1.bias grad: 0.00019051317940466106
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0001664732553763315
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00011566549073904753
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00014595090760849416
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.129610533709638e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0038071777671575546
sam_encoder.blocks.11.norm2.bias grad: 0.00014401067164726555
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0014458016958087683
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00067822978598997
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0006094950367696583
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.0002939963014796376
sam_encoder.neck.conv1.trainable_scale grad: 0.00014595931861549616
sam_encoder.neck.conv1.trainable_shift grad: 0.003385028801858425
sam_encoder.neck.conv2.trainable_scale grad: 2.0133797079324722e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.012368965893983841
mask_decoder.transformer.layers.0.norm1.weight grad: 0.01949123479425907
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0006871148943901062
mask_decoder.transformer.layers.0.norm2.weight grad: -0.4313702881336212
mask_decoder.transformer.layers.0.norm2.bias grad: -0.3214719295501709
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00028653349727392197
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00886429101228714
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0015847950708121061
mask_decoder.transformer.layers.0.norm4.bias grad: -0.001494326046667993
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0011342500802129507
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0007887240499258041
mask_decoder.transformer.layers.1.norm2.weight grad: -0.03141303360462189
mask_decoder.transformer.layers.1.norm2.bias grad: -0.008976602926850319
mask_decoder.transformer.layers.1.norm3.weight grad: -0.004926036112010479
mask_decoder.transformer.layers.1.norm3.bias grad: -0.005039076320827007
mask_decoder.transformer.layers.1.norm4.weight grad: -0.010981779545545578
mask_decoder.transformer.layers.1.norm4.bias grad: -0.021614404395222664
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003957304288633168
mask_decoder.transformer.norm_final_attn.bias grad: 0.0007205649744719267
Text_Embedding_Affine.0.weight grad: -3.196256592730151e-09
Text_Embedding_Affine.0.bias grad: -1.0256189852952957e-07
Text_Embedding_Affine.2.weight grad: -4.564877364998665e-10
Text_Embedding_Affine.2.bias grad: -0.006214777939021587
Epoch 17 finished with average loss: -47.0754
Epoch 18/39
----------
Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/3 [00:01<?, ?it/s, loss=-39.6]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it, loss=-39.6]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it, loss=-48.3]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s, loss=-48.3]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s, loss=-46.4]Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.15it/s, loss=-46.4]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.745782318157145e-13
Max value: 0.9995125532150269
Mean value: 0.06134447455406189

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.745782318157145e-13
Max value: 0.9995125532150269
Mean value: 0.06134447455406189

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07495927810668945

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.007638931274414
Max value: -1.1920928244535389e-07
Mean value: -0.12930697202682495

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04526185989379883

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07495927810668945

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 9.193842887878418
Max value: 56.63182067871094
Mean value: 39.563358306884766

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.745782318157145e-13
Max value: 0.9995125532150269
Mean value: 0.06134447455406189

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.745782318157145e-13
Max value: 0.9995125532150269
Mean value: 0.06134447455406189

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.745782318157145e-13
Max value: 0.9995125532150269
Mean value: 0.06134447455406189

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.007638931274414
Max value: -1.1920928244535389e-07
Mean value: -0.12930697202682495

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 9.193842887878418
Max value: 56.63182067871094
Mean value: 39.563358306884766

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -39.56440734863281
Max value: -39.56440734863281
Mean value: -39.56440734863281
sam_encoder.pos_embed grad: -1.0689227565308101e-06
sam_encoder.blocks.0.norm1.weight grad: -0.004061362240463495
sam_encoder.blocks.0.norm1.bias grad: 0.022144746035337448
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0017837604973465204
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.2013590902788565e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0023411347065120935
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0009239548817276955
sam_encoder.blocks.0.norm2.weight grad: 0.020192712545394897
sam_encoder.blocks.0.norm2.bias grad: -0.002961506601423025
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.003990001976490021
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.001272139372304082
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0026942442636936903
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00024241108621936291
sam_encoder.blocks.1.norm1.weight grad: 0.0031198207288980484
sam_encoder.blocks.1.norm1.bias grad: -0.0011893055634573102
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0009903223253786564
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.00034603019594214857
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0008139949641190469
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00042687426321208477
sam_encoder.blocks.1.norm2.weight grad: -0.00041000646888278425
sam_encoder.blocks.1.norm2.bias grad: 0.0015930002555251122
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0007518173079006374
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00016561026859562844
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.00014620934962294996
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.214131670072675e-05
sam_encoder.blocks.2.norm1.weight grad: 0.001718617044389248
sam_encoder.blocks.2.norm1.bias grad: -0.0012549827806651592
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0011757229221984744
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.134531289106235e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.437845175038092e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0010674502700567245
sam_encoder.blocks.2.norm2.weight grad: -0.00019368708308320493
sam_encoder.blocks.2.norm2.bias grad: -0.002812215592712164
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00039192073745653033
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.272934403270483e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0007128735887818038
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00048258574679493904
sam_encoder.blocks.3.norm1.weight grad: -0.003960299771279097
sam_encoder.blocks.3.norm1.bias grad: 0.001010165666230023
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.002208670135587454
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0002371837035752833
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.511489921947941e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00025351683143526316
sam_encoder.blocks.3.norm2.weight grad: 0.0039372872561216354
sam_encoder.blocks.3.norm2.bias grad: 0.005467727314680815
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0032053273171186447
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.001288914354518056
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0007351398817263544
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00044036045437678695
sam_encoder.blocks.4.norm1.weight grad: -0.0003630662977229804
sam_encoder.blocks.4.norm1.bias grad: 0.0015331212198361754
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0005970068159513175
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0002803214592859149
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00010036973981186748
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002542503352742642
sam_encoder.blocks.4.norm2.weight grad: -0.00478100311011076
sam_encoder.blocks.4.norm2.bias grad: -0.001878451555967331
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.003791455179452896
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.001568418461829424
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0005221401806920767
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00042781466618180275
sam_encoder.blocks.5.norm1.weight grad: 0.002259080298244953
sam_encoder.blocks.5.norm1.bias grad: 0.0008674117270857096
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0011317308526486158
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.016343781491742e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00015007681213319302
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0007923846133053303
sam_encoder.blocks.5.norm2.weight grad: -0.002406700048595667
sam_encoder.blocks.5.norm2.bias grad: -0.0031916345469653606
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0014057325897738338
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0005460999673232436
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00040160826756618917
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.599612531019375e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0003171791904605925
sam_encoder.blocks.6.norm1.bias grad: 0.0017047293949872255
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.7932110242545605e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0002554354432504624
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0003037679707631469
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.9161496311426163e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0016348607605323195
sam_encoder.blocks.6.norm2.bias grad: -0.0004930640570819378
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0011776183964684606
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0005628253566101193
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0008679504389874637
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00037476816214621067
sam_encoder.blocks.7.norm1.weight grad: 0.0012873763917014003
sam_encoder.blocks.7.norm1.bias grad: 0.00038566114380955696
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0014016914647072554
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.000549228279851377
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0008095558732748032
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00021798396483063698
sam_encoder.blocks.7.norm2.weight grad: 0.0008579340646974742
sam_encoder.blocks.7.norm2.bias grad: 0.00026260787853971124
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00017187090998049825
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.00012716393393930048
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0003815696982201189
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0002689200919121504
sam_encoder.blocks.8.norm1.weight grad: -0.00030276496545411646
sam_encoder.blocks.8.norm1.bias grad: 0.000490592559799552
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0008507107850164175
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.000396525691030547
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.09335880249273e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0006603612564504147
sam_encoder.blocks.8.norm2.weight grad: 0.0005168956704437733
sam_encoder.blocks.8.norm2.bias grad: -0.0008437279611825943
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0005684761563315988
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00012202105426695198
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.520137397572398e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00011531877680681646
sam_encoder.blocks.9.norm1.weight grad: -0.0007344478508457541
sam_encoder.blocks.9.norm1.bias grad: 0.00046335533261299133
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0006015794351696968
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0001025123565341346
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.0189385142875835e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0004337290010880679
sam_encoder.blocks.9.norm2.weight grad: 0.0020769916009157896
sam_encoder.blocks.9.norm2.bias grad: -0.00043608201667666435
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0017632333328947425
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0008931200718507171
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00035783665953204036
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.719203080749139e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0004529363941401243
sam_encoder.blocks.10.norm1.bias grad: 0.0002469478640705347
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0005531241185963154
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00037446635542437434
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0003566788218449801
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00020344299264252186
sam_encoder.blocks.10.norm2.weight grad: 0.0017712272237986326
sam_encoder.blocks.10.norm2.bias grad: -0.0007536895573139191
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0011920154793187976
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00033944923779927194
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00019366566266398877
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.621780241606757e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0012854478554800153
sam_encoder.blocks.11.norm1.bias grad: -1.4364602975547314e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00025237794034183025
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.776310768444091e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.294250048696995e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.358263585250825e-05
sam_encoder.blocks.11.norm2.weight grad: -5.448262527352199e-05
sam_encoder.blocks.11.norm2.bias grad: -0.0009658852941356599
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.001039637136273086
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00016271500498987734
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0003692407044582069
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00010159034718526527
sam_encoder.neck.conv1.trainable_scale grad: -0.00019388645887374878
sam_encoder.neck.conv1.trainable_shift grad: -0.006002233363687992
sam_encoder.neck.conv2.trainable_scale grad: -0.00035829609259963036
sam_encoder.neck.conv2.trainable_shift grad: 0.010417592711746693
mask_decoder.transformer.layers.0.norm1.weight grad: -0.06837344914674759
mask_decoder.transformer.layers.0.norm1.bias grad: -3.9478763937950134e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -2.353853464126587
mask_decoder.transformer.layers.0.norm2.bias grad: 0.2187288999557495
mask_decoder.transformer.layers.0.norm3.weight grad: -0.02956084907054901
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00472163176164031
mask_decoder.transformer.layers.0.norm4.weight grad: 0.017103096470236778
mask_decoder.transformer.layers.0.norm4.bias grad: -0.002848118543624878
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0168001726269722
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0002627614885568619
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0031365184113383293
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004587873816490173
mask_decoder.transformer.layers.1.norm3.weight grad: 0.011096920818090439
mask_decoder.transformer.layers.1.norm3.bias grad: 0.015317529439926147
mask_decoder.transformer.layers.1.norm4.weight grad: -0.006530904211103916
mask_decoder.transformer.layers.1.norm4.bias grad: -0.04754239693284035
mask_decoder.transformer.norm_final_attn.weight grad: 0.0018503449391573668
mask_decoder.transformer.norm_final_attn.bias grad: 0.0038828826509416103
Text_Embedding_Affine.0.weight grad: 2.0205712658594166e-09
Text_Embedding_Affine.0.bias grad: 2.0397419575601816e-07
Text_Embedding_Affine.2.weight grad: -2.2286100076485127e-08
Text_Embedding_Affine.2.bias grad: 0.010782778263092041

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.440300786623161e-13
Max value: 0.9990471005439758
Mean value: 0.08927342295646667

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.440300786623161e-13
Max value: 0.9990471005439758
Mean value: 0.08927342295646667

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09430694580078125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.600639343261719
Max value: -1.1920928244535389e-07
Mean value: -0.1316964030265808

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07797479629516602

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09430694580078125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 15.954374313354492
Max value: 83.27030944824219
Mean value: 57.12605285644531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.440300786623161e-13
Max value: 0.9990471005439758
Mean value: 0.08927342295646667

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.440300786623161e-13
Max value: 0.9990471005439758
Mean value: 0.08927342295646667

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.440300786623161e-13
Max value: 0.9990471005439758
Mean value: 0.08927342295646667

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.600639343261719
Max value: -1.1920928244535389e-07
Mean value: -0.1316964030265808

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 15.954374313354492
Max value: 83.27030944824219
Mean value: 57.12605285644531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.127296447753906
Max value: -57.127296447753906
Mean value: -57.127296447753906
sam_encoder.pos_embed grad: -3.465004283498274e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0077463677152991295
sam_encoder.blocks.0.norm1.bias grad: -0.0028319889679551125
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00030017219251021743
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.219948070589453e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0006126249209046364
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.3509494237951003e-05
sam_encoder.blocks.0.norm2.weight grad: -0.0016106727998703718
sam_encoder.blocks.0.norm2.bias grad: 0.002549238968640566
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.000518013839609921
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0002527603937778622
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0028356751427054405
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0010791161330416799
sam_encoder.blocks.1.norm1.weight grad: -0.0020696138963103294
sam_encoder.blocks.1.norm1.bias grad: -8.767207327764481e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00043550290865823627
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00017799535999074578
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00018537922005634755
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00013540690997615457
sam_encoder.blocks.1.norm2.weight grad: 0.001935602631419897
sam_encoder.blocks.1.norm2.bias grad: -0.0005026045837439597
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0012608872493728995
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0003383541479706764
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3482233043760061e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00011255202116444707
sam_encoder.blocks.2.norm1.weight grad: 0.00034674463677220047
sam_encoder.blocks.2.norm1.bias grad: 0.0003866403712891042
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.5308731235563755e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.0320184275042266e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.000300470128422603
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000335065764375031
sam_encoder.blocks.2.norm2.weight grad: 0.000643462932202965
sam_encoder.blocks.2.norm2.bias grad: -0.0013664157595485449
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00039061083225533366
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.1496993465698324e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0003448716306593269
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.226088615017943e-05
sam_encoder.blocks.3.norm1.weight grad: 0.000975453935097903
sam_encoder.blocks.3.norm1.bias grad: -0.0004229351761750877
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 7.653683132957667e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.798029916244559e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.511686271755025e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.422912413952872e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0006417887634597719
sam_encoder.blocks.3.norm2.bias grad: -0.001216623350046575
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0001783145999070257
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.2890515538165346e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0008090645424090326
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00011453242041170597
sam_encoder.blocks.4.norm1.weight grad: 0.0010633936617523432
sam_encoder.blocks.4.norm1.bias grad: -0.000517933804076165
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.000877313083037734
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002279688196722418
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0005220753373578191
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00025985430693253875
sam_encoder.blocks.4.norm2.weight grad: -0.0031085778027772903
sam_encoder.blocks.4.norm2.bias grad: -0.0015424385201185942
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0018796338699758053
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.000653617549687624
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00018528022337704897
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.619375876151025e-06
sam_encoder.blocks.5.norm1.weight grad: 0.0009017577394843102
sam_encoder.blocks.5.norm1.bias grad: 0.00012745390995405614
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0004870173870585859
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.94516527093947e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00031292837229557335
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00014021791866980493
sam_encoder.blocks.5.norm2.weight grad: -0.0010039681801572442
sam_encoder.blocks.5.norm2.bias grad: -0.00080772367073223
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00031385477632284164
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00011205498594790697
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00034920847974717617
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00010813027620315552
sam_encoder.blocks.6.norm1.weight grad: -0.00010469490371178836
sam_encoder.blocks.6.norm1.bias grad: 0.0004980044323019683
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00016674747166689485
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.327999588189414e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.832174065290019e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00015512428944930434
sam_encoder.blocks.6.norm2.weight grad: -0.0005758539191447198
sam_encoder.blocks.6.norm2.bias grad: -9.244195825885981e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00040986662497743964
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00015827309107407928
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002732081338763237
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.7540509108803235e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0005729947006329894
sam_encoder.blocks.7.norm1.bias grad: -4.0473980334354565e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0003084663185290992
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00023787158716004342
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.822280556662008e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.869473948725499e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0003710592573042959
sam_encoder.blocks.7.norm2.bias grad: 0.00015755914500914514
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00011493924830574542
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.231354877352715e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.37026789970696e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.2824479199480265e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0007998530054464936
sam_encoder.blocks.8.norm1.bias grad: 4.160643948125653e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00045291491551324725
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0002011969918385148
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00016821743338368833
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00026629166677594185
sam_encoder.blocks.8.norm2.weight grad: -3.8087124266894534e-05
sam_encoder.blocks.8.norm2.bias grad: -9.732482430990785e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.884285539854318e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.720877667656168e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0001823503989726305
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.5189376174239442e-05
sam_encoder.blocks.9.norm1.weight grad: 8.655269630253315e-05
sam_encoder.blocks.9.norm1.bias grad: -6.090606257203035e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00010290239879395813
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.019408157138969e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.8539070626720786e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00011701932817231864
sam_encoder.blocks.9.norm2.weight grad: 0.00029681395972147584
sam_encoder.blocks.9.norm2.bias grad: 3.007710438396316e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00012860086280852556
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00014228341751731932
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00010848841338884085
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.036804734321777e-06
sam_encoder.blocks.10.norm1.weight grad: 0.0003553669375833124
sam_encoder.blocks.10.norm1.bias grad: 0.00011977424583164975
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00025013438425958157
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00011947118764510378
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.260702502913773e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.6462410712847486e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0006008622003719211
sam_encoder.blocks.10.norm2.bias grad: -2.771412255242467e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0003335836809128523
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00020101798872929066
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00018556986469775438
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.8155022189603187e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0005724873626604676
sam_encoder.blocks.11.norm1.bias grad: 0.00020496800425462425
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.316869176866021e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.839631244773045e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.2343686800450087e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.328673119540326e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0006831646896898746
sam_encoder.blocks.11.norm2.bias grad: -0.00021294421458151191
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00048403581604361534
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00013879846665076911
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00018053494568448514
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.294974835123867e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.059511072933674e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0014038712251931429
sam_encoder.neck.conv2.trainable_scale grad: -6.685219705104828e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.005568656139075756
mask_decoder.transformer.layers.0.norm1.weight grad: 0.009282905608415604
mask_decoder.transformer.layers.0.norm1.bias grad: 5.589146167039871e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.1622443050146103
mask_decoder.transformer.layers.0.norm2.bias grad: -0.09992672502994537
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00325469090603292
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00087692093802616
mask_decoder.transformer.layers.0.norm4.weight grad: 0.002118183532729745
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0002440260723233223
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0024300231598317623
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0004001770867034793
mask_decoder.transformer.layers.1.norm2.weight grad: -0.007062510587275028
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0022151079028844833
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0039542256854474545
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00013170456804800779
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002552254591137171
mask_decoder.transformer.layers.1.norm4.bias grad: -0.012760830111801624
mask_decoder.transformer.norm_final_attn.weight grad: -4.636151425074786e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0006782533600926399
Text_Embedding_Affine.0.weight grad: -1.0817144957542268e-09
Text_Embedding_Affine.0.bias grad: -2.5029294192790985e-08
Text_Embedding_Affine.2.weight grad: -4.074244053242637e-09
Text_Embedding_Affine.2.bias grad: -0.0035348853562027216

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.3765864770884946e-08
Max value: 0.9837179780006409
Mean value: 0.09504333138465881

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.3765864770884946e-08
Max value: 0.9837179780006409
Mean value: 0.09504333138465881

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07976913452148438

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.457077980041504
Max value: -1.1920928244535389e-07
Mean value: -0.1390092670917511

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06604862213134766

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07976913452148438

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 31.06725311279297
Max value: 62.432804107666016
Mean value: 42.52267074584961

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.3765864770884946e-08
Max value: 0.9837179780006409
Mean value: 0.09504333138465881

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.3765864770884946e-08
Max value: 0.9837179780006409
Mean value: 0.09504333138465881

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.3765864770884946e-08
Max value: 0.9837179780006409
Mean value: 0.09504333138465881

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.457077980041504
Max value: -1.1920928244535389e-07
Mean value: -0.1390092670917511

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 31.06725311279297
Max value: 62.432804107666016
Mean value: 42.52267074584961

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -42.524497985839844
Max value: -42.524497985839844
Mean value: -42.524497985839844
sam_encoder.pos_embed grad: -8.104776725303964e-07
sam_encoder.blocks.0.norm1.weight grad: -0.001698052859865129
sam_encoder.blocks.0.norm1.bias grad: -0.0002280101180076599
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00044419695041142404
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.84601759025827e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0008437749929726124
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.4004060328006744e-05
sam_encoder.blocks.0.norm2.weight grad: -0.0026812634896486998
sam_encoder.blocks.0.norm2.bias grad: 0.003007514402270317
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0013732423540204763
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0005495408549904823
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0009980099275708199
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00017851212760433555
sam_encoder.blocks.1.norm1.weight grad: -0.0004074364551343024
sam_encoder.blocks.1.norm1.bias grad: 0.0009239547653123736
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.894653779454529e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.5686491678934544e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0003749451134353876
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.724343206267804e-05
sam_encoder.blocks.1.norm2.weight grad: 0.00017443890101276338
sam_encoder.blocks.1.norm2.bias grad: -0.0003494525735732168
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00014308308891486377
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.829246507957578e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.669930295785889e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00019045505905523896
sam_encoder.blocks.2.norm1.weight grad: 0.001346040517091751
sam_encoder.blocks.2.norm1.bias grad: -0.0012951758690178394
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0006815350498072803
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00020824340754188597
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.0872720496263355e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00018165854271501303
sam_encoder.blocks.2.norm2.weight grad: -0.000326617737300694
sam_encoder.blocks.2.norm2.bias grad: 3.9018032111926004e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00016739394050091505
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.882979970308952e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00038860662607476115
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00019967998377978802
sam_encoder.blocks.3.norm1.weight grad: 0.00034307767054997385
sam_encoder.blocks.3.norm1.bias grad: -0.001023879973217845
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0005307144019752741
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0001155668287537992
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0005908754537813365
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0002745673409663141
sam_encoder.blocks.3.norm2.weight grad: 0.0007398081361316144
sam_encoder.blocks.3.norm2.bias grad: -0.0005049313767813146
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0005091005587019026
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7723734345054254e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.653310265392065e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00018775658099912107
sam_encoder.blocks.4.norm1.weight grad: 0.0012062990572303534
sam_encoder.blocks.4.norm1.bias grad: -0.001389905228279531
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00027381221298128366
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.000237189102335833
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00029682472813874483
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0002949148474726826
sam_encoder.blocks.4.norm2.weight grad: 0.00013779933215118945
sam_encoder.blocks.4.norm2.bias grad: 0.0007382908370345831
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.073683759197593e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.843098056677263e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00020114239305257797
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0001091623998945579
sam_encoder.blocks.5.norm1.weight grad: 0.00045390683226287365
sam_encoder.blocks.5.norm1.bias grad: -0.001938709057867527
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0004353272670414299
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0003516020660754293
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0003084594791289419
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0004675622913055122
sam_encoder.blocks.5.norm2.weight grad: 0.0013043908402323723
sam_encoder.blocks.5.norm2.bias grad: 0.0006280307425186038
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0005467945011332631
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0002656642463989556
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0003206155670341104
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.229132122825831e-05
sam_encoder.blocks.6.norm1.weight grad: 0.000855912163387984
sam_encoder.blocks.6.norm1.bias grad: -4.256410102243535e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0004409576649777591
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00021010222553741187
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0001864677033154294
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00026206791517324746
sam_encoder.blocks.6.norm2.weight grad: -0.00029011405422352254
sam_encoder.blocks.6.norm2.bias grad: -0.00035701351589523256
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0002813679166138172
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00020547755411826074
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00018333853222429752
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.622275057248771e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00020648795180022717
sam_encoder.blocks.7.norm1.bias grad: -9.318280353909358e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.736191714182496e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.0459686210379004e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00020135811064392328
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0002894204808399081
sam_encoder.blocks.7.norm2.weight grad: -0.00011515418736962602
sam_encoder.blocks.7.norm2.bias grad: -2.099021730828099e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00046239799121394753
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002862458932213485
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.033287844620645e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.095320400665514e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0004781808820553124
sam_encoder.blocks.8.norm1.bias grad: -3.844395905616693e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00045821029925718904
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0002115122915711254
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00035068433498963714
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0002306061505805701
sam_encoder.blocks.8.norm2.weight grad: 0.00034738832619041204
sam_encoder.blocks.8.norm2.bias grad: 0.0001235561940120533
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.2785671970050316e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.781292515574023e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00028770643984898925
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.616394527256489e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0005983039154671133
sam_encoder.blocks.9.norm1.bias grad: 0.00011182660819031298
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00034243613481521606
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.212609928799793e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00010893846047110856
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00024319786462001503
sam_encoder.blocks.9.norm2.weight grad: 0.000986885279417038
sam_encoder.blocks.9.norm2.bias grad: 0.0003585129452403635
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.000438408664194867
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0003595354501157999
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0004594934871420264
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00021104631014168262
sam_encoder.blocks.10.norm1.weight grad: 0.0006157697062008083
sam_encoder.blocks.10.norm1.bias grad: 0.0001679977576714009
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0003987402596976608
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00012777643860317767
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.272614079236519e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.936192271998152e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0009804400615394115
sam_encoder.blocks.10.norm2.bias grad: 0.00046247290447354317
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0002626056666485965
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00024387164739891887
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00027857953682541847
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 9.792151831788942e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00016242385026998818
sam_encoder.blocks.11.norm1.bias grad: -2.5279296096414328e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.3441628804430366e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.3649575521412771e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.482638127636164e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.163015233236365e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0012123634805902839
sam_encoder.blocks.11.norm2.bias grad: -0.00041566183790564537
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0006508982041850686
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00025256708613596857
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0002809593570418656
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00016628553566988558
sam_encoder.neck.conv1.trainable_scale grad: 9.12186224013567e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.005722606088966131
sam_encoder.neck.conv2.trainable_scale grad: 0.00010175583884119987
sam_encoder.neck.conv2.trainable_shift grad: -0.00831954088062048
mask_decoder.transformer.layers.0.norm1.weight grad: 0.002334155607968569
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0005873888731002808
mask_decoder.transformer.layers.0.norm2.weight grad: 0.15763086080551147
mask_decoder.transformer.layers.0.norm2.bias grad: -0.10146165639162064
mask_decoder.transformer.layers.0.norm3.weight grad: -0.004841111600399017
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0027049765922129154
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0010089520364999771
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000678044802043587
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0006044306792318821
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0002685688668861985
mask_decoder.transformer.layers.1.norm2.weight grad: -0.011423405259847641
mask_decoder.transformer.layers.1.norm2.bias grad: -0.002839507069438696
mask_decoder.transformer.layers.1.norm3.weight grad: -0.002632845425978303
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0016771801747381687
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0018752319738268852
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0030380841344594955
mask_decoder.transformer.norm_final_attn.weight grad: 0.00010946726979454979
mask_decoder.transformer.norm_final_attn.bias grad: -0.00019100078498013318
Text_Embedding_Affine.0.weight grad: -5.889000398440203e-11
Text_Embedding_Affine.0.bias grad: -8.32369551062584e-09
Text_Embedding_Affine.2.weight grad: -2.5972579642541405e-09
Text_Embedding_Affine.2.bias grad: -0.0026490180753171444
Epoch 18 finished with average loss: -46.4054
Epoch 19/39
----------
Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s, loss=-48.1]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-48.1]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-51]  Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-51]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-55.6]Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-55.6]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.571378873716945e-12
Max value: 0.9983831644058228
Mean value: 0.07578563690185547

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.571378873716945e-12
Max value: 0.9983831644058228
Mean value: 0.07578563690185547

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07160139083862305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11869046092033386

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06243562698364258

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07160139083862305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 24.982385635375977
Max value: 59.02535629272461
Mean value: 48.10491943359375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.571378873716945e-12
Max value: 0.9983831644058228
Mean value: 0.07578563690185547

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.571378873716945e-12
Max value: 0.9983831644058228
Mean value: 0.07578563690185547

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.571378873716945e-12
Max value: 0.9983831644058228
Mean value: 0.07578563690185547

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11869046092033386

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 24.982385635375977
Max value: 59.02535629272461
Mean value: 48.10491943359375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -48.10603713989258
Max value: -48.10603713989258
Mean value: -48.10603713989258
sam_encoder.pos_embed grad: -1.4658326108474284e-07
sam_encoder.blocks.0.norm1.weight grad: -0.01725912094116211
sam_encoder.blocks.0.norm1.bias grad: -0.008560799062252045
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0030248230323195457
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.0006203477969393134
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0042276568710803986
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0012526580831035972
sam_encoder.blocks.0.norm2.weight grad: 0.004662422463297844
sam_encoder.blocks.0.norm2.bias grad: 0.007078354246914387
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.004106336273252964
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0018821824342012405
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.006006187759339809
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0007692200015299022
sam_encoder.blocks.1.norm1.weight grad: -0.005233956500887871
sam_encoder.blocks.1.norm1.bias grad: 0.0003849123604595661
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00017206589109264314
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00023014176986180246
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.000266711984295398
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00013842509360983968
sam_encoder.blocks.1.norm2.weight grad: -0.006219672970473766
sam_encoder.blocks.1.norm2.bias grad: 0.0011094411602243781
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0023780898191034794
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.0003751595504581928
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0004279225831851363
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00017753010615706444
sam_encoder.blocks.2.norm1.weight grad: 0.0015380382537841797
sam_encoder.blocks.2.norm1.bias grad: 0.0021332399919629097
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0007092664018273354
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.0004703949671238661
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00015836147940717638
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0002431357861496508
sam_encoder.blocks.2.norm2.weight grad: 0.003717593615874648
sam_encoder.blocks.2.norm2.bias grad: -0.006909673102200031
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0035185026936233044
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0005658047739416361
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.001243431936018169
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004570209130179137
sam_encoder.blocks.3.norm1.weight grad: 0.0034714797511696815
sam_encoder.blocks.3.norm1.bias grad: 0.0009584733052179217
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0009070043452084064
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003642694791778922
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00018845632439479232
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00045104854507371783
sam_encoder.blocks.3.norm2.weight grad: -0.0022837824653834105
sam_encoder.blocks.3.norm2.bias grad: -0.0027188118547201157
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0023017418570816517
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0010214722715318203
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0004037548787891865
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00010302239388693124
sam_encoder.blocks.4.norm1.weight grad: 0.00041809570393525064
sam_encoder.blocks.4.norm1.bias grad: -0.002290916396304965
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.001196386176161468
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00033732602605596185
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0003138022730126977
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0001332771935267374
sam_encoder.blocks.4.norm2.weight grad: 0.003615700639784336
sam_encoder.blocks.4.norm2.bias grad: 0.0006510082166641951
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0021869668271392584
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0008750492124818265
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.9598908693296835e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00040370222995989025
sam_encoder.blocks.5.norm1.weight grad: 0.0031499709002673626
sam_encoder.blocks.5.norm1.bias grad: -0.00026001266087405384
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0027787459548562765
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0009760758839547634
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0001418272004229948
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0007524912944063544
sam_encoder.blocks.5.norm2.weight grad: 0.00020822894293814898
sam_encoder.blocks.5.norm2.bias grad: -4.7901878133416176e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.907712981454097e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.2460160329937935e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0005983181763440371
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.0005857263458892703
sam_encoder.blocks.6.norm1.weight grad: -0.0007137649226933718
sam_encoder.blocks.6.norm1.bias grad: -0.001247206935659051
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0006178752519190311
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.088709778850898e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0003574094735085964
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0005548064946196973
sam_encoder.blocks.6.norm2.weight grad: -0.001451039919629693
sam_encoder.blocks.6.norm2.bias grad: -0.00014511360495816916
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0009509898955002427
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00041254359530285
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0003283146652393043
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.0002911351330112666
sam_encoder.blocks.7.norm1.weight grad: -0.000938472046982497
sam_encoder.blocks.7.norm1.bias grad: -4.9155594751937315e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0011800213251262903
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.74173968238756e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0004238158871885389
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00013210355245973915
sam_encoder.blocks.7.norm2.weight grad: -0.0005736630409955978
sam_encoder.blocks.7.norm2.bias grad: 0.000590500480029732
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0009807783644646406
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00046796671813353896
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.0001669308840064332
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00024541275342926383
sam_encoder.blocks.8.norm1.weight grad: -0.001392426318489015
sam_encoder.blocks.8.norm1.bias grad: 0.0003949835663661361
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0014355381717905402
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.45018876134418e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0013540604850277305
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0017502348637208343
sam_encoder.blocks.8.norm2.weight grad: 6.8323512095958e-05
sam_encoder.blocks.8.norm2.bias grad: 0.0005446528666652739
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0004551961028482765
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0001121222012443468
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0007035979069769382
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00037075544241815805
sam_encoder.blocks.9.norm1.weight grad: 3.763166751014069e-05
sam_encoder.blocks.9.norm1.bias grad: -0.0002400489174760878
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00041278370190411806
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0007138769142329693
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00033710693242028356
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.548410889692605e-05
sam_encoder.blocks.9.norm2.weight grad: 0.000594787357840687
sam_encoder.blocks.9.norm2.bias grad: 0.0008850976591929793
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00046817222028039396
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00015458543202839792
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0006973942508921027
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0004218433459755033
sam_encoder.blocks.10.norm1.weight grad: -0.0003008526691701263
sam_encoder.blocks.10.norm1.bias grad: -0.00016991961456369609
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0006911446107551455
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00030989060178399086
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.000470686296466738
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.0004133012262172997
sam_encoder.blocks.10.norm2.weight grad: -0.00018109774100594223
sam_encoder.blocks.10.norm2.bias grad: 0.00047495574108324945
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00039253634167835116
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00011251837713643909
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0005435033235698938
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 0.00020505287102423608
sam_encoder.blocks.11.norm1.weight grad: -0.0025347035843878984
sam_encoder.blocks.11.norm1.bias grad: 0.0006617747130803764
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.000642336905002594
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00026249399525113404
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0002094822993967682
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00013349422079045326
sam_encoder.blocks.11.norm2.weight grad: 0.003584963735193014
sam_encoder.blocks.11.norm2.bias grad: 3.171099160681479e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.000811076897662133
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0005178372375667095
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0012098451843485236
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00045610227971337736
sam_encoder.neck.conv1.trainable_scale grad: 0.0004812059924006462
sam_encoder.neck.conv1.trainable_shift grad: 0.004641511477530003
sam_encoder.neck.conv2.trainable_scale grad: 0.0006724335253238678
sam_encoder.neck.conv2.trainable_shift grad: -0.0134676992893219
mask_decoder.transformer.layers.0.norm1.weight grad: 0.051957037299871445
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0029923608526587486
mask_decoder.transformer.layers.0.norm2.weight grad: 1.1419117450714111
mask_decoder.transformer.layers.0.norm2.bias grad: -0.24730603396892548
mask_decoder.transformer.layers.0.norm3.weight grad: 0.049095891416072845
mask_decoder.transformer.layers.0.norm3.bias grad: 0.023392390459775925
mask_decoder.transformer.layers.0.norm4.weight grad: -0.02379448711872101
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0024952716194093227
mask_decoder.transformer.layers.1.norm1.weight grad: -0.003906513564288616
mask_decoder.transformer.layers.1.norm1.bias grad: -0.002007067436352372
mask_decoder.transformer.layers.1.norm2.weight grad: 0.07643593847751617
mask_decoder.transformer.layers.1.norm2.bias grad: 0.02857569232583046
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0050797490403056145
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00027237762697041035
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0009637700859457254
mask_decoder.transformer.layers.1.norm4.bias grad: 0.03693046420812607
mask_decoder.transformer.norm_final_attn.weight grad: -6.076489808037877e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.004216296598315239
Text_Embedding_Affine.0.weight grad: -3.830815664684906e-09
Text_Embedding_Affine.0.bias grad: -4.548928700387478e-08
Text_Embedding_Affine.2.weight grad: -1.2570983365378652e-08
Text_Embedding_Affine.2.bias grad: -0.016440216451883316

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.434528526922824e-14
Max value: 0.9968133568763733
Mean value: 0.08871608972549438

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.434528526922824e-14
Max value: 0.9968133568763733
Mean value: 0.08871608972549438

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08468866348266602

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.698517799377441
Max value: -1.1920928244535389e-07
Mean value: -0.1243499293923378

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07397890090942383

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08468866348266602

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.581775665283203
Max value: 69.9537124633789
Mean value: 53.921043395996094

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.434528526922824e-14
Max value: 0.9968133568763733
Mean value: 0.08871608972549438

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.434528526922824e-14
Max value: 0.9968133568763733
Mean value: 0.08871608972549438

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.434528526922824e-14
Max value: 0.9968133568763733
Mean value: 0.08871608972549438

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.698517799377441
Max value: -1.1920928244535389e-07
Mean value: -0.1243499293923378

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.581775665283203
Max value: 69.9537124633789
Mean value: 53.921043395996094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.92236328125
Max value: -53.92236328125
Mean value: -53.92236328125
sam_encoder.pos_embed grad: 7.501104164475692e-07
sam_encoder.blocks.0.norm1.weight grad: 0.001230198540724814
sam_encoder.blocks.0.norm1.bias grad: 0.009276086464524269
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0002484624565113336
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.369022670085542e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.001798013923689723
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.000759697228204459
sam_encoder.blocks.0.norm2.weight grad: 0.0048327757976949215
sam_encoder.blocks.0.norm2.bias grad: -0.009163003414869308
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.004299516789615154
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0017595558892935514
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0011159669375047088
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0007438290631398559
sam_encoder.blocks.1.norm1.weight grad: 0.0015970764216035604
sam_encoder.blocks.1.norm1.bias grad: 0.0011471802135929465
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00040058360900729895
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.5356806620256975e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0003798229736275971
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00024551129899919033
sam_encoder.blocks.1.norm2.weight grad: -0.00015106289356481284
sam_encoder.blocks.1.norm2.bias grad: -0.0002491316699888557
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00041719223372638226
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.41067555686459e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0013516845647245646
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.106610478833318e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0018288276623934507
sam_encoder.blocks.2.norm1.bias grad: 0.0006797524401918054
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0010741481091827154
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00026701396564021707
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0005110012134537101
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003943149349652231
sam_encoder.blocks.2.norm2.weight grad: -0.0007250198977999389
sam_encoder.blocks.2.norm2.bias grad: -0.0014158531557768583
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0008681592298671603
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00026753320707939565
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006556216394528747
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.981114660855383e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0014266341459006071
sam_encoder.blocks.3.norm1.bias grad: 0.0007578431395813823
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0013037417083978653
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0002372569579165429
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0008415691554546356
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0003284154227003455
sam_encoder.blocks.3.norm2.weight grad: -0.0014379622880369425
sam_encoder.blocks.3.norm2.bias grad: 0.00038219286943785846
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0010899148182943463
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0002489385660737753
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0008257476147264242
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0002916911034844816
sam_encoder.blocks.4.norm1.weight grad: -0.0011149488855153322
sam_encoder.blocks.4.norm1.bias grad: 0.0009469666401855648
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0007540414808318019
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.000255492574069649
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0005531833739951253
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.000708461448084563
sam_encoder.blocks.4.norm2.weight grad: -0.0009646301623433828
sam_encoder.blocks.4.norm2.bias grad: 0.0001025994642986916
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0008419293444603682
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0002651374670676887
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0005321853677742183
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00031356114777736366
sam_encoder.blocks.5.norm1.weight grad: -0.0013657439267262816
sam_encoder.blocks.5.norm1.bias grad: 4.501099465414882e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0004967054119333625
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00018161522166337818
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00039042095886543393
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00048177092685364187
sam_encoder.blocks.5.norm2.weight grad: -0.0011762564536184072
sam_encoder.blocks.5.norm2.bias grad: -0.000607257941737771
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0008723448845557868
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0003516202559694648
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.582247002981603e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.032430534716696e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00044439075281843543
sam_encoder.blocks.6.norm1.bias grad: -0.0004385422798804939
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.595469727064483e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.327470378484577e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.618407107656822e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.708196739666164e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0007835100404918194
sam_encoder.blocks.6.norm2.bias grad: 0.0006311694160103798
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00044960304512642324
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00025382250896655023
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002829479053616524
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00016631324251648039
sam_encoder.blocks.7.norm1.weight grad: -0.0002032007323578
sam_encoder.blocks.7.norm1.bias grad: 8.997968507173937e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00018174822616856545
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.714683306403458e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0001851667620940134
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0002791246515698731
sam_encoder.blocks.7.norm2.weight grad: 0.0006266041891649365
sam_encoder.blocks.7.norm2.bias grad: -4.2735871829790995e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00012006203178316355
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.00010207657760474831
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.700752030359581e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.5091192835825495e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0005205633351579309
sam_encoder.blocks.8.norm1.bias grad: -8.156697731465101e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0004477070178836584
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.502544859657064e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00011467708827694878
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00018724575056694448
sam_encoder.blocks.8.norm2.weight grad: -0.0006199776544235647
sam_encoder.blocks.8.norm2.bias grad: 1.0488448424439412e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0006683929823338985
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00032525582355447114
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00043095610453747213
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00021844354341737926
sam_encoder.blocks.9.norm1.weight grad: -0.0006478022551164031
sam_encoder.blocks.9.norm1.bias grad: 6.246751581784338e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0005350541323423386
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0001704328169580549
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00021120463497936726
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00031749968184158206
sam_encoder.blocks.9.norm2.weight grad: -0.0006024473696015775
sam_encoder.blocks.9.norm2.bias grad: -0.00023359424085356295
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00040757906390354037
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00024517549900338054
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00018169960821978748
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.181036537280306e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00021581476903520525
sam_encoder.blocks.10.norm1.bias grad: -2.8261649276828393e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00013001220941077918
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.018348045065068e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.209596823377069e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.183830115944147e-06
sam_encoder.blocks.10.norm2.weight grad: -0.0019569199066609144
sam_encoder.blocks.10.norm2.bias grad: -0.0006759073003195226
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0006310624303296208
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0005384589312598109
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00041500767110846937
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00012174920266261324
sam_encoder.blocks.11.norm1.weight grad: 0.000676991418004036
sam_encoder.blocks.11.norm1.bias grad: -5.866137144039385e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0007497211918234825
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001319651200901717
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.6644276911392808e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2198075637570582e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0019152779132127762
sam_encoder.blocks.11.norm2.bias grad: -8.332577272085473e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0005620843730866909
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00040477566653862596
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00039629871025681496
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00021395948715507984
sam_encoder.neck.conv1.trainable_scale grad: -0.0001825639046728611
sam_encoder.neck.conv1.trainable_shift grad: -0.003234847914427519
sam_encoder.neck.conv2.trainable_scale grad: -0.00012587918899953365
sam_encoder.neck.conv2.trainable_shift grad: 0.010837172158062458
mask_decoder.transformer.layers.0.norm1.weight grad: -0.025250066071748734
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00024917908012866974
mask_decoder.transformer.layers.0.norm2.weight grad: -0.08635213971138
mask_decoder.transformer.layers.0.norm2.bias grad: 0.23490169644355774
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0073369527235627174
mask_decoder.transformer.layers.0.norm3.bias grad: 0.005675544496625662
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0008510758634656668
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00028575133183039725
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0040039969608187675
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0006729697925038636
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0248723141849041
mask_decoder.transformer.layers.1.norm2.bias grad: 0.009994585998356342
mask_decoder.transformer.layers.1.norm3.weight grad: 0.005278168246150017
mask_decoder.transformer.layers.1.norm3.bias grad: 0.006004171911627054
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0034779601264744997
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0020003137178719044
mask_decoder.transformer.norm_final_attn.weight grad: 0.0002696746669244021
mask_decoder.transformer.norm_final_attn.bias grad: 0.0003396273241378367
Text_Embedding_Affine.0.weight grad: -1.443981600957045e-09
Text_Embedding_Affine.0.bias grad: -5.0640664994716644e-08
Text_Embedding_Affine.2.weight grad: 1.0691902474491144e-08
Text_Embedding_Affine.2.bias grad: 0.0051465630531311035

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.8642739182137564e-12
Max value: 0.9998677968978882
Mean value: 0.09974134713411331

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.8642739182137564e-12
Max value: 0.9998677968978882
Mean value: 0.09974134713411331

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10636138916015625

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13248412311077118

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09207916259765625

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10636138916015625

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 45.2593879699707
Max value: 80.60417938232422
Mean value: 64.85441589355469

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.8642739182137564e-12
Max value: 0.9998677968978882
Mean value: 0.09974134713411331

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.8642739182137564e-12
Max value: 0.9998677968978882
Mean value: 0.09974134713411331

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.8642739182137564e-12
Max value: 0.9998677968978882
Mean value: 0.09974134713411331

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13248412311077118

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 45.2593879699707
Max value: 80.60417938232422
Mean value: 64.85441589355469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.85560607910156
Max value: -64.85560607910156
Mean value: -64.85560607910156
sam_encoder.pos_embed grad: -1.682942638581153e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0019348273053765297
sam_encoder.blocks.0.norm1.bias grad: -0.00775568000972271
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0005918601527810097
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.346356606925838e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0024157424923032522
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0006766896112821996
sam_encoder.blocks.0.norm2.weight grad: -0.0032345231156796217
sam_encoder.blocks.0.norm2.bias grad: 0.007009544875472784
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0027503464370965958
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.000996733084321022
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0014863356482237577
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.000357678160071373
sam_encoder.blocks.1.norm1.weight grad: -0.0020401477813720703
sam_encoder.blocks.1.norm1.bias grad: -0.001606398494914174
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00038513270555995405
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.243401690473547e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0004959092475473881
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00041177752427756786
sam_encoder.blocks.1.norm2.weight grad: 0.0005264824721962214
sam_encoder.blocks.1.norm2.bias grad: 0.000853443518280983
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0002616976562421769
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.7101450794143602e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0013811776880174875
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0002599016879685223
sam_encoder.blocks.2.norm1.weight grad: 0.0018455979879945517
sam_encoder.blocks.2.norm1.bias grad: -0.0008983408915810287
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0013091256842017174
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00038651187787763774
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0005991238285787404
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00043663670658133924
sam_encoder.blocks.2.norm2.weight grad: 0.0016149799339473248
sam_encoder.blocks.2.norm2.bias grad: -0.0008757127216085792
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0016633205814287066
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0004643830470740795
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0005255438154563308
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.648536509601399e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0012840961571782827
sam_encoder.blocks.3.norm1.bias grad: -0.0004136900824960321
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0009528803639113903
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.475976078945678e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0005076845991425216
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.000193376254173927
sam_encoder.blocks.3.norm2.weight grad: 0.0006377114332281053
sam_encoder.blocks.3.norm2.bias grad: -0.0005507095484063029
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00014875218039378524
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.558197830803692e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0006136762676760554
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00021717659546993673
sam_encoder.blocks.4.norm1.weight grad: 0.001427201903425157
sam_encoder.blocks.4.norm1.bias grad: -0.0015092117246240377
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0010884370421990752
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0003716355131473392
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00041728519136086106
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00046937487786635756
sam_encoder.blocks.4.norm2.weight grad: 0.0013209888711571693
sam_encoder.blocks.4.norm2.bias grad: 0.0007593611953780055
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0010752809466794133
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00035629497142508626
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00046980055049061775
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0003781401028390974
sam_encoder.blocks.5.norm1.weight grad: 0.0010219996329396963
sam_encoder.blocks.5.norm1.bias grad: 0.00010369877418270335
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0008755851886235178
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0005698003806173801
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.287422290071845e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00025123648811131716
sam_encoder.blocks.5.norm2.weight grad: 0.0008230726234614849
sam_encoder.blocks.5.norm2.bias grad: 0.00028198372456245124
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0005039774114266038
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00021650151757057756
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00020486405992414802
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00017823079542722553
sam_encoder.blocks.6.norm1.weight grad: -0.0005055742803961039
sam_encoder.blocks.6.norm1.bias grad: 0.00015832764620427042
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0003607120015658438
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.496288576978259e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00016094889724627137
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.1959533165209e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0006132759153842926
sam_encoder.blocks.6.norm2.bias grad: 5.6482581385353114e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00022681467817164958
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.464761049253866e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.482218224031385e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.811945367080625e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00019259545661043376
sam_encoder.blocks.7.norm1.bias grad: -0.00013283616863191128
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.151299097226001e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.816055196803063e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.998265886679292e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0003307135193608701
sam_encoder.blocks.7.norm2.weight grad: -0.0007681994466111064
sam_encoder.blocks.7.norm2.bias grad: 0.00014851194282528013
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0006410726346075535
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002665855863597244
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.0630279070464894e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.0884122932329774e-05
sam_encoder.blocks.8.norm1.weight grad: -0.00029972061747685075
sam_encoder.blocks.8.norm1.bias grad: 0.00033148363581858575
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0003822841099463403
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00010508713603485376
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00040387455374002457
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0004383836349006742
sam_encoder.blocks.8.norm2.weight grad: 0.0005735327722504735
sam_encoder.blocks.8.norm2.bias grad: 0.00013739985297434032
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00041446590330451727
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00023747264640405774
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0005257243174128234
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.000283096800558269
sam_encoder.blocks.9.norm1.weight grad: 0.0003354582004249096
sam_encoder.blocks.9.norm1.bias grad: -3.363268479006365e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00020521592523436993
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.7528916689334437e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00011374318273738027
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00014721964544150978
sam_encoder.blocks.9.norm2.weight grad: 0.0005219969898462296
sam_encoder.blocks.9.norm2.bias grad: 0.00036343533429317176
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 8.019073720788583e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00016066434909589589
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0002934106159955263
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.00018216016178485006
sam_encoder.blocks.10.norm1.weight grad: 0.00025946961250156164
sam_encoder.blocks.10.norm1.bias grad: -2.9124068532837555e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0001225899177370593
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.49165459536016e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.1529889383818954e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0473799193277955e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0008478969102725387
sam_encoder.blocks.10.norm2.bias grad: 0.0004264028393663466
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00010022829519584775
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00010410576214781031
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0002733168366830796
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.514562846859917e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0002890005416702479
sam_encoder.blocks.11.norm1.bias grad: 0.0001017871472868137
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00025805510813370347
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.3772921192867216e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0001764788175933063
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00010126788401976228
sam_encoder.blocks.11.norm2.weight grad: 0.0014566764002665877
sam_encoder.blocks.11.norm2.bias grad: -7.8842476796126e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0004629800678230822
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0002589982468634844
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0004886952228844166
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.0002056251250905916
sam_encoder.neck.conv1.trainable_scale grad: 0.00014541554264724255
sam_encoder.neck.conv1.trainable_shift grad: 0.002694241236895323
sam_encoder.neck.conv2.trainable_scale grad: 0.00015967595390975475
sam_encoder.neck.conv2.trainable_shift grad: -0.006040001288056374
mask_decoder.transformer.layers.0.norm1.weight grad: 0.011728357523679733
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0007385052740573883
mask_decoder.transformer.layers.0.norm2.weight grad: 0.3216296434402466
mask_decoder.transformer.layers.0.norm2.bias grad: -0.12875409424304962
mask_decoder.transformer.layers.0.norm3.weight grad: 0.001963629387319088
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0032632106449455023
mask_decoder.transformer.layers.0.norm4.weight grad: -0.014838931150734425
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0003268580185249448
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0001304965408053249
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00013716815738007426
mask_decoder.transformer.layers.1.norm2.weight grad: 0.007206863723695278
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0005666804499924183
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0038439424242824316
mask_decoder.transformer.layers.1.norm3.bias grad: -0.000895576027687639
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002021207707002759
mask_decoder.transformer.layers.1.norm4.bias grad: 0.014520062133669853
mask_decoder.transformer.norm_final_attn.weight grad: -6.690519512630999e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0015056338161230087
Text_Embedding_Affine.0.weight grad: -4.674182152442086e-10
Text_Embedding_Affine.0.bias grad: -1.1641532182693481e-08
Text_Embedding_Affine.2.weight grad: 3.5384624119672026e-09
Text_Embedding_Affine.2.bias grad: -0.005887599661946297
Epoch 19 finished with average loss: -55.6280
Epoch 20/39
----------
Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s, loss=-50.1]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.13it/s, loss=-50.1]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.13it/s, loss=-49.6]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-49.6]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-51]  Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.15it/s, loss=-51]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.092767800419601e-15
Max value: 0.9968003034591675
Mean value: 0.08369176089763641

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.092767800419601e-15
Max value: 0.9968003034591675
Mean value: 0.08369176089763641

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08993959426879883

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1347762793302536

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0735006332397461

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08993959426879883

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 19.38788604736328
Max value: 70.0450210571289
Mean value: 50.13489532470703

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.092767800419601e-15
Max value: 0.9968003034591675
Mean value: 0.08369176089763641

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.092767800419601e-15
Max value: 0.9968003034591675
Mean value: 0.08369176089763641

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.092767800419601e-15
Max value: 0.9968003034591675
Mean value: 0.08369176089763641

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1347762793302536

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 19.38788604736328
Max value: 70.0450210571289
Mean value: 50.13489532470703

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.13609313964844
Max value: -50.13609313964844
Mean value: -50.13609313964844
sam_encoder.pos_embed grad: -3.9435425946976466e-07
sam_encoder.blocks.0.norm1.weight grad: 0.004307632800191641
sam_encoder.blocks.0.norm1.bias grad: 0.003006997285410762
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0007642335258424282
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.480523835401982e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0001137126237154007
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00014780698984395713
sam_encoder.blocks.0.norm2.weight grad: 0.002113902475684881
sam_encoder.blocks.0.norm2.bias grad: -0.001760127954185009
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.7299200155539438e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003531144466251135
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0007187732262536883
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00019844048074446619
sam_encoder.blocks.1.norm1.weight grad: 0.0009019969729706645
sam_encoder.blocks.1.norm1.bias grad: 0.0009315131464973092
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00014094667858444154
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.611949068726972e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.718535976484418e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.761078111594543e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0008157574920915067
sam_encoder.blocks.1.norm2.bias grad: -0.00013580871745944023
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0007289091008715332
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0002568194759078324
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0005232890835031867
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.264102896442637e-05
sam_encoder.blocks.2.norm1.weight grad: 0.00030083462479524314
sam_encoder.blocks.2.norm1.bias grad: 0.00045508582843467593
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.947062577935867e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.043427336204331e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.441481622867286e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.101602826267481e-07
sam_encoder.blocks.2.norm2.weight grad: -0.0003325049765408039
sam_encoder.blocks.2.norm2.bias grad: -0.0014456433709710836
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0006674990290775895
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0003535034484229982
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006434606621041894
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0001727585622575134
sam_encoder.blocks.3.norm1.weight grad: 0.0002820883528329432
sam_encoder.blocks.3.norm1.bias grad: -0.00013309973292052746
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0007983433897607028
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00017715140711516142
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005371705628931522
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00014431739691644907
sam_encoder.blocks.3.norm2.weight grad: -0.001908584381453693
sam_encoder.blocks.3.norm2.bias grad: -0.0011350972345098853
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0014498670352622867
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0005179553991183639
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0005154007812961936
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00024422642309218645
sam_encoder.blocks.4.norm1.weight grad: 7.484170782845467e-05
sam_encoder.blocks.4.norm1.bias grad: -0.00014426710549741983
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00039768818533048034
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00021191923588048667
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00011102421558462083
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.7353857401758432e-05
sam_encoder.blocks.4.norm2.weight grad: -0.003395977895706892
sam_encoder.blocks.4.norm2.bias grad: -0.001821786630898714
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0022828197106719017
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0007667061872780323
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0007285946048796177
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0003487406938802451
sam_encoder.blocks.5.norm1.weight grad: -9.480088181135216e-08
sam_encoder.blocks.5.norm1.bias grad: -0.0011021476238965988
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.26427640276961e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00013685844896826893
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0003731166943907738
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00046642229426652193
sam_encoder.blocks.5.norm2.weight grad: -0.002351876115426421
sam_encoder.blocks.5.norm2.bias grad: -0.001382437301799655
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0007080491632223129
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0001894319138955325
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.0001393179118167609
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.741514077177271e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00043199810897931457
sam_encoder.blocks.6.norm1.bias grad: 6.131854024715722e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00039865245344117284
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00010276520333718508
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00026661864831112325
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00014764336810912937
sam_encoder.blocks.6.norm2.weight grad: -0.0017912189941853285
sam_encoder.blocks.6.norm2.bias grad: -0.0004250959027558565
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0010068712290376425
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00027222296921536326
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00021863350411877036
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00010638531239237636
sam_encoder.blocks.7.norm1.weight grad: 0.00044906901894137263
sam_encoder.blocks.7.norm1.bias grad: -6.287371797952801e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00010109895083587617
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.039781899540685e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.769042713334784e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0001716081751510501
sam_encoder.blocks.7.norm2.weight grad: 0.0005732590216211975
sam_encoder.blocks.7.norm2.bias grad: 1.2176150448794942e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0004969332367181778
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.000294183730147779
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.57512323919218e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.9608133849687874e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0001237268152181059
sam_encoder.blocks.8.norm1.bias grad: -0.00030380638781934977
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00042877841042354703
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.775505168363452e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.45082545815967e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3937950825493317e-05
sam_encoder.blocks.8.norm2.weight grad: -0.00029593653744086623
sam_encoder.blocks.8.norm2.bias grad: -0.00021893717348575592
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.896417810115963e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.7859896615846083e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00020636338740587234
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.101843897951767e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0006609160918742418
sam_encoder.blocks.9.norm1.bias grad: 5.979486013529822e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0007117709028534591
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00013415503781288862
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00017450741142965853
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0003230474248994142
sam_encoder.blocks.9.norm2.weight grad: -0.0004927194095216691
sam_encoder.blocks.9.norm2.bias grad: -0.00032845043460838497
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00013492602738551795
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00027015406521968544
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.796694939723238e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.602782114990987e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00014023958647157997
sam_encoder.blocks.10.norm1.bias grad: 0.00015082885511219501
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.83084373222664e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.926959678006824e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00012094861449440941
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00011511626507854089
sam_encoder.blocks.10.norm2.weight grad: -0.00010148565343115479
sam_encoder.blocks.10.norm2.bias grad: -0.0003520168538670987
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00021926508634351194
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.4728686993476e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.542045881971717e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.455470429500565e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0004820155445486307
sam_encoder.blocks.11.norm1.bias grad: 0.00010119262151420116
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00012409273767843843
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.415371975279413e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.575721247121692e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.4578796001151204e-05
sam_encoder.blocks.11.norm2.weight grad: -6.090267561376095e-07
sam_encoder.blocks.11.norm2.bias grad: -6.337370723485947e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0004076974873896688
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.892752571729943e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.230357732623816e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00010309678327757865
sam_encoder.neck.conv1.trainable_scale grad: -0.00021365936845541
sam_encoder.neck.conv1.trainable_shift grad: 0.002215888351202011
sam_encoder.neck.conv2.trainable_scale grad: -0.00020322762429714203
sam_encoder.neck.conv2.trainable_shift grad: 0.01009576115757227
mask_decoder.transformer.layers.0.norm1.weight grad: -0.020432425662875175
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00016677938401699066
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3475183844566345
mask_decoder.transformer.layers.0.norm2.bias grad: 0.118989497423172
mask_decoder.transformer.layers.0.norm3.weight grad: -0.002755235880613327
mask_decoder.transformer.layers.0.norm3.bias grad: 0.006864044349640608
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0014798477059230208
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0007472628494724631
mask_decoder.transformer.layers.1.norm1.weight grad: 0.005547132343053818
mask_decoder.transformer.layers.1.norm1.bias grad: 1.1796364560723305e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.031857553869485855
mask_decoder.transformer.layers.1.norm2.bias grad: 0.008818372152745724
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00729620736092329
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0049529168754816055
mask_decoder.transformer.layers.1.norm4.weight grad: 0.011514155194163322
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0018140696920454502
mask_decoder.transformer.norm_final_attn.weight grad: 0.0005250774556770921
mask_decoder.transformer.norm_final_attn.bias grad: 0.000400533783249557
Text_Embedding_Affine.0.weight grad: -2.3630628565030065e-09
Text_Embedding_Affine.0.bias grad: -1.2005330063402653e-07
Text_Embedding_Affine.2.weight grad: 8.558058262053692e-09
Text_Embedding_Affine.2.bias grad: 0.00017693592235445976

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.310806048403061e-13
Max value: 0.9994760155677795
Mean value: 0.07946452498435974

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.310806048403061e-13
Max value: 0.9994760155677795
Mean value: 0.07946452498435974

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07625293731689453

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.648149490356445
Max value: -1.1920928244535389e-07
Mean value: -0.1233375072479248

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0605320930480957

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07625293731689453

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 26.66600227355957
Max value: 83.03585815429688
Mean value: 49.01267623901367

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.310806048403061e-13
Max value: 0.9994760155677795
Mean value: 0.07946452498435974

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.310806048403061e-13
Max value: 0.9994760155677795
Mean value: 0.07946452498435974

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.310806048403061e-13
Max value: 0.9994760155677795
Mean value: 0.07946452498435974

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.648149490356445
Max value: -1.1920928244535389e-07
Mean value: -0.1233375072479248

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 26.66600227355957
Max value: 83.03585815429688
Mean value: 49.01267623901367

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.013916015625
Max value: -49.013916015625
Mean value: -49.013916015625
sam_encoder.pos_embed grad: -3.086704225552239e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0006995815201662481
sam_encoder.blocks.0.norm1.bias grad: -0.0009039935539476573
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.000232052625506185
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.292366404319182e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00015085771156009287
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0423983439977746e-05
sam_encoder.blocks.0.norm2.weight grad: -0.0010066198883578181
sam_encoder.blocks.0.norm2.bias grad: 0.006602983456104994
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.001631985418498516
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0006116923759691417
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0012609914410859346
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00047730907681398094
sam_encoder.blocks.1.norm1.weight grad: 0.0007470321725122631
sam_encoder.blocks.1.norm1.bias grad: 0.0015207523247227073
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0007995275082066655
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 0.00010986813867930323
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.00015043641906231642
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00013161238166503608
sam_encoder.blocks.1.norm2.weight grad: 0.0028674376662820578
sam_encoder.blocks.1.norm2.bias grad: 0.00033385303686372936
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0006126228836365044
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001858175965026021
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0006665200926363468
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.766841837204993e-05
sam_encoder.blocks.2.norm1.weight grad: 0.001030621351674199
sam_encoder.blocks.2.norm1.bias grad: -0.00037594838067889214
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0006857781554572284
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00016547780251130462
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.6890073311515152e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.908009264501743e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0006833052029833198
sam_encoder.blocks.2.norm2.bias grad: -0.0006505123456008732
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0004899262567050755
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00012700812658295035
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.000383965321816504
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.648895552847534e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0005301943747326732
sam_encoder.blocks.3.norm1.bias grad: -0.0008087577298283577
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0004106654960196465
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.555040504783392e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00041478112689219415
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.315504626603797e-05
sam_encoder.blocks.3.norm2.weight grad: 0.00042189162923023105
sam_encoder.blocks.3.norm2.bias grad: -0.0005317097529768944
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00026108612655662
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00011746864765882492
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0006973538547754288
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00011874621122842655
sam_encoder.blocks.4.norm1.weight grad: 0.001580424141138792
sam_encoder.blocks.4.norm1.bias grad: -0.0013925329549238086
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0008611736120656133
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002819266519509256
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0003492950927466154
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00013570793089456856
sam_encoder.blocks.4.norm2.weight grad: -0.0023139440454542637
sam_encoder.blocks.4.norm2.bias grad: -0.0012914560502395034
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0012586083030328155
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0005552053917199373
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00020985989249311388
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.0290357749909163e-05
sam_encoder.blocks.5.norm1.weight grad: 0.001213600393384695
sam_encoder.blocks.5.norm1.bias grad: -0.001060423906892538
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0008362933876924217
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0003181549836881459
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00030000158585608006
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.724409569054842e-07
sam_encoder.blocks.5.norm2.weight grad: -0.0007834945572540164
sam_encoder.blocks.5.norm2.bias grad: -0.0003881033044308424
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00018881195865105838
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00011177004489582032
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0004003209760412574
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.510570579441264e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0008985999738797545
sam_encoder.blocks.6.norm1.bias grad: 0.000263549096416682
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0006191454594954848
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003139172913506627
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00023752081324346364
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.837804100243375e-05
sam_encoder.blocks.6.norm2.weight grad: -0.000935845950152725
sam_encoder.blocks.6.norm2.bias grad: -0.00012926523049827665
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0005970062920823693
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00027941446751356125
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.283536928705871e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0106208492288715e-06
sam_encoder.blocks.7.norm1.weight grad: 0.0012005940079689026
sam_encoder.blocks.7.norm1.bias grad: 2.3627420887351036e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007524561951868236
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00037444429472088814
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00019457022426649928
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.552561196964234e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0004837485612370074
sam_encoder.blocks.7.norm2.bias grad: 6.2348167375603225e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00013390205276664346
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00012406257155817002
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.246005831490038e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.272011235821992e-05
sam_encoder.blocks.8.norm1.weight grad: 3.6338627978693694e-05
sam_encoder.blocks.8.norm1.bias grad: -8.846480341162533e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.561507375910878e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.044889631884871e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00012891844380646944
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.531951708486304e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0001125275157392025
sam_encoder.blocks.8.norm2.bias grad: -0.00013749596837442368
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.3837452065199614e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.920323357917368e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.17232542228885e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.2213498596102e-07
sam_encoder.blocks.9.norm1.weight grad: -3.2060440844361437e-06
sam_encoder.blocks.9.norm1.bias grad: -3.540875331964344e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00012768094893544912
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.3528081581171136e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.2332907216623425e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 8.772611909080297e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00010191478941123933
sam_encoder.blocks.9.norm2.bias grad: 9.788545867195353e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00010930376447504386
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00010495295282453299
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00010595985077088699
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.3435541177386767e-06
sam_encoder.blocks.10.norm1.weight grad: 0.00032174529042094946
sam_encoder.blocks.10.norm1.bias grad: 1.3058093827567063e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00021128809021320194
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0001019710543914698
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00012057370622642338
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.248099841992371e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0002943335275631398
sam_encoder.blocks.10.norm2.bias grad: 0.00020350630802568048
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.5236131477868184e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.00349225755781e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.628237315453589e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.3824878957821056e-05
sam_encoder.blocks.11.norm1.weight grad: 0.00047915949835442007
sam_encoder.blocks.11.norm1.bias grad: 0.00013852628762833774
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.503681652247906e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.288454409921542e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00010403060878161341
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.41568549326621e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0005724132061004639
sam_encoder.blocks.11.norm2.bias grad: 0.00018041828298009932
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00013597426004707813
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0001000649353954941
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00010448065586388111
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.9953203920740634e-05
sam_encoder.neck.conv1.trainable_scale grad: 9.385973680764437e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0012349265161901712
sam_encoder.neck.conv2.trainable_scale grad: -1.3573328033089638e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0032013587187975645
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0002624569460749626
mask_decoder.transformer.layers.0.norm1.bias grad: -7.517263293266296e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.1262713074684143
mask_decoder.transformer.layers.0.norm2.bias grad: -0.14243698120117188
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0013835064601153135
mask_decoder.transformer.layers.0.norm3.bias grad: -0.009832723066210747
mask_decoder.transformer.layers.0.norm4.weight grad: 0.009630026295781136
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0010068153496831656
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0018840811681002378
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0011461549438536167
mask_decoder.transformer.layers.1.norm2.weight grad: -0.030738599598407745
mask_decoder.transformer.layers.1.norm2.bias grad: -0.010008242912590504
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0015269950963556767
mask_decoder.transformer.layers.1.norm3.bias grad: -0.004324184264987707
mask_decoder.transformer.layers.1.norm4.weight grad: -0.005765941459685564
mask_decoder.transformer.layers.1.norm4.bias grad: -0.014686934649944305
mask_decoder.transformer.norm_final_attn.weight grad: -0.0002470251638442278
mask_decoder.transformer.norm_final_attn.bias grad: 0.001107722637243569
Text_Embedding_Affine.0.weight grad: 5.929070567844974e-10
Text_Embedding_Affine.0.bias grad: 3.294553607702255e-08
Text_Embedding_Affine.2.weight grad: 2.8370799043386796e-09
Text_Embedding_Affine.2.bias grad: -0.00017394265159964561

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.975842753969118e-08
Max value: 0.9891019463539124
Mean value: 0.0908794179558754

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.975842753969118e-08
Max value: 0.9891019463539124
Mean value: 0.0908794179558754

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08574295043945312

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.360896110534668
Max value: -1.1920928244535389e-07
Mean value: -0.12084933370351791

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0733327865600586

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08574295043945312

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 42.78050231933594
Max value: 69.53792572021484
Mean value: 53.77375411987305

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.975842753969118e-08
Max value: 0.9891019463539124
Mean value: 0.0908794179558754

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.975842753969118e-08
Max value: 0.9891019463539124
Mean value: 0.0908794179558754

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.975842753969118e-08
Max value: 0.9891019463539124
Mean value: 0.0908794179558754

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.360896110534668
Max value: -1.1920928244535389e-07
Mean value: -0.12084933370351791

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 42.78050231933594
Max value: 69.53792572021484
Mean value: 53.77375411987305

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.77524185180664
Max value: -53.77524185180664
Mean value: -53.77524185180664
sam_encoder.pos_embed grad: 2.0135807687893248e-07
sam_encoder.blocks.0.norm1.weight grad: 0.006018975283950567
sam_encoder.blocks.0.norm1.bias grad: 0.00030075552058406174
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00028253725031390786
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.73262106324546e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0006101705366745591
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.000247000134550035
sam_encoder.blocks.0.norm2.weight grad: 0.004137537442147732
sam_encoder.blocks.0.norm2.bias grad: 0.00010801712051033974
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0021859267726540565
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0012073034886270761
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0011046947911381721
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0003224808897357434
sam_encoder.blocks.1.norm1.weight grad: 0.0015438348054885864
sam_encoder.blocks.1.norm1.bias grad: 0.0007354590343311429
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0001309354993281886
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00011103625729447231
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00017389474669471383
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.0786224265757482e-05
sam_encoder.blocks.1.norm2.weight grad: 0.000576159858610481
sam_encoder.blocks.1.norm2.bias grad: -0.0002722828066907823
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0006138240569271147
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00017372396541759372
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0002610914525575936
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.0999795601237565e-05
sam_encoder.blocks.2.norm1.weight grad: 0.00024332638713531196
sam_encoder.blocks.2.norm1.bias grad: -0.00012317921209614724
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00020758944447152317
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.5719858462689444e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.000539891654625535
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00017727480735629797
sam_encoder.blocks.2.norm2.weight grad: -0.0003930002567358315
sam_encoder.blocks.2.norm2.bias grad: -0.0007071570726111531
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0002509708283469081
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001886085228761658
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0003710351884365082
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00021442779689095914
sam_encoder.blocks.3.norm1.weight grad: -0.0009016795083880424
sam_encoder.blocks.3.norm1.bias grad: 0.00036976602859795094
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0005971842911094427
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00014087135787121952
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00031037942972034216
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.238885493483394e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0006441670120693743
sam_encoder.blocks.3.norm2.bias grad: 0.00039368236321024597
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005114381201565266
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0001411213306710124
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00045292696449905634
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00038015711470507085
sam_encoder.blocks.4.norm1.weight grad: -4.1659613998490386e-06
sam_encoder.blocks.4.norm1.bias grad: 0.00043182389345020056
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00030503934249281883
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00023288291413336992
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00010148106230190024
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00033789637382142246
sam_encoder.blocks.4.norm2.weight grad: -0.0012191312853246927
sam_encoder.blocks.4.norm2.bias grad: -0.00047275004908442497
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0005414375336840749
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.000151349842781201
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00038470441359095275
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00015428874758072197
sam_encoder.blocks.5.norm1.weight grad: -0.0005393993342295289
sam_encoder.blocks.5.norm1.bias grad: -0.0004922476364299655
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0001821396144805476
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.184403173392639e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.289495260920376e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00015757049550302327
sam_encoder.blocks.5.norm2.weight grad: -0.0016439122846350074
sam_encoder.blocks.5.norm2.bias grad: -0.0003264807164669037
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0007210447220131755
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00023514943313784897
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00013088494597468525
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00013647356536239386
sam_encoder.blocks.6.norm1.weight grad: 7.305752660613507e-05
sam_encoder.blocks.6.norm1.bias grad: -0.0001690478529781103
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.381845792522654e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.665122550155502e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.79785046284087e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.947085497202352e-05
sam_encoder.blocks.6.norm2.weight grad: -0.00046773123904131353
sam_encoder.blocks.6.norm2.bias grad: 0.000232417369261384
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0002848372096195817
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.933374733198434e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.316361683886498e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.189867104287259e-05
sam_encoder.blocks.7.norm1.weight grad: -0.00010769523214548826
sam_encoder.blocks.7.norm1.bias grad: 0.00031863513868302107
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0002705395163502544
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.686091364827007e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.476159716024995e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0002510885242372751
sam_encoder.blocks.7.norm2.weight grad: 0.00025600945809856057
sam_encoder.blocks.7.norm2.bias grad: 7.881870260462165e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.474435940617695e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.401523569365963e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00010505266254767776
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.946533252019435e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0007343490142375231
sam_encoder.blocks.8.norm1.bias grad: 8.248138328781351e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0005672343540936708
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.700253288727254e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0001558152143843472
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.836857548682019e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0005748657276853919
sam_encoder.blocks.8.norm2.bias grad: 7.956377521622926e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00047954986803233624
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00020663106988649815
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00023683991457801312
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.0001269285858143121
sam_encoder.blocks.9.norm1.weight grad: -0.00016231511835940182
sam_encoder.blocks.9.norm1.bias grad: -3.1633226171834394e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.272013267036527e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.745846232865006e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.231026054592803e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00015249336138367653
sam_encoder.blocks.9.norm2.weight grad: -0.0004649769398383796
sam_encoder.blocks.9.norm2.bias grad: -0.00013088135165162385
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00022817261924501508
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00014056687359698117
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.201024370966479e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.93182335756137e-06
sam_encoder.blocks.10.norm1.weight grad: 0.0003676096675917506
sam_encoder.blocks.10.norm1.bias grad: 1.338004949502647e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0002471187326591462
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.207328210119158e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00011531924246810377
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.8032826927956194e-05
sam_encoder.blocks.10.norm2.weight grad: -0.000970268331002444
sam_encoder.blocks.10.norm2.bias grad: -0.000287923205178231
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0003333799249958247
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00017272934201173484
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00012346227595116943
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.534036270342767e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0017774205189198256
sam_encoder.blocks.11.norm1.bias grad: 0.00010386189387645572
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0013884974177926779
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00022185615671332926
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00032177081448026
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0001858099567471072
sam_encoder.blocks.11.norm2.weight grad: -0.0014299219474196434
sam_encoder.blocks.11.norm2.bias grad: -0.00032395211746916175
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.246272535761818e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00023183457960840315
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0002794128959067166
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00011953746434301138
sam_encoder.neck.conv1.trainable_scale grad: -6.5050553530454636e-06
sam_encoder.neck.conv1.trainable_shift grad: -0.003195127472281456
sam_encoder.neck.conv2.trainable_scale grad: 1.22834462672472e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.004505298566073179
mask_decoder.transformer.layers.0.norm1.weight grad: -0.013108557090163231
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00034042634069919586
mask_decoder.transformer.layers.0.norm2.weight grad: -0.24730408191680908
mask_decoder.transformer.layers.0.norm2.bias grad: 0.10189668834209442
mask_decoder.transformer.layers.0.norm3.weight grad: 0.009286724030971527
mask_decoder.transformer.layers.0.norm3.bias grad: 0.005044594872742891
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0015986651415005326
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00024061708245426416
mask_decoder.transformer.layers.1.norm1.weight grad: 0.003546951338648796
mask_decoder.transformer.layers.1.norm1.bias grad: -0.000507442862726748
mask_decoder.transformer.layers.1.norm2.weight grad: 0.018315445631742477
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004027962684631348
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0033522266894578934
mask_decoder.transformer.layers.1.norm3.bias grad: 0.004078355617821217
mask_decoder.transformer.layers.1.norm4.weight grad: -0.003810593858361244
mask_decoder.transformer.layers.1.norm4.bias grad: -0.007498112507164478
mask_decoder.transformer.norm_final_attn.weight grad: 0.00014642455789726228
mask_decoder.transformer.norm_final_attn.bias grad: -7.65224831411615e-05
Text_Embedding_Affine.0.weight grad: -1.156177376060441e-10
Text_Embedding_Affine.0.bias grad: -3.9814040064811707e-08
Text_Embedding_Affine.2.weight grad: 1.2867400478455693e-08
Text_Embedding_Affine.2.bias grad: 0.0008624987676739693
Epoch 20 finished with average loss: -50.9751
Epoch 21/39
----------
Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-59]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-54]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-54]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-54]Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-54]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.676269104267065e-16
Max value: 0.9996463060379028
Mean value: 0.0930698812007904

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.676269104267065e-16
Max value: 0.9996463060379028
Mean value: 0.0930698812007904

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08995437622070312

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12992505729198456

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0840764045715332

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08995437622070312

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 32.92158889770508
Max value: 76.38313293457031
Mean value: 58.95838928222656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.676269104267065e-16
Max value: 0.9996463060379028
Mean value: 0.0930698812007904

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.676269104267065e-16
Max value: 0.9996463060379028
Mean value: 0.0930698812007904

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.676269104267065e-16
Max value: 0.9996463060379028
Mean value: 0.0930698812007904

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12992505729198456

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 32.92158889770508
Max value: 76.38313293457031
Mean value: 58.95838928222656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.959556579589844
Max value: -58.959556579589844
Mean value: -58.959556579589844
sam_encoder.pos_embed grad: 8.764154699747451e-07
sam_encoder.blocks.0.norm1.weight grad: 0.008695087395608425
sam_encoder.blocks.0.norm1.bias grad: 0.0016759823774918914
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00011523597640916705
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.481541559973266e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0015705777332186699
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00010065899550681934
sam_encoder.blocks.0.norm2.weight grad: 0.0016131708398461342
sam_encoder.blocks.0.norm2.bias grad: 0.005361041985452175
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.002806004835292697
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.000347975583281368
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0020316997542977333
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00190708227455616
sam_encoder.blocks.1.norm1.weight grad: 0.0005600052536465228
sam_encoder.blocks.1.norm1.bias grad: 0.0016905631637200713
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0013170314487069845
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0003555958974175155
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0011831058654934168
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0005404968396760523
sam_encoder.blocks.1.norm2.weight grad: -0.0014813406160101295
sam_encoder.blocks.1.norm2.bias grad: -0.0013973343884572387
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0016307806363329291
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00018968024232890457
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0008314683800563216
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.891531276982278e-05
sam_encoder.blocks.2.norm1.weight grad: -0.00048090165364556015
sam_encoder.blocks.2.norm1.bias grad: 0.0004907537950202823
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0005102066206745803
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00010557125642662868
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.1407537133200094e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00013019981270190328
sam_encoder.blocks.2.norm2.weight grad: 0.0030965018086135387
sam_encoder.blocks.2.norm2.bias grad: -0.0035535830538719893
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.001397707499563694
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0006790482439100742
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0009243512758985162
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00023915623023640364
sam_encoder.blocks.3.norm1.weight grad: 0.0006129126413725317
sam_encoder.blocks.3.norm1.bias grad: 0.00047095026820898056
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00013991541345603764
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00018305794219486415
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00046050752280279994
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.000623023952357471
sam_encoder.blocks.3.norm2.weight grad: -0.0012817622628062963
sam_encoder.blocks.3.norm2.bias grad: -0.0020787171088159084
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0014258300652727485
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0006431431393139064
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.001197601086460054
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0004232612845953554
sam_encoder.blocks.4.norm1.weight grad: 0.0004935128381475806
sam_encoder.blocks.4.norm1.bias grad: -0.0014458924997597933
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0005057188682258129
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.2608355619886424e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.000437119830166921
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00031273739296011627
sam_encoder.blocks.4.norm2.weight grad: 0.004326849710196257
sam_encoder.blocks.4.norm2.bias grad: 0.003813147312030196
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00203755684196949
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0007490557618439198
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0007884203223511577
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0002583403547760099
sam_encoder.blocks.5.norm1.weight grad: 0.002653572242707014
sam_encoder.blocks.5.norm1.bias grad: -0.0038290712982416153
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0026846956461668015
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0018799095414578915
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00013925349048804492
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00029006937984377146
sam_encoder.blocks.5.norm2.weight grad: 0.0017427706625312567
sam_encoder.blocks.5.norm2.bias grad: 0.0023262277245521545
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0005599035648629069
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0002815767365973443
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0003788587055169046
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.817323785275221e-05
sam_encoder.blocks.6.norm1.weight grad: 4.902854561805725e-05
sam_encoder.blocks.6.norm1.bias grad: -0.001255424926057458
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00030434117070399225
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0004709888016805053
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.7972415409749374e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.845947352005169e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0004480241914279759
sam_encoder.blocks.6.norm2.bias grad: 0.0006575024453923106
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00044277869164943695
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0001924490206874907
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.181151158874854e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.763368921587244e-05
sam_encoder.blocks.7.norm1.weight grad: 0.000809383753221482
sam_encoder.blocks.7.norm1.bias grad: 6.089625458116643e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00021610452677123249
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.584951274315245e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00044684819295071065
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00015765760326758027
sam_encoder.blocks.7.norm2.weight grad: -0.0003976878651883453
sam_encoder.blocks.7.norm2.bias grad: -0.0002118113188771531
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0003887905622832477
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.942091305158101e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00021578857558779418
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00033872597850859165
sam_encoder.blocks.8.norm1.weight grad: 0.0010374871781095862
sam_encoder.blocks.8.norm1.bias grad: -0.00025729782646521926
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0015862410655245185
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0007950402796268463
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0003626015386544168
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0001339075097348541
sam_encoder.blocks.8.norm2.weight grad: -0.0003279523807577789
sam_encoder.blocks.8.norm2.bias grad: 0.0004574460326693952
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00043662049574777484
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.5967368856072426e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00019903419888578355
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0001048397971317172
sam_encoder.blocks.9.norm1.weight grad: -0.000328902096953243
sam_encoder.blocks.9.norm1.bias grad: 0.00010325051698600873
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.000591046642512083
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0002783422532957047
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0003231786540709436
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00018915765394922346
sam_encoder.blocks.9.norm2.weight grad: -0.0017928467132151127
sam_encoder.blocks.9.norm2.bias grad: 0.00048984115710482
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0015212808502838016
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0006983195780776441
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0003965649229940027
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.8486796509241685e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0014372151345014572
sam_encoder.blocks.10.norm1.bias grad: -0.00018864338926505297
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.001285478239879012
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0004753480607178062
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.000559028412681073
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.000279944360954687
sam_encoder.blocks.10.norm2.weight grad: -0.0019718960393220186
sam_encoder.blocks.10.norm2.bias grad: 0.0004318576247896999
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0012357450323179364
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0005198953440412879
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.3358595323516056e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.066625115228817e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0027720078360289335
sam_encoder.blocks.11.norm1.bias grad: -0.0002226321230409667
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0008695704746060073
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.0002784630050882697
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0006627944530919194
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00026225519832223654
sam_encoder.blocks.11.norm2.weight grad: -0.0011782217770814896
sam_encoder.blocks.11.norm2.bias grad: 0.0004605935828294605
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.000886064488440752
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00016248888277914375
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.10260249231942e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.81325286172796e-06
sam_encoder.neck.conv1.trainable_scale grad: 0.00011521950364112854
sam_encoder.neck.conv1.trainable_shift grad: 0.0015987968072295189
sam_encoder.neck.conv2.trainable_scale grad: 0.00010683713480830193
sam_encoder.neck.conv2.trainable_shift grad: -0.0021606548689305782
mask_decoder.transformer.layers.0.norm1.weight grad: 0.019397811964154243
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00035243015736341476
mask_decoder.transformer.layers.0.norm2.weight grad: 1.323913812637329
mask_decoder.transformer.layers.0.norm2.bias grad: -0.006267085671424866
mask_decoder.transformer.layers.0.norm3.weight grad: 0.019093874841928482
mask_decoder.transformer.layers.0.norm3.bias grad: 0.004615327343344688
mask_decoder.transformer.layers.0.norm4.weight grad: -0.022006377577781677
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00202316977083683
mask_decoder.transformer.layers.1.norm1.weight grad: -0.00878983549773693
mask_decoder.transformer.layers.1.norm1.bias grad: 3.11585608869791e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0011862106621265411
mask_decoder.transformer.layers.1.norm2.bias grad: -0.003177439793944359
mask_decoder.transformer.layers.1.norm3.weight grad: -0.011572124436497688
mask_decoder.transformer.layers.1.norm3.bias grad: -0.009309232234954834
mask_decoder.transformer.layers.1.norm4.weight grad: 0.006555444095283747
mask_decoder.transformer.layers.1.norm4.bias grad: 0.036370649933815
mask_decoder.transformer.norm_final_attn.weight grad: -5.399622023105621e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0025989925488829613
Text_Embedding_Affine.0.weight grad: -5.695853566578535e-09
Text_Embedding_Affine.0.bias grad: -2.409215085208416e-07
Text_Embedding_Affine.2.weight grad: -5.954986193046352e-08
Text_Embedding_Affine.2.bias grad: -0.00639647152274847

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.569518929908867e-10
Max value: 0.9980502128601074
Mean value: 0.07406926900148392

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.569518929908867e-10
Max value: 0.9980502128601074
Mean value: 0.07406926900148392

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07548809051513672

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.564739227294922
Max value: -1.1920928244535389e-07
Mean value: -0.11649030447006226

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058793067932128906

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07548809051513672

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.82129669189453
Max value: 68.77931213378906
Mean value: 48.986454010009766

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.569518929908867e-10
Max value: 0.9980502128601074
Mean value: 0.07406926900148392

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.569518929908867e-10
Max value: 0.9980502128601074
Mean value: 0.07406926900148392

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.569518929908867e-10
Max value: 0.9980502128601074
Mean value: 0.07406926900148392

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.564739227294922
Max value: -1.1920928244535389e-07
Mean value: -0.11649030447006226

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.82129669189453
Max value: 68.77931213378906
Mean value: 48.986454010009766

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -48.98764419555664
Max value: -48.98764419555664
Mean value: -48.98764419555664
sam_encoder.pos_embed grad: -2.9691793201891414e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0058610825799405575
sam_encoder.blocks.0.norm1.bias grad: -0.002591900061815977
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0011113111395388842
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00011573712981771678
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0009105291101150215
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00021701361401937902
sam_encoder.blocks.0.norm2.weight grad: 0.003038901835680008
sam_encoder.blocks.0.norm2.bias grad: 0.006675931625068188
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0004645217559300363
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003747277660295367
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.0512923583737575e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.1149429054930806e-05
sam_encoder.blocks.1.norm1.weight grad: -0.0008999921265058219
sam_encoder.blocks.1.norm1.bias grad: -0.00010093474702443928
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00039992405800148845
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.294081398053095e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0002854038611985743
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00038694957038387656
sam_encoder.blocks.1.norm2.weight grad: 0.001469092327170074
sam_encoder.blocks.1.norm2.bias grad: 0.00014405357069335878
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00028329380438663065
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.992381243733689e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0014030062593519688
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.0002161333104595542
sam_encoder.blocks.2.norm1.weight grad: -0.0005242546321824193
sam_encoder.blocks.2.norm1.bias grad: -0.0007431478006765246
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00016816460993140936
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.9362566894851625e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00011282381456112489
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00037914945278316736
sam_encoder.blocks.2.norm2.weight grad: 0.0015568051021546125
sam_encoder.blocks.2.norm2.bias grad: -0.0004942037048749626
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0011264136992394924
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00025230698520317674
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0006406879401765764
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.139988494804129e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0007253617513924837
sam_encoder.blocks.3.norm1.bias grad: -0.0008653390104882419
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0008880309178493917
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00016375433187931776
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0006504739867523313
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00016942110960371792
sam_encoder.blocks.3.norm2.weight grad: 0.0021586124785244465
sam_encoder.blocks.3.norm2.bias grad: 0.0011817633640021086
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0014650595840066671
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0004125781706534326
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.00058313540648669
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0002357472840230912
sam_encoder.blocks.4.norm1.weight grad: 0.0008804245153442025
sam_encoder.blocks.4.norm1.bias grad: -0.000941735168453306
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005327502731233835
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002246019139420241
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00032389434636570513
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00035276514245197177
sam_encoder.blocks.4.norm2.weight grad: 0.0007419083267450333
sam_encoder.blocks.4.norm2.bias grad: -0.00039634230779483914
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00033722532680258155
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.4924665922299027e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0003032268723472953
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00015287537826225162
sam_encoder.blocks.5.norm1.weight grad: 0.0006727862055413425
sam_encoder.blocks.5.norm1.bias grad: -0.0007192420307546854
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0004889133851975203
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00028636655770242214
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.1714864740497433e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.67839841399109e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0012542932527139783
sam_encoder.blocks.5.norm2.bias grad: -0.00023057986982166767
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0005161559674888849
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00019272508507128805
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0002842081885319203
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.472409924957901e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00043460004962980747
sam_encoder.blocks.6.norm1.bias grad: 0.0003808654728345573
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0004444277728907764
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0001042773001245223
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00019435059220995754
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00011188836651854217
sam_encoder.blocks.6.norm2.weight grad: 4.8455851356266066e-05
sam_encoder.blocks.6.norm2.bias grad: -0.0001670343044679612
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.242632273118943e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.1169422577950172e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.412354847881943e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.910716830228921e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0001791703252820298
sam_encoder.blocks.7.norm1.bias grad: 5.58447209186852e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00011125078162876889
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00010947928240057081
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00020949785539414734
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00021818641107529402
sam_encoder.blocks.7.norm2.weight grad: -9.813829092308879e-05
sam_encoder.blocks.7.norm2.bias grad: 0.00015976707800291479
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0003327278536744416
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00011819868086604401
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00015808656462468207
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.995148189365864e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00029417284531518817
sam_encoder.blocks.8.norm1.bias grad: 0.00013241168926469982
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00017135967209469527
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.532699964940548e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.208526428963523e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0002457871160004288
sam_encoder.blocks.8.norm2.weight grad: 0.0003444833564572036
sam_encoder.blocks.8.norm2.bias grad: -8.026564319152385e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00023127844906412065
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00013225051225163043
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00023845524992793798
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0001249145861947909
sam_encoder.blocks.9.norm1.weight grad: 0.00013772165402770042
sam_encoder.blocks.9.norm1.bias grad: 4.7710542276035994e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00012627788237296045
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.072413528570905e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.952609692234546e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1739321053028107e-06
sam_encoder.blocks.9.norm2.weight grad: 0.0007025119848549366
sam_encoder.blocks.9.norm2.bias grad: 6.991407281020656e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0003147301322314888
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0002437972871121019
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.078779839910567e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.3905714846914634e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00026195644750259817
sam_encoder.blocks.10.norm1.bias grad: 1.4164155572871096e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00023432244779542089
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.87914390861988e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.98054432682693e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.1062652851687744e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0006130446563474834
sam_encoder.blocks.10.norm2.bias grad: 2.5181760065606795e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00020811197464354336
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.774279897101223e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.4543936130357906e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.1517880163155496e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00026719109155237675
sam_encoder.blocks.11.norm1.bias grad: 1.8960738088935614e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00015312363393604755
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.135078289546072e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.975512512028217e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.312191281816922e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0003626747929956764
sam_encoder.blocks.11.norm2.bias grad: -0.0003423002490308136
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.000304902670904994
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.779992716270499e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.39073415286839e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.424140494549647e-05
sam_encoder.neck.conv1.trainable_scale grad: 9.314464114140719e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.00039091409416869283
sam_encoder.neck.conv2.trainable_scale grad: 7.7846460044384e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0013497137697413564
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00197885581292212
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0006029398646205664
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3131462335586548
mask_decoder.transformer.layers.0.norm2.bias grad: -0.09724444150924683
mask_decoder.transformer.layers.0.norm3.weight grad: -0.005970165599137545
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0031336366664618254
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0016492534196004272
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0001895951572805643
mask_decoder.transformer.layers.1.norm1.weight grad: 0.004570715129375458
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00018408067990094423
mask_decoder.transformer.layers.1.norm2.weight grad: 0.005816264543682337
mask_decoder.transformer.layers.1.norm2.bias grad: 0.005378951318562031
mask_decoder.transformer.layers.1.norm3.weight grad: 0.001570701482705772
mask_decoder.transformer.layers.1.norm3.bias grad: 0.003724444657564163
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002437558490782976
mask_decoder.transformer.layers.1.norm4.bias grad: -0.004828810691833496
mask_decoder.transformer.norm_final_attn.weight grad: 0.00045451056212186813
mask_decoder.transformer.norm_final_attn.bias grad: 0.0006504647899419069
Text_Embedding_Affine.0.weight grad: -1.7857670897569733e-10
Text_Embedding_Affine.0.bias grad: -1.8684659153223038e-08
Text_Embedding_Affine.2.weight grad: 1.0230079006134929e-09
Text_Embedding_Affine.2.bias grad: -0.0032874178141355515

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.7721700650485846e-15
Max value: 0.9991334080696106
Mean value: 0.07136760652065277

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.7721700650485846e-15
Max value: 0.9991334080696106
Mean value: 0.07136760652065277

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08730125427246094

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.923541069030762
Max value: -1.1920928244535389e-07
Mean value: -0.12268700450658798

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05976104736328125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08730125427246094

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 40.72443771362305
Max value: 74.51195526123047
Mean value: 53.912227630615234

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.7721700650485846e-15
Max value: 0.9991334080696106
Mean value: 0.07136760652065277

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.7721700650485846e-15
Max value: 0.9991334080696106
Mean value: 0.07136760652065277

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.7721700650485846e-15
Max value: 0.9991334080696106
Mean value: 0.07136760652065277

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.923541069030762
Max value: -1.1920928244535389e-07
Mean value: -0.12268700450658798

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 40.72443771362305
Max value: 74.51195526123047
Mean value: 53.912227630615234

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.913291931152344
Max value: -53.913291931152344
Mean value: -53.913291931152344
sam_encoder.pos_embed grad: -2.8376216931746967e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0003622643125709146
sam_encoder.blocks.0.norm1.bias grad: -0.0025836441200226545
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00026789051480591297
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.397528341040015e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0004370184033177793
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.000311422161757946
sam_encoder.blocks.0.norm2.weight grad: -0.0018229380948469043
sam_encoder.blocks.0.norm2.bias grad: 0.0031566317193210125
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.001516328426077962
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0006945043569430709
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0014875562628731132
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0002631784009281546
sam_encoder.blocks.1.norm1.weight grad: -0.00044361589243635535
sam_encoder.blocks.1.norm1.bias grad: -8.04335213615559e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0002036940713878721
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00016663013957440853
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00023075260105542839
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.135668809292838e-05
sam_encoder.blocks.1.norm2.weight grad: -0.00010411402763566002
sam_encoder.blocks.1.norm2.bias grad: -0.00015190907288342714
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0004843452188652009
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.60963453608565e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00038314179982990026
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00016164887347258627
sam_encoder.blocks.2.norm1.weight grad: -0.00047622888814657927
sam_encoder.blocks.2.norm1.bias grad: -0.0002661219332367182
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00037137168692424893
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.588651740457863e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00035086224670521915
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00015688702114857733
sam_encoder.blocks.2.norm2.weight grad: 1.3672785826202016e-05
sam_encoder.blocks.2.norm2.bias grad: -0.00038595590740442276
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0003364047151990235
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.403104973491281e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 9.98894902295433e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2027565389871597e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0001522587117506191
sam_encoder.blocks.3.norm1.bias grad: -0.00016739450802560896
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 8.247791993198916e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1612877642619424e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.194727342925034e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00027936731930822134
sam_encoder.blocks.3.norm2.weight grad: 0.00024012690118979663
sam_encoder.blocks.3.norm2.bias grad: -0.0011202675523236394
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00010036314779426903
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.365780139574781e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0004385358770377934
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00010966331319650635
sam_encoder.blocks.4.norm1.weight grad: 0.001110893557779491
sam_encoder.blocks.4.norm1.bias grad: -0.0010109709110110998
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005101540009491146
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00020076942746527493
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0002519020636100322
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00022998817439656705
sam_encoder.blocks.4.norm2.weight grad: -0.0010984203545376658
sam_encoder.blocks.4.norm2.bias grad: -0.0004639287944883108
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.000664928404148668
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00023971230257302523
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00018633296713232994
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.71024967636913e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0015044473111629486
sam_encoder.blocks.5.norm1.bias grad: -0.0002946321910712868
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0011680154129862785
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0004503923701122403
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00029124278808012605
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0001857107854448259
sam_encoder.blocks.5.norm2.weight grad: -0.0001869264815468341
sam_encoder.blocks.5.norm2.bias grad: 0.00016473594587296247
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00019028919632546604
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.149923890712671e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00016460035112686455
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.665516123874113e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0003167700197082013
sam_encoder.blocks.6.norm1.bias grad: 9.153805149253458e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0002963084843941033
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0002471314219292253
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.537873246590607e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.6092631742358208e-05
sam_encoder.blocks.6.norm2.weight grad: -0.00011215705308131874
sam_encoder.blocks.6.norm2.bias grad: 0.00010849919635802507
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.483171404805034e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.6640135881025344e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0001975179766304791
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.69803048367612e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00012053438695147634
sam_encoder.blocks.7.norm1.bias grad: -2.0825207684538327e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00011164361785631627
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3466443306242581e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.15012356522493e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.106077514938079e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0006840552086941898
sam_encoder.blocks.7.norm2.bias grad: -3.330989784444682e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0005079562542960048
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002791500883176923
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.8047794583253562e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.4119453883031383e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0008038096129894257
sam_encoder.blocks.8.norm1.bias grad: 2.13924067793414e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0006851234938949347
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00037730741314589977
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00021529183140955865
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0002636371646076441
sam_encoder.blocks.8.norm2.weight grad: 0.0001420136250089854
sam_encoder.blocks.8.norm2.bias grad: -5.8405894378665835e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.8923599782283418e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.377408135449514e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0001934894680744037
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.376967161893845e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0004498363414313644
sam_encoder.blocks.9.norm1.bias grad: -2.4232107534771785e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00032130995532497764
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.304714431986213e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.761104330304079e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00012397670070640743
sam_encoder.blocks.9.norm2.weight grad: 0.00023885947302915156
sam_encoder.blocks.9.norm2.bias grad: 0.0002807588898576796
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8535280105425045e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.998459088616073e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00022289917978923768
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.755419937893748e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00010614862549118698
sam_encoder.blocks.10.norm1.bias grad: 4.3997741158818826e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.745146336266771e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.1293129975674674e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.324941750790458e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.218952820636332e-05
sam_encoder.blocks.10.norm2.weight grad: 5.906766091356985e-05
sam_encoder.blocks.10.norm2.bias grad: 0.00027686014072969556
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00013976453919894993
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.440789547923487e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00010769129585241899
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.1960417484478967e-07
sam_encoder.blocks.11.norm1.weight grad: 0.0003638690977822989
sam_encoder.blocks.11.norm1.bias grad: 0.0001946084521478042
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00013885307998862118
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.519157174509019e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3819269952364266e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.746014840544376e-07
sam_encoder.blocks.11.norm2.weight grad: 0.000536761712282896
sam_encoder.blocks.11.norm2.bias grad: 1.2835369489039294e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00018618888861965388
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.438004053663462e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00026638380950316787
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.654206612845883e-05
sam_encoder.neck.conv1.trainable_scale grad: 4.448043182492256e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.00044219091068953276
sam_encoder.neck.conv2.trainable_scale grad: 2.404092811048031e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.005328057333827019
mask_decoder.transformer.layers.0.norm1.weight grad: 0.008830178529024124
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00018544355407357216
mask_decoder.transformer.layers.0.norm2.weight grad: 0.03584262728691101
mask_decoder.transformer.layers.0.norm2.bias grad: -0.11146716773509979
mask_decoder.transformer.layers.0.norm3.weight grad: 0.007513986900448799
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0023018838837742805
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0023033262696117163
mask_decoder.transformer.layers.0.norm4.bias grad: -0.00011210772208869457
mask_decoder.transformer.layers.1.norm1.weight grad: 0.000277498533250764
mask_decoder.transformer.layers.1.norm1.bias grad: -1.9130486180074513e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0008419823134317994
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0004304454196244478
mask_decoder.transformer.layers.1.norm3.weight grad: 0.000339681253535673
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0007988946163095534
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0009428043849766254
mask_decoder.transformer.layers.1.norm4.bias grad: -0.001309832208789885
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003122608468402177
mask_decoder.transformer.norm_final_attn.bias grad: -0.0003505814529489726
Text_Embedding_Affine.0.weight grad: 1.6305217176437736e-09
Text_Embedding_Affine.0.bias grad: 5.663605406880379e-08
Text_Embedding_Affine.2.weight grad: 8.126531447771868e-09
Text_Embedding_Affine.2.bias grad: -0.0029299058951437473
Epoch 21 finished with average loss: -53.9535
Epoch 22/39
----------
Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s, loss=-50.7]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-50.7]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-55.9]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-55.9]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-53.8]Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.14it/s, loss=-53.8]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.592381750023193e-11
Max value: 0.9987506866455078
Mean value: 0.08496005833148956

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.592381750023193e-11
Max value: 0.9987506866455078
Mean value: 0.08496005833148956

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08921003341674805

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.269617080688477
Max value: -1.1920928244535389e-07
Mean value: -0.13543903827667236

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07136106491088867

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08921003341674805

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.98546600341797
Max value: 66.6349105834961
Mean value: 50.706817626953125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.592381750023193e-11
Max value: 0.9987506866455078
Mean value: 0.08496005833148956

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.592381750023193e-11
Max value: 0.9987506866455078
Mean value: 0.08496005833148956

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.592381750023193e-11
Max value: 0.9987506866455078
Mean value: 0.08496005833148956

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.269617080688477
Max value: -1.1920928244535389e-07
Mean value: -0.13543903827667236

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.98546600341797
Max value: 66.6349105834961
Mean value: 50.706817626953125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.70805740356445
Max value: -50.70805740356445
Mean value: -50.70805740356445
sam_encoder.pos_embed grad: -1.2115822300984291e-06
sam_encoder.blocks.0.norm1.weight grad: -0.008739138953387737
sam_encoder.blocks.0.norm1.bias grad: -0.0025486527010798454
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0002989857457578182
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.64671317988541e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00015938578872010112
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.209868297446519e-05
sam_encoder.blocks.0.norm2.weight grad: 0.001178419217467308
sam_encoder.blocks.0.norm2.bias grad: 0.004959565587341785
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0011788809206336737
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0010788709623739123
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.003028084523975849
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0014206727501004934
sam_encoder.blocks.1.norm1.weight grad: -0.0010708635672926903
sam_encoder.blocks.1.norm1.bias grad: 0.00024911219952628016
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0006811335915699601
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.966135409427807e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0001863173965830356
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 7.427728269249201e-05
sam_encoder.blocks.1.norm2.weight grad: 0.003973435144871473
sam_encoder.blocks.1.norm2.bias grad: 0.0005743296351283789
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0015994826098904014
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0004468837287276983
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.709845471661538e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00022287129831966013
sam_encoder.blocks.2.norm1.weight grad: 0.000600286468397826
sam_encoder.blocks.2.norm1.bias grad: -0.0011841979576274753
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0004271905345376581
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.0685430576559156e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00021186551020946354
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.45596519461833e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0006218302296474576
sam_encoder.blocks.2.norm2.bias grad: -0.00011553396325325593
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0005375139880925417
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.4464438297400193e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0007999606314115226
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.507502282853238e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0020293479319661856
sam_encoder.blocks.3.norm1.bias grad: -0.0009187174728140235
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0005528422771021724
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00014034246851224452
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0004238335823174566
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00015098332369234413
sam_encoder.blocks.3.norm2.weight grad: 0.00023435952607542276
sam_encoder.blocks.3.norm2.bias grad: -0.0004068941925652325
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0002588772913441062
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.7437660871073604e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.000753826170694083
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0001245499006472528
sam_encoder.blocks.4.norm1.weight grad: 0.0036269803531467915
sam_encoder.blocks.4.norm1.bias grad: -0.0015711610903963447
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.002042012754827738
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005894628120586276
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0009342044941149652
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0008277933811768889
sam_encoder.blocks.4.norm2.weight grad: -0.005091904662549496
sam_encoder.blocks.4.norm2.bias grad: -0.003125173505395651
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0031108702532947063
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0012415111996233463
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0007187243900261819
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00024688633857294917
sam_encoder.blocks.5.norm1.weight grad: 0.0022174117621034384
sam_encoder.blocks.5.norm1.bias grad: -0.0014092348283156753
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0009873032104223967
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.5216801077476703e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00029929375159554183
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00032292804098688066
sam_encoder.blocks.5.norm2.weight grad: -0.0016534611349925399
sam_encoder.blocks.5.norm2.bias grad: -0.002197651192545891
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00033129635266959667
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.516243982128799e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00036590913077816367
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.6388424632605165e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0008003171533346176
sam_encoder.blocks.6.norm1.bias grad: 0.0009507467038929462
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0005878611700609326
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00021807814482599497
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0003037960850633681
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00013635260984301567
sam_encoder.blocks.6.norm2.weight grad: -0.0024804468266665936
sam_encoder.blocks.6.norm2.bias grad: -0.0006649158895015717
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.001852315734140575
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0007513085147365928
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0001221530546899885
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00019207647710572928
sam_encoder.blocks.7.norm1.weight grad: 0.0018482371233403683
sam_encoder.blocks.7.norm1.bias grad: -0.00015253163292072713
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0011969693005084991
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0005755560705438256
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0005870606983080506
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0003342588897794485
sam_encoder.blocks.7.norm2.weight grad: -8.158108539646491e-05
sam_encoder.blocks.7.norm2.bias grad: 0.0002291530545335263
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00029734219424426556
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.8445589123293757e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002468316233716905
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.0002513252547942102
sam_encoder.blocks.8.norm1.weight grad: 0.000842602108605206
sam_encoder.blocks.8.norm1.bias grad: -0.0004960280493833125
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0006999619654379785
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00023573811631649733
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0005261660553514957
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0004365775384940207
sam_encoder.blocks.8.norm2.weight grad: 0.0002056869416264817
sam_encoder.blocks.8.norm2.bias grad: -0.0001444740337319672
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00030896509997546673
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0001138250736403279
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.087295620702207e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.312968904851004e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0004217464884277433
sam_encoder.blocks.9.norm1.bias grad: -4.808312041859608e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0003610265557654202
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.0001944918039953336
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0001898393384180963
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.00017315521836280823
sam_encoder.blocks.9.norm2.weight grad: 0.0008803123491816223
sam_encoder.blocks.9.norm2.bias grad: 0.000274092482868582
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.000737043097615242
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0003717878716997802
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0003075044951401651
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.6419780877185985e-05
sam_encoder.blocks.10.norm1.weight grad: 0.001254045870155096
sam_encoder.blocks.10.norm1.bias grad: 8.38863052194938e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0007177444058470428
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0002875588834285736
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.0003461579908616841
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.000180058108526282
sam_encoder.blocks.10.norm2.weight grad: 0.0018365667201578617
sam_encoder.blocks.10.norm2.bias grad: 0.0005078248213976622
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0008577571134082973
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0005007588770240545
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0002874722413253039
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.760619155305903e-06
sam_encoder.blocks.11.norm1.weight grad: 0.0019953041337430477
sam_encoder.blocks.11.norm1.bias grad: 9.516642603557557e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0003965711803175509
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.088438850478269e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0002541047288104892
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.218293906887993e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0024490226060152054
sam_encoder.blocks.11.norm2.bias grad: 0.0003382331342436373
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0010211672633886337
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00038925802800804377
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0003177605103701353
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00010387857037130743
sam_encoder.neck.conv1.trainable_scale grad: 5.5833952501416206e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.00010060961358249187
sam_encoder.neck.conv2.trainable_scale grad: -8.221156895160675e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.00723952567204833
mask_decoder.transformer.layers.0.norm1.weight grad: 0.003305629128590226
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00010877009481191635
mask_decoder.transformer.layers.0.norm2.weight grad: -0.4636988043785095
mask_decoder.transformer.layers.0.norm2.bias grad: -0.1756550371646881
mask_decoder.transformer.layers.0.norm3.weight grad: -0.013834809884428978
mask_decoder.transformer.layers.0.norm3.bias grad: -0.005253172945231199
mask_decoder.transformer.layers.0.norm4.weight grad: 0.010078034363687038
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0014052253682166338
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0009195873863063753
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0007754777325317264
mask_decoder.transformer.layers.1.norm2.weight grad: -0.01103911641985178
mask_decoder.transformer.layers.1.norm2.bias grad: -0.006486506201326847
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004639321938157082
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0022357511334121227
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0008598840795457363
mask_decoder.transformer.layers.1.norm4.bias grad: -0.027757860720157623
mask_decoder.transformer.norm_final_attn.weight grad: -0.00023628526832908392
mask_decoder.transformer.norm_final_attn.bias grad: 0.001422514789737761
Text_Embedding_Affine.0.weight grad: 6.315818978919197e-10
Text_Embedding_Affine.0.bias grad: 7.712515071034431e-09
Text_Embedding_Affine.2.weight grad: 7.971715731969198e-09
Text_Embedding_Affine.2.bias grad: 4.4286251068115234e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.337066371126966e-11
Max value: 0.9983136653900146
Mean value: 0.09325458109378815

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.337066371126966e-11
Max value: 0.9983136653900146
Mean value: 0.09325458109378815

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09013652801513672

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.21063232421875
Max value: -1.1920928244535389e-07
Mean value: -0.11597339808940887

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08656883239746094

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09013652801513672

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.602867126464844
Max value: 79.38520050048828
Mean value: 61.028053283691406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.337066371126966e-11
Max value: 0.9983136653900146
Mean value: 0.09325458109378815

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.337066371126966e-11
Max value: 0.9983136653900146
Mean value: 0.09325458109378815

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.337066371126966e-11
Max value: 0.9983136653900146
Mean value: 0.09325458109378815

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.21063232421875
Max value: -1.1920928244535389e-07
Mean value: -0.11597339808940887

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.602867126464844
Max value: 79.38520050048828
Mean value: 61.028053283691406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.029266357421875
Max value: -61.029266357421875
Mean value: -61.029266357421875
sam_encoder.pos_embed grad: -4.1377728621228016e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0033917557448148727
sam_encoder.blocks.0.norm1.bias grad: -0.0001394675055053085
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.017794733750634e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.686861914000474e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.622139800223522e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0003065146738663316
sam_encoder.blocks.0.norm2.weight grad: 0.0016862391494214535
sam_encoder.blocks.0.norm2.bias grad: 0.004684707149863243
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0008830061997286975
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0005629882216453552
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0014501705300062895
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0004901690408587456
sam_encoder.blocks.1.norm1.weight grad: -0.0005310314008966088
sam_encoder.blocks.1.norm1.bias grad: 0.0008711807895451784
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.8627378166420385e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00011793093290179968
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00021222633949946612
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.54129910597112e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0021566792856901884
sam_encoder.blocks.1.norm2.bias grad: -0.0006978122401051223
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0005534386727958918
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001305425976170227
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0004522046074271202
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.094239067053422e-05
sam_encoder.blocks.2.norm1.weight grad: 0.000315257057081908
sam_encoder.blocks.2.norm1.bias grad: -0.0009443880990147591
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.9879214707762003e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.6525885914452374e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0004572242614813149
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0004478401388041675
sam_encoder.blocks.2.norm2.weight grad: 0.0011662505567073822
sam_encoder.blocks.2.norm2.bias grad: -0.0008214018307626247
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0007044567028060555
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.244916999596171e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0002077437238767743
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00012796581722795963
sam_encoder.blocks.3.norm1.weight grad: 0.0006895841797813773
sam_encoder.blocks.3.norm1.bias grad: -0.001379175460897386
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00023937008518259972
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.335572753509041e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.306145900860429e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.038320861989632e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0006639058119617403
sam_encoder.blocks.3.norm2.bias grad: -0.0006318043451756239
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0006044881884008646
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0003001678560394794
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0005673996638506651
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00013629221939481795
sam_encoder.blocks.4.norm1.weight grad: 0.0009298153454437852
sam_encoder.blocks.4.norm1.bias grad: -0.0012918275315314531
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0007500519277527928
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.000261244218563661
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.000518514949362725
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003793566720560193
sam_encoder.blocks.4.norm2.weight grad: -0.0031035030260682106
sam_encoder.blocks.4.norm2.bias grad: -0.002276969375088811
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0018543917685747147
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0006655206670984626
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.620707037858665e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.757101800758392e-05
sam_encoder.blocks.5.norm1.weight grad: 0.00047359796008095145
sam_encoder.blocks.5.norm1.bias grad: -0.0007922638906165957
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00032791460398584604
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.8754467570688576e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0003586627426557243
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00020738050807267427
sam_encoder.blocks.5.norm2.weight grad: -0.001363303861580789
sam_encoder.blocks.5.norm2.bias grad: -0.000832976889796555
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0004027942195534706
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00012733289622701705
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00017856108024716377
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.211332659702748e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0002862911787815392
sam_encoder.blocks.6.norm1.bias grad: 0.00023873783356975764
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.7963959584885743e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.444170579314232e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.3300442232284695e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.681738886982203e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0005685726646333933
sam_encoder.blocks.6.norm2.bias grad: -0.0004288257041480392
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0002342561783734709
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.564781794324517e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.000381366815418005
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00012398434046190232
sam_encoder.blocks.7.norm1.weight grad: 0.0005184722831472754
sam_encoder.blocks.7.norm1.bias grad: 0.00010570441372692585
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0002741793286986649
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0003386370954103768
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00011216149141546339
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0645089787431061e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0003367991594132036
sam_encoder.blocks.7.norm2.bias grad: 0.00013010011753067374
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00023354520089924335
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0001356925640720874
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.776663990924135e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.586415889207274e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00024547154316678643
sam_encoder.blocks.8.norm1.bias grad: 0.00010360567830502987
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00019354325195308775
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.6857578322724294e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.94719671830535e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.790344483917579e-05
sam_encoder.blocks.8.norm2.weight grad: -0.00035793008282780647
sam_encoder.blocks.8.norm2.bias grad: -0.00017829120042733848
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00019931071437895298
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.244324660860002e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.595838880864903e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.622695425699931e-06
sam_encoder.blocks.9.norm1.weight grad: -9.542746556689963e-05
sam_encoder.blocks.9.norm1.bias grad: -3.545422441675328e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.875016985461116e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.99858569027856e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.826378401252441e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00014283017662819475
sam_encoder.blocks.9.norm2.weight grad: 0.0002367163251619786
sam_encoder.blocks.9.norm2.bias grad: -6.289828161243349e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00017011509044095874
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0001031526189763099
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00015766482101753354
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.8966107493033633e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0005045335274189711
sam_encoder.blocks.10.norm1.bias grad: 0.00018171004194300622
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00029417668702080846
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00014088615716900676
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00013449133257381618
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.824732215842232e-05
sam_encoder.blocks.10.norm2.weight grad: 0.00018114666454494
sam_encoder.blocks.10.norm2.bias grad: -8.345942478626966e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00012727730791084468
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.996219159802422e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.3469211959745735e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.4606391889392398e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0008613871177658439
sam_encoder.blocks.11.norm1.bias grad: 0.00026654190151020885
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.052446355577558e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.5000193242449313e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00021106016356498003
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.3118321880465373e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0005354915047064424
sam_encoder.blocks.11.norm2.bias grad: -0.00010668527102097869
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00026819214690476656
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00011952433123951778
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.732545494334772e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.810953553009313e-06
sam_encoder.neck.conv1.trainable_scale grad: 4.9587804824113846e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.001337202382273972
sam_encoder.neck.conv2.trainable_scale grad: -2.6483554393053055e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.002722606062889099
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0021022509317845106
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00012470223009586334
mask_decoder.transformer.layers.0.norm2.weight grad: -0.4945308268070221
mask_decoder.transformer.layers.0.norm2.bias grad: -0.10733535885810852
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0006897157290950418
mask_decoder.transformer.layers.0.norm3.bias grad: -0.005150668788701296
mask_decoder.transformer.layers.0.norm4.weight grad: 0.013909636065363884
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0005617388524115086
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0026990659534931183
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0005901891272515059
mask_decoder.transformer.layers.1.norm2.weight grad: -0.008569449186325073
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00027708522975444794
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004624233581125736
mask_decoder.transformer.layers.1.norm3.bias grad: 0.002053662436082959
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00719255767762661
mask_decoder.transformer.layers.1.norm4.bias grad: -0.02013172209262848
mask_decoder.transformer.norm_final_attn.weight grad: -0.0001758099824655801
mask_decoder.transformer.norm_final_attn.bias grad: 0.0012162295170128345
Text_Embedding_Affine.0.weight grad: 2.2096111607083913e-09
Text_Embedding_Affine.0.bias grad: 5.844049155712128e-08
Text_Embedding_Affine.2.weight grad: 7.985109240493671e-10
Text_Embedding_Affine.2.bias grad: -0.0018512632232159376

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0843664712346728e-18
Max value: 0.9980461597442627
Mean value: 0.06327317655086517

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0843664712346728e-18
Max value: 0.9980461597442627
Mean value: 0.06327317655086517

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05980873107910156

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1114128828048706

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05455780029296875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05980873107910156

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 43.566768646240234
Max value: 56.030372619628906
Mean value: 49.619564056396484

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0843664712346728e-18
Max value: 0.9980461597442627
Mean value: 0.06327317655086517

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0843664712346728e-18
Max value: 0.9980461597442627
Mean value: 0.06327317655086517

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0843664712346728e-18
Max value: 0.9980461597442627
Mean value: 0.06327317655086517

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1114128828048706

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 43.566768646240234
Max value: 56.030372619628906
Mean value: 49.619564056396484

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.62046813964844
Max value: -49.62046813964844
Mean value: -49.62046813964844
sam_encoder.pos_embed grad: 4.4822525069321273e-07
sam_encoder.blocks.0.norm1.weight grad: 0.008836022578179836
sam_encoder.blocks.0.norm1.bias grad: 0.0014131544157862663
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.000590689480304718
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.8596677768509835e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00016297842375934124
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00011491231271065772
sam_encoder.blocks.0.norm2.weight grad: 0.0008965671295300126
sam_encoder.blocks.0.norm2.bias grad: -0.00030048852204345167
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0004660113190766424
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003317669907119125
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0003056103305425495
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006404831074178219
sam_encoder.blocks.1.norm1.weight grad: 0.0012557851150631905
sam_encoder.blocks.1.norm1.bias grad: 0.0015791512560099363
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00015784872812218964
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00011904969869647175
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00037514971336349845
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00016198650700971484
sam_encoder.blocks.1.norm2.weight grad: -0.000257568754022941
sam_encoder.blocks.1.norm2.bias grad: -0.00025703065330162644
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0005351473810151219
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.9343773348955438e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0006095386925153434
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.495133336808067e-06
sam_encoder.blocks.2.norm1.weight grad: -0.001356753520667553
sam_encoder.blocks.2.norm1.bias grad: 0.00021761757670901716
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008832182502374053
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0002305817761225626
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0004773907130584121
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00028370399377308786
sam_encoder.blocks.2.norm2.weight grad: -0.00012939920998178422
sam_encoder.blocks.2.norm2.bias grad: -0.0011928151361644268
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00015251347213052213
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.249335274333134e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.000336996978148818
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.26559994998388e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0004903884837403893
sam_encoder.blocks.3.norm1.bias grad: 0.0002977857075165957
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.5173844985838514e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0001042338481056504
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.761901512509212e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.780318264849484e-05
sam_encoder.blocks.3.norm2.weight grad: 6.363067768688779e-06
sam_encoder.blocks.3.norm2.bias grad: -0.0002146733459085226
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0003818024415522814
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.147102537099272e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0005065682926215231
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0002001999964704737
sam_encoder.blocks.4.norm1.weight grad: 0.0006972700357437134
sam_encoder.blocks.4.norm1.bias grad: -0.0008713718270882964
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00016437002341262996
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.6646873923018575e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0003219093196094036
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00029662656015716493
sam_encoder.blocks.4.norm2.weight grad: 0.001032375730574131
sam_encoder.blocks.4.norm2.bias grad: 0.002094126073643565
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.000430719752330333
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00017238332657143474
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0002521171991247684
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.139812805689871e-05
sam_encoder.blocks.5.norm1.weight grad: 0.001939624547958374
sam_encoder.blocks.5.norm1.bias grad: -0.0017429832369089127
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0019392520189285278
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0010569647420197725
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.5389980035251938e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00011443448602221906
sam_encoder.blocks.5.norm2.weight grad: 0.0010470307897776365
sam_encoder.blocks.5.norm2.bias grad: 0.001045636017806828
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0001879100309452042
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 7.258236291818321e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00012365785369183868
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.59563491656445e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00024764385307207704
sam_encoder.blocks.6.norm1.bias grad: -0.0005245966603979468
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00039422459667548537
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003135858860332519
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0196585208177567e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.7310594557784498e-05
sam_encoder.blocks.6.norm2.weight grad: 0.000202770228497684
sam_encoder.blocks.6.norm2.bias grad: 9.719550143927336e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.6772604542202316e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.713249265681952e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -6.116490112617612e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.765713285654783e-05
sam_encoder.blocks.7.norm1.weight grad: -7.229848415590823e-05
sam_encoder.blocks.7.norm1.bias grad: 0.000148256920510903
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00016587867867201567
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.622156070079654e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00012766371946781874
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.466021891857963e-06
sam_encoder.blocks.7.norm2.weight grad: -0.0001690824719844386
sam_encoder.blocks.7.norm2.bias grad: -0.0003013026434928179
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0003494195989333093
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00015778630040585995
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.250168659491464e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00011174169776495546
sam_encoder.blocks.8.norm1.weight grad: 0.0008441614918410778
sam_encoder.blocks.8.norm1.bias grad: -0.00019117843476124108
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00112440949305892
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0005940005066804588
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.7438705981476232e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.471850949514192e-06
sam_encoder.blocks.8.norm2.weight grad: -0.000204097741516307
sam_encoder.blocks.8.norm2.bias grad: 0.0001837107411120087
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00031541375210508704
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00011150418868055567
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.255824463441968e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.291489312890917e-05
sam_encoder.blocks.9.norm1.weight grad: -5.41378503839951e-05
sam_encoder.blocks.9.norm1.bias grad: 3.837534222839167e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.584464714862406e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.166938692331314e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.84407015494071e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 8.355936006410047e-05
sam_encoder.blocks.9.norm2.weight grad: -0.000784147996455431
sam_encoder.blocks.9.norm2.bias grad: 4.5352044253377244e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0006985565414652228
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0003653992898762226
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00016965382383204997
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.4716002624481916e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00021923943131696433
sam_encoder.blocks.10.norm1.bias grad: -9.01848470675759e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00022442181943915784
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0001129483207478188
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00012948733638040721
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.231091149151325e-05
sam_encoder.blocks.10.norm2.weight grad: -0.000939232180826366
sam_encoder.blocks.10.norm2.bias grad: 5.8053876273334026e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0005582027370110154
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0003272437897976488
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00013294407108332962
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.4849152143578976e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0007947055855765939
sam_encoder.blocks.11.norm1.bias grad: 3.8941238017287105e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.596332918386906e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.78069295140449e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.307125244755298e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.7602513000601903e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0008850310696288943
sam_encoder.blocks.11.norm2.bias grad: 4.292536686989479e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0003884425386786461
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00013642261910717934
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.446887709898874e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.2763665987877175e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.789551556110382e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0008426548447459936
sam_encoder.neck.conv2.trainable_scale grad: 4.3502077460289e-05
sam_encoder.neck.conv2.trainable_shift grad: 6.513003609143198e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0008477814262732863
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00014692358672618866
mask_decoder.transformer.layers.0.norm2.weight grad: 0.4843672215938568
mask_decoder.transformer.layers.0.norm2.bias grad: -0.021182633936405182
mask_decoder.transformer.layers.0.norm3.weight grad: 0.008464434184134007
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0010984363034367561
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0056733181700110435
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0007397984154522419
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0017148938495665789
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00029883894603699446
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0019277608953416348
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0007048211991786957
mask_decoder.transformer.layers.1.norm3.weight grad: -0.002434677444398403
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0021847274620085955
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0004580917302519083
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00908501073718071
mask_decoder.transformer.norm_final_attn.weight grad: -7.447007374139503e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0006461315788328648
Text_Embedding_Affine.0.weight grad: -1.5033444489276349e-09
Text_Embedding_Affine.0.bias grad: -2.991873770952225e-08
Text_Embedding_Affine.2.weight grad: -1.2698448514925076e-08
Text_Embedding_Affine.2.bias grad: -0.0005023113917559385
Epoch 22 finished with average loss: -53.7859
Epoch 23/39
----------
Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/3 [00:01<?, ?it/s, loss=-59.2]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.03s/it, loss=-59.2]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.03s/it, loss=-56.5]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.53it/s, loss=-56.5]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.53it/s, loss=-57.2]Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.14it/s, loss=-57.2]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.582223004958823e-17
Max value: 0.9985184073448181
Mean value: 0.09096471220254898

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.582223004958823e-17
Max value: 0.9985184073448181
Mean value: 0.09096471220254898

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08598709106445312

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12474754452705383

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08241605758666992

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08598709106445312

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.58987808227539
Max value: 86.75114440917969
Mean value: 59.218284606933594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.582223004958823e-17
Max value: 0.9985184073448181
Mean value: 0.09096471220254898

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.582223004958823e-17
Max value: 0.9985184073448181
Mean value: 0.09096471220254898

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.582223004958823e-17
Max value: 0.9985184073448181
Mean value: 0.09096471220254898

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12474754452705383

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.58987808227539
Max value: 86.75114440917969
Mean value: 59.218284606933594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.219478607177734
Max value: -59.219478607177734
Mean value: -59.219478607177734
sam_encoder.pos_embed grad: -5.986357791698538e-07
sam_encoder.blocks.0.norm1.weight grad: 0.00553702749311924
sam_encoder.blocks.0.norm1.bias grad: -0.0024124891497194767
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0008084716973826289
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.9018410209100693e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00047388707753270864
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0004666165914386511
sam_encoder.blocks.0.norm2.weight grad: 0.00018682517111301422
sam_encoder.blocks.0.norm2.bias grad: 0.001609912607818842
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.80023799254559e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00017187296180054545
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0014990707859396935
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00033709773560985923
sam_encoder.blocks.1.norm1.weight grad: -0.00021657513570971787
sam_encoder.blocks.1.norm1.bias grad: 0.0007910248241387308
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0004687764449045062
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.021075675264001e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0003745162102859467
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00022744158923160285
sam_encoder.blocks.1.norm2.weight grad: 3.1184201361611485e-05
sam_encoder.blocks.1.norm2.bias grad: 0.0006569208926521242
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00042999599827453494
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.257046258426271e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0007205590954981744
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00017959442629944533
sam_encoder.blocks.2.norm1.weight grad: -0.00012996932491660118
sam_encoder.blocks.2.norm1.bias grad: -0.0010180913377553225
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00015496363630518317
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.579549674119335e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 8.466390136163682e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00019347293709870428
sam_encoder.blocks.2.norm2.weight grad: -0.00013090399443171918
sam_encoder.blocks.2.norm2.bias grad: -0.00042141310404986143
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0001545075501780957
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.0365125490352511e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0005641508614644408
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00011161431757500395
sam_encoder.blocks.3.norm1.weight grad: -0.0003311198379378766
sam_encoder.blocks.3.norm1.bias grad: -0.00021064793691039085
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0005189543589949608
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 9.867318294709548e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0003351770283188671
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.674004832049832e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0004459176561795175
sam_encoder.blocks.3.norm2.bias grad: 0.0016292169457301497
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00045586429769173265
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00013650373148266226
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.00028989295242354274
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00010630560427671298
sam_encoder.blocks.4.norm1.weight grad: 0.001181948697194457
sam_encoder.blocks.4.norm1.bias grad: -0.00038738976581953466
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0004030778945889324
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 5.558683187700808e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0002720675547607243
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.998309542424977e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0009954827837646008
sam_encoder.blocks.4.norm2.bias grad: 2.031346593867056e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.000556302024051547
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00015081680612638593
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.022166492883116e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.4376065236283466e-05
sam_encoder.blocks.5.norm1.weight grad: 0.001316118985414505
sam_encoder.blocks.5.norm1.bias grad: 0.00034871039679273963
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0010813609696924686
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0004148186999373138
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0005081381532363594
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00013086669787298888
sam_encoder.blocks.5.norm2.weight grad: -0.0010059529449790716
sam_encoder.blocks.5.norm2.bias grad: -0.00046089099487289786
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0006908479845151305
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00019871546828653663
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00017239281442016363
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.735113932634704e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0005065258010290563
sam_encoder.blocks.6.norm1.bias grad: 0.0004874104051850736
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0005064088618382812
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00025677887606434524
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00022092138533480465
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.0001852543791756034
sam_encoder.blocks.6.norm2.weight grad: 0.00037122273351997137
sam_encoder.blocks.6.norm2.bias grad: 0.0003061866736970842
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00038884460809640586
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00019022180640604347
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002328431000933051
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.053018634906039e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0007699255365878344
sam_encoder.blocks.7.norm1.bias grad: 0.00010689297050703317
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0006012681405991316
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00027466844767332077
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00034727936144918203
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0002352587616769597
sam_encoder.blocks.7.norm2.weight grad: 0.00018615151930134743
sam_encoder.blocks.7.norm2.bias grad: 0.000324314838508144
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00016240874538198113
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.7639613108476624e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00020089943427592516
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00018510360678192228
sam_encoder.blocks.8.norm1.weight grad: 0.0006419115234166384
sam_encoder.blocks.8.norm1.bias grad: 3.9844388084020466e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00038553879130631685
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0001928150886669755
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00021858762193005532
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.040833927225322e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0006176031311042607
sam_encoder.blocks.8.norm2.bias grad: -2.135910790457274e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0004507307312451303
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00019977362535428256
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0002153119130525738
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.559911864518654e-06
sam_encoder.blocks.9.norm1.weight grad: 0.0001632316707400605
sam_encoder.blocks.9.norm1.bias grad: 0.0002601073938421905
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.118628466036171e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00015178113244473934
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.0001158361992565915
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 8.278261520899832e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0012998839374631643
sam_encoder.blocks.9.norm2.bias grad: 0.00028455298161134124
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00097951153293252
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0005028096493333578
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00028911425033584237
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.958246816182509e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00015091971727088094
sam_encoder.blocks.10.norm1.bias grad: 0.00013496070459950715
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00016257516108453274
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00011052269110223278
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00010368655784986913
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.166212839772925e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0016545479884371161
sam_encoder.blocks.10.norm2.bias grad: 0.00029703095788136125
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0007907852414064109
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.0003856231924146414
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0001394410355715081
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.5448011001572013e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0015477007254958153
sam_encoder.blocks.11.norm1.bias grad: -4.0039943996816874e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00032600417034700513
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00011827262642327696
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00017441825184505433
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.746233571495395e-06
sam_encoder.blocks.11.norm2.weight grad: 0.0014672689139842987
sam_encoder.blocks.11.norm2.bias grad: -0.00015013598022051156
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0010264684678986669
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00023889972362667322
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00011015043128281832
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.77531458879821e-05
sam_encoder.neck.conv1.trainable_scale grad: 2.1627172827720642e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0012063757749274373
sam_encoder.neck.conv2.trainable_scale grad: 5.275709554553032e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.003473449731245637
mask_decoder.transformer.layers.0.norm1.weight grad: -0.007593521848320961
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00011306488886475563
mask_decoder.transformer.layers.0.norm2.weight grad: -0.6514007449150085
mask_decoder.transformer.layers.0.norm2.bias grad: -0.03415333852171898
mask_decoder.transformer.layers.0.norm3.weight grad: -0.009951296262443066
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0030631939880549908
mask_decoder.transformer.layers.0.norm4.weight grad: 0.007593363989144564
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0014211400412023067
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0036211200058460236
mask_decoder.transformer.layers.1.norm1.bias grad: 0.00034217932261526585
mask_decoder.transformer.layers.1.norm2.weight grad: -0.009388444013893604
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0012371060438454151
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0008693172130733728
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0031023477204144
mask_decoder.transformer.layers.1.norm4.weight grad: -0.009302067570388317
mask_decoder.transformer.layers.1.norm4.bias grad: -0.015970397740602493
mask_decoder.transformer.norm_final_attn.weight grad: 0.000437836250057444
mask_decoder.transformer.norm_final_attn.bias grad: 0.0016227525193244219
Text_Embedding_Affine.0.weight grad: -2.9481341812243045e-09
Text_Embedding_Affine.0.bias grad: -8.475035429000854e-08
Text_Embedding_Affine.2.weight grad: 4.2705678993115725e-09
Text_Embedding_Affine.2.bias grad: -4.308894858695567e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.260354427038318e-13
Max value: 0.9997499585151672
Mean value: 0.0928693413734436

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.260354427038318e-13
Max value: 0.9997499585151672
Mean value: 0.0928693413734436

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08457040786743164

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12929895520210266

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07703685760498047

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08457040786743164

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.86841583251953
Max value: 69.35263061523438
Mean value: 53.832191467285156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.260354427038318e-13
Max value: 0.9997499585151672
Mean value: 0.0928693413734436

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.260354427038318e-13
Max value: 0.9997499585151672
Mean value: 0.0928693413734436

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.260354427038318e-13
Max value: 0.9997499585151672
Mean value: 0.0928693413734436

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12929895520210266

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.86841583251953
Max value: 69.35263061523438
Mean value: 53.832191467285156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.83353042602539
Max value: -53.83353042602539
Mean value: -53.83353042602539
sam_encoder.pos_embed grad: 2.097514055776628e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0027186297811567783
sam_encoder.blocks.0.norm1.bias grad: -0.0015324510168284178
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.000254991085967049
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.1886722859344445e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0005822973325848579
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.33559000864625e-05
sam_encoder.blocks.0.norm2.weight grad: -0.0005869781016372144
sam_encoder.blocks.0.norm2.bias grad: 0.000777321751229465
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0007032396970316768
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00039124878821894526
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0016253187786787748
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00020278955344110727
sam_encoder.blocks.1.norm1.weight grad: -0.0007152475300244987
sam_encoder.blocks.1.norm1.bias grad: 0.0006021592998877168
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00010964044486172497
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.779599400237203e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0002134349779225886
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.00012679856445174664
sam_encoder.blocks.1.norm2.weight grad: -9.381790005136281e-05
sam_encoder.blocks.1.norm2.bias grad: 0.0002801459049805999
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00044974801130592823
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00011917604570044205
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.72819621488452e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.3592929462902248e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0006065747584216297
sam_encoder.blocks.2.norm1.bias grad: -0.0006474158726632595
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00023567990865558386
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.15357013582252e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0002755068999249488
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00017387360276188701
sam_encoder.blocks.2.norm2.weight grad: 0.0009523447370156646
sam_encoder.blocks.2.norm2.bias grad: -0.0013526510447263718
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0007251091301441193
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00014363173977471888
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0002547008916735649
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.282013782765716e-05
sam_encoder.blocks.3.norm1.weight grad: 0.00027361069805920124
sam_encoder.blocks.3.norm1.bias grad: 0.0004247009055688977
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.897607894032262e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00010097928316099569
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00020829879213124514
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00035933341132476926
sam_encoder.blocks.3.norm2.weight grad: 0.0007658683462068439
sam_encoder.blocks.3.norm2.bias grad: 9.135904110735282e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00025452228146605194
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0001687679614406079
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0002834057086147368
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.635843889554963e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0010582348331809044
sam_encoder.blocks.4.norm1.bias grad: -0.0004961816011928022
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00038552575279027224
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.624157635495067e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.7179007853847e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.904943150701001e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0012876852415502071
sam_encoder.blocks.4.norm2.bias grad: 0.0003816136159002781
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0007717923144809902
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00022274178627412766
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.000277933431789279
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.4246839782572351e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0001864603691501543
sam_encoder.blocks.5.norm1.bias grad: -0.0002949907211586833
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0005794622702524066
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00041268038330599666
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00047244015149772167
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0003758221282623708
sam_encoder.blocks.5.norm2.weight grad: -0.0014897220535203815
sam_encoder.blocks.5.norm2.bias grad: -5.6494765885872766e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0007634551730006933
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.000189273152500391
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.4645886848447844e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.162292705383152e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00016675435472279787
sam_encoder.blocks.6.norm1.bias grad: 8.624927431810647e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -7.09380692569539e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.6252796487824526e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.36149852653034e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.780119979841402e-06
sam_encoder.blocks.6.norm2.weight grad: -0.0005749305710196495
sam_encoder.blocks.6.norm2.bias grad: 0.0003036172711290419
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.3934209821163677e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.3971460652537644e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0001722418237477541
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00012314390914980322
sam_encoder.blocks.7.norm1.weight grad: 0.0002459486713632941
sam_encoder.blocks.7.norm1.bias grad: -2.017028418777045e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00013440159091260284
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.099490125663579e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.787494930904359e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.494991248473525e-05
sam_encoder.blocks.7.norm2.weight grad: -0.00014105507580097765
sam_encoder.blocks.7.norm2.bias grad: 0.00011408678255975246
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00023289897944778204
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.936276622582227e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00011645410995697603
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0145078704226762e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0001334944972768426
sam_encoder.blocks.8.norm1.bias grad: 0.00013572329771704972
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.564900392433628e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0002139370481017977
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0001819194294512272
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0003042701864615083
sam_encoder.blocks.8.norm2.weight grad: 0.0003584455116651952
sam_encoder.blocks.8.norm2.bias grad: 0.0002550902427174151
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00029431292205117643
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0001688409538473934
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00027096859412267804
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00010335010301787406
sam_encoder.blocks.9.norm1.weight grad: -0.00023227190831676126
sam_encoder.blocks.9.norm1.bias grad: 1.0962688065774273e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00028323946753516793
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.849788870662451e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.8661905718036e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0001012456341413781
sam_encoder.blocks.9.norm2.weight grad: 4.17474948335439e-05
sam_encoder.blocks.9.norm2.bias grad: 0.00013019693142268807
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.2967902118107304e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.6742167139891535e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.131550177698955e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.253890412859619e-05
sam_encoder.blocks.10.norm1.weight grad: -2.6194202291662805e-05
sam_encoder.blocks.10.norm1.bias grad: -3.485025808913633e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.75933770253323e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.7268201190745458e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.5534343421895755e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.6331361368647777e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0003852240042760968
sam_encoder.blocks.10.norm2.bias grad: -0.00012030990910716355
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00018549073138274252
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00011952147906413302
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2319263760218746e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.3790886189090088e-05
sam_encoder.blocks.11.norm1.weight grad: -0.001171349547803402
sam_encoder.blocks.11.norm1.bias grad: 0.00017034220218192786
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0001275647955480963
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.7513280909042805e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00013857554586138576
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.154687045840546e-05
sam_encoder.blocks.11.norm2.weight grad: 0.00011135948443552479
sam_encoder.blocks.11.norm2.bias grad: -0.00013073490117676556
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.25720965419896e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.5695130615495145e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.133543552597985e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0958311577269342e-05
sam_encoder.neck.conv1.trainable_scale grad: -2.56318598985672e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0007460991619154811
sam_encoder.neck.conv2.trainable_scale grad: 3.4528609830886126e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.00022659398382529616
mask_decoder.transformer.layers.0.norm1.weight grad: -0.013171428814530373
mask_decoder.transformer.layers.0.norm1.bias grad: 0.000212215818464756
mask_decoder.transformer.layers.0.norm2.weight grad: -0.021126188337802887
mask_decoder.transformer.layers.0.norm2.bias grad: 0.042831823229789734
mask_decoder.transformer.layers.0.norm3.weight grad: 0.004858856089413166
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0036157325375825167
mask_decoder.transformer.layers.0.norm4.weight grad: -0.004149633459746838
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0005661747418344021
mask_decoder.transformer.layers.1.norm1.weight grad: 0.004706748761236668
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00046000792644917965
mask_decoder.transformer.layers.1.norm2.weight grad: 0.02591920644044876
mask_decoder.transformer.layers.1.norm2.bias grad: 0.007561780512332916
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0018970649689435959
mask_decoder.transformer.layers.1.norm3.bias grad: 0.004339425824582577
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0013582308311015368
mask_decoder.transformer.layers.1.norm4.bias grad: -0.001706491457298398
mask_decoder.transformer.norm_final_attn.weight grad: 0.00013430207036435604
mask_decoder.transformer.norm_final_attn.bias grad: 0.00015875436656642705
Text_Embedding_Affine.0.weight grad: 3.880090915231449e-09
Text_Embedding_Affine.0.bias grad: 4.4819898903369904e-08
Text_Embedding_Affine.2.weight grad: 3.838053430627042e-09
Text_Embedding_Affine.2.bias grad: -0.0010829491075128317

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.797427258385597e-18
Max value: 0.9997324347496033
Mean value: 0.08370406180620193

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.797427258385597e-18
Max value: 0.9997324347496033
Mean value: 0.08370406180620193

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07745742797851562

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12320125102996826

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0748281478881836

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07745742797851562

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.52878189086914
Max value: 66.6583480834961
Mean value: 58.52386474609375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.797427258385597e-18
Max value: 0.9997324347496033
Mean value: 0.08370406180620193

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.797427258385597e-18
Max value: 0.9997324347496033
Mean value: 0.08370406180620193

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.797427258385597e-18
Max value: 0.9997324347496033
Mean value: 0.08370406180620193

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12320125102996826

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.52878189086914
Max value: 66.6583480834961
Mean value: 58.52386474609375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.525047302246094
Max value: -58.525047302246094
Mean value: -58.525047302246094
sam_encoder.pos_embed grad: 8.36338585941121e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0030107805505394936
sam_encoder.blocks.0.norm1.bias grad: 0.0028675959911197424
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0003275823255535215
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00017864975961856544
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0010000972542911768
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.9961360269226134e-05
sam_encoder.blocks.0.norm2.weight grad: 0.005857107229530811
sam_encoder.blocks.0.norm2.bias grad: -0.004485536366701126
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0019695493392646313
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.676954555790871e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0004497446061577648
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00029113783966749907
sam_encoder.blocks.1.norm1.weight grad: 0.0006032771780155599
sam_encoder.blocks.1.norm1.bias grad: 0.002026800299063325
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0002904366119764745
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00012843219155911356
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00044127096771262586
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002992043155245483
sam_encoder.blocks.1.norm2.weight grad: -0.0015108892694115639
sam_encoder.blocks.1.norm2.bias grad: -0.00013292208313941956
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0001647650933591649
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.886546907480806e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.001757355174049735
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0003200047358404845
sam_encoder.blocks.2.norm1.weight grad: -0.0010146162239834666
sam_encoder.blocks.2.norm1.bias grad: 0.0015620014164596796
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008965869201347232
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0001963536924449727
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0002495142398402095
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00036805978743359447
sam_encoder.blocks.2.norm2.weight grad: -0.000556206563487649
sam_encoder.blocks.2.norm2.bias grad: -0.0013642938574776053
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.000540534034371376
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00017374486196786165
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.001618614187464118
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0004723223391920328
sam_encoder.blocks.3.norm1.weight grad: -0.00040463003097102046
sam_encoder.blocks.3.norm1.bias grad: 0.0010778981959447265
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0015286162961274385
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00045497037353925407
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.001001799595542252
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0005719205364584923
sam_encoder.blocks.3.norm2.weight grad: -0.00220108893699944
sam_encoder.blocks.3.norm2.bias grad: -0.0015490477671846747
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0016218414530158043
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0004069558344781399
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00025083409855142236
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0003143819631077349
sam_encoder.blocks.4.norm1.weight grad: -0.00011686544166877866
sam_encoder.blocks.4.norm1.bias grad: 0.0004292551602702588
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00021653214935213327
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00013913802104070783
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0002109565248247236
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00034239969681948423
sam_encoder.blocks.4.norm2.weight grad: -0.00187732744961977
sam_encoder.blocks.4.norm2.bias grad: -0.0007505490793846548
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.001429004012607038
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0002640408929437399
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0005181817687116563
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0001757472346071154
sam_encoder.blocks.5.norm1.weight grad: -0.0007434334838762879
sam_encoder.blocks.5.norm1.bias grad: -0.0009186012903228402
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0002876193611882627
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00028235637000761926
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00035244598984718323
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 9.83228674158454e-05
sam_encoder.blocks.5.norm2.weight grad: -0.0023238223511725664
sam_encoder.blocks.5.norm2.bias grad: -0.0007487862603738904
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.001232864335179329
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00047264815657399595
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.8112570614903234e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.38914867118001e-06
sam_encoder.blocks.6.norm1.weight grad: -0.0011559403501451015
sam_encoder.blocks.6.norm1.bias grad: -0.0005518581601791084
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.000689446460455656
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00019379791046958417
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0002725472440943122
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0003651644801720977
sam_encoder.blocks.6.norm2.weight grad: -6.229234713828191e-05
sam_encoder.blocks.6.norm2.bias grad: 0.0006493350374512374
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00041839759796857834
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0001860873308032751
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0001477697805967182
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.717873035697266e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0007135467021726072
sam_encoder.blocks.7.norm1.bias grad: 6.1187506616988685e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0007299698772840202
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00021786894649267197
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0004948345012962818
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0005922158597968519
sam_encoder.blocks.7.norm2.weight grad: 0.0004080621001776308
sam_encoder.blocks.7.norm2.bias grad: 0.00017683819169178605
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.553365867352113e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.861000631237403e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.871202928479761e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00014352667494677007
sam_encoder.blocks.8.norm1.weight grad: -6.984954234212637e-05
sam_encoder.blocks.8.norm1.bias grad: 0.0004001709748990834
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00040265332791022956
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00010783271864056587
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0007283311570063233
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0008682244224473834
sam_encoder.blocks.8.norm2.weight grad: -0.0007527185371145606
sam_encoder.blocks.8.norm2.bias grad: -2.1952728275209665e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0010304230963811278
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0005570101784542203
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0003100412432104349
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00013217859668657184
sam_encoder.blocks.9.norm1.weight grad: -0.000574873702134937
sam_encoder.blocks.9.norm1.bias grad: -0.00012048156349919736
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0005064053693786263
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00031469008536078036
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00023133703507483006
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0004190203035250306
sam_encoder.blocks.9.norm2.weight grad: -0.0006974490825086832
sam_encoder.blocks.9.norm2.bias grad: -0.00013007302186451852
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.000679950462654233
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00033735897159203887
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.454330362728797e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.5698802599217743e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0003441101871430874
sam_encoder.blocks.10.norm1.bias grad: -9.465658513363451e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00022373457613866776
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0001143510962720029
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00014296648441813886
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.972301631933078e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0021431278437376022
sam_encoder.blocks.10.norm2.bias grad: -0.00071589311119169
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.000834218633826822
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0005998753476887941
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00021284460672177374
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.134541374398395e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0006317548686638474
sam_encoder.blocks.11.norm1.bias grad: 0.00020816366304643452
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0006500240415334702
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.0001442025532014668
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.5108659833204e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.0601906473748386e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0016412127297371626
sam_encoder.blocks.11.norm2.bias grad: -0.0003699901863001287
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0005513852811418474
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00038209889316931367
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00010312802623957396
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00010082176595460624
sam_encoder.neck.conv1.trainable_scale grad: -7.742841262370348e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0027367444708943367
sam_encoder.neck.conv2.trainable_scale grad: -5.556037649512291e-06
sam_encoder.neck.conv2.trainable_shift grad: 0.0027081817388534546
mask_decoder.transformer.layers.0.norm1.weight grad: -0.005108803976327181
mask_decoder.transformer.layers.0.norm1.bias grad: 4.1326507925987244e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.04898104816675186
mask_decoder.transformer.layers.0.norm2.bias grad: 0.10108475387096405
mask_decoder.transformer.layers.0.norm3.weight grad: 0.013334007002413273
mask_decoder.transformer.layers.0.norm3.bias grad: 0.011586615815758705
mask_decoder.transformer.layers.0.norm4.weight grad: -0.006176238413900137
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0006727797444909811
mask_decoder.transformer.layers.1.norm1.weight grad: 0.005555591080337763
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0009712364408187568
mask_decoder.transformer.layers.1.norm2.weight grad: 0.04639279097318649
mask_decoder.transformer.layers.1.norm2.bias grad: 0.015398619696497917
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004277866333723068
mask_decoder.transformer.layers.1.norm3.bias grad: 0.006564483046531677
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0056299674324691296
mask_decoder.transformer.layers.1.norm4.bias grad: 0.010804984718561172
mask_decoder.transformer.norm_final_attn.weight grad: 0.00015067015192471445
mask_decoder.transformer.norm_final_attn.bias grad: -0.0010454364819452167
Text_Embedding_Affine.0.weight grad: -2.614828353841858e-10
Text_Embedding_Affine.0.bias grad: -4.1443854570388794e-08
Text_Embedding_Affine.2.weight grad: -7.547356073445144e-10
Text_Embedding_Affine.2.bias grad: -0.0025827307254076004
Epoch 23 finished with average loss: -57.1927
Epoch 24/39
----------
Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.8]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-57.8]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-59.4]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-59.4]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-59]  Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-59]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.350879461740732e-12
Max value: 0.9979124665260315
Mean value: 0.0827881321310997

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.350879461740732e-12
Max value: 0.9979124665260315
Mean value: 0.0827881321310997

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08346319198608398

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11487475037574768

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07343053817749023

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08346319198608398

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.66654968261719
Max value: 82.958251953125
Mean value: 57.82521438598633

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.350879461740732e-12
Max value: 0.9979124665260315
Mean value: 0.0827881321310997

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.350879461740732e-12
Max value: 0.9979124665260315
Mean value: 0.0827881321310997

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.350879461740732e-12
Max value: 0.9979124665260315
Mean value: 0.0827881321310997

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11487475037574768

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.66654968261719
Max value: 82.958251953125
Mean value: 57.82521438598633

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.82632064819336
Max value: -57.82632064819336
Mean value: -57.82632064819336
sam_encoder.pos_embed grad: -2.7627481813397026e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0012457896955311298
sam_encoder.blocks.0.norm1.bias grad: 0.004051661118865013
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0013109315186738968
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00017940047837328166
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.003546928288415e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00010971636220347136
sam_encoder.blocks.0.norm2.weight grad: 0.010247928090393543
sam_encoder.blocks.0.norm2.bias grad: 0.002930361544713378
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.001971679972484708
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00032813288271427155
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0035132586490362883
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.001051253406330943
sam_encoder.blocks.1.norm1.weight grad: 0.0002644355408847332
sam_encoder.blocks.1.norm1.bias grad: 0.0013427188387140632
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0007805950008332729
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00019884423818439245
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0006852370570413768
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.873604722088203e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0017751067643985152
sam_encoder.blocks.1.norm2.bias grad: -0.0001821818295866251
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.952606342267245e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.35048665269278e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00040885538328438997
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00016541509830858558
sam_encoder.blocks.2.norm1.weight grad: -0.0014560086419805884
sam_encoder.blocks.2.norm1.bias grad: 0.00023712396796327084
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00117699452675879
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00014685129281133413
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0006063581677153707
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000867266790010035
sam_encoder.blocks.2.norm2.weight grad: -0.00013515198952518404
sam_encoder.blocks.2.norm2.bias grad: -0.0002796572807710618
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0003797526005655527
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.7858695830218494e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005587473278865218
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3581147868535481e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0008949249750003219
sam_encoder.blocks.3.norm1.bias grad: -0.0001769527734722942
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.959343277732842e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.232461676816456e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0001588800805620849
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.46760784345679e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0007960202055983245
sam_encoder.blocks.3.norm2.bias grad: 0.0016349701909348369
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0008134687086567283
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00038093148032203317
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00024976799613796175
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.572171645937487e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0013824835186824203
sam_encoder.blocks.4.norm1.bias grad: -0.0004019073094241321
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005015088245272636
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00016961953951977193
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.855221676640213e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.1128975529572926e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0016847450751811266
sam_encoder.blocks.4.norm2.bias grad: -0.0002721754717640579
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00028878776356577873
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.476496203802526e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00019818735017906874
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.0967714590369724e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0005511224153451622
sam_encoder.blocks.5.norm1.bias grad: -0.0015169493854045868
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0007456647581420839
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00022087650722824037
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0003554259310476482
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00022118038032203913
sam_encoder.blocks.5.norm2.weight grad: 0.0011204916518181562
sam_encoder.blocks.5.norm2.bias grad: -7.270269270520657e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00035347146331332624
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00012284694821573794
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.288716733455658e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.1226867172808852e-05
sam_encoder.blocks.6.norm1.weight grad: -0.000694174028467387
sam_encoder.blocks.6.norm1.bias grad: 0.00016162448446266353
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0005339725757949054
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00011200386506970972
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00026569486362859607
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.000140593052492477
sam_encoder.blocks.6.norm2.weight grad: 0.0011271359398961067
sam_encoder.blocks.6.norm2.bias grad: -0.0001876936003100127
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00039377156645059586
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00013944311649538577
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.515811866032891e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.276507388567552e-05
sam_encoder.blocks.7.norm1.weight grad: -8.297058957396075e-05
sam_encoder.blocks.7.norm1.bias grad: 9.591445996193215e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.3359235607786104e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.836129326373339e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.8236233599018306e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00013241397391539067
sam_encoder.blocks.7.norm2.weight grad: 0.000580216757953167
sam_encoder.blocks.7.norm2.bias grad: -0.0003012494998984039
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.4850108527753036e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.634110806975514e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0002435520727885887
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.682727977633476e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00027280833455733955
sam_encoder.blocks.8.norm1.bias grad: 6.761844269931316e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0002704043872654438
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00014386328984983265
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.1489057214930654e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00014991938951425254
sam_encoder.blocks.8.norm2.weight grad: 1.4694194760522805e-05
sam_encoder.blocks.8.norm2.bias grad: 6.0107195167802274e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0001766030618455261
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00014896132051944733
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00012085780326742679
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.950211587129161e-05
sam_encoder.blocks.9.norm1.weight grad: -7.243111031129956e-05
sam_encoder.blocks.9.norm1.bias grad: 0.0001335113774985075
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00019663874991238117
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.1087459976552054e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1471193829493131e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00010741154255811125
sam_encoder.blocks.9.norm2.weight grad: 0.0004202050040476024
sam_encoder.blocks.9.norm2.bias grad: -1.2501550372689962e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.0583505829563364e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.248755820095539e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00020586726895999163
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.863702633883804e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0005330552230589092
sam_encoder.blocks.10.norm1.bias grad: 4.035517849843018e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0002923048159573227
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.440799835312646e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00010596272477414459
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.319931708276272e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00011310713307466358
sam_encoder.blocks.10.norm2.bias grad: -0.00020841986406594515
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00010225870937574655
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00010322449816158041
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00023774532019160688
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.496536661870778e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0005767773254774511
sam_encoder.blocks.11.norm1.bias grad: -0.00015029864152893424
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0005454913480207324
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.912400178611279e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.20026800991036e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.50126491766423e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0007084819371812046
sam_encoder.blocks.11.norm2.bias grad: -0.00028452076367102563
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.775383371859789e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00021044978348072618
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00028293527429923415
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.0121289202943444e-05
sam_encoder.neck.conv1.trainable_scale grad: -3.183574881404638e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0007350090891122818
sam_encoder.neck.conv2.trainable_scale grad: 0.00017282215412706137
sam_encoder.neck.conv2.trainable_shift grad: 0.00995631143450737
mask_decoder.transformer.layers.0.norm1.weight grad: -0.008993813768029213
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00032392796128988266
mask_decoder.transformer.layers.0.norm2.weight grad: -0.2737814784049988
mask_decoder.transformer.layers.0.norm2.bias grad: 0.04540427029132843
mask_decoder.transformer.layers.0.norm3.weight grad: 0.003489430993795395
mask_decoder.transformer.layers.0.norm3.bias grad: 0.008293557912111282
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0014666481874883175
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000308024522382766
mask_decoder.transformer.layers.1.norm1.weight grad: 0.004125396255403757
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0006140390178188682
mask_decoder.transformer.layers.1.norm2.weight grad: 0.018680203706026077
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004995701834559441
mask_decoder.transformer.layers.1.norm3.weight grad: -0.003630084916949272
mask_decoder.transformer.layers.1.norm3.bias grad: 0.002909007715061307
mask_decoder.transformer.layers.1.norm4.weight grad: -0.006227809004485607
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0014295072760432959
mask_decoder.transformer.norm_final_attn.weight grad: 0.00039153354009613395
mask_decoder.transformer.norm_final_attn.bias grad: -0.0002791732840705663
Text_Embedding_Affine.0.weight grad: -1.7022347975625962e-09
Text_Embedding_Affine.0.bias grad: -6.522168405354023e-08
Text_Embedding_Affine.2.weight grad: -3.043151064474614e-09
Text_Embedding_Affine.2.bias grad: -0.002055839169770479

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.86024581155797e-11
Max value: 0.9993939399719238
Mean value: 0.09231816977262497

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.86024581155797e-11
Max value: 0.9993939399719238
Mean value: 0.09231816977262497

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08990859985351562

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12106189131736755

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08253288269042969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08990859985351562

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.189395904541016
Max value: 76.62374114990234
Mean value: 61.0235595703125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.86024581155797e-11
Max value: 0.9993939399719238
Mean value: 0.09231816977262497

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.86024581155797e-11
Max value: 0.9993939399719238
Mean value: 0.09231816977262497

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.86024581155797e-11
Max value: 0.9993939399719238
Mean value: 0.09231816977262497

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12106189131736755

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.189395904541016
Max value: 76.62374114990234
Mean value: 61.0235595703125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.02477264404297
Max value: -61.02477264404297
Mean value: -61.02477264404297
sam_encoder.pos_embed grad: 3.5516868024387804e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0025400547310709953
sam_encoder.blocks.0.norm1.bias grad: 0.0027507534250617027
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00041562714613974094
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.668424480769318e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0005596367991529405
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00018334176274947822
sam_encoder.blocks.0.norm2.weight grad: -0.0007145440904423594
sam_encoder.blocks.0.norm2.bias grad: -9.648874402046204e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0004896417958661914
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00042956668767146766
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0003269208245910704
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0004318423743825406
sam_encoder.blocks.1.norm1.weight grad: 0.0007533635944128036
sam_encoder.blocks.1.norm1.bias grad: 0.0007125063566491008
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00042706570820882916
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.729026351124048e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00043024588376283646
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00020210191723890603
sam_encoder.blocks.1.norm2.weight grad: 0.00043646834092214704
sam_encoder.blocks.1.norm2.bias grad: -0.0004538775538094342
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0002496266970410943
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00012174198491265997
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0007709306082688272
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.886031380621716e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0005710594123229384
sam_encoder.blocks.2.norm1.bias grad: 0.0006565295625478029
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0007196691585704684
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.327477164333686e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003363839350640774
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00016292883083224297
sam_encoder.blocks.2.norm2.weight grad: 0.00012123316992074251
sam_encoder.blocks.2.norm2.bias grad: -0.0014591342769563198
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00021450684289447963
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.8526290154550225e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005230688257142901
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00016549880092497915
sam_encoder.blocks.3.norm1.weight grad: -0.000967048283200711
sam_encoder.blocks.3.norm1.bias grad: 0.0007517868070863187
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0010233181528747082
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0002070477930828929
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005266433581709862
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.000264670088654384
sam_encoder.blocks.3.norm2.weight grad: 0.000146050748298876
sam_encoder.blocks.3.norm2.bias grad: -0.0005335846799425781
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.320075873285532e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00017228684737347066
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0006594109581783414
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00017552505596540868
sam_encoder.blocks.4.norm1.weight grad: -0.0007818228332325816
sam_encoder.blocks.4.norm1.bias grad: 0.00027986190980300307
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0006842681905254722
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00012806638551410288
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0004529333091340959
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00038583818241022527
sam_encoder.blocks.4.norm2.weight grad: -0.0007614525384269655
sam_encoder.blocks.4.norm2.bias grad: -8.47353003337048e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0007775434642098844
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0001852876739576459
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0003151303972117603
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00012138090096414089
sam_encoder.blocks.5.norm1.weight grad: -0.0007619393290951848
sam_encoder.blocks.5.norm1.bias grad: -5.224488995736465e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0006259701913222671
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00025297311367467046
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00030903395963832736
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00017295099678449333
sam_encoder.blocks.5.norm2.weight grad: 0.00012370006879791617
sam_encoder.blocks.5.norm2.bias grad: 0.00024192598357331008
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0299283530912362e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.719180656640674e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.710896847536787e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.794091051327996e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0004985373234376311
sam_encoder.blocks.6.norm1.bias grad: -0.0002557968255132437
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00037849516957066953
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00010219852993031964
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00016437540762126446
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00010210531763732433
sam_encoder.blocks.6.norm2.weight grad: 0.0006255991756916046
sam_encoder.blocks.6.norm2.bias grad: 0.0005130231729708612
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00040079531027004123
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00011192520469194278
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00013729164493270218
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.815079879947007e-05
sam_encoder.blocks.7.norm1.weight grad: -0.00016823252371978015
sam_encoder.blocks.7.norm1.bias grad: -6.809870683355257e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0001874861482065171
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -9.598543692845851e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00016171066090464592
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00022696760424878448
sam_encoder.blocks.7.norm2.weight grad: 0.00046471389941871166
sam_encoder.blocks.7.norm2.bias grad: -0.00013626020518131554
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0001347248035017401
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.171570127364248e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.412410923279822e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.108408443746157e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00040070046088658273
sam_encoder.blocks.8.norm1.bias grad: 0.00011484215792734176
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0002100733545375988
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.5193315448414069e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00020068965386599302
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.000141195923788473
sam_encoder.blocks.8.norm2.weight grad: -6.664895772701129e-05
sam_encoder.blocks.8.norm2.bias grad: 0.0001136098217102699
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0001680628483882174
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.7498419765615836e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00015162061026785523
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.652207568753511e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00019954975869040936
sam_encoder.blocks.9.norm1.bias grad: -4.2017214582301676e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00017608079360798
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.679500100086443e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.95143927866593e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00014262666809372604
sam_encoder.blocks.9.norm2.weight grad: -1.4482706319540739e-05
sam_encoder.blocks.9.norm2.bias grad: -3.276298230048269e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.457262785872445e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.192819349351339e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.4282975573441945e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.0964129362255335e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00011434113548602909
sam_encoder.blocks.10.norm1.bias grad: -8.119008271023631e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.168091279803775e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.386419328104239e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.11994692008011e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.080050737480633e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0009413358638994396
sam_encoder.blocks.10.norm2.bias grad: -0.00038721016608178616
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00035712955286726356
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00022859603632241488
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00021246371034067124
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.15738715371117e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0012004004092887044
sam_encoder.blocks.11.norm1.bias grad: 0.00013393971312325448
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00035783613566309214
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.772348256665282e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.637354529928416e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.774250661896076e-06
sam_encoder.blocks.11.norm2.weight grad: -0.0006712763570249081
sam_encoder.blocks.11.norm2.bias grad: 1.4892527815391077e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00020525880972854793
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00013230709009803832
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00010901647328864783
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.89092994434759e-05
sam_encoder.neck.conv1.trainable_scale grad: -7.579755038022995e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0006896978011354804
sam_encoder.neck.conv2.trainable_scale grad: -3.144738730043173e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.004471710883080959
mask_decoder.transformer.layers.0.norm1.weight grad: -0.011458568274974823
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00033274944871664047
mask_decoder.transformer.layers.0.norm2.weight grad: 0.05974729731678963
mask_decoder.transformer.layers.0.norm2.bias grad: 0.08682893216609955
mask_decoder.transformer.layers.0.norm3.weight grad: 0.006651629693806171
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0009753573685884476
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0031037824228405952
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000527281139511615
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0011882210383191705
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00019917276222258806
mask_decoder.transformer.layers.1.norm2.weight grad: 0.005461462773382664
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0005120586138218641
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0005210915114730597
mask_decoder.transformer.layers.1.norm3.bias grad: 0.001235876465216279
mask_decoder.transformer.layers.1.norm4.weight grad: -1.742178574204445e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0019452471751719713
mask_decoder.transformer.norm_final_attn.weight grad: 1.6219615645240992e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0002672430709935725
Text_Embedding_Affine.0.weight grad: 1.2740253296783521e-09
Text_Embedding_Affine.0.bias grad: 5.855690687894821e-08
Text_Embedding_Affine.2.weight grad: 1.5094661076631155e-09
Text_Embedding_Affine.2.bias grad: 0.0019176803762093186

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.9763141145685477e-16
Max value: 0.9990090131759644
Mean value: 0.07338150590658188

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.9763141145685477e-16
Max value: 0.9990090131759644
Mean value: 0.07338150590658188

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07239818572998047

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12541401386260986

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06555461883544922

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07239818572998047

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.23509216308594
Max value: 68.1696548461914
Mean value: 58.169517517089844

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.9763141145685477e-16
Max value: 0.9990090131759644
Mean value: 0.07338150590658188

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.9763141145685477e-16
Max value: 0.9990090131759644
Mean value: 0.07338150590658188

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.9763141145685477e-16
Max value: 0.9990090131759644
Mean value: 0.07338150590658188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12541401386260986

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.23509216308594
Max value: 68.1696548461914
Mean value: 58.169517517089844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.17048263549805
Max value: -58.17048263549805
Mean value: -58.17048263549805
sam_encoder.pos_embed grad: 3.2456495091537363e-07
sam_encoder.blocks.0.norm1.weight grad: 0.005150046199560165
sam_encoder.blocks.0.norm1.bias grad: 0.0007468887488357723
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.000780115311499685
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.1701113180606626e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.4351438721860177e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0002296145394211635
sam_encoder.blocks.0.norm2.weight grad: 0.0003864867612719536
sam_encoder.blocks.0.norm2.bias grad: -0.003734323661774397
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000540596607606858
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00019862786575686187
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00013027724344283342
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00038566230796277523
sam_encoder.blocks.1.norm1.weight grad: 0.000301434745779261
sam_encoder.blocks.1.norm1.bias grad: 0.0012630975106731057
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00025468977401033044
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.5946711654542014e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0003109473327640444
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00013701296120416373
sam_encoder.blocks.1.norm2.weight grad: 0.00048277515452355146
sam_encoder.blocks.1.norm2.bias grad: -3.754871431738138e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00024727656273171306
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.000122796802315861
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0007073053857311606
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.4286430086940527e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0014590000500902534
sam_encoder.blocks.2.norm1.bias grad: 0.0009398586116731167
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.000941127713304013
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.000196999913896434
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003483566106297076
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00011126101890113205
sam_encoder.blocks.2.norm2.weight grad: -0.00012168276589363813
sam_encoder.blocks.2.norm2.bias grad: -0.0009626960381865501
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.598393131047487e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.472880679415539e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00047469581477344036
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.453565533272922e-05
sam_encoder.blocks.3.norm1.weight grad: 2.926541492342949e-05
sam_encoder.blocks.3.norm1.bias grad: 0.0008850125013850629
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00044338320731185377
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00013080697681289166
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0003403525333851576
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00026203770539723337
sam_encoder.blocks.3.norm2.weight grad: -0.001172432443127036
sam_encoder.blocks.3.norm2.bias grad: 1.6968173440545797e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0012659637723118067
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00032834027661010623
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0003565313236322254
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00015409270417876542
sam_encoder.blocks.4.norm1.weight grad: 0.00018258410273119807
sam_encoder.blocks.4.norm1.bias grad: -5.8016325056087226e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0001564839476486668
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.289116623112932e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0003131897537969053
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00033121241722255945
sam_encoder.blocks.4.norm2.weight grad: 0.0002759506751317531
sam_encoder.blocks.4.norm2.bias grad: 0.0005731044802814722
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.553990973159671e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.9519566194503568e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0002995992254000157
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1777625079266727e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0014237628784030676
sam_encoder.blocks.5.norm1.bias grad: -0.0009273159666918218
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0008166077896021307
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00021806567383464426
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0005760448984801769
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00025340565480291843
sam_encoder.blocks.5.norm2.weight grad: -0.00023770041298121214
sam_encoder.blocks.5.norm2.bias grad: -0.00023259528097696602
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0002963641018141061
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.101779869524762e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.428568253293633e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.0351300918264315e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0008464910788461566
sam_encoder.blocks.6.norm1.bias grad: -0.0005209561786614358
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0003054755215998739
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.8856854846235365e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00021106847270857543
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00013438283349387348
sam_encoder.blocks.6.norm2.weight grad: -7.708033081144094e-06
sam_encoder.blocks.6.norm2.bias grad: 0.00027219776529818773
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00011404625547584146
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.0828712119255215e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.337320180842653e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.904730980750173e-06
sam_encoder.blocks.7.norm1.weight grad: -3.633645246736705e-05
sam_encoder.blocks.7.norm1.bias grad: -0.00012915262777823955
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00012902438174933195
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00013246289745438844
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00014251827087718993
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003025992773473263
sam_encoder.blocks.7.norm2.weight grad: 0.00016879779286682606
sam_encoder.blocks.7.norm2.bias grad: -8.394270844291896e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0001168780290754512
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.613812754745595e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.538856981322169e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.3984986152499914e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0003490049857646227
sam_encoder.blocks.8.norm1.bias grad: -0.00010261002171318978
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0004406978841871023
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0002322777290828526
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00015085001359693706
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00023154137306846678
sam_encoder.blocks.8.norm2.weight grad: -0.0004140656383242458
sam_encoder.blocks.8.norm2.bias grad: 0.00011253155389567837
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00045062380377203226
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0002554524107836187
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00024135466082952917
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00010567393474048004
sam_encoder.blocks.9.norm1.weight grad: -0.00013520295033231378
sam_encoder.blocks.9.norm1.bias grad: -1.2870485079474747e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00011010636808350682
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.999634206295013e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.30358704761602e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.169947977876291e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0005637235590256751
sam_encoder.blocks.9.norm2.bias grad: -9.632825094740838e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00047674746019765735
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00029989652102813125
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.05040357488906e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.229791557008866e-06
sam_encoder.blocks.10.norm1.weight grad: -0.0001779242156771943
sam_encoder.blocks.10.norm1.bias grad: -2.7555133783607744e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00013935533934272826
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.684791176463477e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.4010023227892816e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.1541054593399167e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0014641683083027601
sam_encoder.blocks.10.norm2.bias grad: -0.0005092954379506409
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0005792084848508239
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00045227594091556966
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.000194456399185583
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.528669812018052e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0006665847613476217
sam_encoder.blocks.11.norm1.bias grad: 9.493179095443338e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.000125395818031393
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.69862573784485e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.0288691050373018e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.350521365064196e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0012933581601828337
sam_encoder.blocks.11.norm2.bias grad: -0.00028815341647714376
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0003671263693831861
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00027928384952247143
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00015972254914231598
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.758308831602335e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.00011202949099242687
sam_encoder.neck.conv1.trainable_shift grad: -0.000592193566262722
sam_encoder.neck.conv2.trainable_scale grad: -3.347988240420818e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0036667403765022755
mask_decoder.transformer.layers.0.norm1.weight grad: -0.01347869448363781
mask_decoder.transformer.layers.0.norm1.bias grad: -9.387172758579254e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.22946806252002716
mask_decoder.transformer.layers.0.norm2.bias grad: 0.10766765475273132
mask_decoder.transformer.layers.0.norm3.weight grad: -0.000923382118344307
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0030200514011085033
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0052618589252233505
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0003475596895441413
mask_decoder.transformer.layers.1.norm1.weight grad: 9.154979488812387e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0004481141804717481
mask_decoder.transformer.layers.1.norm2.weight grad: 0.020738773047924042
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0020540545228868723
mask_decoder.transformer.layers.1.norm3.weight grad: 0.001647929660975933
mask_decoder.transformer.layers.1.norm3.bias grad: 0.002018289640545845
mask_decoder.transformer.layers.1.norm4.weight grad: 0.004017329309135675
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0040473612025380135
mask_decoder.transformer.norm_final_attn.weight grad: 0.00011789349082391709
mask_decoder.transformer.norm_final_attn.bias grad: -3.917168942280114e-05
Text_Embedding_Affine.0.weight grad: -2.742563953717081e-10
Text_Embedding_Affine.0.bias grad: -2.8347130864858627e-08
Text_Embedding_Affine.2.weight grad: -2.1816117801165547e-09
Text_Embedding_Affine.2.bias grad: 0.0012588733807206154
Epoch 24 finished with average loss: -59.0072
Epoch 25/39
----------
Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s, loss=-53.7]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-53.7]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-53.6]Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-53.6]Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-53.3]Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-53.3]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.214088135581548e-10
Max value: 0.9984647035598755
Mean value: 0.09279409795999527

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.214088135581548e-10
Max value: 0.9984647035598755
Mean value: 0.09279409795999527

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09083890914916992

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.100513458251953
Max value: -1.1920928244535389e-07
Mean value: -0.134349524974823

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0815725326538086

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09083890914916992

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.6213264465332
Max value: 66.80523681640625
Mean value: 53.724952697753906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.214088135581548e-10
Max value: 0.9984647035598755
Mean value: 0.09279409795999527

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.214088135581548e-10
Max value: 0.9984647035598755
Mean value: 0.09279409795999527

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.214088135581548e-10
Max value: 0.9984647035598755
Mean value: 0.09279409795999527

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.100513458251953
Max value: -1.1920928244535389e-07
Mean value: -0.134349524974823

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.6213264465332
Max value: 66.80523681640625
Mean value: 53.724952697753906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.72624969482422
Max value: -53.72624969482422
Mean value: -53.72624969482422
sam_encoder.pos_embed grad: -4.569841962620558e-07
sam_encoder.blocks.0.norm1.weight grad: -0.001657609362155199
sam_encoder.blocks.0.norm1.bias grad: 0.00532506313174963
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.76953568472527e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.94854053715244e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00042051481432281435
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00015855398669373244
sam_encoder.blocks.0.norm2.weight grad: 0.005587138235569
sam_encoder.blocks.0.norm2.bias grad: 0.004810374695807695
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0007125390693545341
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00022731686476618052
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00030541722662746906
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.646298864623532e-05
sam_encoder.blocks.1.norm1.weight grad: 0.0016411961987614632
sam_encoder.blocks.1.norm1.bias grad: 0.0015568388625979424
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0005596725968644023
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.144648407120258e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.00021229914273135364
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0004898484330624342
sam_encoder.blocks.1.norm2.weight grad: 0.004975275136530399
sam_encoder.blocks.1.norm2.bias grad: 0.00035018863854929805
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0008407918503507972
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001152155309682712
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0015257971826940775
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2871014405391179e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0014216257259249687
sam_encoder.blocks.2.norm1.bias grad: -0.0001750414667185396
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.000997301540337503
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00017732543346937746
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0007618576055392623
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0009261743980459869
sam_encoder.blocks.2.norm2.weight grad: 4.699702185462229e-05
sam_encoder.blocks.2.norm2.bias grad: -0.0010696293320506811
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00025481561897322536
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00021166630904190242
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00026826103567145765
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0002591678639873862
sam_encoder.blocks.3.norm1.weight grad: -0.00017088023014366627
sam_encoder.blocks.3.norm1.bias grad: -0.0013663097051903605
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00018315683701075613
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.312143566196028e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0003072607214562595
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0002521391143091023
sam_encoder.blocks.3.norm2.weight grad: 0.0004950682050548494
sam_encoder.blocks.3.norm2.bias grad: 0.0008979574195109308
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0005320052150636911
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00024113841936923563
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.00045726177631877363
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.0635004804935306e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0013974374160170555
sam_encoder.blocks.4.norm1.bias grad: 0.0004541593079920858
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0010489595588296652
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0002774417807813734
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0007234247168526053
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0003795220982283354
sam_encoder.blocks.4.norm2.weight grad: -0.002489569364115596
sam_encoder.blocks.4.norm2.bias grad: -0.0037527221720665693
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0018140701577067375
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0008322633802890778
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.507375266868621e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0001274057140108198
sam_encoder.blocks.5.norm1.weight grad: -0.001120922970585525
sam_encoder.blocks.5.norm1.bias grad: -0.00038561580004170537
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.001030575716868043
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0006070986273698509
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.1566713005304337e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0002661707694642246
sam_encoder.blocks.5.norm2.weight grad: -0.0012825621524825692
sam_encoder.blocks.5.norm2.bias grad: -0.0015682808589190245
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0004644505097530782
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00017321936320513487
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00012288423022255301
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.0001822675985749811
sam_encoder.blocks.6.norm1.weight grad: -0.0003297205548733473
sam_encoder.blocks.6.norm1.bias grad: 0.00038983006379567087
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0004619676328729838
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00024566904176026583
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00012798454554285854
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.978703378175851e-05
sam_encoder.blocks.6.norm2.weight grad: -4.188293678453192e-05
sam_encoder.blocks.6.norm2.bias grad: -4.117439311812632e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00018515146803110838
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.171741602476686e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002545429742895067
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.290048193273833e-06
sam_encoder.blocks.7.norm1.weight grad: 0.0006062686443328857
sam_encoder.blocks.7.norm1.bias grad: 0.0003172065189573914
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0002665314241312444
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00019410773529671133
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00011402244854252785
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0002460512623656541
sam_encoder.blocks.7.norm2.weight grad: -0.00017723918426781893
sam_encoder.blocks.7.norm2.bias grad: 0.0002448991290293634
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00025522400392219424
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00012972555123269558
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00024179054889827967
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00014895841013640165
sam_encoder.blocks.8.norm1.weight grad: -6.74581533530727e-05
sam_encoder.blocks.8.norm1.bias grad: 7.599247328471392e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00037875660927966237
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0003634027671068907
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.79608778632246e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00014090765034779906
sam_encoder.blocks.8.norm2.weight grad: -0.0005326143000274897
sam_encoder.blocks.8.norm2.bias grad: -0.0005022336263209581
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00027980166487395763
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00016529473941773176
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00011651065142359585
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00011634679685812443
sam_encoder.blocks.9.norm1.weight grad: -0.0001218181278090924
sam_encoder.blocks.9.norm1.bias grad: 9.726888674777001e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.607020961586386e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.025059752166271e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.186780188319972e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00022768483904656023
sam_encoder.blocks.9.norm2.weight grad: 0.000315421842969954
sam_encoder.blocks.9.norm2.bias grad: -0.0005290346452966332
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00038927083369344473
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00021237826149445027
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.9976616133353673e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -0.00014231636305339634
sam_encoder.blocks.10.norm1.weight grad: 0.0004915350582450628
sam_encoder.blocks.10.norm1.bias grad: 0.00016195484204217792
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00042000992107205093
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0002194062399212271
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00023508757294621319
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00010418061719974503
sam_encoder.blocks.10.norm2.weight grad: 1.6896170563995838e-05
sam_encoder.blocks.10.norm2.bias grad: -0.0005272122798487544
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.00027765659615397453
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.683411654899828e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00021229588310234249
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -0.00014178937999531627
sam_encoder.blocks.11.norm1.weight grad: 0.00149429845623672
sam_encoder.blocks.11.norm1.bias grad: 0.00010728494089562446
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0006631269934587181
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00018831701891031116
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0005036289803683758
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.0002145771577488631
sam_encoder.blocks.11.norm2.weight grad: 2.694675231396104e-06
sam_encoder.blocks.11.norm2.bias grad: -0.0002541413123253733
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0003847345942631364
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.442617162363604e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00024987029610201716
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.551766950404271e-05
sam_encoder.neck.conv1.trainable_scale grad: -2.7962494641542435e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0036240373738110065
sam_encoder.neck.conv2.trainable_scale grad: -3.9818231016397476e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0062422542832791805
mask_decoder.transformer.layers.0.norm1.weight grad: -0.01956888474524021
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00040357839316129684
mask_decoder.transformer.layers.0.norm2.weight grad: -1.2798759937286377
mask_decoder.transformer.layers.0.norm2.bias grad: 0.04006323590874672
mask_decoder.transformer.layers.0.norm3.weight grad: -0.013008790090680122
mask_decoder.transformer.layers.0.norm3.bias grad: -0.003061116673052311
mask_decoder.transformer.layers.0.norm4.weight grad: 0.022059960290789604
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0007420196197926998
mask_decoder.transformer.layers.1.norm1.weight grad: 0.008647707290947437
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0002845386043190956
mask_decoder.transformer.layers.1.norm2.weight grad: -0.014941925182938576
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0018257945775985718
mask_decoder.transformer.layers.1.norm3.weight grad: 0.009197795763611794
mask_decoder.transformer.layers.1.norm3.bias grad: 0.008702907711267471
mask_decoder.transformer.layers.1.norm4.weight grad: -0.010209673084318638
mask_decoder.transformer.layers.1.norm4.bias grad: -0.030433328822255135
mask_decoder.transformer.norm_final_attn.weight grad: 0.0006198977353051305
mask_decoder.transformer.norm_final_attn.bias grad: 0.0021733897738158703
Text_Embedding_Affine.0.weight grad: -1.3443819391056877e-09
Text_Embedding_Affine.0.bias grad: -3.3160176826640964e-08
Text_Embedding_Affine.2.weight grad: 1.2700260398901264e-08
Text_Embedding_Affine.2.bias grad: 0.004314744845032692

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.3288332322139206e-15
Max value: 0.999940037727356
Mean value: 0.08304418623447418

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3288332322139206e-15
Max value: 0.999940037727356
Mean value: 0.08304418623447418

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08007383346557617

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11721032857894897

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07614850997924805

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08007383346557617

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 25.57598876953125
Max value: 76.31194305419922
Mean value: 53.41713333129883

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.3288332322139206e-15
Max value: 0.999940037727356
Mean value: 0.08304418623447418

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3288332322139206e-15
Max value: 0.999940037727356
Mean value: 0.08304418623447418

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3288332322139206e-15
Max value: 0.999940037727356
Mean value: 0.08304418623447418

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11721032857894897

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 25.57598876953125
Max value: 76.31194305419922
Mean value: 53.41713333129883

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.41810989379883
Max value: -53.41810989379883
Mean value: -53.41810989379883
sam_encoder.pos_embed grad: 6.368233016473823e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0015239508356899023
sam_encoder.blocks.0.norm1.bias grad: 0.002945044543594122
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.643688251031563e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.8962243454298005e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.105072679929435e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00010148208093596622
sam_encoder.blocks.0.norm2.weight grad: 0.005202382802963257
sam_encoder.blocks.0.norm2.bias grad: -0.004151677712798119
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.002366425935178995
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0006222990341484547
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0008820525254122913
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0002501082781236619
sam_encoder.blocks.1.norm1.weight grad: -0.00036784191615879536
sam_encoder.blocks.1.norm1.bias grad: 0.00019890614203177392
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00019537762273103
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.801940177567303e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.000437353941379115
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00014495078357867897
sam_encoder.blocks.1.norm2.weight grad: -0.0007412069826386869
sam_encoder.blocks.1.norm2.bias grad: 0.0006558093591593206
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0008440220262855291
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00011007831199094653
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0013237057719379663
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00023307748779188842
sam_encoder.blocks.2.norm1.weight grad: -0.0013325877953320742
sam_encoder.blocks.2.norm1.bias grad: 0.00016280426643788815
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0005417615175247192
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00024592704721726477
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003679325745906681
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000169351274962537
sam_encoder.blocks.2.norm2.weight grad: 0.00031273544300347567
sam_encoder.blocks.2.norm2.bias grad: -0.0010624660644680262
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00010801706230267882
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00012289988808333874
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0007480063359253109
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00017261144239455462
sam_encoder.blocks.3.norm1.weight grad: -0.0009983903728425503
sam_encoder.blocks.3.norm1.bias grad: 9.25877466215752e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0013406699290499091
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00037147788680158556
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0006514447741210461
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0005419265944510698
sam_encoder.blocks.3.norm2.weight grad: -0.000642758677713573
sam_encoder.blocks.3.norm2.bias grad: -0.0014898031949996948
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0006055041449144483
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.889753528113943e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.308166560600512e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00011902502592420205
sam_encoder.blocks.4.norm1.weight grad: 0.0011941486736759543
sam_encoder.blocks.4.norm1.bias grad: -0.0008975345990620553
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0007555544143542647
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00024559718440286815
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0001095569459721446
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.040227991528809e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0016620744718238711
sam_encoder.blocks.4.norm2.bias grad: -0.0009272724273614585
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.001078817411325872
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00031443845364265144
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00021015375386923552
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00012719232472591102
sam_encoder.blocks.5.norm1.weight grad: -0.00035511513124220073
sam_encoder.blocks.5.norm1.bias grad: -0.0009024086757563055
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.954928489401937e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.15335991117172e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00015576415171381086
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.16555368853733e-05
sam_encoder.blocks.5.norm2.weight grad: -0.0006552952108904719
sam_encoder.blocks.5.norm2.bias grad: -0.0003747306764125824
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0002774724271148443
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.023946768138558e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.090011861990206e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.2125960893172305e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0006900432053953409
sam_encoder.blocks.6.norm1.bias grad: -0.0003781625418923795
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00018791788897942752
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.312600402859971e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00016837158182170242
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00023850379511713982
sam_encoder.blocks.6.norm2.weight grad: -0.00029327746597118676
sam_encoder.blocks.6.norm2.bias grad: 0.000315438344841823
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00028354368987493217
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.300120680360124e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00012687449634540826
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.258850332116708e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00015403427823912352
sam_encoder.blocks.7.norm1.bias grad: -0.00010455983283463866
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0001363895135000348
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6089708879007958e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00022590984008274972
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00026749103562906384
sam_encoder.blocks.7.norm2.weight grad: -0.00020853083697147667
sam_encoder.blocks.7.norm2.bias grad: 2.776722794806119e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.069988689385355e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0001473589363740757
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.521954780211672e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.6281490388792008e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0003213913587387651
sam_encoder.blocks.8.norm1.bias grad: -0.00013985765690449625
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003184203233104199
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00014134299999568611
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00031547946855425835
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00033066602190956473
sam_encoder.blocks.8.norm2.weight grad: -0.0007363946060650051
sam_encoder.blocks.8.norm2.bias grad: -0.0001713167002890259
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0007971012964844704
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0004144689009990543
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.000347908993717283
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00012725092528853565
sam_encoder.blocks.9.norm1.weight grad: -0.000436664093285799
sam_encoder.blocks.9.norm1.bias grad: -8.107879693852738e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0004046379472129047
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0002132722147507593
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0001230687485076487
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00010524563549552113
sam_encoder.blocks.9.norm2.weight grad: -0.0008446708088740706
sam_encoder.blocks.9.norm2.bias grad: -3.5865097743226215e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0006664730608463287
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0003675075713545084
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.018557855393738e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.200549978530034e-05
sam_encoder.blocks.10.norm1.weight grad: 4.6004424802958965e-05
sam_encoder.blocks.10.norm1.bias grad: -8.194197289412841e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.5514331102604046e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.5529076335951686e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6801568563096225e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.357196899538394e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0016210873145610094
sam_encoder.blocks.10.norm2.bias grad: -0.0001611004554433748
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0007898639305494726
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00047575979260727763
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0001377963781123981
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.526353485649452e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0009892159141600132
sam_encoder.blocks.11.norm1.bias grad: 1.5888435882516205e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00013902891078032553
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.495808287989348e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.540785110089928e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.798013858613558e-05
sam_encoder.blocks.11.norm2.weight grad: -0.001763427397236228
sam_encoder.blocks.11.norm2.bias grad: -1.5414010704262182e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0006875414401292801
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00036624353379011154
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00012199443153804168
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.813344513531774e-05
sam_encoder.neck.conv1.trainable_scale grad: -5.1261973567306995e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0015684326644986868
sam_encoder.neck.conv2.trainable_scale grad: -3.1578121706843376e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.00045152223901823163
mask_decoder.transformer.layers.0.norm1.weight grad: -0.004743611440062523
mask_decoder.transformer.layers.0.norm1.bias grad: 7.891282439231873e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.03141404688358307
mask_decoder.transformer.layers.0.norm2.bias grad: 0.04966254532337189
mask_decoder.transformer.layers.0.norm3.weight grad: -0.003171779215335846
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0029656607657670975
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0005061354022473097
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000251048244535923
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0023553369101136923
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00022699718829244375
mask_decoder.transformer.layers.1.norm2.weight grad: 0.01855049654841423
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0034422888420522213
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0033178518060594797
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0027224174700677395
mask_decoder.transformer.layers.1.norm4.weight grad: 0.004780324175953865
mask_decoder.transformer.layers.1.norm4.bias grad: 0.006231497973203659
mask_decoder.transformer.norm_final_attn.weight grad: 4.776025889441371e-06
mask_decoder.transformer.norm_final_attn.bias grad: -0.0001275929098483175
Text_Embedding_Affine.0.weight grad: 1.1146638057013547e-09
Text_Embedding_Affine.0.bias grad: 2.9569491744041443e-08
Text_Embedding_Affine.2.weight grad: -4.562957789389088e-10
Text_Embedding_Affine.2.bias grad: 7.845135405659676e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.59660963663265e-14
Max value: 0.9977238774299622
Mean value: 0.07585439085960388

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.59660963663265e-14
Max value: 0.9977238774299622
Mean value: 0.07585439085960388

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07691574096679688

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11739986389875412

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05921649932861328

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07691574096679688

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 37.099491119384766
Max value: 64.33676147460938
Mean value: 52.737640380859375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.59660963663265e-14
Max value: 0.9977238774299622
Mean value: 0.07585439085960388

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.59660963663265e-14
Max value: 0.9977238774299622
Mean value: 0.07585439085960388

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.59660963663265e-14
Max value: 0.9977238774299622
Mean value: 0.07585439085960388

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11739986389875412

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 37.099491119384766
Max value: 64.33676147460938
Mean value: 52.737640380859375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.7389030456543
Max value: -52.7389030456543
Mean value: -52.7389030456543
sam_encoder.pos_embed grad: -2.849906479696074e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0023406127002090216
sam_encoder.blocks.0.norm1.bias grad: 0.004405918996781111
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0011517172679305077
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.984810897847638e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.71293278678786e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00010426749213365838
sam_encoder.blocks.0.norm2.weight grad: 0.0004923112574033439
sam_encoder.blocks.0.norm2.bias grad: 0.003201468614861369
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0008789391140453517
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00018820908735506237
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0022572819143533707
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0007730176439508796
sam_encoder.blocks.1.norm1.weight grad: 0.0004737412673421204
sam_encoder.blocks.1.norm1.bias grad: 0.0013390490785241127
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005380032816901803
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0001532562164356932
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0004582850669976324
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0001399590983055532
sam_encoder.blocks.1.norm2.weight grad: 0.0010850261896848679
sam_encoder.blocks.1.norm2.bias grad: -0.0008942936547100544
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00015862395230215043
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.5900112784001976e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0005359036149457097
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.281487053958699e-05
sam_encoder.blocks.2.norm1.weight grad: -9.689257421996444e-05
sam_encoder.blocks.2.norm1.bias grad: -0.0007558485376648605
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00036184588680043817
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.527754466223996e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00028482626657932997
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0005997053813189268
sam_encoder.blocks.2.norm2.weight grad: 0.0007558108191005886
sam_encoder.blocks.2.norm2.bias grad: -9.812490316107869e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00026344205252826214
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.096013824688271e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 8.553349471185356e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.673991886898875e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0002028981689363718
sam_encoder.blocks.3.norm1.bias grad: -0.0006045548943802714
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.802118958948995e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.813688378315419e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0001412140263710171
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0002407860301900655
sam_encoder.blocks.3.norm2.weight grad: 0.0006996958400122821
sam_encoder.blocks.3.norm2.bias grad: 0.0005393080646172166
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0006376297678798437
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00015731356688775122
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00015461756265722215
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.6183566155377775e-05
sam_encoder.blocks.4.norm1.weight grad: -0.0006463518366217613
sam_encoder.blocks.4.norm1.bias grad: -0.00038316030986607075
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0003933912084903568
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.198965820658486e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.624650369398296e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.762511136708781e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0006085726199671626
sam_encoder.blocks.4.norm2.bias grad: 0.0003125338989775628
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.737896961160004e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.536773773608729e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00024633551947772503
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.953439489938319e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0005687284865416586
sam_encoder.blocks.5.norm1.bias grad: -0.001083799754269421
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0006405994645319879
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.116099004633725e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00017214046965818852
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00042097558616660535
sam_encoder.blocks.5.norm2.weight grad: 0.00033209891989827156
sam_encoder.blocks.5.norm2.bias grad: -0.00022789998911321163
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.12169343791902e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.7209123800275847e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00011101237032562494
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.7150697860633954e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0004960811347700655
sam_encoder.blocks.6.norm1.bias grad: -0.00010341567394789308
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0005753575824201107
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0002511492930352688
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00012588585377670825
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.046252044849098e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0007761400192975998
sam_encoder.blocks.6.norm2.bias grad: -2.508952093194239e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00044467876432463527
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00017097980889957398
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00014407106209546328
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.346181908156723e-05
sam_encoder.blocks.7.norm1.weight grad: 4.058676859131083e-05
sam_encoder.blocks.7.norm1.bias grad: 0.0002043876302195713
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.16592582850717e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.5287219361634925e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.434324702946469e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.7590717915445566e-05
sam_encoder.blocks.7.norm2.weight grad: 0.0005369819700717926
sam_encoder.blocks.7.norm2.bias grad: 6.208941340446472e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.7250811197300209e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.450597771210596e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.563529602019116e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.043227429268882e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0005938130198046565
sam_encoder.blocks.8.norm1.bias grad: 0.0001911378203658387
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0009453759412281215
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00039511764771305025
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0002240172470919788
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00020564600708894432
sam_encoder.blocks.8.norm2.weight grad: 0.00027443451108410954
sam_encoder.blocks.8.norm2.bias grad: -0.0001538320502731949
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00016306462930515409
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.779123552609235e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.020121898269281e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.815714191863663e-07
sam_encoder.blocks.9.norm1.weight grad: -0.0002590710355434567
sam_encoder.blocks.9.norm1.bias grad: 0.0001897854235721752
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00025057236780412495
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.5636265490902588e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.950007784529589e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.248472295235842e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0007453075959347188
sam_encoder.blocks.9.norm2.bias grad: -0.0001244154991582036
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0005163996247574687
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00027696412871591747
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.128453242126852e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.6857933360370225e-06
sam_encoder.blocks.10.norm1.weight grad: -9.294900519307703e-05
sam_encoder.blocks.10.norm1.bias grad: 6.604580266866833e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.6321616284549236e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.9296934371814132e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.622643139853608e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.551055556272331e-07
sam_encoder.blocks.10.norm2.weight grad: 0.0007050118292681873
sam_encoder.blocks.10.norm2.bias grad: -0.00014568031474482268
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0003988365060649812
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00016810325905680656
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.589034016244113e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.448974919389002e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0001339073060080409
sam_encoder.blocks.11.norm1.bias grad: 4.212378917145543e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00012173011782579124
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.6671657906263135e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.7433421817258932e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.735000271059107e-05
sam_encoder.blocks.11.norm2.weight grad: 4.882098801317625e-05
sam_encoder.blocks.11.norm2.bias grad: -0.0004622611158993095
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00029651724616996944
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.8935006412211806e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0001690371718723327
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.8029066268354654e-05
sam_encoder.neck.conv1.trainable_scale grad: -1.6832549590617418e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0002733177097979933
sam_encoder.neck.conv2.trainable_scale grad: -2.388888970017433e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0016940025379881263
mask_decoder.transformer.layers.0.norm1.weight grad: -0.011960337869822979
mask_decoder.transformer.layers.0.norm1.bias grad: -4.033511504530907e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.5849708318710327
mask_decoder.transformer.layers.0.norm2.bias grad: -0.007855048403143883
mask_decoder.transformer.layers.0.norm3.weight grad: -0.011647159233689308
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0029120370745658875
mask_decoder.transformer.layers.0.norm4.weight grad: 0.007473018020391464
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0006144416984170675
mask_decoder.transformer.layers.1.norm1.weight grad: 0.007404149975627661
mask_decoder.transformer.layers.1.norm1.bias grad: -5.295570008456707e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0004712422378361225
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004306240007281303
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0034444606862962246
mask_decoder.transformer.layers.1.norm3.bias grad: 0.005758428946137428
mask_decoder.transformer.layers.1.norm4.weight grad: -0.004095160402357578
mask_decoder.transformer.layers.1.norm4.bias grad: -0.01335813757032156
mask_decoder.transformer.norm_final_attn.weight grad: 0.000679010059684515
mask_decoder.transformer.norm_final_attn.bias grad: 0.0013520554639399052
Text_Embedding_Affine.0.weight grad: -1.4410473925252631e-09
Text_Embedding_Affine.0.bias grad: -6.877235136926174e-08
Text_Embedding_Affine.2.weight grad: -8.497471615243057e-10
Text_Embedding_Affine.2.bias grad: 0.0003498590085655451
Epoch 25 finished with average loss: -53.2944
Epoch 26/39
----------
Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s, loss=-51.7]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-51.7]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-56]  Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-56]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-55.2]Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.25it/s, loss=-55.2]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.8623789102844022e-11
Max value: 0.9985873699188232
Mean value: 0.0770031064748764

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8623789102844022e-11
Max value: 0.9985873699188232
Mean value: 0.0770031064748764

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08179903030395508

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.165346145629883
Max value: -1.1920928244535389e-07
Mean value: -0.1249055415391922

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06435298919677734

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08179903030395508

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 9.440128326416016
Max value: 82.8065185546875
Mean value: 51.74205017089844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.8623789102844022e-11
Max value: 0.9985873699188232
Mean value: 0.0770031064748764

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8623789102844022e-11
Max value: 0.9985873699188232
Mean value: 0.0770031064748764

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8623789102844022e-11
Max value: 0.9985873699188232
Mean value: 0.0770031064748764

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.165346145629883
Max value: -1.1920928244535389e-07
Mean value: -0.1249055415391922

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 9.440128326416016
Max value: 82.8065185546875
Mean value: 51.74205017089844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -51.743160247802734
Max value: -51.743160247802734
Mean value: -51.743160247802734
sam_encoder.pos_embed grad: -6.915693973041925e-08
sam_encoder.blocks.0.norm1.weight grad: -0.000518388522323221
sam_encoder.blocks.0.norm1.bias grad: -0.0013877039309591055
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.596497693564743e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.8566826586029492e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00038606332964263856
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0001412959973094985
sam_encoder.blocks.0.norm2.weight grad: 0.001886589452624321
sam_encoder.blocks.0.norm2.bias grad: -0.0009471820667386055
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0008533882792107761
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00014696239668410271
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0007198324310593307
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0001903817756101489
sam_encoder.blocks.1.norm1.weight grad: 7.90622434578836e-05
sam_encoder.blocks.1.norm1.bias grad: 0.0013392757391557097
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0002999305725097656
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00017218738503288478
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00037440028972923756
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00017213616229128093
sam_encoder.blocks.1.norm2.weight grad: -0.00040362318395636976
sam_encoder.blocks.1.norm2.bias grad: -0.00022191705647855997
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.335091373126488e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.1963076758547686e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0014517863746732473
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00025346025358885527
sam_encoder.blocks.2.norm1.weight grad: -0.0006613619043491781
sam_encoder.blocks.2.norm1.bias grad: 0.0006372327916324139
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0006495311390608549
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00015647069085389376
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0005234041600488126
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0002017623046413064
sam_encoder.blocks.2.norm2.weight grad: 9.523293556412682e-05
sam_encoder.blocks.2.norm2.bias grad: -0.0008807340636849403
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.4199787478428334e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.271233385428786e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0004589771560858935
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7198188288602978e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0010508120758458972
sam_encoder.blocks.3.norm1.bias grad: 0.00014404913235921413
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.00010360377928009257
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00010102021042257547
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0001454161392757669
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0002840085653588176
sam_encoder.blocks.3.norm2.weight grad: -0.0016135459300130606
sam_encoder.blocks.3.norm2.bias grad: -0.000592990720178932
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0012642326764762402
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00038300507003441453
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.2041455117214355e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3607370419776998e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0012958658626303077
sam_encoder.blocks.4.norm1.bias grad: -0.0005738057661801577
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0007837701123207808
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001889440172817558
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00016434848657809198
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.0108025637455285e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0013647731393575668
sam_encoder.blocks.4.norm2.bias grad: 0.0004891909775324166
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0010367876384407282
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00029317400185391307
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00024995056446641684
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.525409192661755e-05
sam_encoder.blocks.5.norm1.weight grad: 4.978930519428104e-05
sam_encoder.blocks.5.norm1.bias grad: -0.0004970621084794402
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00025659194216132164
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0002767262631095946
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.97058208566159e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.9677571951178834e-05
sam_encoder.blocks.5.norm2.weight grad: -0.0012385410955175757
sam_encoder.blocks.5.norm2.bias grad: 0.00017498046508990228
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0004960611695423722
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00014056707732379436
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.795105582568794e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.2686224333010614e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00012457931006792933
sam_encoder.blocks.6.norm1.bias grad: -0.0001416838204022497
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00018500880105420947
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00013988357386551797
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.168266504071653e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.545385546516627e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0008456972427666187
sam_encoder.blocks.6.norm2.bias grad: 0.00025857030414044857
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0005672305705957115
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0002770691062323749
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00020156055688858032
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.3836640290683135e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00010071869473904371
sam_encoder.blocks.7.norm1.bias grad: -0.00011590460781008005
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00013403705088421702
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.810723137576133e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.402577416040003e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.5472443161997944e-05
sam_encoder.blocks.7.norm2.weight grad: -0.00014103605644777417
sam_encoder.blocks.7.norm2.bias grad: 6.87314459355548e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.072027513757348e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.705445750616491e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.4539038349757902e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.600639714335557e-06
sam_encoder.blocks.8.norm1.weight grad: 0.0002537695108912885
sam_encoder.blocks.8.norm1.bias grad: 7.554265175713226e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003603346413001418
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00019302101281937212
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.000232296297326684
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00021714117610827088
sam_encoder.blocks.8.norm2.weight grad: 0.0001362012990284711
sam_encoder.blocks.8.norm2.bias grad: 0.00022386368073057383
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.137708987807855e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.1176918633282185e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00014602200826629996
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.674662730190903e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0001497731718700379
sam_encoder.blocks.9.norm1.bias grad: -1.8181619452661835e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00025221813120879233
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00014206612831912935
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.0001559474185341969
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00011888145672855899
sam_encoder.blocks.9.norm2.weight grad: 2.7324442271492444e-05
sam_encoder.blocks.9.norm2.bias grad: 0.00026137172244489193
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00020386793767102063
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.582409019349143e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.000139711526571773
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.0586688050534576e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00013926973042543977
sam_encoder.blocks.10.norm1.bias grad: -0.00011501980770844966
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.510235834866762e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.135959544437355e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.115428838413209e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.2148887587245554e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00031760448473505676
sam_encoder.blocks.10.norm2.bias grad: 3.0324741601361893e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00022582535166293383
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00014203086902853101
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00014587465557269752
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.0686033167294227e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00011919200187548995
sam_encoder.blocks.11.norm1.bias grad: -9.991932165576145e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.995723065803759e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.981186015764251e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00021188973914831877
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00012982047337573022
sam_encoder.blocks.11.norm2.weight grad: -6.118955207057297e-05
sam_encoder.blocks.11.norm2.bias grad: -0.00023223226889967918
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.685786941787228e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.239248952828348e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.0001276728289667517
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.050643474329263e-05
sam_encoder.neck.conv1.trainable_scale grad: 5.549739580601454e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.00039186503272503614
sam_encoder.neck.conv2.trainable_scale grad: 0.00011804274981841445
sam_encoder.neck.conv2.trainable_shift grad: -0.0022194001358002424
mask_decoder.transformer.layers.0.norm1.weight grad: 0.010457135736942291
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0003750389441847801
mask_decoder.transformer.layers.0.norm2.weight grad: 0.4061915874481201
mask_decoder.transformer.layers.0.norm2.bias grad: -0.05904126167297363
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0015495396219193935
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0027269190177321434
mask_decoder.transformer.layers.0.norm4.weight grad: -0.007306003011763096
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00015830749180167913
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0020190351642668247
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0003544075007084757
mask_decoder.transformer.layers.1.norm2.weight grad: 0.017658323049545288
mask_decoder.transformer.layers.1.norm2.bias grad: 0.001523391343653202
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0041389381512999535
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0009158565662801266
mask_decoder.transformer.layers.1.norm4.weight grad: 0.002715985756367445
mask_decoder.transformer.layers.1.norm4.bias grad: 0.010038943961262703
mask_decoder.transformer.norm_final_attn.weight grad: -0.00025061622727662325
mask_decoder.transformer.norm_final_attn.bias grad: -0.0006894519901834428
Text_Embedding_Affine.0.weight grad: -1.081187639417891e-10
Text_Embedding_Affine.0.bias grad: 3.9726728573441505e-09
Text_Embedding_Affine.2.weight grad: -1.6115553336248922e-08
Text_Embedding_Affine.2.bias grad: -0.00468905596062541

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2901623129210615e-12
Max value: 0.9988817572593689
Mean value: 0.09368287771940231

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2901623129210615e-12
Max value: 0.9988817572593689
Mean value: 0.09368287771940231

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08971071243286133

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.92509651184082
Max value: -1.1920928244535389e-07
Mean value: -0.11769329756498337

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08435297012329102

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08971071243286133

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.2701416015625
Max value: 71.84420776367188
Mean value: 60.255943298339844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2901623129210615e-12
Max value: 0.9988817572593689
Mean value: 0.09368287771940231

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2901623129210615e-12
Max value: 0.9988817572593689
Mean value: 0.09368287771940231

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2901623129210615e-12
Max value: 0.9988817572593689
Mean value: 0.09368287771940231

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.92509651184082
Max value: -1.1920928244535389e-07
Mean value: -0.11769329756498337

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.2701416015625
Max value: 71.84420776367188
Mean value: 60.255943298339844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.257286071777344
Max value: -60.257286071777344
Mean value: -60.257286071777344
sam_encoder.pos_embed grad: 7.509329691401945e-08
sam_encoder.blocks.0.norm1.weight grad: 0.004253485705703497
sam_encoder.blocks.0.norm1.bias grad: 0.0006175771122798324
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0008750820416025817
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.613014319445938e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00022827275097370148
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.775595440762118e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0016127884155139327
sam_encoder.blocks.0.norm2.bias grad: -0.0027888766489923
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0012790056644007564
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0003014794201590121
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.5743289370439015e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00014115292287897319
sam_encoder.blocks.1.norm1.weight grad: 0.00020524153660517186
sam_encoder.blocks.1.norm1.bias grad: 0.0003258046635892242
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0002665939391590655
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.659180846530944e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00035886684781871736
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00013165120617486537
sam_encoder.blocks.1.norm2.weight grad: 0.001073684194125235
sam_encoder.blocks.1.norm2.bias grad: 9.854394011199474e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00036360009107738733
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001166022484540008
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0007529863505624235
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00011286091466899961
sam_encoder.blocks.2.norm1.weight grad: -0.0015323623083531857
sam_encoder.blocks.2.norm1.bias grad: 0.0002742944343481213
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008443379192613065
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00021832832135260105
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003585111116990447
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.039689808152616e-05
sam_encoder.blocks.2.norm2.weight grad: 4.866502058575861e-05
sam_encoder.blocks.2.norm2.bias grad: -0.0005381869268603623
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00046092504635453224
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00012540232273750007
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005017074872739613
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00016546566621400416
sam_encoder.blocks.3.norm1.weight grad: 0.00013031040725763887
sam_encoder.blocks.3.norm1.bias grad: 0.0003507416695356369
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0008580964058637619
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0001928730052895844
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005358475027605891
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00022576012997888029
sam_encoder.blocks.3.norm2.weight grad: 0.0003065782366320491
sam_encoder.blocks.3.norm2.bias grad: -6.739655509591103e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.8233465855009854e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00015103908663149923
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0005289737600833178
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0002726527745835483
sam_encoder.blocks.4.norm1.weight grad: 0.0005984645686112344
sam_encoder.blocks.4.norm1.bias grad: -0.0003187380207236856
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00034446429344825447
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.610748823732138e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.4084368710173294e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.643931657075882e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0016036583110690117
sam_encoder.blocks.4.norm2.bias grad: -0.001383526949211955
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0012331216130405664
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.000398949341615662
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0003703365509863943
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0001732718519633636
sam_encoder.blocks.5.norm1.weight grad: -0.00033524027094244957
sam_encoder.blocks.5.norm1.bias grad: -0.001056480105035007
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00039767695125192404
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0002363824751228094
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.015220813220367e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.869123661890626e-05
sam_encoder.blocks.5.norm2.weight grad: -0.001527222222648561
sam_encoder.blocks.5.norm2.bias grad: -0.0009495836566202343
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0005280803306959569
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00018429997726343572
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -7.665706652915105e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.916350422310643e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0007935040048323572
sam_encoder.blocks.6.norm1.bias grad: -0.0002907929301727563
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.000500342866871506
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00015487425844185054
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00014356574683915824
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00021141182514838874
sam_encoder.blocks.6.norm2.weight grad: -0.0006362469866871834
sam_encoder.blocks.6.norm2.bias grad: 0.00014184467727318406
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0004946710541844368
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00016534817405045033
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.5997793020214885e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.154829184699338e-06
sam_encoder.blocks.7.norm1.weight grad: 6.252001912798733e-05
sam_encoder.blocks.7.norm1.bias grad: -2.9923641704954207e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0001622859126655385
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.768839451367967e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.000154761946760118
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003365831798873842
sam_encoder.blocks.7.norm2.weight grad: 0.00023152833455242217
sam_encoder.blocks.7.norm2.bias grad: -1.9591690943343565e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00027053867233917117
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0001011766362353228
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.035186717985198e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.65841731056571e-06
sam_encoder.blocks.8.norm1.weight grad: 3.173633012920618e-05
sam_encoder.blocks.8.norm1.bias grad: -0.00013190577737987041
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00013314753596205264
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0001512154849478975
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00019455974688753486
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00024394811771344393
sam_encoder.blocks.8.norm2.weight grad: -0.0005605492042377591
sam_encoder.blocks.8.norm2.bias grad: -0.0001453143631806597
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0005141180008649826
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0002632772666402161
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0003575080190785229
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00016366178169846535
sam_encoder.blocks.9.norm1.weight grad: -0.00031606905395165086
sam_encoder.blocks.9.norm1.bias grad: 1.383635935781058e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0002979995624627918
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.942978795152158e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.532759238732979e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00014689516683574766
sam_encoder.blocks.9.norm2.weight grad: -0.0006680515361949801
sam_encoder.blocks.9.norm2.bias grad: -0.0002805949770845473
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00038657322875224054
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00031596090411767364
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0001946047123055905
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.219791925512254e-05
sam_encoder.blocks.10.norm1.weight grad: 8.094493387034163e-05
sam_encoder.blocks.10.norm1.bias grad: 1.619523754925467e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.8829020923003554e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.434362148866057e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.7716977102682e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.19121128693223e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0008799041388556361
sam_encoder.blocks.10.norm2.bias grad: -0.0003465015906840563
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0002568286727182567
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0001849447435233742
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.950492388568819e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.272042860975489e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00013339135330170393
sam_encoder.blocks.11.norm1.bias grad: 8.954083023127168e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00015260698273777962
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1516119684529258e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00010108690185006708
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.956225843168795e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0007826613145880401
sam_encoder.blocks.11.norm2.bias grad: -5.181063897907734e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00019669193716254085
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00018951724632643163
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00015732375322841108
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00010713381198002025
sam_encoder.neck.conv1.trainable_scale grad: -0.0001599518582224846
sam_encoder.neck.conv1.trainable_shift grad: -0.0013671575579792261
sam_encoder.neck.conv2.trainable_scale grad: -0.00013063853839412332
sam_encoder.neck.conv2.trainable_shift grad: 0.0057046799920499325
mask_decoder.transformer.layers.0.norm1.weight grad: -0.009615777060389519
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00012608245015144348
mask_decoder.transformer.layers.0.norm2.weight grad: -0.1966707408428192
mask_decoder.transformer.layers.0.norm2.bias grad: 0.08603605628013611
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0008161577861756086
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0015082897152751684
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0023662843741476536
mask_decoder.transformer.layers.0.norm4.bias grad: -7.089151768013835e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0018299592193216085
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2657372280955315e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0058537693694233894
mask_decoder.transformer.layers.1.norm2.bias grad: 0.001412669662386179
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0035459501668810844
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0011645265622064471
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0036365496926009655
mask_decoder.transformer.layers.1.norm4.bias grad: -0.006576309911906719
mask_decoder.transformer.norm_final_attn.weight grad: 4.622604319592938e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0006253854953683913
Text_Embedding_Affine.0.weight grad: -7.278766478435728e-10
Text_Embedding_Affine.0.bias grad: -3.6263372749090195e-08
Text_Embedding_Affine.2.weight grad: 8.341766388753058e-09
Text_Embedding_Affine.2.bias grad: 0.002256432082504034

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.344786667224824e-12
Max value: 0.9960013031959534
Mean value: 0.08159862458705902

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.344786667224824e-12
Max value: 0.9960013031959534
Mean value: 0.08159862458705902

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07528877258300781

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.70042610168457
Max value: -1.1920928244535389e-07
Mean value: -0.11867086589336395

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0665140151977539

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07528877258300781

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.6085090637207
Max value: 55.87375259399414
Mean value: 53.476253509521484

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.344786667224824e-12
Max value: 0.9960013031959534
Mean value: 0.08159862458705902

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.344786667224824e-12
Max value: 0.9960013031959534
Mean value: 0.08159862458705902

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.344786667224824e-12
Max value: 0.9960013031959534
Mean value: 0.08159862458705902

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.70042610168457
Max value: -1.1920928244535389e-07
Mean value: -0.11867086589336395

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.6085090637207
Max value: 55.87375259399414
Mean value: 53.476253509521484

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.4775390625
Max value: -53.4775390625
Mean value: -53.4775390625
sam_encoder.pos_embed grad: 2.6469103886483936e-07
sam_encoder.blocks.0.norm1.weight grad: 0.002763599855825305
sam_encoder.blocks.0.norm1.bias grad: 0.002286989241838455
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0002888586022891104
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.9456154152285308e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00018456956604495645
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00010557682253420353
sam_encoder.blocks.0.norm2.weight grad: 0.003923952579498291
sam_encoder.blocks.0.norm2.bias grad: 0.0016154563054442406
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000493187690153718
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.365749166230671e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0017033012118190527
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0009919559815898538
sam_encoder.blocks.1.norm1.weight grad: -0.0009246771223843098
sam_encoder.blocks.1.norm1.bias grad: -3.789780748775229e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0011319855693727732
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0003061207535210997
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0008989237248897552
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0004199672839604318
sam_encoder.blocks.1.norm2.weight grad: -0.0013194669736549258
sam_encoder.blocks.1.norm2.bias grad: -0.00024282332742586732
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0008766194805502892
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00010555344488238916
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0010334611870348454
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00011087569146184251
sam_encoder.blocks.2.norm1.weight grad: -0.0019210990285500884
sam_encoder.blocks.2.norm1.bias grad: 0.00031859450973570347
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0015543708577752113
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0003008234780281782
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0008244516211561859
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0005982494330964983
sam_encoder.blocks.2.norm2.weight grad: 0.0007165797869674861
sam_encoder.blocks.2.norm2.bias grad: -0.0013228080933913589
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00022387935314327478
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0002672632981557399
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0004597303341142833
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.5656850993982516e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0001536347554065287
sam_encoder.blocks.3.norm1.bias grad: -8.855325859258301e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 6.677035707980394e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.056343772797845e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00014548550825566053
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00016033565043471754
sam_encoder.blocks.3.norm2.weight grad: -5.241405960987322e-05
sam_encoder.blocks.3.norm2.bias grad: -0.0007638311944901943
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.00027516213594935834
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.073262531775981e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00022032768174540251
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.339973368885694e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0010540082585066557
sam_encoder.blocks.4.norm1.bias grad: -0.0012304416159167886
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.000412417808547616
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001976865460164845
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00015818832616787404
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -8.411023009102792e-05
sam_encoder.blocks.4.norm2.weight grad: 0.002229105681180954
sam_encoder.blocks.4.norm2.bias grad: 0.002076354343444109
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0009236913174390793
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00035572395427152514
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.024481212487444e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.4330987798748538e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0016970018623396754
sam_encoder.blocks.5.norm1.bias grad: -0.0017646632622927427
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0015634631272405386
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0009411910432390869
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.512238178402185e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00011127225297968835
sam_encoder.blocks.5.norm2.weight grad: 0.0015924647450447083
sam_encoder.blocks.5.norm2.bias grad: 0.0011153551749885082
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0005065954755991697
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0001823540951590985
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00016455391596537083
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.550078640226275e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00027750362642109394
sam_encoder.blocks.6.norm1.bias grad: -0.0005560124991461635
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -7.366755744442344e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00022430214448831975
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00015450319915544242
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.835408566985279e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0005031171021983027
sam_encoder.blocks.6.norm2.bias grad: 0.00015699482173658907
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.7492183512076735e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.129374039825052e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.917091665556654e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.8715202612802386e-05
sam_encoder.blocks.7.norm1.weight grad: -8.341258944710717e-05
sam_encoder.blocks.7.norm1.bias grad: -2.268272146466188e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00011020658712368459
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.6541132683632895e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00017793521692510694
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.809643435990438e-05
sam_encoder.blocks.7.norm2.weight grad: -6.548924829985481e-06
sam_encoder.blocks.7.norm2.bias grad: -0.0001276418479392305
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0002751719148363918
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00013769151701126248
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.852645649109036e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.383665408473462e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0001509095454821363
sam_encoder.blocks.8.norm1.bias grad: 3.357872992637567e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003420225693844259
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00024932902306318283
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0002804854593705386
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00019699549011420459
sam_encoder.blocks.8.norm2.weight grad: -9.753162157721817e-05
sam_encoder.blocks.8.norm2.bias grad: 0.00020582470460794866
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0002845406124833971
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00012650375720113516
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.566487718373537e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.01440915488638e-05
sam_encoder.blocks.9.norm1.weight grad: 0.0001154129859060049
sam_encoder.blocks.9.norm1.bias grad: 2.9157279641367495e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.929912782041356e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.6419688917230815e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.2212006266927347e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.979197496548295e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0003854564856737852
sam_encoder.blocks.9.norm2.bias grad: 0.0002588752540759742
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0005498880054801702
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00020908207807224244
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00010858538735192269
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.185082798358053e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00044836028246209025
sam_encoder.blocks.10.norm1.bias grad: -6.176690658321604e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0004000919288955629
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00015799705579411238
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00022769502538722008
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00013859631144441664
sam_encoder.blocks.10.norm2.weight grad: -0.0005372286541387439
sam_encoder.blocks.10.norm2.bias grad: 0.00023927462461870164
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0004139879602007568
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00021542617469094694
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.98581765795825e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.0522587621817365e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0009762227418832481
sam_encoder.blocks.11.norm1.bias grad: -3.158932668156922e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.692859197850339e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.503014366084244e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0002475157380104065
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00010759135329863057
sam_encoder.blocks.11.norm2.weight grad: -0.00085779360961169
sam_encoder.blocks.11.norm2.bias grad: 6.353467324515805e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.000504413852468133
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0001520494115538895
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.8176716265734285e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.9593951694550924e-05
sam_encoder.neck.conv1.trainable_scale grad: 6.313319317996502e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0007200662512332201
sam_encoder.neck.conv2.trainable_scale grad: 0.00017275253776460886
sam_encoder.neck.conv2.trainable_shift grad: 0.0009561226470395923
mask_decoder.transformer.layers.0.norm1.weight grad: 0.013695765286684036
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00025874190032482147
mask_decoder.transformer.layers.0.norm2.weight grad: 0.6368921399116516
mask_decoder.transformer.layers.0.norm2.bias grad: -0.044263631105422974
mask_decoder.transformer.layers.0.norm3.weight grad: 0.009520115330815315
mask_decoder.transformer.layers.0.norm3.bias grad: 0.004246830474585295
mask_decoder.transformer.layers.0.norm4.weight grad: -0.012594154104590416
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0008574422681704164
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0018282760865986347
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00024466891773045063
mask_decoder.transformer.layers.1.norm2.weight grad: 0.015152061358094215
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0016167270950973034
mask_decoder.transformer.layers.1.norm3.weight grad: -0.006021711975336075
mask_decoder.transformer.layers.1.norm3.bias grad: -0.003743065521121025
mask_decoder.transformer.layers.1.norm4.weight grad: 0.004384397529065609
mask_decoder.transformer.layers.1.norm4.bias grad: 0.022665731608867645
mask_decoder.transformer.norm_final_attn.weight grad: -1.5110999811440706e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.002054681070148945
Text_Embedding_Affine.0.weight grad: 9.453209326437673e-10
Text_Embedding_Affine.0.bias grad: 2.8958311304450035e-08
Text_Embedding_Affine.2.weight grad: -7.485457587108613e-09
Text_Embedding_Affine.2.bias grad: -0.004395168274641037
Epoch 26 finished with average loss: -55.1593
Epoch 27/39
----------
Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.2]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.13it/s, loss=-56.2]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.13it/s, loss=-55.1]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-55.1]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-53.8]Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-53.8]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.5220909522237775e-10
Max value: 0.9935892820358276
Mean value: 0.08851529657840729

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5220909522237775e-10
Max value: 0.9935892820358276
Mean value: 0.08851529657840729

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08890819549560547

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.011886596679688
Max value: -1.1920928244535389e-07
Mean value: -0.11844980716705322

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08153009414672852

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08890819549560547

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.97590255737305
Max value: 83.52693939208984
Mean value: 56.166786193847656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.5220909522237775e-10
Max value: 0.9935892820358276
Mean value: 0.08851529657840729

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5220909522237775e-10
Max value: 0.9935892820358276
Mean value: 0.08851529657840729

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5220909522237775e-10
Max value: 0.9935892820358276
Mean value: 0.08851529657840729

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.011886596679688
Max value: -1.1920928244535389e-07
Mean value: -0.11844980716705322

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.97590255737305
Max value: 83.52693939208984
Mean value: 56.166786193847656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.16793441772461
Max value: -56.16793441772461
Mean value: -56.16793441772461
sam_encoder.pos_embed grad: 5.49295066321065e-07
sam_encoder.blocks.0.norm1.weight grad: -0.00022743949375580996
sam_encoder.blocks.0.norm1.bias grad: 0.001005850499495864
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0005365990218706429
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.831342837656848e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0002923141000792384
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0001016251917462796
sam_encoder.blocks.0.norm2.weight grad: -0.000915521930437535
sam_encoder.blocks.0.norm2.bias grad: -0.0019939891062676907
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00014796484902035445
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00017911776376422495
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0004941842635162175
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0001534342154627666
sam_encoder.blocks.1.norm1.weight grad: -0.001232565613463521
sam_encoder.blocks.1.norm1.bias grad: -0.0005109227495267987
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004768991784658283
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0001262971491087228
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.965909541468136e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.5246677725808695e-05
sam_encoder.blocks.1.norm2.weight grad: -0.0006547298980876803
sam_encoder.blocks.1.norm2.bias grad: 0.00025584810646250844
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0001129141601268202
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.7098124923650175e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00044284993782639503
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.748394273221493e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0005375075270421803
sam_encoder.blocks.2.norm1.bias grad: 0.0004107614513486624
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0002818226639647037
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.4150565372547135e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00011218768486287445
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00014266000653151423
sam_encoder.blocks.2.norm2.weight grad: 0.00045369495637714863
sam_encoder.blocks.2.norm2.bias grad: -0.0008034582133404911
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.000253483303822577
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00014724917127750814
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005810962757095695
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00016278673138003796
sam_encoder.blocks.3.norm1.weight grad: 0.0005250299000181258
sam_encoder.blocks.3.norm1.bias grad: 6.388811016222462e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.228770795743912e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.8510890590259805e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0001657601387705654
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00019547092961147428
sam_encoder.blocks.3.norm2.weight grad: -0.0020451329182833433
sam_encoder.blocks.3.norm2.bias grad: -0.0014612674713134766
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0015263499226421118
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0005195242119953036
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.0572944777086377e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.21549877198413e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0002848719013854861
sam_encoder.blocks.4.norm1.bias grad: -7.931666186777875e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00023427097767125815
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.979404472280294e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00017323749489150941
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.100767076422926e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0005160849541425705
sam_encoder.blocks.4.norm2.bias grad: 0.0001721506705507636
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0005847440916113555
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0002799867943394929
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.5863186490605585e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.4979202205722686e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0002256732404930517
sam_encoder.blocks.5.norm1.bias grad: 0.0005095461965538561
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.000347842404153198
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00013990807929076254
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.257584027480334e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00011542164429556578
sam_encoder.blocks.5.norm2.weight grad: -0.00012276401685085148
sam_encoder.blocks.5.norm2.bias grad: -0.00016896871966309845
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00015619132318533957
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.39669750246685e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.04044830147177e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.557972377166152e-05
sam_encoder.blocks.6.norm1.weight grad: -2.0976052837795578e-05
sam_encoder.blocks.6.norm1.bias grad: 0.0001161182444775477
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.353469946887344e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.1438789190142415e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00011088949395343661
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.054332334315404e-05
sam_encoder.blocks.6.norm2.weight grad: 0.00014231985551305115
sam_encoder.blocks.6.norm2.bias grad: 8.714006980881095e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.1639592887368053e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.055451063322835e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.922399527160451e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.8379772882326506e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00024145294446498156
sam_encoder.blocks.7.norm1.bias grad: -3.5771732655121014e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.7816643927944824e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.521704118407797e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0001180940234917216
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0001063797390088439
sam_encoder.blocks.7.norm2.weight grad: -0.0002894143108278513
sam_encoder.blocks.7.norm2.bias grad: -0.00010490728891454637
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0002625437336973846
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.585496885236353e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00011732070561265573
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00010124166146852076
sam_encoder.blocks.8.norm1.weight grad: 0.0007427572272717953
sam_encoder.blocks.8.norm1.bias grad: 7.571202877443284e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0008821864030323923
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.000377995049348101
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0001450464187655598
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00022959752823226154
sam_encoder.blocks.8.norm2.weight grad: -0.00017822551308199763
sam_encoder.blocks.8.norm2.bias grad: 7.22485565347597e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000151127198478207
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.4904397175996564e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.152046909031924e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.774434637511149e-05
sam_encoder.blocks.9.norm1.weight grad: 6.522718467749655e-05
sam_encoder.blocks.9.norm1.bias grad: -0.00010129711881745607
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00013037631288170815
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.75823695625877e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.5112068871967494e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.52074852748774e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0004509823047555983
sam_encoder.blocks.9.norm2.bias grad: 1.2836833775509149e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0003746091388165951
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00017966478480957448
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.978711902163923e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.087713776039891e-05
sam_encoder.blocks.10.norm1.weight grad: -5.9869460528716445e-05
sam_encoder.blocks.10.norm1.bias grad: -5.28895398019813e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.192822522483766e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.440232467255555e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.166255090851337e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.283917511813343e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0007653806824237108
sam_encoder.blocks.10.norm2.bias grad: -7.789558003423735e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00039752593147568405
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0002109785273205489
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5585863366140984e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.825059932045406e-06
sam_encoder.blocks.11.norm1.weight grad: -0.001074924017302692
sam_encoder.blocks.11.norm1.bias grad: -0.00010942134395008907
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00021635484881699085
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.491046300041489e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.621280383318663e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.2481124940677546e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0005968550103716552
sam_encoder.blocks.11.norm2.bias grad: -0.0001646259770495817
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00028679342358373106
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.47794144647196e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.1581014152616262e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.555658284109086e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.669834066182375e-05
sam_encoder.neck.conv1.trainable_shift grad: -1.2710923328995705e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.523689419031143e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0012341818073764443
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0012213557492941618
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00011061504483222961
mask_decoder.transformer.layers.0.norm2.weight grad: 0.24223066866397858
mask_decoder.transformer.layers.0.norm2.bias grad: 0.008635390549898148
mask_decoder.transformer.layers.0.norm3.weight grad: 0.01031793374568224
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0028695331420749426
mask_decoder.transformer.layers.0.norm4.weight grad: -0.006528068333864212
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0012765235733240843
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0009032211964949965
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0004979725345037878
mask_decoder.transformer.layers.1.norm2.weight grad: 0.009683319367468357
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0012830034829676151
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0001470037386752665
mask_decoder.transformer.layers.1.norm3.bias grad: 0.000381117599317804
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00040213880129158497
mask_decoder.transformer.layers.1.norm4.bias grad: 0.011976839043200016
mask_decoder.transformer.norm_final_attn.weight grad: -8.213784894905984e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0012033612001687288
Text_Embedding_Affine.0.weight grad: 1.226067691817434e-09
Text_Embedding_Affine.0.bias grad: 1.9957951735705137e-08
Text_Embedding_Affine.2.weight grad: -6.878060787585127e-09
Text_Embedding_Affine.2.bias grad: -0.002017352730035782

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.674035381484586e-11
Max value: 0.9961528182029724
Mean value: 0.09117390960454941

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.674035381484586e-11
Max value: 0.9961528182029724
Mean value: 0.09117390960454941

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08735084533691406

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12834566831588745

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07504796981811523

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08735084533691406

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.29104232788086
Max value: 69.37425231933594
Mean value: 54.065704345703125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.674035381484586e-11
Max value: 0.9961528182029724
Mean value: 0.09117390960454941

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.674035381484586e-11
Max value: 0.9961528182029724
Mean value: 0.09117390960454941

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.674035381484586e-11
Max value: 0.9961528182029724
Mean value: 0.09117390960454941

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12834566831588745

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.29104232788086
Max value: 69.37425231933594
Mean value: 54.065704345703125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.06708526611328
Max value: -54.06708526611328
Mean value: -54.06708526611328
sam_encoder.pos_embed grad: -3.246228743591928e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0009827811736613512
sam_encoder.blocks.0.norm1.bias grad: -0.0009778020903468132
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00048583879834041
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.035435136349406e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0006438366253860295
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00022500025806948543
sam_encoder.blocks.0.norm2.weight grad: -0.0011982773430645466
sam_encoder.blocks.0.norm2.bias grad: 0.002228501718491316
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0008103718282654881
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0005790646537207067
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0007397743756882846
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.000257361214607954
sam_encoder.blocks.1.norm1.weight grad: -0.0011703482596203685
sam_encoder.blocks.1.norm1.bias grad: -0.0004301910230424255
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0001316722627962008
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.978113328339532e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0001674145896686241
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 0.0001215363954543136
sam_encoder.blocks.1.norm2.weight grad: 0.0001510329602751881
sam_encoder.blocks.1.norm2.bias grad: 0.0002807246055454016
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.521705214865506e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.384971013379982e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0005487144808284938
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.601285324199125e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0004519820213317871
sam_encoder.blocks.2.norm1.bias grad: -0.0009317891672253609
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00015904437168501318
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.6309880670160055e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.794545045820996e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00021236459724605083
sam_encoder.blocks.2.norm2.weight grad: 0.0008827715064398944
sam_encoder.blocks.2.norm2.bias grad: -0.0005615950794890523
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.000716923619620502
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0001168239614344202
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00040302425622940063
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00011683616321533918
sam_encoder.blocks.3.norm1.weight grad: 0.000873367884196341
sam_encoder.blocks.3.norm1.bias grad: -0.0003454498655628413
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0007537147030234337
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00016050387057475746
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0004264322924427688
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00018273676687385887
sam_encoder.blocks.3.norm2.weight grad: 0.0005637626745738089
sam_encoder.blocks.3.norm2.bias grad: 0.0001778784644557163
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0003104961651843041
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.033502591482829e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.000271407887339592
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00012297029024921358
sam_encoder.blocks.4.norm1.weight grad: 0.000528778531588614
sam_encoder.blocks.4.norm1.bias grad: -0.000563291076105088
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00016983532987069339
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.14058439573273e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00010943393863271922
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00012907219934277236
sam_encoder.blocks.4.norm2.weight grad: -0.0002796905755531043
sam_encoder.blocks.4.norm2.bias grad: 0.0003765005967579782
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.228848360478878e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.563746865140274e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00013122854579705745
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.49224379635416e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0008717821910977364
sam_encoder.blocks.5.norm1.bias grad: -0.000503277056850493
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0007144962437450886
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0003750626929104328
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002372952876612544
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.798242247896269e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0005073934444226325
sam_encoder.blocks.5.norm2.bias grad: -3.077677683904767e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00023297776351682842
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.880511788651347e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001692708465270698
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.876066668657586e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00023463330580852926
sam_encoder.blocks.6.norm1.bias grad: 0.00016274199879262596
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00012239633360877633
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.8059431466972455e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.475663783727214e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.289342415286228e-05
sam_encoder.blocks.6.norm2.weight grad: -0.00025785129400901496
sam_encoder.blocks.6.norm2.bias grad: -0.0002470394829288125
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00011973601067438722
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.3521261027781293e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.993448914727196e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0114843007613672e-06
sam_encoder.blocks.7.norm1.weight grad: 0.0003122046182397753
sam_encoder.blocks.7.norm1.bias grad: 6.18806661805138e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00026670561055652797
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00013959358329884708
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0001694100210443139
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00025074335280805826
sam_encoder.blocks.7.norm2.weight grad: -8.132656148518436e-06
sam_encoder.blocks.7.norm2.bias grad: -7.179682143032551e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00013490280252881348
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.8097687390982173e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.5312812542542815e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.9362563762115315e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00017645912885200232
sam_encoder.blocks.8.norm1.bias grad: -3.455776459304616e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.09735475841444e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.375485099852085e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.265416646376252e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.757386315963231e-05
sam_encoder.blocks.8.norm2.weight grad: 0.0002344132517464459
sam_encoder.blocks.8.norm2.bias grad: -4.665363576350501e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00017790919810067862
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0001255935349036008
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0002325579262105748
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.017619595397264e-05
sam_encoder.blocks.9.norm1.weight grad: 0.000226950942305848
sam_encoder.blocks.9.norm1.bias grad: 4.234494917909615e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00016712088836356997
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.837275577709079e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.174186612246558e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.593587361043319e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0004087879788130522
sam_encoder.blocks.9.norm2.bias grad: 6.63125392748043e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00019026792142540216
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0001435077574569732
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.98670220724307e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.1706218325998634e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00017663417384028435
sam_encoder.blocks.10.norm1.bias grad: 3.955986903747544e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00010275994281983003
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.408918539411388e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.1592710001859814e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.8944254154339433e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0006001675501465797
sam_encoder.blocks.10.norm2.bias grad: 9.959172166418284e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0002268621901748702
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00011162435112055391
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.54189180850517e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.797141056973487e-06
sam_encoder.blocks.11.norm1.weight grad: 7.217474922072142e-05
sam_encoder.blocks.11.norm1.bias grad: 3.96221257688012e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.947747947880998e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.87882100767456e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.4008338439452928e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.6564036943454994e-06
sam_encoder.blocks.11.norm2.weight grad: 0.000476932356832549
sam_encoder.blocks.11.norm2.bias grad: -0.00017836973711382598
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0003216646146029234
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.976309956982732e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.7820561778498814e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.011900793761015e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.1748320907354355e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.001303676050156355
sam_encoder.neck.conv2.trainable_scale grad: 7.392605766654015e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.003536428790539503
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0030706252437084913
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0003799307160079479
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0790749192237854
mask_decoder.transformer.layers.0.norm2.bias grad: -0.05981394648551941
mask_decoder.transformer.layers.0.norm3.weight grad: -7.505447138100863e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00027434329967945814
mask_decoder.transformer.layers.0.norm4.weight grad: -2.3245695047080517e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -0.000114411988761276
mask_decoder.transformer.layers.1.norm1.weight grad: 0.00042658959864638746
mask_decoder.transformer.layers.1.norm1.bias grad: -2.4618377210572362e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.002923106076195836
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0006564261857420206
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0008332853903993964
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0001180375402327627
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0014503637794405222
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00290049915201962
mask_decoder.transformer.norm_final_attn.weight grad: 1.7603018932277337e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0005311910063028336
Text_Embedding_Affine.0.weight grad: 1.1164489333026495e-09
Text_Embedding_Affine.0.bias grad: 2.7706846594810486e-08
Text_Embedding_Affine.2.weight grad: -3.9369059123828265e-09
Text_Embedding_Affine.2.bias grad: -0.0011932896450161934

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0539357164773833e-09
Max value: 0.9913421273231506
Mean value: 0.06241385638713837

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0539357164773833e-09
Max value: 0.9913421273231506
Mean value: 0.06241385638713837

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06613731384277344

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.458176612854004
Max value: -1.1920928244535389e-07
Mean value: -0.1077740341424942

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05080890655517578

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06613731384277344

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 38.670326232910156
Max value: 67.7164077758789
Mean value: 51.16436767578125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0539357164773833e-09
Max value: 0.9913421273231506
Mean value: 0.06241385638713837

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0539357164773833e-09
Max value: 0.9913421273231506
Mean value: 0.06241385638713837

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0539357164773833e-09
Max value: 0.9913421273231506
Mean value: 0.06241385638713837

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.458176612854004
Max value: -1.1920928244535389e-07
Mean value: -0.1077740341424942

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 38.670326232910156
Max value: 67.7164077758789
Mean value: 51.16436767578125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -51.165374755859375
Max value: -51.165374755859375
Mean value: -51.165374755859375
sam_encoder.pos_embed grad: 9.770433280209545e-07
sam_encoder.blocks.0.norm1.weight grad: 0.006711920257657766
sam_encoder.blocks.0.norm1.bias grad: 0.0009077747818082571
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00041140359826385975
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.790647653862834e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0005593164823949337
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.233746833255282e-06
sam_encoder.blocks.0.norm2.weight grad: 0.0010806897189468145
sam_encoder.blocks.0.norm2.bias grad: -5.564128514379263e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.202647248050198e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0007103813695721328
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0030076480470597744
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.001765661290846765
sam_encoder.blocks.1.norm1.weight grad: 0.001034458982758224
sam_encoder.blocks.1.norm1.bias grad: 0.001688132411800325
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0009998136665672064
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00024767901049926877
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0009038324351422489
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.000345358595950529
sam_encoder.blocks.1.norm2.weight grad: -0.0007312146481126547
sam_encoder.blocks.1.norm2.bias grad: -0.0006306960131041706
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0006413906812667847
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.881958249025047e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0009735313942655921
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.270680412650108e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0024601854383945465
sam_encoder.blocks.2.norm1.bias grad: 0.0016613639891147614
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0016356650739908218
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0002434685593470931
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003051476087421179
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.71222437126562e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0002448486629873514
sam_encoder.blocks.2.norm2.bias grad: -0.0015233529265969992
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00017262638721149415
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.0003048512153327465
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0009769719326868653
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00013252068310976028
sam_encoder.blocks.3.norm1.weight grad: -0.00014239321171771735
sam_encoder.blocks.3.norm1.bias grad: 0.0012370599433779716
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00037546013481914997
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00012898881686851382
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0004115969641134143
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00029459339566528797
sam_encoder.blocks.3.norm2.weight grad: -0.0012013622326776385
sam_encoder.blocks.3.norm2.bias grad: -0.00036834459751844406
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0010407826630398631
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0002800527145154774
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00122174434363842
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0003239947254769504
sam_encoder.blocks.4.norm1.weight grad: -0.0006968695670366287
sam_encoder.blocks.4.norm1.bias grad: -0.00022128566342871636
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0003697462088894099
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.071633495390415e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0005344242672435939
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0005244881613180041
sam_encoder.blocks.4.norm2.weight grad: 0.0039519136771559715
sam_encoder.blocks.4.norm2.bias grad: 0.002403938677161932
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0019223246490582824
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0007418281165882945
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0006260768859647214
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00014502844715025276
sam_encoder.blocks.5.norm1.weight grad: -0.0011511323973536491
sam_encoder.blocks.5.norm1.bias grad: -0.0011202356545254588
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00037882098695263267
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00011291632836218923
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0005067100282758474
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.134028469910845e-05
sam_encoder.blocks.5.norm2.weight grad: 0.001140705542638898
sam_encoder.blocks.5.norm2.bias grad: 0.0014223845209926367
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00018460568389855325
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.869733912637457e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00019647703447844833
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.935171015560627e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0008625956252217293
sam_encoder.blocks.6.norm1.bias grad: -0.0011490097967907786
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00045862531987950206
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.3355561299686087e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00029800384072586894
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00015245229587890208
sam_encoder.blocks.6.norm2.weight grad: 0.001728953793644905
sam_encoder.blocks.6.norm2.bias grad: 0.0008029690361581743
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0009658008348196745
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0003010798245668411
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.496229277923703e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00012558663729578257
sam_encoder.blocks.7.norm1.weight grad: -0.0009778579697012901
sam_encoder.blocks.7.norm1.bias grad: -0.0001139549640356563
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0007542329258285463
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00037849671207368374
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0004954718169756234
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00033131003146991134
sam_encoder.blocks.7.norm2.weight grad: -9.201825014315546e-05
sam_encoder.blocks.7.norm2.bias grad: -0.00023871571465861052
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00046245043631643057
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00022351671941578388
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.9921120333019644e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00016471307026222348
sam_encoder.blocks.8.norm1.weight grad: -0.00045382531243376434
sam_encoder.blocks.8.norm1.bias grad: 0.0001628369209356606
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0002056527155218646
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.8542590371216647e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0006021656445227563
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0004074900643900037
sam_encoder.blocks.8.norm2.weight grad: -0.0005035861395299435
sam_encoder.blocks.8.norm2.bias grad: 0.0002808593853842467
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0007258201367221773
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0002947606553789228
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0003120055771432817
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2366045666567516e-05
sam_encoder.blocks.9.norm1.weight grad: -0.000324711058055982
sam_encoder.blocks.9.norm1.bias grad: 2.9014128813287243e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00042598461732268333
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0001879473275039345
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00015219746273942292
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.282250301912427e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0010494443122297525
sam_encoder.blocks.9.norm2.bias grad: -2.2826116037322208e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0009533773991279304
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00046476535499095917
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.0001951234880834818
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.9062797693768516e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0011259553721174598
sam_encoder.blocks.10.norm1.bias grad: -3.061741153942421e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0007950125145725906
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0002957078395411372
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.000344518746715039
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00018787987937685102
sam_encoder.blocks.10.norm2.weight grad: -0.002194114960730076
sam_encoder.blocks.10.norm2.bias grad: -0.0003633631858974695
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0011137346737086773
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0005864031845703721
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00026386516401544213
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.021298471139744e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0015882885782048106
sam_encoder.blocks.11.norm1.bias grad: 6.078800652176142e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.741597381827887e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.622612661682069e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00022718767286278307
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.41802214179188e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0022247517481446266
sam_encoder.blocks.11.norm2.bias grad: -0.00012525425700005144
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.001033687382005155
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00039334569009952247
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0002066645392915234
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00011037955846404657
sam_encoder.neck.conv1.trainable_scale grad: -6.31771981716156e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0009211848955601454
sam_encoder.neck.conv2.trainable_scale grad: 4.752539098262787e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0074764699675142765
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0015904172323644161
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00017165951430797577
mask_decoder.transformer.layers.0.norm2.weight grad: 0.6624257564544678
mask_decoder.transformer.layers.0.norm2.bias grad: 0.11852867156267166
mask_decoder.transformer.layers.0.norm3.weight grad: 0.01296488381922245
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0038918950594961643
mask_decoder.transformer.layers.0.norm4.weight grad: -0.012770624831318855
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0009615758899599314
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0009036042611114681
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0007439493201673031
mask_decoder.transformer.layers.1.norm2.weight grad: 0.026311900466680527
mask_decoder.transformer.layers.1.norm2.bias grad: 0.005529029760509729
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0017755503067746758
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0010474352166056633
mask_decoder.transformer.layers.1.norm4.weight grad: 0.010379200801253319
mask_decoder.transformer.layers.1.norm4.bias grad: 0.027023810893297195
mask_decoder.transformer.norm_final_attn.weight grad: 0.0002691031841095537
mask_decoder.transformer.norm_final_attn.bias grad: -0.0016268055187538266
Text_Embedding_Affine.0.weight grad: -1.9115047322770806e-09
Text_Embedding_Affine.0.bias grad: -4.413595888763666e-08
Text_Embedding_Affine.2.weight grad: -5.678005177145451e-09
Text_Embedding_Affine.2.bias grad: -0.002004306297749281
Epoch 27 finished with average loss: -53.8001
Epoch 28/39
----------
Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s, loss=-50.9]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-50.9]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-53.4]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-53.4]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-56.6]Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-56.6]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8134344720310835e-11
Max value: 0.9998718500137329
Mean value: 0.08288687467575073

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8134344720310835e-11
Max value: 0.9998718500137329
Mean value: 0.08288687467575073

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07815694808959961

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13427944481372833

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06951570510864258

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07815694808959961

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 32.67582321166992
Max value: 67.8998031616211
Mean value: 50.879364013671875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8134344720310835e-11
Max value: 0.9998718500137329
Mean value: 0.08288687467575073

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8134344720310835e-11
Max value: 0.9998718500137329
Mean value: 0.08288687467575073

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8134344720310835e-11
Max value: 0.9998718500137329
Mean value: 0.08288687467575073

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13427944481372833

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 32.67582321166992
Max value: 67.8998031616211
Mean value: 50.879364013671875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.88066864013672
Max value: -50.88066864013672
Mean value: -50.88066864013672
sam_encoder.pos_embed grad: 2.438610806621e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0010171551257371902
sam_encoder.blocks.0.norm1.bias grad: 0.0004541408270597458
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.285257141920738e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.7487981393933296e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00046053528785705566
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0001655292435316369
sam_encoder.blocks.0.norm2.weight grad: -0.0028385126497596502
sam_encoder.blocks.0.norm2.bias grad: 0.0005840572412125766
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.001747538335621357
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0006340824766084552
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0005049710161983967
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00017057584773283452
sam_encoder.blocks.1.norm1.weight grad: 0.00045613478869199753
sam_encoder.blocks.1.norm1.bias grad: 0.0009415766689926386
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004094139439985156
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0001337445864919573
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00028611821471713483
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.171890421072021e-05
sam_encoder.blocks.1.norm2.weight grad: 4.029165575047955e-05
sam_encoder.blocks.1.norm2.bias grad: -0.0005854748887941241
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0005552817601710558
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00012002522998955101
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.979020978789777e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.3148246327764355e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0011966994497925043
sam_encoder.blocks.2.norm1.bias grad: 0.00020939265959896147
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008270893013104796
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00031199745717458427
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00048195626004599035
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000370670051779598
sam_encoder.blocks.2.norm2.weight grad: -0.0014247042126953602
sam_encoder.blocks.2.norm2.bias grad: -0.0010821183677762747
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0006708410801365972
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001571580651216209
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00019241985864937305
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00017189850041177124
sam_encoder.blocks.3.norm1.weight grad: -0.0006016801344230771
sam_encoder.blocks.3.norm1.bias grad: -1.2839582268497907e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00035396486055105925
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.827150355093181e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00015611411072313786
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.993553299456835e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0010147634893655777
sam_encoder.blocks.3.norm2.bias grad: -0.00043090255348943174
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005894436035305262
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.140318434219807e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.155014564981684e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.585689986124635e-05
sam_encoder.blocks.4.norm1.weight grad: -0.0014149233466014266
sam_encoder.blocks.4.norm1.bias grad: 0.0007962527452036738
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0009882632875815034
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0003921652096323669
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.30000314838253e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00017474638298153877
sam_encoder.blocks.4.norm2.weight grad: -0.00015356687072198838
sam_encoder.blocks.4.norm2.bias grad: -0.0009256385965272784
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.516295302892104e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.59776128991507e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00011803150846390054
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.907589704496786e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0003484631306491792
sam_encoder.blocks.5.norm1.bias grad: 0.0008121882565319538
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0004241775022819638
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0002574212267063558
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.849946945905685e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00021571083925664425
sam_encoder.blocks.5.norm2.weight grad: -0.00010194527567364275
sam_encoder.blocks.5.norm2.bias grad: -0.0007250501657836139
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.11698706052266e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.3580665583722293e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00013576127821579576
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.5108681661076844e-05
sam_encoder.blocks.6.norm1.weight grad: 3.102202754234895e-05
sam_encoder.blocks.6.norm1.bias grad: 0.0003314153873361647
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0001325985649600625
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00011813222954515368
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.628344746990479e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.4457001927657984e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0002757604233920574
sam_encoder.blocks.6.norm2.bias grad: -0.00018005393212661147
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00013083683734294027
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 8.53991587064229e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.022301022312604e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.9884707569417515e-07
sam_encoder.blocks.7.norm1.weight grad: 0.00031977012986317277
sam_encoder.blocks.7.norm1.bias grad: 0.0002281524648424238
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00017331102571915835
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.8480884035816416e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00015371463086921722
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.974976663012058e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0003007969062309712
sam_encoder.blocks.7.norm2.bias grad: -0.0002232265833299607
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00015908222121652216
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00010062544606626034
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.263829320436344e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.842011938104406e-05
sam_encoder.blocks.8.norm1.weight grad: 0.000333899020915851
sam_encoder.blocks.8.norm1.bias grad: 0.00021124896011315286
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0002733606961555779
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.555522612761706e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00010584503615973517
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.987724539911142e-06
sam_encoder.blocks.8.norm2.weight grad: -0.0002392829628661275
sam_encoder.blocks.8.norm2.bias grad: -0.00013385791680775583
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.810501817089971e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.957355071790516e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.706116593908519e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.504343837335e-08
sam_encoder.blocks.9.norm1.weight grad: 0.00048458640230819583
sam_encoder.blocks.9.norm1.bias grad: -2.2180778614711016e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.0004324144101701677
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00020746086374856532
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.8693786084186286e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.4116626668255776e-05
sam_encoder.blocks.9.norm2.weight grad: -0.00015398234245367348
sam_encoder.blocks.9.norm2.bias grad: -0.0001244105224031955
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0001271028449991718
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.604855222278275e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.5591725463746116e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.84644374914933e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0006032041856087744
sam_encoder.blocks.10.norm1.bias grad: 3.365541488165036e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0004095989279448986
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.0001468079863116145
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.6071835236507468e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.9408508857595734e-06
sam_encoder.blocks.10.norm2.weight grad: -0.00011024354898836464
sam_encoder.blocks.10.norm2.bias grad: -8.662244363222271e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00012665605754591525
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.655372918525245e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.94892629426613e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.693349183071405e-06
sam_encoder.blocks.11.norm1.weight grad: 0.0011649170191958547
sam_encoder.blocks.11.norm1.bias grad: 0.00040435296250507236
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002528773620724678
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.133126539178193e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.44519791926723e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0125029348273529e-06
sam_encoder.blocks.11.norm2.weight grad: 7.36076690373011e-05
sam_encoder.blocks.11.norm2.bias grad: 0.00019487898680381477
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00016788369975984097
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.4929038267582655e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.1956115486100316e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2611162674147636e-05
sam_encoder.neck.conv1.trainable_scale grad: 7.782469037920237e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.001492078066803515
sam_encoder.neck.conv2.trainable_scale grad: 4.704459570348263e-06
sam_encoder.neck.conv2.trainable_shift grad: 0.0002580967266112566
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00483451783657074
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00044243689626455307
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0999990925192833
mask_decoder.transformer.layers.0.norm2.bias grad: -0.01916884258389473
mask_decoder.transformer.layers.0.norm3.weight grad: -0.008890056982636452
mask_decoder.transformer.layers.0.norm3.bias grad: -0.007507107220590115
mask_decoder.transformer.layers.0.norm4.weight grad: 0.003439670894294977
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0010614523198455572
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0009912400273606181
mask_decoder.transformer.layers.1.norm1.bias grad: 0.000297382241114974
mask_decoder.transformer.layers.1.norm2.weight grad: -0.023450233042240143
mask_decoder.transformer.layers.1.norm2.bias grad: -0.002745483536273241
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0007097760681062937
mask_decoder.transformer.layers.1.norm3.bias grad: -0.001890092622488737
mask_decoder.transformer.layers.1.norm4.weight grad: -0.005446083843708038
mask_decoder.transformer.layers.1.norm4.bias grad: -0.01076616533100605
mask_decoder.transformer.norm_final_attn.weight grad: -0.00017751078121364117
mask_decoder.transformer.norm_final_attn.bias grad: 0.00043828896014019847
Text_Embedding_Affine.0.weight grad: 2.3404844728958096e-10
Text_Embedding_Affine.0.bias grad: 1.0812073014676571e-08
Text_Embedding_Affine.2.weight grad: 3.6627354482732244e-09
Text_Embedding_Affine.2.bias grad: 0.0012441847939044237

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.684388459410329e-11
Max value: 0.9940310120582581
Mean value: 0.08016050606966019

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.684388459410329e-11
Max value: 0.9940310120582581
Mean value: 0.08016050606966019

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08032798767089844

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1194068044424057

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06688261032104492

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08032798767089844

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 27.59429931640625
Max value: 80.86557006835938
Mean value: 55.97959518432617

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.684388459410329e-11
Max value: 0.9940310120582581
Mean value: 0.08016050606966019

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.684388459410329e-11
Max value: 0.9940310120582581
Mean value: 0.08016050606966019

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.684388459410329e-11
Max value: 0.9940310120582581
Mean value: 0.08016050606966019

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1194068044424057

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 27.59429931640625
Max value: 80.86557006835938
Mean value: 55.97959518432617

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.980796813964844
Max value: -55.980796813964844
Mean value: -55.980796813964844
sam_encoder.pos_embed grad: 7.417775123030879e-07
sam_encoder.blocks.0.norm1.weight grad: 0.004162265919148922
sam_encoder.blocks.0.norm1.bias grad: -0.0010256380774080753
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0005397724453359842
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.98567933391314e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0003465659392531961
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.187329250271432e-05
sam_encoder.blocks.0.norm2.weight grad: 0.008558104746043682
sam_encoder.blocks.0.norm2.bias grad: -0.0068133058957755566
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.003355292370542884
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.001529612927697599
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.003349070902913809
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0014569272752851248
sam_encoder.blocks.1.norm1.weight grad: 0.0024818903766572475
sam_encoder.blocks.1.norm1.bias grad: 0.0006977720186114311
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0015103996265679598
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0005507580353878438
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.001641497015953064
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0006115434225648642
sam_encoder.blocks.1.norm2.weight grad: 0.0011208615032956004
sam_encoder.blocks.1.norm2.bias grad: -0.0006554800784215331
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0003553858259692788
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.332719491794705e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0012310887686908245
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.896604751702398e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0016300715506076813
sam_encoder.blocks.2.norm1.bias grad: 0.0011481618275865912
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0013374596601352096
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.000357216689735651
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0005696996231563389
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.7432662793435156e-05
sam_encoder.blocks.2.norm2.weight grad: -0.0012729819864034653
sam_encoder.blocks.2.norm2.bias grad: 0.0008368505514226854
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0008616474806331098
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.512108277296647e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0009860943537205458
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0002099761040881276
sam_encoder.blocks.3.norm1.weight grad: -0.000891170697286725
sam_encoder.blocks.3.norm1.bias grad: 0.0013579375809058547
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.000677403062582016
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003086984797846526
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00040007763891480863
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0002938642865046859
sam_encoder.blocks.3.norm2.weight grad: -0.0007690293714404106
sam_encoder.blocks.3.norm2.bias grad: -0.0007392260013148189
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005506462184712291
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.322447810205631e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0007792201358824968
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00025613640900701284
sam_encoder.blocks.4.norm1.weight grad: -0.0023703158367425203
sam_encoder.blocks.4.norm1.bias grad: -0.0014940414112061262
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0015156466979533434
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0003917220456060022
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0006733692134730518
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.000648889341391623
sam_encoder.blocks.4.norm2.weight grad: 0.0030166655778884888
sam_encoder.blocks.4.norm2.bias grad: 0.0019388031214475632
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.001657744636759162
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0006914794794283807
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.6289496569661424e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00010931903671007603
sam_encoder.blocks.5.norm1.weight grad: -0.001819611992686987
sam_encoder.blocks.5.norm1.bias grad: -0.0005707643576897681
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.001014621346257627
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.9078762963763438e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.000641662918496877
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0002335260360268876
sam_encoder.blocks.5.norm2.weight grad: 0.0011640115408226848
sam_encoder.blocks.5.norm2.bias grad: 0.0009891001973301172
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0003349656180944294
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0002355280885240063
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00016029865946620703
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.562089351471514e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0007834425196051598
sam_encoder.blocks.6.norm1.bias grad: -0.0006672099698334932
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00039356364868581295
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.758205275516957e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0002916197699960321
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0002552582882344723
sam_encoder.blocks.6.norm2.weight grad: 0.00048233274719677866
sam_encoder.blocks.6.norm2.bias grad: 0.0002602692402433604
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00015787105076014996
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.946659828419797e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0003023790486622602
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.74176057043951e-05
sam_encoder.blocks.7.norm1.weight grad: -4.377681761980057e-06
sam_encoder.blocks.7.norm1.bias grad: -9.301948011852801e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.127071563038044e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.688562957104295e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00022651393373962492
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0001324643671978265
sam_encoder.blocks.7.norm2.weight grad: 9.24684209167026e-05
sam_encoder.blocks.7.norm2.bias grad: -0.00013641186524182558
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0001469353592256084
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.345087215071544e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.113349081715569e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 0.00013040582416579127
sam_encoder.blocks.8.norm1.weight grad: -0.0003535427094902843
sam_encoder.blocks.8.norm1.bias grad: 0.0003976501466240734
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00021728435240220279
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.2409383998601697e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0006205133977346122
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.000472646759590134
sam_encoder.blocks.8.norm2.weight grad: 0.00017729526734910905
sam_encoder.blocks.8.norm2.bias grad: 0.00022724577866028994
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.9234196265169885e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.9009425159310922e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.418626096798107e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.792550993850455e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00021428967011161149
sam_encoder.blocks.9.norm1.bias grad: -1.1058640666306019e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0002338278864044696
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.182356785051525e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00015538200386799872
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00010703526641009375
sam_encoder.blocks.9.norm2.weight grad: -0.00041299941949546337
sam_encoder.blocks.9.norm2.bias grad: 1.857693678175565e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00031741673592478037
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00025919219478964806
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.2590614864602685e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.5007484004599974e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00034381618024781346
sam_encoder.blocks.10.norm1.bias grad: -2.5240549803129397e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0002364569081692025
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.455410377588123e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0002031302428804338
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00010936285252682865
sam_encoder.blocks.10.norm2.weight grad: -0.0015005609020590782
sam_encoder.blocks.10.norm2.bias grad: -0.0003956797008868307
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0005522042047232389
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0004289373755455017
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00015620161138940603
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.491800013463944e-05
sam_encoder.blocks.11.norm1.weight grad: -0.002631362294778228
sam_encoder.blocks.11.norm1.bias grad: 0.0002623116015456617
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00016301084542647004
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.538022818043828e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00026081857504323125
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00011473276390461251
sam_encoder.blocks.11.norm2.weight grad: -0.0013808729127049446
sam_encoder.blocks.11.norm2.bias grad: -0.0002508243196643889
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00029757682932540774
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00022955177701078355
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00011444608389865607
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.776158599881455e-05
sam_encoder.neck.conv1.trainable_scale grad: 5.51808625459671e-07
sam_encoder.neck.conv1.trainable_shift grad: -0.0026625879108905792
sam_encoder.neck.conv2.trainable_scale grad: 0.00015519920270889997
sam_encoder.neck.conv2.trainable_shift grad: -0.0025028905365616083
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010511279106140137
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0002955356612801552
mask_decoder.transformer.layers.0.norm2.weight grad: -0.27015894651412964
mask_decoder.transformer.layers.0.norm2.bias grad: 0.08640889823436737
mask_decoder.transformer.layers.0.norm3.weight grad: -0.004564010072499514
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0012930103112012148
mask_decoder.transformer.layers.0.norm4.weight grad: -0.004418661352247
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0009585075313225389
mask_decoder.transformer.layers.1.norm1.weight grad: 0.006675714161247015
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0006784378783777356
mask_decoder.transformer.layers.1.norm2.weight grad: 0.024288427084684372
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0063148383051157
mask_decoder.transformer.layers.1.norm3.weight grad: 0.002509692218154669
mask_decoder.transformer.layers.1.norm3.bias grad: 0.006353710778057575
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0028153019957244396
mask_decoder.transformer.layers.1.norm4.bias grad: 0.012748578563332558
mask_decoder.transformer.norm_final_attn.weight grad: 0.00016919341578613967
mask_decoder.transformer.norm_final_attn.bias grad: -0.0008419436635449529
Text_Embedding_Affine.0.weight grad: -2.6006929942923307e-09
Text_Embedding_Affine.0.bias grad: -5.098991096019745e-08
Text_Embedding_Affine.2.weight grad: 9.777671117205955e-09
Text_Embedding_Affine.2.bias grad: -0.0036853002384305

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.92948937277815e-11
Max value: 0.9990934133529663
Mean value: 0.10415902733802795

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.92948937277815e-11
Max value: 0.9990934133529663
Mean value: 0.10415902733802795

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10195732116699219

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.082635879516602
Max value: -1.1920928244535389e-07
Mean value: -0.13066698610782623

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1006765365600586

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10195732116699219

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 54.872589111328125
Max value: 67.55887603759766
Mean value: 62.99230194091797

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.92948937277815e-11
Max value: 0.9990934133529663
Mean value: 0.10415902733802795

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.92948937277815e-11
Max value: 0.9990934133529663
Mean value: 0.10415902733802795

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.92948937277815e-11
Max value: 0.9990934133529663
Mean value: 0.10415902733802795

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.082635879516602
Max value: -1.1920928244535389e-07
Mean value: -0.13066698610782623

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 54.872589111328125
Max value: 67.55887603759766
Mean value: 62.99230194091797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.993431091308594
Max value: -62.993431091308594
Mean value: -62.993431091308594
sam_encoder.pos_embed grad: 1.879090234524483e-07
sam_encoder.blocks.0.norm1.weight grad: 0.003266924526542425
sam_encoder.blocks.0.norm1.bias grad: -0.00018207337416242808
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.326036575250328e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.931770829192828e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.8085010601207614e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0497572475287598e-05
sam_encoder.blocks.0.norm2.weight grad: 0.00159282679669559
sam_encoder.blocks.0.norm2.bias grad: -0.00197995756752789
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0004957031924277544
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0001532515452709049
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0011024953564628959
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0005098327528685331
sam_encoder.blocks.1.norm1.weight grad: 0.00016891297127585858
sam_encoder.blocks.1.norm1.bias grad: 0.0006467841449193656
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004675351083278656
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00013643853890243918
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0004976694472134113
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00025878180167637765
sam_encoder.blocks.1.norm2.weight grad: -0.00011480668763397262
sam_encoder.blocks.1.norm2.bias grad: -5.793126183561981e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0005424490664154291
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.216057616053149e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0009187997202388942
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00010049092816188931
sam_encoder.blocks.2.norm1.weight grad: -0.001176461111754179
sam_encoder.blocks.2.norm1.bias grad: 0.00014754323638044298
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0006837465334683657
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0001477605983382091
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00033416153746657073
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0002604055916890502
sam_encoder.blocks.2.norm2.weight grad: -0.0004928462440147996
sam_encoder.blocks.2.norm2.bias grad: -0.00014323799405246973
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00044137201621197164
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.410826997831464e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005753448931500316
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00011047812586184591
sam_encoder.blocks.3.norm1.weight grad: 6.452295201597735e-05
sam_encoder.blocks.3.norm1.bias grad: 0.00017375365132465959
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00032334192655980587
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00011726422235369682
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0002954482042696327
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00017512860358692706
sam_encoder.blocks.3.norm2.weight grad: -0.0006360798724927008
sam_encoder.blocks.3.norm2.bias grad: -0.00038128072628751397
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0006452041561715305
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00018783034465741366
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00029788658139295876
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0001261361758224666
sam_encoder.blocks.4.norm1.weight grad: 0.0006354757933877409
sam_encoder.blocks.4.norm1.bias grad: -7.223602733574808e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.00020807333930861205
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.3493797723640455e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.209208656102419e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00013430361286737025
sam_encoder.blocks.4.norm2.weight grad: 2.1117390133440495e-05
sam_encoder.blocks.4.norm2.bias grad: 0.0001529096334706992
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.00021491343795787543
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.7496883275453e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00027327873976901174
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.970686081331223e-05
sam_encoder.blocks.5.norm1.weight grad: 1.1770040146075189e-05
sam_encoder.blocks.5.norm1.bias grad: -0.000855714431963861
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.931876123417169e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.633013592567295e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00020817769109271467
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 9.543707710690796e-05
sam_encoder.blocks.5.norm2.weight grad: -6.479618605226278e-05
sam_encoder.blocks.5.norm2.bias grad: 6.672156450804323e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.713653369341046e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.570225842646323e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.2019332643831149e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.1669907154282555e-06
sam_encoder.blocks.6.norm1.weight grad: -6.713701441185549e-05
sam_encoder.blocks.6.norm1.bias grad: -0.0005595742259174585
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.969106496195309e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.804607255617157e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.7106525269337e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.71576674701646e-05
sam_encoder.blocks.6.norm2.weight grad: 6.951335672056302e-05
sam_encoder.blocks.6.norm2.bias grad: 0.00012933478865306824
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00013720968854613602
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.841355934739113e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.000138678980874829
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.524001375713851e-06
sam_encoder.blocks.7.norm1.weight grad: -0.00039637714507989585
sam_encoder.blocks.7.norm1.bias grad: 1.2264839597264654e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00032803299836814404
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00015084008919075131
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00021917243429925293
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00016305604367516935
sam_encoder.blocks.7.norm2.weight grad: 6.81862875353545e-05
sam_encoder.blocks.7.norm2.bias grad: -1.2678521670750342e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.2790598450228572e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00010654696961864829
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.167591734789312e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.6395154640777037e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0002179888979298994
sam_encoder.blocks.8.norm1.bias grad: -0.00012229154526721686
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00010913633741438389
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.188197297276929e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00020870908338110894
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00017451604071538895
sam_encoder.blocks.8.norm2.weight grad: -0.00034664961276575923
sam_encoder.blocks.8.norm2.bias grad: 1.5635538147762418e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0004505769757088274
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00021110448869876564
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00020550494082272053
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.171116208657622e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0002572612138465047
sam_encoder.blocks.9.norm1.bias grad: -3.4294015449631843e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0002665810752660036
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00013131430023349822
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.55464638536796e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.8315188905689865e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0004741035809274763
sam_encoder.blocks.9.norm2.bias grad: -2.778329508146271e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0005288522806949914
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0002681136829778552
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.312750676646829e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.306604624725878e-06
sam_encoder.blocks.10.norm1.weight grad: -0.0002479565446265042
sam_encoder.blocks.10.norm1.bias grad: -2.6206098482361995e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00023734159185551107
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00010166385618504137
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.614747250452638e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.708365253871307e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0008115618256852031
sam_encoder.blocks.10.norm2.bias grad: -0.00019315215467941016
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00042301457142457366
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00026977882953360677
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.871504592709243e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.0957838842150522e-06
sam_encoder.blocks.11.norm1.weight grad: -0.0004927873960696161
sam_encoder.blocks.11.norm1.bias grad: -2.3406979380524717e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.492552686017007e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2432019502739422e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.7068203053204343e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.7803051782248076e-06
sam_encoder.blocks.11.norm2.weight grad: -0.0008035298669710755
sam_encoder.blocks.11.norm2.bias grad: -0.00017842178931459785
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0002944714797195047
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00019068902474828064
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.4032432672102004e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.6110035580350086e-05
sam_encoder.neck.conv1.trainable_scale grad: -2.5930465199053288e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.00027911446522921324
sam_encoder.neck.conv2.trainable_scale grad: 5.278678145259619e-06
sam_encoder.neck.conv2.trainable_shift grad: 0.0012995190918445587
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0022825985215604305
mask_decoder.transformer.layers.0.norm1.bias grad: -4.2532337829470634e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.3364608883857727
mask_decoder.transformer.layers.0.norm2.bias grad: 0.04722947999835014
mask_decoder.transformer.layers.0.norm3.weight grad: 0.002290612319484353
mask_decoder.transformer.layers.0.norm3.bias grad: 0.003260544501245022
mask_decoder.transformer.layers.0.norm4.weight grad: -0.006236434448510408
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00030813872581347823
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0014066251460462809
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0003248668508604169
mask_decoder.transformer.layers.1.norm2.weight grad: 0.011142955161631107
mask_decoder.transformer.layers.1.norm2.bias grad: -2.4884939193725586e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0007364945486187935
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0006995769217610359
mask_decoder.transformer.layers.1.norm4.weight grad: 0.007321475073695183
mask_decoder.transformer.layers.1.norm4.bias grad: 0.012770524248480797
mask_decoder.transformer.norm_final_attn.weight grad: 0.0003181830979883671
mask_decoder.transformer.norm_final_attn.bias grad: -0.0003460781299509108
Text_Embedding_Affine.0.weight grad: -2.4517166075099794e-10
Text_Embedding_Affine.0.bias grad: -1.3562384992837906e-08
Text_Embedding_Affine.2.weight grad: 9.022813607373337e-10
Text_Embedding_Affine.2.bias grad: -8.228933438658714e-05
Epoch 28 finished with average loss: -56.6183
Epoch 29/39
----------
Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.4]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.17it/s, loss=-61.4]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.17it/s, loss=-57.6]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-57.6]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-54.9]Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-54.9]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.072739525466499e-12
Max value: 0.9982491731643677
Mean value: 0.09420598298311234

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.072739525466499e-12
Max value: 0.9982491731643677
Mean value: 0.09420598298311234

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0937185287475586

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.411410331726074
Max value: -1.1920928244535389e-07
Mean value: -0.1208714097738266

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08491134643554688

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0937185287475586

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.420204162597656
Max value: 78.5130844116211
Mean value: 61.35115432739258

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.072739525466499e-12
Max value: 0.9982491731643677
Mean value: 0.09420598298311234

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.072739525466499e-12
Max value: 0.9982491731643677
Mean value: 0.09420598298311234

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.072739525466499e-12
Max value: 0.9982491731643677
Mean value: 0.09420598298311234

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.411410331726074
Max value: -1.1920928244535389e-07
Mean value: -0.1208714097738266

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.420204162597656
Max value: 78.5130844116211
Mean value: 61.35115432739258

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.35243225097656
Max value: -61.35243225097656
Mean value: -61.35243225097656
sam_encoder.pos_embed grad: 1.8936087542442692e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0024439035914838314
sam_encoder.blocks.0.norm1.bias grad: -0.0017739103641360998
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00028853354160673916
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.9863254389492795e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0010833267588168383
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0002127634361386299
sam_encoder.blocks.0.norm2.weight grad: -0.0023496984504163265
sam_encoder.blocks.0.norm2.bias grad: 0.0064169554971158504
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0016323374584317207
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003112812992185354
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0013082673540338874
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006791352643631399
sam_encoder.blocks.1.norm1.weight grad: 0.0007495912723243237
sam_encoder.blocks.1.norm1.bias grad: 0.000355343334376812
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005281808553263545
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00022032273409422487
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0005249145906418562
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.067232895176858e-05
sam_encoder.blocks.1.norm2.weight grad: 0.001618386129848659
sam_encoder.blocks.1.norm2.bias grad: -0.00039547972846776247
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0001663691073190421
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.238068064907566e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0008930381154641509
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00017371788271702826
sam_encoder.blocks.2.norm1.weight grad: -0.00013538850180339068
sam_encoder.blocks.2.norm1.bias grad: -0.0006493785767816007
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.00012214155867695808
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.370787691092119e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.880141073546838e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.203707355074584e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0020674082916229963
sam_encoder.blocks.2.norm2.bias grad: -0.00025877385633066297
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0011469165328890085
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.000405154365580529
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0002056216762866825
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0001912951993290335
sam_encoder.blocks.3.norm1.weight grad: -0.0006148684187792242
sam_encoder.blocks.3.norm1.bias grad: -0.00042049825424328446
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0003762022824957967
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.252651580027305e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00016914107254706323
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.996576924691908e-05
sam_encoder.blocks.3.norm2.weight grad: 0.001366761396639049
sam_encoder.blocks.3.norm2.bias grad: 0.0002921497798524797
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0009731510654091835
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0004846719093620777
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0002591957454569638
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.568434865679592e-06
sam_encoder.blocks.4.norm1.weight grad: -0.0016284588491544127
sam_encoder.blocks.4.norm1.bias grad: -0.0009947479702532291
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0007239446858875453
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.346417260123417e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00017935800133273005
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002366163971601054
sam_encoder.blocks.4.norm2.weight grad: 0.0021918423008173704
sam_encoder.blocks.4.norm2.bias grad: 0.0005121992435306311
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0013746712356805801
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0004999895463697612
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00011500098480610177
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.0948802810162306e-05
sam_encoder.blocks.5.norm1.weight grad: -0.00046033269609324634
sam_encoder.blocks.5.norm1.bias grad: -0.001302554039284587
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00018308164726477116
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0002658419543877244
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00012004221207462251
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00046808039769530296
sam_encoder.blocks.5.norm2.weight grad: 0.0007928113336674869
sam_encoder.blocks.5.norm2.bias grad: 0.0009896347764879465
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00035100331297144294
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00017074053175747395
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.757910548709333e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.4363426998897921e-05
sam_encoder.blocks.6.norm1.weight grad: -0.000687137886416167
sam_encoder.blocks.6.norm1.bias grad: -0.0006931661628186703
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0006158789619803429
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00020530587062239647
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00022196071222424507
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.850212568882853e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0010575379710644484
sam_encoder.blocks.6.norm2.bias grad: 0.0008301213383674622
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0007503151427954435
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00030709593556821346
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002521072456147522
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.000128289801068604
sam_encoder.blocks.7.norm1.weight grad: -0.0006045777699910104
sam_encoder.blocks.7.norm1.bias grad: 0.0001620456314412877
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0005616140551865101
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.0002007976290769875
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00042862602276727557
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00036596282734535635
sam_encoder.blocks.7.norm2.weight grad: -0.00019920806516893208
sam_encoder.blocks.7.norm2.bias grad: 0.0003093070408795029
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00030714014428667724
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.218809772282839e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.3988493467186345e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.0016694432124496e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0011840444058179855
sam_encoder.blocks.8.norm1.bias grad: 0.00015796121442690492
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0013788732467219234
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0005915573565289378
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00045342801604419947
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0004278186825104058
sam_encoder.blocks.8.norm2.weight grad: -0.00021729157015215605
sam_encoder.blocks.8.norm2.bias grad: -0.0003311494365334511
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00014711153926327825
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.7440092051401734e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.585078204399906e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.819366611423902e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0006895230617374182
sam_encoder.blocks.9.norm1.bias grad: 0.00014972126518841833
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.000622392341028899
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0002251148980576545
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00014262004697229713
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.09717457741499e-05
sam_encoder.blocks.9.norm2.weight grad: -2.3646174668101594e-05
sam_encoder.blocks.9.norm2.bias grad: -0.00010981662489939481
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.3085411157808267e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00011304317740723491
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00010330969234928489
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.6042037865845487e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0006801864365115762
sam_encoder.blocks.10.norm1.bias grad: 1.76383964571869e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0003401503199711442
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.612205758458003e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00011324202932883054
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.791137275286019e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0001215717347804457
sam_encoder.blocks.10.norm2.bias grad: -0.00013439696340356022
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0001976222702069208
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.9566093669709517e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.5742861907929182e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.9363203541142866e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0012454120442271233
sam_encoder.blocks.11.norm1.bias grad: 0.00015095641720108688
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00013060937635600567
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.172851575072855e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.0229707742109895e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.8044457798823714e-06
sam_encoder.blocks.11.norm2.weight grad: -0.00040942884515970945
sam_encoder.blocks.11.norm2.bias grad: -0.000211927923373878
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0003252886817790568
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.298145697452128e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0001020168128889054
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.552768299006857e-05
sam_encoder.neck.conv1.trainable_scale grad: -1.4591147191822529e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0012510349042713642
sam_encoder.neck.conv2.trainable_scale grad: -8.67210328578949e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0030240274500101805
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0026674545370042324
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00025368062779307365
mask_decoder.transformer.layers.0.norm2.weight grad: -0.42697376012802124
mask_decoder.transformer.layers.0.norm2.bias grad: -0.05680301785469055
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0002528760815039277
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0038912147283554077
mask_decoder.transformer.layers.0.norm4.weight grad: 0.01084167417138815
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0008366451365873218
mask_decoder.transformer.layers.1.norm1.weight grad: 0.003359281923621893
mask_decoder.transformer.layers.1.norm1.bias grad: 0.00028649764135479927
mask_decoder.transformer.layers.1.norm2.weight grad: -0.020078279078006744
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0015746355056762695
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0012915306724607944
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0015756108332425356
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0002991848159581423
mask_decoder.transformer.layers.1.norm4.bias grad: -0.008598960936069489
mask_decoder.transformer.norm_final_attn.weight grad: 0.0004839002212975174
mask_decoder.transformer.norm_final_attn.bias grad: 0.0014437143690884113
Text_Embedding_Affine.0.weight grad: 8.605205437106633e-10
Text_Embedding_Affine.0.bias grad: 3.215973265469074e-08
Text_Embedding_Affine.2.weight grad: 1.5248517726274002e-10
Text_Embedding_Affine.2.bias grad: 0.0003664845135062933

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4983938569079758e-12
Max value: 0.9981480836868286
Mean value: 0.07897333800792694

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4983938569079758e-12
Max value: 0.9981480836868286
Mean value: 0.07897333800792694

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07605314254760742

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11630314588546753

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07070302963256836

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07605314254760742

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.72407531738281
Max value: 71.13546752929688
Mean value: 53.80818176269531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4983938569079758e-12
Max value: 0.9981480836868286
Mean value: 0.07897333800792694

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4983938569079758e-12
Max value: 0.9981480836868286
Mean value: 0.07897333800792694

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4983938569079758e-12
Max value: 0.9981480836868286
Mean value: 0.07897333800792694

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11630314588546753

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.72407531738281
Max value: 71.13546752929688
Mean value: 53.80818176269531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.80924606323242
Max value: -53.80924606323242
Mean value: -53.80924606323242
sam_encoder.pos_embed grad: 9.742435480575296e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0002672958071343601
sam_encoder.blocks.0.norm1.bias grad: 0.0015486746560782194
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.016399179818109e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.0116622181376442e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0002796642656903714
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.248302815947682e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0029930684249848127
sam_encoder.blocks.0.norm2.bias grad: -0.0012184095103293657
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.001113556558266282
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.2774369426770136e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -8.96318451850675e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.899136936524883e-05
sam_encoder.blocks.1.norm1.weight grad: -0.0003249741857871413
sam_encoder.blocks.1.norm1.bias grad: 0.0002684093778952956
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00036426709266379476
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.166915358742699e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0002139597199857235
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00010216834198217839
sam_encoder.blocks.1.norm2.weight grad: 0.00042537739500403404
sam_encoder.blocks.1.norm2.bias grad: -1.5963674741215073e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0002746886748354882
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.548574987798929e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00012813377543352544
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.4159762940835208e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0013067005202174187
sam_encoder.blocks.2.norm1.bias grad: 0.00023108234745450318
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0010240552946925163
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.000212647340958938
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00044957263162359595
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00037995140883140266
sam_encoder.blocks.2.norm2.weight grad: 0.0006262261304073036
sam_encoder.blocks.2.norm2.bias grad: -0.0009867355693131685
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0001614042412256822
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00010564122203504667
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00010571369057288393
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.162097300446476e-06
sam_encoder.blocks.3.norm1.weight grad: 0.00043940223986282945
sam_encoder.blocks.3.norm1.bias grad: -6.267257958825212e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.581177068350371e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.321615076856688e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00016360823065042496
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.441230263793841e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0003664559917524457
sam_encoder.blocks.3.norm2.bias grad: -0.0005692254635505378
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.00047586060827597976
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.296752978116274e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00011774015001719818
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.820014848723076e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0009299895609728992
sam_encoder.blocks.4.norm1.bias grad: -0.00015930348308756948
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0003135688602924347
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.275565389543772e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.969482794578653e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.6304478524252772e-06
sam_encoder.blocks.4.norm2.weight grad: 0.0004740731092169881
sam_encoder.blocks.4.norm2.bias grad: 0.00033001237898133695
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00013637136726174504
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.016641130670905e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00013186546857468784
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.146681617887225e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0012062345631420612
sam_encoder.blocks.5.norm1.bias grad: -0.0008541098795831203
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0009730189922265708
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0003561764024198055
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.112756768241525e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00014972221106290817
sam_encoder.blocks.5.norm2.weight grad: 0.00038769078673794866
sam_encoder.blocks.5.norm2.bias grad: -0.000325651781167835
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00017086118168663234
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.871585017303005e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.236417827196419e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.0572649361838558e-07
sam_encoder.blocks.6.norm1.weight grad: -0.000355282798409462
sam_encoder.blocks.6.norm1.bias grad: -0.00021158966410439461
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0001502829691162333
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.35998512734659e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0002080136036965996
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0001460936910007149
sam_encoder.blocks.6.norm2.weight grad: 0.00032575707882642746
sam_encoder.blocks.6.norm2.bias grad: 3.7764704757137224e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.1014628398697823e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.1458363335113972e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.1160124712623656e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.243561877752654e-05
sam_encoder.blocks.7.norm1.weight grad: -7.253259536810219e-05
sam_encoder.blocks.7.norm1.bias grad: -8.454996714135632e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.617015267489478e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.2817042412934825e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00014388089766725898
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00011075907968915999
sam_encoder.blocks.7.norm2.weight grad: 0.00036825588904321194
sam_encoder.blocks.7.norm2.bias grad: -6.064522312954068e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00016023741045501083
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.00011204995098523796
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.476960308849812e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.749453364638612e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00040831504156813025
sam_encoder.blocks.8.norm1.bias grad: -0.00020883706747554243
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0005411563324742019
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00023284151393454522
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00011969941988354549
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.900442091748118e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0001401848130626604
sam_encoder.blocks.8.norm2.bias grad: 0.0001878374896477908
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000258121348451823
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00011543097207322717
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.000137610943056643
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.6408935809740797e-05
sam_encoder.blocks.9.norm1.weight grad: 5.406138370744884e-05
sam_encoder.blocks.9.norm1.bias grad: -6.100890459492803e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.673177373770159e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.0399052522843704e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.061720366938971e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.41303340671584e-05
sam_encoder.blocks.9.norm2.weight grad: -0.00037820375291630626
sam_encoder.blocks.9.norm2.bias grad: 2.5696621378301643e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0004098697972949594
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0002035411016549915
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00011769102275138721
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.2144936590630095e-05
sam_encoder.blocks.10.norm1.weight grad: -4.480078860069625e-05
sam_encoder.blocks.10.norm1.bias grad: 7.094253078321344e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -9.283877443522215e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.474417073652148e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.614037506049499e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.349804607452825e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0005541014252230525
sam_encoder.blocks.10.norm2.bias grad: -4.8818837967701256e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00022994358732830733
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00017995532834902406
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.280145756434649e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.6876198060344905e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00010508365085115656
sam_encoder.blocks.11.norm1.bias grad: -3.788213507505134e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00029236049158498645
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.136692950851284e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2801620869140606e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.9331767766270787e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0007199255633167922
sam_encoder.blocks.11.norm2.bias grad: -5.9693746152333915e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0002069906040560454
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00013295785174705088
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.9461803175508976e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.869250213028863e-05
sam_encoder.neck.conv1.trainable_scale grad: -5.64156798645854e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.00011008128058165312
sam_encoder.neck.conv2.trainable_scale grad: 3.867177292704582e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.004487220663577318
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0020429822616279125
mask_decoder.transformer.layers.0.norm1.bias grad: 1.5137717127799988e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.38861215114593506
mask_decoder.transformer.layers.0.norm2.bias grad: 0.03855086490511894
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0016604438424110413
mask_decoder.transformer.layers.0.norm3.bias grad: 0.003629712387919426
mask_decoder.transformer.layers.0.norm4.weight grad: -0.007300889119505882
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0007142648100852966
mask_decoder.transformer.layers.1.norm1.weight grad: -0.001169213093817234
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0003407493932172656
mask_decoder.transformer.layers.1.norm2.weight grad: 0.014465241692960262
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0009455052204430103
mask_decoder.transformer.layers.1.norm3.weight grad: -0.00063893391052261
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0006289085722528398
mask_decoder.transformer.layers.1.norm4.weight grad: 0.005062413401901722
mask_decoder.transformer.layers.1.norm4.bias grad: 0.010594284161925316
mask_decoder.transformer.norm_final_attn.weight grad: 2.9102375265210867e-07
mask_decoder.transformer.norm_final_attn.bias grad: -0.0008080998668447137
Text_Embedding_Affine.0.weight grad: 9.036080217406095e-10
Text_Embedding_Affine.0.bias grad: 2.6659108698368073e-08
Text_Embedding_Affine.2.weight grad: 1.564136820064732e-09
Text_Embedding_Affine.2.bias grad: -0.0014368626289069653

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6371328731844557e-11
Max value: 0.9956958293914795
Mean value: 0.07996006309986115

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6371328731844557e-11
Max value: 0.9956958293914795
Mean value: 0.07996006309986115

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07919025421142578

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12447667866945267

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06075572967529297

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07919025421142578

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 40.59978103637695
Max value: 65.47502899169922
Mean value: 49.52493667602539

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6371328731844557e-11
Max value: 0.9956958293914795
Mean value: 0.07996006309986115

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6371328731844557e-11
Max value: 0.9956958293914795
Mean value: 0.07996006309986115

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6371328731844557e-11
Max value: 0.9956958293914795
Mean value: 0.07996006309986115

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12447667866945267

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 40.59978103637695
Max value: 65.47502899169922
Mean value: 49.52493667602539

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.52622985839844
Max value: -49.52622985839844
Mean value: -49.52622985839844
sam_encoder.pos_embed grad: -2.279845645603018e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0017654707189649343
sam_encoder.blocks.0.norm1.bias grad: -0.0003802409628406167
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0003040445735678077
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.6517408665968105e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00046718260273337364
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00023739102471154183
sam_encoder.blocks.0.norm2.weight grad: -0.0010831872932612896
sam_encoder.blocks.0.norm2.bias grad: 0.001974997343495488
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0008092906209640205
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.8523172659333795e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0004926999099552631
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0002007514121942222
sam_encoder.blocks.1.norm1.weight grad: -0.0002661195758264512
sam_encoder.blocks.1.norm1.bias grad: -0.0001372089027427137
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00046285041025839746
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00018847495084628463
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0002539029228501022
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.000103085782029666
sam_encoder.blocks.1.norm2.weight grad: 0.0003062500327359885
sam_encoder.blocks.1.norm2.bias grad: -0.0006374000804498792
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.1556271500885487e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.9263031794689596e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.563986739318352e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.251923069707118e-05
sam_encoder.blocks.2.norm1.weight grad: -6.43289095023647e-05
sam_encoder.blocks.2.norm1.bias grad: -0.00018899174756370485
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0002282081841258332
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.5348311939742416e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0001890892453957349
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0002793089661281556
sam_encoder.blocks.2.norm2.weight grad: -0.00011930520122405142
sam_encoder.blocks.2.norm2.bias grad: -0.0001242715516127646
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.792117452889215e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.8704744181595743e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0002644126070663333
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.573796028736979e-05
sam_encoder.blocks.3.norm1.weight grad: -0.00013184212730266154
sam_encoder.blocks.3.norm1.bias grad: -0.0001535245100967586
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.797137707006186e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.98407108959509e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.718707739608362e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00015380322292912751
sam_encoder.blocks.3.norm2.weight grad: -0.00021343078697100282
sam_encoder.blocks.3.norm2.bias grad: -4.243926014169119e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.366740929777734e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.9702721803914756e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.073454718105495e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.393796113319695e-05
sam_encoder.blocks.4.norm1.weight grad: -0.0007803324842825532
sam_encoder.blocks.4.norm1.bias grad: 9.199295891448855e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0003688574070110917
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.0999060476897284e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3916675925429445e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.530456160660833e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0002201310999225825
sam_encoder.blocks.4.norm2.bias grad: -7.646412996109575e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00016338184650521725
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.4460659662727267e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1770320017822087e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.666811658651568e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0007651048945263028
sam_encoder.blocks.5.norm1.bias grad: 0.00019806972704827785
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0006674038013443351
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00025388854555785656
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00023426569532603025
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.793564484221861e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0002437789225950837
sam_encoder.blocks.5.norm2.bias grad: 0.0002970563364215195
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00011841271043522283
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.585189839825034e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.6421285181422718e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.2696729754679836e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00023230424267239869
sam_encoder.blocks.6.norm1.bias grad: -0.0001426005910616368
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00020545197185128927
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.1829218136845157e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.96056808414869e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.291720713605173e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0006846643518656492
sam_encoder.blocks.6.norm2.bias grad: 5.210943982092431e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00046638556523248553
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00016731407959014177
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002788687706924975
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00013265275629237294
sam_encoder.blocks.7.norm1.weight grad: -0.00012499550939537585
sam_encoder.blocks.7.norm1.bias grad: 4.4724904000759125e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.882027421146631e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.1923015335923992e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.882791704905685e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.346119334921241e-06
sam_encoder.blocks.7.norm2.weight grad: -0.00016365844930987805
sam_encoder.blocks.7.norm2.bias grad: -5.231786781223491e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0002653759147506207
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00015994321438483894
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.980330413673073e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.1187468519201502e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00020293210400268435
sam_encoder.blocks.8.norm1.bias grad: 0.00022479903418570757
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.433893612556858e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.419130618771305e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00021980982273817062
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00027660117484629154
sam_encoder.blocks.8.norm2.weight grad: -0.0001636027591302991
sam_encoder.blocks.8.norm2.bias grad: -7.844255742384121e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00020604458404704928
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0001294647081522271
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.877859752625227e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.564299549907446e-05
sam_encoder.blocks.9.norm1.weight grad: 0.00013746684999205172
sam_encoder.blocks.9.norm1.bias grad: 5.1124749006703496e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.219179628416896e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1711813385772984e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.6201792176580057e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.470145020401105e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00013666649465449154
sam_encoder.blocks.9.norm2.bias grad: -5.70050033275038e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.701359310070984e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.4665414457558654e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.069535786285996e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.9518196495482698e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0001909986895043403
sam_encoder.blocks.10.norm1.bias grad: 0.00011132395593449473
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -9.810405026655644e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.1627947717206553e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.1967503926134668e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.4641014786320738e-05
sam_encoder.blocks.10.norm2.weight grad: -1.9552175217540935e-05
sam_encoder.blocks.10.norm2.bias grad: -0.00022747009643353522
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.59259325300809e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.6538240490481257e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.5216936743818223e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.096110594924539e-05
sam_encoder.blocks.11.norm1.weight grad: 9.924982441589236e-05
sam_encoder.blocks.11.norm1.bias grad: 0.00014196860138326883
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.4841635826742277e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.923173790099099e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.766326598357409e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.904382901964709e-05
sam_encoder.blocks.11.norm2.weight grad: 0.00018527961219660938
sam_encoder.blocks.11.norm2.bias grad: -0.00019003695342689753
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.8098343793535605e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.919034482663847e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.6499200177786406e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0708298759709578e-05
sam_encoder.neck.conv1.trainable_scale grad: -3.4282857086509466e-06
sam_encoder.neck.conv1.trainable_shift grad: 5.848065484315157e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.2718217223882675e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0004418051685206592
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0002548701595515013
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00018472736701369286
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3067440390586853
mask_decoder.transformer.layers.0.norm2.bias grad: -0.030053656548261642
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00579786067828536
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0004916437901556492
mask_decoder.transformer.layers.0.norm4.weight grad: 0.002689375076442957
mask_decoder.transformer.layers.0.norm4.bias grad: -5.3660827688872814e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.003868922358378768
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00025925831869244576
mask_decoder.transformer.layers.1.norm2.weight grad: 0.002864179201424122
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0029703988693654537
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0015158758033066988
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0024048045743256807
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002833619248121977
mask_decoder.transformer.layers.1.norm4.bias grad: -0.004762656055390835
mask_decoder.transformer.norm_final_attn.weight grad: 0.00027981193852610886
mask_decoder.transformer.norm_final_attn.bias grad: 0.000798641936853528
Text_Embedding_Affine.0.weight grad: 6.882379666173222e-10
Text_Embedding_Affine.0.bias grad: 4.936009645462036e-08
Text_Embedding_Affine.2.weight grad: -1.02508257437961e-09
Text_Embedding_Affine.2.bias grad: -0.0005886870203539729
Epoch 29 finished with average loss: -54.8960
Epoch 30/39
----------
Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.1]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-60.1]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-53]  Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-53]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-54.4]Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-54.4]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.095553674503648e-11
Max value: 0.9963085055351257
Mean value: 0.08695536851882935

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.095553674503648e-11
Max value: 0.9963085055351257
Mean value: 0.08695536851882935

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0799875259399414

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1144457459449768

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07630491256713867

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0799875259399414

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.3412971496582
Max value: 83.71854400634766
Mean value: 60.08563232421875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.095553674503648e-11
Max value: 0.9963085055351257
Mean value: 0.08695536851882935

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.095553674503648e-11
Max value: 0.9963085055351257
Mean value: 0.08695536851882935

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.095553674503648e-11
Max value: 0.9963085055351257
Mean value: 0.08695536851882935

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1144457459449768

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.3412971496582
Max value: 83.71854400634766
Mean value: 60.08563232421875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.086891174316406
Max value: -60.086891174316406
Mean value: -60.086891174316406
sam_encoder.pos_embed grad: -4.344712323245403e-08
sam_encoder.blocks.0.norm1.weight grad: -0.004700553137809038
sam_encoder.blocks.0.norm1.bias grad: -0.00048749762936495245
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0003764526336453855
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.57269367063418e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0007132843602448702
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0002586369519121945
sam_encoder.blocks.0.norm2.weight grad: 0.0016948517877608538
sam_encoder.blocks.0.norm2.bias grad: -0.0012063203612342477
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0012573129497468472
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0002582741144578904
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.00010170941095566377
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.409141406038543e-06
sam_encoder.blocks.1.norm1.weight grad: 2.8340418793959543e-05
sam_encoder.blocks.1.norm1.bias grad: 0.001659671775996685
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00041872760630212724
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00017085380386561155
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00042500748531892896
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002736304886639118
sam_encoder.blocks.1.norm2.weight grad: -0.0007377518340945244
sam_encoder.blocks.1.norm2.bias grad: -0.0010259108385071158
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.2289266325969948e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.4716711272485554e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0009041181183420122
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0001456156314816326
sam_encoder.blocks.2.norm1.weight grad: -0.000813466205727309
sam_encoder.blocks.2.norm1.bias grad: -2.8412014216883108e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.000792246893979609
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00020142958965152502
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0002504974836483598
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.9376503739040345e-05
sam_encoder.blocks.2.norm2.weight grad: 0.0010476590832695365
sam_encoder.blocks.2.norm2.bias grad: -0.00090198585530743
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0004248524783179164
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 8.609743963461369e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00017330770788248628
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.219317583600059e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0009351394837722182
sam_encoder.blocks.3.norm1.bias grad: 7.717435801168904e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.00026447803247720003
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 8.383901877095923e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.926111432723701e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00016246724408119917
sam_encoder.blocks.3.norm2.weight grad: -0.0004870595585089177
sam_encoder.blocks.3.norm2.bias grad: 0.0007574748015031219
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0004743273602798581
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00014687595830764621
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00034086848609149456
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.633908247342333e-05
sam_encoder.blocks.4.norm1.weight grad: 0.00022560590878129005
sam_encoder.blocks.4.norm1.bias grad: -0.0005223185289651155
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.4900269131176174e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.953943061991595e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.198875341098756e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.4978982007014565e-06
sam_encoder.blocks.4.norm2.weight grad: 0.0006364051951095462
sam_encoder.blocks.4.norm2.bias grad: 0.000730748928617686
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.996158531866968e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.2326617252256256e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.4684099116711877e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.7112774811685085e-06
sam_encoder.blocks.5.norm1.weight grad: -8.510652696713805e-05
sam_encoder.blocks.5.norm1.bias grad: -0.0003907598729711026
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00020899632363580167
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0002669875684659928
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.8609086914220825e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.985697397496551e-05
sam_encoder.blocks.5.norm2.weight grad: 4.0969462133944035e-06
sam_encoder.blocks.5.norm2.bias grad: 0.00015201710630208254
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.8925227019935846e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5296962374122813e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00015771636390127242
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.4203490688232705e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00013425180804915726
sam_encoder.blocks.6.norm1.bias grad: -0.00027012810460291803
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00011945921869482845
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0001308100763708353
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.460188185679726e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.540821126080118e-05
sam_encoder.blocks.6.norm2.weight grad: 7.639961404493079e-05
sam_encoder.blocks.6.norm2.bias grad: -3.6489996091404464e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.676937169278972e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.457614755257964e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.3373944461345673e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.557254088576883e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0001516070478828624
sam_encoder.blocks.7.norm1.bias grad: 8.544089359929785e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.140849730698392e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.36001890496118e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.305426798760891e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.898649007780477e-05
sam_encoder.blocks.7.norm2.weight grad: 0.0002106077445205301
sam_encoder.blocks.7.norm2.bias grad: -0.00014679665036965162
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00012946399510838091
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.02179125053226e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0538249625824392e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.5288842405425385e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0006558712921105325
sam_encoder.blocks.8.norm1.bias grad: 0.00012458270066417754
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0005013851332478225
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00025241164257749915
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.7001642592949793e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.6477063733618706e-05
sam_encoder.blocks.8.norm2.weight grad: 0.00013189739547669888
sam_encoder.blocks.8.norm2.bias grad: 0.0001292386878049001
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.744708581303712e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00017456477507948875
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.4428077419288456e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.555660805432126e-05
sam_encoder.blocks.9.norm1.weight grad: 0.00010628568998072296
sam_encoder.blocks.9.norm1.bias grad: -4.1826002416200936e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.901084922603332e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.31067334022373e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00012382410932332277
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.111642091535032e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00011561537394300103
sam_encoder.blocks.9.norm2.bias grad: 9.357946692034602e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.688372817123309e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.886660488205962e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.7843847672338597e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.0199302273103967e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0002086954627884552
sam_encoder.blocks.10.norm1.bias grad: -8.381952648051083e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0001013354049064219
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2907261407235637e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.127238207729533e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.9333447097742464e-06
sam_encoder.blocks.10.norm2.weight grad: -0.0004757296701427549
sam_encoder.blocks.10.norm2.bias grad: -0.0002968442568089813
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00013760337606072426
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00018061173614114523
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.385053322650492e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.0133868424163666e-06
sam_encoder.blocks.11.norm1.weight grad: 0.0007452726131305099
sam_encoder.blocks.11.norm1.bias grad: 6.529319216497242e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.0631056031561457e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.697819869965315e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0001023078802973032
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.222289524273947e-05
sam_encoder.blocks.11.norm2.weight grad: -6.322078115772456e-05
sam_encoder.blocks.11.norm2.bias grad: -0.00013079782365821302
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.734444231260568e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.2218598789768293e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.212234489386901e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.926452361862175e-05
sam_encoder.neck.conv1.trainable_scale grad: 4.942450323142111e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.000469291175249964
sam_encoder.neck.conv2.trainable_scale grad: 3.211235161870718e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.005083754193037748
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0008184919133782387
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0002517803804948926
mask_decoder.transformer.layers.0.norm2.weight grad: 0.07057945430278778
mask_decoder.transformer.layers.0.norm2.bias grad: -0.03586876392364502
mask_decoder.transformer.layers.0.norm3.weight grad: 0.002276891376823187
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0007801817264407873
mask_decoder.transformer.layers.0.norm4.weight grad: -0.004987669643014669
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0006801536655984819
mask_decoder.transformer.layers.1.norm1.weight grad: -0.000938398705329746
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0006994522409513593
mask_decoder.transformer.layers.1.norm2.weight grad: 0.02277606725692749
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0032164144795387983
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00039808053406886756
mask_decoder.transformer.layers.1.norm3.bias grad: 0.001968842465430498
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0038264186587184668
mask_decoder.transformer.layers.1.norm4.bias grad: -0.001709936186671257
mask_decoder.transformer.norm_final_attn.weight grad: 4.241905844537541e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0006771216285414994
Text_Embedding_Affine.0.weight grad: -1.4631365008455077e-09
Text_Embedding_Affine.0.bias grad: 3.6670826375484467e-09
Text_Embedding_Affine.2.weight grad: 6.67593758052476e-10
Text_Embedding_Affine.2.bias grad: -0.0029387706890702248

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0272605682759561e-11
Max value: 0.9988875985145569
Mean value: 0.0632377415895462

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0272605682759561e-11
Max value: 0.9988875985145569
Mean value: 0.0632377415895462

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07078361511230469

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1209934875369072

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.055108070373535156

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07078361511230469

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 24.406780242919922
Max value: 59.660667419433594
Mean value: 45.82456970214844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0272605682759561e-11
Max value: 0.9988875985145569
Mean value: 0.0632377415895462

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0272605682759561e-11
Max value: 0.9988875985145569
Mean value: 0.0632377415895462

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0272605682759561e-11
Max value: 0.9988875985145569
Mean value: 0.0632377415895462

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1209934875369072

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 24.406780242919922
Max value: 59.660667419433594
Mean value: 45.82456970214844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -45.82550048828125
Max value: -45.82550048828125
Mean value: -45.82550048828125
sam_encoder.pos_embed grad: 9.995044365496142e-07
sam_encoder.blocks.0.norm1.weight grad: 0.004408444277942181
sam_encoder.blocks.0.norm1.bias grad: 0.001412636018358171
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00026478676591068506
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.585681017488241e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0005691068945452571
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0002217348082922399
sam_encoder.blocks.0.norm2.weight grad: 0.0024958704598248005
sam_encoder.blocks.0.norm2.bias grad: -0.0035611798521131277
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0017916191136464477
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0008484078571200371
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.003294664900749922
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0012216027826070786
sam_encoder.blocks.1.norm1.weight grad: 0.0014005156699568033
sam_encoder.blocks.1.norm1.bias grad: 0.001838188385590911
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.000708480307366699
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00018886494217440486
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.000670753768645227
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002793824241962284
sam_encoder.blocks.1.norm2.weight grad: -0.00016304382006637752
sam_encoder.blocks.1.norm2.bias grad: -0.0006750327884219587
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0003943586489185691
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.2834788726177067e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.001182469306513667
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.807324047666043e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0023361672647297382
sam_encoder.blocks.2.norm1.bias grad: 0.0012652315199375153
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0015226854011416435
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0002839173539541662
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0004912699805572629
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003092929837293923
sam_encoder.blocks.2.norm2.weight grad: -0.0004972976166754961
sam_encoder.blocks.2.norm2.bias grad: -0.0006142279598861933
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0005295170703902841
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.847527012927458e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0008082044078037143
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00011056388029828668
sam_encoder.blocks.3.norm1.weight grad: -0.00012738067016471177
sam_encoder.blocks.3.norm1.bias grad: 0.0009001758880913258
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0002780821523629129
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0001746674533933401
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0003780893166549504
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00028451866819523275
sam_encoder.blocks.3.norm2.weight grad: -0.0010361263994127512
sam_encoder.blocks.3.norm2.bias grad: 0.00023370741109829396
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0010004981886595488
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0002364552055951208
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0007624853169545531
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00024533498799428344
sam_encoder.blocks.4.norm1.weight grad: -6.997284071985632e-05
sam_encoder.blocks.4.norm1.bias grad: 0.0002194139378843829
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00023551483172923326
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00010695829405449331
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0005402558017522097
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00046194400056265295
sam_encoder.blocks.4.norm2.weight grad: 0.0018336870707571507
sam_encoder.blocks.4.norm2.bias grad: 0.0016465880908071995
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0007760364096611738
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00035846064565703273
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00036542429006658494
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.795723260845989e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0017685404745861888
sam_encoder.blocks.5.norm1.bias grad: -0.00041958410292863846
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0008826367557048798
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.8358459025621414e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0007379694143310189
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0003002590674441308
sam_encoder.blocks.5.norm2.weight grad: 0.0002617982972878963
sam_encoder.blocks.5.norm2.bias grad: 0.0010364865884184837
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0001709318603388965
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.825366704608314e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.44228174071759e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.6199271815130487e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0008309048134833574
sam_encoder.blocks.6.norm1.bias grad: -0.0008657582802698016
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00029864555108360946
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.7583237422513776e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00028002855833619833
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00020983311696909368
sam_encoder.blocks.6.norm2.weight grad: 0.0006894235848449171
sam_encoder.blocks.6.norm2.bias grad: 0.0006484136683866382
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00031907123047858477
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.605674858903512e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00019110084394924343
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.905300011159852e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0004065270768478513
sam_encoder.blocks.7.norm1.bias grad: -5.9296085964888334e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00042454979848116636
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00025614589685574174
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00034701041295193136
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003302419208921492
sam_encoder.blocks.7.norm2.weight grad: -0.00024884610320441425
sam_encoder.blocks.7.norm2.bias grad: -0.0002854786580428481
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00045250810217112303
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002685164217837155
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00011832335439976305
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.337512993719429e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0002594966790638864
sam_encoder.blocks.8.norm1.bias grad: 0.00013220716209616512
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0004954212927259505
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00024476696853525937
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00032643877784721553
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00030709843849763274
sam_encoder.blocks.8.norm2.weight grad: -0.0006631977739743888
sam_encoder.blocks.8.norm2.bias grad: 0.0001539877848699689
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0007214710931293666
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.000419247051468119
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0002681738114915788
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.45934638264589e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00040149441338144243
sam_encoder.blocks.9.norm1.bias grad: -4.2831303289858624e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0003847930929623544
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0001771360111888498
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00019148537830915302
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0001487520639784634
sam_encoder.blocks.9.norm2.weight grad: -0.0009937186259776354
sam_encoder.blocks.9.norm2.bias grad: -0.00013725321332458407
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0009015949908643961
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0004684804880525917
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00018530459783505648
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.0427178242243826e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0007804498309269547
sam_encoder.blocks.10.norm1.bias grad: -5.6624259741511196e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0005130901117809117
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0002103655569953844
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0002423737314529717
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00012889993377029896
sam_encoder.blocks.10.norm2.weight grad: -0.002187760081142187
sam_encoder.blocks.10.norm2.bias grad: -0.0005540967686101794
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0010592513717710972
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0006300811073742807
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00027996866265311837
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.919739123783074e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0010868925601243973
sam_encoder.blocks.11.norm1.bias grad: 0.00012111023534089327
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0003382080467417836
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.71403862623265e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.0002360721555305645
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.112382784020156e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0022053667344152927
sam_encoder.blocks.11.norm2.bias grad: -0.00023347887326963246
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0008654892444610596
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0004312768578529358
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0002593011304270476
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00013416486035566777
sam_encoder.neck.conv1.trainable_scale grad: -5.784514360129833e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0014362495858222246
sam_encoder.neck.conv2.trainable_scale grad: 7.149088196456432e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.007629081141203642
mask_decoder.transformer.layers.0.norm1.weight grad: -0.006336074322462082
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0002724872902035713
mask_decoder.transformer.layers.0.norm2.weight grad: 0.5436640381813049
mask_decoder.transformer.layers.0.norm2.bias grad: 0.13721847534179688
mask_decoder.transformer.layers.0.norm3.weight grad: 0.010591201484203339
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00442894734442234
mask_decoder.transformer.layers.0.norm4.weight grad: -0.011055994778871536
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000742365256883204
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0009650468127802014
mask_decoder.transformer.layers.1.norm1.bias grad: -0.000683058868162334
mask_decoder.transformer.layers.1.norm2.weight grad: 0.030853725969791412
mask_decoder.transformer.layers.1.norm2.bias grad: 0.007023112382739782
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0019667595624923706
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0016444312641397119
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0030922796577215195
mask_decoder.transformer.layers.1.norm4.bias grad: 0.01910712942481041
mask_decoder.transformer.norm_final_attn.weight grad: -0.00018481312145013362
mask_decoder.transformer.norm_final_attn.bias grad: -0.0011189943179488182
Text_Embedding_Affine.0.weight grad: 2.2398344290408545e-10
Text_Embedding_Affine.0.bias grad: 1.3620592653751373e-08
Text_Embedding_Affine.2.weight grad: -2.627374984243147e-09
Text_Embedding_Affine.2.bias grad: -0.00025819195434451103

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.301000277098012e-10
Max value: 0.9992327690124512
Mean value: 0.10703379660844803

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.301000277098012e-10
Max value: 0.9992327690124512
Mean value: 0.10703379660844803

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11685943603515625

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.65863037109375
Max value: -1.1920928244535389e-07
Mean value: -0.1689264476299286

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09092521667480469

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11685943603515625

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 23.853939056396484
Max value: 76.72212219238281
Mean value: 57.38676071166992

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.301000277098012e-10
Max value: 0.9992327690124512
Mean value: 0.10703379660844803

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.301000277098012e-10
Max value: 0.9992327690124512
Mean value: 0.10703379660844803

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.301000277098012e-10
Max value: 0.9992327690124512
Mean value: 0.10703379660844803

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.65863037109375
Max value: -1.1920928244535389e-07
Mean value: -0.1689264476299286

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 23.853939056396484
Max value: 76.72212219238281
Mean value: 57.38676071166992

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.38835906982422
Max value: -57.38835906982422
Mean value: -57.38835906982422
sam_encoder.pos_embed grad: -1.0518008366489084e-06
sam_encoder.blocks.0.norm1.weight grad: -0.003665800904855132
sam_encoder.blocks.0.norm1.bias grad: 0.00033425280707888305
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.000801331247203052
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.459847206017002e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0004523670650087297
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.244259672414046e-06
sam_encoder.blocks.0.norm2.weight grad: 0.0037906616926193237
sam_encoder.blocks.0.norm2.bias grad: 0.0009306709980592132
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0001677041727816686
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003857774136122316
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.001234143041074276
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0005459709791466594
sam_encoder.blocks.1.norm1.weight grad: 0.0010657964739948511
sam_encoder.blocks.1.norm1.bias grad: 0.0007099073845893145
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00011093784996774048
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.333490894874558e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0003537558950483799
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.2554954891093075e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0012743370607495308
sam_encoder.blocks.1.norm2.bias grad: -0.0007026377134025097
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0005090762278996408
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00015812729543540627
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0004314636462368071
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.2150672773714177e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0011772013967856765
sam_encoder.blocks.2.norm1.bias grad: -0.0003941306786146015
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0003770876210182905
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.670051854802296e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0001929231220856309
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00020322085765656084
sam_encoder.blocks.2.norm2.weight grad: -0.0004625543369911611
sam_encoder.blocks.2.norm2.bias grad: 0.00027027667965739965
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00032268892391584814
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00029372365679591894
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0002830383600667119
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 4.1523358049744274e-06
sam_encoder.blocks.3.norm1.weight grad: -0.0005500854458659887
sam_encoder.blocks.3.norm1.bias grad: -0.00026338687166571617
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0001524703111499548
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.0416226107045077e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00023541638802271336
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00028078703326173127
sam_encoder.blocks.3.norm2.weight grad: 0.0009893508395180106
sam_encoder.blocks.3.norm2.bias grad: 0.0008225281490013003
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.001223334576934576
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00045396803761832416
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.51158669218421e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.586810923181474e-05
sam_encoder.blocks.4.norm1.weight grad: -0.00012361885455902666
sam_encoder.blocks.4.norm1.bias grad: -0.0006282684626057744
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.4016480640275404e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001197050660266541
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0003610490821301937
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00026982632698491216
sam_encoder.blocks.4.norm2.weight grad: -0.0019072707509621978
sam_encoder.blocks.4.norm2.bias grad: -0.0017482172697782516
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.001120787812396884
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0004848674579989165
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0001442612410755828
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.172746412223205e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0004932485171593726
sam_encoder.blocks.5.norm1.bias grad: -0.00013394956476986408
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0007566410349681973
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00032755988650023937
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0003554270078893751
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.911855856131297e-06
sam_encoder.blocks.5.norm2.weight grad: -0.0006005236646160483
sam_encoder.blocks.5.norm2.bias grad: -0.0013756013941019773
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.602186891133897e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.6907662181183696e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00014208888751454651
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.1848881917539984e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00022488593822345138
sam_encoder.blocks.6.norm1.bias grad: 0.0004799356684088707
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00019841318135149777
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0001618541282368824
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.432018512394279e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.9030452676815912e-05
sam_encoder.blocks.6.norm2.weight grad: -0.000640290672890842
sam_encoder.blocks.6.norm2.bias grad: -0.0004851230187341571
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00034063003840856254
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.841152884997427e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.939443558920175e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.739743599202484e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0005445160204544663
sam_encoder.blocks.7.norm1.bias grad: 0.00013024166401010007
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0005405456759035587
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00019360703299753368
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00040312419878318906
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00036118965363129973
sam_encoder.blocks.7.norm2.weight grad: 0.0005613191751763225
sam_encoder.blocks.7.norm2.bias grad: 0.00012721326493192464
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00037224520929157734
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.0001688196207396686
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.306266732281074e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00010424794163554907
sam_encoder.blocks.8.norm1.weight grad: -0.00014088455645833164
sam_encoder.blocks.8.norm1.bias grad: 2.0215386030031368e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0005208479706197977
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00028775015380233526
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0002585735637694597
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0002445483114570379
sam_encoder.blocks.8.norm2.weight grad: 0.000478711212053895
sam_encoder.blocks.8.norm2.bias grad: -0.0001627151359571144
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.0005875495844520628
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0002960209967568517
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0002605269255582243
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.4539976948290132e-05
sam_encoder.blocks.9.norm1.weight grad: -5.885262362426147e-05
sam_encoder.blocks.9.norm1.bias grad: 0.000133628083858639
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.463842095807195e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.960446964716539e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.941783820162527e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.189551408577245e-06
sam_encoder.blocks.9.norm2.weight grad: 0.0009506357600912452
sam_encoder.blocks.9.norm2.bias grad: -0.00012536733993329108
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0008696067961864173
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00042192271212115884
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00013556721387431026
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.270398444030434e-06
sam_encoder.blocks.10.norm1.weight grad: 0.00048655341379344463
sam_encoder.blocks.10.norm1.bias grad: 0.00014095965889282525
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00036937365075573325
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00019409651577007025
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00018893327796831727
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.0001125248963944614
sam_encoder.blocks.10.norm2.weight grad: 0.0014562191208824515
sam_encoder.blocks.10.norm2.bias grad: 2.705546467041131e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.000914291013032198
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00041037413757294416
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.499470666516572e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.2736559256154578e-05
sam_encoder.blocks.11.norm1.weight grad: 0.000634277705103159
sam_encoder.blocks.11.norm1.bias grad: 5.731166311306879e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00018252762674819678
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.099515015492216e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00017641640442889184
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.607497198274359e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0017013782635331154
sam_encoder.blocks.11.norm2.bias grad: -8.559735579183325e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0010577361099421978
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00029450125293806195
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.0508363124681637e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.0661300115752965e-05
sam_encoder.neck.conv1.trainable_scale grad: -5.19799068570137e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.000753118540160358
sam_encoder.neck.conv2.trainable_scale grad: -7.563130930066109e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.005346896592527628
mask_decoder.transformer.layers.0.norm1.weight grad: -0.002614533295854926
mask_decoder.transformer.layers.0.norm1.bias grad: 3.7606805562973022e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -1.079155683517456
mask_decoder.transformer.layers.0.norm2.bias grad: -0.050503335893154144
mask_decoder.transformer.layers.0.norm3.weight grad: -0.011922329664230347
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0009590438567101955
mask_decoder.transformer.layers.0.norm4.weight grad: 0.013578318059444427
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0011057519586756825
mask_decoder.transformer.layers.1.norm1.weight grad: 0.005724803078919649
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0003239160869270563
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0038636834360659122
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0002965116873383522
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004639891907572746
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0041896807961165905
mask_decoder.transformer.layers.1.norm4.weight grad: -0.005488788243383169
mask_decoder.transformer.layers.1.norm4.bias grad: -0.027049235999584198
mask_decoder.transformer.norm_final_attn.weight grad: 0.00034125358797609806
mask_decoder.transformer.norm_final_attn.bias grad: 0.001883436692878604
Text_Embedding_Affine.0.weight grad: -1.6676567904383433e-09
Text_Embedding_Affine.0.bias grad: -2.8405338525772095e-08
Text_Embedding_Affine.2.weight grad: 1.816659533915299e-08
Text_Embedding_Affine.2.bias grad: 0.000452414620667696
Epoch 30 finished with average loss: -54.4336
Epoch 31/39
----------
Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.7]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-55.7]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-54.4]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-54.4]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-55]  Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-55]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.6558323682618346e-13
Max value: 0.99791020154953
Mean value: 0.08424429595470428

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6558323682618346e-13
Max value: 0.99791020154953
Mean value: 0.08424429595470428

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08265447616577148

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.63924789428711
Max value: -1.1920928244535389e-07
Mean value: -0.1173224076628685

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07275581359863281

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08265447616577148

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.66089630126953
Max value: 84.21448516845703
Mean value: 55.728599548339844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.6558323682618346e-13
Max value: 0.99791020154953
Mean value: 0.08424429595470428

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6558323682618346e-13
Max value: 0.99791020154953
Mean value: 0.08424429595470428

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6558323682618346e-13
Max value: 0.99791020154953
Mean value: 0.08424429595470428

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.63924789428711
Max value: -1.1920928244535389e-07
Mean value: -0.1173224076628685

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.66089630126953
Max value: 84.21448516845703
Mean value: 55.728599548339844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.72984313964844
Max value: -55.72984313964844
Mean value: -55.72984313964844
sam_encoder.pos_embed grad: -5.131093416821386e-07
sam_encoder.blocks.0.norm1.weight grad: -0.00036118782008998096
sam_encoder.blocks.0.norm1.bias grad: 3.042475782422116e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00038957037031650543
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00014301121700555086
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.500542854657397e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00035390816628932953
sam_encoder.blocks.0.norm2.weight grad: 0.005320427473634481
sam_encoder.blocks.0.norm2.bias grad: -0.005837759934365749
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0027535639237612486
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0010143659310415387
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.004055186174809933
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.000881590589415282
sam_encoder.blocks.1.norm1.weight grad: -5.563276863540523e-05
sam_encoder.blocks.1.norm1.bias grad: -0.000984010985121131
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005120927235111594
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00026088239974342287
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0008044188725762069
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00033038732362911105
sam_encoder.blocks.1.norm2.weight grad: 0.0026903562247753143
sam_encoder.blocks.1.norm2.bias grad: 0.0007517458871006966
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.343141234945506e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.687957597430795e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0007692434592172503
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.439676947891712e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0012290871236473322
sam_encoder.blocks.2.norm1.bias grad: 0.0005314878653734922
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0005670181708410382
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00027407772722654045
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0006947831134311855
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00039609376108273864
sam_encoder.blocks.2.norm2.weight grad: -0.0014319925103336573
sam_encoder.blocks.2.norm2.bias grad: 0.0002447252336423844
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0008071723859757185
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.609005580074154e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005438168300315738
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0001628583704587072
sam_encoder.blocks.3.norm1.weight grad: -0.001223523635417223
sam_encoder.blocks.3.norm1.bias grad: 0.0001984958944376558
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0009412711369805038
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0003405785537324846
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0001899567141663283
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0003111122059635818
sam_encoder.blocks.3.norm2.weight grad: -0.002079347614198923
sam_encoder.blocks.3.norm2.bias grad: -0.0011542490683495998
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0016313226660713553
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0005358710186555982
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0005294512375257909
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00018855577218346298
sam_encoder.blocks.4.norm1.weight grad: 0.0003087051445618272
sam_encoder.blocks.4.norm1.bias grad: -0.002284675370901823
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0005048426100984216
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.756962440907955e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0001572573382873088
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00010584543633740395
sam_encoder.blocks.4.norm2.weight grad: 0.0016624241834506392
sam_encoder.blocks.4.norm2.bias grad: 0.00012721556413453072
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.000766222074162215
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0001640349510125816
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0003463441680651158
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00026560481637716293
sam_encoder.blocks.5.norm1.weight grad: 0.0004479841736610979
sam_encoder.blocks.5.norm1.bias grad: -0.0029590632766485214
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00012680252257268876
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.518222264479846e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0005660431925207376
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.616478665615432e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0016749263741075993
sam_encoder.blocks.5.norm2.bias grad: -0.00048732664436101913
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0009174084989354014
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00042989617213606834
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00013802754983771592
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.8948596082045697e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0005077853566035628
sam_encoder.blocks.6.norm1.bias grad: -0.0004951390437781811
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00041667462210170925
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00026884887483902276
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.1652378816506825e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.922327207168564e-05
sam_encoder.blocks.6.norm2.weight grad: -0.00116565206553787
sam_encoder.blocks.6.norm2.bias grad: -0.00029601616552099586
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0011704155476763844
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0005085848970338702
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.000297753227641806
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00011218103463761508
sam_encoder.blocks.7.norm1.weight grad: 0.0011930917389690876
sam_encoder.blocks.7.norm1.bias grad: -0.0003361774142831564
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0007573984330520034
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00024955475237220526
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00016351351223420352
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00019747894839383662
sam_encoder.blocks.7.norm2.weight grad: 8.91540403245017e-05
sam_encoder.blocks.7.norm2.bias grad: -1.12259685920435e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0002774631429929286
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.649154187878594e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.233186963479966e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.385815064888448e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0003320933901704848
sam_encoder.blocks.8.norm1.bias grad: -0.0004688984190579504
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0006752129993401468
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00034529383992776275
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.8177531172987074e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00030627549858763814
sam_encoder.blocks.8.norm2.weight grad: -0.0004040546191390604
sam_encoder.blocks.8.norm2.bias grad: 1.3343436876311898e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00043258152436465025
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00022263985010795295
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00011152120714541525
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.677165220025927e-05
sam_encoder.blocks.9.norm1.weight grad: -8.256414730567485e-05
sam_encoder.blocks.9.norm1.bias grad: 5.7867531722877175e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.899714885046706e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.4647422328125685e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.536092870286666e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.921432552393526e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0006113306153565645
sam_encoder.blocks.9.norm2.bias grad: -9.286731801694259e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0005436853971332312
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0002904227585531771
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.9512561266310513e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.9457045457093045e-05
sam_encoder.blocks.10.norm1.weight grad: -6.7643318288901355e-06
sam_encoder.blocks.10.norm1.bias grad: 1.3651413610205054e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.6737516489229165e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.4951947377994657e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.28102833009325e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0435480362502858e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0004609081079252064
sam_encoder.blocks.10.norm2.bias grad: -0.00021837578970007598
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00019855389837175608
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00017019826918840408
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.664587711682543e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.785286596918013e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0008044224232435226
sam_encoder.blocks.11.norm1.bias grad: 0.00013146395212970674
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0004124398692511022
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00015265810361597687
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.854291182709858e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.139072451740503e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0008226327481679618
sam_encoder.blocks.11.norm2.bias grad: -0.00032090264721773565
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.139713615179062e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00010733064118539914
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.405179298482835e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.088381582638249e-05
sam_encoder.neck.conv1.trainable_scale grad: -5.753757432103157e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0008463241392746568
sam_encoder.neck.conv2.trainable_scale grad: 1.409091055393219e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0017116365488618612
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0009186533279716969
mask_decoder.transformer.layers.0.norm1.bias grad: -2.6592053472995758e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.06468985974788666
mask_decoder.transformer.layers.0.norm2.bias grad: 0.033334068953990936
mask_decoder.transformer.layers.0.norm3.weight grad: -0.015682702884078026
mask_decoder.transformer.layers.0.norm3.bias grad: -0.001980239525437355
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0005965158343315125
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0002698702737689018
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0003134768339805305
mask_decoder.transformer.layers.1.norm1.bias grad: 8.869596058502793e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0026274570263922215
mask_decoder.transformer.layers.1.norm2.bias grad: -0.002225826494395733
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004912520293146372
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0007128384313546121
mask_decoder.transformer.layers.1.norm4.weight grad: 0.007659050170332193
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0018064780160784721
mask_decoder.transformer.norm_final_attn.weight grad: -3.360748814884573e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.00010668369941413403
Text_Embedding_Affine.0.weight grad: -8.548126095853092e-10
Text_Embedding_Affine.0.bias grad: -1.6676494851708412e-08
Text_Embedding_Affine.2.weight grad: -6.249540329683612e-10
Text_Embedding_Affine.2.bias grad: 8.492497727274895e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.738725021384397e-12
Max value: 0.9967934489250183
Mean value: 0.08246581256389618

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.738725021384397e-12
Max value: 0.9967934489250183
Mean value: 0.08246581256389618

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0770268440246582

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1219203844666481

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07039165496826172

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0770268440246582

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.669296264648438
Max value: 67.2431869506836
Mean value: 53.094261169433594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.738725021384397e-12
Max value: 0.9967934489250183
Mean value: 0.08246581256389618

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.738725021384397e-12
Max value: 0.9967934489250183
Mean value: 0.08246581256389618

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.738725021384397e-12
Max value: 0.9967934489250183
Mean value: 0.08246581256389618

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1219203844666481

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.669296264648438
Max value: 67.2431869506836
Mean value: 53.094261169433594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.095458984375
Max value: -53.095458984375
Mean value: -53.095458984375
sam_encoder.pos_embed grad: 5.47018714769365e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0027221799828112125
sam_encoder.blocks.0.norm1.bias grad: -0.0007735146209597588
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0002671091351658106
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 0.00013099724310450256
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00019384745974093676
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0001086938864318654
sam_encoder.blocks.0.norm2.weight grad: 0.001022728974930942
sam_encoder.blocks.0.norm2.bias grad: 0.00010733204544521868
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00045736724860034883
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.100077785551548e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00026616238756105304
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0003411775396671146
sam_encoder.blocks.1.norm1.weight grad: 0.00033553523826412857
sam_encoder.blocks.1.norm1.bias grad: 0.001403399626724422
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00023590726777911186
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -6.355436926241964e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00044199987314641476
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002756747999228537
sam_encoder.blocks.1.norm2.weight grad: 0.0005150510114617646
sam_encoder.blocks.1.norm2.bias grad: -0.0004971965681761503
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00018859491683542728
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.2463896786794066e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0004254730883985758
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.716194133739918e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0017696376889944077
sam_encoder.blocks.2.norm1.bias grad: 0.00013343992759473622
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0011149466736242175
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0002909430768340826
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003834146773442626
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0002178690629079938
sam_encoder.blocks.2.norm2.weight grad: -0.00023807850084267557
sam_encoder.blocks.2.norm2.bias grad: -9.361857519252226e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0004705425235442817
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.382535841315985e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0004910821444354951
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00012863511801697314
sam_encoder.blocks.3.norm1.weight grad: -0.0001797389704734087
sam_encoder.blocks.3.norm1.bias grad: 0.0001054170643328689
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0003983663336839527
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.733760089147836e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0004942183149978518
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00027404510183259845
sam_encoder.blocks.3.norm2.weight grad: -0.000924328516703099
sam_encoder.blocks.3.norm2.bias grad: -0.0009272826137021184
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0009278686484321952
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00026328995591029525
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0002562516601756215
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00019484855874907225
sam_encoder.blocks.4.norm1.weight grad: 0.0012013412779197097
sam_encoder.blocks.4.norm1.bias grad: 0.0003345161385368556
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0004443042853381485
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.660768900066614e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.8153143173549324e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00012590811820700765
sam_encoder.blocks.4.norm2.weight grad: -0.0006375892553478479
sam_encoder.blocks.4.norm2.bias grad: -0.0003799046971835196
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0005282288184389472
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00016336757107637823
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00015957870346028358
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00011233007535338402
sam_encoder.blocks.5.norm1.weight grad: 0.0007666556048206985
sam_encoder.blocks.5.norm1.bias grad: -0.0010151801398023963
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.000745507306419313
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00025090662529692054
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.396227137069218e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0002886952424887568
sam_encoder.blocks.5.norm2.weight grad: -0.00023269682424142957
sam_encoder.blocks.5.norm2.bias grad: 8.322024950757623e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0002599841100163758
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00011116303357994184
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3922946891398169e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.019805030315183e-05
sam_encoder.blocks.6.norm1.weight grad: -9.660563955549151e-05
sam_encoder.blocks.6.norm1.bias grad: -0.0005477210506796837
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.2460098484298214e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.718102228362113e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.71970410621725e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.072618559002876e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0005179267609491944
sam_encoder.blocks.6.norm2.bias grad: 0.00036323192762210965
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.876705785747617e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.131213477696292e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.801163853087928e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0288138330215588e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0001257089024875313
sam_encoder.blocks.7.norm1.bias grad: -6.888117059133947e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00015971579705365002
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.813498425297439e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00019978894852101803
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003139281179755926
sam_encoder.blocks.7.norm2.weight grad: 0.00019998237257823348
sam_encoder.blocks.7.norm2.bias grad: -0.0001327054196735844
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00014480430399999022
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.4153159099805634e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5392539353342727e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.443126090336591e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0004100902588106692
sam_encoder.blocks.8.norm1.bias grad: -0.00021856054081581533
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0007409316021949053
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00023104940191842616
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.277566767996177e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.513144424185157e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0006290549645200372
sam_encoder.blocks.8.norm2.bias grad: 0.00011028826702386141
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0006479655276052654
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00033574827830307186
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00040871798410080373
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00014865328557789326
sam_encoder.blocks.9.norm1.weight grad: -8.174397953553125e-05
sam_encoder.blocks.9.norm1.bias grad: -8.997326222015545e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.053774657426402e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.1332554752007127e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.8728052964434028e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5370809705927968e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0007725277682766318
sam_encoder.blocks.9.norm2.bias grad: 1.6127238268381916e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0006151708075776696
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0003283733385615051
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00013473884609993547
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.2833777873311192e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00018160662148147821
sam_encoder.blocks.10.norm1.bias grad: -2.0600235075107776e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00021366920555010438
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0001000824267975986
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.26285798009485e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.431892764638178e-05
sam_encoder.blocks.10.norm2.weight grad: -0.001214259653352201
sam_encoder.blocks.10.norm2.bias grad: -3.172911601723172e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0006605376256629825
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00030685579986311495
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.322290861746296e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.235135864088079e-06
sam_encoder.blocks.11.norm1.weight grad: -0.0006055964040569961
sam_encoder.blocks.11.norm1.bias grad: 8.770037675276399e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0004357512225396931
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.0304606955032796e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.0154646335868165e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.1843841750524007e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0013347932836040854
sam_encoder.blocks.11.norm2.bias grad: 0.00017690667300485075
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0006752449553459883
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00028232071781530976
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00013392769324127585
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.35055107017979e-05
sam_encoder.neck.conv1.trainable_scale grad: -1.2563075870275497e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0015224434901028872
sam_encoder.neck.conv2.trainable_scale grad: 1.0302755981683731e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.00554543174803257
mask_decoder.transformer.layers.0.norm1.weight grad: -0.004693829920142889
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0003142678178846836
mask_decoder.transformer.layers.0.norm2.weight grad: 0.4721950888633728
mask_decoder.transformer.layers.0.norm2.bias grad: 0.06768989562988281
mask_decoder.transformer.layers.0.norm3.weight grad: 0.006969360634684563
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0013626086292788386
mask_decoder.transformer.layers.0.norm4.weight grad: -0.008561807684600353
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0008525572484359145
mask_decoder.transformer.layers.1.norm1.weight grad: -0.002957257442176342
mask_decoder.transformer.layers.1.norm1.bias grad: 3.624870441854e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.014016053639352322
mask_decoder.transformer.layers.1.norm2.bias grad: -0.003230530768632889
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0017514426726847887
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0026225887704640627
mask_decoder.transformer.layers.1.norm4.weight grad: 0.007431241683661938
mask_decoder.transformer.layers.1.norm4.bias grad: 0.01658296212553978
mask_decoder.transformer.norm_final_attn.weight grad: 0.00016968122508842498
mask_decoder.transformer.norm_final_attn.bias grad: -0.0010277110850438476
Text_Embedding_Affine.0.weight grad: -4.63886012935788e-10
Text_Embedding_Affine.0.bias grad: -2.2526364773511887e-08
Text_Embedding_Affine.2.weight grad: -6.2692295799138265e-09
Text_Embedding_Affine.2.bias grad: 0.0011540497653186321

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.910171489517893e-10
Max value: 0.9993751645088196
Mean value: 0.08829881995916367

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.910171489517893e-10
Max value: 0.9993751645088196
Mean value: 0.08829881995916367

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09951114654541016

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.002236366271973
Max value: -1.1920928244535389e-07
Mean value: -0.12732243537902832

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08266067504882812

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09951114654541016

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 25.99713706970215
Max value: 77.16108703613281
Mean value: 56.184417724609375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.910171489517893e-10
Max value: 0.9993751645088196
Mean value: 0.08829881995916367

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.910171489517893e-10
Max value: 0.9993751645088196
Mean value: 0.08829881995916367

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.910171489517893e-10
Max value: 0.9993751645088196
Mean value: 0.08829881995916367

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.002236366271973
Max value: -1.1920928244535389e-07
Mean value: -0.12732243537902832

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 25.99713706970215
Max value: 77.16108703613281
Mean value: 56.184417724609375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.18552017211914
Max value: -56.18552017211914
Mean value: -56.18552017211914
sam_encoder.pos_embed grad: -6.932824447858366e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0006482020253315568
sam_encoder.blocks.0.norm1.bias grad: 0.00029416289180517197
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00023923224944155663
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.4326451491797343e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00025689357426017523
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.9458000426529907e-05
sam_encoder.blocks.0.norm2.weight grad: -0.0009184136870317161
sam_encoder.blocks.0.norm2.bias grad: 8.831937884679064e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00011969164188485593
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0002150562941096723
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.00022088193509262055
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00012421375140547752
sam_encoder.blocks.1.norm1.weight grad: -0.0008381170919165015
sam_encoder.blocks.1.norm1.bias grad: 0.00011600075958995149
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.481228047050536e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.916556801821571e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.2615898312069476e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.5774614439578727e-05
sam_encoder.blocks.1.norm2.weight grad: -0.0006737977964803576
sam_encoder.blocks.1.norm2.bias grad: -0.000505616539157927
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.598708281060681e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.94754349347204e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.219393541570753e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.8536803711176617e-06
sam_encoder.blocks.2.norm1.weight grad: 0.00026862716185860336
sam_encoder.blocks.2.norm1.bias grad: -0.000551692966837436
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.3893328034318984e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.5291282983962446e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00014330731937661767
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0850160833797418e-05
sam_encoder.blocks.2.norm2.weight grad: -3.379437839612365e-05
sam_encoder.blocks.2.norm2.bias grad: -8.501716365572065e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.297198185871821e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.590304236742668e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00019533696467988193
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.8409907321911305e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0007841702317818999
sam_encoder.blocks.3.norm1.bias grad: -0.000167434845934622
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.00045231886906549335
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.757452840451151e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00021537381689995527
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.311651617987081e-05
sam_encoder.blocks.3.norm2.weight grad: 0.00013849786773789674
sam_encoder.blocks.3.norm2.bias grad: 0.0002766550751402974
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00012370622425805777
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.3458304238156416e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.7001588023267686e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.6093889725161716e-05
sam_encoder.blocks.4.norm1.weight grad: -0.00039273357833735645
sam_encoder.blocks.4.norm1.bias grad: -0.00013643955753650516
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00021528045181185007
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00011247317161178216
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.255398486449849e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.350763785827439e-06
sam_encoder.blocks.4.norm2.weight grad: 0.0004812375991605222
sam_encoder.blocks.4.norm2.bias grad: 9.242210944648832e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0003218288184143603
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00014239069423638284
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00010467111133038998
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.552813960704952e-05
sam_encoder.blocks.5.norm1.weight grad: -0.00020663274335674942
sam_encoder.blocks.5.norm1.bias grad: 6.541268521687016e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0003960322355851531
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00018098617147188634
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.9042475691530854e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00012848206097260118
sam_encoder.blocks.5.norm2.weight grad: 0.0005044365534558892
sam_encoder.blocks.5.norm2.bias grad: -0.00020938237139489502
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0002760942152235657
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00012596146552823484
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.451083830441348e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.417650052346289e-05
sam_encoder.blocks.6.norm1.weight grad: -0.000221635855268687
sam_encoder.blocks.6.norm1.bias grad: -8.430973684880883e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00017309430404566228
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.718174310866743e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.761588595807552e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.278531999560073e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0003850513603538275
sam_encoder.blocks.6.norm2.bias grad: -9.004162711789832e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0002950866473838687
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00013008071982767433
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.063258767127991e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.987700983998366e-05
sam_encoder.blocks.7.norm1.weight grad: 7.223976717796177e-05
sam_encoder.blocks.7.norm1.bias grad: 6.655817560385913e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00011540892592165619
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.504532939288765e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.900312630226836e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.3742682717274874e-05
sam_encoder.blocks.7.norm2.weight grad: 0.0002074307994917035
sam_encoder.blocks.7.norm2.bias grad: 5.039097595727071e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.171564407646656e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.115908864652738e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.4865679228678346e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.313593283062801e-05
sam_encoder.blocks.8.norm1.weight grad: -0.00013665668666362762
sam_encoder.blocks.8.norm1.bias grad: 0.0001310423540417105
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0002693117130547762
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.044215403264388e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.913076943717897e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00018058977730106562
sam_encoder.blocks.8.norm2.weight grad: 0.00013919419143348932
sam_encoder.blocks.8.norm2.bias grad: -9.725394193083048e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.0566414857748896e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.3167318431660533e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.7840621846262366e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.2127132979221642e-05
sam_encoder.blocks.9.norm1.weight grad: 3.167730392306112e-05
sam_encoder.blocks.9.norm1.bias grad: 2.3324346329900436e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.886844544671476e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.881724170350935e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.5973107767640613e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.159671465866268e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0004323608591221273
sam_encoder.blocks.9.norm2.bias grad: 4.3866159103345126e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00019259456894360483
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00014251598622649908
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.084908379008994e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.4957746063591912e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00016813496768008918
sam_encoder.blocks.10.norm1.bias grad: 7.22436816431582e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.780669693602249e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.5753519366844557e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.212589035683777e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.1310887202853337e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0002511833736207336
sam_encoder.blocks.10.norm2.bias grad: -0.0001663631701376289
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.68571548582986e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.355474862270057e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.7049562302418053e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.759095539455302e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0003640400245785713
sam_encoder.blocks.11.norm1.bias grad: 8.437898213742301e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.1944672375393566e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.974265044031199e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.358300743158907e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.662732706288807e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0002208733931183815
sam_encoder.blocks.11.norm2.bias grad: -0.000231529280426912
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00011152851220685989
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2650375538214575e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.9240716230560793e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.8427208235370927e-05
sam_encoder.neck.conv1.trainable_scale grad: 1.5085097402334213e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.00033464201260358095
sam_encoder.neck.conv2.trainable_scale grad: 2.8954236768186092e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0012699568178504705
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0005078453104943037
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00024410709738731384
mask_decoder.transformer.layers.0.norm2.weight grad: -0.21532535552978516
mask_decoder.transformer.layers.0.norm2.bias grad: -0.036428146064281464
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0036378640215843916
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0010643858695402741
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0025007431395351887
mask_decoder.transformer.layers.0.norm4.bias grad: -0.00026198691921308637
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0023729854729026556
mask_decoder.transformer.layers.1.norm1.bias grad: -7.176527287811041e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0032061871606856585
mask_decoder.transformer.layers.1.norm2.bias grad: 0.002470993436872959
mask_decoder.transformer.layers.1.norm3.weight grad: -4.772277316078544e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.001914335647597909
mask_decoder.transformer.layers.1.norm4.weight grad: -0.004039888270199299
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0023895036429166794
mask_decoder.transformer.norm_final_attn.weight grad: 0.00016345140466000885
mask_decoder.transformer.norm_final_attn.bias grad: 0.0003906584461219609
Text_Embedding_Affine.0.weight grad: 1.0542899886445412e-11
Text_Embedding_Affine.0.bias grad: -1.0986695997416973e-08
Text_Embedding_Affine.2.weight grad: 6.755062620378283e-10
Text_Embedding_Affine.2.bias grad: -0.0012964733177796006
Epoch 31 finished with average loss: -55.0036
Epoch 32/39
----------
Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s, loss=-54.1]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.20it/s, loss=-54.1]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.20it/s, loss=-56.9]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.75it/s, loss=-56.9]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.75it/s, loss=-57.8]Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.37it/s, loss=-57.8]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6149135793810249e-13
Max value: 0.9991307854652405
Mean value: 0.07817408442497253

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6149135793810249e-13
Max value: 0.9991307854652405
Mean value: 0.07817408442497253

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07468175888061523

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10939528048038483

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06981658935546875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07468175888061523

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.016902923583984
Max value: 86.06458282470703
Mean value: 54.1043701171875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6149135793810249e-13
Max value: 0.9991307854652405
Mean value: 0.07817408442497253

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6149135793810249e-13
Max value: 0.9991307854652405
Mean value: 0.07817408442497253

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6149135793810249e-13
Max value: 0.9991307854652405
Mean value: 0.07817408442497253

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10939528048038483

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.016902923583984
Max value: 86.06458282470703
Mean value: 54.1043701171875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.10539627075195
Max value: -54.10539627075195
Mean value: -54.10539627075195
sam_encoder.pos_embed grad: -1.2743279285132303e-06
sam_encoder.blocks.0.norm1.weight grad: -0.005770208314061165
sam_encoder.blocks.0.norm1.bias grad: 0.0006791249616071582
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0007969836005941033
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.776705281983595e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00025120089412666857
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00037593598244711757
sam_encoder.blocks.0.norm2.weight grad: 0.004590320400893688
sam_encoder.blocks.0.norm2.bias grad: 0.01039933878928423
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0015285336412489414
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0013393944827839732
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0019191623432561755
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0012965057976543903
sam_encoder.blocks.1.norm1.weight grad: -0.0016276484820991755
sam_encoder.blocks.1.norm1.bias grad: 0.00011666107457131147
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0005384553805924952
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.470872565638274e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.1685778847313486e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.394583710469306e-05
sam_encoder.blocks.1.norm2.weight grad: 0.002117876661941409
sam_encoder.blocks.1.norm2.bias grad: 2.0563526049954817e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0004381586331874132
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00014215036935638636
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.000808228156529367
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00025524836382828653
sam_encoder.blocks.2.norm1.weight grad: 0.0022620144300162792
sam_encoder.blocks.2.norm1.bias grad: -0.002226710319519043
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0011986205354332924
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00020619816496036947
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00012502609752118587
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003888540668413043
sam_encoder.blocks.2.norm2.weight grad: 0.0017477825749665499
sam_encoder.blocks.2.norm2.bias grad: -0.00014924033894203603
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0009687867714092135
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00010896137973759323
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.0006730745080858469
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.539285823237151e-05
sam_encoder.blocks.3.norm1.weight grad: 0.001026482554152608
sam_encoder.blocks.3.norm1.bias grad: -0.0018499767174944282
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0004965341067872941
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.600394797511399e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0006030036020092666
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.00030479696579277515
sam_encoder.blocks.3.norm2.weight grad: 0.001219234662130475
sam_encoder.blocks.3.norm2.bias grad: -0.0005048415041528642
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0012725002598017454
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.0003125082585029304
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0010623622220009565
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00031970543204806745
sam_encoder.blocks.4.norm1.weight grad: 0.0032664351165294647
sam_encoder.blocks.4.norm1.bias grad: -0.0022869501262903214
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0018348016310483217
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0005060892435722053
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.000977840623818338
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0008809067076072097
sam_encoder.blocks.4.norm2.weight grad: -0.0034190926235169172
sam_encoder.blocks.4.norm2.bias grad: -0.002947496250271797
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0020042266696691513
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0008545966120436788
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0003663716488517821
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.2320320820435882e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0030739677604287863
sam_encoder.blocks.5.norm1.bias grad: -0.0023487701546400785
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0020776973105967045
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0006305769784376025
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0011315164156258106
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.000520955421961844
sam_encoder.blocks.5.norm2.weight grad: -0.0006472303648479283
sam_encoder.blocks.5.norm2.bias grad: -0.0008923984132707119
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 7.219830149551854e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.6230449040886015e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00038561641122214496
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.642021329142153e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0009830961935222149
sam_encoder.blocks.6.norm1.bias grad: 0.0003398089320398867
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0005714587750844657
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00030435301596298814
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00030694156885147095
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00019500455528032035
sam_encoder.blocks.6.norm2.weight grad: -0.0016604395350441337
sam_encoder.blocks.6.norm2.bias grad: -0.0008806079858914018
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0011543876025825739
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00045660100295208395
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0001428808900527656
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.982996663078666e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0011357341427356005
sam_encoder.blocks.7.norm1.bias grad: 9.428452904103324e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0008160588331520557
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0005402518436312675
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0003720723034348339
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00043669852311722934
sam_encoder.blocks.7.norm2.weight grad: -0.0002868299779947847
sam_encoder.blocks.7.norm2.bias grad: 0.00010025163646787405
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00010686463065212592
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.121142774238251e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.446251013083383e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00011463082046248019
sam_encoder.blocks.8.norm1.weight grad: 0.0008513568318448961
sam_encoder.blocks.8.norm1.bias grad: -0.0003228879068046808
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.000578259932808578
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0001498000929132104
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.000498291861731559
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.0003736231883522123
sam_encoder.blocks.8.norm2.weight grad: -2.8579652280313894e-05
sam_encoder.blocks.8.norm2.bias grad: -0.00020641872833948582
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.9977599196136e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.015822095330805e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00013056030729785562
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.2536664144136012e-05
sam_encoder.blocks.9.norm1.weight grad: -3.373483195900917e-06
sam_encoder.blocks.9.norm1.bias grad: 5.9627236623782665e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.952651842264459e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.113169779884629e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.708924512262456e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0001055495667969808
sam_encoder.blocks.9.norm2.weight grad: 0.0007244910812005401
sam_encoder.blocks.9.norm2.bias grad: 0.00015593122225254774
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0004597346414811909
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00032945090788416564
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00016979622887447476
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.4637422282248735e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0003851754008792341
sam_encoder.blocks.10.norm1.bias grad: 8.044743299251422e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00016885960940271616
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00013513023441191763
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00010846725490409881
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.8116984291700646e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0020967558957636356
sam_encoder.blocks.10.norm2.bias grad: 0.0006416662945412099
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0007669427432119846
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.000597005826421082
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0003867918567266315
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.492801599553786e-05
sam_encoder.blocks.11.norm1.weight grad: 0.002085837535560131
sam_encoder.blocks.11.norm1.bias grad: -8.850067388266325e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.666184683330357e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.3653315111005213e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00022580198128707707
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.076704812585376e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0017611099174246192
sam_encoder.blocks.11.norm2.bias grad: 0.00025433485279791057
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0006657461635768414
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0003140468033961952
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00015137949958443642
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.801347914617509e-05
sam_encoder.neck.conv1.trainable_scale grad: 0.00013154430780559778
sam_encoder.neck.conv1.trainable_shift grad: 0.0011054002679884434
sam_encoder.neck.conv2.trainable_scale grad: 3.3692456781864166e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.00412876158952713
mask_decoder.transformer.layers.0.norm1.weight grad: 0.02435581013560295
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0006345715373754501
mask_decoder.transformer.layers.0.norm2.weight grad: -0.5984758138656616
mask_decoder.transformer.layers.0.norm2.bias grad: -0.2847907245159149
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0032417578622698784
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0091971755027771
mask_decoder.transformer.layers.0.norm4.weight grad: 0.01859305053949356
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0011834725737571716
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0033965252805501223
mask_decoder.transformer.layers.1.norm1.bias grad: 0.001511383568868041
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0441434346139431
mask_decoder.transformer.layers.1.norm2.bias grad: -0.009698460809886456
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0006627654656767845
mask_decoder.transformer.layers.1.norm3.bias grad: -0.005463482346385717
mask_decoder.transformer.layers.1.norm4.weight grad: -0.008510520681738853
mask_decoder.transformer.layers.1.norm4.bias grad: -0.024020090699195862
mask_decoder.transformer.norm_final_attn.weight grad: -0.00025921844644472003
mask_decoder.transformer.norm_final_attn.bias grad: 0.0013773005921393633
Text_Embedding_Affine.0.weight grad: -3.1790716725765833e-09
Text_Embedding_Affine.0.bias grad: -9.417999535799026e-08
Text_Embedding_Affine.2.weight grad: -1.3408511634338538e-08
Text_Embedding_Affine.2.bias grad: -0.002316715195775032

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.389571639737554e-14
Max value: 0.9992517828941345
Mean value: 0.08274035155773163

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.389571639737554e-14
Max value: 0.9992517828941345
Mean value: 0.08274035155773163

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08804702758789062

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12385672330856323

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07251691818237305

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08804702758789062

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.36780548095703
Max value: 76.58396911621094
Mean value: 59.70259094238281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.389571639737554e-14
Max value: 0.9992517828941345
Mean value: 0.08274035155773163

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.389571639737554e-14
Max value: 0.9992517828941345
Mean value: 0.08274035155773163

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.389571639737554e-14
Max value: 0.9992517828941345
Mean value: 0.08274035155773163

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12385672330856323

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.36780548095703
Max value: 76.58396911621094
Mean value: 59.70259094238281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.70370101928711
Max value: -59.70370101928711
Mean value: -59.70370101928711
sam_encoder.pos_embed grad: -4.0124609768099617e-07
sam_encoder.blocks.0.norm1.weight grad: 0.000893384451046586
sam_encoder.blocks.0.norm1.bias grad: -0.0016262694261968136
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00033658521715551615
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.4929638786707073e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00019245478324592113
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.494650031323545e-05
sam_encoder.blocks.0.norm2.weight grad: -2.3504049750044942e-05
sam_encoder.blocks.0.norm2.bias grad: 0.001483714091591537
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00021941341401543468
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.9300199356803205e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0003917250724043697
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.721424142597243e-05
sam_encoder.blocks.1.norm1.weight grad: -0.0002517413813620806
sam_encoder.blocks.1.norm1.bias grad: -0.000329129456076771
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00023686772328801453
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.138007170695346e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0002457082737237215
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 9.034678078023717e-05
sam_encoder.blocks.1.norm2.weight grad: -0.000775938096921891
sam_encoder.blocks.1.norm2.bias grad: -0.00010621870023896918
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.385398203041404e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.322718010982499e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0004084068350493908
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00010587048018351197
sam_encoder.blocks.2.norm1.weight grad: 0.0005126902833580971
sam_encoder.blocks.2.norm1.bias grad: -0.0009261196246370673
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00035899848444387317
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00013356054842006415
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.00033444652217440307
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00019035552395507693
sam_encoder.blocks.2.norm2.weight grad: 0.0002325305831618607
sam_encoder.blocks.2.norm2.bias grad: 0.00020449698786251247
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00026439144858159125
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.4889770429581404e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00017246208153665066
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.43273742753081e-05
sam_encoder.blocks.3.norm1.weight grad: 0.000781401467975229
sam_encoder.blocks.3.norm1.bias grad: -0.0004403538187034428
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0007281213765963912
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00013776475680060685
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0002961681457236409
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.252001473214477e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0002119108976330608
sam_encoder.blocks.3.norm2.bias grad: 0.0009698967332951725
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00020113945356570184
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.4464752136263996e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.430103480350226e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.500833402853459e-05
sam_encoder.blocks.4.norm1.weight grad: -0.0008325970266014338
sam_encoder.blocks.4.norm1.bias grad: -0.00032017179182730615
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0005151350051164627
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.0001467966940253973
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3659955584444106e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.2305332095129415e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0009088261285796762
sam_encoder.blocks.4.norm2.bias grad: 0.00048774489550851285
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0005842705722898245
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00022264127619564533
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.944524986669421e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.8498201572801918e-05
sam_encoder.blocks.5.norm1.weight grad: -2.5034572900040075e-05
sam_encoder.blocks.5.norm1.bias grad: 7.724211172899231e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.7571803558385e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0001507198321633041
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.474568312522024e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00011467737931525335
sam_encoder.blocks.5.norm2.weight grad: 0.000576497579459101
sam_encoder.blocks.5.norm2.bias grad: -3.946976357838139e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00022216785873752087
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00012726119894068688
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.911874854471534e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.811528949881904e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0002493584470357746
sam_encoder.blocks.6.norm1.bias grad: 9.077141294255853e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00015772176266182214
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.191598029341549e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.0001085936528397724
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00015327158325817436
sam_encoder.blocks.6.norm2.weight grad: 2.6462517780601047e-05
sam_encoder.blocks.6.norm2.bias grad: -7.81191629357636e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.294042395893484e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.98138784780167e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.837772576138377e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.191994670080021e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00018479078426025808
sam_encoder.blocks.7.norm1.bias grad: 0.00013187530566938221
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00019762368174269795
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00010417369048809633
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0001976426283363253
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00020468863658607006
sam_encoder.blocks.7.norm2.weight grad: 0.000175637353095226
sam_encoder.blocks.7.norm2.bias grad: 0.0001456579630030319
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0001485110551584512
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.404040060355328e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.5762750738067552e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.26186005724594e-05
sam_encoder.blocks.8.norm1.weight grad: -2.6796295060194097e-05
sam_encoder.blocks.8.norm1.bias grad: 8.830075239529833e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0002244763309136033
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.181102748494595e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.1454375352477655e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.288812149548903e-05
sam_encoder.blocks.8.norm2.weight grad: 0.00033212441485375166
sam_encoder.blocks.8.norm2.bias grad: -7.307447958737612e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00023682310711592436
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00017348163237329572
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00016945716924965382
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.843982216902077e-05
sam_encoder.blocks.9.norm1.weight grad: -2.0549075543385698e-06
sam_encoder.blocks.9.norm1.bias grad: 0.00011179006833117455
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0706882676458918e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.573202078172471e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.8888549422845244e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.960887837223709e-06
sam_encoder.blocks.9.norm2.weight grad: 0.0006876638508401811
sam_encoder.blocks.9.norm2.bias grad: 5.9087433328386396e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0004380979517009109
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0002494196523912251
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.404313459526747e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.6558051104075275e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00016197934746742249
sam_encoder.blocks.10.norm1.bias grad: 7.439833279931918e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00013117548951413482
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.304896669462323e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.730396853527054e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.866644253022969e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0007036418537609279
sam_encoder.blocks.10.norm2.bias grad: -1.7032871255651116e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0003627608239185065
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00012592754501383752
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.9171999156242236e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.950467049027793e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0005047979648225009
sam_encoder.blocks.11.norm1.bias grad: -4.181543772574514e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0001025510355248116
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.899784835288301e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.7363093219464645e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.5149025532300584e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0007382556796073914
sam_encoder.blocks.11.norm2.bias grad: -0.0001975717459572479
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0004687599139288068
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0001334648986812681
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.228050107078161e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.405014624353498e-05
sam_encoder.neck.conv1.trainable_scale grad: 2.7458183467388153e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0018123479094356298
sam_encoder.neck.conv2.trainable_scale grad: 2.4078646674752235e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.00040961342165246606
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0029074782505631447
mask_decoder.transformer.layers.0.norm1.bias grad: 0.00032821460627019405
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3906777501106262
mask_decoder.transformer.layers.0.norm2.bias grad: -0.03497137129306793
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0028858790174126625
mask_decoder.transformer.layers.0.norm3.bias grad: -2.942740684375167e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0025923149660229683
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0002769260900095105
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0025677396915853024
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00013353745453059673
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0068647596053779125
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004074769094586372
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0009565496584400535
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0029597063548862934
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002306646667420864
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0028560697101056576
mask_decoder.transformer.norm_final_attn.weight grad: 0.00033066640025936067
mask_decoder.transformer.norm_final_attn.bias grad: 0.0005321742501109838
Text_Embedding_Affine.0.weight grad: 3.487049538009046e-10
Text_Embedding_Affine.0.bias grad: -5.617039278149605e-09
Text_Embedding_Affine.2.weight grad: -1.8936270329561466e-09
Text_Embedding_Affine.2.bias grad: -0.0015855967067182064

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.929604560121984e-13
Max value: 0.9997106194496155
Mean value: 0.1121319904923439

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.929604560121984e-13
Max value: 0.9997106194496155
Mean value: 0.1121319904923439

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09430217742919922

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.512678146362305
Max value: -1.1920928244535389e-07
Mean value: -0.13856256008148193

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10353374481201172

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09430217742919922

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.18849182128906
Max value: 72.23513793945312
Mean value: 59.657257080078125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.929604560121984e-13
Max value: 0.9997106194496155
Mean value: 0.1121319904923439

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.929604560121984e-13
Max value: 0.9997106194496155
Mean value: 0.1121319904923439

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.929604560121984e-13
Max value: 0.9997106194496155
Mean value: 0.1121319904923439

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.512678146362305
Max value: -1.1920928244535389e-07
Mean value: -0.13856256008148193

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.18849182128906
Max value: 72.23513793945312
Mean value: 59.657257080078125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.658729553222656
Max value: -59.658729553222656
Mean value: -59.658729553222656
sam_encoder.pos_embed grad: -1.8061334117192018e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0008357914048247039
sam_encoder.blocks.0.norm1.bias grad: 0.0017903989646583796
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0005759153282269835
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.4884702725103125e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0005948596517555416
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0001637119275983423
sam_encoder.blocks.0.norm2.weight grad: 0.004272548481822014
sam_encoder.blocks.0.norm2.bias grad: -0.002703503705561161
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0019299726700410247
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00036209236714057624
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.00019048634567297995
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.455131379974773e-06
sam_encoder.blocks.1.norm1.weight grad: -0.00045989075442776084
sam_encoder.blocks.1.norm1.bias grad: -0.00015262651140801609
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.726025038806256e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.878553277696483e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00015062891179695725
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.048929218290141e-06
sam_encoder.blocks.1.norm2.weight grad: 0.000762045499868691
sam_encoder.blocks.1.norm2.bias grad: 0.0002753676672000438
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.203682015533559e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6599875380052254e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00063781050266698
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00016852316912263632
sam_encoder.blocks.2.norm1.weight grad: -0.001489850226789713
sam_encoder.blocks.2.norm1.bias grad: 0.0005400435766205192
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008795430767349899
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00024498498532921076
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003849672502838075
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00030689529376104474
sam_encoder.blocks.2.norm2.weight grad: -0.0008023266564123333
sam_encoder.blocks.2.norm2.bias grad: -0.00048465360305272043
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0004507256089709699
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.657854050397873e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.917534043779597e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.918798655737191e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0003137155144941062
sam_encoder.blocks.3.norm1.bias grad: 0.00014375787577591836
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0005415864288806915
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00018241684301756322
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00023878709180280566
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.40854738978669e-05
sam_encoder.blocks.3.norm2.weight grad: -0.000708413717802614
sam_encoder.blocks.3.norm2.bias grad: -0.00044436362804844975
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005647087818942964
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00011130118946311995
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.9873335734009743e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00013571939780376852
sam_encoder.blocks.4.norm1.weight grad: 0.000841998029500246
sam_encoder.blocks.4.norm1.bias grad: 0.00025060668122023344
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0003758755046874285
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1612467460508924e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00020004516409244388
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00019100889039691538
sam_encoder.blocks.4.norm2.weight grad: -0.0019189389422535896
sam_encoder.blocks.4.norm2.bias grad: -0.0017103864811360836
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0012565188808366656
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0004459699848666787
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.366596350446343e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.9531635189196095e-05
sam_encoder.blocks.5.norm1.weight grad: -0.00056244689039886
sam_encoder.blocks.5.norm1.bias grad: -0.0003195488825440407
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.000511106220073998
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.0005063791759312153
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00020083847630303353
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 5.387005512602627e-05
sam_encoder.blocks.5.norm2.weight grad: -0.0002758627524599433
sam_encoder.blocks.5.norm2.bias grad: -0.0014389767311513424
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.700940447335597e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.6843623345484957e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.51962249726057e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.6636706024874002e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0010548701975494623
sam_encoder.blocks.6.norm1.bias grad: -0.0002414775372017175
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0005238185403868556
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00016263657016679645
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.0002574759710114449
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00022084490046836436
sam_encoder.blocks.6.norm2.weight grad: -7.079384522512555e-05
sam_encoder.blocks.6.norm2.bias grad: 0.00010942918015643954
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0002627101493999362
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00010492734145373106
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.771738405106589e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.693081842153333e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00036337864003144205
sam_encoder.blocks.7.norm1.bias grad: -0.00027928478084504604
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0003189812123309821
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00010314378596376628
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.558556484989822e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.269216388929635e-05
sam_encoder.blocks.7.norm2.weight grad: 0.0005430664168670774
sam_encoder.blocks.7.norm2.bias grad: 0.00024446583120152354
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0003371376951690763
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.369543214328587e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3972952729091048e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.807849861914292e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0006992140552029014
sam_encoder.blocks.8.norm1.bias grad: -0.00021222382201813161
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0006710239103995264
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0002005885762628168
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.61471016833093e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.517477176093962e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0002896918449550867
sam_encoder.blocks.8.norm2.bias grad: 1.0043548172689043e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0003871597000397742
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.0002283622743561864
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00024055613903328776
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00014482435653917491
sam_encoder.blocks.9.norm1.weight grad: 2.5219731469405815e-05
sam_encoder.blocks.9.norm1.bias grad: -2.743523145909421e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.670013368013315e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1052807167288847e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.6990724513307214e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.25829020969104e-05
sam_encoder.blocks.9.norm2.weight grad: -6.870803190395236e-05
sam_encoder.blocks.9.norm2.bias grad: -7.651471241842955e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00013040410703979433
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.908274321584031e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.614160206983797e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.129852070240304e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00022128006094135344
sam_encoder.blocks.10.norm1.bias grad: 4.4191343476995826e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00018991061369888484
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.811868610791862e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00010705958993639797
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.976810305379331e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00043996001477353275
sam_encoder.blocks.10.norm2.bias grad: -0.0002630552917253226
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.200169006362557e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00012348219752311707
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00011597698903642595
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.074355380609632e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0009317941730841994
sam_encoder.blocks.11.norm1.bias grad: 0.00017819447384681553
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002643580664880574
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.988889461150393e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.000290308496914804
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 0.00013893446885049343
sam_encoder.blocks.11.norm2.weight grad: -0.0005842854734510183
sam_encoder.blocks.11.norm2.bias grad: -0.0002440267417114228
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.603075260296464e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00014082511188462377
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00010927836410701275
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.785929144825786e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.00013671326451003551
sam_encoder.neck.conv1.trainable_shift grad: -0.001133363926783204
sam_encoder.neck.conv2.trainable_scale grad: -0.000105653190985322
sam_encoder.neck.conv2.trainable_shift grad: 0.001725699519738555
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0073465160094201565
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00015547964721918106
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3338615894317627
mask_decoder.transformer.layers.0.norm2.bias grad: 0.041457947343587875
mask_decoder.transformer.layers.0.norm3.weight grad: -0.006643377244472504
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00011887168511748314
mask_decoder.transformer.layers.0.norm4.weight grad: 0.004240168258547783
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0005254238494671881
mask_decoder.transformer.layers.1.norm1.weight grad: 0.004781479947268963
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00016738998237997293
mask_decoder.transformer.layers.1.norm2.weight grad: 0.021088363602757454
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004364757798612118
mask_decoder.transformer.layers.1.norm3.weight grad: 0.007382056675851345
mask_decoder.transformer.layers.1.norm3.bias grad: 0.005330835469067097
mask_decoder.transformer.layers.1.norm4.weight grad: 0.005731668323278427
mask_decoder.transformer.layers.1.norm4.bias grad: -0.006576973013579845
mask_decoder.transformer.norm_final_attn.weight grad: 0.0002439885283820331
mask_decoder.transformer.norm_final_attn.bias grad: 0.0009059067815542221
Text_Embedding_Affine.0.weight grad: -4.872783287979132e-10
Text_Embedding_Affine.0.bias grad: -5.494803190231323e-08
Text_Embedding_Affine.2.weight grad: 5.270823777436817e-10
Text_Embedding_Affine.2.bias grad: 0.0016750559443607926
Epoch 32 finished with average loss: -57.8226
Epoch 33/39
----------
Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62.5]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-62.5]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-56]  Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.56it/s, loss=-56]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.56it/s, loss=-57.7]Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.15it/s, loss=-57.7]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.121472515765921e-14
Max value: 0.997936487197876
Mean value: 0.09379572421312332

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.121472515765921e-14
Max value: 0.997936487197876
Mean value: 0.09379572421312332

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08861827850341797

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12162217497825623

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08592557907104492

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08861827850341797

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.3162956237793
Max value: 71.4908218383789
Mean value: 62.493568420410156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.121472515765921e-14
Max value: 0.997936487197876
Mean value: 0.09379572421312332

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.121472515765921e-14
Max value: 0.997936487197876
Mean value: 0.09379572421312332

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.121472515765921e-14
Max value: 0.997936487197876
Mean value: 0.09379572421312332

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12162217497825623

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.3162956237793
Max value: 71.4908218383789
Mean value: 62.493568420410156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.49481964111328
Max value: -62.49481964111328
Mean value: -62.49481964111328
sam_encoder.pos_embed grad: 4.1371146153323934e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0024796463549137115
sam_encoder.blocks.0.norm1.bias grad: -0.0018266811966896057
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00026289469678886235
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.552228635177016e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0008637713617645204
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.527403921703808e-05
sam_encoder.blocks.0.norm2.weight grad: -0.0023368680849671364
sam_encoder.blocks.0.norm2.bias grad: -0.0023911395110189915
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0018584182253107429
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0008610006188973784
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00015225805691443384
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00013379623123910278
sam_encoder.blocks.1.norm1.weight grad: -0.0005468901363201439
sam_encoder.blocks.1.norm1.bias grad: -0.0007816813886165619
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.50566105125472e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.8444250347092748e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00035488695721141994
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.28226189292036e-05
sam_encoder.blocks.1.norm2.weight grad: -0.0011130283819511533
sam_encoder.blocks.1.norm2.bias grad: 0.0003768130554817617
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00023674490512348711
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00010052385914605111
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00010283617302775383
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00018626684322953224
sam_encoder.blocks.2.norm1.weight grad: 0.0018599102040752769
sam_encoder.blocks.2.norm1.bias grad: -0.00031852928805164993
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0009481217130087316
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00031179291545413435
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 0.0010910941055044532
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.0007107508135959506
sam_encoder.blocks.2.norm2.weight grad: 0.0016829841770231724
sam_encoder.blocks.2.norm2.bias grad: 8.605436596553773e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0010929456911981106
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.000411305547459051
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0003901506424881518
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.237618319777539e-06
sam_encoder.blocks.3.norm1.weight grad: 0.0002654390118550509
sam_encoder.blocks.3.norm1.bias grad: 0.0011133920634165406
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.00019868387607857585
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.417946234345436e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0001518366625532508
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.312023389094975e-05
sam_encoder.blocks.3.norm2.weight grad: -0.000726304657291621
sam_encoder.blocks.3.norm2.bias grad: -0.0010554792825132608
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005106742610223591
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00022434757556766272
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.2754829842597246e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00021947907225694507
sam_encoder.blocks.4.norm1.weight grad: -0.0002628301444929093
sam_encoder.blocks.4.norm1.bias grad: -0.0008816075278446078
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0004370806855149567
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.110182195901871e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00034641902311705053
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002923064457718283
sam_encoder.blocks.4.norm2.weight grad: 0.0017640129663050175
sam_encoder.blocks.4.norm2.bias grad: 0.002485285047441721
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0013345666229724884
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0006189043051563203
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0003549927787389606
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.496417881862726e-06
sam_encoder.blocks.5.norm1.weight grad: -0.0016916447784751654
sam_encoder.blocks.5.norm1.bias grad: -0.0006921895546838641
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.000968181062489748
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00013390521053224802
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00024822389241307974
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0001161293766926974
sam_encoder.blocks.5.norm2.weight grad: 0.0006510763196274638
sam_encoder.blocks.5.norm2.bias grad: 0.0011902819387614727
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00019723500008694828
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.00022721197456121445
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0002819047658704221
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00012210512068122625
sam_encoder.blocks.6.norm1.weight grad: 0.0001640956907067448
sam_encoder.blocks.6.norm1.bias grad: -0.0005830292357131839
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00019647464796435088
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00010399246093584225
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.284415187314153e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00013590202433988452
sam_encoder.blocks.6.norm2.weight grad: 0.000299839855870232
sam_encoder.blocks.6.norm2.bias grad: 0.0004314715915825218
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00029104168061167
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.503991218982264e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.904098826344125e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 0.00013093372399453074
sam_encoder.blocks.7.norm1.weight grad: -0.000840680324472487
sam_encoder.blocks.7.norm1.bias grad: -0.0001640796835999936
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0007061533397063613
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00033938008709810674
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0003174595476593822
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0001866493112174794
sam_encoder.blocks.7.norm2.weight grad: -0.00035565459984354675
sam_encoder.blocks.7.norm2.bias grad: 5.865692855877569e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.000513920676894486
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.000278662919299677
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.2409323214087635e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.1767739932984114e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0003874251269735396
sam_encoder.blocks.8.norm1.bias grad: 0.0003585206577554345
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0001658002147451043
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0001839085598476231
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.000342723069479689
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00044337561121210456
sam_encoder.blocks.8.norm2.weight grad: 8.625572081655264e-05
sam_encoder.blocks.8.norm2.bias grad: 0.0003424735914450139
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.09055961528793e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.143100133864209e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0001683114533079788
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00013514290913008153
sam_encoder.blocks.9.norm1.weight grad: -0.0001323738251812756
sam_encoder.blocks.9.norm1.bias grad: 4.294058453524485e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00025919044855982065
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00014336660387925804
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.426009688060731e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.415566218085587e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0004200773546472192
sam_encoder.blocks.9.norm2.bias grad: 0.00018300217925570905
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.0001795474672690034
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00010723814193625003
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00044873784645460546
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 0.0002500342670828104
sam_encoder.blocks.10.norm1.weight grad: -0.0006296522915363312
sam_encoder.blocks.10.norm1.bias grad: 5.567387415794656e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00034350258647464216
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00012738312943838537
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00018890039063990116
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.7176603655098006e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0007522364030592144
sam_encoder.blocks.10.norm2.bias grad: -0.00020471905008889735
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0002510707709006965
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0002967708860523999
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0001035098684951663
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.745902985334396e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0017616677796468139
sam_encoder.blocks.11.norm1.bias grad: 6.786423909943551e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002219289162894711
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.921338692540303e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00019017243175767362
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.5071177737554535e-05
sam_encoder.blocks.11.norm2.weight grad: 0.000345449720043689
sam_encoder.blocks.11.norm2.bias grad: -0.0002508265315555036
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.1517345127649605e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.7412985218688846e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00031978526385501027
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00012961348693352193
sam_encoder.neck.conv1.trainable_scale grad: 1.9009225070476532e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0071465931832790375
sam_encoder.neck.conv2.trainable_scale grad: 5.8714766055345535e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.005225140601396561
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0007692156359553337
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0007068943232297897
mask_decoder.transformer.layers.0.norm2.weight grad: -0.07877658307552338
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00877080112695694
mask_decoder.transformer.layers.0.norm3.weight grad: 0.005721363238990307
mask_decoder.transformer.layers.0.norm3.bias grad: 0.004847995936870575
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0034138718619942665
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0003185737878084183
mask_decoder.transformer.layers.1.norm1.weight grad: 0.006135344505310059
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00042836752254515886
mask_decoder.transformer.layers.1.norm2.weight grad: 0.01885126531124115
mask_decoder.transformer.layers.1.norm2.bias grad: 0.009274954907596111
mask_decoder.transformer.layers.1.norm3.weight grad: -0.001592287328094244
mask_decoder.transformer.layers.1.norm3.bias grad: 0.005707999691367149
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00019012449774891138
mask_decoder.transformer.layers.1.norm4.bias grad: 0.018659112975001335
mask_decoder.transformer.norm_final_attn.weight grad: 0.0002461397962179035
mask_decoder.transformer.norm_final_attn.bias grad: -0.0003956491709686816
Text_Embedding_Affine.0.weight grad: -2.7339197572473495e-09
Text_Embedding_Affine.0.bias grad: -4.761386662721634e-08
Text_Embedding_Affine.2.weight grad: -3.461293696105372e-09
Text_Embedding_Affine.2.bias grad: -0.0049985782243311405

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9030519347873476e-12
Max value: 0.9963964819908142
Mean value: 0.0780196338891983

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9030519347873476e-12
Max value: 0.9963964819908142
Mean value: 0.0780196338891983

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07550048828125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12035409361124039

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06573104858398438

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07550048828125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.3010311126709
Max value: 69.49911499023438
Mean value: 49.572975158691406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9030519347873476e-12
Max value: 0.9963964819908142
Mean value: 0.0780196338891983

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9030519347873476e-12
Max value: 0.9963964819908142
Mean value: 0.0780196338891983

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9030519347873476e-12
Max value: 0.9963964819908142
Mean value: 0.0780196338891983

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12035409361124039

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.3010311126709
Max value: 69.49911499023438
Mean value: 49.572975158691406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.57416915893555
Max value: -49.57416915893555
Mean value: -49.57416915893555
sam_encoder.pos_embed grad: 1.50888354255585e-07
sam_encoder.blocks.0.norm1.weight grad: 0.004595960956066847
sam_encoder.blocks.0.norm1.bias grad: 0.0010167292784899473
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00011099236871814355
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.806317393667996e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00044580872054211795
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.4911609216360375e-05
sam_encoder.blocks.0.norm2.weight grad: 0.003128834068775177
sam_encoder.blocks.0.norm2.bias grad: 0.004200101364403963
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.000595262972638011
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00010535347973927855
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0017283230554312468
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0010478938929736614
sam_encoder.blocks.1.norm1.weight grad: 0.00012661682558245957
sam_encoder.blocks.1.norm1.bias grad: 0.0016947592375800014
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00046440408914349973
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.000143172568641603
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0005461475811898708
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00029341617482714355
sam_encoder.blocks.1.norm2.weight grad: -0.0009912624955177307
sam_encoder.blocks.1.norm2.bias grad: -0.0003526606014929712
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00039074951200746
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -0.00010822453623404726
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0006386835011653602
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.7846780691761523e-05
sam_encoder.blocks.2.norm1.weight grad: -0.00046663451939821243
sam_encoder.blocks.2.norm1.bias grad: -3.881395605276339e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0004799022281076759
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.3999240763951093e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00011663459008559585
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00013378934818319976
sam_encoder.blocks.2.norm2.weight grad: 0.0003067897923756391
sam_encoder.blocks.2.norm2.bias grad: -0.0010031139245256782
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.187023922801018e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 0.00014579223352484405
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005125264870002866
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.000320354360156e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0008246238576248288
sam_encoder.blocks.3.norm1.bias grad: 0.00023652799427509308
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0005862867692485452
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.404198549920693e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.00013639210374094546
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8509752408135682e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0007154665654525161
sam_encoder.blocks.3.norm2.bias grad: 0.0002753690932877362
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0005884948186576366
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00028627534629777074
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0006691806484013796
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.744748679921031e-05
sam_encoder.blocks.4.norm1.weight grad: -5.555261668632738e-05
sam_encoder.blocks.4.norm1.bias grad: -0.0008000587113201618
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.808353257132694e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.582126661669463e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00014821451622992754
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00018675962928682566
sam_encoder.blocks.4.norm2.weight grad: 0.0024874317459762096
sam_encoder.blocks.4.norm2.bias grad: 0.0018030361970886588
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0012405564775690436
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.0004577510408125818
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00022694614017382264
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.95638232678175e-07
sam_encoder.blocks.5.norm1.weight grad: 0.00031642685644328594
sam_encoder.blocks.5.norm1.bias grad: -0.00132371939253062
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0006991366390138865
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0006168707623146474
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.9015008446294814e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.7324084183201194e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0009853184456005692
sam_encoder.blocks.5.norm2.bias grad: 0.0007891417481005192
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0004057972109876573
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0001946495467564091
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.8166009694105014e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.8075514162774198e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00023512197367381305
sam_encoder.blocks.6.norm1.bias grad: -0.0006374675431288779
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00013443781062960625
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.69731496903114e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.583744445582852e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.461809006286785e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0005533786024898291
sam_encoder.blocks.6.norm2.bias grad: 0.00027918090927414596
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00027309422148391604
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00010727866174420342
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00018449133494868875
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.6819472875795327e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0003734971396625042
sam_encoder.blocks.7.norm1.bias grad: 5.276077354210429e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0002518256660550833
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00013369371299631894
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00015687334234826267
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.947077518911101e-05
sam_encoder.blocks.7.norm2.weight grad: 6.706337444484234e-06
sam_encoder.blocks.7.norm2.bias grad: -6.461057637352496e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00028927059611305594
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00011318673932692036
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.919123213971034e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.869676609407179e-05
sam_encoder.blocks.8.norm1.weight grad: -0.00030190913821570575
sam_encoder.blocks.8.norm1.bias grad: 1.35269856400555e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.00015048542991280556
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.071075454703532e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0002118373231496662
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00014382379595190287
sam_encoder.blocks.8.norm2.weight grad: 0.00028201829991303384
sam_encoder.blocks.8.norm2.bias grad: 0.0001990387390833348
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00013932460569776595
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0001404455106239766
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0001170462928712368
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00010833745909621939
sam_encoder.blocks.9.norm1.weight grad: -0.0002720056800171733
sam_encoder.blocks.9.norm1.bias grad: 0.00011946385347982869
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00033259723568335176
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.0001211567287100479
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.972147381631657e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.400018638581969e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00013669313921127468
sam_encoder.blocks.9.norm2.bias grad: 0.0003030340885743499
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0002127532789018005
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.071867442689836e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.8836151361465454e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.972032082965598e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0005420921952463686
sam_encoder.blocks.10.norm1.bias grad: -8.913611054595094e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0003742147237062454
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.0001346357457805425
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00017944665160030127
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.501217573415488e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00036380960955284536
sam_encoder.blocks.10.norm2.bias grad: 2.2889154934091493e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00041128587326966226
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00017510075122117996
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.72486756532453e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.9812969185295515e-05
sam_encoder.blocks.11.norm1.weight grad: -0.000228879478527233
sam_encoder.blocks.11.norm1.bias grad: -4.505644756136462e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.811096682213247e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.7097829186241142e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00020593393128365278
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00015107664512470365
sam_encoder.blocks.11.norm2.weight grad: -0.0007256478420458734
sam_encoder.blocks.11.norm2.bias grad: -0.00024113754625432193
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0003423173911869526
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00012778575182892382
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.192239329218864e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.24772178020794e-06
sam_encoder.neck.conv1.trainable_scale grad: 6.364937871694565e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0011716700391843915
sam_encoder.neck.conv2.trainable_scale grad: 0.00010260561248287559
sam_encoder.neck.conv2.trainable_shift grad: 0.001536857569590211
mask_decoder.transformer.layers.0.norm1.weight grad: 0.007317297626286745
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0002666783984750509
mask_decoder.transformer.layers.0.norm2.weight grad: 0.3570594787597656
mask_decoder.transformer.layers.0.norm2.bias grad: -0.05589701980352402
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0036491029895842075
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0007061504293233156
mask_decoder.transformer.layers.0.norm4.weight grad: -0.010351087898015976
mask_decoder.transformer.layers.0.norm4.bias grad: 0.000177194073330611
mask_decoder.transformer.layers.1.norm1.weight grad: -0.001424456830136478
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00029654294485226274
mask_decoder.transformer.layers.1.norm2.weight grad: 0.012714698910713196
mask_decoder.transformer.layers.1.norm2.bias grad: 0.002942016115412116
mask_decoder.transformer.layers.1.norm3.weight grad: -0.004127221647650003
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00055260508088395
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0015734974294900894
mask_decoder.transformer.layers.1.norm4.bias grad: 0.014483840204775333
mask_decoder.transformer.norm_final_attn.weight grad: 0.0003254589973948896
mask_decoder.transformer.norm_final_attn.bias grad: -0.0010110089788213372
Text_Embedding_Affine.0.weight grad: -3.6041325479629904e-10
Text_Embedding_Affine.0.bias grad: -1.728767529129982e-08
Text_Embedding_Affine.2.weight grad: -3.824875083324741e-09
Text_Embedding_Affine.2.bias grad: -0.004652270581573248

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.08227703513742e-12
Max value: 0.9980089068412781
Mean value: 0.08638760447502136

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.08227703513742e-12
Max value: 0.9980089068412781
Mean value: 0.08638760447502136

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09100341796875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12239520251750946

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07819366455078125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09100341796875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.147953033447266
Max value: 84.51089477539062
Mean value: 60.93623352050781

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.08227703513742e-12
Max value: 0.9980089068412781
Mean value: 0.08638760447502136

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.08227703513742e-12
Max value: 0.9980089068412781
Mean value: 0.08638760447502136

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.08227703513742e-12
Max value: 0.9980089068412781
Mean value: 0.08638760447502136

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12239520251750946

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.147953033447266
Max value: 84.51089477539062
Mean value: 60.93623352050781

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.93733596801758
Max value: -60.93733596801758
Mean value: -60.93733596801758
sam_encoder.pos_embed grad: -1.620972795990383e-07
sam_encoder.blocks.0.norm1.weight grad: -0.002863758010789752
sam_encoder.blocks.0.norm1.bias grad: -0.0029341138433665037
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00039104075403884053
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.9976316252723336e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0005957841640338302
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.0003777457750402391
sam_encoder.blocks.0.norm2.weight grad: 0.0021254438906908035
sam_encoder.blocks.0.norm2.bias grad: 0.0031276377849280834
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0006347554153762758
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0007020109333097935
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0005577494157478213
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00020306906662881374
sam_encoder.blocks.1.norm1.weight grad: -0.0006458009011112154
sam_encoder.blocks.1.norm1.bias grad: -3.722581823240034e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.89677295263391e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00017079428653232753
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00017488872981630266
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.89890189783182e-05
sam_encoder.blocks.1.norm2.weight grad: -0.00029980202089063823
sam_encoder.blocks.1.norm2.bias grad: -0.00021107270731590688
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00042912428034469485
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.204196688486263e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.670881703030318e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00013743119779974222
sam_encoder.blocks.2.norm1.weight grad: 0.0007528709247708321
sam_encoder.blocks.2.norm1.bias grad: -0.0009996097069233656
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00027780671371147037
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.366357411025092e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00021404935978353024
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00014585000462830067
sam_encoder.blocks.2.norm2.weight grad: 9.208838309859857e-05
sam_encoder.blocks.2.norm2.bias grad: -0.00013521904475055635
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00018246006220579147
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.708627784566488e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.000140970922075212
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.70641748001799e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0005928759346716106
sam_encoder.blocks.3.norm1.bias grad: -0.0006711090682074428
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0001617806701688096
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.572107046551537e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.6996789023978636e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0001239690463989973
sam_encoder.blocks.3.norm2.weight grad: 0.0007721030851826072
sam_encoder.blocks.3.norm2.bias grad: -0.0004508884740062058
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0005512943025678396
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00014551884669344872
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0005039711249992251
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00018537887081038207
sam_encoder.blocks.4.norm1.weight grad: 0.0012426415923982859
sam_encoder.blocks.4.norm1.bias grad: -0.0008990267524495721
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0006057463469915092
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001373965060338378
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00027134755509905517
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.00020509326714091003
sam_encoder.blocks.4.norm2.weight grad: -0.0010866210795938969
sam_encoder.blocks.4.norm2.bias grad: -0.0008200143347494304
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0006135128205642104
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00016276209498755634
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00024389440659433603
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.688825280638412e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0015599550679326057
sam_encoder.blocks.5.norm1.bias grad: -0.0003637801273725927
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.001150466618128121
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00041516413330100477
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002818491484504193
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.0001120559754781425
sam_encoder.blocks.5.norm2.weight grad: -0.0006049432558938861
sam_encoder.blocks.5.norm2.bias grad: -3.1217263313010335e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00048034716746769845
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00016435436555184424
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.66245396132581e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.3805797607346904e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0003242138191126287
sam_encoder.blocks.6.norm1.bias grad: 5.888839950785041e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00021651957649737597
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0001711062213871628
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.699360528727993e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.7470969396526925e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0005817671772092581
sam_encoder.blocks.6.norm2.bias grad: 5.516484088730067e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0004162380355410278
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00017848456627689302
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.077937021269463e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.205731218258734e-06
sam_encoder.blocks.7.norm1.weight grad: 0.00044432407594285905
sam_encoder.blocks.7.norm1.bias grad: 3.810027556028217e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00021104728512000293
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00019328363123349845
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.02851903042756e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 9.492300159763545e-05
sam_encoder.blocks.7.norm2.weight grad: -0.0004380859900265932
sam_encoder.blocks.7.norm2.bias grad: 0.00019486664677970111
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00044383047497831285
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.0002214715350419283
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.136765245581046e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.7827711417339742e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0006557035958394408
sam_encoder.blocks.8.norm1.bias grad: 4.440946941031143e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0004992135218344629
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00021843970171175897
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.471711741236504e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.951751417247579e-05
sam_encoder.blocks.8.norm2.weight grad: -1.2730156413454097e-05
sam_encoder.blocks.8.norm2.bias grad: -5.1547365728765726e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.50294197537005e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.070333645562641e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00013530532305594534
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.026471186894923e-05
sam_encoder.blocks.9.norm1.weight grad: -4.483949669520371e-05
sam_encoder.blocks.9.norm1.bias grad: 3.143153151086153e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.87091820104979e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.4765994971385226e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7603331798454747e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6096451872726902e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00024910044157877564
sam_encoder.blocks.9.norm2.bias grad: 0.00018291798187419772
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.084980461513624e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.006958862300962e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.0001492006704211235
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.074861110188067e-05
sam_encoder.blocks.10.norm1.weight grad: 9.93848079815507e-05
sam_encoder.blocks.10.norm1.bias grad: 5.284756116452627e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.7516728702466935e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.44739894696977e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.4101444321568124e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2529587365861516e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0004437713068909943
sam_encoder.blocks.10.norm2.bias grad: 0.0002583767636679113
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.08947773091495e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00011273649579379708
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.000125536898849532
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.919402949279174e-06
sam_encoder.blocks.11.norm1.weight grad: 0.0007028268883004785
sam_encoder.blocks.11.norm1.bias grad: 0.00010832872067112476
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00015538177103735507
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.507186091970652e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.2814993978245184e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.052290412597358e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0006518977461382747
sam_encoder.blocks.11.norm2.bias grad: 4.6774955990258604e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.000240550929447636
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00013745567412115633
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00017098691023420542
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.824151205364615e-05
sam_encoder.neck.conv1.trainable_scale grad: 8.633744437247515e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0010303945746272802
sam_encoder.neck.conv2.trainable_scale grad: 9.065051563084126e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.004829157143831253
mask_decoder.transformer.layers.0.norm1.weight grad: 0.011094346642494202
mask_decoder.transformer.layers.0.norm1.bias grad: 0.000319688580930233
mask_decoder.transformer.layers.0.norm2.weight grad: -0.03167439624667168
mask_decoder.transformer.layers.0.norm2.bias grad: -0.10869607329368591
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0025459937751293182
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0002753247390501201
mask_decoder.transformer.layers.0.norm4.weight grad: 0.003214721567928791
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0002665796782821417
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0015061527956277132
mask_decoder.transformer.layers.1.norm1.bias grad: 0.00015369744505733252
mask_decoder.transformer.layers.1.norm2.weight grad: 0.002697374438866973
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00218583014793694
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0009542892221361399
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00027992913965135813
mask_decoder.transformer.layers.1.norm4.weight grad: -0.001463491003960371
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010970572475343943
mask_decoder.transformer.norm_final_attn.weight grad: -0.00018208833353128284
mask_decoder.transformer.norm_final_attn.bias grad: 0.00031928924727253616
Text_Embedding_Affine.0.weight grad: 3.242307533568578e-10
Text_Embedding_Affine.0.bias grad: 9.313225746154785e-10
Text_Embedding_Affine.2.weight grad: 5.03339547819337e-09
Text_Embedding_Affine.2.bias grad: -0.002880966989323497
Epoch 33 finished with average loss: -57.6688
Epoch 34/39
----------
Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.9]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.16it/s, loss=-59.9]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.16it/s, loss=-57]  Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-57]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-58.3]Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-58.3]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.595543571737302e-12
Max value: 0.9980834722518921
Mean value: 0.08606653660535812

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.595543571737302e-12
Max value: 0.9980834722518921
Mean value: 0.08606653660535812

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0909128189086914

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1164192333817482

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07816648483276367

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0909128189086914

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.30544662475586
Max value: 80.09506225585938
Mean value: 59.87019348144531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.595543571737302e-12
Max value: 0.9980834722518921
Mean value: 0.08606653660535812

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.595543571737302e-12
Max value: 0.9980834722518921
Mean value: 0.08606653660535812

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.595543571737302e-12
Max value: 0.9980834722518921
Mean value: 0.08606653660535812

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1164192333817482

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.30544662475586
Max value: 80.09506225585938
Mean value: 59.87019348144531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.87135696411133
Max value: -59.87135696411133
Mean value: -59.87135696411133
sam_encoder.pos_embed grad: 8.764751413536942e-08
sam_encoder.blocks.0.norm1.weight grad: 0.001684294082224369
sam_encoder.blocks.0.norm1.bias grad: 0.005290800705552101
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0006133039714768529
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.4699409045279026e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0006930026574991643
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0001900239149108529
sam_encoder.blocks.0.norm2.weight grad: 0.0022489558905363083
sam_encoder.blocks.0.norm2.bias grad: -0.003836610820144415
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0016451053088530898
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00040995384915731847
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0017104459693655372
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.559710941975936e-05
sam_encoder.blocks.1.norm1.weight grad: 0.0012604802614077926
sam_encoder.blocks.1.norm1.bias grad: 0.0010441674385219812
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.343275501625612e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.604389399290085e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00024014763766899705
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0001052802981575951
sam_encoder.blocks.1.norm2.weight grad: -0.0013125891564413905
sam_encoder.blocks.1.norm2.bias grad: -0.00014921254478394985
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00034767325269058347
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.7244679838768207e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0011739633046090603
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.0002145930629922077
sam_encoder.blocks.2.norm1.weight grad: -0.0009052450186572969
sam_encoder.blocks.2.norm1.bias grad: -0.00011448007717262954
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0008702042396180332
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00030088768107816577
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0006677140481770039
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003887712664436549
sam_encoder.blocks.2.norm2.weight grad: -0.0006653065211139619
sam_encoder.blocks.2.norm2.bias grad: -0.0011082642013207078
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0007046420942060649
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00028132443549111485
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005678050220012665
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00019514547602739185
sam_encoder.blocks.3.norm1.weight grad: -0.0008487027953378856
sam_encoder.blocks.3.norm1.bias grad: 3.824777195404749e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0010478098411113024
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00022080469352658838
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0005644317716360092
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00021099808509461582
sam_encoder.blocks.3.norm2.weight grad: 0.0008755060844123363
sam_encoder.blocks.3.norm2.bias grad: 0.00026954812346957624
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0005640060408040881
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00043450965313240886
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0005946451565250754
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00020015050540678203
sam_encoder.blocks.4.norm1.weight grad: 0.00032989104511216283
sam_encoder.blocks.4.norm1.bias grad: 0.0006234124302864075
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0001256085088243708
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.115172825753689e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.071125532500446e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00018329935846850276
sam_encoder.blocks.4.norm2.weight grad: -0.0032843647059053183
sam_encoder.blocks.4.norm2.bias grad: -0.0019973558373749256
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0021461828146129847
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0006916701095178723
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00038468962884508073
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0002167126367567107
sam_encoder.blocks.5.norm1.weight grad: 0.00018580126925371587
sam_encoder.blocks.5.norm1.bias grad: 0.000321223255014047
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00014931503392290324
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00010198491509072483
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002587397466413677
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00010652103082975373
sam_encoder.blocks.5.norm2.weight grad: -0.0018037976697087288
sam_encoder.blocks.5.norm2.bias grad: -0.000931775663048029
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0008793737506493926
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00030990445520728827
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00025668006855994463
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.565561413182877e-06
sam_encoder.blocks.6.norm1.weight grad: -2.0949437384842895e-05
sam_encoder.blocks.6.norm1.bias grad: 0.00013218887033872306
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.07186967600137e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.502250390534755e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.794243770651519e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1084142897743732e-05
sam_encoder.blocks.6.norm2.weight grad: -5.392435468820622e-06
sam_encoder.blocks.6.norm2.bias grad: 7.578560325782746e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.8075940867420286e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.454491813201457e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0003617212059907615
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.726519783725962e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00043532485142350197
sam_encoder.blocks.7.norm1.bias grad: -1.861462624219712e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0003922928008250892
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00019414277630858123
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.95338855823502e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00016170163871720433
sam_encoder.blocks.7.norm2.weight grad: 0.00020646877237595618
sam_encoder.blocks.7.norm2.bias grad: 9.793329809326679e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.5930522901471704e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.2327873264439404e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.252757990907412e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.9492158975917846e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0006925665657036006
sam_encoder.blocks.8.norm1.bias grad: 2.3520609829574823e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0005750320851802826
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00015242028166539967
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.556461756990757e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.128829747671261e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0004834305727854371
sam_encoder.blocks.8.norm2.bias grad: -0.00012637519103009254
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00033039445406757295
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00020874524489045143
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0001410364347975701
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.635159949539229e-05
sam_encoder.blocks.9.norm1.weight grad: 1.4383847883436829e-05
sam_encoder.blocks.9.norm1.bias grad: -1.1684649507515132e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.158751006703824e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.911453965585679e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.0489012715406716e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00014190361252985895
sam_encoder.blocks.9.norm2.weight grad: -0.00031470635440200567
sam_encoder.blocks.9.norm2.bias grad: -0.00029456752236001194
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0002484488650225103
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00018626381643116474
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00016790232621133327
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.786068403627723e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00017261083121411502
sam_encoder.blocks.10.norm1.bias grad: 2.7464955564937554e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00011076352529926226
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.567828702623956e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.828031761571765e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.823388685006648e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0005712498677894473
sam_encoder.blocks.10.norm2.bias grad: -0.00042008195305243134
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0001643420400796458
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00015179443289525807
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00012223637895658612
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.195579044288024e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0012595989974215627
sam_encoder.blocks.11.norm1.bias grad: 9.807628521230072e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0004176056245341897
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.162431524600834e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00013051339192315936
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.606558650266379e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0002760921779554337
sam_encoder.blocks.11.norm2.bias grad: 8.417681783612352e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.1016381904482841e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00011383488163119182
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0001609576283954084
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00011122437717858702
sam_encoder.neck.conv1.trainable_scale grad: -0.00010678218677639961
sam_encoder.neck.conv1.trainable_shift grad: -0.002172914333641529
sam_encoder.neck.conv2.trainable_scale grad: -0.00010434293653815985
sam_encoder.neck.conv2.trainable_shift grad: 0.0025908355601131916
mask_decoder.transformer.layers.0.norm1.weight grad: -0.013031363487243652
mask_decoder.transformer.layers.0.norm1.bias grad: -0.0006042607128620148
mask_decoder.transformer.layers.0.norm2.weight grad: -0.45830225944519043
mask_decoder.transformer.layers.0.norm2.bias grad: 0.062383998185396194
mask_decoder.transformer.layers.0.norm3.weight grad: 0.002832414349541068
mask_decoder.transformer.layers.0.norm3.bias grad: -0.001367713324725628
mask_decoder.transformer.layers.0.norm4.weight grad: 0.008121888153254986
mask_decoder.transformer.layers.0.norm4.bias grad: -0.00016645400319248438
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0036679573822766542
mask_decoder.transformer.layers.1.norm1.bias grad: 9.359081741422415e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0035985619761049747
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00025180401280522346
mask_decoder.transformer.layers.1.norm3.weight grad: 0.004671238362789154
mask_decoder.transformer.layers.1.norm3.bias grad: 0.003909696359187365
mask_decoder.transformer.layers.1.norm4.weight grad: -0.002643580548465252
mask_decoder.transformer.layers.1.norm4.bias grad: -0.013423817232251167
mask_decoder.transformer.norm_final_attn.weight grad: 5.797296762466431e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0008154015522450209
Text_Embedding_Affine.0.weight grad: 4.0634322573396275e-09
Text_Embedding_Affine.0.bias grad: 1.126900315284729e-07
Text_Embedding_Affine.2.weight grad: 3.984385266164736e-09
Text_Embedding_Affine.2.bias grad: 0.00124067859724164

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.838182809773327e-12
Max value: 0.999212384223938
Mean value: 0.0862904042005539

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.838182809773327e-12
Max value: 0.999212384223938
Mean value: 0.0862904042005539

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07962894439697266

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12090294808149338

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07220220565795898

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07962894439697266

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.06310272216797
Max value: 68.0
Mean value: 54.18321990966797

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.838182809773327e-12
Max value: 0.999212384223938
Mean value: 0.0862904042005539

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.838182809773327e-12
Max value: 0.999212384223938
Mean value: 0.0862904042005539

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.838182809773327e-12
Max value: 0.999212384223938
Mean value: 0.0862904042005539

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12090294808149338

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.06310272216797
Max value: 68.0
Mean value: 54.18321990966797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.18449020385742
Max value: -54.18449020385742
Mean value: -54.18449020385742
sam_encoder.pos_embed grad: -3.497830789456202e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0007412642007693648
sam_encoder.blocks.0.norm1.bias grad: 0.0014777891337871552
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.578363536391407e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.8291142371017486e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00015662048826925457
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.1601480916142464e-05
sam_encoder.blocks.0.norm2.weight grad: 0.005344999488443136
sam_encoder.blocks.0.norm2.bias grad: 0.0005337160546332598
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000706988328602165
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0004182590637356043
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0008064366411417723
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.395914609427564e-05
sam_encoder.blocks.1.norm1.weight grad: 0.00040454952977597713
sam_encoder.blocks.1.norm1.bias grad: 0.0008805476827546954
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0004409587709233165
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00022041608463041484
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.000646635890007019
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00037962145870551467
sam_encoder.blocks.1.norm2.weight grad: 0.0007453975267708302
sam_encoder.blocks.1.norm2.bias grad: -0.00036372721660882235
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00013532086450140923
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0001751464733388275
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0008627958595752716
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00015106187493074685
sam_encoder.blocks.2.norm1.weight grad: -0.0012959098676219583
sam_encoder.blocks.2.norm1.bias grad: -0.0003756029182113707
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0010608003940433264
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0002909962786361575
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0010282385628670454
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.000697595183737576
sam_encoder.blocks.2.norm2.weight grad: -0.000742969335988164
sam_encoder.blocks.2.norm2.bias grad: -0.0011991134379059076
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0006376763340085745
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00019074667943641543
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0003313970228191465
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.181251905625686e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0004689747584052384
sam_encoder.blocks.3.norm1.bias grad: -0.00022224010899662971
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0006393921794369817
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0002041455009020865
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00034283901914022863
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00027513859095051885
sam_encoder.blocks.3.norm2.weight grad: 0.0005819552461616695
sam_encoder.blocks.3.norm2.bias grad: -0.0002247896045446396
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00020204430620651692
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.9342265659361146e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.1826104026986286e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.688403325621039e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0018816303927451372
sam_encoder.blocks.4.norm1.bias grad: -0.0006519129383377731
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005683862254954875
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001305439800489694
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.951058508595452e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.110001752153039e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0022486159577965736
sam_encoder.blocks.4.norm2.bias grad: -0.0012016324326395988
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0017426781123504043
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0006766765145584941
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00010647717863321304
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.579376688227057e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0016337222186848521
sam_encoder.blocks.5.norm1.bias grad: -0.0014978812541812658
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0013070213608443737
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0004904598463326693
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00026703119510784745
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00021331626339815557
sam_encoder.blocks.5.norm2.weight grad: -0.0009072307730093598
sam_encoder.blocks.5.norm2.bias grad: -0.000451475236332044
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0005906561855226755
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0002372076123720035
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00024813582422211766
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.306761547923088e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00016905336815398186
sam_encoder.blocks.6.norm1.bias grad: 7.950291910674423e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00029242498567327857
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00023198514827527106
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00012023013550788164
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.227276465622708e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0005402226815931499
sam_encoder.blocks.6.norm2.bias grad: -8.76676058396697e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0004773004329763353
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0002142363809980452
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.631874177604914e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.226585573022021e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0006020150030963123
sam_encoder.blocks.7.norm1.bias grad: 6.7877508627134375e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0003864201717078686
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00014318778994493186
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.0001190204857266508
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00011227127106394619
sam_encoder.blocks.7.norm2.weight grad: 6.218398630153388e-05
sam_encoder.blocks.7.norm2.bias grad: -7.27745791664347e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00010351131641073152
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00011844941764138639
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.0565220842836425e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.9631468350999057e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0008796234615147114
sam_encoder.blocks.8.norm1.bias grad: -0.00013317754201125354
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0009423377923667431
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0004226602322887629
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00012208119733259082
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00010902447684202343
sam_encoder.blocks.8.norm2.weight grad: 2.055041022686055e-06
sam_encoder.blocks.8.norm2.bias grad: 0.00010015904990723357
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.120119774597697e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.3587519283173606e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.223644595593214e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.571676749445032e-06
sam_encoder.blocks.9.norm1.weight grad: 0.00033352337777614594
sam_encoder.blocks.9.norm1.bias grad: 3.123805799987167e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00012727826833724976
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.135665898909792e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.3469878467731178e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.3079253878677264e-05
sam_encoder.blocks.9.norm2.weight grad: -0.00022047133825253695
sam_encoder.blocks.9.norm2.bias grad: -8.487540981150232e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00023987004533410072
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0001390956895193085
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.299537926679477e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.4973418728914112e-05
sam_encoder.blocks.10.norm1.weight grad: 6.406604370567948e-05
sam_encoder.blocks.10.norm1.bias grad: 8.96897108759731e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.4856711610918865e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.255463525420055e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.3280590034555644e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.654993740085047e-06
sam_encoder.blocks.10.norm2.weight grad: -1.9778584828600287e-05
sam_encoder.blocks.10.norm2.bias grad: 4.401936166686937e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.8532958317082375e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.3355252526234835e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.402534497989109e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.1218347026442643e-05
sam_encoder.blocks.11.norm1.weight grad: 0.00026775430887937546
sam_encoder.blocks.11.norm1.bias grad: 7.140498928492889e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.000318238977342844
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.93608349643182e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.89680813997984e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.6530236937105656e-05
sam_encoder.blocks.11.norm2.weight grad: 0.00012087562936358154
sam_encoder.blocks.11.norm2.bias grad: 7.811083924025297e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.00018634313892107457
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.8004890080192126e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.19960133008135e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.3419222745578736e-05
sam_encoder.neck.conv1.trainable_scale grad: -2.9520131647586823e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0006377204554155469
sam_encoder.neck.conv2.trainable_scale grad: 2.6181747671216726e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.00023301714099943638
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0007182771805673838
mask_decoder.transformer.layers.0.norm1.bias grad: 3.5157427191734314e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.044216811656951904
mask_decoder.transformer.layers.0.norm2.bias grad: 0.001787847839295864
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0031816367991268635
mask_decoder.transformer.layers.0.norm3.bias grad: 7.983553223311901e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.968876838684082e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 0.001230976078659296
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0006409477791748941
mask_decoder.transformer.layers.1.norm1.bias grad: 8.927995804697275e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00835221167653799
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0027472213841974735
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00022060793708078563
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00043562668724916875
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0013306024484336376
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0041145216673612595
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003557475283741951
mask_decoder.transformer.norm_final_attn.bias grad: -0.0002800762886181474
Text_Embedding_Affine.0.weight grad: -1.1206747752012802e-09
Text_Embedding_Affine.0.bias grad: -6.530899554491043e-08
Text_Embedding_Affine.2.weight grad: -2.912244445596457e-09
Text_Embedding_Affine.2.bias grad: -0.0018977008294314146

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.2107779800936926e-14
Max value: 0.9978500604629517
Mean value: 0.08527945727109909

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.2107779800936926e-14
Max value: 0.9978500604629517
Mean value: 0.08527945727109909

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07805824279785156

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12244191765785217

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08043479919433594

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07805824279785156

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 56.57981872558594
Max value: 67.55646514892578
Mean value: 60.96855545043945

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.2107779800936926e-14
Max value: 0.9978500604629517
Mean value: 0.08527945727109909

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.2107779800936926e-14
Max value: 0.9978500604629517
Mean value: 0.08527945727109909

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.2107779800936926e-14
Max value: 0.9978500604629517
Mean value: 0.08527945727109909

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12244191765785217

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 56.57981872558594
Max value: 67.55646514892578
Mean value: 60.96855545043945

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.969635009765625
Max value: -60.969635009765625
Mean value: -60.969635009765625
sam_encoder.pos_embed grad: 6.670310881418118e-07
sam_encoder.blocks.0.norm1.weight grad: 0.004861220717430115
sam_encoder.blocks.0.norm1.bias grad: 0.0002623267355374992
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0009455324034206569
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.022104546194896e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0008458872325718403
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.00026941392570734024
sam_encoder.blocks.0.norm2.weight grad: 0.001596425543539226
sam_encoder.blocks.0.norm2.bias grad: -0.0041819727048277855
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0018265664111822844
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0005926373414695263
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0010430956026539207
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006630352581851184
sam_encoder.blocks.1.norm1.weight grad: 0.000488463556393981
sam_encoder.blocks.1.norm1.bias grad: 0.001181107247248292
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00048293068539351225
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00012942466128151864
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0004967550048604608
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00021610164549201727
sam_encoder.blocks.1.norm2.weight grad: -0.0010496687609702349
sam_encoder.blocks.1.norm2.bias grad: -0.00031497474992647767
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0005355936591513455
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.848497964208946e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0012390036135911942
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00012359631364233792
sam_encoder.blocks.2.norm1.weight grad: -0.00167407828848809
sam_encoder.blocks.2.norm1.bias grad: 0.0006500339950434864
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0009471136145293713
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00024377965019084513
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0003014489193446934
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.717138315550983e-05
sam_encoder.blocks.2.norm2.weight grad: 1.8312595784664154e-05
sam_encoder.blocks.2.norm2.bias grad: -0.00028067847597412765
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00015059327415656298
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.736475476529449e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0007212783675640821
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00012597795284818858
sam_encoder.blocks.3.norm1.weight grad: 5.350701030693017e-05
sam_encoder.blocks.3.norm1.bias grad: 0.0003547954838722944
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0003066415374632925
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0001224653096869588
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00039631029358133674
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00035229302011430264
sam_encoder.blocks.3.norm2.weight grad: -0.002045545494183898
sam_encoder.blocks.3.norm2.bias grad: -0.0003533023118507117
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.001555299386382103
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0004579093656502664
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0004082361701875925
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0001877198665169999
sam_encoder.blocks.4.norm1.weight grad: -0.0008093464421108365
sam_encoder.blocks.4.norm1.bias grad: -0.00022453544079326093
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0004380253376439214
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00013973734166938812
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00027870736084878445
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00034641529782675207
sam_encoder.blocks.4.norm2.weight grad: 0.0003848306369036436
sam_encoder.blocks.4.norm2.bias grad: 0.0008583293529227376
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 8.762135257711634e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00014807117986492813
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.000156404945300892
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.681687177158892e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0009032534435391426
sam_encoder.blocks.5.norm1.bias grad: 1.6481810234836303e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.000378813681891188
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.6199576900107786e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00032019871287047863
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0001896433241199702
sam_encoder.blocks.5.norm2.weight grad: -2.5130255380645394e-05
sam_encoder.blocks.5.norm2.bias grad: 0.00037741404958069324
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00017769934493117034
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.970389298046939e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.273846469819546e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4349654520628974e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00030895290547050536
sam_encoder.blocks.6.norm1.bias grad: -0.00039943851879797876
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -7.533418101957068e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.1105795642361045e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -9.26549473660998e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00010440588084748015
sam_encoder.blocks.6.norm2.weight grad: 0.000549036602023989
sam_encoder.blocks.6.norm2.bias grad: 0.0005283844075165689
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.000275677622994408
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00011783077206928283
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.77484830096364e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.81485578045249e-05
sam_encoder.blocks.7.norm1.weight grad: -0.00016311541548930109
sam_encoder.blocks.7.norm1.bias grad: -5.2253086323617026e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00019799984875135124
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00014176545664668083
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00027000525733456016
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003464452165644616
sam_encoder.blocks.7.norm2.weight grad: 6.291372119449079e-05
sam_encoder.blocks.7.norm2.bias grad: 1.6798619981273077e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00012134015560150146
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.691365029430017e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.261567664798349e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.867651195032522e-05
sam_encoder.blocks.8.norm1.weight grad: 3.0214065191103145e-05
sam_encoder.blocks.8.norm1.bias grad: 0.00022788641217630357
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.95937604480423e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.345259392517619e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00034868059447035193
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0003575620648916811
sam_encoder.blocks.8.norm2.weight grad: -0.0003856989205814898
sam_encoder.blocks.8.norm2.bias grad: 1.112403242586879e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0004418760654516518
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00018303676915820688
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0001499028003308922
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.703398058656603e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0001971959718503058
sam_encoder.blocks.9.norm1.bias grad: -5.385050462791696e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0001554903428768739
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00011722464114427567
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00010673752694856375
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.0001320885494351387
sam_encoder.blocks.9.norm2.weight grad: -0.000487365061417222
sam_encoder.blocks.9.norm2.bias grad: -3.5063356335740536e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00045286817476153374
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00022009675740264356
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.030332845810335e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.158150098490296e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0002955365343950689
sam_encoder.blocks.10.norm1.bias grad: -9.824259905144572e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00015269548748619854
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.263305112952366e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00010365362686570734
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.443851503310725e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0013439900940284133
sam_encoder.blocks.10.norm2.bias grad: -0.0004144401173107326
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00065733672818169
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0004110686422791332
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0001418108440702781
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.696698695421219e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0010325509356334805
sam_encoder.blocks.11.norm1.bias grad: 7.290793291758746e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0001415459264535457
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.4832789020147175e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00015942289610393345
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.373341602738947e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0013893357245251536
sam_encoder.blocks.11.norm2.bias grad: -0.00024060779833234847
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0005465691210702062
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0002617303398437798
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.136520045809448e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.056973532191478e-05
sam_encoder.neck.conv1.trainable_scale grad: -2.2008840460330248e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0015794947976246476
sam_encoder.neck.conv2.trainable_scale grad: -9.609968401491642e-06
sam_encoder.neck.conv2.trainable_shift grad: 0.0021712221205234528
mask_decoder.transformer.layers.0.norm1.weight grad: -0.005768706556409597
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00014184648171067238
mask_decoder.transformer.layers.0.norm2.weight grad: 0.19251762330532074
mask_decoder.transformer.layers.0.norm2.bias grad: 0.039386291056871414
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00791305024176836
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0011161998845636845
mask_decoder.transformer.layers.0.norm4.weight grad: -0.004504556301981211
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00036512548103928566
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0009244161774404347
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0005486433510668576
mask_decoder.transformer.layers.1.norm2.weight grad: 0.016863202676177025
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004540153779089451
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00032579724211245775
mask_decoder.transformer.layers.1.norm3.bias grad: 0.002060116268694401
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0019305931637063622
mask_decoder.transformer.layers.1.norm4.bias grad: 0.010677790269255638
mask_decoder.transformer.norm_final_attn.weight grad: 4.115864430787042e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0006714677438139915
Text_Embedding_Affine.0.weight grad: -8.882691249212371e-10
Text_Embedding_Affine.0.bias grad: -2.371962182223797e-08
Text_Embedding_Affine.2.weight grad: 4.735885461570888e-09
Text_Embedding_Affine.2.bias grad: -0.0010479448828846216
Epoch 34 finished with average loss: -58.3418
Epoch 35/39
----------
Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.2]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-58.2]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-55.8]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-55.8]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-57.7]Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.19it/s, loss=-57.7]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.20106418870625e-14
Max value: 0.9999111890792847
Mean value: 0.08852346241474152

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.20106418870625e-14
Max value: 0.9999111890792847
Mean value: 0.08852346241474152

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08455753326416016

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12606285512447357

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07758283615112305

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08455753326416016

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.3057861328125
Max value: 86.47943115234375
Mean value: 58.22534942626953

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.20106418870625e-14
Max value: 0.9999111890792847
Mean value: 0.08852346241474152

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.20106418870625e-14
Max value: 0.9999111890792847
Mean value: 0.08852346241474152

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.20106418870625e-14
Max value: 0.9999111890792847
Mean value: 0.08852346241474152

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12606285512447357

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.3057861328125
Max value: 86.47943115234375
Mean value: 58.22534942626953

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.22650146484375
Max value: -58.22650146484375
Mean value: -58.22650146484375
sam_encoder.pos_embed grad: -5.5334037796228586e-08
sam_encoder.blocks.0.norm1.weight grad: 0.003460020525380969
sam_encoder.blocks.0.norm1.bias grad: 0.0011004226980730891
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00025039134197868407
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.722005986783188e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.00018967935466207564
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.877192597836256e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0021955419797450304
sam_encoder.blocks.0.norm2.bias grad: 0.00122038833796978
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0006567080272361636
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0002826722920872271
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0006284618284553289
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006425988976843655
sam_encoder.blocks.1.norm1.weight grad: 0.001235223957337439
sam_encoder.blocks.1.norm1.bias grad: 0.0004740555305033922
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0001544663537060842
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.171034667408094e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00024977271095849574
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.75190458423458e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0006817933171987534
sam_encoder.blocks.1.norm2.bias grad: -0.00022446730872616172
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.277304393937811e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.394495019572787e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0001369601086480543
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.127691787900403e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0007837891462258995
sam_encoder.blocks.2.norm1.bias grad: -0.0003908528888132423
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0004638629616238177
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.798305548727512e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.902496483642608e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.509510083356872e-05
sam_encoder.blocks.2.norm2.weight grad: -0.0011036916403099895
sam_encoder.blocks.2.norm2.bias grad: 0.00037539179902523756
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0007072293665260077
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00016858700837474316
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00020387471886351705
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.365444616880268e-05
sam_encoder.blocks.3.norm1.weight grad: -0.0008798906346783042
sam_encoder.blocks.3.norm1.bias grad: -0.0004629215691238642
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.375266017741524e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.851703902706504e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.097441994119436e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.5046529117389582e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0010910059791058302
sam_encoder.blocks.3.norm2.bias grad: 0.0011722005438059568
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.000771297374740243
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.000295050791464746
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00031136616598814726
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.6645484720356762e-05
sam_encoder.blocks.4.norm1.weight grad: -0.00040655373595654964
sam_encoder.blocks.4.norm1.bias grad: -0.00014966080198064446
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00034927084925584495
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00012108508235542104
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.0001950246951309964
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.576276842271909e-05
sam_encoder.blocks.4.norm2.weight grad: 0.0014993313234299421
sam_encoder.blocks.4.norm2.bias grad: 0.0007590343011543155
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0006716501666232944
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00020486777066253126
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00011016372445737943
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.5679742217762396e-05
sam_encoder.blocks.5.norm1.weight grad: 0.00016932599828578532
sam_encoder.blocks.5.norm1.bias grad: -0.00029114849166944623
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0001287283084820956
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.062739081855398e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00020081565889995545
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00017304020002484322
sam_encoder.blocks.5.norm2.weight grad: 0.0008673607371747494
sam_encoder.blocks.5.norm2.bias grad: 0.0003033392713405192
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00011204255133634433
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.217414319398813e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.2617535655153915e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.082123319269158e-05
sam_encoder.blocks.6.norm1.weight grad: -0.00039335573092103004
sam_encoder.blocks.6.norm1.bias grad: -0.00019121592049486935
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00015354080824181437
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.893602065043524e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00013918025069870055
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00011397444177418947
sam_encoder.blocks.6.norm2.weight grad: 0.0011809251736849546
sam_encoder.blocks.6.norm2.bias grad: 0.0001875504822237417
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0004998194053769112
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.000167401711223647
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00010753773676697165
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.625137757509947e-05
sam_encoder.blocks.7.norm1.weight grad: -9.756054350873455e-05
sam_encoder.blocks.7.norm1.bias grad: 6.378541729645804e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00011526470188982785
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.5124670325312763e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.336275742389262e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.5130134569481015e-05
sam_encoder.blocks.7.norm2.weight grad: 0.0005438884254544973
sam_encoder.blocks.7.norm2.bias grad: -9.907274034048896e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.00012976548168808222
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.880339186755009e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.7766170357353985e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.711685662390664e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00018904279568232596
sam_encoder.blocks.8.norm1.bias grad: -1.3901716556574684e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00027724815299734473
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.320541741733905e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.534497641841881e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00011315813026158139
sam_encoder.blocks.8.norm2.weight grad: 1.5145123143156525e-05
sam_encoder.blocks.8.norm2.bias grad: -6.460326403612271e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00018605042714625597
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00014382024528458714
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.0001655752130318433
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.385910430457443e-05
sam_encoder.blocks.9.norm1.weight grad: -3.2595831726212054e-05
sam_encoder.blocks.9.norm1.bias grad: 0.000160076524480246
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.427487384527922e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.416913594061043e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.269167387363268e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.932897379854694e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00026401373906992376
sam_encoder.blocks.9.norm2.bias grad: -5.080343908048235e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.970478378003463e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.6513380614924245e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00010033390572061762
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.757799226557836e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00010840917093446478
sam_encoder.blocks.10.norm1.bias grad: 3.374060906935483e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.8258540371316485e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.747363760136068e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.247300239512697e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.587275594123639e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0002494939253665507
sam_encoder.blocks.10.norm2.bias grad: -3.969320096075535e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 8.649012306705117e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.3535151083488017e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00014536190428771079
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.5068223951384425e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0004197934176772833
sam_encoder.blocks.11.norm1.bias grad: -6.27001136308536e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00026944177807308733
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.9031667003873736e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00011239263403695077
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.890226748306304e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0001388673554174602
sam_encoder.blocks.11.norm2.bias grad: 0.00010115017357748002
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.187808346818201e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.5462009944021702e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.695726526435465e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.720011803437956e-06
sam_encoder.neck.conv1.trainable_scale grad: -1.1904863640666008e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0002619170118123293
sam_encoder.neck.conv2.trainable_scale grad: 4.344462649896741e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.004244870971888304
mask_decoder.transformer.layers.0.norm1.weight grad: -0.009491071105003357
mask_decoder.transformer.layers.0.norm1.bias grad: 8.444348350167274e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.4330649971961975
mask_decoder.transformer.layers.0.norm2.bias grad: 0.03197658807039261
mask_decoder.transformer.layers.0.norm3.weight grad: -0.009182990528643131
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0021650916896760464
mask_decoder.transformer.layers.0.norm4.weight grad: 0.002753336913883686
mask_decoder.transformer.layers.0.norm4.bias grad: -3.2398966141045094e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0011073057539761066
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00018452585209161043
mask_decoder.transformer.layers.1.norm2.weight grad: -0.007190941832959652
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0022354531101882458
mask_decoder.transformer.layers.1.norm3.weight grad: -0.00010345180635340512
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00172464270144701
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0011663190089166164
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0007944598328322172
mask_decoder.transformer.norm_final_attn.weight grad: 0.0007557083154097199
mask_decoder.transformer.norm_final_attn.bias grad: 0.0009021887672133744
Text_Embedding_Affine.0.weight grad: -1.1266828581213417e-09
Text_Embedding_Affine.0.bias grad: -2.1733285393565893e-08
Text_Embedding_Affine.2.weight grad: -6.989951395475202e-10
Text_Embedding_Affine.2.bias grad: 0.00229250593110919

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.623237122997059e-12
Max value: 0.9977037310600281
Mean value: 0.07217200100421906

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.623237122997059e-12
Max value: 0.9977037310600281
Mean value: 0.07217200100421906

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07529306411743164

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1107993870973587

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06501340866088867

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07529306411743164

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 24.53734016418457
Max value: 68.1327896118164
Mean value: 53.363643646240234

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.623237122997059e-12
Max value: 0.9977037310600281
Mean value: 0.07217200100421906

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.623237122997059e-12
Max value: 0.9977037310600281
Mean value: 0.07217200100421906

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.623237122997059e-12
Max value: 0.9977037310600281
Mean value: 0.07217200100421906

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1107993870973587

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 24.53734016418457
Max value: 68.1327896118164
Mean value: 53.363643646240234

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.36465072631836
Max value: -53.36465072631836
Mean value: -53.36465072631836
sam_encoder.pos_embed grad: -4.11164933211694e-08
sam_encoder.blocks.0.norm1.weight grad: -0.002212990541011095
sam_encoder.blocks.0.norm1.bias grad: 0.000114717215183191
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00043678563088178635
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.330186882521957e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0002748326223809272
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00018954661209136248
sam_encoder.blocks.0.norm2.weight grad: 0.0030947800260037184
sam_encoder.blocks.0.norm2.bias grad: 0.0001910565624712035
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.00040128984255716205
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0002131182700395584
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0003771376796066761
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00016102938388939947
sam_encoder.blocks.1.norm1.weight grad: 0.00033779069781303406
sam_encoder.blocks.1.norm1.bias grad: 0.001263121608644724
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00021084600302856416
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00015888907364569604
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00033861291012726724
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00023103375860955566
sam_encoder.blocks.1.norm2.weight grad: -0.00023481957032345235
sam_encoder.blocks.1.norm2.bias grad: -0.0011716227745637298
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00010049370757769793
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4018452020536643e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00027933670207858086
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.957435784395784e-05
sam_encoder.blocks.2.norm1.weight grad: -0.00025370524963364005
sam_encoder.blocks.2.norm1.bias grad: -0.0003161801432725042
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0002713745925575495
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.5676158000133e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.656649929936975e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00020245682389941067
sam_encoder.blocks.2.norm2.weight grad: -0.0001236692478414625
sam_encoder.blocks.2.norm2.bias grad: -0.000148332939716056
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00013417695299722254
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00022779544815421104
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006329889874905348
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00024758436484262347
sam_encoder.blocks.3.norm1.weight grad: 0.0001881036296254024
sam_encoder.blocks.3.norm1.bias grad: -0.00036440457915887237
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00030710414284840226
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.5591914891265333e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00028795324033126235
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.45732801684062e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0006873138481751084
sam_encoder.blocks.3.norm2.bias grad: 0.00025050199474208057
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.000341600039973855
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0001319964212598279
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.665949796210043e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.4055934520438313e-05
sam_encoder.blocks.4.norm1.weight grad: -0.00034128929837606847
sam_encoder.blocks.4.norm1.bias grad: 0.00030925002647563815
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00015369657194241881
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00010713541269069538
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.0190530348336324e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002307444519829005
sam_encoder.blocks.4.norm2.weight grad: -0.0010670097544789314
sam_encoder.blocks.4.norm2.bias grad: -0.000813797116279602
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0006057096179574728
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0001343291369266808
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00039218930760398507
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00012971599062439054
sam_encoder.blocks.5.norm1.weight grad: -0.0008974270895123482
sam_encoder.blocks.5.norm1.bias grad: -0.0006483631441369653
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00048087042523548007
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00023672182578593493
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00014975597150623798
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00011490675387904048
sam_encoder.blocks.5.norm2.weight grad: -0.0018479484133422375
sam_encoder.blocks.5.norm2.bias grad: -0.0007221915293484926
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0010289977071806788
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00036488124169409275
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -0.00021676986943930387
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.216821930138394e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0007750688819214702
sam_encoder.blocks.6.norm1.bias grad: -0.0002968484186567366
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.0005351390573196113
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.00021053175441920757
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.944718865677714e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.342537330463529e-05
sam_encoder.blocks.6.norm2.weight grad: 0.00035231339279562235
sam_encoder.blocks.6.norm2.bias grad: 0.00020680039597209543
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.510197949362919e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.4804899264127016e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00012925556802656502
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.757328083040193e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0007247262983582914
sam_encoder.blocks.7.norm1.bias grad: 0.00021382134582381696
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.0006172008579596877
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00018296419875696301
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00016206165309995413
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0003231806622352451
sam_encoder.blocks.7.norm2.weight grad: 0.00035011846921406686
sam_encoder.blocks.7.norm2.bias grad: 0.00034546092501841486
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00014432682655751705
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00012010001228190958
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00012030184734612703
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.994029485620558e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0002927241730503738
sam_encoder.blocks.8.norm1.bias grad: 0.0001731901429593563
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0005948352627456188
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.0002234231069451198
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00022423877089750022
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00036100868601351976
sam_encoder.blocks.8.norm2.weight grad: -0.00026392246945761144
sam_encoder.blocks.8.norm2.bias grad: -5.883062112843618e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000411054992582649
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00029536543297581375
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00015835947124287486
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.298761142417789e-05
sam_encoder.blocks.9.norm1.weight grad: -0.0003153413417749107
sam_encoder.blocks.9.norm1.bias grad: 0.00010978508362313733
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0003026234917342663
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00014968228060752153
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.396844401024282e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00025610020384192467
sam_encoder.blocks.9.norm2.weight grad: 0.00025668376474641263
sam_encoder.blocks.9.norm2.bias grad: -0.00019923609215766191
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00015968437946867198
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.1303159175877227e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.168660522438586e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.5425732019357383e-05
sam_encoder.blocks.10.norm1.weight grad: 9.206955292029306e-05
sam_encoder.blocks.10.norm1.bias grad: 0.00011144409654662013
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.951002044137567e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.744767723721452e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.095067849149927e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.3346134336607065e-06
sam_encoder.blocks.10.norm2.weight grad: -0.0003700864617712796
sam_encoder.blocks.10.norm2.bias grad: -0.0004346763889770955
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.5027139801968588e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00014766809181310236
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00014625575568061322
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.456827784655616e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0006710761226713657
sam_encoder.blocks.11.norm1.bias grad: 7.261425253091147e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0006421449361369014
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00013074168236926198
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0002118996053468436
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.582552593201399e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0003712511097546667
sam_encoder.blocks.11.norm2.bias grad: -0.00032682111486792564
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.542509749531746e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00011765479575842619
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00015866306785028428
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.532468250952661e-05
sam_encoder.neck.conv1.trainable_scale grad: 8.622708264738321e-06
sam_encoder.neck.conv1.trainable_shift grad: -0.0008038565283641219
sam_encoder.neck.conv2.trainable_scale grad: 7.41748372092843e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0011380688520148396
mask_decoder.transformer.layers.0.norm1.weight grad: -0.01205240935087204
mask_decoder.transformer.layers.0.norm1.bias grad: -2.102646976709366e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.5564118027687073
mask_decoder.transformer.layers.0.norm2.bias grad: 0.05296464264392853
mask_decoder.transformer.layers.0.norm3.weight grad: -0.004696441814303398
mask_decoder.transformer.layers.0.norm3.bias grad: 0.009640879929065704
mask_decoder.transformer.layers.0.norm4.weight grad: 0.003018805757164955
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0010561615927144885
mask_decoder.transformer.layers.1.norm1.weight grad: 0.007256884593516588
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0005474291974678636
mask_decoder.transformer.layers.1.norm2.weight grad: 0.029083028435707092
mask_decoder.transformer.layers.1.norm2.bias grad: 0.006342509761452675
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0037314961664378643
mask_decoder.transformer.layers.1.norm3.bias grad: 0.007881170138716698
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0022352500818669796
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0068066841922700405
mask_decoder.transformer.norm_final_attn.weight grad: 0.0003987587697338313
mask_decoder.transformer.norm_final_attn.bias grad: 0.0008780558709986508
Text_Embedding_Affine.0.weight grad: -6.403408914223974e-10
Text_Embedding_Affine.0.bias grad: -1.0826624929904938e-08
Text_Embedding_Affine.2.weight grad: 1.400318350164298e-08
Text_Embedding_Affine.2.bias grad: -0.0015390446642413735

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.50389561914821e-10
Max value: 0.9989068508148193
Mean value: 0.09075220674276352

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.50389561914821e-10
Max value: 0.9989068508148193
Mean value: 0.09075220674276352

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09841346740722656

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.006834030151367
Max value: -1.1920928244535389e-07
Mean value: -0.13819296658039093

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08485221862792969

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09841346740722656

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 36.765968322753906
Max value: 77.0506362915039
Mean value: 61.39678192138672

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.50389561914821e-10
Max value: 0.9989068508148193
Mean value: 0.09075220674276352

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.50389561914821e-10
Max value: 0.9989068508148193
Mean value: 0.09075220674276352

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.50389561914821e-10
Max value: 0.9989068508148193
Mean value: 0.09075220674276352

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.006834030151367
Max value: -1.1920928244535389e-07
Mean value: -0.13819296658039093

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 36.765968322753906
Max value: 77.0506362915039
Mean value: 61.39678192138672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.39792251586914
Max value: -61.39792251586914
Mean value: -61.39792251586914
sam_encoder.pos_embed grad: -5.238713356447988e-07
sam_encoder.blocks.0.norm1.weight grad: -0.002063620835542679
sam_encoder.blocks.0.norm1.bias grad: -0.00012551943655125797
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0003448066709097475
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.7878969060802774e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0002828500000759959
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00021839849068783224
sam_encoder.blocks.0.norm2.weight grad: 0.0002712053246796131
sam_encoder.blocks.0.norm2.bias grad: 0.003961670212447643
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0010989776346832514
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0007456297753378749
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0015261173248291016
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0004719768767245114
sam_encoder.blocks.1.norm1.weight grad: -0.000718543422408402
sam_encoder.blocks.1.norm1.bias grad: -0.00021360690880101174
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0003593156288843602
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.701871901284903e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 0.0002203146432293579
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.4571843318408355e-05
sam_encoder.blocks.1.norm2.weight grad: 0.001328206853941083
sam_encoder.blocks.1.norm2.bias grad: -0.0002880845859181136
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.0005369039135985076
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00010811735410243273
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.0009340487304143608
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 0.00012564091593958437
sam_encoder.blocks.2.norm1.weight grad: 0.0005715074948966503
sam_encoder.blocks.2.norm1.bias grad: -0.001226193504408002
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00037647815770469606
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.322081314167008e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.311328565469012e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00019763546879403293
sam_encoder.blocks.2.norm2.weight grad: 0.00037866015918552876
sam_encoder.blocks.2.norm2.bias grad: 0.0002724441874306649
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.0002705044753383845
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.79048859840259e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.000500608584843576
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.950088284909725e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0004394529387354851
sam_encoder.blocks.3.norm1.bias grad: -0.0011212164536118507
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0004459738847799599
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.00012568378588184714
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0003733163175638765
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 0.0002552260411903262
sam_encoder.blocks.3.norm2.weight grad: 0.0003532014670781791
sam_encoder.blocks.3.norm2.bias grad: 0.0002185696503147483
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.00043465307680889964
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00012620560301002115
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0006241193041205406
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.00020356963796075433
sam_encoder.blocks.4.norm1.weight grad: -0.00015819170221220702
sam_encoder.blocks.4.norm1.bias grad: -0.000676554162055254
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00021624795044772327
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.539374539395794e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00022437333245761693
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0002345230896025896
sam_encoder.blocks.4.norm2.weight grad: -0.0015116370050236583
sam_encoder.blocks.4.norm2.bias grad: -0.0003341335686855018
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.000787904195021838
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00032679777359589934
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00027033366495743394
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.5929544537793845e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0005627530626952648
sam_encoder.blocks.5.norm1.bias grad: -0.00040194758912548423
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0003370666818227619
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00014941317203920335
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0002048262394964695
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.438644878566265e-05
sam_encoder.blocks.5.norm2.weight grad: 0.00023251240781974047
sam_encoder.blocks.5.norm2.bias grad: -0.00045451472396962345
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.485121411969885e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.3749102183501236e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0002473506610840559
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.1674506569979712e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0005766121903434396
sam_encoder.blocks.6.norm1.bias grad: 0.00017774931620806456
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00045926659367978573
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00018709534197114408
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00019654985226225108
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.0001424851652700454
sam_encoder.blocks.6.norm2.weight grad: -9.588890679879114e-05
sam_encoder.blocks.6.norm2.bias grad: -0.0002222147595603019
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.404486288782209e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.5776498154737055e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.0002611080417409539
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.769326965790242e-05
sam_encoder.blocks.7.norm1.weight grad: 0.0006394149968400598
sam_encoder.blocks.7.norm1.bias grad: 0.00010086980182677507
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0004919881466776133
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0002590108197182417
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00023224300821311772
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00021891568030696362
sam_encoder.blocks.7.norm2.weight grad: -6.0346930695232004e-05
sam_encoder.blocks.7.norm2.bias grad: 4.8083158617373556e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.4811002984060906e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.745749149355106e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.1565300155780278e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.195072587113827e-05
sam_encoder.blocks.8.norm1.weight grad: -2.1761527023045346e-05
sam_encoder.blocks.8.norm1.bias grad: -5.70232150494121e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.30716240266338e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.718518074601889e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00010095606558024883
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00012241849617566913
sam_encoder.blocks.8.norm2.weight grad: 0.00011189872020622715
sam_encoder.blocks.8.norm2.bias grad: -0.00011828485003206879
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.00020316406153142452
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.0001513091119704768
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00014160681166686118
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.2457676095655188e-05
sam_encoder.blocks.9.norm1.weight grad: 0.00017172179650515318
sam_encoder.blocks.9.norm1.bias grad: 4.390181493363343e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00021347164874896407
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.572413207730278e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.23161899461411e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 8.51273798616603e-05
sam_encoder.blocks.9.norm2.weight grad: 0.0005528801120817661
sam_encoder.blocks.9.norm2.bias grad: 0.00013280495477374643
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.00039522023871541023
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.00024422333808615804
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.415933603420854e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.1957516107941046e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0002953110379166901
sam_encoder.blocks.10.norm1.bias grad: 0.0001694129896350205
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.00019116785551887006
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.612631791038439e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00010009166726376861
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.364172830013558e-05
sam_encoder.blocks.10.norm2.weight grad: 0.0012283966643735766
sam_encoder.blocks.10.norm2.bias grad: 0.000247846357524395
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.0005568804335780442
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00030989732476882637
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.00011281243496341631
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.1059531061619055e-05
sam_encoder.blocks.11.norm1.weight grad: 0.001015103654935956
sam_encoder.blocks.11.norm1.bias grad: 6.350914190988988e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00010215368820354342
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.654021202237345e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.0001452416181564331
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.100089088547975e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0010625370778143406
sam_encoder.blocks.11.norm2.bias grad: -3.7054280255688354e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0005221290048211813
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.00022510762210004032
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.344788900809363e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.462651486392133e-05
sam_encoder.neck.conv1.trainable_scale grad: 7.749511860311031e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0008124076994135976
sam_encoder.neck.conv2.trainable_scale grad: -2.5541987270116806e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.007370103150606155
mask_decoder.transformer.layers.0.norm1.weight grad: -1.7727958038449287e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.3931730538606644e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.3055534064769745
mask_decoder.transformer.layers.0.norm2.bias grad: -0.09132654219865799
mask_decoder.transformer.layers.0.norm3.weight grad: -0.003762276377528906
mask_decoder.transformer.layers.0.norm3.bias grad: -0.004797120112925768
mask_decoder.transformer.layers.0.norm4.weight grad: 0.007154417689889669
mask_decoder.transformer.layers.0.norm4.bias grad: 1.6345642507076263e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0003327279700897634
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0007164529524743557
mask_decoder.transformer.layers.1.norm2.weight grad: -0.027249746024608612
mask_decoder.transformer.layers.1.norm2.bias grad: -0.004649236798286438
mask_decoder.transformer.layers.1.norm3.weight grad: 0.000569254974834621
mask_decoder.transformer.layers.1.norm3.bias grad: -0.001523816492408514
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0073112864047288895
mask_decoder.transformer.layers.1.norm4.bias grad: -0.014471437782049179
mask_decoder.transformer.norm_final_attn.weight grad: -2.293665602337569e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0010575023479759693
Text_Embedding_Affine.0.weight grad: -6.02997762833013e-10
Text_Embedding_Affine.0.bias grad: -2.0372681319713593e-08
Text_Embedding_Affine.2.weight grad: -8.683540553278135e-10
Text_Embedding_Affine.2.bias grad: -6.312993355095387e-05
Epoch 35 finished with average loss: -57.6630
Epoch 36/39
----------
Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/3 [00:01<?, ?it/s, loss=-61]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.06s/it, loss=-61]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.06s/it, loss=-55.1]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.51it/s, loss=-55.1]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.51it/s, loss=-56]  Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.13it/s, loss=-56]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.825588275665261e-12
Max value: 0.9994105100631714
Mean value: 0.09587869048118591

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.825588275665261e-12
Max value: 0.9994105100631714
Mean value: 0.09587869048118591

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09557533264160156

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1290787011384964

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08714628219604492

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09557533264160156

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 17.277015686035156
Max value: 80.44137573242188
Mean value: 60.989253997802734

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.825588275665261e-12
Max value: 0.9994105100631714
Mean value: 0.09587869048118591

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.825588275665261e-12
Max value: 0.9994105100631714
Mean value: 0.09587869048118591

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.825588275665261e-12
Max value: 0.9994105100631714
Mean value: 0.09587869048118591

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1290787011384964

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 17.277015686035156
Max value: 80.44137573242188
Mean value: 60.989253997802734

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.99053192138672
Max value: -60.99053192138672
Mean value: -60.99053192138672
sam_encoder.pos_embed grad: 1.0093445723668992e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0007413196144625545
sam_encoder.blocks.0.norm1.bias grad: -0.004852360114455223
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0012687162961810827
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2696832527581137e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0006396532407961786
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0007033743895590305
sam_encoder.blocks.0.norm2.weight grad: 0.0048660412430763245
sam_encoder.blocks.0.norm2.bias grad: -0.0041596717201173306
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0008494495414197445
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.148629472590983e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0019246935844421387
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0009927884675562382
sam_encoder.blocks.1.norm1.weight grad: 0.0017863920656964183
sam_encoder.blocks.1.norm1.bias grad: 0.003484858898445964
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0010638050734996796
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00033809393062256277
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0013293575029820204
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0005674817366525531
sam_encoder.blocks.1.norm2.weight grad: 0.0017919595120474696
sam_encoder.blocks.1.norm2.bias grad: 2.2313015506369993e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.00014909547462593764
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.00018029322382062674
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0013761643785983324
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.273254282656126e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0006676893099211156
sam_encoder.blocks.2.norm1.bias grad: 0.0029514902271330357
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0010056369937956333
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00025241984985768795
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00044551765313372016
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003223349340260029
sam_encoder.blocks.2.norm2.weight grad: -0.0025918339379131794
sam_encoder.blocks.2.norm2.bias grad: 0.00011739209003280848
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0020315859001129866
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0005392810562625527
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0009653570014052093
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.0003709638840518892
sam_encoder.blocks.3.norm1.weight grad: 0.0005750020500272512
sam_encoder.blocks.3.norm1.bias grad: 0.000920579768717289
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0001155682111857459
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.459550498519093e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.617623097961769e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.27264559827745e-05
sam_encoder.blocks.3.norm2.weight grad: -0.0031632445752620697
sam_encoder.blocks.3.norm2.bias grad: -0.0006467977073043585
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0018681930378079414
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0004570343007799238
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0011794932652264833
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0005603061872534454
sam_encoder.blocks.4.norm1.weight grad: -0.0010272300569340587
sam_encoder.blocks.4.norm1.bias grad: -0.0005070468178018928
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0007004257058724761
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00016072444850578904
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00034507777309045196
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002959779812954366
sam_encoder.blocks.4.norm2.weight grad: 0.00042009662138298154
sam_encoder.blocks.4.norm2.bias grad: -0.001051721628755331
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.00016871243133209646
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00011026561696780846
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0002682633057702333
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.0001602913107490167
sam_encoder.blocks.5.norm1.weight grad: -0.002679792931303382
sam_encoder.blocks.5.norm1.bias grad: -0.0008926831069402397
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.002281279768794775
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.000887116591911763
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0008137723198160529
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.000246775452978909
sam_encoder.blocks.5.norm2.weight grad: 0.0002942400751635432
sam_encoder.blocks.5.norm2.bias grad: -0.00102391024120152
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.2447882656706497e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0001134064732468687
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00010425706568639725
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.1629077309626155e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0005198580911383033
sam_encoder.blocks.6.norm1.bias grad: -0.0005236699944362044
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00019703895668499172
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.5939137887908146e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.0115497540682554e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.404236071626656e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0009863737504929304
sam_encoder.blocks.6.norm2.bias grad: 0.000471100996946916
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0007623665733262897
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0002009788149734959
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0003239641373511404
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00012951326789334416
sam_encoder.blocks.7.norm1.weight grad: 0.0007088191341608763
sam_encoder.blocks.7.norm1.bias grad: -0.00023894288460724056
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0002504491130821407
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.082359762629494e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.730047167977318e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00021061417646706104
sam_encoder.blocks.7.norm2.weight grad: 0.0006391864735633135
sam_encoder.blocks.7.norm2.bias grad: 0.00020433605823200196
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 0.0006720707751810551
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 0.00022980195353738964
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.9671162085141987e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.000756911817007e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00023151490313466638
sam_encoder.blocks.8.norm1.bias grad: 0.00017327179375570267
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003301681426819414
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.9025853816856397e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.145879807358142e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 0.00015827539027668536
sam_encoder.blocks.8.norm2.weight grad: 5.999310451443307e-05
sam_encoder.blocks.8.norm2.bias grad: -1.1539479601196945e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.4939097026363015e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.8314167391508818e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00014221029414329678
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.727982978802174e-05
sam_encoder.blocks.9.norm1.weight grad: 7.781924068694934e-05
sam_encoder.blocks.9.norm1.bias grad: -9.886727639241144e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00012356851948425174
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.540569716482423e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.873966099694371e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.8396612833603285e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0003541594778653234
sam_encoder.blocks.9.norm2.bias grad: -7.239921251311898e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00028190057491883636
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0001493931486038491
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.532827683258802e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.5309407647000626e-05
sam_encoder.blocks.10.norm1.weight grad: 0.00013647577725350857
sam_encoder.blocks.10.norm1.bias grad: -2.369290086789988e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0002498610410839319
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.447913230862468e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.706837590783834e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00010827743972185999
sam_encoder.blocks.10.norm2.weight grad: -0.00035225989995524287
sam_encoder.blocks.10.norm2.bias grad: -0.0001821113983169198
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0003131378616672009
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.332347478135489e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.320952474605292e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.6439504179288633e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0014432109892368317
sam_encoder.blocks.11.norm1.bias grad: 0.0002580445143394172
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00039818297955207527
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -0.00010030429984908551
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.351642539608292e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.3752274336839037e-07
sam_encoder.blocks.11.norm2.weight grad: -0.0008079087710939348
sam_encoder.blocks.11.norm2.bias grad: -0.00010768084030132741
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0003036016132682562
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0001417288149241358
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.180967036721995e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.4939322581049055e-05
sam_encoder.neck.conv1.trainable_scale grad: -0.00011562311556190252
sam_encoder.neck.conv1.trainable_shift grad: -0.0009837182005867362
sam_encoder.neck.conv2.trainable_scale grad: -0.00012463482562452555
sam_encoder.neck.conv2.trainable_shift grad: 0.0007857776945456862
mask_decoder.transformer.layers.0.norm1.weight grad: -0.007773729972541332
mask_decoder.transformer.layers.0.norm1.bias grad: -0.000563004519790411
mask_decoder.transformer.layers.0.norm2.weight grad: -0.10631201416254044
mask_decoder.transformer.layers.0.norm2.bias grad: -0.01984918862581253
mask_decoder.transformer.layers.0.norm3.weight grad: -0.003965829499065876
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00691227987408638
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0008909369353204966
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00040472415275871754
mask_decoder.transformer.layers.1.norm1.weight grad: 0.000508834607899189
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00011361634824424982
mask_decoder.transformer.layers.1.norm2.weight grad: 0.02418493665754795
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0008373181335628033
mask_decoder.transformer.layers.1.norm3.weight grad: 0.005397046450525522
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0003689575823955238
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0042685880325734615
mask_decoder.transformer.layers.1.norm4.bias grad: -0.008692133240401745
mask_decoder.transformer.norm_final_attn.weight grad: 0.00022379320580512285
mask_decoder.transformer.norm_final_attn.bias grad: 0.0014004460535943508
Text_Embedding_Affine.0.weight grad: -4.044925505652941e-10
Text_Embedding_Affine.0.bias grad: -1.2398231774568558e-08
Text_Embedding_Affine.2.weight grad: 8.022403186203064e-09
Text_Embedding_Affine.2.bias grad: 0.001789608970284462

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9631815270648723e-11
Max value: 0.9977118968963623
Mean value: 0.07201177626848221

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9631815270648723e-11
Max value: 0.9977118968963623
Mean value: 0.07201177626848221

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07507562637329102

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.639223098754883
Max value: -1.1920928244535389e-07
Mean value: -0.12628522515296936

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05651569366455078

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07507562637329102

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 25.945693969726562
Max value: 63.716854095458984
Mean value: 49.170448303222656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9631815270648723e-11
Max value: 0.9977118968963623
Mean value: 0.07201177626848221

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9631815270648723e-11
Max value: 0.9977118968963623
Mean value: 0.07201177626848221

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9631815270648723e-11
Max value: 0.9977118968963623
Mean value: 0.07201177626848221

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.639223098754883
Max value: -1.1920928244535389e-07
Mean value: -0.12628522515296936

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 25.945693969726562
Max value: 63.716854095458984
Mean value: 49.170448303222656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.171630859375
Max value: -49.171630859375
Mean value: -49.171630859375
sam_encoder.pos_embed grad: 9.218456398230046e-08
sam_encoder.blocks.0.norm1.weight grad: 0.0007671450148336589
sam_encoder.blocks.0.norm1.bias grad: -0.00019025089568458498
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0004498489142861217
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.881459219381213e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.942018884117715e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.138715540757403e-05
sam_encoder.blocks.0.norm2.weight grad: 0.00463783647865057
sam_encoder.blocks.0.norm2.bias grad: 0.0005276491865515709
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0010374117409810424
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.3764262702316046e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0015418212860822678
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0008031741017475724
sam_encoder.blocks.1.norm1.weight grad: 0.00010237158858217299
sam_encoder.blocks.1.norm1.bias grad: 0.001135022728703916
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0008755227318033576
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0002834809711202979
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0008642375469207764
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0004311454249545932
sam_encoder.blocks.1.norm2.weight grad: 0.0009027727646753192
sam_encoder.blocks.1.norm2.bias grad: -0.00019287108443677425
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0002647244546096772
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.9774116380140185e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0007399760652333498
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.446970994351432e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0022793454118072987
sam_encoder.blocks.2.norm1.bias grad: 9.905851766234264e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0015800429973751307
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0003458971332293004
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0010392244439572096
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0007963104872033
sam_encoder.blocks.2.norm2.weight grad: -0.001550388871692121
sam_encoder.blocks.2.norm2.bias grad: -0.0007483187364414334
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0010142041137441993
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001956973283085972
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005463012494146824
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00012129996321164072
sam_encoder.blocks.3.norm1.weight grad: -3.91071371268481e-05
sam_encoder.blocks.3.norm1.bias grad: -2.7358444640412927e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.203389006666839e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.139515946619213e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00020272406982257962
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0002314750454388559
sam_encoder.blocks.3.norm2.weight grad: -0.00037157064070925117
sam_encoder.blocks.3.norm2.bias grad: 0.00011303629435133189
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0004699087585322559
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0001807076041586697
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.4882092374318745e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.534617674944457e-06
sam_encoder.blocks.4.norm1.weight grad: 0.0016188230365514755
sam_encoder.blocks.4.norm1.bias grad: -0.0005369411082938313
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0004694439412560314
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001517453056294471
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.606567068141885e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.367329478962347e-05
sam_encoder.blocks.4.norm2.weight grad: 1.6929097910178825e-05
sam_encoder.blocks.4.norm2.bias grad: 2.704458893276751e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0004699154233094305
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00024282622325699776
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00010749752254923806
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.9468081518425606e-05
sam_encoder.blocks.5.norm1.weight grad: 0.0007297857664525509
sam_encoder.blocks.5.norm1.bias grad: -0.001541742472909391
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0005690927500836551
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00030127522768452764
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.396527118748054e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.081583417952061e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0005215599667280912
sam_encoder.blocks.5.norm2.bias grad: 0.00021054470562376082
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.719461139757186e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.036560428881785e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001101549351005815
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.2682702365273144e-06
sam_encoder.blocks.6.norm1.weight grad: -0.0001292511005885899
sam_encoder.blocks.6.norm1.bias grad: -0.00025828121579252183
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.649285645224154e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00012353251804597676
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.901318556629121e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.763202741742134e-05
sam_encoder.blocks.6.norm2.weight grad: 0.00020202188170515
sam_encoder.blocks.6.norm2.bias grad: 0.00012109601811971515
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00010783928883029148
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.073913340922445e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00020426156697794795
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.132709778379649e-05
sam_encoder.blocks.7.norm1.weight grad: 0.000244921597186476
sam_encoder.blocks.7.norm1.bias grad: 2.5892903067870066e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.0450904382159933e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.995019015856087e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.040664058877155e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.4484925486613065e-05
sam_encoder.blocks.7.norm2.weight grad: -0.00011593198723858222
sam_encoder.blocks.7.norm2.bias grad: -0.0002110918576363474
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.0002973775553982705
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00023964126012288034
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.0001686381147010252
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.7721715266816318e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00038912598392926157
sam_encoder.blocks.8.norm1.bias grad: -8.360044739674777e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00046448910143226385
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00022187840659171343
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.654474130598828e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.960334288422018e-05
sam_encoder.blocks.8.norm2.weight grad: -0.000171282488736324
sam_encoder.blocks.8.norm2.bias grad: 0.00012977594451513141
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00033568055368959904
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00018008837650995702
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.358841634821147e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.746486517135054e-06
sam_encoder.blocks.9.norm1.weight grad: 0.00022064776567276567
sam_encoder.blocks.9.norm1.bias grad: 7.572710273962002e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00012711843010038137
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.7013771614292637e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.901575837517157e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.462187280296348e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0003989799879491329
sam_encoder.blocks.9.norm2.bias grad: 6.231370207387954e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0005566330510191619
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00023915988276712596
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00016659838729538023
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.8361235056072474e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00037474907003343105
sam_encoder.blocks.10.norm1.bias grad: 2.826059608196374e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00025798060232773423
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.425606549484655e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.00012276743655093014
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.856841380591504e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0005842132377438247
sam_encoder.blocks.10.norm2.bias grad: -0.00012387138849589974
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0003845641331281513
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0002176215930376202
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00011483527487143874
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.571993875084445e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00047593674389645457
sam_encoder.blocks.11.norm1.bias grad: 4.761977106682025e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00017226944328285754
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.728487046028022e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.708507812116295e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.001829125219956e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0008748920517973602
sam_encoder.blocks.11.norm2.bias grad: -9.250988659914583e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0002923712891060859
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0001758643629727885
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.687200508778915e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.246337968856096e-05
sam_encoder.neck.conv1.trainable_scale grad: 6.166053935885429e-06
sam_encoder.neck.conv1.trainable_shift grad: 0.000334947369992733
sam_encoder.neck.conv2.trainable_scale grad: 7.781182648614049e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.002477950882166624
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0003268334548920393
mask_decoder.transformer.layers.0.norm1.bias grad: 8.909963071346283e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.23432089388370514
mask_decoder.transformer.layers.0.norm2.bias grad: 0.03632287681102753
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00017543043941259384
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00014791288413107395
mask_decoder.transformer.layers.0.norm4.weight grad: -0.004427955485880375
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0009935301495715976
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0008123866282403469
mask_decoder.transformer.layers.1.norm1.bias grad: -2.3512926418334246e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.005190622992813587
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011130399070680141
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0026349469553679228
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00129497773014009
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0010936150792986155
mask_decoder.transformer.layers.1.norm4.bias grad: 0.008789649233222008
mask_decoder.transformer.norm_final_attn.weight grad: 7.954805914778262e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.00044846965465694666
Text_Embedding_Affine.0.weight grad: -2.0937132028109318e-09
Text_Embedding_Affine.0.bias grad: -5.538458935916424e-08
Text_Embedding_Affine.2.weight grad: 3.390695058058668e-09
Text_Embedding_Affine.2.bias grad: -0.0008969574701040983

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.8386748720788937e-11
Max value: 0.9976741671562195
Mean value: 0.08051982522010803

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.8386748720788937e-11
Max value: 0.9976741671562195
Mean value: 0.08051982522010803

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07708263397216797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10795731842517853

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07425498962402344

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07708263397216797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 48.556907653808594
Max value: 67.37434387207031
Mean value: 57.831031799316406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.8386748720788937e-11
Max value: 0.9976741671562195
Mean value: 0.08051982522010803

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.8386748720788937e-11
Max value: 0.9976741671562195
Mean value: 0.08051982522010803

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.8386748720788937e-11
Max value: 0.9976741671562195
Mean value: 0.08051982522010803

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10795731842517853

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 48.556907653808594
Max value: 67.37434387207031
Mean value: 57.831031799316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.83211898803711
Max value: -57.83211898803711
Mean value: -57.83211898803711
sam_encoder.pos_embed grad: -6.366191485085437e-08
sam_encoder.blocks.0.norm1.weight grad: 0.0041207666508853436
sam_encoder.blocks.0.norm1.bias grad: 0.0018883547745645046
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.520865230821073e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.87793782769586e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.5102537620114163e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.744826972251758e-05
sam_encoder.blocks.0.norm2.weight grad: -0.001487448811531067
sam_encoder.blocks.0.norm2.bias grad: 0.0026369811967015266
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.001423228532075882
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0004990528104826808
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0007059655035845935
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.00011074399662902579
sam_encoder.blocks.1.norm1.weight grad: 0.0007335254922509193
sam_encoder.blocks.1.norm1.bias grad: 0.0011774428421631455
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.0001073479070328176
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.2236580308526754e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0001655039086472243
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.912630538456142e-05
sam_encoder.blocks.1.norm2.weight grad: 0.000711798551492393
sam_encoder.blocks.1.norm2.bias grad: -0.00013672540080733597
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0001886452955659479
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.128193515702151e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.067727736080997e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.134874562732875e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0003967042430303991
sam_encoder.blocks.2.norm1.bias grad: -0.0001815625437302515
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0001819496974349022
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.7117188437841833e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.6440686522400938e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00016893759311642498
sam_encoder.blocks.2.norm2.weight grad: 0.00015174031432252377
sam_encoder.blocks.2.norm2.bias grad: -0.0007177339866757393
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.00010300244321115315
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.643700180575252e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0002416679635643959
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00017924816347658634
sam_encoder.blocks.3.norm1.weight grad: -0.0007439353503286839
sam_encoder.blocks.3.norm1.bias grad: -0.0003643491945695132
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0005505634471774101
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.917907790513709e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0002087085449602455
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.140724584227428e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0001346063072560355
sam_encoder.blocks.3.norm2.bias grad: 0.00024848285829648376
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0001583538542035967
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00018967152573168278
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00023398756457027048
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00013099225179757923
sam_encoder.blocks.4.norm1.weight grad: 0.00041289778891950846
sam_encoder.blocks.4.norm1.bias grad: 0.00013362252502702177
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.1578031009994447e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.238613034132868e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.440444925217889e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.082922921748832e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0017405900871381164
sam_encoder.blocks.4.norm2.bias grad: -0.0015245176618918777
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0010774325346574187
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0003697982174344361
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.0001071641017915681
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.00016724574379622936
sam_encoder.blocks.5.norm1.weight grad: -4.7088869905564934e-05
sam_encoder.blocks.5.norm1.bias grad: -0.000664534920360893
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.360937211662531e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00013549299910664558
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.0001656754029681906
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.0707817384391092e-05
sam_encoder.blocks.5.norm2.weight grad: -0.001204553060233593
sam_encoder.blocks.5.norm2.bias grad: -0.0004700269491877407
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0005914027569815516
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00022392008395399898
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.613880107877776e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -0.00010610895697027445
sam_encoder.blocks.6.norm1.weight grad: 0.0003805183805525303
sam_encoder.blocks.6.norm1.bias grad: -5.778963532065973e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00019385413907002658
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3678257346327882e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00015557932783849537
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.0678816478466615e-05
sam_encoder.blocks.6.norm2.weight grad: -7.602209370816126e-05
sam_encoder.blocks.6.norm2.bias grad: 0.0002128535124938935
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.58254575682804e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0532842679822352e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00020119629334658384
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.8912007110193372e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00026472279569134116
sam_encoder.blocks.7.norm1.bias grad: 0.00011132420331705362
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00022175138292368501
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.917850209400058e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.887447281973436e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.577451080782339e-05
sam_encoder.blocks.7.norm2.weight grad: -7.822664338164032e-05
sam_encoder.blocks.7.norm2.bias grad: 1.718852945487015e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.917957656085491e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.827690190722933e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.324818579945713e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.820695074973628e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00032659561838954687
sam_encoder.blocks.8.norm1.bias grad: -2.0506802684394643e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00016819313168525696
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.795032383408397e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.00010939099593088031
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.352856093551964e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0004439027688931674
sam_encoder.blocks.8.norm2.bias grad: -8.521172276232392e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00031827890779823065
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00016508667613379657
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00017047402798198164
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -0.00013004025095142424
sam_encoder.blocks.9.norm1.weight grad: -0.00015225884271785617
sam_encoder.blocks.9.norm1.bias grad: -3.416324034333229e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00011752689897548407
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3408632185019087e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7777701941668056e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.9288053307682276e-05
sam_encoder.blocks.9.norm2.weight grad: -0.00011444551637396216
sam_encoder.blocks.9.norm2.bias grad: -0.00020080877584405243
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.810347672901116e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.399054159875959e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.856667171930894e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.754961628350429e-05
sam_encoder.blocks.10.norm1.weight grad: 6.877991836518049e-05
sam_encoder.blocks.10.norm1.bias grad: 3.304233177914284e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.825667954515666e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.825842264224775e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.438347918447107e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.3802104957867414e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00011081289267167449
sam_encoder.blocks.10.norm2.bias grad: -0.0002353984018554911
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.5377174349850975e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2347975825832691e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.405308911576867e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.7307229427387938e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0010158218210563064
sam_encoder.blocks.11.norm1.bias grad: 7.200829713838175e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.000487499259179458
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.223714783322066e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.78493771981448e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.6141085729468614e-05
sam_encoder.blocks.11.norm2.weight grad: -8.19985507405363e-05
sam_encoder.blocks.11.norm2.bias grad: 6.516344001283869e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.876424307236448e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.6770550397923216e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.292619506595656e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.600481745204888e-05
sam_encoder.neck.conv1.trainable_scale grad: -3.1031668186187744e-06
sam_encoder.neck.conv1.trainable_shift grad: -0.0010772085515782237
sam_encoder.neck.conv2.trainable_scale grad: -5.597790004685521e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0031511688139289618
mask_decoder.transformer.layers.0.norm1.weight grad: -0.008814278990030289
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00016357377171516418
mask_decoder.transformer.layers.0.norm2.weight grad: -0.331987202167511
mask_decoder.transformer.layers.0.norm2.bias grad: 0.013926113955676556
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00420554680749774
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0028869840316474438
mask_decoder.transformer.layers.0.norm4.weight grad: 0.010584713891148567
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0003353775246068835
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0007803309708833694
mask_decoder.transformer.layers.1.norm1.bias grad: 0.000527473515830934
mask_decoder.transformer.layers.1.norm2.weight grad: -0.008678825572133064
mask_decoder.transformer.layers.1.norm2.bias grad: -0.001857777708210051
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0017758230678737164
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0010194946080446243
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00453230319544673
mask_decoder.transformer.layers.1.norm4.bias grad: -0.01029400434345007
mask_decoder.transformer.norm_final_attn.weight grad: 7.154842023737729e-06
mask_decoder.transformer.norm_final_attn.bias grad: 0.00098852114751935
Text_Embedding_Affine.0.weight grad: -3.0684202401154437e-10
Text_Embedding_Affine.0.bias grad: -2.3515895009040833e-08
Text_Embedding_Affine.2.weight grad: 4.271975218017587e-09
Text_Embedding_Affine.2.bias grad: 0.001947746961377561
Epoch 36 finished with average loss: -55.9981
Epoch 37/39
----------
Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.8]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.03it/s, loss=-55.8]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.03it/s, loss=-58.1]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-58.1]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-56.2]Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-56.2]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.203706480132574e-11
Max value: 0.9986316561698914
Mean value: 0.08755286037921906

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.203706480132574e-11
Max value: 0.9986316561698914
Mean value: 0.08755286037921906

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08906841278076172

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12895365059375763

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08164596557617188

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08906841278076172

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.37091064453125
Max value: 73.4954833984375
Mean value: 55.83345031738281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.203706480132574e-11
Max value: 0.9986316561698914
Mean value: 0.08755286037921906

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.203706480132574e-11
Max value: 0.9986316561698914
Mean value: 0.08755286037921906

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.203706480132574e-11
Max value: 0.9986316561698914
Mean value: 0.08755286037921906

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12895365059375763

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.37091064453125
Max value: 73.4954833984375
Mean value: 55.83345031738281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.83461380004883
Max value: -55.83461380004883
Mean value: -55.83461380004883
sam_encoder.pos_embed grad: 6.781098704777833e-07
sam_encoder.blocks.0.norm1.weight grad: -0.002222208771854639
sam_encoder.blocks.0.norm1.bias grad: -0.0005675172433257103
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00029867381090298295
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.93825859343633e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0005527811590582132
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 0.0002440249518258497
sam_encoder.blocks.0.norm2.weight grad: 0.0022014460992068052
sam_encoder.blocks.0.norm2.bias grad: -0.0021924281027168036
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.001691623474471271
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.000821688212454319
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0014692018739879131
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0006185476668179035
sam_encoder.blocks.1.norm1.weight grad: 0.0003564169746823609
sam_encoder.blocks.1.norm1.bias grad: 0.001388870645314455
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0007887475076131523
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00016025936929509044
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0007416662992909551
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00047779083251953125
sam_encoder.blocks.1.norm2.weight grad: 0.00038214499363675714
sam_encoder.blocks.1.norm2.bias grad: -0.0003567979147192091
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.2809311556338798e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.943547982198652e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0011819221545010805
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00014442577958106995
sam_encoder.blocks.2.norm1.weight grad: -0.001708702533505857
sam_encoder.blocks.2.norm1.bias grad: 0.0010338134597986937
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0011955577647313476
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0002606573689263314
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0005660835886374116
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0004435853043105453
sam_encoder.blocks.2.norm2.weight grad: -0.0005901281256228685
sam_encoder.blocks.2.norm2.bias grad: -0.00026403626543469727
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0007144158589653671
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.405799210071564e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0007822068873792887
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00020752844284288585
sam_encoder.blocks.3.norm1.weight grad: -8.412222086917609e-05
sam_encoder.blocks.3.norm1.bias grad: 0.00047492922749370337
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0003404341987334192
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.20695243217051e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.0003785284934565425
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0001544936967547983
sam_encoder.blocks.3.norm2.weight grad: -0.0011355008464306593
sam_encoder.blocks.3.norm2.bias grad: 6.477365968748927e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0008445023559033871
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.0001453830918762833
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.00032990722684189677
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.129638783633709e-05
sam_encoder.blocks.4.norm1.weight grad: 0.00011351775901857764
sam_encoder.blocks.4.norm1.bias grad: 0.0008112394716590643
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.302182813058607e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.8807435228372924e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00023846082331147045
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0003543255152180791
sam_encoder.blocks.4.norm2.weight grad: 0.00021885466412641108
sam_encoder.blocks.4.norm2.bias grad: 0.00020361487986519933
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.00011551498027984053
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.069358328706585e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.000305110210319981
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.49434470385313e-05
sam_encoder.blocks.5.norm1.weight grad: -0.001032874919474125
sam_encoder.blocks.5.norm1.bias grad: 1.0701905921450816e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.0007464959053322673
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -0.00037880887975916266
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0004080540966242552
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.00013359528384171426
sam_encoder.blocks.5.norm2.weight grad: -0.00043988408287987113
sam_encoder.blocks.5.norm2.bias grad: 0.00017900204693432897
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.0003749322786461562
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.00010785652557387948
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.708386066136882e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.5638393708504736e-05
sam_encoder.blocks.6.norm1.weight grad: -0.0006979353493079543
sam_encoder.blocks.6.norm1.bias grad: -0.000617187179159373
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.000492274179123342
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -0.0002119591081282124
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00019608924048952758
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.00016020526527427137
sam_encoder.blocks.6.norm2.weight grad: 0.0009090582607313991
sam_encoder.blocks.6.norm2.bias grad: 0.0006047138595022261
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00043793878285214305
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.0001868739927886054
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.01520446757786e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.4025713325245306e-05
sam_encoder.blocks.7.norm1.weight grad: -0.0005530404159799218
sam_encoder.blocks.7.norm1.bias grad: -6.389026384567842e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -0.00041130202589556575
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -0.00022194992925506085
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0002995749528054148
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00038915080949664116
sam_encoder.blocks.7.norm2.weight grad: -4.3280811951262876e-05
sam_encoder.blocks.7.norm2.bias grad: 2.1973432012600824e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00012343790149316192
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00015571681433357298
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -0.00016271707136183977
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.462195672909729e-05
sam_encoder.blocks.8.norm1.weight grad: 7.11166940163821e-05
sam_encoder.blocks.8.norm1.bias grad: 6.686532287858427e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.0287467375746928e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.0640803237911314e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0003461148589849472
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.00036021904088556767
sam_encoder.blocks.8.norm2.weight grad: -0.00014877921785227954
sam_encoder.blocks.8.norm2.bias grad: 6.118654710007831e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00012541472096927464
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00011262715270277113
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.978680125437677e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.2306798200588673e-05
sam_encoder.blocks.9.norm1.weight grad: -0.00016015020082704723
sam_encoder.blocks.9.norm1.bias grad: -2.5107437977567315e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.00013569110888056457
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.963142080465332e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.592270412715152e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -0.00012264509859960526
sam_encoder.blocks.9.norm2.weight grad: -0.00031192199094220996
sam_encoder.blocks.9.norm2.bias grad: -6.289400334935635e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0003348443133290857
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00010626819857861847
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.233326085843146e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.3533686797018163e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0003493489639367908
sam_encoder.blocks.10.norm1.bias grad: 2.0932358893333003e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00018517093849368393
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.760011067148298e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.87244930001907e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.28085869923234e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0012221909128129482
sam_encoder.blocks.10.norm2.bias grad: -0.0005316179012879729
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0005918882670812309
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0003435396938584745
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.0001417583116563037
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.022967449505813e-06
sam_encoder.blocks.11.norm1.weight grad: -3.807673783740029e-05
sam_encoder.blocks.11.norm1.bias grad: 0.00019734480883926153
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0004899563500657678
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 0.00010091731382999569
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -6.866418698336929e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.8407942813355476e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0014398833736777306
sam_encoder.blocks.11.norm2.bias grad: -0.0002808020799420774
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.0005996796535328031
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.0003086871874984354
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.00014226711937226355
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.142023630673066e-05
sam_encoder.neck.conv1.trainable_scale grad: -1.1538737453520298e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0004063702654093504
sam_encoder.neck.conv2.trainable_scale grad: 2.2780324798077345e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0024911181535571814
mask_decoder.transformer.layers.0.norm1.weight grad: -0.005165868438780308
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00024028122425079346
mask_decoder.transformer.layers.0.norm2.weight grad: 0.14855079352855682
mask_decoder.transformer.layers.0.norm2.bias grad: 0.062103044241666794
mask_decoder.transformer.layers.0.norm3.weight grad: 0.007959921844303608
mask_decoder.transformer.layers.0.norm3.bias grad: 0.002296303864568472
mask_decoder.transformer.layers.0.norm4.weight grad: -0.005778105463832617
mask_decoder.transformer.layers.0.norm4.bias grad: -7.856721640564501e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0015587599482387304
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00016512873116880655
mask_decoder.transformer.layers.1.norm2.weight grad: 0.017057621851563454
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0015250365249812603
mask_decoder.transformer.layers.1.norm3.weight grad: -0.000946303247474134
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0015253000892698765
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0004687094478867948
mask_decoder.transformer.layers.1.norm4.bias grad: 0.007973283529281616
mask_decoder.transformer.norm_final_attn.weight grad: 0.00021470538922585547
mask_decoder.transformer.norm_final_attn.bias grad: -0.00036869762698188424
Text_Embedding_Affine.0.weight grad: 1.7965740006786746e-11
Text_Embedding_Affine.0.bias grad: -6.490154191851616e-09
Text_Embedding_Affine.2.weight grad: 8.352090574703652e-09
Text_Embedding_Affine.2.bias grad: 0.0002379093784838915

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.278389274803285e-12
Max value: 0.9996359348297119
Mean value: 0.08997229486703873

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.278389274803285e-12
Max value: 0.9996359348297119
Mean value: 0.08997229486703873

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08386564254760742

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11839839071035385

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07887792587280273

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08386564254760742

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.562442779541016
Max value: 82.55816650390625
Mean value: 60.445377349853516

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.278389274803285e-12
Max value: 0.9996359348297119
Mean value: 0.08997229486703873

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.278389274803285e-12
Max value: 0.9996359348297119
Mean value: 0.08997229486703873

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.278389274803285e-12
Max value: 0.9996359348297119
Mean value: 0.08997229486703873

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11839839071035385

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.562442779541016
Max value: 82.55816650390625
Mean value: 60.445377349853516

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.446598052978516
Max value: -60.446598052978516
Mean value: -60.446598052978516
sam_encoder.pos_embed grad: 3.125085186184151e-07
sam_encoder.blocks.0.norm1.weight grad: 0.0033603431656956673
sam_encoder.blocks.0.norm1.bias grad: 0.0017730724066495895
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.000455968314781785
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.833268369315192e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0001215146912727505
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00013671180931851268
sam_encoder.blocks.0.norm2.weight grad: -8.63545574247837e-05
sam_encoder.blocks.0.norm2.bias grad: 0.0015835929661989212
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0003777412639465183
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003528114757500589
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.0008651752723380923
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.432282755966298e-05
sam_encoder.blocks.1.norm1.weight grad: 0.0006740953540429473
sam_encoder.blocks.1.norm1.bias grad: 3.6576646380126476e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 0.00018751299649011344
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.9672728487639688e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.254790398292243e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.3440963559551165e-05
sam_encoder.blocks.1.norm2.weight grad: 0.0002171253290725872
sam_encoder.blocks.1.norm2.bias grad: 6.066451169317588e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00046646929695270956
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.615717964246869e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.410483471583575e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.441231329925358e-06
sam_encoder.blocks.2.norm1.weight grad: 0.000277404353255406
sam_encoder.blocks.2.norm1.bias grad: -0.00048068547039292753
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.00022935331799089909
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.4825354557833634e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.0886250644689426e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.263852729811333e-05
sam_encoder.blocks.2.norm2.weight grad: -0.0005043229321017861
sam_encoder.blocks.2.norm2.bias grad: -0.0012306843418627977
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.720947567373514e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.017421739874408e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00011608819477260113
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00012914012768305838
sam_encoder.blocks.3.norm1.weight grad: -0.0009275664924643934
sam_encoder.blocks.3.norm1.bias grad: -0.00044407875975593925
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0002847091236617416
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.93811452947557e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.5243483833037317e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00012259598588570952
sam_encoder.blocks.3.norm2.weight grad: 0.0013324407627806067
sam_encoder.blocks.3.norm2.bias grad: 0.0006778572569601238
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0008205770282074809
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00024382401898037642
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.875482747796923e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.825270636705682e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0003465971094556153
sam_encoder.blocks.4.norm1.bias grad: -0.0006311027682386339
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00014836576883681118
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.275471580214798e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00016725482419133186
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -7.923939119791612e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0005680467002093792
sam_encoder.blocks.4.norm2.bias grad: 0.00012168939429102466
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0004022631037514657
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00020998489344492555
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.167620484920917e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.40552568458952e-05
sam_encoder.blocks.5.norm1.weight grad: 0.00023146640160121024
sam_encoder.blocks.5.norm1.bias grad: -0.000914699281565845
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00042737380135804415
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00025893235579133034
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.405427534948103e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0001466698304284364
sam_encoder.blocks.5.norm2.weight grad: 0.00048681008047424257
sam_encoder.blocks.5.norm2.bias grad: 0.0004073705931659788
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00014190003275871277
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 7.865540101192892e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00035953414044342935
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.4580476242117584e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00041522117680869997
sam_encoder.blocks.6.norm1.bias grad: -9.498174040345475e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00038046768167987466
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00023239942674990743
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00018483992607798427
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.00011302632628940046
sam_encoder.blocks.6.norm2.weight grad: -0.00022864516358822584
sam_encoder.blocks.6.norm2.bias grad: 0.00022636691574007273
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.967709396121791e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.593007568269968e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00015112229448277503
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.279207733925432e-05
sam_encoder.blocks.7.norm1.weight grad: 0.000482968520373106
sam_encoder.blocks.7.norm1.bias grad: 6.225815013749525e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00037602681550197303
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00021972096874378622
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.00015120251919142902
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00016625432181172073
sam_encoder.blocks.7.norm2.weight grad: -9.225267422152683e-05
sam_encoder.blocks.7.norm2.bias grad: 1.202429643853975e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00010834889690158889
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.808765854453668e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.7303511160425842e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.767833186429925e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00040535529842600226
sam_encoder.blocks.8.norm1.bias grad: 9.915136615745723e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003484506160020828
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.0001879097253549844
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.0447620045160875e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.663560947752558e-06
sam_encoder.blocks.8.norm2.weight grad: -0.00015045443433336914
sam_encoder.blocks.8.norm2.bias grad: -6.731515168212354e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.3988311265129596e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.7512861783616245e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.449340435210615e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.245131690870039e-05
sam_encoder.blocks.9.norm1.weight grad: -7.33861088519916e-05
sam_encoder.blocks.9.norm1.bias grad: -2.2634892957285047e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.473670120816678e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.7502253690036014e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.679948299075477e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.5442474250448868e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00011216588609386235
sam_encoder.blocks.9.norm2.bias grad: 4.4902495574206114e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.6483415947732283e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.02181927813217e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00012827137834392488
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.116105214459822e-05
sam_encoder.blocks.10.norm1.weight grad: -3.3356627682223916e-05
sam_encoder.blocks.10.norm1.bias grad: 5.5962402257137e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.3499177233316e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.218456888338551e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6489297195221297e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.720039967447519e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00011735298903658986
sam_encoder.blocks.10.norm2.bias grad: 2.6785910449689254e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00025391922099515796
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.509538510115817e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.0446319518378e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.0643177776946686e-05
sam_encoder.blocks.11.norm1.weight grad: 5.747110117226839e-05
sam_encoder.blocks.11.norm1.bias grad: 0.0002308495168108493
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0001062562150764279
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.3839503380004317e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.2101783542893827e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.8218367990339175e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0003536682343110442
sam_encoder.blocks.11.norm2.bias grad: -0.00012250887812115252
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.8735288399038836e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.4346805477980524e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.241015317849815e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0506080798222683e-05
sam_encoder.neck.conv1.trainable_scale grad: -5.5365380831062794e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0004368596419226378
sam_encoder.neck.conv2.trainable_scale grad: -7.591862231492996e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0006518509471789002
mask_decoder.transformer.layers.0.norm1.weight grad: -0.004193003289401531
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00010746275074779987
mask_decoder.transformer.layers.0.norm2.weight grad: -0.08098353445529938
mask_decoder.transformer.layers.0.norm2.bias grad: -0.015618603676557541
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0013495091116055846
mask_decoder.transformer.layers.0.norm3.bias grad: -0.004003358073532581
mask_decoder.transformer.layers.0.norm4.weight grad: 0.005667922552675009
mask_decoder.transformer.layers.0.norm4.bias grad: 9.365659207105637e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0020383168011903763
mask_decoder.transformer.layers.1.norm1.bias grad: -0.000174430082552135
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0050626941956579685
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004423273727297783
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0032625491730868816
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0013587726280093193
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0024086677003651857
mask_decoder.transformer.layers.1.norm4.bias grad: -0.008263491094112396
mask_decoder.transformer.norm_final_attn.weight grad: 7.611494220327586e-05
mask_decoder.transformer.norm_final_attn.bias grad: 0.0010007241507992148
Text_Embedding_Affine.0.weight grad: 1.3569646795108525e-10
Text_Embedding_Affine.0.bias grad: 1.8742866814136505e-08
Text_Embedding_Affine.2.weight grad: 1.1999841120768906e-09
Text_Embedding_Affine.2.bias grad: -0.0016427126247435808

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.9752682128837407e-11
Max value: 0.9926584362983704
Mean value: 0.07290102541446686

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9752682128837407e-11
Max value: 0.9926584362983704
Mean value: 0.07290102541446686

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07314300537109375

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.662967681884766
Max value: -1.1920928244535389e-07
Mean value: -0.10799749195575714

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.061591148376464844

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07314300537109375

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 32.85466384887695
Max value: 62.930179595947266
Mean value: 52.357025146484375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.9752682128837407e-11
Max value: 0.9926584362983704
Mean value: 0.07290102541446686

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9752682128837407e-11
Max value: 0.9926584362983704
Mean value: 0.07290102541446686

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9752682128837407e-11
Max value: 0.9926584362983704
Mean value: 0.07290102541446686

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.662967681884766
Max value: -1.1920928244535389e-07
Mean value: -0.10799749195575714

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 32.85466384887695
Max value: 62.930179595947266
Mean value: 52.357025146484375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.35810852050781
Max value: -52.35810852050781
Mean value: -52.35810852050781
sam_encoder.pos_embed grad: 4.478154096432263e-07
sam_encoder.blocks.0.norm1.weight grad: 0.00336892856284976
sam_encoder.blocks.0.norm1.bias grad: 0.0003359872498549521
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.0003337119414936751
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.8304659281275235e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.4786971809808165e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.990536111406982e-05
sam_encoder.blocks.0.norm2.weight grad: 0.0006357457023113966
sam_encoder.blocks.0.norm2.bias grad: -0.0015283571556210518
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000381613674107939
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.0002315902238478884
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0007297237170860171
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0005988511256873608
sam_encoder.blocks.1.norm1.weight grad: 0.0003505174536257982
sam_encoder.blocks.1.norm1.bias grad: -0.0004747314960695803
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00020684945047833025
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00011711166007444263
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00024148150987457484
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.024672908708453e-05
sam_encoder.blocks.1.norm2.weight grad: -0.0005583053571172059
sam_encoder.blocks.1.norm2.bias grad: -0.00017823911912273616
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0003948592930100858
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.5372671340592206e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.00039929774357005954
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.136191470635822e-06
sam_encoder.blocks.2.norm1.weight grad: -0.001010208623483777
sam_encoder.blocks.2.norm1.bias grad: 0.0005173393874429166
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.0004901906941086054
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00010877934983000159
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.964568456169218e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.1599142201012e-05
sam_encoder.blocks.2.norm2.weight grad: -9.833505464484915e-05
sam_encoder.blocks.2.norm2.bias grad: -0.00025014541461132467
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.591983062913641e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 8.142700971802697e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0005916476948186755
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00014340609777718782
sam_encoder.blocks.3.norm1.weight grad: -0.0005568010965362191
sam_encoder.blocks.3.norm1.bias grad: 0.00036705349339172244
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0004856299492530525
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.0001936466433107853
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00025609941803850234
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00026909593725576997
sam_encoder.blocks.3.norm2.weight grad: -0.0007517989724874496
sam_encoder.blocks.3.norm2.bias grad: -0.0002682635677047074
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0007685704040341079
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00025193841429427266
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0004761800810229033
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.0001471696887165308
sam_encoder.blocks.4.norm1.weight grad: -0.0011206355411559343
sam_encoder.blocks.4.norm1.bias grad: -4.1637918911874294e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0006648540729656816
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00024240893253590912
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.000343150895787403
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0002992961963173002
sam_encoder.blocks.4.norm2.weight grad: 0.0010394998826086521
sam_encoder.blocks.4.norm2.bias grad: 0.0006317346123978496
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 0.0005875470233149827
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 0.00027186726219952106
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.070148083381355e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.2345648176269606e-05
sam_encoder.blocks.5.norm1.weight grad: -0.0004972319002263248
sam_encoder.blocks.5.norm1.bias grad: -0.00027121175662614405
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -0.00013043236685916781
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2567441444844007e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.0003556832089088857
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.272080205846578e-05
sam_encoder.blocks.5.norm2.weight grad: 0.0006060061859898269
sam_encoder.blocks.5.norm2.bias grad: 0.00048762798542156816
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.00018160289619117975
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 8.790162246441469e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.267470987746492e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.7362102527113166e-06
sam_encoder.blocks.6.norm1.weight grad: -0.00036367628490552306
sam_encoder.blocks.6.norm1.bias grad: -0.00038290047086775303
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -0.00014102105342317373
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4732788258697838e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -0.00011640146840363741
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -0.0001009896514005959
sam_encoder.blocks.6.norm2.weight grad: 0.0005364252720028162
sam_encoder.blocks.6.norm2.bias grad: 0.00031917233718559146
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.0002655444841366261
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.58417445467785e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.561710061854683e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.442575638880953e-05
sam_encoder.blocks.7.norm1.weight grad: -2.413208676443901e-05
sam_encoder.blocks.7.norm1.bias grad: -2.5278201064793393e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.125998283503577e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.5166437959996983e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.00010504177043912932
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.00011937793897232041
sam_encoder.blocks.7.norm2.weight grad: -0.00011212470417376608
sam_encoder.blocks.7.norm2.bias grad: -5.258986493572593e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00025670387549325824
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00016414825222454965
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.168554369243793e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.8905414587352425e-05
sam_encoder.blocks.8.norm1.weight grad: 0.0003560141194611788
sam_encoder.blocks.8.norm1.bias grad: 0.00013381072494667023
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003386868047527969
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00019061370403505862
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0002385303087066859
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0002754816669039428
sam_encoder.blocks.8.norm2.weight grad: -0.0002477129455655813
sam_encoder.blocks.8.norm2.bias grad: 4.1117957152891904e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.00038847135147079825
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00021506866323761642
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.4370346586219966e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.6304489438189194e-05
sam_encoder.blocks.9.norm1.weight grad: -9.816093370318413e-05
sam_encoder.blocks.9.norm1.bias grad: -4.371213435661048e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.271072536241263e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.974675150355324e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.8566242690430954e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.951142520643771e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0003827416803687811
sam_encoder.blocks.9.norm2.bias grad: -7.195601210696623e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.00034526136005297303
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00018896762048825622
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.636408554390073e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.0144731024629436e-05
sam_encoder.blocks.10.norm1.weight grad: -0.000289801973849535
sam_encoder.blocks.10.norm1.bias grad: 1.1836629710160196e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.00014567332982551306
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.270215817494318e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.199885294539854e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.2196941901929677e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0009709373116493225
sam_encoder.blocks.10.norm2.bias grad: -0.0002458474482409656
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0004611798212863505
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00030141096794977784
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.746575233293697e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.009674219356384e-05
sam_encoder.blocks.11.norm1.weight grad: -0.0005391419399529696
sam_encoder.blocks.11.norm1.bias grad: 0.0001505119726061821
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00023442719248123467
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.538354212651029e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.331674815854058e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.389714381934027e-06
sam_encoder.blocks.11.norm2.weight grad: -0.0006401288555935025
sam_encoder.blocks.11.norm2.bias grad: -0.00012718135258182883
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00025913023273460567
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00012769944441970438
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.3689344743615948e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.3321910046215635e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.860099241137505e-06
sam_encoder.neck.conv1.trainable_shift grad: 0.0003463261527940631
sam_encoder.neck.conv2.trainable_scale grad: 6.355467485263944e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.001205675769597292
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0013538382481783628
mask_decoder.transformer.layers.0.norm1.bias grad: -6.586313247680664e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.12098313868045807
mask_decoder.transformer.layers.0.norm2.bias grad: 0.045317143201828
mask_decoder.transformer.layers.0.norm3.weight grad: 0.006017995532602072
mask_decoder.transformer.layers.0.norm3.bias grad: 0.001273381058126688
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0027392394840717316
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00025777146220207214
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0022396864369511604
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00043989159166812897
mask_decoder.transformer.layers.1.norm2.weight grad: 0.02076222002506256
mask_decoder.transformer.layers.1.norm2.bias grad: 0.004841736517846584
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0009028013446368277
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0027768262661993504
mask_decoder.transformer.layers.1.norm4.weight grad: 0.003063581883907318
mask_decoder.transformer.layers.1.norm4.bias grad: 0.010999167338013649
mask_decoder.transformer.norm_final_attn.weight grad: 1.8703751266002655e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.0004879167827311903
Text_Embedding_Affine.0.weight grad: 3.9515291039293743e-10
Text_Embedding_Affine.0.bias grad: -1.7826096154749393e-09
Text_Embedding_Affine.2.weight grad: 9.762229913334863e-10
Text_Embedding_Affine.2.bias grad: -0.0011873571202158928
Epoch 37 finished with average loss: -56.2131
Epoch 38/39
----------
Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s, loss=-47.8]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-47.8]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-51.5]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-51.5]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-57.3]Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.17it/s, loss=-57.3]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.3106595510055143e-11
Max value: 0.9985460042953491
Mean value: 0.0764499083161354

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.3106595510055143e-11
Max value: 0.9985460042953491
Mean value: 0.0764499083161354

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07886123657226562

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.704459190368652
Max value: -1.1920928244535389e-07
Mean value: -0.12592414021492004

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06212663650512695

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07886123657226562

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 19.8550968170166
Max value: 70.21043395996094
Mean value: 47.794921875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.3106595510055143e-11
Max value: 0.9985460042953491
Mean value: 0.0764499083161354

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.3106595510055143e-11
Max value: 0.9985460042953491
Mean value: 0.0764499083161354

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.3106595510055143e-11
Max value: 0.9985460042953491
Mean value: 0.0764499083161354

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.704459190368652
Max value: -1.1920928244535389e-07
Mean value: -0.12592414021492004

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 19.8550968170166
Max value: 70.21043395996094
Mean value: 47.794921875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -47.796173095703125
Max value: -47.796173095703125
Mean value: -47.796173095703125
sam_encoder.pos_embed grad: 7.350271147288368e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0006548860110342503
sam_encoder.blocks.0.norm1.bias grad: -0.002197656547650695
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.7729500541463494e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.542563404655084e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.00011949904001085088
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00022499446640722454
sam_encoder.blocks.0.norm2.weight grad: 0.0007299920544028282
sam_encoder.blocks.0.norm2.bias grad: -0.0015751731116324663
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000690639833919704
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.00019901397172361612
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.000413467496400699
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00012127463560318574
sam_encoder.blocks.1.norm1.weight grad: -4.642766361939721e-05
sam_encoder.blocks.1.norm1.bias grad: -0.0003089257515966892
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.149571269517764e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.121147114550695e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00011483245179988444
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.131375605240464e-05
sam_encoder.blocks.1.norm2.weight grad: -0.001362530281767249
sam_encoder.blocks.1.norm2.bias grad: 0.00010465367085998878
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00047704647295176983
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.498254464939237e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0009689537109807134
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.000204377225600183
sam_encoder.blocks.2.norm1.weight grad: 0.001135603990405798
sam_encoder.blocks.2.norm1.bias grad: -0.0007936293259263039
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.000500817084684968
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.41075782570988e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.342069587437436e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 0.00011703198833856732
sam_encoder.blocks.2.norm2.weight grad: -9.524947381578386e-05
sam_encoder.blocks.2.norm2.bias grad: 0.0008309909608215094
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.460342900827527e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.280312062590383e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.00034786909236572683
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.931321356911212e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0006533859996125102
sam_encoder.blocks.3.norm1.bias grad: -0.000511504418682307
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.00013291067443788052
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.961234531539958e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00010606838623061776
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00018317349895369262
sam_encoder.blocks.3.norm2.weight grad: -0.0008043954148888588
sam_encoder.blocks.3.norm2.bias grad: -0.00044816764420829713
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0004206851008348167
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00019298917322885245
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.00021466919861268252
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.818629430606961e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0006985312211327255
sam_encoder.blocks.4.norm1.bias grad: -0.0006933402037248015
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0003061813476961106
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.237931716488674e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.170257645659149e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.8677284464938566e-05
sam_encoder.blocks.4.norm2.weight grad: -0.0013803777983412147
sam_encoder.blocks.4.norm2.bias grad: 0.0001955243496922776
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0006881699664518237
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00014917241060175002
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.588205749518238e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.3100965588819236e-05
sam_encoder.blocks.5.norm1.weight grad: -1.4202762031345628e-05
sam_encoder.blocks.5.norm1.bias grad: 6.47753695375286e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.875361239304766e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.182141078170389e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.3698343536816537e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.806910535786301e-05
sam_encoder.blocks.5.norm2.weight grad: -0.00042343675158917904
sam_encoder.blocks.5.norm2.bias grad: 0.00014196224219631404
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -0.00044441811041906476
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -0.0001274964597541839
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001135646816692315
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.906004920077976e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00040374352829530835
sam_encoder.blocks.6.norm1.bias grad: -0.00011669487867038697
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0003711169119924307
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.00017913419287651777
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.673627987969667e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.9297189282951877e-05
sam_encoder.blocks.6.norm2.weight grad: -0.000350161426467821
sam_encoder.blocks.6.norm2.bias grad: 4.315988553571515e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0001853669818956405
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.913935067132115e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.890841177664697e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0075887732673436e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00023426958068739623
sam_encoder.blocks.7.norm1.bias grad: -4.8416048230137676e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00017055109492503107
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.618945917580277e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.118946137372404e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.708470704732463e-05
sam_encoder.blocks.7.norm2.weight grad: -0.00018876348622143269
sam_encoder.blocks.7.norm2.bias grad: 0.0001452851138310507
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00020775044686160982
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.968696056399494e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 0.00010490357817616314
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.6676472265971825e-05
sam_encoder.blocks.8.norm1.weight grad: 0.000562867266125977
sam_encoder.blocks.8.norm1.bias grad: 4.543019167613238e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0005560152931138873
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00023746029182802886
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.6161033019889146e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.4154694326862227e-05
sam_encoder.blocks.8.norm2.weight grad: 3.083841147599742e-05
sam_encoder.blocks.8.norm2.bias grad: 2.0188626876915805e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.086952635087073e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.314423520350829e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.00021354819182306528
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.00013319561548996717
sam_encoder.blocks.9.norm1.weight grad: 0.00010178511001868173
sam_encoder.blocks.9.norm1.bias grad: -2.6335022994317114e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.913741577183828e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.2457361435735947e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.5327890398330055e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.801332008559257e-05
sam_encoder.blocks.9.norm2.weight grad: 8.53760284371674e-05
sam_encoder.blocks.9.norm2.bias grad: 0.00014178871060721576
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.7541518395300955e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.943018575431779e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00014894385822117329
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.695870590396225e-05
sam_encoder.blocks.10.norm1.weight grad: -0.00010028549877461046
sam_encoder.blocks.10.norm1.bias grad: -4.103375249542296e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.06252251600381e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.7743757780408487e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.028903640573844e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.374248187057674e-06
sam_encoder.blocks.10.norm2.weight grad: -1.1520484804350417e-05
sam_encoder.blocks.10.norm2.bias grad: 0.00010755326366052032
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.00016235304065048695
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.692809332278557e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.967043686425313e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.3300450518727303e-07
sam_encoder.blocks.11.norm1.weight grad: -0.0005519086262211204
sam_encoder.blocks.11.norm1.bias grad: 3.649260906968266e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -8.990507194539532e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.358610279567074e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -6.116712029324844e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.527588756289333e-05
sam_encoder.blocks.11.norm2.weight grad: -1.8398070096736774e-05
sam_encoder.blocks.11.norm2.bias grad: -0.00013225022121332586
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.6330377295380458e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.204255209420808e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00011705351062119007
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.758244201890193e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.6549405194818974e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.00034565606620162725
sam_encoder.neck.conv2.trainable_scale grad: 2.1353596821427345e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.0035147422458976507
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00779733108356595
mask_decoder.transformer.layers.0.norm1.bias grad: 5.577504634857178e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.20186376571655273
mask_decoder.transformer.layers.0.norm2.bias grad: -0.08202506601810455
mask_decoder.transformer.layers.0.norm3.weight grad: 0.008035166189074516
mask_decoder.transformer.layers.0.norm3.bias grad: -0.001605411060154438
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0007349250954575837
mask_decoder.transformer.layers.0.norm4.bias grad: -0.00026401830837130547
mask_decoder.transformer.layers.1.norm1.weight grad: 0.000699264754075557
mask_decoder.transformer.layers.1.norm1.bias grad: 0.0002461361000314355
mask_decoder.transformer.layers.1.norm2.weight grad: 0.008397284895181656
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0024227951653301716
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0005116224056109786
mask_decoder.transformer.layers.1.norm3.bias grad: -0.00017662550089880824
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0008440985111519694
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0013438441092148423
mask_decoder.transformer.norm_final_attn.weight grad: -0.00025323827867396176
mask_decoder.transformer.norm_final_attn.bias grad: -3.8223610317800194e-05
Text_Embedding_Affine.0.weight grad: 2.6422120047442377e-10
Text_Embedding_Affine.0.bias grad: 8.825736586004496e-09
Text_Embedding_Affine.2.weight grad: -6.436033483936399e-09
Text_Embedding_Affine.2.bias grad: -0.0020946317818015814

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.055290082887012e-15
Max value: 0.9997780919075012
Mean value: 0.09101143479347229

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.055290082887012e-15
Max value: 0.9997780919075012
Mean value: 0.09101143479347229

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08635187149047852

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13152851164340973

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0824136734008789

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08635187149047852

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 23.310178756713867
Max value: 69.66373443603516
Mean value: 55.2786979675293

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.055290082887012e-15
Max value: 0.9997780919075012
Mean value: 0.09101143479347229

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.055290082887012e-15
Max value: 0.9997780919075012
Mean value: 0.09101143479347229

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.055290082887012e-15
Max value: 0.9997780919075012
Mean value: 0.09101143479347229

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13152851164340973

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 23.310178756713867
Max value: 69.66373443603516
Mean value: 55.2786979675293

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.27989959716797
Max value: -55.27989959716797
Mean value: -55.27989959716797
sam_encoder.pos_embed grad: 3.529773664467939e-07
sam_encoder.blocks.0.norm1.weight grad: 5.5350479669868946e-05
sam_encoder.blocks.0.norm1.bias grad: 0.001411797828041017
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.000182328192749992
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.127328429603949e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0004975091433152556
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.017667818814516e-05
sam_encoder.blocks.0.norm2.weight grad: 0.002180239651352167
sam_encoder.blocks.0.norm2.bias grad: -0.002737778704613447
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0013960960786789656
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00031490912078879774
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.0011998885311186314
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0005641027237288654
sam_encoder.blocks.1.norm1.weight grad: 0.00046157752512954175
sam_encoder.blocks.1.norm1.bias grad: 0.0002782664087135345
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.00032145457225851715
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.0001367138174828142
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00043400769936852157
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002442366676405072
sam_encoder.blocks.1.norm2.weight grad: 0.00042254477739334106
sam_encoder.blocks.1.norm2.bias grad: 0.00015559363237116486
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00021844955335836858
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0694042430259287e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0009046411141753197
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -0.00011159435962326825
sam_encoder.blocks.2.norm1.weight grad: -0.0008046420989558101
sam_encoder.blocks.2.norm1.bias grad: 0.00023837042681407183
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.000568719522561878
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0001805542124202475
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00043663891847245395
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0003073191037401557
sam_encoder.blocks.2.norm2.weight grad: -0.0015056378906592727
sam_encoder.blocks.2.norm2.bias grad: -0.0010036996100097895
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.001077254069969058
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.0001941305526997894
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0006395116215571761
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00019602570682764053
sam_encoder.blocks.3.norm1.weight grad: -0.0004961781669408083
sam_encoder.blocks.3.norm1.bias grad: -8.825880649965256e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.0003040492010768503
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.879535794723779e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00019485174561850727
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.0001575890346430242
sam_encoder.blocks.3.norm2.weight grad: -0.00028706027660518885
sam_encoder.blocks.3.norm2.bias grad: -0.0005122538423165679
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0002458740200381726
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.361555385112297e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0002278380998177454
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00015815110236871988
sam_encoder.blocks.4.norm1.weight grad: 0.00029416457982733846
sam_encoder.blocks.4.norm1.bias grad: -0.00047021309728734195
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.00013597232464235276
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.866803126584273e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00011608748900471255
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -7.687525794608518e-05
sam_encoder.blocks.4.norm2.weight grad: -0.00012448694906197488
sam_encoder.blocks.4.norm2.bias grad: -0.00015327973233070225
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.00021580036263912916
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.397061952156946e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.00012951645476277918
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.497654900769703e-06
sam_encoder.blocks.5.norm1.weight grad: 0.00043969700345769525
sam_encoder.blocks.5.norm1.bias grad: -0.000647692009806633
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.00045707449316978455
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0002618669532239437
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00012482531019486487
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.220949100883445e-06
sam_encoder.blocks.5.norm2.weight grad: 0.0004032891592942178
sam_encoder.blocks.5.norm2.bias grad: 0.00042788084829226136
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 7.677705434616655e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.94414996157866e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.0001575183414388448
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.855319952592254e-06
sam_encoder.blocks.6.norm1.weight grad: -3.3476302633062005e-05
sam_encoder.blocks.6.norm1.bias grad: -0.00022298924159258604
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.789541607256979e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.6816016593948e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.24406246363651e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.652050377742853e-05
sam_encoder.blocks.6.norm2.weight grad: -9.40383761189878e-05
sam_encoder.blocks.6.norm2.bias grad: 6.281504465732723e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0002158076094929129
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0001336603454547003
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.46175428503193e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.452607986924704e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00038969225715845823
sam_encoder.blocks.7.norm1.bias grad: 3.8782795854785945e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00023425642575602978
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.699944788124412e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.510415940079838e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.786700057797134e-06
sam_encoder.blocks.7.norm2.weight grad: -0.00010172875772695988
sam_encoder.blocks.7.norm2.bias grad: -0.00011910209286725149
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00016385875642299652
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -0.00012441076978575438
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.200602415949106e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.511851203569677e-06
sam_encoder.blocks.8.norm1.weight grad: 0.0002876264916267246
sam_encoder.blocks.8.norm1.bias grad: 3.024867964995792e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.0003791887720581144
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00015515316044911742
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.00020201969891786575
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.848514698911458e-05
sam_encoder.blocks.8.norm2.weight grad: -0.00020306158694438636
sam_encoder.blocks.8.norm2.bias grad: 1.8539380107540637e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000280102773103863
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00011925925355171785
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.609493670519441e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.63116986490786e-06
sam_encoder.blocks.9.norm1.weight grad: 0.00010791521344799548
sam_encoder.blocks.9.norm1.bias grad: 4.67062636744231e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.405131716746837e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.764225791906938e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.9876613047672436e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.2886652004672214e-05
sam_encoder.blocks.9.norm2.weight grad: -0.0003870086220558733
sam_encoder.blocks.9.norm2.bias grad: 1.4033217667019926e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0004022769280709326
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.00020191998919472098
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.283183756750077e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.0755034963949583e-05
sam_encoder.blocks.10.norm1.weight grad: -6.83355174260214e-05
sam_encoder.blocks.10.norm1.bias grad: 6.778258102713153e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.6729073801543564e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1332640497130342e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.602668483741581e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.432649802765809e-05
sam_encoder.blocks.10.norm2.weight grad: -0.0006252756575122476
sam_encoder.blocks.10.norm2.bias grad: -0.00010332051897421479
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0003880982694681734
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.0001908654667204246
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.896881728200242e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.3593960829894058e-05
sam_encoder.blocks.11.norm1.weight grad: 0.00010295420361217111
sam_encoder.blocks.11.norm1.bias grad: 0.00023444990802090615
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.0002077026292681694
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.3371179092209786e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.876548669903059e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.6268738767830655e-05
sam_encoder.blocks.11.norm2.weight grad: -0.0006920426385477185
sam_encoder.blocks.11.norm2.bias grad: -4.756914677273016e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.00029388110851868987
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00011874349729623646
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.996482599992305e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.1928203902207315e-05
sam_encoder.neck.conv1.trainable_scale grad: -1.1897413060069084e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0011845596600323915
sam_encoder.neck.conv2.trainable_scale grad: 4.808494122698903e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.00122289196588099
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0030615278519690037
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00019008945673704147
mask_decoder.transformer.layers.0.norm2.weight grad: 0.21692048013210297
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0357721708714962
mask_decoder.transformer.layers.0.norm3.weight grad: -0.001133486395701766
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00037748715840280056
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0013880395563319325
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00037781684659421444
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0015075679402798414
mask_decoder.transformer.layers.1.norm1.bias grad: -8.258619345724583e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.007887998595833778
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0030437626410275698
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0020606196485459805
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0009052823297679424
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0024783057160675526
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0038201366551220417
mask_decoder.transformer.norm_final_attn.weight grad: -7.028378604445606e-05
mask_decoder.transformer.norm_final_attn.bias grad: -0.00035190884955227375
Text_Embedding_Affine.0.weight grad: 1.03601882628368e-09
Text_Embedding_Affine.0.bias grad: 3.0486262403428555e-08
Text_Embedding_Affine.2.weight grad: -6.142419906041141e-12
Text_Embedding_Affine.2.bias grad: -0.0012094477424398065

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.051444430468564e-09
Max value: 0.995974600315094
Mean value: 0.0858507826924324

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.051444430468564e-09
Max value: 0.995974600315094
Mean value: 0.0858507826924324

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08765506744384766

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.958375930786133
Max value: -1.1920928244535389e-07
Mean value: -0.09704937785863876

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07898521423339844

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08765506744384766

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 53.388084411621094
Max value: 84.4967041015625
Mean value: 68.90181732177734

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.051444430468564e-09
Max value: 0.995974600315094
Mean value: 0.0858507826924324

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.051444430468564e-09
Max value: 0.995974600315094
Mean value: 0.0858507826924324

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.051444430468564e-09
Max value: 0.995974600315094
Mean value: 0.0858507826924324

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.958375930786133
Max value: -1.1920928244535389e-07
Mean value: -0.09704937785863876

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 53.388084411621094
Max value: 84.4967041015625
Mean value: 68.90181732177734

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.90292358398438
Max value: -68.90292358398438
Mean value: -68.90292358398438
sam_encoder.pos_embed grad: -5.484556453438927e-08
sam_encoder.blocks.0.norm1.weight grad: -0.0020924159325659275
sam_encoder.blocks.0.norm1.bias grad: 0.0014223188627511263
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00012864824384450912
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.375766391400248e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 0.0003538518794812262
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.2663783965981565e-05
sam_encoder.blocks.0.norm2.weight grad: 0.004950598813593388
sam_encoder.blocks.0.norm2.bias grad: -0.0011566075263544917
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0018117971485480666
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 0.00037783707375638187
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.581450674682856e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.00042382231913506985
sam_encoder.blocks.1.norm1.weight grad: 0.00039309373823925853
sam_encoder.blocks.1.norm1.bias grad: 0.00040184042882174253
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0001948622229974717
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.699917553807609e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.00024376795045100152
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.00010028938413597643
sam_encoder.blocks.1.norm2.weight grad: -0.00024161857436411083
sam_encoder.blocks.1.norm2.bias grad: -0.0001789407542673871
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.00018164614448323846
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.898571569356136e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.632219057995826e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.385774809634313e-05
sam_encoder.blocks.2.norm1.weight grad: -0.0009474739781580865
sam_encoder.blocks.2.norm1.bias grad: -0.00018705474212765694
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.000629307993222028
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.00012244927347637713
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.00027493597008287907
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.00027524432516656816
sam_encoder.blocks.2.norm2.weight grad: 0.0002975451061502099
sam_encoder.blocks.2.norm2.bias grad: -0.0002994287060573697
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00010540714720264077
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.3098581803205889e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0001242640137206763
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 4.525587064563297e-05
sam_encoder.blocks.3.norm1.weight grad: -0.00038773659616708755
sam_encoder.blocks.3.norm1.bias grad: -0.00021415080118458718
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.170346513390541e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.2620213207555935e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.1777834263048135e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.555670213652775e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0006289123557507992
sam_encoder.blocks.3.norm2.bias grad: 0.0010294675594195724
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0003643943928182125
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00011851396266138181
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.487476639449596e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.443322051083669e-05
sam_encoder.blocks.4.norm1.weight grad: -0.00047085521509870887
sam_encoder.blocks.4.norm1.bias grad: -8.06290190666914e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -0.0005083595169708133
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -0.00010988069698214531
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00020070900791324675
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.0001322585012530908
sam_encoder.blocks.4.norm2.weight grad: 0.0003512208932079375
sam_encoder.blocks.4.norm2.bias grad: 0.00010598920925986022
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.00012669844727497548
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.00010176158684771508
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.776678441790864e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.989336932543665e-05
sam_encoder.blocks.5.norm1.weight grad: -0.00021572524565272033
sam_encoder.blocks.5.norm1.bias grad: -0.00017770877457223833
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.685134864412248e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.6155633754096925e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -0.00024278537603095174
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -0.0003366178716532886
sam_encoder.blocks.5.norm2.weight grad: 0.0004350172821432352
sam_encoder.blocks.5.norm2.bias grad: -0.0002723165089264512
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.17648576432839e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.5138964196667075e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00010599898814689368
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.520179446553811e-06
sam_encoder.blocks.6.norm1.weight grad: 7.74810032453388e-05
sam_encoder.blocks.6.norm1.bias grad: -0.00013013572606723756
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00011244406778132543
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.018062701215968e-05
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.1832647572873611e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0910410310316365e-05
sam_encoder.blocks.6.norm2.weight grad: 0.0006133313290774822
sam_encoder.blocks.6.norm2.bias grad: 9.342849807580933e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 0.00028650404419749975
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 0.00011777082545449957
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 0.00010701309656724334
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.092630428611301e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00019309899653308094
sam_encoder.blocks.7.norm1.bias grad: 9.016234253067523e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00017863254470285028
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.64991717308294e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.974501204444095e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.98980875313282e-06
sam_encoder.blocks.7.norm2.weight grad: 0.0003425867180339992
sam_encoder.blocks.7.norm2.bias grad: 3.019238283741288e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.8764161723083816e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.398344804532826e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2810941370844375e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.6636769689503126e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00048478064127266407
sam_encoder.blocks.8.norm1.bias grad: 0.000160475421580486
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 0.00041558314114809036
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 0.00016838731244206429
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.012308585923165e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -0.0001287680643144995
sam_encoder.blocks.8.norm2.weight grad: -4.384181920613628e-06
sam_encoder.blocks.8.norm2.bias grad: -6.87813080730848e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.233629341702908e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -8.394428004976362e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.17227628431283e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.572203811723739e-05
sam_encoder.blocks.9.norm1.weight grad: -1.9360091755515896e-05
sam_encoder.blocks.9.norm1.bias grad: 5.019047239329666e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.468960090278415e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.964528514188714e-05
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.0091491276398301e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.106552948243916e-05
sam_encoder.blocks.9.norm2.weight grad: 0.00018617445311974734
sam_encoder.blocks.9.norm2.bias grad: -5.8696601627161726e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.4467581170029007e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.9210645152488723e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.251411105040461e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.359601760166697e-05
sam_encoder.blocks.10.norm1.weight grad: 3.545803701854311e-05
sam_encoder.blocks.10.norm1.bias grad: 3.420392022235319e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.139366789488122e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.142370744375512e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.708009510068223e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.10868669860065e-05
sam_encoder.blocks.10.norm2.weight grad: -0.00013978226343169808
sam_encoder.blocks.10.norm2.bias grad: -0.00024759932421147823
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.97353428020142e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00012695920304395258
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -0.00017288564413320273
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.141889414517209e-05
sam_encoder.blocks.11.norm1.weight grad: 6.490683881565928e-05
sam_encoder.blocks.11.norm1.bias grad: 1.9692617570399307e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 0.00011449038720456883
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.6471714591025375e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.0894731278531253e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.4384353309869766e-06
sam_encoder.blocks.11.norm2.weight grad: -0.0004579123924486339
sam_encoder.blocks.11.norm2.bias grad: -0.00022667714802082628
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.2699404982849956e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00011756875028368086
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0001526388805359602
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.729735883302055e-05
sam_encoder.neck.conv1.trainable_scale grad: -1.940201036632061e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0004447565879672766
sam_encoder.neck.conv2.trainable_scale grad: -3.4109922125935555e-05
sam_encoder.neck.conv2.trainable_shift grad: 0.0026165919844061136
mask_decoder.transformer.layers.0.norm1.weight grad: -0.007402168586850166
mask_decoder.transformer.layers.0.norm1.bias grad: 6.506312638521194e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.4238051176071167
mask_decoder.transformer.layers.0.norm2.bias grad: 0.003522997722029686
mask_decoder.transformer.layers.0.norm3.weight grad: -0.004840219393372536
mask_decoder.transformer.layers.0.norm3.bias grad: 0.003913088236004114
mask_decoder.transformer.layers.0.norm4.weight grad: 0.002075513359159231
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0008242716430686414
mask_decoder.transformer.layers.1.norm1.weight grad: 0.0037907061632722616
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0001040017232298851
mask_decoder.transformer.layers.1.norm2.weight grad: 0.008446261286735535
mask_decoder.transformer.layers.1.norm2.bias grad: 0.005165984854102135
mask_decoder.transformer.layers.1.norm3.weight grad: 0.0006794825312681496
mask_decoder.transformer.layers.1.norm3.bias grad: 0.003584658494219184
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0015243940288200974
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0009675014880485833
mask_decoder.transformer.norm_final_attn.weight grad: 0.00043783336877822876
mask_decoder.transformer.norm_final_attn.bias grad: 0.0009661737713031471
Text_Embedding_Affine.0.weight grad: 5.421316173759294e-10
Text_Embedding_Affine.0.bias grad: 2.1784217096865177e-08
Text_Embedding_Affine.2.weight grad: 1.2962846351882717e-09
Text_Embedding_Affine.2.bias grad: -9.723828407004476e-05
Epoch 38 finished with average loss: -57.3263
Epoch 39/39
----------
Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s, loss=-52.6]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-52.6]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-52]  Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-52]Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-56.3]Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-56.3]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1028393753775845e-09
Max value: 0.9964189529418945
Mean value: 0.071182981133461

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1028393753775845e-09
Max value: 0.9964189529418945
Mean value: 0.071182981133461

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07706880569458008

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.829092025756836
Max value: -1.1920928244535389e-07
Mean value: -0.10491617023944855

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058942317962646484

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07706880569458008

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.361183166503906
Max value: 84.80721282958984
Mean value: 52.61351013183594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1028393753775845e-09
Max value: 0.9964189529418945
Mean value: 0.071182981133461

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1028393753775845e-09
Max value: 0.9964189529418945
Mean value: 0.071182981133461

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1028393753775845e-09
Max value: 0.9964189529418945
Mean value: 0.071182981133461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.829092025756836
Max value: -1.1920928244535389e-07
Mean value: -0.10491617023944855

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.361183166503906
Max value: 84.80721282958984
Mean value: 52.61351013183594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.614566802978516
Max value: -52.614566802978516
Mean value: -52.614566802978516
sam_encoder.pos_embed grad: 5.353994083634461e-07
sam_encoder.blocks.0.norm1.weight grad: 0.008045628666877747
sam_encoder.blocks.0.norm1.bias grad: 0.0039085885509848595
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 0.00032259017461910844
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.303866808186285e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.686551543883979e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.4236873034387827e-06
sam_encoder.blocks.0.norm2.weight grad: 0.003459770232439041
sam_encoder.blocks.0.norm2.bias grad: -0.002101865131407976
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.0013673985376954079
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.877103366306983e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.001662898575887084
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 0.0011648897780105472
sam_encoder.blocks.1.norm1.weight grad: 0.00039931334322318435
sam_encoder.blocks.1.norm1.bias grad: 0.0013911370187997818
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0014009575825184584
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00039101584115996957
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0013375254347920418
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0006371624767780304
sam_encoder.blocks.1.norm2.weight grad: 0.0008488410385325551
sam_encoder.blocks.1.norm2.bias grad: 0.00017710719839669764
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0004990176530554891
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.987011485965922e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -0.0010696826502680779
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.625576108694077e-05
sam_encoder.blocks.2.norm1.weight grad: -0.002445872640237212
sam_encoder.blocks.2.norm1.bias grad: 0.0003185227978974581
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -0.001921926042996347
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -0.0004239227273501456
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.001174585777334869
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -0.0008326686220243573
sam_encoder.blocks.2.norm2.weight grad: -0.000856191327329725
sam_encoder.blocks.2.norm2.bias grad: -0.0008584186434745789
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.0011117256944999099
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00012259416689630598
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -0.0008882110705599189
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -0.00024027176550589502
sam_encoder.blocks.3.norm1.weight grad: 0.00043401127913966775
sam_encoder.blocks.3.norm1.bias grad: 0.00024064964964054525
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00014331411512102932
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.234866982093081e-05
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -0.00034738279646262527
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -0.00036887219175696373
sam_encoder.blocks.3.norm2.weight grad: -0.0009846161119639874
sam_encoder.blocks.3.norm2.bias grad: -0.0008898302912712097
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -0.0008895647479221225
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -0.00022438314044848084
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -0.0004643876454792917
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -0.00020273860718589276
sam_encoder.blocks.4.norm1.weight grad: 0.0012397633399814367
sam_encoder.blocks.4.norm1.bias grad: -0.0005626120837405324
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0002869908348657191
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.588761733728461e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -0.00030007597524672747
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -0.00032228027703240514
sam_encoder.blocks.4.norm2.weight grad: 0.00031937420135363936
sam_encoder.blocks.4.norm2.bias grad: 0.0014833351597189903
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.00015409149636980146
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.88992440700531e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -0.00044050952419638634
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -0.0001918867783388123
sam_encoder.blocks.5.norm1.weight grad: 0.001189095200970769
sam_encoder.blocks.5.norm1.bias grad: -0.0018227153923362494
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0009571424452587962
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.00060354481684044
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.805582572473213e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 9.540989412926137e-05
sam_encoder.blocks.5.norm2.weight grad: 8.527674071956426e-05
sam_encoder.blocks.5.norm2.bias grad: 0.0012172204442322254
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.154878014465794e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.503420313994866e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.809570236830041e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.581714554456994e-05
sam_encoder.blocks.6.norm1.weight grad: 0.00033102845191024244
sam_encoder.blocks.6.norm1.bias grad: -0.0009015752002596855
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00048807900748215616
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0003931348619516939
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.080232272623107e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.1806688386714086e-05
sam_encoder.blocks.6.norm2.weight grad: -4.8914022045210004e-05
sam_encoder.blocks.6.norm2.bias grad: 0.00047026295214891434
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.00014313924475573003
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.9028167268261313e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.0001456575409974903
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.3234710422693752e-05
sam_encoder.blocks.7.norm1.weight grad: 0.00016504942323081195
sam_encoder.blocks.7.norm1.bias grad: -9.512513497611508e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.06082971394062e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.8696314226835966e-05
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -0.0002451283799018711
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -0.0001341534371022135
sam_encoder.blocks.7.norm2.weight grad: -0.0002735226880759001
sam_encoder.blocks.7.norm2.bias grad: -0.0001447052782168612
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00017989031039178371
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.706520798616111e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2228158993821125e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.394549852004275e-05
sam_encoder.blocks.8.norm1.weight grad: -0.0003650034195743501
sam_encoder.blocks.8.norm1.bias grad: -0.0002739418123383075
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.9908998587634414e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.54001414659433e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -0.0003204673412255943
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.536781150614843e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0007335483096539974
sam_encoder.blocks.8.norm2.bias grad: 1.1985617675236426e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.000612309668213129
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -0.00029172663926146924
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -0.00019023672211915255
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.703714567876887e-06
sam_encoder.blocks.9.norm1.weight grad: -0.000384268700145185
sam_encoder.blocks.9.norm1.bias grad: 5.893084562558215e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -0.0005001169629395008
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -0.00018864723097067326
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -0.00015036010881885886
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.993315087631345e-06
sam_encoder.blocks.9.norm2.weight grad: -0.001251646433956921
sam_encoder.blocks.9.norm2.bias grad: -0.00015199172776192427
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -0.0009685058612376451
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -0.0005115428939461708
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -0.00018807174637913704
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.684153696463909e-05
sam_encoder.blocks.10.norm1.weight grad: -0.0008413628675043583
sam_encoder.blocks.10.norm1.bias grad: 3.8064968975959346e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -0.0006806781748309731
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -0.00024491618387401104
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -0.0002506190212443471
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -0.00012782571138814092
sam_encoder.blocks.10.norm2.weight grad: -0.001299585448578
sam_encoder.blocks.10.norm2.bias grad: -9.896738629322499e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -0.0007313810056075454
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -0.00033426255686208606
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.325752236880362e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.948153814941179e-05
sam_encoder.blocks.11.norm1.weight grad: -0.00143923400901258
sam_encoder.blocks.11.norm1.bias grad: 8.663073822390288e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.00010197760275332257
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.4726882808608934e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -0.00028626780840568244
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -0.00014945441216696054
sam_encoder.blocks.11.norm2.weight grad: -0.0015110712265595794
sam_encoder.blocks.11.norm2.bias grad: 0.00012149402755312622
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -0.000750935054384172
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -0.00023794776643626392
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -0.0001191036426462233
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -0.00011466923024272546
sam_encoder.neck.conv1.trainable_scale grad: -7.082568481564522e-05
sam_encoder.neck.conv1.trainable_shift grad: -0.0004268928896635771
sam_encoder.neck.conv2.trainable_scale grad: 7.783761247992516e-06
sam_encoder.neck.conv2.trainable_shift grad: 0.004394622519612312
mask_decoder.transformer.layers.0.norm1.weight grad: 0.009025117382407188
mask_decoder.transformer.layers.0.norm1.bias grad: -0.00027859490364789963
mask_decoder.transformer.layers.0.norm2.weight grad: 1.0081982612609863
mask_decoder.transformer.layers.0.norm2.bias grad: 0.058850619941949844
mask_decoder.transformer.layers.0.norm3.weight grad: 0.015768686309456825
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0012401072308421135
mask_decoder.transformer.layers.0.norm4.weight grad: -0.01198172103613615
mask_decoder.transformer.layers.0.norm4.bias grad: 0.0012575527653098106
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0027961789164692163
mask_decoder.transformer.layers.1.norm1.bias grad: -0.0004161754623055458
mask_decoder.transformer.layers.1.norm2.weight grad: 0.013611024245619774
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0004036170430481434
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0024206526577472687
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0038272826932370663
mask_decoder.transformer.layers.1.norm4.weight grad: 0.010616010054945946
mask_decoder.transformer.layers.1.norm4.bias grad: 0.024585027247667313
mask_decoder.transformer.norm_final_attn.weight grad: -0.0003745535505004227
mask_decoder.transformer.norm_final_attn.bias grad: -0.0016620776150375605
Text_Embedding_Affine.0.weight grad: 1.1064205107658154e-09
Text_Embedding_Affine.0.bias grad: 2.5756889954209328e-08
Text_Embedding_Affine.2.weight grad: 6.413201525390377e-09
Text_Embedding_Affine.2.bias grad: -0.002661967184394598

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5994502597371785e-11
Max value: 0.9978237152099609
Mean value: 0.07602053880691528

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5994502597371785e-11
Max value: 0.9978237152099609
Mean value: 0.07602053880691528

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07962989807128906

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12256269156932831

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0686197280883789

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07962989807128906

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.33766174316406
Max value: 69.35739135742188
Mean value: 51.30072021484375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5994502597371785e-11
Max value: 0.9978237152099609
Mean value: 0.07602053880691528

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5994502597371785e-11
Max value: 0.9978237152099609
Mean value: 0.07602053880691528

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5994502597371785e-11
Max value: 0.9978237152099609
Mean value: 0.07602053880691528

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12256269156932831

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.33766174316406
Max value: 69.35739135742188
Mean value: 51.30072021484375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -51.30171585083008
Max value: -51.30171585083008
Mean value: -51.30171585083008
sam_encoder.pos_embed grad: -2.364929798659432e-07
sam_encoder.blocks.0.norm1.weight grad: -0.0022528518456965685
sam_encoder.blocks.0.norm1.bias grad: -0.0009983114432543516
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.00011821562657132745
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.7968700528144836e-05
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0005467343726195395
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00016623263945803046
sam_encoder.blocks.0.norm2.weight grad: 0.00013342034071683884
sam_encoder.blocks.0.norm2.bias grad: -5.170198619453004e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -0.0006122122867964208
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0003039728326257318
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -0.000967335538007319
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -0.0002665711217559874
sam_encoder.blocks.1.norm1.weight grad: -0.0003266231797169894
sam_encoder.blocks.1.norm1.bias grad: -0.001266929553821683
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.61741355038248e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5292392820119858e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.10569591622334e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.709776840172708e-05
sam_encoder.blocks.1.norm2.weight grad: -0.00030408077873289585
sam_encoder.blocks.1.norm2.bias grad: 0.0005924153374508023
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -0.0004893915611319244
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.113857959164307e-05
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.006238931557164e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.0234408515971154e-05
sam_encoder.blocks.2.norm1.weight grad: 0.00010997621575370431
sam_encoder.blocks.2.norm1.bias grad: -0.00031011016108095646
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.330731462687254e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.114510274026543e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.848153599188663e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.691118323942646e-05
sam_encoder.blocks.2.norm2.weight grad: 0.00036570505471900105
sam_encoder.blocks.2.norm2.bias grad: -0.0006095296703279018
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 0.00030753336613997817
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.793036300223321e-05
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00019106145191472024
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.651190728414804e-05
sam_encoder.blocks.3.norm1.weight grad: 0.0001994150661630556
sam_encoder.blocks.3.norm1.bias grad: 0.00020697663421742618
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -0.00017167201440315694
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -0.00010093780292663723
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.5879344320856035e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.578744356986135e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0002895600046031177
sam_encoder.blocks.3.norm2.bias grad: -0.0005777009064331651
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.073144661262631e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.1439743502705824e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0001887498947326094
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.571042907424271e-05
sam_encoder.blocks.4.norm1.weight grad: 0.0010263960575684905
sam_encoder.blocks.4.norm1.bias grad: -0.000309736467897892
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.0005662849871441722
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.0001169157330878079
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.00014749194087926298
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.7573698440101e-05
sam_encoder.blocks.4.norm2.weight grad: -0.001187336165457964
sam_encoder.blocks.4.norm2.bias grad: -0.0005750899435952306
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0007149112643674016
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0002781512157525867
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.1589220927562565e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.4281395124271512e-05
sam_encoder.blocks.5.norm1.weight grad: 0.001624376280233264
sam_encoder.blocks.5.norm1.bias grad: -6.056140409782529e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 0.0010684006847441196
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 0.0003234572650399059
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00022330216597765684
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 0.00017674302216619253
sam_encoder.blocks.5.norm2.weight grad: -0.00024834962096065283
sam_encoder.blocks.5.norm2.bias grad: -0.0003640977665781975
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.614790906198323e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.2781976440455765e-05
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 0.00014151548384688795
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.9688253056956455e-05
sam_encoder.blocks.6.norm1.weight grad: 0.0002710339322220534
sam_encoder.blocks.6.norm1.bias grad: 0.0001651457860134542
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.00020150697673670948
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 0.0001094910257961601
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.866708958521485e-05
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.168098141439259e-05
sam_encoder.blocks.6.norm2.weight grad: -0.0006072829710319638
sam_encoder.blocks.6.norm2.bias grad: -0.00018789328169077635
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0004293752717785537
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.00017698323063086718
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.6205187168670818e-05
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.83128712605685e-06
sam_encoder.blocks.7.norm1.weight grad: 0.00043274692143313587
sam_encoder.blocks.7.norm1.bias grad: -7.362462201854214e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.00023289221280720085
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.0001276905823033303
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.440930105280131e-05
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.00010096663027070463
sam_encoder.blocks.7.norm2.weight grad: -0.0003095819556619972
sam_encoder.blocks.7.norm2.bias grad: 5.905851139687002e-05
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -0.00016512667934875935
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.723052112851292e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.537735341931693e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.0096107618883252e-05
sam_encoder.blocks.8.norm1.weight grad: 0.00031514136935584247
sam_encoder.blocks.8.norm1.bias grad: -0.00010534383909543976
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.72967391135171e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.184062345302664e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.613038178533316e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.718842243775725e-05
sam_encoder.blocks.8.norm2.weight grad: -0.0001554621703689918
sam_encoder.blocks.8.norm2.bias grad: -7.625319994986057e-05
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -0.0001398523017996922
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.054229015717283e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.0322444470366463e-05
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.249273388268193e-06
sam_encoder.blocks.9.norm1.weight grad: 0.00027290789876133204
sam_encoder.blocks.9.norm1.bias grad: -1.964880902960431e-05
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 0.00013218412641435862
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.361445568676572e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.4705051803030074e-05
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.99059635028243e-05
sam_encoder.blocks.9.norm2.weight grad: 4.666073073167354e-05
sam_encoder.blocks.9.norm2.bias grad: 2.518598012102302e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.7810823667095974e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.631948907743208e-05
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.478659244952723e-05
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.0267557778861374e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0002687894448172301
sam_encoder.blocks.10.norm1.bias grad: 2.9054030164843425e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.0827012930531055e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.6140802472364157e-05
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.9809825971606188e-05
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.034411520275171e-06
sam_encoder.blocks.10.norm2.weight grad: 0.0003892167878802866
sam_encoder.blocks.10.norm2.bias grad: 0.00016836886061355472
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.277465920196846e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.891491648275405e-05
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 0.0001230858324561268
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.419043448753655e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0005781326908618212
sam_encoder.blocks.11.norm1.bias grad: 4.9541820771992207e-05
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.408149445429444e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.150689038506243e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.174078640062362e-05
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.5507841201033443e-05
sam_encoder.blocks.11.norm2.weight grad: 0.00023327319649979472
sam_encoder.blocks.11.norm2.bias grad: -5.774432793259621e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0001521617959951982
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.429419252322987e-05
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.933332719607279e-05
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.3929223971208557e-05
sam_encoder.neck.conv1.trainable_scale grad: 3.775866935029626e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0005978549597784877
sam_encoder.neck.conv2.trainable_scale grad: 1.2409873306751251e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.0027625607326626778
mask_decoder.transformer.layers.0.norm1.weight grad: 0.002345987129956484
mask_decoder.transformer.layers.0.norm1.bias grad: 7.323524914681911e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.13098162412643433
mask_decoder.transformer.layers.0.norm2.bias grad: -0.03586733341217041
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0030111041851341724
mask_decoder.transformer.layers.0.norm3.bias grad: -0.002840062603354454
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0008670433890074492
mask_decoder.transformer.layers.0.norm4.bias grad: 0.00026176939718425274
mask_decoder.transformer.layers.1.norm1.weight grad: -0.0015781689435243607
mask_decoder.transformer.layers.1.norm1.bias grad: 0.00018999091116711497
mask_decoder.transformer.layers.1.norm2.weight grad: -0.004565298557281494
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0036347340792417526
mask_decoder.transformer.layers.1.norm3.weight grad: -0.0002687882515601814
mask_decoder.transformer.layers.1.norm3.bias grad: -0.0019779670983552933
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0009455524850636721
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0011593826347962022
mask_decoder.transformer.norm_final_attn.weight grad: -0.00017639665747992694
mask_decoder.transformer.norm_final_attn.bias grad: 5.25452196598053e-05
Text_Embedding_Affine.0.weight grad: 4.1600978217815054e-10
Text_Embedding_Affine.0.bias grad: 3.4924596548080444e-09
Text_Embedding_Affine.2.weight grad: -1.0897331925718845e-09
Text_Embedding_Affine.2.bias grad: -0.0010589256417006254

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.6036373617911437e-12
Max value: 0.9987347722053528
Mean value: 0.10212923586368561

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.6036373617911437e-12
Max value: 0.9987347722053528
Mean value: 0.10212923586368561

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10543060302734375

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.146059051156044

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09952926635742188

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10543060302734375

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 55.91054153442383
Max value: 78.01822662353516
Mean value: 64.98175811767578

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.6036373617911437e-12
Max value: 0.9987347722053528
Mean value: 0.10212923586368561

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.6036373617911437e-12
Max value: 0.9987347722053528
Mean value: 0.10212923586368561

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.6036373617911437e-12
Max value: 0.9987347722053528
Mean value: 0.10212923586368561

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.146059051156044

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 55.91054153442383
Max value: 78.01822662353516
Mean value: 64.98175811767578

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.98280334472656
Max value: -64.98280334472656
Mean value: -64.98280334472656
sam_encoder.pos_embed grad: -1.3339624729269417e-06
sam_encoder.blocks.0.norm1.weight grad: -0.009161284193396568
sam_encoder.blocks.0.norm1.bias grad: -0.002760083880275488
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -0.0005396237829700112
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -0.00011401069059502333
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -0.0011528594186529517
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -0.00039305328391492367
sam_encoder.blocks.0.norm2.weight grad: 0.0016149056609719992
sam_encoder.blocks.0.norm2.bias grad: -0.000635514035820961
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 0.000905716500710696
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -0.0002842644171323627
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 0.00037096079904586077
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.964717380877119e-06
sam_encoder.blocks.1.norm1.weight grad: 0.00013208483869675547
sam_encoder.blocks.1.norm1.bias grad: 0.0027205280493944883
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -0.0005288320244289935
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -0.00012980264727957547
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -0.0005316328606568277
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -0.0002168863866245374
sam_encoder.blocks.1.norm2.weight grad: 0.0022949976846575737
sam_encoder.blocks.1.norm2.bias grad: 8.625909686088562e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 0.000910317525267601
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 0.0002020208048634231
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 0.00014065256982576102
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.9233400204684585e-05
sam_encoder.blocks.2.norm1.weight grad: 0.0018131214892491698
sam_encoder.blocks.2.norm1.bias grad: -0.001204641186632216
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 0.0007076833280734718
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 0.00022808570065535605
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -0.0004783940385095775
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.3229589209659025e-05
sam_encoder.blocks.2.norm2.weight grad: -0.0017309136455878615
sam_encoder.blocks.2.norm2.bias grad: 0.0014135874807834625
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -0.001003095181658864
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -0.00038907083217054605
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 0.00037277847877703607
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 0.00011021882528439164
sam_encoder.blocks.3.norm1.weight grad: 0.0007085022516548634
sam_encoder.blocks.3.norm1.bias grad: -0.00105614576023072
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 0.0006854899693280458
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 0.0002929857582785189
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 0.0004875356098636985
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.0003091271501034e-05
sam_encoder.blocks.3.norm2.weight grad: 0.0007534445030614734
sam_encoder.blocks.3.norm2.bias grad: -0.0004828345845453441
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 0.0009546882938593626
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 0.00017039499653037637
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 0.0004988233558833599
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 0.0003495151177048683
sam_encoder.blocks.4.norm1.weight grad: 0.0005941878771409392
sam_encoder.blocks.4.norm1.bias grad: -0.001571191824041307
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 0.000562678964342922
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 0.00034182891249656677
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 0.0005806121043860912
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 0.0005826619453728199
sam_encoder.blocks.4.norm2.weight grad: -0.0018973200349137187
sam_encoder.blocks.4.norm2.bias grad: -0.001490759546868503
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.0010059438645839691
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -0.0004226680030114949
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 0.0005469602765515447
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 0.00023234871332533658
sam_encoder.blocks.5.norm1.weight grad: 0.0010894418228417635
sam_encoder.blocks.5.norm1.bias grad: 0.0012743184342980385
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3531417525646248e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.7587608201429248e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 0.00030893704388290644
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.498137372545898e-05
sam_encoder.blocks.5.norm2.weight grad: -0.00022227733279578388
sam_encoder.blocks.5.norm2.bias grad: -0.0011985527817159891
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 0.0003757947706617415
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 0.0002657762379385531
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.022860179655254e-05
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 0.00012290343875065446
sam_encoder.blocks.6.norm1.weight grad: 0.0004503415839280933
sam_encoder.blocks.6.norm1.bias grad: 0.0014334903098642826
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 0.0003653930907603353
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.040124051447492e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 0.00013059504271950573
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 0.000140472810016945
sam_encoder.blocks.6.norm2.weight grad: -0.0017573791556060314
sam_encoder.blocks.6.norm2.bias grad: -0.0010361658642068505
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -0.0008416594355367124
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -0.0003433473175391555
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -0.00029651797376573086
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -0.00015099607117008418
sam_encoder.blocks.7.norm1.weight grad: 0.0006461816374212503
sam_encoder.blocks.7.norm1.bias grad: 1.4723336789757013e-05
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 0.0005617490969598293
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 0.00031850271625444293
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 0.000469742197310552
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 0.0007547929417341948
sam_encoder.blocks.7.norm2.weight grad: 0.00011008077854057774
sam_encoder.blocks.7.norm2.bias grad: 0.0002692782727535814
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.5073941312948591e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.963649527984671e-05
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.796784924110398e-05
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -0.00015753787010908127
sam_encoder.blocks.8.norm1.weight grad: -0.0003466277848929167
sam_encoder.blocks.8.norm1.bias grad: -5.675833017448895e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -0.0008032805053517222
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -0.00012943898036610335
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 0.0001619128161109984
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.1451114662340842e-05
sam_encoder.blocks.8.norm2.weight grad: 0.000935747055336833
sam_encoder.blocks.8.norm2.bias grad: -0.0002025095745921135
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 0.000954534625634551
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 0.00051652587717399
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 0.0006470562657341361
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 0.0002017597871599719
sam_encoder.blocks.9.norm1.weight grad: 0.00037111827987246215
sam_encoder.blocks.9.norm1.bias grad: 0.0002737828763201833
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.483918984187767e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 0.00017919216770678759
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 0.00016060841153375804
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 0.0001365675125271082
sam_encoder.blocks.9.norm2.weight grad: 0.0014177499106153846
sam_encoder.blocks.9.norm2.bias grad: 0.00028676603687927127
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 0.001087758457288146
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 0.0005322673823684454
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 0.00026471924502402544
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.215946344425902e-05
sam_encoder.blocks.10.norm1.weight grad: 0.0006092233816161752
sam_encoder.blocks.10.norm1.bias grad: -4.8410322051495314e-05
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 0.0004204440047033131
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 0.00023708966909907758
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 0.00023173962836153805
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 0.00015589300892315805
sam_encoder.blocks.10.norm2.weight grad: 0.0023121691774576902
sam_encoder.blocks.10.norm2.bias grad: 0.00038653885712847114
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 0.001037972280755639
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 0.00052011723164469
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.464102186029777e-05
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.502528463490307e-05
sam_encoder.blocks.11.norm1.weight grad: 0.0011470727622509003
sam_encoder.blocks.11.norm1.bias grad: -0.0001686701871221885
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -0.0006597846513614058
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.0445295376703143e-05
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 0.00018989419913850725
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.2421241485280916e-05
sam_encoder.blocks.11.norm2.weight grad: 0.0028041996993124485
sam_encoder.blocks.11.norm2.bias grad: -0.00017607863992452621
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 0.0013503478839993477
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 0.0004772904794663191
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 0.00021965810446999967
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 0.00013928137195762247
sam_encoder.neck.conv1.trainable_scale grad: 2.020306419581175e-05
sam_encoder.neck.conv1.trainable_shift grad: 0.0037938139867037535
sam_encoder.neck.conv2.trainable_scale grad: 6.991112604737282e-05
sam_encoder.neck.conv2.trainable_shift grad: -0.012600868009030819
mask_decoder.transformer.layers.0.norm1.weight grad: -0.000804500188678503
mask_decoder.transformer.layers.0.norm1.bias grad: 0.0005568712949752808
mask_decoder.transformer.layers.0.norm2.weight grad: -1.125260829925537
mask_decoder.transformer.layers.0.norm2.bias grad: -0.16281640529632568
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0203119944781065
mask_decoder.transformer.layers.0.norm3.bias grad: -0.0034474830608814955
mask_decoder.transformer.layers.0.norm4.weight grad: 0.011496974155306816
mask_decoder.transformer.layers.0.norm4.bias grad: -0.0015370470937341452
mask_decoder.transformer.layers.1.norm1.weight grad: 0.006532474886626005
mask_decoder.transformer.layers.1.norm1.bias grad: -0.00021807663142681122
mask_decoder.transformer.layers.1.norm2.weight grad: -0.008118651807308197
mask_decoder.transformer.layers.1.norm2.bias grad: 0.006298307329416275
mask_decoder.transformer.layers.1.norm3.weight grad: 0.001897643436677754
mask_decoder.transformer.layers.1.norm3.bias grad: 0.004841635003685951
mask_decoder.transformer.layers.1.norm4.weight grad: -0.011456651613116264
mask_decoder.transformer.layers.1.norm4.bias grad: -0.029773583635687828
mask_decoder.transformer.norm_final_attn.weight grad: 0.00027955672703683376
mask_decoder.transformer.norm_final_attn.bias grad: 0.0017858073115348816
Text_Embedding_Affine.0.weight grad: -1.900825719047816e-09
Text_Embedding_Affine.0.bias grad: -8.62637534737587e-08
Text_Embedding_Affine.2.weight grad: 1.6786135148549874e-08
Text_Embedding_Affine.2.bias grad: -0.0016390467062592506
Epoch 39 finished with average loss: -56.2997
Final Validation
Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, Loss=0.689, Dice=0.695]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.85it/s, Loss=0.689, Dice=0.695]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.85it/s, Loss=0.69, Dice=0.673] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                        
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0681847529278782e-36
Max value: 0.9999991655349731
Mean value: 0.06254812330007553

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0681847529278782e-36
Max value: 0.9999991655349731
Mean value: 0.06254812330007553

Debugging images:
Shape: torch.Size([8, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 0.8751826286315918

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06483793258666992

Debugging predicted segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058527469635009766

Debugging Raw model output:
Shape: torch.Size([2, 512, 512])
Contains NaN: False
Min value: 1.0229785670418775e-26
Max value: 0.999580442905426
Mean value: 0.0660768449306488

Debugging Processed model output:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 1.0229785670418775e-26
Max value: 0.999580442905426
Mean value: 0.0660768449306488

Debugging images:
Shape: torch.Size([2, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 0.7623386383056641

Debugging Ground truth:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07178306579589844

Debugging predicted segs:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06229972839355469
Validation completed for Epoch 1:
Average Loss: 0.6898, Average Dice: 0.6730
