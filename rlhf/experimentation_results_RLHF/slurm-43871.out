Sun Oct 13 21:29:49 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        On  | 00000000:41:00.0 Off |                  Off |
|  0%   36C    P8              10W / 450W |     48MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   1770066      G   /usr/lib/xorg/Xorg                           38MiB |
+---------------------------------------------------------------------------------------+
wandb: Currently logged in as: abdelrahman-elsayed (dinesh_saggurthi). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/abdelrahman.elsayed/wandb/run-20241013_213002-m03tos6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DIAS_modelnone
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dinesh_saggurthi/SVD_exps
wandb: üöÄ View run at https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/m03tos6l
{'data_transforms': {'a_min': 0, 'a_max': 255, 'img_size': 512, 'use_random_crop': False, 'use_rotation': True, 'rotation_angle': 10, 'use_saturation': False, 'saturation': 2, 'use_brightness': True, 'brightness': 2, 'use_horizontal_flip': True, 'use_random_scale': True}, 'data': {'name': 'ArcadeDataset', 'root_path': '/home/abdelrahman.elsayed/DIAS', 'data_split_csv': '/home/abdelrahman.elsayed/DIAS/data_split.csv', 'fold_num': 0, 'label_list': [0, 1], 'label_names': ['Background', 'Vein'], 'volume_channel': 3, 'negative_to_positive_ratio': -1}}
{'sam': {'img_size': 512, 'num_classes': 2, 'sam_type': 'base'}, 'img_type': 'image', 'arch': 'Prompt Adapted SAM', 'use_fdn': False, 'decoder_training': 'none', 'mlp_transform': False, 'prompts': {'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}, 'training': {'optimizer': 'adamw', 'lr': '1e-4', 'batch_size': 8, 'num_epochs': 200, 'schedule_step': 200, 'schedule_step_factor': 0.2, 'weight_decay': '1e-2', 'loss': 'focal+dice', 'reg_multiplier': 0}}
HERE
Train dataset size: 20
Val dataset size: 10
Train dataset size: 20
Val dataset size: 10
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Total parameters: 242,767,409
Trainable parameters: 1,034,496
Frozen parameters: 241,732,913

Parameters by module:
*************************************************************************************************************
  sam_encoder:
    Total: 87,293,696
    Trainable: 898,048
    Frozen: 86,395,648
*******************************************************************************************
*************************************************************************************************************
  clip_model:
    Total: 151,277,313
    Trainable: 0
    Frozen: 151,277,313
*******************************************************************************************
*************************************************************************************************************
  prompt_encoder:
    Total: 6,220
    Trainable: 0
    Frozen: 6,220
*******************************************************************************************
*************************************************************************************************************
  mask_decoder:
    Total: 4,058,340
    Trainable: 4,608
    Frozen: 4,053,732
*******************************************************************************************
*************************************************************************************************************
  Text_Embedding_Affine:
    Total: 131,840
    Trainable: 131,840
    Frozen: 0
*******************************************************************************************
./svdtuning/DIAS
Training parameters: 
----------
number of trainable parameters:  1034496
batch size:  5
num epochs:  200
Epoch 0/199
----------
train Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 0:   0%|          | 0/4 [00:02<?, ?it/s, loss=0.981, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.87s/it, loss=0.981, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:03<00:08,  2.87s/it, loss=0.964, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.28s/it, loss=0.964, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.28s/it, loss=0.928, dice=tensor(0.0002, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.30it/s, loss=0.928, dice=tensor(0.0002, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.30it/s, loss=0.912, dice=tensor(0.0005, device='cuda:0')]train Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.89it/s, loss=0.912, dice=tensor(0.0005, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                              train Loss: 0.9462 Dice: 0.0001
val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.909, dice=tensor(0.0126, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.909, dice=tensor(0.0126, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.913, dice=tensor(0.0077, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9110 Dice: 0.0015
Epoch 1/199
----------
train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.931, dice=tensor(0.0109, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.931, dice=tensor(0.0109, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.916, dice=tensor(0.0243, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.916, dice=tensor(0.0243, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.917, dice=tensor(0.0427, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.917, dice=tensor(0.0427, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.874, dice=tensor(0.0570, device='cuda:0')]train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.874, dice=tensor(0.0570, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                              train Loss: 0.9095 Dice: 0.0114
val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.911, dice=tensor(0.2341, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.911, dice=tensor(0.2341, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.926, dice=tensor(0.1463, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.9183 Dice: 0.0293
Epoch 2/199
----------
train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.913, dice=tensor(0.0881, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.913, dice=tensor(0.0881, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.89, dice=tensor(0.1779, device='cuda:0')] train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.89, dice=tensor(0.1779, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.893, dice=tensor(0.1279, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.893, dice=tensor(0.1279, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.897, dice=tensor(0.1436, device='cuda:0')]train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.897, dice=tensor(0.1436, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                              train Loss: 0.8980 Dice: 0.0287
val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.903, dice=tensor(0.3176, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.903, dice=tensor(0.3176, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.928, dice=tensor(0.1940, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.9154 Dice: 0.0388
Epoch 3/199
----------
train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.893, dice=tensor(0.5667, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.893, dice=tensor(0.5667, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.91, dice=tensor(0.3810, device='cuda:0')] train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.91, dice=tensor(0.3810, device='cuda:0')]train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.887, dice=tensor(0.3745, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.887, dice=tensor(0.3745, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.916, dice=tensor(0.2881, device='cuda:0')]train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.916, dice=tensor(0.2881, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                              train Loss: 0.9014 Dice: 0.0576
val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.914, dice=tensor(0.2819, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.914, dice=tensor(0.2819, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.91, dice=tensor(0.2338, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                           val Loss: 0.9121 Dice: 0.0468
Epoch 4/199
----------
train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.882, dice=tensor(0.5568, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.882, dice=tensor(0.5568, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.892, dice=tensor(0.3948, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.892, dice=tensor(0.3948, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.916, dice=tensor(0.3250, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.04it/s, loss=0.916, dice=tensor(0.3250, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.04it/s, loss=0.89, dice=tensor(0.3200, device='cuda:0')] train Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.68it/s, loss=0.89, dice=tensor(0.3200, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                             train Loss: 0.8950 Dice: 0.0640
val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.904, dice=tensor(0.3736, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.904, dice=tensor(0.3736, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.914, dice=tensor(0.2507, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.9090 Dice: 0.0501
Epoch 5/199
----------
train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.884, dice=tensor(0.1085, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.884, dice=tensor(0.1085, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.908, dice=tensor(0.2049, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.908, dice=tensor(0.2049, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.913, dice=tensor(0.1697, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.913, dice=tensor(0.1697, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.868, dice=tensor(0.2307, device='cuda:0')]train Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.868, dice=tensor(0.2307, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.8930 Dice: 0.0461
val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.899, dice=tensor(0.2403, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.899, dice=tensor(0.2403, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.91, dice=tensor(0.1998, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                           val Loss: 0.9047 Dice: 0.0400
Epoch 6/199
----------
train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.89, dice=tensor(0.1101, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.89, dice=tensor(0.1101, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.886, dice=tensor(0.1581, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.886, dice=tensor(0.1581, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.855, dice=tensor(0.1738, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.855, dice=tensor(0.1738, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.909, dice=tensor(0.1763, device='cuda:0')]train Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.909, dice=tensor(0.1763, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                              train Loss: 0.8850 Dice: 0.0353
val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.916, dice=tensor(0.2182, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.916, dice=tensor(0.2182, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.885, dice=tensor(0.1883, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9004 Dice: 0.0377
Epoch 7/199
----------
train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.881, dice=tensor(0.1504, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.881, dice=tensor(0.1504, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.886, dice=tensor(0.1565, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.886, dice=tensor(0.1565, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.884, dice=tensor(0.1931, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.884, dice=tensor(0.1931, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.88, dice=tensor(0.2210, device='cuda:0')] train Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.88, dice=tensor(0.2210, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                             train Loss: 0.8826 Dice: 0.0442
val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.913, dice=tensor(0.2329, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.913, dice=tensor(0.2329, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.877, dice=tensor(0.1998, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.8954 Dice: 0.0400
Epoch 8/199
----------
train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.866, dice=tensor(0.3831, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.866, dice=tensor(0.3831, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.895, dice=tensor(0.2536, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.895, dice=tensor(0.2536, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.865, dice=tensor(0.2395, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.865, dice=tensor(0.2395, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.887, dice=tensor(0.1924, device='cuda:0')]train Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.887, dice=tensor(0.1924, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                              train Loss: 0.8782 Dice: 0.0385
val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.902, dice=tensor(0.1499, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.95it/s, loss=0.902, dice=tensor(0.1499, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.95it/s, loss=0.888, dice=tensor(0.2008, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.8953 Dice: 0.0402
Epoch 9/199
----------
train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.854, dice=tensor(0.1014, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.854, dice=tensor(0.1014, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.88, dice=tensor(0.2268, device='cuda:0')] train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.88, dice=tensor(0.2268, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.854, dice=tensor(0.2822, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.854, dice=tensor(0.2822, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.894, dice=tensor(0.2652, device='cuda:0')]train Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.894, dice=tensor(0.2652, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                              train Loss: 0.8707 Dice: 0.0530
val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.904, dice=tensor(0.2805, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.904, dice=tensor(0.2805, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.876, dice=tensor(0.1753, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.8898 Dice: 0.0351
Epoch 10/199
----------
train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.89, dice=tensor(0.0488, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.89, dice=tensor(0.0488, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.868, dice=tensor(0.1585, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.868, dice=tensor(0.1585, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.87, dice=tensor(0.1292, device='cuda:0')] train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.87, dice=tensor(0.1292, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.846, dice=tensor(0.1488, device='cuda:0')]train Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.846, dice=tensor(0.1488, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.8686 Dice: 0.0298
val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.909, dice=tensor(0.1032, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.909, dice=tensor(0.1032, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.873, dice=tensor(0.1202, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.8912 Dice: 0.0240
Epoch 11/199
----------
train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.861, dice=tensor(0.3149, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.861, dice=tensor(0.3149, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.9, dice=tensor(0.2924, device='cuda:0')]  train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.9, dice=tensor(0.2924, device='cuda:0')]train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.833, dice=tensor(0.3623, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.833, dice=tensor(0.3623, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.805, dice=tensor(0.3050, device='cuda:0')]train Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.805, dice=tensor(0.3050, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.8499 Dice: 0.0610
val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.88, dice=tensor(0.2103, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.92it/s, loss=0.88, dice=tensor(0.2103, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.92it/s, loss=0.894, dice=tensor(0.1459, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.8873 Dice: 0.0292
Epoch 12/199
----------
train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.854, dice=tensor(0.5289, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.854, dice=tensor(0.5289, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.859, dice=tensor(0.4870, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.859, dice=tensor(0.4870, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.831, dice=tensor(0.4398, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.831, dice=tensor(0.4398, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.846, dice=tensor(0.3906, device='cuda:0')]train Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.846, dice=tensor(0.3906, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.8477 Dice: 0.0781
val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.88, dice=tensor(0.4628, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.88, dice=tensor(0.4628, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.881, dice=tensor(0.2887, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.8809 Dice: 0.0577
Epoch 13/199
----------
train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.839, dice=tensor(0.1402, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.839, dice=tensor(0.1402, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.819, dice=tensor(0.2861, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.819, dice=tensor(0.2861, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.854, dice=tensor(0.3628, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.854, dice=tensor(0.3628, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.788, dice=tensor(0.6015, device='cuda:0')]train Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.788, dice=tensor(0.6015, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.8251 Dice: 0.1203
val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.885, dice=tensor(0.3508, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.885, dice=tensor(0.3508, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.874, dice=tensor(0.2099, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.8794 Dice: 0.0420
Epoch 14/199
----------
train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.781, dice=tensor(1.0890, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.781, dice=tensor(1.0890, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.778, dice=tensor(1.3929, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.778, dice=tensor(1.3929, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.783, dice=tensor(1.2328, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.783, dice=tensor(1.2328, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.852, dice=tensor(1.2174, device='cuda:0')]train Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.852, dice=tensor(1.2174, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.7987 Dice: 0.2435
val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.889, dice=tensor(0.0441, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.889, dice=tensor(0.0441, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.894, dice=tensor(0.0636, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.8914 Dice: 0.0127
Epoch 15/199
----------
train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.725, dice=tensor(2.1779, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.725, dice=tensor(2.1779, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.81, dice=tensor(1.9973, device='cuda:0')] train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.81, dice=tensor(1.9973, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.809, dice=tensor(1.7597, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.809, dice=tensor(1.7597, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.74, dice=tensor(1.6952, device='cuda:0')] train Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.74, dice=tensor(1.6952, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                              train Loss: 0.7712 Dice: 0.3390
val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.885, dice=tensor(0.1594, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.885, dice=tensor(0.1594, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.894, dice=tensor(0.2083, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.8896 Dice: 0.0417
Epoch 16/199
----------
train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.816, dice=tensor(1.6167, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.816, dice=tensor(1.6167, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.771, dice=tensor(1.6727, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.771, dice=tensor(1.6727, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.644, dice=tensor(1.8215, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.644, dice=tensor(1.8215, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.69, dice=tensor(1.8605, device='cuda:0')] train Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.69, dice=tensor(1.8605, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                              train Loss: 0.7303 Dice: 0.3721
val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, loss=1, dice=tensor(0.0004, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=1, dice=tensor(0.0004, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.865, dice=tensor(0.1957, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.9350 Dice: 0.0391
Epoch 17/199
----------
train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.65, dice=tensor(2.4743, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.65, dice=tensor(2.4743, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.664, dice=tensor(2.3811, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.664, dice=tensor(2.3811, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.666, dice=tensor(2.1245, device='cuda:0')]train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.666, dice=tensor(2.1245, device='cuda:0')]train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.714, dice=tensor(2.0417, device='cuda:0')]train Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.67it/s, loss=0.714, dice=tensor(2.0417, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.6733 Dice: 0.4083
val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.826, dice=tensor(1.5923, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.826, dice=tensor(1.5923, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.878, dice=tensor(1.2579, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.8518 Dice: 0.2516
Epoch 18/199
----------
train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.607, dice=tensor(2.3839, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.607, dice=tensor(2.3839, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.674, dice=tensor(2.4217, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.674, dice=tensor(2.4217, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.523, dice=tensor(2.4188, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.523, dice=tensor(2.4188, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.484, dice=tensor(2.4477, device='cuda:0')]train Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.484, dice=tensor(2.4477, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.5721 Dice: 0.4895
val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.782, dice=tensor(1.4423, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.782, dice=tensor(1.4423, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.754, dice=tensor(1.7916, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.7677 Dice: 0.3583
Epoch 19/199
----------
train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.45, dice=tensor(2.6785, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.45, dice=tensor(2.6785, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.501, dice=tensor(2.7620, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.501, dice=tensor(2.7620, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.607, dice=tensor(2.4533, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.607, dice=tensor(2.4533, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.429, dice=tensor(2.5651, device='cuda:0')]train Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.429, dice=tensor(2.5651, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.4969 Dice: 0.5130
val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.958, dice=tensor(0.2794, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.958, dice=tensor(0.2794, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.876, dice=tensor(0.4796, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.9170 Dice: 0.0959
Epoch 20/199
----------
train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.481, dice=tensor(2.7443, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.481, dice=tensor(2.7443, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.394, dice=tensor(2.9293, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.394, dice=tensor(2.9293, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.405, dice=tensor(2.9560, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.405, dice=tensor(2.9560, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.493, dice=tensor(2.8227, device='cuda:0')]train Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.493, dice=tensor(2.8227, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.4432 Dice: 0.5645
val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.904, dice=tensor(0.5354, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.904, dice=tensor(0.5354, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.924, dice=tensor(0.5298, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.9138 Dice: 0.1060
Epoch 21/199
----------
train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.591, dice=tensor(2.5676, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.591, dice=tensor(2.5676, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.433, dice=tensor(2.6208, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.433, dice=tensor(2.6208, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.367, dice=tensor(2.8435, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.367, dice=tensor(2.8435, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.4, dice=tensor(2.9342, device='cuda:0')]  train Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.4, dice=tensor(2.9342, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                             train Loss: 0.4479 Dice: 0.5868
val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.903, dice=tensor(0.6064, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.903, dice=tensor(0.6064, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.946, dice=tensor(0.5103, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.9245 Dice: 0.1021
Epoch 22/199
----------
train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4067, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.322, dice=tensor(3.4067, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.438, dice=tensor(3.1601, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.438, dice=tensor(3.1601, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.382, dice=tensor(3.1118, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.382, dice=tensor(3.1118, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.394, dice=tensor(3.1146, device='cuda:0')]train Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.394, dice=tensor(3.1146, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3840 Dice: 0.6229
val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.931, dice=tensor(0.4698, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.931, dice=tensor(0.4698, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.926, dice=tensor(0.4624, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.9285 Dice: 0.0925
Epoch 23/199
----------
train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.497, dice=tensor(2.6836, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.497, dice=tensor(2.6836, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.339, dice=tensor(3.0017, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.339, dice=tensor(3.0017, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.379, dice=tensor(3.0410, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.02it/s, loss=0.379, dice=tensor(3.0410, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.02it/s, loss=0.381, dice=tensor(3.0348, device='cuda:0')]train Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.381, dice=tensor(3.0348, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3991 Dice: 0.6070
val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.98, dice=tensor(0.2187, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.98, dice=tensor(0.2187, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.979, dice=tensor(0.2246, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.9795 Dice: 0.0449
Epoch 24/199
----------
train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.385, dice=tensor(3.0245, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.385, dice=tensor(3.0245, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.365, dice=tensor(3.0666, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.365, dice=tensor(3.0666, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.342, dice=tensor(3.1714, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.342, dice=tensor(3.1714, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.367, dice=tensor(3.1595, device='cuda:0')]train Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.367, dice=tensor(3.1595, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3650 Dice: 0.6319
val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.01, dice=tensor(0.0609, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=1.01, dice=tensor(0.0609, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=1.01, dice=tensor(0.0613, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 1.0129 Dice: 0.0123
Epoch 25/199
----------
train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.405, dice=tensor(3.0519, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.405, dice=tensor(3.0519, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.432, dice=tensor(2.9855, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.432, dice=tensor(2.9855, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.311, dice=tensor(3.1543, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.311, dice=tensor(3.1543, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.37, dice=tensor(3.1233, device='cuda:0')] train Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.37, dice=tensor(3.1233, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                              train Loss: 0.3794 Dice: 0.6247
val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.02, dice=tensor(0.0193, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=1.02, dice=tensor(0.0193, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=1.02, dice=tensor(0.0176, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 1.0217 Dice: 0.0035
Epoch 26/199
----------
train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.383, dice=tensor(2.9850, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.383, dice=tensor(2.9850, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.357, dice=tensor(3.1150, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.357, dice=tensor(3.1150, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.339, dice=tensor(3.2066, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.339, dice=tensor(3.2066, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.388, dice=tensor(3.1537, device='cuda:0')]train Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.388, dice=tensor(3.1537, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3666 Dice: 0.6307
val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.02, dice=tensor(0.0357, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=1.02, dice=tensor(0.0357, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=1.02, dice=tensor(0.0270, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 1.0195 Dice: 0.0054
Epoch 27/199
----------
train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.391, dice=tensor(3.0960, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.391, dice=tensor(3.0960, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.352, dice=tensor(3.2089, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.352, dice=tensor(3.2089, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.396, dice=tensor(3.1414, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.396, dice=tensor(3.1414, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.315, dice=tensor(3.2123, device='cuda:0')]train Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.315, dice=tensor(3.2123, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3634 Dice: 0.6425
val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.01, dice=tensor(0.0619, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=1.01, dice=tensor(0.0619, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=1, dice=tensor(0.0747, device='cuda:0')]   /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                         val Loss: 1.0068 Dice: 0.0149
Epoch 28/199
----------
train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2380, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.352, dice=tensor(3.2380, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.394, dice=tensor(3.1784, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.394, dice=tensor(3.1784, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.394, dice=tensor(3.1042, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.394, dice=tensor(3.1042, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.325, dice=tensor(3.1904, device='cuda:0')]train Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.325, dice=tensor(3.1904, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3662 Dice: 0.6381
val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.986, dice=tensor(0.1601, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.986, dice=tensor(0.1601, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=1, dice=tensor(0.1238, device='cuda:0')]    /home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                         val Loss: 0.9940 Dice: 0.0248
Epoch 29/199
----------
train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.382, dice=tensor(3.0644, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.382, dice=tensor(3.0644, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.35, dice=tensor(3.1547, device='cuda:0')] train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.35, dice=tensor(3.1547, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.35, dice=tensor(3.2142, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.35, dice=tensor(3.2142, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.363, dice=tensor(3.2068, device='cuda:0')]train Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.363, dice=tensor(3.2068, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3613 Dice: 0.6414
val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.929, dice=tensor(0.3790, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.929, dice=tensor(0.3790, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.967, dice=tensor(0.3042, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.9481 Dice: 0.0608
Epoch 30/199
----------
train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.3015, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.36, dice=tensor(3.3015, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.339, dice=tensor(3.3353, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.339, dice=tensor(3.3353, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.315, dice=tensor(3.3482, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.315, dice=tensor(3.3482, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.405, dice=tensor(3.2422, device='cuda:0')]train Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.405, dice=tensor(3.2422, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3549 Dice: 0.6484
val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.954, dice=tensor(0.3166, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.954, dice=tensor(0.3166, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.93, dice=tensor(0.3252, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.9422 Dice: 0.0650
Epoch 31/199
----------
train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4785, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.315, dice=tensor(3.4785, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.364, dice=tensor(3.3264, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.364, dice=tensor(3.3264, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.362, dice=tensor(3.2724, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.362, dice=tensor(3.2724, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.377, dice=tensor(3.2505, device='cuda:0')]train Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.377, dice=tensor(3.2505, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3543 Dice: 0.6501
val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.838, dice=tensor(0.6524, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.838, dice=tensor(0.6524, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.947, dice=tensor(0.4984, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.8924 Dice: 0.0997
Epoch 32/199
----------
train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4360, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.314, dice=tensor(3.4360, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.364, dice=tensor(3.3470, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.364, dice=tensor(3.3470, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.348, dice=tensor(3.3330, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.348, dice=tensor(3.3330, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.384, dice=tensor(3.2778, device='cuda:0')]train Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.384, dice=tensor(3.2778, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3524 Dice: 0.6556
val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.669, dice=tensor(1.4804, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.669, dice=tensor(1.4804, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.843, dice=tensor(1.1398, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.7560 Dice: 0.2280
Epoch 33/199
----------
train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2746, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.35, dice=tensor(3.2746, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.318, dice=tensor(3.3395, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.318, dice=tensor(3.3395, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.341, dice=tensor(3.3422, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.02it/s, loss=0.341, dice=tensor(3.3422, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.02it/s, loss=0.414, dice=tensor(3.2596, device='cuda:0')]train Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.414, dice=tensor(3.2596, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3557 Dice: 0.6519
val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.54, dice=tensor(2.0866, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.54, dice=tensor(2.0866, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.404, dice=tensor(2.6114, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4723 Dice: 0.5223
Epoch 34/199
----------
train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2945, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.336, dice=tensor(3.2945, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.385, dice=tensor(3.2135, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.385, dice=tensor(3.2135, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.342, dice=tensor(3.2491, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.342, dice=tensor(3.2491, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.354, dice=tensor(3.2580, device='cuda:0')]train Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.354, dice=tensor(3.2580, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3543 Dice: 0.6516
val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.773, dice=tensor(0.9690, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.773, dice=tensor(0.9690, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.601, dice=tensor(1.4233, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.6872 Dice: 0.2847
Epoch 35/199
----------
train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1715, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.376, dice=tensor(3.1715, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.354, dice=tensor(3.2178, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.354, dice=tensor(3.2178, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.306, dice=tensor(3.2652, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.306, dice=tensor(3.2652, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.409, dice=tensor(3.1935, device='cuda:0')]train Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.409, dice=tensor(3.1935, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3613 Dice: 0.6387
val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.692, dice=tensor(1.3707, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.692, dice=tensor(1.3707, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.631, dice=tensor(1.4771, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.6611 Dice: 0.2954
Epoch 36/199
----------
train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2899, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.362, dice=tensor(3.2899, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.368, dice=tensor(3.2642, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.368, dice=tensor(3.2642, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.302, dice=tensor(3.3077, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.302, dice=tensor(3.3077, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.37, dice=tensor(3.2755, device='cuda:0')] train Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.37, dice=tensor(3.2755, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                              train Loss: 0.3506 Dice: 0.6551
val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.581, dice=tensor(1.9039, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.91it/s, loss=0.581, dice=tensor(1.9039, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.91it/s, loss=0.514, dice=tensor(2.1325, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.5475 Dice: 0.4265
Epoch 37/199
----------
train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.2639, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.341, dice=tensor(3.2639, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.336, dice=tensor(3.2939, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.336, dice=tensor(3.2939, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.396, dice=tensor(3.2119, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.396, dice=tensor(3.2119, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.336, dice=tensor(3.2440, device='cuda:0')]train Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.336, dice=tensor(3.2440, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3523 Dice: 0.6488
val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.57, dice=tensor(2.0304, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.57, dice=tensor(2.0304, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.544, dice=tensor(2.1543, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.5570 Dice: 0.4309
Epoch 38/199
----------
train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1465, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.369, dice=tensor(3.1465, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.351, dice=tensor(3.2239, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.351, dice=tensor(3.2239, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.333, dice=tensor(3.2807, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.333, dice=tensor(3.2807, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.361, dice=tensor(3.2674, device='cuda:0')]train Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.361, dice=tensor(3.2674, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3535 Dice: 0.6535
val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.606, dice=tensor(1.8606, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.606, dice=tensor(1.8606, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.57, dice=tensor(2.0148, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.5879 Dice: 0.4030
Epoch 39/199
----------
train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.404, dice=tensor(3.0528, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.404, dice=tensor(3.0528, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.334, dice=tensor(3.1842, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.334, dice=tensor(3.1842, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.391, dice=tensor(3.1723, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.391, dice=tensor(3.1723, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.294, dice=tensor(3.2819, device='cuda:0')]train Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.294, dice=tensor(3.2819, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3557 Dice: 0.6564
val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.523, dice=tensor(2.3365, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.523, dice=tensor(2.3365, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.477, dice=tensor(2.5250, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.5002 Dice: 0.5050
Epoch 40/199
----------
train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3051, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.345, dice=tensor(3.3051, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.345, dice=tensor(3.2718, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.345, dice=tensor(3.2718, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.336, dice=tensor(3.3125, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.336, dice=tensor(3.3125, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.346, dice=tensor(3.2929, device='cuda:0')]train Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.346, dice=tensor(3.2929, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3429 Dice: 0.6586
val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.459, dice=tensor(2.7834, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.459, dice=tensor(2.7834, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.573, dice=tensor(2.4681, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.5159 Dice: 0.4936
Epoch 41/199
----------
train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.297, dice=tensor(3.5380, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.297, dice=tensor(3.5380, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.346, dice=tensor(3.4362, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.346, dice=tensor(3.4362, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.341, dice=tensor(3.3723, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.341, dice=tensor(3.3723, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.406, dice=tensor(3.2885, device='cuda:0')]train Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.406, dice=tensor(3.2885, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3475 Dice: 0.6577
val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.531, dice=tensor(2.3466, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.531, dice=tensor(2.3466, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.49, dice=tensor(2.4319, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.5107 Dice: 0.4864
Epoch 42/199
----------
train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1820, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.369, dice=tensor(3.1820, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.278, dice=tensor(3.4177, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.278, dice=tensor(3.4177, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.373, dice=tensor(3.3577, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.373, dice=tensor(3.3577, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.374, dice=tensor(3.3109, device='cuda:0')]train Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.374, dice=tensor(3.3109, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3484 Dice: 0.6622
val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.445, dice=tensor(2.6837, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.445, dice=tensor(2.6837, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.508, dice=tensor(2.5804, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4764 Dice: 0.5161
Epoch 43/199
----------
train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4521, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.305, dice=tensor(3.4521, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.312, dice=tensor(3.4658, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.312, dice=tensor(3.4658, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.37, dice=tensor(3.3702, device='cuda:0')] train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.37, dice=tensor(3.3702, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.383, dice=tensor(3.3158, device='cuda:0')]train Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.383, dice=tensor(3.3158, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3424 Dice: 0.6632
val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.393, dice=tensor(3.1184, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.393, dice=tensor(3.1184, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.426, dice=tensor(2.9364, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.4096 Dice: 0.5873
Epoch 44/199
----------
train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.2607, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.348, dice=tensor(3.2607, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.395, dice=tensor(3.1773, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.395, dice=tensor(3.1773, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.357, dice=tensor(3.1359, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.357, dice=tensor(3.1359, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.304, dice=tensor(3.2156, device='cuda:0')]train Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.304, dice=tensor(3.2156, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3511 Dice: 0.6431
val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.2281, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.341, dice=tensor(3.2281, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.443, dice=tensor(3.0340, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3921 Dice: 0.6068
Epoch 45/199
----------
train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.5689, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.296, dice=tensor(3.5689, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.387, dice=tensor(3.3301, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.387, dice=tensor(3.3301, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.373, dice=tensor(3.2781, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.373, dice=tensor(3.2781, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.361, dice=tensor(3.2439, device='cuda:0')]train Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.361, dice=tensor(3.2439, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3542 Dice: 0.6488
val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.403, dice=tensor(3.0090, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.403, dice=tensor(3.0090, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.406, dice=tensor(2.9947, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4043 Dice: 0.5989
Epoch 46/199
----------
train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3270, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.345, dice=tensor(3.3270, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.405, dice=tensor(3.1678, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.405, dice=tensor(3.1678, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.331, dice=tensor(3.2320, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.331, dice=tensor(3.2320, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.3, dice=tensor(3.2897, device='cuda:0')]  train Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.3, dice=tensor(3.2897, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                             train Loss: 0.3452 Dice: 0.6579
val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.448, dice=tensor(2.8402, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.448, dice=tensor(2.8402, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.377, dice=tensor(2.9643, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.4123 Dice: 0.5929
Epoch 47/199
----------
train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.382, dice=tensor(3.1670, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.382, dice=tensor(3.1670, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.397, dice=tensor(3.1030, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.397, dice=tensor(3.1030, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.296, dice=tensor(3.2408, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.296, dice=tensor(3.2408, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.33, dice=tensor(3.2720, device='cuda:0')] train Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.33, dice=tensor(3.2720, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                              train Loss: 0.3511 Dice: 0.6544
val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.451, dice=tensor(2.7767, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.451, dice=tensor(2.7767, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.366, dice=tensor(2.9989, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.4087 Dice: 0.5998
Epoch 48/199
----------
train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.3732, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.323, dice=tensor(3.3732, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.337, dice=tensor(3.3275, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.337, dice=tensor(3.3275, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.419, dice=tensor(3.1716, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.419, dice=tensor(3.1716, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.344, dice=tensor(3.1855, device='cuda:0')]train Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.344, dice=tensor(3.1855, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3558 Dice: 0.6371
val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.423, dice=tensor(2.9329, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.423, dice=tensor(2.9329, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.4, dice=tensor(2.9769, device='cuda:0')]  /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                           val Loss: 0.4112 Dice: 0.5954
Epoch 49/199
----------
train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1794, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.366, dice=tensor(3.1794, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.306, dice=tensor(3.3484, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.306, dice=tensor(3.3484, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.353, dice=tensor(3.3192, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.353, dice=tensor(3.3192, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.369, dice=tensor(3.2965, device='cuda:0')]train Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.369, dice=tensor(3.2965, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3484 Dice: 0.6593
val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.417, dice=tensor(2.9352, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.417, dice=tensor(2.9352, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.432, dice=tensor(2.9133, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.4241 Dice: 0.5827
Epoch 50/199
----------
train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3325, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.339, dice=tensor(3.3325, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.317, dice=tensor(3.3983, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.317, dice=tensor(3.3983, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.422, dice=tensor(3.2441, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.422, dice=tensor(3.2441, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.315, dice=tensor(3.2795, device='cuda:0')]train Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.315, dice=tensor(3.2795, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3483 Dice: 0.6559
val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.425, dice=tensor(2.9546, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.29it/s, loss=0.425, dice=tensor(2.9546, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.29it/s, loss=0.38, dice=tensor(3.0133, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.4025 Dice: 0.6027
Epoch 51/199
----------
train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2616, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.362, dice=tensor(3.2616, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.306, dice=tensor(3.2793, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.306, dice=tensor(3.2793, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.355, dice=tensor(3.2915, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.355, dice=tensor(3.2915, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.363, dice=tensor(3.2436, device='cuda:0')]train Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.363, dice=tensor(3.2436, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3466 Dice: 0.6487
val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.2165, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.376, dice=tensor(3.2165, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.408, dice=tensor(3.0723, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3922 Dice: 0.6145
Epoch 52/199
----------
train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.2005, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.367, dice=tensor(3.2005, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.327, dice=tensor(3.2961, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.18it/s, loss=0.327, dice=tensor(3.2961, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.18it/s, loss=0.358, dice=tensor(3.2636, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.07it/s, loss=0.358, dice=tensor(3.2636, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.07it/s, loss=0.324, dice=tensor(3.2970, device='cuda:0')]train Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.70it/s, loss=0.324, dice=tensor(3.2970, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3441 Dice: 0.6594
val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.422, dice=tensor(2.9869, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.422, dice=tensor(2.9869, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.388, dice=tensor(3.0190, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.4051 Dice: 0.6038
Epoch 53/199
----------
train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.309, dice=tensor(3.5153, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.309, dice=tensor(3.5153, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.363, dice=tensor(3.3626, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.363, dice=tensor(3.3626, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.326, dice=tensor(3.3656, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.326, dice=tensor(3.3656, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.446, dice=tensor(3.2431, device='cuda:0')]train Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.446, dice=tensor(3.2431, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3612 Dice: 0.6486
val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.1529, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.394, dice=tensor(3.1529, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.413, dice=tensor(3.0353, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4035 Dice: 0.6071
Epoch 54/199
----------
train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.2783, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.342, dice=tensor(3.2783, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.417, dice=tensor(3.0926, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.417, dice=tensor(3.0926, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.308, dice=tensor(3.1520, device='cuda:0')]train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.308, dice=tensor(3.1520, device='cuda:0')]train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.35, dice=tensor(3.1993, device='cuda:0')] train Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.35, dice=tensor(3.1993, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                              train Loss: 0.3543 Dice: 0.6399
val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.47, dice=tensor(2.7513, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.47, dice=tensor(2.7513, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.443, dice=tensor(2.8009, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4565 Dice: 0.5602
Epoch 55/199
----------
train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.3084, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.356, dice=tensor(3.3084, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.33, dice=tensor(3.3512, device='cuda:0')] train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.33, dice=tensor(3.3512, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.352, dice=tensor(3.3126, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.352, dice=tensor(3.3126, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.308, dice=tensor(3.2980, device='cuda:0')]train Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.308, dice=tensor(3.2980, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3367 Dice: 0.6596
val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.431, dice=tensor(3.0216, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.431, dice=tensor(3.0216, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.516, dice=tensor(2.7400, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.4733 Dice: 0.5480
Epoch 56/199
----------
train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4759, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.306, dice=tensor(3.4759, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.369, dice=tensor(3.3670, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.369, dice=tensor(3.3670, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.38, dice=tensor(3.2857, device='cuda:0')] train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.38, dice=tensor(3.2857, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.316, dice=tensor(3.3230, device='cuda:0')]train Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.316, dice=tensor(3.3230, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3428 Dice: 0.6646
val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.477, dice=tensor(2.7176, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.477, dice=tensor(2.7176, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.498, dice=tensor(2.6814, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4875 Dice: 0.5363
Epoch 57/199
----------
train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.2725, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.342, dice=tensor(3.2725, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.336, dice=tensor(3.3269, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.336, dice=tensor(3.3269, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.343, dice=tensor(3.3064, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.343, dice=tensor(3.3064, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.323, dice=tensor(3.3248, device='cuda:0')]train Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.323, dice=tensor(3.3248, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3361 Dice: 0.6650
val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.483, dice=tensor(2.7415, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.483, dice=tensor(2.7415, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.463, dice=tensor(2.7523, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4730 Dice: 0.5505
Epoch 58/199
----------
train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3438, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.329, dice=tensor(3.3438, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.329, dice=tensor(3.3569, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.329, dice=tensor(3.3569, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.312, dice=tensor(3.3897, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.312, dice=tensor(3.3897, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.369, dice=tensor(3.3345, device='cuda:0')]train Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.369, dice=tensor(3.3345, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3346 Dice: 0.6669
val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.433, dice=tensor(2.8481, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.433, dice=tensor(2.8481, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.441, dice=tensor(2.8931, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4370 Dice: 0.5786
Epoch 59/199
----------
train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3415, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.329, dice=tensor(3.3415, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.373, dice=tensor(3.2647, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.373, dice=tensor(3.2647, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.328, dice=tensor(3.2817, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.328, dice=tensor(3.2817, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.321, dice=tensor(3.3041, device='cuda:0')]train Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.321, dice=tensor(3.3041, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3378 Dice: 0.6608
val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.408, dice=tensor(2.9988, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.408, dice=tensor(2.9988, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.437, dice=tensor(2.9602, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4227 Dice: 0.5920
Epoch 60/199
----------
train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.1873, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.357, dice=tensor(3.1873, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.345, dice=tensor(3.2632, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.345, dice=tensor(3.2632, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.365, dice=tensor(3.2439, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.365, dice=tensor(3.2439, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.308, dice=tensor(3.2937, device='cuda:0')]train Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.308, dice=tensor(3.2937, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3439 Dice: 0.6587
val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.414, dice=tensor(2.9954, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.414, dice=tensor(2.9954, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.397, dice=tensor(3.0406, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4054 Dice: 0.6081
Epoch 61/199
----------
train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1371, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.376, dice=tensor(3.1371, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.301, dice=tensor(3.3431, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.301, dice=tensor(3.3431, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.309, dice=tensor(3.3786, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.309, dice=tensor(3.3786, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.381, dice=tensor(3.3248, device='cuda:0')]train Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.381, dice=tensor(3.3248, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3418 Dice: 0.6650
val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.406, dice=tensor(3.0832, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.406, dice=tensor(3.0832, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.35, dice=tensor(3.1478, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.3782 Dice: 0.6296
Epoch 62/199
----------
train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.5084, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.308, dice=tensor(3.5084, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.32, dice=tensor(3.4517, device='cuda:0')] train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.32, dice=tensor(3.4517, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.371, dice=tensor(3.3501, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.371, dice=tensor(3.3501, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.373, dice=tensor(3.3210, device='cuda:0')]train Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.373, dice=tensor(3.3210, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3428 Dice: 0.6642
val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1761, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.379, dice=tensor(3.1761, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.378, dice=tensor(3.1476, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3787 Dice: 0.6295
Epoch 63/199
----------
train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.0973, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.389, dice=tensor(3.0973, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.388, dice=tensor(3.1198, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.388, dice=tensor(3.1198, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.32, dice=tensor(3.2018, device='cuda:0')] train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.32, dice=tensor(3.2018, device='cuda:0')]train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.269, dice=tensor(3.3263, device='cuda:0')]train Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.269, dice=tensor(3.3263, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3414 Dice: 0.6653
val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.393, dice=tensor(3.0468, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.393, dice=tensor(3.0468, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.373, dice=tensor(3.1352, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3826 Dice: 0.6270
Epoch 64/199
----------
train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.2855, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.342, dice=tensor(3.2855, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.331, dice=tensor(3.3318, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.331, dice=tensor(3.3318, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.342, dice=tensor(3.3307, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.342, dice=tensor(3.3307, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.319, dice=tensor(3.3424, device='cuda:0')]train Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.319, dice=tensor(3.3424, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3337 Dice: 0.6685
val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1615, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.363, dice=tensor(3.1615, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.396, dice=tensor(3.1461, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3795 Dice: 0.6292
Epoch 65/199
----------
train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3834, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.334, dice=tensor(3.3834, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.383, dice=tensor(3.2683, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.383, dice=tensor(3.2683, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.305, dice=tensor(3.3382, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.305, dice=tensor(3.3382, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.342, dice=tensor(3.3420, device='cuda:0')]train Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.342, dice=tensor(3.3420, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3409 Dice: 0.6684
val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.4661, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.317, dice=tensor(3.4661, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.436, dice=tensor(3.1581, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3764 Dice: 0.6316
Epoch 66/199
----------
train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3507, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.333, dice=tensor(3.3507, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.314, dice=tensor(3.4090, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.314, dice=tensor(3.4090, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.348, dice=tensor(3.3437, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.348, dice=tensor(3.3437, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.354, dice=tensor(3.3182, device='cuda:0')]train Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.354, dice=tensor(3.3182, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3373 Dice: 0.6636
val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.2517, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.365, dice=tensor(3.2517, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.386, dice=tensor(3.1659, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3755 Dice: 0.6332
Epoch 67/199
----------
train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.2339, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.364, dice=tensor(3.2339, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.324, dice=tensor(3.2600, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.324, dice=tensor(3.2600, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.343, dice=tensor(3.2893, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.343, dice=tensor(3.2893, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.301, dice=tensor(3.3467, device='cuda:0')]train Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.301, dice=tensor(3.3467, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3328 Dice: 0.6693
val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1521, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.366, dice=tensor(3.1521, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.384, dice=tensor(3.1634, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3754 Dice: 0.6327
Epoch 68/199
----------
train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3245, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.341, dice=tensor(3.3245, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.312, dice=tensor(3.3838, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.312, dice=tensor(3.3838, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.322, dice=tensor(3.3971, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.322, dice=tensor(3.3971, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.334, dice=tensor(3.3718, device='cuda:0')]train Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.334, dice=tensor(3.3718, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3273 Dice: 0.6744
val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1886, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.377, dice=tensor(3.1886, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.38, dice=tensor(3.1517, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.3786 Dice: 0.6303
Epoch 69/199
----------
train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2549, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.343, dice=tensor(3.2549, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.352, dice=tensor(3.2879, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.352, dice=tensor(3.2879, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.287, dice=tensor(3.3838, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.287, dice=tensor(3.3838, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.381, dice=tensor(3.3182, device='cuda:0')]train Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.381, dice=tensor(3.3182, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3409 Dice: 0.6636
val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.0375, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.389, dice=tensor(3.0375, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.354, dice=tensor(3.1714, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3716 Dice: 0.6343
Epoch 70/199
----------
train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4222, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.318, dice=tensor(3.4222, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.307, dice=tensor(3.4065, device='cuda:0')]train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.307, dice=tensor(3.4065, device='cuda:0')]train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.37, dice=tensor(3.3286, device='cuda:0')] train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.37, dice=tensor(3.3286, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.361, dice=tensor(3.3040, device='cuda:0')]train Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.361, dice=tensor(3.3040, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3391 Dice: 0.6608
val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.388, dice=tensor(3.0389, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.388, dice=tensor(3.0389, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.359, dice=tensor(3.1635, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3735 Dice: 0.6327
Epoch 71/199
----------
train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3538, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.332, dice=tensor(3.3538, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.324, dice=tensor(3.3800, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.324, dice=tensor(3.3800, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.334, dice=tensor(3.3781, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.334, dice=tensor(3.3781, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.323, dice=tensor(3.3715, device='cuda:0')]train Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.323, dice=tensor(3.3715, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3284 Dice: 0.6743
val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.396, dice=tensor(3.0286, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.396, dice=tensor(3.0286, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.355, dice=tensor(3.1569, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3753 Dice: 0.6314
Epoch 72/199
----------
train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3482, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.324, dice=tensor(3.3482, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.356, dice=tensor(3.2947, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.356, dice=tensor(3.2947, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.314, dice=tensor(3.3443, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.314, dice=tensor(3.3443, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.369, dice=tensor(3.3116, device='cuda:0')]train Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.369, dice=tensor(3.3116, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3407 Dice: 0.6623
val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2941, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.353, dice=tensor(3.2941, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.397, dice=tensor(3.1620, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3754 Dice: 0.6324
Epoch 73/199
----------
train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.383, dice=tensor(3.1570, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.383, dice=tensor(3.1570, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.308, dice=tensor(3.3319, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.308, dice=tensor(3.3319, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.335, dice=tensor(3.3236, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.61it/s, loss=0.335, dice=tensor(3.3236, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.32, dice=tensor(3.3148, device='cuda:0')] train Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.31it/s, loss=0.32, dice=tensor(3.3148, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                              train Loss: 0.3364 Dice: 0.6630
val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.424, dice=tensor(2.8980, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.424, dice=tensor(2.8980, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.331, dice=tensor(3.1475, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3772 Dice: 0.6295
Epoch 74/199
----------
train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3301, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.348, dice=tensor(3.3301, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.28, dice=tensor(3.4515, device='cuda:0')] train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.28, dice=tensor(3.4515, device='cuda:0')]train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.316, dice=tensor(3.4398, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.316, dice=tensor(3.4398, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.387, dice=tensor(3.3466, device='cuda:0')]train Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.387, dice=tensor(3.3466, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3325 Dice: 0.6693
val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.435, dice=tensor(2.8585, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.435, dice=tensor(2.8585, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.322, dice=tensor(3.1542, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3786 Dice: 0.6308
Epoch 75/199
----------
train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.273, dice=tensor(3.7084, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.41it/s, loss=0.273, dice=tensor(3.7084, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.41it/s, loss=0.35, dice=tensor(3.5016, device='cuda:0')] train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.58it/s, loss=0.35, dice=tensor(3.5016, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.58it/s, loss=0.426, dice=tensor(3.2889, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.52it/s, loss=0.426, dice=tensor(3.2889, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.52it/s, loss=0.331, dice=tensor(3.3139, device='cuda:0')]train Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.24it/s, loss=0.331, dice=tensor(3.3139, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3450 Dice: 0.6628
val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.4247, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.325, dice=tensor(3.4247, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.428, dice=tensor(3.1634, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3766 Dice: 0.6327
Epoch 76/199
----------
train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3829, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.328, dice=tensor(3.3829, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.325, dice=tensor(3.3534, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.325, dice=tensor(3.3534, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.354, dice=tensor(3.3255, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.354, dice=tensor(3.3255, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.332, dice=tensor(3.3365, device='cuda:0')]train Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.332, dice=tensor(3.3365, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3348 Dice: 0.6673
val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.1870, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.356, dice=tensor(3.1870, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.39, dice=tensor(3.1644, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.3730 Dice: 0.6329
Epoch 77/199
----------
train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.2584, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.368, dice=tensor(3.2584, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.354, dice=tensor(3.2531, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.354, dice=tensor(3.2531, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.303, dice=tensor(3.3246, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.303, dice=tensor(3.3246, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.294, dice=tensor(3.3673, device='cuda:0')]train Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.294, dice=tensor(3.3673, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3300 Dice: 0.6735
val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.1332, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.374, dice=tensor(3.1332, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.377, dice=tensor(3.1575, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3754 Dice: 0.6315
Epoch 78/199
----------
train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.1841, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.354, dice=tensor(3.1841, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.293, dice=tensor(3.3586, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.293, dice=tensor(3.3586, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.369, dice=tensor(3.3187, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.369, dice=tensor(3.3187, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.334, dice=tensor(3.3271, device='cuda:0')]train Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.334, dice=tensor(3.3271, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3372 Dice: 0.6654
val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.407, dice=tensor(2.9577, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.407, dice=tensor(2.9577, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.34, dice=tensor(3.1677, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                            val Loss: 0.3734 Dice: 0.6335
Epoch 79/199
----------
train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5477, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.29, dice=tensor(3.5477, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.33, dice=tensor(3.4279, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.33, dice=tensor(3.4279, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.34, dice=tensor(3.4100, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.34, dice=tensor(3.4100, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.411, dice=tensor(3.2817, device='cuda:0')]train Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.411, dice=tensor(3.2817, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3428 Dice: 0.6563
val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2941, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.353, dice=tensor(3.2941, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.389, dice=tensor(3.1803, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3712 Dice: 0.6361
Epoch 80/199
----------
train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4263, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.32, dice=tensor(3.4263, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.347, dice=tensor(3.3422, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.347, dice=tensor(3.3422, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.366, dice=tensor(3.3130, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.366, dice=tensor(3.3130, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.302, dice=tensor(3.3529, device='cuda:0')]train Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.302, dice=tensor(3.3529, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3336 Dice: 0.6706
val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.382, dice=tensor(3.0979, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.382, dice=tensor(3.0979, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.357, dice=tensor(3.1856, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3697 Dice: 0.6371
Epoch 81/199
----------
train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2934, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.352, dice=tensor(3.2934, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.321, dice=tensor(3.2552, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.321, dice=tensor(3.2552, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.328, dice=tensor(3.2907, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.10it/s, loss=0.328, dice=tensor(3.2907, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.10it/s, loss=0.318, dice=tensor(3.3311, device='cuda:0')]train Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.72it/s, loss=0.318, dice=tensor(3.3311, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3300 Dice: 0.6662
val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.403, dice=tensor(3.0651, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.403, dice=tensor(3.0651, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.331, dice=tensor(3.1806, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3670 Dice: 0.6361
Epoch 82/199
----------
train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4932, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.305, dice=tensor(3.4932, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.331, dice=tensor(3.3890, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.331, dice=tensor(3.3890, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.302, dice=tensor(3.4350, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.302, dice=tensor(3.4350, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.388, dice=tensor(3.3533, device='cuda:0')]train Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.388, dice=tensor(3.3533, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3315 Dice: 0.6707
val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.2941, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.332, dice=tensor(3.2941, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.406, dice=tensor(3.1731, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3690 Dice: 0.6346
Epoch 83/199
----------
train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.298, dice=tensor(3.4758, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.298, dice=tensor(3.4758, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.346, dice=tensor(3.3865, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.346, dice=tensor(3.3865, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.348, dice=tensor(3.3668, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.348, dice=tensor(3.3668, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.313, dice=tensor(3.3894, device='cuda:0')]train Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.313, dice=tensor(3.3894, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3264 Dice: 0.6779
val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.0971, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.374, dice=tensor(3.0971, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.374, dice=tensor(3.1547, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3744 Dice: 0.6309
Epoch 84/199
----------
train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.347, dice=tensor(3.2289, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.347, dice=tensor(3.2289, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.317, dice=tensor(3.2656, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.317, dice=tensor(3.2656, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.346, dice=tensor(3.2605, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.346, dice=tensor(3.2605, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.337, dice=tensor(3.2866, device='cuda:0')]train Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.337, dice=tensor(3.2866, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3368 Dice: 0.6573
val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.0983, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.377, dice=tensor(3.0983, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.388, dice=tensor(3.1225, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3825 Dice: 0.6245
Epoch 85/199
----------
train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3538, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.329, dice=tensor(3.3538, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.325, dice=tensor(3.3689, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.325, dice=tensor(3.3689, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.318, dice=tensor(3.3799, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.318, dice=tensor(3.3799, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.339, dice=tensor(3.3744, device='cuda:0')]train Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.339, dice=tensor(3.3744, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3278 Dice: 0.6749
val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2164, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.356, dice=tensor(3.2164, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.411, dice=tensor(3.1221, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3836 Dice: 0.6244
Epoch 86/199
----------
train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2248, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.352, dice=tensor(3.2248, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.364, dice=tensor(3.2040, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.364, dice=tensor(3.2040, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.307, dice=tensor(3.2841, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.307, dice=tensor(3.2841, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.315, dice=tensor(3.3224, device='cuda:0')]train Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.315, dice=tensor(3.3224, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3345 Dice: 0.6645
val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.402, dice=tensor(3.0306, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.402, dice=tensor(3.0306, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.364, dice=tensor(3.1342, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3832 Dice: 0.6268
Epoch 87/199
----------
train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3320, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.338, dice=tensor(3.3320, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.343, dice=tensor(3.2891, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.343, dice=tensor(3.2891, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.322, dice=tensor(3.3196, device='cuda:0')]train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.322, dice=tensor(3.3196, device='cuda:0')]train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.305, dice=tensor(3.3664, device='cuda:0')]train Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.305, dice=tensor(3.3664, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3270 Dice: 0.6733
val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.3144, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.353, dice=tensor(3.3144, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.387, dice=tensor(3.1849, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3699 Dice: 0.6370
Epoch 88/199
----------
train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2549, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.358, dice=tensor(3.2549, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.333, dice=tensor(3.3150, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.333, dice=tensor(3.3150, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.272, dice=tensor(3.4058, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.272, dice=tensor(3.4058, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.34, dice=tensor(3.3828, device='cuda:0')] train Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.34, dice=tensor(3.3828, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                              train Loss: 0.3256 Dice: 0.6766
val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4406, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.323, dice=tensor(3.4406, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.42, dice=tensor(3.1951, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.3714 Dice: 0.6390
Epoch 89/199
----------
train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2314, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.351, dice=tensor(3.2314, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.317, dice=tensor(3.2452, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.317, dice=tensor(3.2452, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.334, dice=tensor(3.2892, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.334, dice=tensor(3.2892, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.318, dice=tensor(3.3241, device='cuda:0')]train Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.318, dice=tensor(3.3241, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3301 Dice: 0.6648
val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.1005, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.384, dice=tensor(3.1005, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.347, dice=tensor(3.2085, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3654 Dice: 0.6417
Epoch 90/199
----------
train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4312, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.315, dice=tensor(3.4312, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.295, dice=tensor(3.4796, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.295, dice=tensor(3.4796, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.363, dice=tensor(3.3899, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.363, dice=tensor(3.3899, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.335, dice=tensor(3.3676, device='cuda:0')]train Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.335, dice=tensor(3.3676, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3270 Dice: 0.6735
val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.3026, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.352, dice=tensor(3.3026, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.378, dice=tensor(3.2080, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3653 Dice: 0.6416
Epoch 91/199
----------
train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.2554, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.324, dice=tensor(3.2554, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.364, dice=tensor(3.2439, device='cuda:0')]train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.364, dice=tensor(3.2439, device='cuda:0')]train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.329, dice=tensor(3.2980, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.329, dice=tensor(3.2980, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.324, dice=tensor(3.3054, device='cuda:0')]train Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.324, dice=tensor(3.3054, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3349 Dice: 0.6611
val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.382, dice=tensor(3.1725, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.382, dice=tensor(3.1725, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.342, dice=tensor(3.2112, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3621 Dice: 0.6422
Epoch 92/199
----------
train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1108, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.378, dice=tensor(3.1108, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.331, dice=tensor(3.1909, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.12it/s, loss=0.331, dice=tensor(3.1909, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.12it/s, loss=0.307, dice=tensor(3.2688, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.307, dice=tensor(3.2688, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.303, dice=tensor(3.3221, device='cuda:0')]train Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.303, dice=tensor(3.3221, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3296 Dice: 0.6644
val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3683, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.341, dice=tensor(3.3683, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.396, dice=tensor(3.1973, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3684 Dice: 0.6395
Epoch 93/199
----------
train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4125, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.311, dice=tensor(3.4125, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.275, dice=tensor(3.5206, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.275, dice=tensor(3.5206, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.348, dice=tensor(3.4422, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.348, dice=tensor(3.4422, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.375, dice=tensor(3.3752, device='cuda:0')]train Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.375, dice=tensor(3.3752, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3270 Dice: 0.6750
val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.4093, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.329, dice=tensor(3.4093, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.412, dice=tensor(3.1893, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3708 Dice: 0.6379
Epoch 94/199
----------
train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2112, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.363, dice=tensor(3.2112, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.348, dice=tensor(3.2647, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.348, dice=tensor(3.2647, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.281, dice=tensor(3.3753, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.281, dice=tensor(3.3753, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.316, dice=tensor(3.3908, device='cuda:0')]train Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.316, dice=tensor(3.3908, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3270 Dice: 0.6782
val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.383, dice=tensor(3.0922, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.383, dice=tensor(3.0922, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.358, dice=tensor(3.1893, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3705 Dice: 0.6379
Epoch 95/199
----------
train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.4855, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.90it/s, loss=0.307, dice=tensor(3.4855, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.90it/s, loss=0.284, dice=tensor(3.5312, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.19it/s, loss=0.284, dice=tensor(3.5312, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.19it/s, loss=0.366, dice=tensor(3.4182, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.09it/s, loss=0.366, dice=tensor(3.4182, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.09it/s, loss=0.363, dice=tensor(3.3597, device='cuda:0')]train Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.71it/s, loss=0.363, dice=tensor(3.3597, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3300 Dice: 0.6719
val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.416, dice=tensor(2.9636, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.416, dice=tensor(2.9636, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.327, dice=tensor(3.1935, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3712 Dice: 0.6387
Epoch 96/199
----------
train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.0420, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.398, dice=tensor(3.0420, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.307, dice=tensor(3.2614, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.307, dice=tensor(3.2614, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.314, dice=tensor(3.3218, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.314, dice=tensor(3.3218, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.337, dice=tensor(3.3076, device='cuda:0')]train Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.337, dice=tensor(3.3076, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3390 Dice: 0.6615
val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1091, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.378, dice=tensor(3.1091, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.353, dice=tensor(3.2060, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3657 Dice: 0.6412
Epoch 97/199
----------
train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4185, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.326, dice=tensor(3.4185, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.261, dice=tensor(3.5288, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.261, dice=tensor(3.5288, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.339, dice=tensor(3.4754, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.339, dice=tensor(3.4754, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.367, dice=tensor(3.4073, device='cuda:0')]train Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.31it/s, loss=0.367, dice=tensor(3.4073, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3234 Dice: 0.6815
val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.407, dice=tensor(2.9962, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.407, dice=tensor(2.9962, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.327, dice=tensor(3.2095, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3666 Dice: 0.6419
Epoch 98/199
----------
train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.3998, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.307, dice=tensor(3.3998, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.363, dice=tensor(3.2776, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.363, dice=tensor(3.2776, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.329, dice=tensor(3.2994, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.329, dice=tensor(3.2994, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.331, dice=tensor(3.3122, device='cuda:0')]train Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.331, dice=tensor(3.3122, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3328 Dice: 0.6624
val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.1147, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.374, dice=tensor(3.1147, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.354, dice=tensor(3.2123, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3641 Dice: 0.6425
Epoch 99/199
----------
train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.3609, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.317, dice=tensor(3.3609, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.291, dice=tensor(3.4701, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.291, dice=tensor(3.4701, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.358, dice=tensor(3.4168, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.358, dice=tensor(3.4168, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.348, dice=tensor(3.3881, device='cuda:0')]train Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.348, dice=tensor(3.3881, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3285 Dice: 0.6776
val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3469, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.344, dice=tensor(3.3469, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.93it/s, loss=0.388, dice=tensor(3.2114, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3656 Dice: 0.6423
Epoch 100/199
----------
train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.279, dice=tensor(3.5211, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.279, dice=tensor(3.5211, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.329, dice=tensor(3.4105, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.329, dice=tensor(3.4105, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.34, dice=tensor(3.3853, device='cuda:0')] train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.34, dice=tensor(3.3853, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.347, dice=tensor(3.3640, device='cuda:0')]train Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.347, dice=tensor(3.3640, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3237 Dice: 0.6728
val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0685, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.39, dice=tensor(3.0685, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.341, dice=tensor(3.2153, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3654 Dice: 0.6431
Epoch 101/199
----------
train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.4403, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.319, dice=tensor(3.4403, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.362, dice=tensor(3.3258, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.362, dice=tensor(3.3258, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.335, dice=tensor(3.3042, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.335, dice=tensor(3.3042, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.302, dice=tensor(3.3436, device='cuda:0')]train Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.302, dice=tensor(3.3436, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3295 Dice: 0.6687
val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2931, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.356, dice=tensor(3.2931, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.369, dice=tensor(3.2206, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3622 Dice: 0.6441
Epoch 102/199
----------
train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.347, dice=tensor(3.2166, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.347, dice=tensor(3.2166, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.334, dice=tensor(3.2783, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.334, dice=tensor(3.2783, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.295, dice=tensor(3.3642, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.295, dice=tensor(3.3642, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.319, dice=tensor(3.3762, device='cuda:0')]train Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.28it/s, loss=0.319, dice=tensor(3.3762, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3236 Dice: 0.6752
val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.1763, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.36, dice=tensor(3.1763, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.361, dice=tensor(3.2242, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3606 Dice: 0.6448
Epoch 103/199
----------
train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.4387, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.304, dice=tensor(3.4387, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.385, dice=tensor(3.2924, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.385, dice=tensor(3.2924, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.308, dice=tensor(3.3581, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.308, dice=tensor(3.3581, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.308, dice=tensor(3.4009, device='cuda:0')]train Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.308, dice=tensor(3.4009, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3262 Dice: 0.6802
val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.413, dice=tensor(2.9541, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.413, dice=tensor(2.9541, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.307, dice=tensor(3.2254, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3599 Dice: 0.6451
Epoch 104/199
----------
train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3742, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.332, dice=tensor(3.3742, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.344, dice=tensor(3.3435, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.344, dice=tensor(3.3435, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.297, dice=tensor(3.3904, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.297, dice=tensor(3.3904, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.307, dice=tensor(3.4007, device='cuda:0')]train Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.307, dice=tensor(3.4007, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3198 Dice: 0.6801
val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1922, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.38, dice=tensor(3.1922, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.34, dice=tensor(3.2272, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3597 Dice: 0.6454
Epoch 105/199
----------
train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2487, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.352, dice=tensor(3.2487, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.326, dice=tensor(3.3260, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.326, dice=tensor(3.3260, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.337, dice=tensor(3.3235, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.337, dice=tensor(3.3235, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.287, dice=tensor(3.3879, device='cuda:0')]train Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.287, dice=tensor(3.3879, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3253 Dice: 0.6776
val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0654, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.39, dice=tensor(3.0654, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.332, dice=tensor(3.2273, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3607 Dice: 0.6455
Epoch 106/199
----------
train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3582, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.333, dice=tensor(3.3582, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.305, dice=tensor(3.3578, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.305, dice=tensor(3.3578, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.333, dice=tensor(3.3587, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.333, dice=tensor(3.3587, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.327, dice=tensor(3.3735, device='cuda:0')]train Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.327, dice=tensor(3.3735, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3245 Dice: 0.6747
val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.412, dice=tensor(2.9789, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.412, dice=tensor(2.9789, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.313, dice=tensor(3.2252, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3624 Dice: 0.6450
Epoch 107/199
----------
train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.5462, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.293, dice=tensor(3.5462, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.366, dice=tensor(3.3510, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.366, dice=tensor(3.3510, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.328, dice=tensor(3.3565, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.328, dice=tensor(3.3565, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.307, dice=tensor(3.3833, device='cuda:0')]train Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.307, dice=tensor(3.3833, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3234 Dice: 0.6767
val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3977, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.329, dice=tensor(3.3977, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.393, dice=tensor(3.2267, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3614 Dice: 0.6453
Epoch 108/199
----------
train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3699, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.327, dice=tensor(3.3699, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.28, dice=tensor(3.4974, device='cuda:0')] train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.28, dice=tensor(3.4974, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.315, dice=tensor(3.4869, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.315, dice=tensor(3.4869, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.377, dice=tensor(3.3947, device='cuda:0')]train Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.377, dice=tensor(3.3947, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3247 Dice: 0.6789
val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.1615, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.364, dice=tensor(3.1615, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.357, dice=tensor(3.2242, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3605 Dice: 0.6448
Epoch 109/199
----------
train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2977, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.345, dice=tensor(3.2977, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.324, dice=tensor(3.3441, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.324, dice=tensor(3.3441, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.288, dice=tensor(3.4282, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.288, dice=tensor(3.4282, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.336, dice=tensor(3.3942, device='cuda:0')]train Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.336, dice=tensor(3.3942, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3233 Dice: 0.6788
val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.385, dice=tensor(3.0590, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.385, dice=tensor(3.0590, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.335, dice=tensor(3.2241, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3600 Dice: 0.6448
Epoch 110/199
----------
train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3277, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.339, dice=tensor(3.3277, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.312, dice=tensor(3.3829, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.312, dice=tensor(3.3829, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.317, dice=tensor(3.4065, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.317, dice=tensor(3.4065, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.307, dice=tensor(3.4133, device='cuda:0')]train Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.307, dice=tensor(3.4133, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3188 Dice: 0.6827
val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.5095, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.308, dice=tensor(3.5095, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.418, dice=tensor(3.2264, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3629 Dice: 0.6453
Epoch 111/199
----------
train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2680, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.353, dice=tensor(3.2680, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.305, dice=tensor(3.3765, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.305, dice=tensor(3.3765, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.308, dice=tensor(3.4017, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.308, dice=tensor(3.4017, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.313, dice=tensor(3.4040, device='cuda:0')]train Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.313, dice=tensor(3.4040, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3195 Dice: 0.6808
val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2697, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.358, dice=tensor(3.2697, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.363, dice=tensor(3.2273, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3603 Dice: 0.6455
Epoch 112/199
----------
train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3153, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.346, dice=tensor(3.3153, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.332, dice=tensor(3.3372, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.332, dice=tensor(3.3372, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.283, dice=tensor(3.4023, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.283, dice=tensor(3.4023, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.316, dice=tensor(3.4074, device='cuda:0')]train Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.316, dice=tensor(3.4074, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3193 Dice: 0.6815
val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3559, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.343, dice=tensor(3.3559, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.377, dice=tensor(3.2290, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3600 Dice: 0.6458
Epoch 113/199
----------
train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3696, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.327, dice=tensor(3.3696, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.314, dice=tensor(3.4039, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.12it/s, loss=0.314, dice=tensor(3.4039, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.12it/s, loss=0.311, dice=tensor(3.4205, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.02it/s, loss=0.311, dice=tensor(3.4205, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.02it/s, loss=0.308, dice=tensor(3.4259, device='cuda:0')]train Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.308, dice=tensor(3.4259, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3151 Dice: 0.6852
val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.3100, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.354, dice=tensor(3.3100, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.365, dice=tensor(3.2333, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3592 Dice: 0.6467
Epoch 114/199
----------
train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.5586, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.291, dice=tensor(3.5586, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.328, dice=tensor(3.4559, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.328, dice=tensor(3.4559, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.312, dice=tensor(3.4508, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.312, dice=tensor(3.4508, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.335, dice=tensor(3.4227, device='cuda:0')]train Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.335, dice=tensor(3.4227, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3166 Dice: 0.6845
val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.5252, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.303, dice=tensor(3.5252, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.416, dice=tensor(3.2347, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3594 Dice: 0.6469
Epoch 115/199
----------
train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.31, dice=tensor(3.4438, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.31, dice=tensor(3.4438, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.349, dice=tensor(3.3607, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.349, dice=tensor(3.3607, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.292, dice=tensor(3.4258, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.292, dice=tensor(3.4258, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.348, dice=tensor(3.4034, device='cuda:0')]train Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.348, dice=tensor(3.4034, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3249 Dice: 0.6807
val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.372, dice=tensor(3.1317, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.372, dice=tensor(3.1317, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.346, dice=tensor(3.2347, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3592 Dice: 0.6469
Epoch 116/199
----------
train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4518, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.316, dice=tensor(3.4518, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.319, dice=tensor(3.4274, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.319, dice=tensor(3.4274, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.326, dice=tensor(3.4040, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.326, dice=tensor(3.4040, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.308, dice=tensor(3.4202, device='cuda:0')]train Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.308, dice=tensor(3.4202, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3174 Dice: 0.6840
val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1873, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.363, dice=tensor(3.1873, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.35, dice=tensor(3.2469, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3564 Dice: 0.6494
Epoch 117/199
----------
train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3711, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.338, dice=tensor(3.3711, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.355, dice=tensor(3.3100, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.355, dice=tensor(3.3100, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.303, dice=tensor(3.3716, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.303, dice=tensor(3.3716, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.29, dice=tensor(3.4146, device='cuda:0')] train Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.29, dice=tensor(3.4146, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3214 Dice: 0.6829
val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2848, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.359, dice=tensor(3.2848, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.352, dice=tensor(3.2499, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3553 Dice: 0.6500
Epoch 118/199
----------
train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.28, dice=tensor(3.5567, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.28, dice=tensor(3.5567, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.36, dice=tensor(3.3911, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.36, dice=tensor(3.3911, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.344, dice=tensor(3.3637, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.344, dice=tensor(3.3637, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.306, dice=tensor(3.3949, device='cuda:0')]train Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.306, dice=tensor(3.3949, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3226 Dice: 0.6790
val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.0577, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.394, dice=tensor(3.0577, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.323, dice=tensor(3.2460, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3583 Dice: 0.6492
Epoch 119/199
----------
train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3570, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.324, dice=tensor(3.3570, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.349, dice=tensor(3.3272, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.349, dice=tensor(3.3272, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.298, dice=tensor(3.3809, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.298, dice=tensor(3.3809, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.322, dice=tensor(3.3788, device='cuda:0')]train Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.322, dice=tensor(3.3788, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3233 Dice: 0.6758
val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1975, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.376, dice=tensor(3.1975, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.334, dice=tensor(3.2497, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3551 Dice: 0.6499
Epoch 120/199
----------
train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.3685, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.319, dice=tensor(3.3685, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.311, dice=tensor(3.4077, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.311, dice=tensor(3.4077, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.298, dice=tensor(3.4498, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.298, dice=tensor(3.4498, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.348, dice=tensor(3.4122, device='cuda:0')]train Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.348, dice=tensor(3.4122, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3190 Dice: 0.6824
val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1934, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.379, dice=tensor(3.1934, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.332, dice=tensor(3.2494, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3558 Dice: 0.6499
Epoch 121/199
----------
train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.4146, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.331, dice=tensor(3.4146, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.322, dice=tensor(3.3967, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.322, dice=tensor(3.3967, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.333, dice=tensor(3.3894, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.62it/s, loss=0.333, dice=tensor(3.3894, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.62it/s, loss=0.287, dice=tensor(3.4199, device='cuda:0')]train Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.287, dice=tensor(3.4199, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3181 Dice: 0.6840
val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.373, dice=tensor(3.1448, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.373, dice=tensor(3.1448, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.339, dice=tensor(3.2510, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3559 Dice: 0.6502
Epoch 122/199
----------
train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3700, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.333, dice=tensor(3.3700, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.297, dice=tensor(3.4552, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.297, dice=tensor(3.4552, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.325, dice=tensor(3.4022, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.325, dice=tensor(3.4022, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.334, dice=tensor(3.3785, device='cuda:0')]train Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.334, dice=tensor(3.3785, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3221 Dice: 0.6757
val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2714, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.363, dice=tensor(3.2714, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.35, dice=tensor(3.2461, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3564 Dice: 0.6492
Epoch 123/199
----------
train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.302, dice=tensor(3.5504, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.302, dice=tensor(3.5504, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.355, dice=tensor(3.3988, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.355, dice=tensor(3.3988, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.286, dice=tensor(3.4370, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.286, dice=tensor(3.4370, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.358, dice=tensor(3.4007, device='cuda:0')]train Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.358, dice=tensor(3.4007, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3253 Dice: 0.6801
val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.1922, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.357, dice=tensor(3.1922, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.354, dice=tensor(3.2485, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3555 Dice: 0.6497
Epoch 124/199
----------
train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3827, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.338, dice=tensor(3.3827, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.311, dice=tensor(3.3983, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.311, dice=tensor(3.3983, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.309, dice=tensor(3.4066, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.309, dice=tensor(3.4066, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.33, dice=tensor(3.3843, device='cuda:0')] train Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.33, dice=tensor(3.3843, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3219 Dice: 0.6769
val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2868, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.359, dice=tensor(3.2868, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.35, dice=tensor(3.2516, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3547 Dice: 0.6503
Epoch 125/199
----------
train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.288, dice=tensor(3.5887, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.288, dice=tensor(3.5887, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.324, dice=tensor(3.4647, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.324, dice=tensor(3.4647, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.312, dice=tensor(3.4598, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.312, dice=tensor(3.4598, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.352, dice=tensor(3.4191, device='cuda:0')]train Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.352, dice=tensor(3.4191, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3191 Dice: 0.6838
val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.1268, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.375, dice=tensor(3.1268, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.338, dice=tensor(3.2484, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3564 Dice: 0.6497
Epoch 126/199
----------
train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.3669, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.316, dice=tensor(3.3669, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.318, dice=tensor(3.3582, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.318, dice=tensor(3.3582, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.332, dice=tensor(3.3726, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.332, dice=tensor(3.3726, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.304, dice=tensor(3.4059, device='cuda:0')]train Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.304, dice=tensor(3.4059, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3176 Dice: 0.6812
val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.5126, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.304, dice=tensor(3.5126, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.406, dice=tensor(3.2489, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3552 Dice: 0.6498
Epoch 127/199
----------
train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4326, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.322, dice=tensor(3.4326, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.322, dice=tensor(3.4084, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.322, dice=tensor(3.4084, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.298, dice=tensor(3.4212, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.298, dice=tensor(3.4212, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.337, dice=tensor(3.3838, device='cuda:0')]train Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.337, dice=tensor(3.3838, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3198 Dice: 0.6768
val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3702, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.34, dice=tensor(3.3702, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.369, dice=tensor(3.2508, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3544 Dice: 0.6502
Epoch 128/199
----------
train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.295, dice=tensor(3.4828, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.295, dice=tensor(3.4828, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.345, dice=tensor(3.4105, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.345, dice=tensor(3.4105, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.327, dice=tensor(3.3870, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.327, dice=tensor(3.3870, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.29, dice=tensor(3.4409, device='cuda:0')] train Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.29, dice=tensor(3.4409, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3140 Dice: 0.6882
val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.1609, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.367, dice=tensor(3.1609, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.343, dice=tensor(3.2520, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3550 Dice: 0.6504
Epoch 129/199
----------
train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.294, dice=tensor(3.5059, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.294, dice=tensor(3.5059, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.326, dice=tensor(3.4230, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.326, dice=tensor(3.4230, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.373, dice=tensor(3.3148, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.373, dice=tensor(3.3148, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.316, dice=tensor(3.3352, device='cuda:0')]train Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.316, dice=tensor(3.3352, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3271 Dice: 0.6670
val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.1877, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.381, dice=tensor(3.1877, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.327, dice=tensor(3.2537, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3540 Dice: 0.6507
Epoch 130/199
----------
train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3161, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.335, dice=tensor(3.3161, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.293, dice=tensor(3.4141, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.293, dice=tensor(3.4141, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.319, dice=tensor(3.4266, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.319, dice=tensor(3.4266, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.321, dice=tensor(3.4265, device='cuda:0')]train Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.321, dice=tensor(3.4265, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3172 Dice: 0.6853
val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.404, dice=tensor(3.0215, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.404, dice=tensor(3.0215, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.311, dice=tensor(3.2614, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3575 Dice: 0.6523
Epoch 131/199
----------
train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4297, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.313, dice=tensor(3.4297, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.287, dice=tensor(3.5027, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.287, dice=tensor(3.5027, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.37, dice=tensor(3.3824, device='cuda:0')] train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.37, dice=tensor(3.3824, device='cuda:0')]train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.322, dice=tensor(3.3922, device='cuda:0')]train Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.322, dice=tensor(3.3922, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3230 Dice: 0.6784
val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1599, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.369, dice=tensor(3.1599, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.347, dice=tensor(3.2582, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3577 Dice: 0.6516
Epoch 132/199
----------
train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.1615, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.36, dice=tensor(3.1615, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.324, dice=tensor(3.2913, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.324, dice=tensor(3.2913, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.35, dice=tensor(3.2905, device='cuda:0')] train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.35, dice=tensor(3.2905, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.252, dice=tensor(3.4053, device='cuda:0')]train Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.252, dice=tensor(3.4053, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3215 Dice: 0.6811
val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.1937, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.361, dice=tensor(3.1937, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.356, dice=tensor(3.2483, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3587 Dice: 0.6497
Epoch 133/199
----------
train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3033, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.343, dice=tensor(3.3033, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.351, dice=tensor(3.3195, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.351, dice=tensor(3.3195, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.315, dice=tensor(3.3446, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.315, dice=tensor(3.3446, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.282, dice=tensor(3.3926, device='cuda:0')]train Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.282, dice=tensor(3.3926, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3228 Dice: 0.6785
val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.386, dice=tensor(3.0880, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.94it/s, loss=0.386, dice=tensor(3.0880, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.94it/s, loss=0.336, dice=tensor(3.2432, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3613 Dice: 0.6486
Epoch 134/199
----------
train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.278, dice=tensor(3.6433, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.278, dice=tensor(3.6433, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.351, dice=tensor(3.4502, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.351, dice=tensor(3.4502, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.329, dice=tensor(3.4430, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.329, dice=tensor(3.4430, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.345, dice=tensor(3.3526, device='cuda:0')]train Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.345, dice=tensor(3.3526, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3257 Dice: 0.6705
val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.3263, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.365, dice=tensor(3.3263, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.31it/s, loss=0.398, dice=tensor(3.2922, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3814 Dice: 0.6584
Epoch 135/199
----------
train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.5393, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.291, dice=tensor(3.5393, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.345, dice=tensor(3.4241, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.345, dice=tensor(3.4241, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.303, dice=tensor(3.4452, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.303, dice=tensor(3.4452, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.344, dice=tensor(3.4104, device='cuda:0')]train Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.344, dice=tensor(3.4104, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3207 Dice: 0.6821
val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.4, dice=tensor(3.2620, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.4, dice=tensor(3.2620, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.438, dice=tensor(3.2336, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.4189 Dice: 0.6467
Epoch 136/199
----------
train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.297, dice=tensor(3.5511, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.297, dice=tensor(3.5511, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.35, dice=tensor(3.3990, device='cuda:0')] train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.35, dice=tensor(3.3990, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.31, dice=tensor(3.4136, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.31, dice=tensor(3.4136, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.312, dice=tensor(3.4120, device='cuda:0')]train Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.312, dice=tensor(3.4120, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3173 Dice: 0.6824
val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.482, dice=tensor(2.7544, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.482, dice=tensor(2.7544, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.406, dice=tensor(2.9841, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.4444 Dice: 0.5968
Epoch 137/199
----------
train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.295, dice=tensor(3.4745, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.295, dice=tensor(3.4745, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.336, dice=tensor(3.3952, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.336, dice=tensor(3.3952, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.67it/s, loss=0.299, dice=tensor(3.4410, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.299, dice=tensor(3.4410, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.329, dice=tensor(3.4292, device='cuda:0')]train Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.31it/s, loss=0.329, dice=tensor(3.4292, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3148 Dice: 0.6858
val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.401, dice=tensor(3.1810, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.401, dice=tensor(3.1810, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.344, dice=tensor(3.2905, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3727 Dice: 0.6581
Epoch 138/199
----------
train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3049, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.343, dice=tensor(3.3049, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.3, dice=tensor(3.4066, device='cuda:0')]  train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.3, dice=tensor(3.4066, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.303, dice=tensor(3.4326, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.303, dice=tensor(3.4326, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.324, dice=tensor(3.4169, device='cuda:0')]train Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.324, dice=tensor(3.4169, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3173 Dice: 0.6834
val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4891, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.315, dice=tensor(3.4891, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.402, dice=tensor(3.2644, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3587 Dice: 0.6529
Epoch 139/199
----------
train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5772, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.29, dice=tensor(3.5772, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.324, dice=tensor(3.4770, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.324, dice=tensor(3.4770, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.309, dice=tensor(3.4781, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.309, dice=tensor(3.4781, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.331, dice=tensor(3.4440, device='cuda:0')]train Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.331, dice=tensor(3.4440, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3133 Dice: 0.6888
val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.2749, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.361, dice=tensor(3.2749, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.352, dice=tensor(3.2595, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3563 Dice: 0.6519
Epoch 140/199
----------
train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.286, dice=tensor(3.5627, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.286, dice=tensor(3.5627, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.323, dice=tensor(3.4546, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.323, dice=tensor(3.4546, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.347, dice=tensor(3.4017, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.347, dice=tensor(3.4017, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.314, dice=tensor(3.4023, device='cuda:0')]train Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.314, dice=tensor(3.4023, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3176 Dice: 0.6805
val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2346, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.351, dice=tensor(3.2346, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.363, dice=tensor(3.2612, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3570 Dice: 0.6522
Epoch 141/199
----------
train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3185, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.342, dice=tensor(3.3185, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.282, dice=tensor(3.4204, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.282, dice=tensor(3.4204, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.29, dice=tensor(3.4661, device='cuda:0')] train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.29, dice=tensor(3.4661, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.334, dice=tensor(3.4456, device='cuda:0')]train Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.334, dice=tensor(3.4456, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3119 Dice: 0.6891
val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.1814, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.381, dice=tensor(3.1814, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.32, dice=tensor(3.2697, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3505 Dice: 0.6539
Epoch 142/199
----------
train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.4452, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.303, dice=tensor(3.4452, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.332, dice=tensor(3.3986, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.332, dice=tensor(3.3986, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.312, dice=tensor(3.4275, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.312, dice=tensor(3.4275, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.301, dice=tensor(3.4470, device='cuda:0')]train Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.301, dice=tensor(3.4470, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3120 Dice: 0.6894
val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.4156, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.331, dice=tensor(3.4156, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.367, dice=tensor(3.2852, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3489 Dice: 0.6570
Epoch 143/199
----------
train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.276, dice=tensor(3.6040, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.276, dice=tensor(3.6040, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.312, dice=tensor(3.5028, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.312, dice=tensor(3.5028, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.348, dice=tensor(3.4246, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.348, dice=tensor(3.4246, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.377, dice=tensor(3.3514, device='cuda:0')]train Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.377, dice=tensor(3.3514, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3280 Dice: 0.6703
val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1789, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.379, dice=tensor(3.1789, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.31, dice=tensor(3.2893, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3449 Dice: 0.6579
Epoch 144/199
----------
train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.294, dice=tensor(3.5192, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.294, dice=tensor(3.5192, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.339, dice=tensor(3.4355, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.339, dice=tensor(3.4355, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.328, dice=tensor(3.4246, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.328, dice=tensor(3.4246, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.293, dice=tensor(3.4459, device='cuda:0')]train Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.293, dice=tensor(3.4459, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3137 Dice: 0.6892
val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2155, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.354, dice=tensor(3.2155, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.342, dice=tensor(3.2932, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3478 Dice: 0.6586
Epoch 145/199
----------
train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4686, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.84it/s, loss=0.316, dice=tensor(3.4686, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.84it/s, loss=0.33, dice=tensor(3.4241, device='cuda:0')] train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.33, dice=tensor(3.4241, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.296, dice=tensor(3.4649, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.296, dice=tensor(3.4649, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.31, dice=tensor(3.4522, device='cuda:0')] train Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.67it/s, loss=0.31, dice=tensor(3.4522, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3130 Dice: 0.6904
val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.2711, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.342, dice=tensor(3.2711, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.352, dice=tensor(3.2933, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3471 Dice: 0.6587
Epoch 146/199
----------
train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4393, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.314, dice=tensor(3.4393, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.325, dice=tensor(3.4335, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.325, dice=tensor(3.4335, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.331, dice=tensor(3.4169, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.331, dice=tensor(3.4169, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.28, dice=tensor(3.4595, device='cuda:0')] train Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.28, dice=tensor(3.4595, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3125 Dice: 0.6919
val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.1568, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.374, dice=tensor(3.1568, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.323, dice=tensor(3.2941, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3485 Dice: 0.6588
Epoch 147/199
----------
train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3706, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.336, dice=tensor(3.3706, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.316, dice=tensor(3.3822, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.316, dice=tensor(3.3822, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.276, dice=tensor(3.4699, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.276, dice=tensor(3.4699, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.336, dice=tensor(3.4495, device='cuda:0')]train Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.336, dice=tensor(3.4495, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3158 Dice: 0.6899
val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2172, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.357, dice=tensor(3.2172, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.342, dice=tensor(3.2852, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3492 Dice: 0.6570
Epoch 148/199
----------
train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.4692, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.304, dice=tensor(3.4692, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.357, dice=tensor(3.3042, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.357, dice=tensor(3.3042, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.335, dice=tensor(3.3115, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.335, dice=tensor(3.3115, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.313, dice=tensor(3.3468, device='cuda:0')]train Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.313, dice=tensor(3.3468, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3272 Dice: 0.6694
val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.383, dice=tensor(3.1126, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.383, dice=tensor(3.1126, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.321, dice=tensor(3.2781, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3522 Dice: 0.6556
Epoch 149/199
----------
train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4229, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.315, dice=tensor(3.4229, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.316, dice=tensor(3.3966, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.316, dice=tensor(3.3966, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.313, dice=tensor(3.4186, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.313, dice=tensor(3.4186, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.33, dice=tensor(3.4118, device='cuda:0')] train Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.33, dice=tensor(3.4118, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3187 Dice: 0.6824
val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.31, dice=tensor(3.5073, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.31, dice=tensor(3.5073, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.399, dice=tensor(3.2712, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3546 Dice: 0.6542
Epoch 150/199
----------
train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4522, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.32, dice=tensor(3.4522, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.327, dice=tensor(3.4340, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.327, dice=tensor(3.4340, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.289, dice=tensor(3.4578, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.04it/s, loss=0.289, dice=tensor(3.4578, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.04it/s, loss=0.306, dice=tensor(3.4621, device='cuda:0')]train Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.67it/s, loss=0.306, dice=tensor(3.4621, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3106 Dice: 0.6924
val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3717, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.343, dice=tensor(3.3717, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.364, dice=tensor(3.2724, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3535 Dice: 0.6545
Epoch 151/199
----------
train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.284, dice=tensor(3.6308, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.284, dice=tensor(3.6308, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.277, dice=tensor(3.6340, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.277, dice=tensor(3.6340, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.355, dice=tensor(3.5152, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.355, dice=tensor(3.5152, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.411, dice=tensor(3.3937, device='cuda:0')]train Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.411, dice=tensor(3.3937, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3317 Dice: 0.6787
val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.2426, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.379, dice=tensor(3.2426, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.348, dice=tensor(3.2831, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3631 Dice: 0.6566
Epoch 152/199
----------
train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.31, dice=tensor(3.4771, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.31, dice=tensor(3.4771, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.304, dice=tensor(3.4788, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.304, dice=tensor(3.4788, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.336, dice=tensor(3.4240, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.336, dice=tensor(3.4240, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.311, dice=tensor(3.4342, device='cuda:0')]train Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.311, dice=tensor(3.4342, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3151 Dice: 0.6868
val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.3449, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.354, dice=tensor(3.3449, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.371, dice=tensor(3.2772, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3623 Dice: 0.6554
Epoch 153/199
----------
train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.4664, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.303, dice=tensor(3.4664, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.413, dice=tensor(3.2480, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.413, dice=tensor(3.2480, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.319, dice=tensor(3.3084, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.319, dice=tensor(3.3084, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.286, dice=tensor(3.3804, device='cuda:0')]train Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.286, dice=tensor(3.3804, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3301 Dice: 0.6761
val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3156, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.348, dice=tensor(3.3156, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.345, dice=tensor(3.2945, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3462 Dice: 0.6589
Epoch 154/199
----------
train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4494, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.312, dice=tensor(3.4494, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.329, dice=tensor(3.4061, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.329, dice=tensor(3.4061, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.281, dice=tensor(3.4664, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.281, dice=tensor(3.4664, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.326, dice=tensor(3.4404, device='cuda:0')]train Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.326, dice=tensor(3.4404, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3121 Dice: 0.6881
val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.2906, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.342, dice=tensor(3.2906, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.349, dice=tensor(3.2978, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3457 Dice: 0.6596
Epoch 155/199
----------
train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.5384, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.296, dice=tensor(3.5384, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.306, dice=tensor(3.4929, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.18it/s, loss=0.306, dice=tensor(3.4929, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.18it/s, loss=0.313, dice=tensor(3.4631, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.08it/s, loss=0.313, dice=tensor(3.4631, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.08it/s, loss=0.335, dice=tensor(3.4413, device='cuda:0')]train Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.71it/s, loss=0.335, dice=tensor(3.4413, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3124 Dice: 0.6883
val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3924, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.332, dice=tensor(3.3924, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.364, dice=tensor(3.2996, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3482 Dice: 0.6599
Epoch 156/199
----------
train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.3822, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.313, dice=tensor(3.3822, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.313, dice=tensor(3.4128, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.313, dice=tensor(3.4128, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.327, dice=tensor(3.3890, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.327, dice=tensor(3.3890, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.324, dice=tensor(3.3832, device='cuda:0')]train Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.324, dice=tensor(3.3832, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3192 Dice: 0.6766
val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4968, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.85it/s, loss=0.312, dice=tensor(3.4968, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.85it/s, loss=0.39, dice=tensor(3.2941, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3513 Dice: 0.6588
Epoch 157/199
----------
train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3782, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.45it/s, loss=0.333, dice=tensor(3.3782, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.45it/s, loss=0.322, dice=tensor(3.3903, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.63it/s, loss=0.322, dice=tensor(3.3903, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.63it/s, loss=0.325, dice=tensor(3.3342, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.325, dice=tensor(3.3342, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.306, dice=tensor(3.3559, device='cuda:0')]train Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.26it/s, loss=0.306, dice=tensor(3.3559, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3216 Dice: 0.6712
val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.3187, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.362, dice=tensor(3.3187, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.39, dice=tensor(3.2767, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3762 Dice: 0.6553
Epoch 158/199
----------
train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.372, dice=tensor(3.1981, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.372, dice=tensor(3.1981, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.302, dice=tensor(3.3687, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.302, dice=tensor(3.3687, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.276, dice=tensor(3.4424, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.276, dice=tensor(3.4424, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.302, dice=tensor(3.4657, device='cuda:0')]train Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.302, dice=tensor(3.4657, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3131 Dice: 0.6931
val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.403, dice=tensor(3.1532, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.403, dice=tensor(3.1532, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.459, dice=tensor(3.1367, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.4309 Dice: 0.6273
Epoch 159/199
----------
train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.3848, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.315, dice=tensor(3.3848, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.299, dice=tensor(3.4379, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.299, dice=tensor(3.4379, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.307, dice=tensor(3.4576, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.04it/s, loss=0.307, dice=tensor(3.4576, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.04it/s, loss=0.323, dice=tensor(3.4348, device='cuda:0')]train Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.67it/s, loss=0.323, dice=tensor(3.4348, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3110 Dice: 0.6870
val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.48, dice=tensor(2.9560, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.48, dice=tensor(2.9560, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.443, dice=tensor(3.0571, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.4612 Dice: 0.6114
Epoch 160/199
----------
train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.277, dice=tensor(3.6231, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.277, dice=tensor(3.6231, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.315, dice=tensor(3.4945, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.315, dice=tensor(3.4945, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.328, dice=tensor(3.4608, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.328, dice=tensor(3.4608, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.326, dice=tensor(3.4280, device='cuda:0')]train Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.326, dice=tensor(3.4280, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3117 Dice: 0.6856
val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.534, dice=tensor(2.5149, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.534, dice=tensor(2.5149, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.537, dice=tensor(2.7747, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.5356 Dice: 0.5549
Epoch 161/199
----------
train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2731, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.343, dice=tensor(3.2731, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.312, dice=tensor(3.3861, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.312, dice=tensor(3.3861, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.353, dice=tensor(3.3416, device='cuda:0')]train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.353, dice=tensor(3.3416, device='cuda:0')]train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.257, dice=tensor(3.4325, device='cuda:0')]train Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.257, dice=tensor(3.4325, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3161 Dice: 0.6865
val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.488, dice=tensor(2.8817, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.488, dice=tensor(2.8817, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.393, dice=tensor(3.0920, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.4406 Dice: 0.6184
Epoch 162/199
----------
train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4123, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.327, dice=tensor(3.4123, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.317, dice=tensor(3.4294, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.317, dice=tensor(3.4294, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.291, dice=tensor(3.4580, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.291, dice=tensor(3.4580, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.295, dice=tensor(3.4773, device='cuda:0')]train Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.295, dice=tensor(3.4773, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3074 Dice: 0.6955
val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.527, dice=tensor(2.6076, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.527, dice=tensor(2.6076, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.41, dice=tensor(2.9327, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4684 Dice: 0.5865
Epoch 163/199
----------
train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.272, dice=tensor(3.6684, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.272, dice=tensor(3.6684, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.335, dice=tensor(3.5103, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.335, dice=tensor(3.5103, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.331, dice=tensor(3.4653, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.331, dice=tensor(3.4653, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.301, dice=tensor(3.4670, device='cuda:0')]train Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.301, dice=tensor(3.4670, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3097 Dice: 0.6934
val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.3948, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.354, dice=tensor(3.3948, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.485, dice=tensor(3.1576, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.4194 Dice: 0.6315
Epoch 164/199
----------
train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.2804, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.339, dice=tensor(3.2804, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.297, dice=tensor(3.3989, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.297, dice=tensor(3.3989, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.373, dice=tensor(3.3269, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.373, dice=tensor(3.3269, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.267, dice=tensor(3.4179, device='cuda:0')]train Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.267, dice=tensor(3.4179, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3190 Dice: 0.6836
val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.1716, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.37, dice=tensor(3.1716, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.337, dice=tensor(3.3016, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3532 Dice: 0.6603
Epoch 165/199
----------
train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.298, dice=tensor(3.3628, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.298, dice=tensor(3.3628, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.324, dice=tensor(3.3811, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.324, dice=tensor(3.3811, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.292, dice=tensor(3.4337, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.292, dice=tensor(3.4337, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.321, dice=tensor(3.4339, device='cuda:0')]train Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.321, dice=tensor(3.4339, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3088 Dice: 0.6868
val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.2999, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.339, dice=tensor(3.2999, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.348, dice=tensor(3.3108, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3434 Dice: 0.6622
Epoch 166/199
----------
train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.3709, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.314, dice=tensor(3.3709, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.291, dice=tensor(3.4520, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.291, dice=tensor(3.4520, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.316, dice=tensor(3.4566, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.316, dice=tensor(3.4566, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.325, dice=tensor(3.4488, device='cuda:0')]train Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.325, dice=tensor(3.4488, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3116 Dice: 0.6898
val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.5143, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.305, dice=tensor(3.5143, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.385, dice=tensor(3.3078, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3453 Dice: 0.6616
Epoch 167/199
----------
train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.294, dice=tensor(3.5204, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.294, dice=tensor(3.5204, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.316, dice=tensor(3.4624, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.316, dice=tensor(3.4624, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.352, dice=tensor(3.4001, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.352, dice=tensor(3.4001, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.293, dice=tensor(3.4435, device='cuda:0')]train Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.293, dice=tensor(3.4435, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3137 Dice: 0.6887
val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2170, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.362, dice=tensor(3.2170, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.335, dice=tensor(3.3105, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3481 Dice: 0.6621
Epoch 168/199
----------
train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.274, dice=tensor(3.6290, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.08it/s, loss=0.274, dice=tensor(3.6290, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.08it/s, loss=0.353, dice=tensor(3.4617, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.41it/s, loss=0.353, dice=tensor(3.4617, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.41it/s, loss=0.332, dice=tensor(3.4297, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.27it/s, loss=0.332, dice=tensor(3.4297, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.27it/s, loss=0.282, dice=tensor(3.4722, device='cuda:0')]train Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.84it/s, loss=0.282, dice=tensor(3.4722, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3104 Dice: 0.6944
val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.2567, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.365, dice=tensor(3.2567, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.317, dice=tensor(3.3171, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3409 Dice: 0.6634
Epoch 169/199
----------
train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4908, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.305, dice=tensor(3.4908, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.342, dice=tensor(3.4230, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.342, dice=tensor(3.4230, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.277, dice=tensor(3.4623, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.277, dice=tensor(3.4623, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.309, dice=tensor(3.4766, device='cuda:0')]train Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.309, dice=tensor(3.4766, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3082 Dice: 0.6953
val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1415, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.378, dice=tensor(3.1415, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.311, dice=tensor(3.3160, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3445 Dice: 0.6632
Epoch 170/199
----------
train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4451, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.314, dice=tensor(3.4451, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.275, dice=tensor(3.5373, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.275, dice=tensor(3.5373, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.314, dice=tensor(3.4996, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.314, dice=tensor(3.4996, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.345, dice=tensor(3.4479, device='cuda:0')]train Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.345, dice=tensor(3.4479, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3120 Dice: 0.6896
val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4520, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.323, dice=tensor(3.4520, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.371, dice=tensor(3.3197, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3472 Dice: 0.6639
Epoch 171/199
----------
train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.3913, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.32, dice=tensor(3.3913, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.316, dice=tensor(3.4313, device='cuda:0')]train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.316, dice=tensor(3.4313, device='cuda:0')]train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.306, dice=tensor(3.4471, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.306, dice=tensor(3.4471, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.296, dice=tensor(3.4562, device='cuda:0')]train Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.296, dice=tensor(3.4562, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3095 Dice: 0.6912
val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.4418, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.325, dice=tensor(3.4418, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.361, dice=tensor(3.3158, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3430 Dice: 0.6632
Epoch 172/199
----------
train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2738, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.351, dice=tensor(3.2738, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.298, dice=tensor(3.3819, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.298, dice=tensor(3.3819, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.292, dice=tensor(3.4259, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.292, dice=tensor(3.4259, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.308, dice=tensor(3.4497, device='cuda:0')]train Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.308, dice=tensor(3.4497, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3119 Dice: 0.6899
val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3313, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.348, dice=tensor(3.3313, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.334, dice=tensor(3.3176, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3413 Dice: 0.6635
Epoch 173/199
----------
train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.26, dice=tensor(3.7107, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.26, dice=tensor(3.7107, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.341, dice=tensor(3.4931, device='cuda:0')]train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.341, dice=tensor(3.4931, device='cuda:0')]train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.318, dice=tensor(3.4752, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.318, dice=tensor(3.4752, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.317, dice=tensor(3.4582, device='cuda:0')]train Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.317, dice=tensor(3.4582, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3093 Dice: 0.6916
val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3006, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.335, dice=tensor(3.3006, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.348, dice=tensor(3.3182, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3415 Dice: 0.6636
Epoch 174/199
----------
train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.288, dice=tensor(3.5599, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.288, dice=tensor(3.5599, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.309, dice=tensor(3.4930, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.309, dice=tensor(3.4930, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.329, dice=tensor(3.4637, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.329, dice=tensor(3.4637, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.308, dice=tensor(3.4654, device='cuda:0')]train Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.308, dice=tensor(3.4654, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3084 Dice: 0.6931
val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.2625, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.349, dice=tensor(3.2625, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.333, dice=tensor(3.3230, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3411 Dice: 0.6646
Epoch 175/199
----------
train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3439, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.342, dice=tensor(3.3439, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.303, dice=tensor(3.4085, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.303, dice=tensor(3.4085, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.267, dice=tensor(3.4945, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.267, dice=tensor(3.4945, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.314, dice=tensor(3.4851, device='cuda:0')]train Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.314, dice=tensor(3.4851, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3067 Dice: 0.6970
val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.2173, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.37, dice=tensor(3.2173, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.306, dice=tensor(3.3235, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3380 Dice: 0.6647
Epoch 176/199
----------
train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1109, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.379, dice=tensor(3.1109, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.289, dice=tensor(3.3487, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.289, dice=tensor(3.3487, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.309, dice=tensor(3.3950, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.309, dice=tensor(3.3950, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.279, dice=tensor(3.4529, device='cuda:0')]train Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.279, dice=tensor(3.4529, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3141 Dice: 0.6906
val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2842, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.359, dice=tensor(3.2842, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.322, dice=tensor(3.3262, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3409 Dice: 0.6652
Epoch 177/199
----------
train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.5238, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.296, dice=tensor(3.5238, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.299, dice=tensor(3.5015, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.299, dice=tensor(3.5015, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.33, dice=tensor(3.4706, device='cuda:0')] train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.33, dice=tensor(3.4706, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.303, dice=tensor(3.4796, device='cuda:0')]train Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.303, dice=tensor(3.4796, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3067 Dice: 0.6959
val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2261, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.359, dice=tensor(3.2261, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.324, dice=tensor(3.3248, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3416 Dice: 0.6650
Epoch 178/199
----------
train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.2259, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.364, dice=tensor(3.2259, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.339, dice=tensor(3.1853, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.339, dice=tensor(3.1853, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.274, dice=tensor(3.3357, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.274, dice=tensor(3.3357, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.294, dice=tensor(3.3915, device='cuda:0')]train Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.294, dice=tensor(3.3915, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3177 Dice: 0.6783
val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2058, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.356, dice=tensor(3.2058, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.325, dice=tensor(3.3217, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3407 Dice: 0.6643
Epoch 179/199
----------
train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3354, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.329, dice=tensor(3.3354, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.309, dice=tensor(3.3782, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.309, dice=tensor(3.3782, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.321, dice=tensor(3.3872, device='cuda:0')]train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.321, dice=tensor(3.3872, device='cuda:0')]train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.268, dice=tensor(3.4616, device='cuda:0')]train Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.268, dice=tensor(3.4616, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3069 Dice: 0.6923
val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1361, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.38, dice=tensor(3.1361, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.308, dice=tensor(3.3210, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3440 Dice: 0.6642
Epoch 180/199
----------
train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.4893, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.307, dice=tensor(3.4893, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.329, dice=tensor(3.4180, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.329, dice=tensor(3.4180, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.252, dice=tensor(3.5240, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.252, dice=tensor(3.5240, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.328, dice=tensor(3.4874, device='cuda:0')]train Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.328, dice=tensor(3.4874, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3041 Dice: 0.6975
val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.5064, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.33it/s, loss=0.308, dice=tensor(3.5064, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.33it/s, loss=0.375, dice=tensor(3.3225, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3414 Dice: 0.6645
Epoch 181/199
----------
train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.2274, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.366, dice=tensor(3.2274, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.327, dice=tensor(3.3283, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.327, dice=tensor(3.3283, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.275, dice=tensor(3.4362, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.275, dice=tensor(3.4362, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.286, dice=tensor(3.4763, device='cuda:0')]train Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.286, dice=tensor(3.4763, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3136 Dice: 0.6953
val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3719, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.341, dice=tensor(3.3719, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.338, dice=tensor(3.3296, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3392 Dice: 0.6659
Epoch 182/199
----------
train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4481, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.315, dice=tensor(3.4481, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.274, dice=tensor(3.5597, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.274, dice=tensor(3.5597, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.344, dice=tensor(3.4579, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.344, dice=tensor(3.4579, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.313, dice=tensor(3.4501, device='cuda:0')]train Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.313, dice=tensor(3.4501, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3116 Dice: 0.6900
val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1360, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.378, dice=tensor(3.1360, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.301, dice=tensor(3.3324, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3394 Dice: 0.6665
Epoch 183/199
----------
train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.288, dice=tensor(3.5810, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.94it/s, loss=0.288, dice=tensor(3.5810, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.94it/s, loss=0.351, dice=tensor(3.4240, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.24it/s, loss=0.351, dice=tensor(3.4240, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.24it/s, loss=0.283, dice=tensor(3.4659, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.13it/s, loss=0.283, dice=tensor(3.4659, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.13it/s, loss=0.287, dice=tensor(3.4908, device='cuda:0')]train Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.73it/s, loss=0.287, dice=tensor(3.4908, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3022 Dice: 0.6982
val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2058, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.363, dice=tensor(3.2058, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.319, dice=tensor(3.3344, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3407 Dice: 0.6669
Epoch 184/199
----------
train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3426, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.344, dice=tensor(3.3426, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.269, dice=tensor(3.4979, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.269, dice=tensor(3.4979, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.306, dice=tensor(3.4965, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.10it/s, loss=0.306, dice=tensor(3.4965, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.10it/s, loss=0.32, dice=tensor(3.4752, device='cuda:0')] train Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.71it/s, loss=0.32, dice=tensor(3.4752, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3095 Dice: 0.6950
val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1260, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.379, dice=tensor(3.1260, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.297, dice=tensor(3.3345, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3382 Dice: 0.6669
Epoch 185/199
----------
train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.5093, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.301, dice=tensor(3.5093, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.294, dice=tensor(3.5201, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.294, dice=tensor(3.5201, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.333, dice=tensor(3.4705, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.62it/s, loss=0.333, dice=tensor(3.4705, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.62it/s, loss=0.308, dice=tensor(3.4719, device='cuda:0')]train Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.308, dice=tensor(3.4719, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3090 Dice: 0.6944
val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.3236, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.352, dice=tensor(3.3236, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.325, dice=tensor(3.3360, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3385 Dice: 0.6672
Epoch 186/199
----------
train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.3999, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.314, dice=tensor(3.3999, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.293, dice=tensor(3.4828, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.293, dice=tensor(3.4828, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.309, dice=tensor(3.4804, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.309, dice=tensor(3.4804, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.343, dice=tensor(3.4391, device='cuda:0')]train Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.343, dice=tensor(3.4391, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3147 Dice: 0.6878
val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.3404, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.33, dice=tensor(3.3404, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.346, dice=tensor(3.3366, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3377 Dice: 0.6673
Epoch 187/199
----------
train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.2869, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.333, dice=tensor(3.2869, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.306, dice=tensor(3.3815, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.306, dice=tensor(3.3815, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.341, dice=tensor(3.3718, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.341, dice=tensor(3.3718, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.28, dice=tensor(3.4296, device='cuda:0')] train Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.28, dice=tensor(3.4296, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3152 Dice: 0.6859
val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3941, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.333, dice=tensor(3.3941, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.344, dice=tensor(3.3418, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3382 Dice: 0.6684
Epoch 188/199
----------
train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5130, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.29, dice=tensor(3.5130, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.3, dice=tensor(3.5273, device='cuda:0')] train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.3, dice=tensor(3.5273, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.353, dice=tensor(3.4397, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.353, dice=tensor(3.4397, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.308, dice=tensor(3.4373, device='cuda:0')]train Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.308, dice=tensor(3.4373, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3128 Dice: 0.6875
val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3543, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.329, dice=tensor(3.3543, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.343, dice=tensor(3.3473, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3362 Dice: 0.6695
Epoch 189/199
----------
train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5321, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.29, dice=tensor(3.5321, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.348, dice=tensor(3.4188, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.348, dice=tensor(3.4188, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.282, dice=tensor(3.4706, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.282, dice=tensor(3.4706, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.31, dice=tensor(3.4744, device='cuda:0')] train Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.31, dice=tensor(3.4744, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3077 Dice: 0.6949
val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3322, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.346, dice=tensor(3.3322, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.333, dice=tensor(3.3335, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3396 Dice: 0.6667
Epoch 190/199
----------
train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.3326, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.343, dice=tensor(3.3326, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.349, dice=tensor(3.2472, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.349, dice=tensor(3.2472, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.265, dice=tensor(3.3920, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.265, dice=tensor(3.3920, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.295, dice=tensor(3.4383, device='cuda:0')]train Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.295, dice=tensor(3.4383, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3132 Dice: 0.6877
val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3559, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.34, dice=tensor(3.3559, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.356, dice=tensor(3.3017, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3477 Dice: 0.6603
Epoch 191/199
----------
train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.4491, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.325, dice=tensor(3.4491, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.322, dice=tensor(3.4165, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.322, dice=tensor(3.4165, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.274, dice=tensor(3.4763, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.274, dice=tensor(3.4763, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.309, dice=tensor(3.4838, device='cuda:0')]train Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.309, dice=tensor(3.4838, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3074 Dice: 0.6968
val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2265, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.357, dice=tensor(3.2265, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.348, dice=tensor(3.2779, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3525 Dice: 0.6556
Epoch 192/199
----------
train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.269, dice=tensor(3.6604, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.269, dice=tensor(3.6604, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.366, dice=tensor(3.4286, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.366, dice=tensor(3.4286, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.304, dice=tensor(3.4645, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.304, dice=tensor(3.4645, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.302, dice=tensor(3.4681, device='cuda:0')]train Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.302, dice=tensor(3.4681, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3103 Dice: 0.6936
val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2253, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.36, dice=tensor(3.2253, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.328, dice=tensor(3.3221, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3440 Dice: 0.6644
Epoch 193/199
----------
train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.3648, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.305, dice=tensor(3.3648, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.278, dice=tensor(3.5025, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.278, dice=tensor(3.5025, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.307, dice=tensor(3.4998, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.307, dice=tensor(3.4998, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.351, dice=tensor(3.4526, device='cuda:0')]train Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.351, dice=tensor(3.4526, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3104 Dice: 0.6905
val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3205, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.351, dice=tensor(3.3205, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.324, dice=tensor(3.3422, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3373 Dice: 0.6684
Epoch 194/199
----------
train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.289, dice=tensor(3.4691, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.289, dice=tensor(3.4691, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.362, dice=tensor(3.3612, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.362, dice=tensor(3.3612, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.297, dice=tensor(3.4271, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.297, dice=tensor(3.4271, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.332, dice=tensor(3.4094, device='cuda:0')]train Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.332, dice=tensor(3.4094, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3200 Dice: 0.6819
val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2840, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.343, dice=tensor(3.2840, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.335, dice=tensor(3.3372, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3387 Dice: 0.6674
Epoch 195/199
----------
train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2913, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.35, dice=tensor(3.2913, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.26, dice=tensor(3.4919, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.26, dice=tensor(3.4919, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.299, dice=tensor(3.5120, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.299, dice=tensor(3.5120, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.327, dice=tensor(3.4876, device='cuda:0')]train Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.327, dice=tensor(3.4876, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3089 Dice: 0.6975
val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3854, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.339, dice=tensor(3.3854, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.366, dice=tensor(3.3250, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3526 Dice: 0.6650
Epoch 196/199
----------
train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4387, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.313, dice=tensor(3.4387, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.285, dice=tensor(3.4980, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.285, dice=tensor(3.4980, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.329, dice=tensor(3.4530, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.329, dice=tensor(3.4530, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.296, dice=tensor(3.4737, device='cuda:0')]train Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.296, dice=tensor(3.4737, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3058 Dice: 0.6947
val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.4169, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.346, dice=tensor(3.4169, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.356, dice=tensor(3.3307, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3509 Dice: 0.6661
Epoch 197/199
----------
train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.276, dice=tensor(3.5730, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.276, dice=tensor(3.5730, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.302, dice=tensor(3.5314, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.302, dice=tensor(3.5314, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.319, dice=tensor(3.5133, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.319, dice=tensor(3.5133, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.317, dice=tensor(3.4948, device='cuda:0')]train Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.317, dice=tensor(3.4948, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3036 Dice: 0.6990
val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.2086, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.376, dice=tensor(3.2086, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.322, dice=tensor(3.3338, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3492 Dice: 0.6668
Epoch 198/199
----------
train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.285, dice=tensor(3.6103, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.285, dice=tensor(3.6103, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.313, dice=tensor(3.5404, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.313, dice=tensor(3.5404, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.291, dice=tensor(3.5396, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.291, dice=tensor(3.5396, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.322, dice=tensor(3.4912, device='cuda:0')]train Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.322, dice=tensor(3.4912, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3029 Dice: 0.6982
val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.4088, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.334, dice=tensor(3.4088, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.357, dice=tensor(3.3252, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3452 Dice: 0.6650
Epoch 199/199
----------
train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4226, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.326, dice=tensor(3.4226, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.252, dice=tensor(3.5871, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.252, dice=tensor(3.5871, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.304, dice=tensor(3.5532, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.304, dice=tensor(3.5532, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.351, dice=tensor(3.4887, device='cuda:0')]train Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.351, dice=tensor(3.4887, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3084 Dice: 0.6977
val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2989, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.336, dice=tensor(3.2989, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.346, dice=tensor(3.3215, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: train_dice ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   val_dice ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   val_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: best_val_dice 0.66946
wandb: best_val_loss 0.33624
wandb:         epoch 199
wandb:    train_dice 0.69774
wandb:    train_loss 0.30835
wandb:      val_dice 0.66431
wandb:      val_loss 0.34091
wandb: 
wandb: üöÄ View run DIAS_modelnone at: https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/m03tos6l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241013_213002-m03tos6l/logs
val Loss: 0.3409 Dice: 0.6643
Best val loss: 0.336241, best val dice: 0.669460
Model saved at: ./modelsDIAS/final_model.pth
Starting RLHF fine-tuning...
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Epoch 0/39
----------
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/3 [00:02<?, ?it/s, loss=-62.9]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:05,  2.52s/it, loss=-62.9]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:05,  2.52s/it, loss=-69.2]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.24s/it, loss=-69.2]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:03<00:01,  1.24s/it, loss=-67.7]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.29it/s, loss=-67.7]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07369879633188248

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07369879633188248

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06980371475219727

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.424931138753891

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0737600326538086

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06980371475219727

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 49.749874114990234
Max value: 73.92951965332031
Mean value: 62.92805480957031

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07369879633188248

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07369879633188248

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07369879633188248

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.424931138753891

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 49.749874114990234
Max value: 73.92951965332031
Mean value: 62.92805480957031

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.92814254760742
Max value: -62.92814254760742
Mean value: -62.92814254760742

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11074087768793106

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11074087768793106

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10180854797363281

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.48706141114234924

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1108250617980957

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10180854797363281

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 61.094093322753906
Max value: 90.40657043457031
Mean value: 75.17221069335938

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10918617993593216

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10918617993593216

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10918617993593216

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.47227752208709717

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.12299646437168121
Max value: 9.999995231628418
Mean value: 1.0251948833465576

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 61.094093322753906
Max value: 90.40657043457031
Mean value: 75.17221069335938

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -75.44719696044922
Max value: -75.44719696044922
Mean value: -75.44719696044922
sam_encoder.pos_embed grad: 6.5780212388233394e-09
sam_encoder.blocks.0.norm1.weight grad: -5.330753265297972e-05
sam_encoder.blocks.0.norm1.bias grad: 2.4132268663379364e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.4713009426923236e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.189886399468378e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.554157264166861e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.215215530071873e-07
sam_encoder.blocks.0.norm2.weight grad: 2.8976295652682893e-05
sam_encoder.blocks.0.norm2.bias grad: -2.0224306354066357e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.776819878316019e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.433864887687378e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.37195807939861e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.8143598430906422e-06
sam_encoder.blocks.1.norm1.weight grad: -6.8122712946205866e-06
sam_encoder.blocks.1.norm1.bias grad: -9.793588105821982e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.5939897366479272e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.006418627497624e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.523588129108248e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1351740880627403e-07
sam_encoder.blocks.1.norm2.weight grad: 4.7701441872050054e-06
sam_encoder.blocks.1.norm2.bias grad: 5.626777692668838e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.390592031697452e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5217186444260733e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.658477396584203e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.058043133336469e-07
sam_encoder.blocks.2.norm1.weight grad: -1.429205440217629e-06
sam_encoder.blocks.2.norm1.bias grad: 1.0442583970871055e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.615249503738596e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.088283382472582e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.382534941920312e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.4878397653083084e-06
sam_encoder.blocks.2.norm2.weight grad: 2.887521532102255e-06
sam_encoder.blocks.2.norm2.bias grad: 1.7479642338003032e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.8427724575740285e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.2447562767192721e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.69959229324013e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7550221400597366e-06
sam_encoder.blocks.3.norm1.weight grad: -9.38975608733017e-06
sam_encoder.blocks.3.norm1.bias grad: -1.2400454352246015e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.748922947328538e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6066800299086026e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.245868128942675e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.057584879366914e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0226271115243435e-05
sam_encoder.blocks.3.norm2.bias grad: 1.5376112060039304e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.340927029668819e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.0096507543930784e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.0538732314889785e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.811174095375463e-08
sam_encoder.blocks.4.norm1.weight grad: -2.3228662030305713e-05
sam_encoder.blocks.4.norm1.bias grad: -4.2954934542649426e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.4054526218387764e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.816045475308783e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -5.819650141347665e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.524178737279726e-06
sam_encoder.blocks.4.norm2.weight grad: 1.5391154875032953e-06
sam_encoder.blocks.4.norm2.bias grad: 1.4903038390912116e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.2446541808894835e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.3343332057047519e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.0941828299546614e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.655288977228338e-07
sam_encoder.blocks.5.norm1.weight grad: -1.4291877960204147e-05
sam_encoder.blocks.5.norm1.bias grad: -1.6718111055524787e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.953456926974468e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.6072151538537582e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.8092480281193275e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.226143573760055e-06
sam_encoder.blocks.5.norm2.weight grad: 2.1911407657171367e-06
sam_encoder.blocks.5.norm2.bias grad: 8.181050361599773e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.0410751605813857e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.551218187818449e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.115364605349896e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.3076673844334437e-08
sam_encoder.blocks.6.norm1.weight grad: -8.767487997829448e-07
sam_encoder.blocks.6.norm1.bias grad: -2.6740698544358565e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.2701756279275287e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.4286877103586448e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.2408487154734757e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1957838523812825e-06
sam_encoder.blocks.6.norm2.weight grad: 2.745197889453266e-06
sam_encoder.blocks.6.norm2.bias grad: 2.3233412775880424e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.3857002108561574e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.9999970390927047e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.448100637295283e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.141637994805933e-06
sam_encoder.blocks.7.norm1.weight grad: -1.194471906273975e-06
sam_encoder.blocks.7.norm1.bias grad: 1.7160618881462142e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.197100100915122e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.598201818836969e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.990753374542692e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.903659249881457e-07
sam_encoder.blocks.7.norm2.weight grad: 4.5846491047996096e-07
sam_encoder.blocks.7.norm2.bias grad: 1.2273555505259992e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.5881431636444177e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.12586768258916e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.326275752144284e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.8744119024158863e-07
sam_encoder.blocks.8.norm1.weight grad: -2.951656597360852e-06
sam_encoder.blocks.8.norm1.bias grad: 4.62849948235089e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.2638075683498755e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.1325835203024326e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.5608146643207874e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.5470438888296485e-06
sam_encoder.blocks.8.norm2.weight grad: 1.7312731870333664e-07
sam_encoder.blocks.8.norm2.bias grad: -2.6397119654575363e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.2811234973451064e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.279312406652025e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.3435771961667342e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.530362609031727e-07
sam_encoder.blocks.9.norm1.weight grad: -2.2310082385956775e-06
sam_encoder.blocks.9.norm1.bias grad: -1.1156652135468903e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.029861540606362e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.955518709768512e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.0627688829554245e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.3732440038438654e-06
sam_encoder.blocks.9.norm2.weight grad: -2.5853494207694894e-06
sam_encoder.blocks.9.norm2.bias grad: -2.120454382747994e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.957160500562168e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.215328779835545e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.733218131354079e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.47305830878031e-07
sam_encoder.blocks.10.norm1.weight grad: 6.815135833448949e-08
sam_encoder.blocks.10.norm1.bias grad: -1.8181780205850373e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.3364400476566516e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.00408770373906e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.443588750291383e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.401961237159412e-07
sam_encoder.blocks.10.norm2.weight grad: -6.048335762898205e-06
sam_encoder.blocks.10.norm2.bias grad: -4.2348810893599875e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.408998625469394e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.190786517530796e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.702370127532049e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.948202215222409e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3461768503475469e-05
sam_encoder.blocks.11.norm1.bias grad: 2.135351678589359e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.8071264043537667e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.391514719121915e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.3710233563178917e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.4959118743718136e-06
sam_encoder.blocks.11.norm2.weight grad: -5.304111255099997e-06
sam_encoder.blocks.11.norm2.bias grad: -3.217588073312072e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.2655390264626476e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3002776313442155e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.651865416846704e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.3098183987713128e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.913108568871394e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.43671306129545e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.3998569556861185e-06
sam_encoder.neck.conv2.trainable_shift grad: 7.866100531828124e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002579960273578763
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3100943760946393e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0011481402907520533
mask_decoder.transformer.layers.0.norm2.bias grad: -8.125603199005127e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 6.919301813468337e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.127042484469712e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.42814042698592e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.189061529468745e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 0.00010046023817267269
mask_decoder.transformer.layers.1.norm1.bias grad: -4.126171916141175e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.405079405638389e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010041799396276474
mask_decoder.transformer.layers.1.norm3.weight grad: 5.605023034149781e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00010324952017981559
mask_decoder.transformer.layers.1.norm4.weight grad: 7.119181100279093e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -2.4873279471648857e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.496524393791333e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.4657927749794908e-05
Text_Embedding_Affine.0.weight grad: -7.448451577740656e-12
Text_Embedding_Affine.0.bias grad: -3.386671498795124e-10
Text_Embedding_Affine.2.weight grad: 2.7976870820012323e-11
Text_Embedding_Affine.2.bias grad: -9.072053217096254e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07735363394021988

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07735363394021988

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07647514343261719

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.43225958943367004

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07733535766601562

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07647514343261719

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.59708786010742
Max value: 71.39901733398438
Mean value: 64.36107635498047

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07657378911972046

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07657378911972046

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07657378911972046

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40759167075157166

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.09989498555660248
Max value: 129.7535400390625
Mean value: 1.0576074123382568

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.59708786010742
Max value: 71.39901733398438
Mean value: 64.36107635498047

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.65261840820312
Max value: -64.65261840820312
Mean value: -64.65261840820312
sam_encoder.pos_embed grad: -1.3453444580591167e-08
sam_encoder.blocks.0.norm1.weight grad: -2.7796629638032755e-06
sam_encoder.blocks.0.norm1.bias grad: 1.4593269952456467e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0268847745464882e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.7512370220629236e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.371703658354818e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.743017143482575e-07
sam_encoder.blocks.0.norm2.weight grad: 2.7586924261413515e-05
sam_encoder.blocks.0.norm2.bias grad: 1.5626637832610868e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.411776444612769e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.998269560019253e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.7289072275161743e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.6642787714954466e-06
sam_encoder.blocks.1.norm1.weight grad: -1.4120316791377263e-06
sam_encoder.blocks.1.norm1.bias grad: 2.0182169464533217e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.6732635635416955e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.085084922029637e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.9884100765921175e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 7.04329295331263e-07
sam_encoder.blocks.1.norm2.weight grad: 1.0070736607303843e-05
sam_encoder.blocks.1.norm2.bias grad: 2.4385570895901765e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.536965439503547e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0877583918045275e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.297659648320405e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.5591595001751557e-06
sam_encoder.blocks.2.norm1.weight grad: 8.729884939384647e-06
sam_encoder.blocks.2.norm1.bias grad: -7.303664460778236e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.743521458294708e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.335125135592534e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.040938852587715e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.7281730581307784e-06
sam_encoder.blocks.2.norm2.weight grad: -2.8305162231845316e-06
sam_encoder.blocks.2.norm2.bias grad: -8.825058102956973e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.805885287671117e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.515718506401754e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.869298327823344e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.507063628509059e-07
sam_encoder.blocks.3.norm1.weight grad: 3.51453127223067e-06
sam_encoder.blocks.3.norm1.bias grad: -6.5620552049949765e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.249285898869857e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4246476887080917e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.287792757575517e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.1630205537803704e-07
sam_encoder.blocks.3.norm2.weight grad: 2.974545623146696e-06
sam_encoder.blocks.3.norm2.bias grad: -2.4965097509266343e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.1791714718565345e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.794475772650912e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.70513793718419e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.023298409563722e-06
sam_encoder.blocks.4.norm1.weight grad: 2.2641615942120552e-05
sam_encoder.blocks.4.norm1.bias grad: -2.7528592454473255e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.227869051945163e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.965625299111707e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.450864930229727e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.043059445597464e-06
sam_encoder.blocks.4.norm2.weight grad: -4.213469219394028e-05
sam_encoder.blocks.4.norm2.bias grad: -3.075771746807732e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.8566375476657413e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.0445217412780039e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.543326331760909e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.980564535297162e-07
sam_encoder.blocks.5.norm1.weight grad: 1.2688848073594272e-05
sam_encoder.blocks.5.norm1.bias grad: -4.88269643028616e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.4288504947617184e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.4127224403637229e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.996735697204713e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.946040123992134e-06
sam_encoder.blocks.5.norm2.weight grad: -2.2483340217149816e-05
sam_encoder.blocks.5.norm2.bias grad: -1.408615480613662e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.886093721434008e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.5832770208799047e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.202580932613273e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.919207180544618e-07
sam_encoder.blocks.6.norm1.weight grad: 4.967505446984433e-06
sam_encoder.blocks.6.norm1.bias grad: 5.310436790750828e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.5054609977814835e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.426510832265194e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.047563611995429e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.264241735858377e-07
sam_encoder.blocks.6.norm2.weight grad: -1.327319387200987e-05
sam_encoder.blocks.6.norm2.bias grad: -3.236332076994586e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0038176696980372e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.3234390432189684e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1642780464171665e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.888562999549322e-07
sam_encoder.blocks.7.norm1.weight grad: 4.2302708607167006e-06
sam_encoder.blocks.7.norm1.bias grad: 2.0933346149831777e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.0999259504606016e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.359663428956992e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.653030722081894e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.5693340666730364e-07
sam_encoder.blocks.7.norm2.weight grad: 2.487823621777352e-06
sam_encoder.blocks.7.norm2.bias grad: 2.5208164515788667e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.352274805161869e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.551903435232816e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3732895922657917e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.463565907528391e-07
sam_encoder.blocks.8.norm1.weight grad: 1.9234248611610383e-06
sam_encoder.blocks.8.norm1.bias grad: -1.8557029761723243e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.9283172036921314e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.170980526576386e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.0541737032763194e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.4879677792123402e-06
sam_encoder.blocks.8.norm2.weight grad: -3.325556861000223e-07
sam_encoder.blocks.8.norm2.bias grad: -8.903185744202347e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.413735427670872e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.019728289174964e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.462294841938274e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.236211109149735e-07
sam_encoder.blocks.9.norm1.weight grad: 2.0793472685909364e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0832939096871996e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.148517061570601e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.327041089411068e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.0108757199705e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9668088668822747e-07
sam_encoder.blocks.9.norm2.weight grad: 5.732987119699828e-06
sam_encoder.blocks.9.norm2.bias grad: 9.008246024677646e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.1252797018387355e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.6012072592275217e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.917385798667965e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.205848527926719e-08
sam_encoder.blocks.10.norm1.weight grad: 6.92214507580502e-06
sam_encoder.blocks.10.norm1.bias grad: 1.2112006970710354e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.2758341603766894e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.4134493540041149e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7229087916348362e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0156627467949875e-06
sam_encoder.blocks.10.norm2.weight grad: 8.81464256963227e-06
sam_encoder.blocks.10.norm2.bias grad: 1.26714462567179e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.2752307055925485e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.8649923276825575e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.598500815220177e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.3434035395221144e-07
sam_encoder.blocks.11.norm1.weight grad: 1.415307997376658e-05
sam_encoder.blocks.11.norm1.bias grad: -2.191713974752929e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.8444347915647086e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6873704566933156e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.4672203860754962e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.270936634995451e-07
sam_encoder.blocks.11.norm2.weight grad: 1.124642130889697e-05
sam_encoder.blocks.11.norm2.bias grad: 1.76770754478639e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.267045137064997e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2895909549115459e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.376783747124136e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.305903355041664e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.9932554096158128e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.095112838811474e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.7633465176913887e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.533146915899124e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -4.1719038563314825e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.3009342839941382e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005954783409833908
mask_decoder.transformer.layers.0.norm2.bias grad: -8.519980474375188e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 8.224471457651816e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 1.7517737433081493e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.441446359734982e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.882182111032307e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.192825018544681e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 2.7323899303155486e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00016562500968575478
mask_decoder.transformer.layers.1.norm2.bias grad: 2.6476449420442805e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.366052219964331e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -8.66157188283978e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -8.644828631076962e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016811073874123394
mask_decoder.transformer.norm_final_attn.weight grad: 5.69959229324013e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.2209679829975357e-06
Text_Embedding_Affine.0.weight grad: 3.4709392478238232e-12
Text_Embedding_Affine.0.bias grad: 9.65014596010505e-11
Text_Embedding_Affine.2.weight grad: -1.7800034016191013e-11
Text_Embedding_Affine.2.bias grad: 1.0592571015877184e-06
Epoch 0 finished with average loss: -67.6760
Epoch 1/39
----------
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62.2]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-62.2]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-68.4]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-68.4]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-66.3]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-66.3]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07364675402641296

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07364675402641296

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0702977180480957

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3901909589767456

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07356071472167969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0702977180480957

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.498382568359375
Max value: 69.26806640625
Mean value: 62.15431594848633

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07364675402641296

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07364675402641296

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07364675402641296

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3901909589767456

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.498382568359375
Max value: 69.26806640625
Mean value: 62.15431594848633

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.1544303894043
Max value: -62.1544303894043
Mean value: -62.1544303894043
sam_encoder.pos_embed grad: -9.324713445835187e-09
sam_encoder.blocks.0.norm1.weight grad: -2.268602474941872e-05
sam_encoder.blocks.0.norm1.bias grad: 1.2741453247144818e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.1155469792356598e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.6965600480034482e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.5525935143377865e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.2941310362512013e-06
sam_encoder.blocks.0.norm2.weight grad: 4.675461968872696e-05
sam_encoder.blocks.0.norm2.bias grad: 2.570616743469145e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.102771865495015e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.7047408366343006e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5432880900334567e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.326672984054312e-06
sam_encoder.blocks.1.norm1.weight grad: -8.933235449148924e-07
sam_encoder.blocks.1.norm1.bias grad: -2.2381877329280542e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.8513486540759914e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.9568838044724544e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.9349226931808516e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.601963049324695e-06
sam_encoder.blocks.1.norm2.weight grad: 6.276571184571367e-06
sam_encoder.blocks.1.norm2.bias grad: -6.641886102443095e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.794250672712224e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.1701624771376373e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.394194082939066e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.582624802016653e-06
sam_encoder.blocks.2.norm1.weight grad: 2.0914430933771655e-06
sam_encoder.blocks.2.norm1.bias grad: -6.557061169587541e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.3047654142137617e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.225466909701936e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.549253666638833e-08
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0994828869570483e-07
sam_encoder.blocks.2.norm2.weight grad: 2.5508857106615324e-06
sam_encoder.blocks.2.norm2.bias grad: -1.1667010767268948e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.716767183614138e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.1698474483855534e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.6527223983284784e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.882841378479498e-07
sam_encoder.blocks.3.norm1.weight grad: 5.279271135805175e-06
sam_encoder.blocks.3.norm1.bias grad: -7.380463557637995e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.454338184383232e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.613925158191705e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.4182861579902237e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.9573467941190756e-07
sam_encoder.blocks.3.norm2.weight grad: 6.102571887822705e-07
sam_encoder.blocks.3.norm2.bias grad: 2.2218914637051057e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.723401272916817e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 8.480978976876941e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.8809741959557869e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8089301647705724e-06
sam_encoder.blocks.4.norm1.weight grad: 1.8633498257258907e-05
sam_encoder.blocks.4.norm1.bias grad: -6.529573056468507e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1910433386219665e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.958537834274466e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.013020083628362e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.17035572961322e-06
sam_encoder.blocks.4.norm2.weight grad: -3.3674470614641905e-05
sam_encoder.blocks.4.norm2.bias grad: -2.4479295461787842e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.270864206366241e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.609862223034725e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1635030122979515e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.207126842928119e-07
sam_encoder.blocks.5.norm1.weight grad: 8.26577888801694e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2970681382284965e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.718946224282263e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.056651027260159e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.22708490077639e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.006990588502958e-06
sam_encoder.blocks.5.norm2.weight grad: -1.7772032151697204e-05
sam_encoder.blocks.5.norm2.bias grad: -8.851062375470065e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.4899835453834385e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.1108853616169654e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.352020242658909e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.2761476853029308e-07
sam_encoder.blocks.6.norm1.weight grad: -2.653383489814587e-06
sam_encoder.blocks.6.norm1.bias grad: -2.8703950647468446e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.1226234991900128e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.751936669184943e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.021355253935326e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.029680091363844e-07
sam_encoder.blocks.6.norm2.weight grad: -1.43308416227228e-05
sam_encoder.blocks.6.norm2.bias grad: 8.837002383188519e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0714119525800925e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.96807342642569e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1982024261669721e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.239417646407674e-07
sam_encoder.blocks.7.norm1.weight grad: -1.021103798848344e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3955057056591613e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.625778051879024e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.254403597135024e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.05064593375937e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2637218560485053e-06
sam_encoder.blocks.7.norm2.weight grad: -1.921972852869658e-06
sam_encoder.blocks.7.norm2.bias grad: 3.565303586583468e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.204992241189757e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.0415866401890526e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.93427973474536e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.3404751320631476e-07
sam_encoder.blocks.8.norm1.weight grad: 9.679426966613391e-07
sam_encoder.blocks.8.norm1.bias grad: -1.3069615079075447e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.763294090385898e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.2998195586533257e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.7685043733072234e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.9499085485440446e-06
sam_encoder.blocks.8.norm2.weight grad: -8.970928320195526e-06
sam_encoder.blocks.8.norm2.bias grad: -9.362244099975214e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.428133696725126e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.7930053622403648e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.006174554480822e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0700986194933648e-06
sam_encoder.blocks.9.norm1.weight grad: -6.303552595454676e-07
sam_encoder.blocks.9.norm1.bias grad: 1.0077040997202857e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.282544983245316e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.094022743738606e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.744728401983593e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.504859240725636e-07
sam_encoder.blocks.9.norm2.weight grad: -3.851785550068598e-06
sam_encoder.blocks.9.norm2.bias grad: 6.656523510173429e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.174643552483758e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.824882929213345e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.610557541833259e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.968075018041418e-07
sam_encoder.blocks.10.norm1.weight grad: 6.839691195636988e-06
sam_encoder.blocks.10.norm1.bias grad: 7.172779419306607e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.08549715555273e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2308364603086375e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6341002719855169e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2802456694771536e-06
sam_encoder.blocks.10.norm2.weight grad: -3.336206191306701e-06
sam_encoder.blocks.10.norm2.bias grad: -2.607406202059792e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.6428929257017444e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -7.18607111593883e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.0392789679135603e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.319254796631867e-07
sam_encoder.blocks.11.norm1.weight grad: 8.096979399851989e-06
sam_encoder.blocks.11.norm1.bias grad: 6.289632210609852e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.247348675155081e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.6656408635972184e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.889665665861685e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2485355682656518e-06
sam_encoder.blocks.11.norm2.weight grad: -3.321542862977367e-07
sam_encoder.blocks.11.norm2.bias grad: -2.9291277314769104e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.640401579716126e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.414770948344085e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.5542061621308676e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.2639607045202865e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.87757164996583e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.9269396034360398e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.574064173037186e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.285844493599143e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.9319711757125333e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.5912155504338443e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005980512127280235
mask_decoder.transformer.layers.0.norm2.bias grad: -3.885608748532832e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -2.462417251081206e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.4369441487360746e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.640016651246697e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 9.076058631762862e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.040224540513009e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -8.572601473133545e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00018462738080415875
mask_decoder.transformer.layers.1.norm2.bias grad: 4.47285856353119e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -9.595216397428885e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -1.39105995913269e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.1536157116061077e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016015901928767562
mask_decoder.transformer.norm_final_attn.weight grad: 1.083437746274285e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.828756679373328e-06
Text_Embedding_Affine.0.weight grad: 3.935814781724778e-12
Text_Embedding_Affine.0.bias grad: 2.924475939192206e-11
Text_Embedding_Affine.2.weight grad: 2.4343088309008998e-11
Text_Embedding_Affine.2.bias grad: 5.057363523519598e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10925190150737762

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10925190150737762

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09692668914794922

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4409758150577545

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10933589935302734

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09692668914794922

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 64.32817840576172
Max value: 88.96509552001953
Mean value: 74.68473815917969

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1107301115989685

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1107301115989685

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1107301115989685

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4327811598777771

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.21840044856071472
Max value: 15.393449783325195
Mean value: 1.0164024829864502

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 64.32817840576172
Max value: 88.96509552001953
Mean value: 74.68473815917969

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -74.74414825439453
Max value: -74.74414825439453
Mean value: -74.74414825439453
sam_encoder.pos_embed grad: -1.5361609762010175e-09
sam_encoder.blocks.0.norm1.weight grad: -7.049678242765367e-05
sam_encoder.blocks.0.norm1.bias grad: 1.7625883629079908e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.491594609135063e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.2026076723923325e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.100553816968386e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.185152301441121e-07
sam_encoder.blocks.0.norm2.weight grad: 3.452657983871177e-05
sam_encoder.blocks.0.norm2.bias grad: 2.5226230718544684e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.5257404584190226e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.698761707302765e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.262235835194588e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.0626575860660523e-06
sam_encoder.blocks.1.norm1.weight grad: -5.659366252075415e-06
sam_encoder.blocks.1.norm1.bias grad: -5.883287485630717e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.235957254015375e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.105353703678702e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.2818147701618727e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.2975136769455275e-06
sam_encoder.blocks.1.norm2.weight grad: 9.792692253540736e-06
sam_encoder.blocks.1.norm2.bias grad: -1.1620963960012887e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.415173735760618e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.378394128754735e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.9695961428806186e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.3159818763597286e-06
sam_encoder.blocks.2.norm1.weight grad: 6.6716488618112635e-06
sam_encoder.blocks.2.norm1.bias grad: -3.4189210964541417e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.7224648369592614e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.802879503695294e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.9003098234170466e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.5728190848894883e-06
sam_encoder.blocks.2.norm2.weight grad: 5.448394404083956e-06
sam_encoder.blocks.2.norm2.bias grad: 1.1676851485731277e-08
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.8095629406598164e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.2953342926921323e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.4946921282898984e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.977913440981865e-08
sam_encoder.blocks.3.norm1.weight grad: -1.2799598152923863e-05
sam_encoder.blocks.3.norm1.bias grad: -1.4686245322081959e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.2259911222354276e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.512591650993272e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0287234175621052e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.581492695862835e-07
sam_encoder.blocks.3.norm2.weight grad: 1.63349395734258e-05
sam_encoder.blocks.3.norm2.bias grad: 8.846302989695687e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2487626008805819e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.3320478653186e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.2243376608676044e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.916495974313875e-07
sam_encoder.blocks.4.norm1.weight grad: -7.967755664139986e-06
sam_encoder.blocks.4.norm1.bias grad: 1.840255208662711e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.272177077131346e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.9254589460615534e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2078987765562488e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.387593766201462e-07
sam_encoder.blocks.4.norm2.weight grad: -6.473003850260284e-06
sam_encoder.blocks.4.norm2.bias grad: -2.3736072307656286e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.169428732187953e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.7302776313954382e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.5343961169710383e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.63621120161406e-07
sam_encoder.blocks.5.norm1.weight grad: 1.5845565712879761e-06
sam_encoder.blocks.5.norm1.bias grad: 6.1158989410614595e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.070811888188473e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.3504024991561892e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.4011836810823297e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.2620672268658382e-07
sam_encoder.blocks.5.norm2.weight grad: -6.264792773436056e-07
sam_encoder.blocks.5.norm2.bias grad: 1.736661943141371e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0412046549390652e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.706044134967669e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.943258894243627e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.8306595822868985e-07
sam_encoder.blocks.6.norm1.weight grad: 4.0192267078964505e-06
sam_encoder.blocks.6.norm1.bias grad: 2.3333102490141755e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.4153462163667427e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.761776371102314e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.7418815332348458e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0028858241639682e-06
sam_encoder.blocks.6.norm2.weight grad: -2.508158445380104e-07
sam_encoder.blocks.6.norm2.bias grad: -9.779763558981358e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.594606591330376e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.187299277371494e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.2939129874212085e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.4589197639434133e-07
sam_encoder.blocks.7.norm1.weight grad: 2.2094563973951153e-06
sam_encoder.blocks.7.norm1.bias grad: 1.7321485756838229e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.9931750304967863e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.527672793599777e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.6561946267756866e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.056765980451019e-07
sam_encoder.blocks.7.norm2.weight grad: 3.2174953048524912e-06
sam_encoder.blocks.7.norm2.bias grad: -8.148655972206598e-09
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.7021205849232501e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.2702292906396906e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.735222536415677e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.017238891014131e-08
sam_encoder.blocks.8.norm1.weight grad: -2.8373076474963455e-06
sam_encoder.blocks.8.norm1.bias grad: 2.7709825189958792e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.039019702555379e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.331705541626434e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.030137231187837e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.413938760691963e-07
sam_encoder.blocks.8.norm2.weight grad: 2.208440946560586e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4727578445672407e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.5327180992462672e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.6787242884674924e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4269216990214773e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.883978365593066e-07
sam_encoder.blocks.9.norm1.weight grad: 1.4231317209123517e-06
sam_encoder.blocks.9.norm1.bias grad: -2.6074036441059434e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.5628625078534242e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.137594608735526e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.514303893505712e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.444327027566032e-07
sam_encoder.blocks.9.norm2.weight grad: 2.0013728772028117e-06
sam_encoder.blocks.9.norm2.bias grad: -9.532449212201755e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7612362626096e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.872901738257497e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.541033552461158e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.009360287047457e-07
sam_encoder.blocks.10.norm1.weight grad: 4.232898618283798e-07
sam_encoder.blocks.10.norm1.bias grad: -8.073483286352712e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.9025168285224936e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.925716888872557e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.956013981427532e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.317523239980801e-07
sam_encoder.blocks.10.norm2.weight grad: 1.267175662178488e-06
sam_encoder.blocks.10.norm2.bias grad: -1.5796501884324243e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.3591787819677847e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.5919356378144585e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.619801405984617e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.9581091237341752e-07
sam_encoder.blocks.11.norm1.weight grad: 5.663867341354489e-06
sam_encoder.blocks.11.norm1.bias grad: -5.402732767834095e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.4501373470920953e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.539504286389274e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1385602647351334e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.177623047027737e-07
sam_encoder.blocks.11.norm2.weight grad: 1.2153755051258486e-06
sam_encoder.blocks.11.norm2.bias grad: -4.550531116365164e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.3316229089687113e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.8943318025321787e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.646294074627804e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.172232598240953e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.9421115616278257e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.17178204972879e-06
sam_encoder.neck.conv2.trainable_scale grad: -7.063144948915578e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.2958699699083809e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018249175627715886
mask_decoder.transformer.layers.0.norm1.bias grad: -4.945650289300829e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0034194993786513805
mask_decoder.transformer.layers.0.norm2.bias grad: 9.63543716352433e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 3.4039207093883306e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.716564970090985e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.350496161961928e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.9251347112003714e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.358231232501566e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.8970198400202207e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00010339036816731095
mask_decoder.transformer.layers.1.norm2.bias grad: 8.568180783186108e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.4953230826649815e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.145749259507284e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.182214514818043e-07
mask_decoder.transformer.layers.1.norm4.bias grad: -7.416008156724274e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.6141759260790423e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.1114332664874382e-05
Text_Embedding_Affine.0.weight grad: 1.1770156030377343e-11
Text_Embedding_Affine.0.bias grad: 3.170661788676199e-10
Text_Embedding_Affine.2.weight grad: 1.717589265259889e-10
Text_Embedding_Affine.2.bias grad: -8.75174009706825e-07

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09071800112724304

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09071800112724304

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08455848693847656

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4217680096626282

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09076690673828125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08455848693847656

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.76892852783203
Max value: 71.50901794433594
Mean value: 61.59751892089844

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09117116779088974

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09117116779088974

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09117116779088974

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.399418443441391

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.31796789169311523
Max value: 52.274845123291016
Mean value: 1.0474693775177002

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.76892852783203
Max value: 71.50901794433594
Mean value: 61.59751892089844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.879268646240234
Max value: -61.879268646240234
Mean value: -61.879268646240234
sam_encoder.pos_embed grad: 1.5630689631507266e-08
sam_encoder.blocks.0.norm1.weight grad: -3.509228554321453e-05
sam_encoder.blocks.0.norm1.bias grad: -4.134707523917314e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.929756869387347e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.447832739311707e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.369255528516078e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.104676456037851e-07
sam_encoder.blocks.0.norm2.weight grad: -2.745062010944821e-05
sam_encoder.blocks.0.norm2.bias grad: -2.189975930377841e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.1319846129918005e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.991679699945962e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2794385838788003e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.176241979323095e-06
sam_encoder.blocks.1.norm1.weight grad: -5.551469712372636e-06
sam_encoder.blocks.1.norm1.bias grad: 4.100547812413424e-08
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.860573426412884e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1571645472940872e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.2291803816187894e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.3670010048372205e-06
sam_encoder.blocks.1.norm2.weight grad: -3.0803203117102385e-06
sam_encoder.blocks.1.norm2.bias grad: -1.9022711512661772e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.2323081212744e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.015436504938407e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.9740938316535903e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.923946001625154e-06
sam_encoder.blocks.2.norm1.weight grad: -4.667206212616293e-06
sam_encoder.blocks.2.norm1.bias grad: 2.1320570340321865e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.5539800390106393e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.897768579008698e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 9.634030675442773e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0511495247556013e-06
sam_encoder.blocks.2.norm2.weight grad: 7.94169227447128e-06
sam_encoder.blocks.2.norm2.bias grad: 7.010433819232276e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.577949872938916e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.6431988519325387e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.8770195993056404e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.301672902329301e-07
sam_encoder.blocks.3.norm1.weight grad: -4.29746205554693e-06
sam_encoder.blocks.3.norm1.bias grad: 2.8327067411737517e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.6343254856110434e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.8957134645679616e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.2469613958928676e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.904955398567836e-07
sam_encoder.blocks.3.norm2.weight grad: 4.470648491405882e-06
sam_encoder.blocks.3.norm2.bias grad: 7.133923645596951e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.4601182556361891e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.041129374054435e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.528283170657232e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.74399654296576e-07
sam_encoder.blocks.4.norm1.weight grad: -2.841906825779006e-05
sam_encoder.blocks.4.norm1.bias grad: -2.569168600530247e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.663105285842903e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.320304469729308e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.637192538823001e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.322408014762914e-06
sam_encoder.blocks.4.norm2.weight grad: 3.551682675606571e-05
sam_encoder.blocks.4.norm2.bias grad: 2.7880199922947213e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.3821339709684253e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 9.20856837183237e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.707191767598488e-08
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.05269856223822e-07
sam_encoder.blocks.5.norm1.weight grad: -1.9378847355255857e-05
sam_encoder.blocks.5.norm1.bias grad: -1.121501895795518e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.799295185075607e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5486501752093318e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.436197170638479e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.785453595308354e-06
sam_encoder.blocks.5.norm2.weight grad: 1.7738784663379192e-05
sam_encoder.blocks.5.norm2.bias grad: 1.3259859770187177e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 7.522167834395077e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.5150554847641615e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.6685358989197994e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.382456601590093e-07
sam_encoder.blocks.6.norm1.weight grad: -5.090816102892859e-06
sam_encoder.blocks.6.norm1.bias grad: -6.036963895894587e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.8311558253335534e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.26622863819648e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.831666168072843e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.3423119677754585e-07
sam_encoder.blocks.6.norm2.weight grad: 1.0272447070747148e-05
sam_encoder.blocks.6.norm2.bias grad: 5.010260792914778e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.9475743152434e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.6200315207679523e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.352899385499768e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1582726529013598e-06
sam_encoder.blocks.7.norm1.weight grad: -6.534005478897598e-06
sam_encoder.blocks.7.norm1.bias grad: -7.482353225896077e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.4894690088549396e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.6446276731585385e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.0510765352810267e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.369230393625912e-07
sam_encoder.blocks.7.norm2.weight grad: -4.4092485040891916e-06
sam_encoder.blocks.7.norm2.bias grad: -3.234662472095806e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.016077582491562e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.9630086828547064e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.052534457812726e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.848774773970945e-07
sam_encoder.blocks.8.norm1.weight grad: -3.367266799614299e-06
sam_encoder.blocks.8.norm1.bias grad: 3.602879587560892e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.5127338883758057e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.2838354374907794e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.3711420403269585e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.2029881822381867e-06
sam_encoder.blocks.8.norm2.weight grad: -3.369850674062036e-06
sam_encoder.blocks.8.norm2.bias grad: -5.54596226720605e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.3601752420509e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.4468126892097644e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.1688401713172425e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.184795099921757e-07
sam_encoder.blocks.9.norm1.weight grad: -3.6428925795917166e-06
sam_encoder.blocks.9.norm1.bias grad: -1.4649679087597178e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.941204345712322e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.2299645959501504e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.995583241106942e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0540176162976422e-06
sam_encoder.blocks.9.norm2.weight grad: -1.1038303455279674e-05
sam_encoder.blocks.9.norm2.bias grad: -2.822573833327624e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.796036697982345e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.017738319816999e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6132066775753628e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.72523061287211e-07
sam_encoder.blocks.10.norm1.weight grad: -6.810061677242629e-06
sam_encoder.blocks.10.norm1.bias grad: -2.571204959167517e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.975881898237276e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.4756958535144804e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.344113115919754e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.522856779156427e-07
sam_encoder.blocks.10.norm2.weight grad: -1.66314475791296e-05
sam_encoder.blocks.10.norm2.bias grad: -4.866121344093699e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.47866522235563e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.607146820490016e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.8893485957960365e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.415837330881914e-07
sam_encoder.blocks.11.norm1.weight grad: -2.286152266606223e-05
sam_encoder.blocks.11.norm1.bias grad: 9.507124332230887e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.5811100411156076e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.941481736546848e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.7548065898154164e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.0773230769700604e-06
sam_encoder.blocks.11.norm2.weight grad: -1.727143353491556e-05
sam_encoder.blocks.11.norm2.bias grad: -4.537530003290158e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -8.068080205703154e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.726268576225266e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2421436395015917e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.9954114804932033e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.381019375112373e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.9176500902394764e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.493428372777998e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.1216247912670951e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010540086077526212
mask_decoder.transformer.layers.0.norm1.bias grad: 2.5005865609273314e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0058752670884132385
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00021337991347536445
mask_decoder.transformer.layers.0.norm3.weight grad: -8.570154022891074e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -1.2573509593494236e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.157849955139682e-06
mask_decoder.transformer.layers.0.norm4.bias grad: -6.770795152988285e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.8687405321979895e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.3789923438453116e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.000192251056432724
mask_decoder.transformer.layers.1.norm2.bias grad: 1.9306120520923287e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.951377195538953e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.556262087542564e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00014280756295192987
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016260820848401636
mask_decoder.transformer.norm_final_attn.weight grad: 1.0011521226260811e-05
mask_decoder.transformer.norm_final_attn.bias grad: 5.715880888601532e-06
Text_Embedding_Affine.0.weight grad: -9.820920118808196e-12
Text_Embedding_Affine.0.bias grad: -2.9726890393710903e-10
Text_Embedding_Affine.2.weight grad: -6.621461712263965e-11
Text_Embedding_Affine.2.bias grad: 4.133575203013606e-06
Epoch 1 finished with average loss: -66.2593
Epoch 2/39
----------
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.2]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-64.2]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-63.4]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-63.4]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-63.6]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-63.6]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08428673446178436

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08428673446178436

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0821695327758789

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4001026749610901

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08439493179321289

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0821695327758789

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 32.57992935180664
Max value: 89.84246063232422
Mean value: 64.20980072021484

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08428673446178436

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08428673446178436

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08428673446178436

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4001026749610901

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 32.57992935180664
Max value: 89.84246063232422
Mean value: 64.20980072021484

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.20994567871094
Max value: -64.20994567871094
Mean value: -64.20994567871094
sam_encoder.pos_embed grad: 1.7399315765942447e-08
sam_encoder.blocks.0.norm1.weight grad: 1.8155651559936814e-06
sam_encoder.blocks.0.norm1.bias grad: -1.1760384950321168e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -8.412882380071096e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.146301423839759e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.622249086125521e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.7743753915056004e-06
sam_encoder.blocks.0.norm2.weight grad: -2.802328162943013e-05
sam_encoder.blocks.0.norm2.bias grad: -1.9394296032260172e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.4965125855233055e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.47782179233036e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.701187102298718e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.669550879858434e-06
sam_encoder.blocks.1.norm1.weight grad: -4.124550287087914e-06
sam_encoder.blocks.1.norm1.bias grad: 4.750620519189397e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.910576303198468e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2110962188671692e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.373137360540568e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.8194059521192685e-06
sam_encoder.blocks.1.norm2.weight grad: -2.2755830286769196e-05
sam_encoder.blocks.1.norm2.bias grad: -1.923891431943048e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.50579227617709e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.1098713912360836e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.340738996688742e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.28028976987116e-07
sam_encoder.blocks.2.norm1.weight grad: -6.065034085622756e-06
sam_encoder.blocks.2.norm1.bias grad: 9.223965207638685e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.0740754886646755e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.877169069075535e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.4145598470349796e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.456098630114866e-06
sam_encoder.blocks.2.norm2.weight grad: 1.6617159417364746e-05
sam_encoder.blocks.2.norm2.bias grad: -8.768298584982404e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.4696952146478e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.913552063750103e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.168905995058594e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4088861917116446e-06
sam_encoder.blocks.3.norm1.weight grad: -1.0927406037808396e-05
sam_encoder.blocks.3.norm1.bias grad: 1.0115634722751565e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.6644756871974096e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.700189841358224e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.653394287539413e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.360443300465704e-07
sam_encoder.blocks.3.norm2.weight grad: 3.915844899893273e-06
sam_encoder.blocks.3.norm2.bias grad: 1.6279567489618785e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2620923826034414e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.584418439255387e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.334708698181203e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.660094085309538e-06
sam_encoder.blocks.4.norm1.weight grad: -2.7257265173830092e-05
sam_encoder.blocks.4.norm1.bias grad: 1.0924838989012642e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.357464770990191e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.0112748845567694e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.88877787272213e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.0938100432395e-06
sam_encoder.blocks.4.norm2.weight grad: 3.54737821908202e-05
sam_encoder.blocks.4.norm2.bias grad: 3.092123370151967e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.400343510089442e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.0390980605734512e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.000015683734091e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.6447060602331476e-07
sam_encoder.blocks.5.norm1.weight grad: -1.637770765228197e-05
sam_encoder.blocks.5.norm1.bias grad: 1.0367373761255294e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.1563245001016185e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.682438664829533e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.5468401620164514e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.641720690618968e-06
sam_encoder.blocks.5.norm2.weight grad: 6.899011623318074e-06
sam_encoder.blocks.5.norm2.bias grad: 1.869389416242484e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.205230319101247e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.199257995831431e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.809876703708142e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.174794637241575e-07
sam_encoder.blocks.6.norm1.weight grad: -1.1437441571615636e-05
sam_encoder.blocks.6.norm1.bias grad: -4.032824563182658e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.263348718173802e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.3037614482745994e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.3890171380335232e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.614481445561978e-06
sam_encoder.blocks.6.norm2.weight grad: 1.7761900380719453e-05
sam_encoder.blocks.6.norm2.bias grad: 4.715765498986002e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.5519955923082307e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.590483735635644e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1352685760357417e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.5869763956288807e-06
sam_encoder.blocks.7.norm1.weight grad: -9.412480721948668e-06
sam_encoder.blocks.7.norm1.bias grad: 5.566057552641723e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.250214482861338e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.5296963030996267e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.3061760404962115e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.6502630160175613e-06
sam_encoder.blocks.7.norm2.weight grad: -2.8341082725091837e-06
sam_encoder.blocks.7.norm2.bias grad: -2.4924406716309022e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.2228696252568625e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.149108907673508e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.368802243945538e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.199852577992715e-07
sam_encoder.blocks.8.norm1.weight grad: -7.076424935803516e-06
sam_encoder.blocks.8.norm1.bias grad: 4.841930149268592e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.610994205402676e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.966123929581954e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.587456598732388e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.596757551349583e-06
sam_encoder.blocks.8.norm2.weight grad: -1.2857420870204805e-06
sam_encoder.blocks.8.norm2.bias grad: -2.1874302547075786e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.389899580317433e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.593816930129833e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.3910857887822203e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.953122806407919e-07
sam_encoder.blocks.9.norm1.weight grad: -5.377108664106345e-06
sam_encoder.blocks.9.norm1.bias grad: -1.2343523394520162e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.398701664991677e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.775089799593843e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.6316520259351819e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.3604230844066478e-06
sam_encoder.blocks.9.norm2.weight grad: -8.704711945028976e-06
sam_encoder.blocks.9.norm2.bias grad: -1.930080316014937e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.318206033029128e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.7112855605082586e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.825373828978627e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.8359627296813414e-07
sam_encoder.blocks.10.norm1.weight grad: -8.795346730039455e-06
sam_encoder.blocks.10.norm1.bias grad: -2.4835378553689225e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.118460765312193e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.0007264538435265e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.9823346519842744e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.769315738594742e-07
sam_encoder.blocks.10.norm2.weight grad: -1.5818657630006783e-05
sam_encoder.blocks.10.norm2.bias grad: -4.061370418639854e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.454029739368707e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.036587597511243e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.9709041225723922e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.948726311544306e-07
sam_encoder.blocks.11.norm1.weight grad: -2.252702324767597e-05
sam_encoder.blocks.11.norm1.bias grad: 1.7019692677422427e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -8.657329999550711e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2678638938723452e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.617062818899285e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.5302036899811355e-06
sam_encoder.blocks.11.norm2.weight grad: -1.8769480448099785e-05
sam_encoder.blocks.11.norm2.bias grad: -4.527839791990118e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.022423910209909e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.7089026843896136e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.666738512540178e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.580796033020306e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0491885404917412e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.616680623963475e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8884929886553437e-07
sam_encoder.neck.conv2.trainable_shift grad: 9.129602403845638e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -9.467496420256793e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.7300699255429208e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005790247581899166
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002540809800848365
mask_decoder.transformer.layers.0.norm3.weight grad: 8.847768185660243e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 7.18327282811515e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -4.465559686650522e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.463105819420889e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.841895522782579e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.83805615658639e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00019889445684384555
mask_decoder.transformer.layers.1.norm2.bias grad: 3.799951809924096e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.9405374738853425e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.53949537081644e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00012431261711753905
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016976677579805255
mask_decoder.transformer.norm_final_attn.weight grad: 5.7719144024304114e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.9571692721219733e-06
Text_Embedding_Affine.0.weight grad: 2.9322230407635708e-12
Text_Embedding_Affine.0.bias grad: 1.3301089396566823e-10
Text_Embedding_Affine.2.weight grad: -1.6928923540771024e-12
Text_Embedding_Affine.2.bias grad: 1.362781404168345e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08605760335922241

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08605760335922241

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07812738418579102

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3912067711353302

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08620643615722656

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07812738418579102

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.80147171020508
Max value: 75.26467895507812
Mean value: 62.30482482910156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08513200283050537

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08513200283050537

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08513200283050537

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3786943256855011

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.4415690004825592
Max value: 6.0
Mean value: 1.0170537233352661

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.80147171020508
Max value: 75.26467895507812
Mean value: 62.30482482910156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.656837463378906
Max value: -62.656837463378906
Mean value: -62.656837463378906
sam_encoder.pos_embed grad: -1.4153396232785553e-09
sam_encoder.blocks.0.norm1.weight grad: -3.0238406907301396e-05
sam_encoder.blocks.0.norm1.bias grad: 1.5951767409205786e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.311940516454342e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.864012801888748e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.9073643215961056e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.9812337086477783e-06
sam_encoder.blocks.0.norm2.weight grad: 3.0869014153722674e-05
sam_encoder.blocks.0.norm2.bias grad: -1.58073289640015e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4763931176275946e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.0318441127310507e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.000390491564758e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.27861982138711e-06
sam_encoder.blocks.1.norm1.weight grad: -1.246549572897493e-06
sam_encoder.blocks.1.norm1.bias grad: 2.43703652813565e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.154248123697471e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2923603662784444e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.117266366345575e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.6485696455201833e-06
sam_encoder.blocks.1.norm2.weight grad: 1.1622024430835154e-05
sam_encoder.blocks.1.norm2.bias grad: -1.1756826268083387e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.5344255643867655e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.773452696506865e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.579549113259418e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.2881643840501056e-07
sam_encoder.blocks.2.norm1.weight grad: -7.814492164470721e-06
sam_encoder.blocks.2.norm1.bias grad: -2.06004006031435e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.91687444789568e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.365492476514191e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.487154562113574e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.5327636851434363e-06
sam_encoder.blocks.2.norm2.weight grad: -5.0636895139177795e-06
sam_encoder.blocks.2.norm2.bias grad: 9.966310244635679e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.596014266804559e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.737878036095935e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.761936687216803e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.732364224466437e-07
sam_encoder.blocks.3.norm1.weight grad: -1.0516931070014834e-05
sam_encoder.blocks.3.norm1.bias grad: -3.3437618185416795e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.123577921040123e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.585261639382225e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.1086117360246135e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.5152321566347382e-06
sam_encoder.blocks.3.norm2.weight grad: 5.289141881803516e-06
sam_encoder.blocks.3.norm2.bias grad: 6.810478225816041e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.717781848739833e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.172162794522592e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.771173169297981e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5815965070942184e-06
sam_encoder.blocks.4.norm1.weight grad: -8.2028664110112e-06
sam_encoder.blocks.4.norm1.bias grad: -5.031515684095211e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.98718997935066e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2673554010689259e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.4113314793794416e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5577347767248284e-06
sam_encoder.blocks.4.norm2.weight grad: -5.724586571886903e-06
sam_encoder.blocks.4.norm2.bias grad: 4.000239641754888e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.640431027131854e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6353205865016207e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.1731347058230313e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.3126374060211674e-07
sam_encoder.blocks.5.norm1.weight grad: -6.86988187226234e-06
sam_encoder.blocks.5.norm1.bias grad: 2.1707360247091856e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.623703716788441e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.8574809185499817e-09
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.929721747728763e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.8233877199236304e-06
sam_encoder.blocks.5.norm2.weight grad: -2.8090978503314545e-06
sam_encoder.blocks.5.norm2.bias grad: 8.194318752430263e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2265262487053405e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.659497960801673e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.507503252985771e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.6769287703464215e-07
sam_encoder.blocks.6.norm1.weight grad: 3.0869891816109885e-06
sam_encoder.blocks.6.norm1.bias grad: 3.032212362086284e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2187547326902859e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.588867917234893e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.811534826236311e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.955562538569211e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1003542113030562e-06
sam_encoder.blocks.6.norm2.bias grad: 1.683491461790254e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.823190586947021e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.183622751152143e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.2331855714364792e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.125401194457254e-08
sam_encoder.blocks.7.norm1.weight grad: -1.944461473613046e-06
sam_encoder.blocks.7.norm1.bias grad: 1.2232676454004832e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.820054068157333e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0917044335201354e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.695207280747127e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.478367946423532e-07
sam_encoder.blocks.7.norm2.weight grad: -1.5620994986420556e-07
sam_encoder.blocks.7.norm2.bias grad: -4.787253828908433e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.8863343004559283e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.191585271153599e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.500597689613642e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.3182743663928704e-07
sam_encoder.blocks.8.norm1.weight grad: -6.5985877881757915e-06
sam_encoder.blocks.8.norm1.bias grad: 2.3701666123088216e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.119462108879816e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.4845621737767942e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.6428939488832839e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.2029822755721398e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0183230187976733e-06
sam_encoder.blocks.8.norm2.bias grad: -2.5456170078541618e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.6889198377612047e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.014864197823044e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.115228769776877e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.581150676585821e-07
sam_encoder.blocks.9.norm1.weight grad: -1.1197382718819426e-06
sam_encoder.blocks.9.norm1.bias grad: -1.8659582678992592e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.14502937423822e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.450948942278046e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.1660514448740287e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.8068725416451343e-07
sam_encoder.blocks.9.norm2.weight grad: 8.579374366490811e-07
sam_encoder.blocks.9.norm2.bias grad: -1.122003823184059e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.2348511972959386e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.318289998333057e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.857064332483787e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.8570946142281173e-07
sam_encoder.blocks.10.norm1.weight grad: 6.215543066900864e-07
sam_encoder.blocks.10.norm1.bias grad: -6.151641969154298e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.6520920098628267e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.583015531054116e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.813322789232188e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.48315767900931e-07
sam_encoder.blocks.10.norm2.weight grad: -7.057680591060489e-07
sam_encoder.blocks.10.norm2.bias grad: -2.5019521672220435e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.831241765008599e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.360598376886628e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.669387281974196e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.152106723471661e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0126915185537655e-05
sam_encoder.blocks.11.norm1.bias grad: 3.580253178370185e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.425643510330701e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.334154025149473e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.660204816289479e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.146754584624432e-06
sam_encoder.blocks.11.norm2.weight grad: -9.519404784441576e-07
sam_encoder.blocks.11.norm2.bias grad: -2.4065775505732745e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.482348125136923e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.471711238489661e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.940658406369039e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.3861533665913157e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.4333803594345227e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3582230167230591e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.851273716776632e-07
sam_encoder.neck.conv2.trainable_shift grad: -9.332828994956799e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019802073074970394
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6550366126466542e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0034376662224531174
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001824157079681754
mask_decoder.transformer.layers.0.norm3.weight grad: 1.0921561624854803e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.3680011508986354e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.639088628115132e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.672286639921367e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 7.50255276216194e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.7280644897255115e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.00725072924979e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010234248475171626
mask_decoder.transformer.layers.1.norm3.weight grad: 4.394764982862398e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.602499342989177e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.397291271132417e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00012377992970868945
mask_decoder.transformer.norm_final_attn.weight grad: 1.5392255590995774e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.15319671749603e-05
Text_Embedding_Affine.0.weight grad: 2.4945427667955045e-12
Text_Embedding_Affine.0.bias grad: -3.4612590571470037e-13
Text_Embedding_Affine.2.weight grad: -1.5445936196734067e-11
Text_Embedding_Affine.2.bias grad: 1.9867911760229617e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11308670043945312

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11308670043945312

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0983285903930664

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3754349648952484

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11300468444824219

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0983285903930664

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 43.984962463378906
Max value: 76.31902313232422
Mean value: 63.64244079589844

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11137092113494873

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11137092113494873

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11137092113494873

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.346779465675354

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.3183228075504303
Max value: 20.000001907348633
Mean value: 1.0534743070602417

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 43.984962463378906
Max value: 76.31902313232422
Mean value: 63.64244079589844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.05757904052734
Max value: -64.05757904052734
Mean value: -64.05757904052734
sam_encoder.pos_embed grad: -1.5026330402179155e-08
sam_encoder.blocks.0.norm1.weight grad: 1.1486738912935834e-05
sam_encoder.blocks.0.norm1.bias grad: 2.895016768889036e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.985769912011165e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8295563108949864e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.860065463522915e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.524060048221145e-07
sam_encoder.blocks.0.norm2.weight grad: 4.8999943828675896e-05
sam_encoder.blocks.0.norm2.bias grad: 1.7445348930777982e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.0417066732770763e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.941668966144789e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.4362037947867066e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.849933121586218e-06
sam_encoder.blocks.1.norm1.weight grad: 3.6350263599160826e-06
sam_encoder.blocks.1.norm1.bias grad: 7.837310477043502e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.6578501294570742e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.6468160285730846e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.920958645016071e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.5959862764702848e-07
sam_encoder.blocks.1.norm2.weight grad: 1.9715250800800277e-06
sam_encoder.blocks.1.norm2.bias grad: -3.054302169402945e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.070417278649984e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.4137718191450404e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.328118383360561e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.216278400941519e-06
sam_encoder.blocks.2.norm1.weight grad: 1.5502255337196402e-05
sam_encoder.blocks.2.norm1.bias grad: -3.420809662202373e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.88677698437823e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.0351734545110958e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7574910771145369e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.658317953319056e-06
sam_encoder.blocks.2.norm2.weight grad: -3.1987256079446524e-06
sam_encoder.blocks.2.norm2.bias grad: -1.4223401194612961e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.786830353012192e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.0932284314767458e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.42563794220041e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.609342120900692e-06
sam_encoder.blocks.3.norm1.weight grad: 3.589182142604841e-06
sam_encoder.blocks.3.norm1.bias grad: -3.0580549719161354e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.890416676062159e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.525689937892821e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.208336636362219e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.57557700126199e-07
sam_encoder.blocks.3.norm2.weight grad: 2.0460295218072133e-06
sam_encoder.blocks.3.norm2.bias grad: -7.192045359261101e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.462013526383089e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.627822237234795e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.754348189337179e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.031767500440765e-07
sam_encoder.blocks.4.norm1.weight grad: 3.318194285384379e-05
sam_encoder.blocks.4.norm1.bias grad: -2.911041519837454e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.734876786940731e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.847952823183732e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.163106031133793e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.6020485317276325e-06
sam_encoder.blocks.4.norm2.weight grad: -5.8454592362977564e-05
sam_encoder.blocks.4.norm2.bias grad: -3.4717082598945126e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.017777246190235e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.4491035472019576e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.240345000041998e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.774750206910539e-07
sam_encoder.blocks.5.norm1.weight grad: 2.8586733606061898e-05
sam_encoder.blocks.5.norm1.bias grad: -7.738065505691338e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.6313519154209644e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.994664100697264e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.960190148674883e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.594123533432139e-06
sam_encoder.blocks.5.norm2.weight grad: -2.8007954824715853e-05
sam_encoder.blocks.5.norm2.bias grad: -1.5012414223747328e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.280370543099707e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.3673417167156e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.91735078059719e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.364636308513582e-07
sam_encoder.blocks.6.norm1.weight grad: 8.648694347357377e-06
sam_encoder.blocks.6.norm1.bias grad: 5.474248609971255e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.01783870276995e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0978617410728475e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.4049614896503044e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0947678674710914e-06
sam_encoder.blocks.6.norm2.weight grad: -1.352114304609131e-05
sam_encoder.blocks.6.norm2.bias grad: -3.4453278203727677e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.907107596518472e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.790094862983096e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.826324584428221e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.774205303372582e-07
sam_encoder.blocks.7.norm1.weight grad: 7.17476723366417e-06
sam_encoder.blocks.7.norm1.bias grad: 2.845916924343328e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.1806221159058623e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6761781580498791e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.8496546090318589e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.3397137763604405e-06
sam_encoder.blocks.7.norm2.weight grad: 2.5667591216915753e-06
sam_encoder.blocks.7.norm2.bias grad: 3.4740039609459927e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.3996288948401343e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.323559205156926e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3681360542250331e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.311764195743308e-07
sam_encoder.blocks.8.norm1.weight grad: 6.759401912859175e-06
sam_encoder.blocks.8.norm1.bias grad: -1.605196644050011e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.9759028166154167e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.994721282651881e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.7649733712896705e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.131916744474438e-06
sam_encoder.blocks.8.norm2.weight grad: -3.007380655617453e-08
sam_encoder.blocks.8.norm2.bias grad: -6.825193850090727e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.934198508024565e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.698595895049948e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.026671487939893e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.581450975318148e-07
sam_encoder.blocks.9.norm1.weight grad: 2.0576437691488536e-06
sam_encoder.blocks.9.norm1.bias grad: 1.3494822042048327e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.291775078016144e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.574316901402199e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.88178044281085e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0110644410588066e-07
sam_encoder.blocks.9.norm2.weight grad: 6.2523081396648195e-06
sam_encoder.blocks.9.norm2.bias grad: 1.959520204763976e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.41900465375511e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.417736823190353e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.529692212898226e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.425766230222507e-08
sam_encoder.blocks.10.norm1.weight grad: 7.973136234795675e-06
sam_encoder.blocks.10.norm1.bias grad: 1.7587716456546332e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.738072337000631e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.868288563855458e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.1732969344157027e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1223063438592362e-06
sam_encoder.blocks.10.norm2.weight grad: 8.79120398167288e-06
sam_encoder.blocks.10.norm2.bias grad: 1.588809936947655e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.937515313940821e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.96360065274348e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.349708539550193e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.0035463304802761e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2157293895143084e-05
sam_encoder.blocks.11.norm1.bias grad: 4.007177665243944e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.3320393463800428e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.488406695671074e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.6584954209974967e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.087560452921025e-07
sam_encoder.blocks.11.norm2.weight grad: 9.596105883247219e-06
sam_encoder.blocks.11.norm2.bias grad: 9.66339825936302e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.529691745527089e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.823051302897511e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.3856529196564225e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.9382766797425575e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.1052983356639743e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.173157554352656e-06
sam_encoder.neck.conv2.trainable_scale grad: -7.32440639694687e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.332062306071748e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -8.612301462562755e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.5819139156956226e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005558585748076439
mask_decoder.transformer.layers.0.norm2.bias grad: 9.615236194804311e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 4.9259233492193744e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.9944935047533363e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.621212327852845e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.593902071472257e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.4864820514048915e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.007826424232917e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00021560609457083046
mask_decoder.transformer.layers.1.norm2.bias grad: 1.89712482097093e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.1607726264628582e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.1834782526420895e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.617330316454172e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018119758169632405
mask_decoder.transformer.norm_final_attn.weight grad: 1.0922012734226882e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.735363396932371e-06
Text_Embedding_Affine.0.weight grad: 1.0033213843074762e-11
Text_Embedding_Affine.0.bias grad: 2.676537602663842e-10
Text_Embedding_Affine.2.weight grad: 7.881877095439194e-11
Text_Embedding_Affine.2.bias grad: 7.982699571584817e-06
Epoch 2 finished with average loss: -63.6415
Epoch 3/39
----------
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.3]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-60.3]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-64.5]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-64.5]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-64.9]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-64.9]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07116889953613281

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07116889953613281

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06783246994018555

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.33163440227508545

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07124042510986328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06783246994018555

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.84664535522461
Max value: 70.4100341796875
Mean value: 60.26259231567383

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07116889953613281

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07116889953613281

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07116889953613281

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.33163440227508545

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.84664535522461
Max value: 70.4100341796875
Mean value: 60.26259231567383

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.26271438598633
Max value: -60.26271438598633
Mean value: -60.26271438598633
sam_encoder.pos_embed grad: -5.785384171730357e-09
sam_encoder.blocks.0.norm1.weight grad: 2.391729867667891e-05
sam_encoder.blocks.0.norm1.bias grad: -1.2303176845307462e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.461620740883518e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.869796488397697e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.069646694115363e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5727140407761908e-06
sam_encoder.blocks.0.norm2.weight grad: -6.414447125280276e-05
sam_encoder.blocks.0.norm2.bias grad: 1.877603972388897e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.030983174947323e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.045041911624139e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.006994277006015e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.602990596438758e-05
sam_encoder.blocks.1.norm1.weight grad: -2.6392597646918148e-05
sam_encoder.blocks.1.norm1.bias grad: -3.83949009119533e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.347852377075469e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.2372403186163865e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.721110144600971e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.923067866817291e-07
sam_encoder.blocks.1.norm2.weight grad: 4.0014285332290456e-05
sam_encoder.blocks.1.norm2.bias grad: -1.6468724197693518e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.82111507456284e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.576301762426738e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.315528935374459e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.0285946245858213e-06
sam_encoder.blocks.2.norm1.weight grad: 7.553773684776388e-06
sam_encoder.blocks.2.norm1.bias grad: -6.966905402805423e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.620576641580556e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.815328449898516e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.8006364825851051e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.5657536184553464e-07
sam_encoder.blocks.2.norm2.weight grad: 2.6739480745163746e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0447920431033708e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.143890691921115e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.209473445371259e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 6.761441909475252e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.61269349266513e-07
sam_encoder.blocks.3.norm1.weight grad: 2.0158950064796954e-05
sam_encoder.blocks.3.norm1.bias grad: -1.108300330088241e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.0775614782687626e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.989731448607927e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 6.655577067249396e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.229842135027866e-07
sam_encoder.blocks.3.norm2.weight grad: 4.366435746305797e-07
sam_encoder.blocks.3.norm2.bias grad: -2.583516834420152e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.090954467348638e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.4880070011713542e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.628931376122637e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1197676030860748e-06
sam_encoder.blocks.4.norm1.weight grad: 2.4979830413940363e-05
sam_encoder.blocks.4.norm1.bias grad: -3.400198693270795e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.2654340935114305e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.949737452378031e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.778978331567487e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.627496532018995e-06
sam_encoder.blocks.4.norm2.weight grad: -4.741161683341488e-05
sam_encoder.blocks.4.norm2.bias grad: -4.7671601350884885e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.813472929119598e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.1743502909666859e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.5542437924741535e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.319299537452025e-07
sam_encoder.blocks.5.norm1.weight grad: 5.161974513612222e-06
sam_encoder.blocks.5.norm1.bias grad: -2.2231133698369376e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3747259092488093e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.291534191404935e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.528233704259037e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.328271643316839e-06
sam_encoder.blocks.5.norm2.weight grad: -9.700494047137909e-06
sam_encoder.blocks.5.norm2.bias grad: -2.5156285119010136e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.899530500144465e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.352426566991198e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3847745776729425e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.430756467219908e-07
sam_encoder.blocks.6.norm1.weight grad: 3.58564193447819e-06
sam_encoder.blocks.6.norm1.bias grad: 2.4582782316429075e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.594660367729375e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3585107581093325e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.406693738521426e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.0147638224443654e-06
sam_encoder.blocks.6.norm2.weight grad: -2.616323035908863e-05
sam_encoder.blocks.6.norm2.bias grad: -3.60199101123726e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.839012657001149e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.965878467075527e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.515312520605221e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.4555009784089634e-06
sam_encoder.blocks.7.norm1.weight grad: 8.375921424885746e-06
sam_encoder.blocks.7.norm1.bias grad: -3.10988980345428e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.588906793083879e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.781762517173775e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.942464890220435e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.5694489522720687e-06
sam_encoder.blocks.7.norm2.weight grad: 5.989036253595259e-06
sam_encoder.blocks.7.norm2.bias grad: 3.980217570642708e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.437793672375847e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.278033133824465e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.9132453417114448e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.8034295951329113e-07
sam_encoder.blocks.8.norm1.weight grad: 1.1968480066570919e-05
sam_encoder.blocks.8.norm1.bias grad: -6.387070243363269e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.26401282614097e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.362918273021933e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.871736564382445e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.3438145692343824e-06
sam_encoder.blocks.8.norm2.weight grad: -4.365577751741512e-06
sam_encoder.blocks.8.norm2.bias grad: -5.993276204208087e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.358987098385114e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.181750232921331e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.0244506231392734e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.6303422398777911e-06
sam_encoder.blocks.9.norm1.weight grad: 1.7936288259079447e-06
sam_encoder.blocks.9.norm1.bias grad: 3.3533154919496155e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.2578205996760516e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.7971358090562717e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.376128921037889e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.492289977202745e-07
sam_encoder.blocks.9.norm2.weight grad: -2.7132446120958775e-06
sam_encoder.blocks.9.norm2.bias grad: 6.118168016655545e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.7574792511586566e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.5615072470609448e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.458510253854911e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.93011100388685e-07
sam_encoder.blocks.10.norm1.weight grad: 3.6169428767607315e-06
sam_encoder.blocks.10.norm1.bias grad: 1.79792527887912e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.5377762540301774e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0466714002177469e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.158878487534821e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.219696615517023e-07
sam_encoder.blocks.10.norm2.weight grad: 1.1034010185539955e-06
sam_encoder.blocks.10.norm2.bias grad: 3.496534191071987e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.014636433817941e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1928855769838265e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.298361667068093e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.708501085635362e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1258077392994892e-05
sam_encoder.blocks.11.norm1.bias grad: 3.2209579785558162e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.0858694824710255e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1228801213292172e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.851110704999883e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4820964224782074e-06
sam_encoder.blocks.11.norm2.weight grad: 4.857352450926555e-06
sam_encoder.blocks.11.norm2.bias grad: -3.2166857977244945e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.7912334442371503e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.205733989375403e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.4516534722351935e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.476890609808379e-08
sam_encoder.neck.conv1.trainable_scale grad: -2.1585719878203236e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.091380909201689e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.826768650265876e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.0044100640225224e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 1.3323005987331271e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -6.4203668443951756e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0018640963826328516
mask_decoder.transformer.layers.0.norm2.bias grad: 9.301246609538794e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 8.171393710654229e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.0970106814056635e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.342233635019511e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.1171468941029161e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.6492389224586077e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.0345672712428495e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00013023859355598688
mask_decoder.transformer.layers.1.norm2.bias grad: -6.145190127426758e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.0593219485599548e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.987059946870431e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0001292422239203006
mask_decoder.transformer.layers.1.norm4.bias grad: -3.634006134234369e-06
mask_decoder.transformer.norm_final_attn.weight grad: 1.2068599971826188e-05
mask_decoder.transformer.norm_final_attn.bias grad: 8.32199748401763e-06
Text_Embedding_Affine.0.weight grad: 1.0157961277679206e-11
Text_Embedding_Affine.0.bias grad: 1.0239845082971044e-10
Text_Embedding_Affine.2.weight grad: 1.0118272539272333e-11
Text_Embedding_Affine.2.bias grad: 5.495025106938556e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11183176189661026

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11183176189661026

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10030841827392578

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40884703397750854

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11191511154174805

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10030841827392578

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 55.57117462158203
Max value: 80.90516662597656
Mean value: 68.26777648925781

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11209975183010101

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11209975183010101

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11209975183010101

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3976286053657532

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6575731635093689
Max value: 4.775681495666504
Mean value: 1.0146982669830322

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 55.57117462158203
Max value: 80.90516662597656
Mean value: 68.26777648925781

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.66361999511719
Max value: -68.66361999511719
Mean value: -68.66361999511719
sam_encoder.pos_embed grad: -1.1326111160059327e-09
sam_encoder.blocks.0.norm1.weight grad: -5.171860539121553e-05
sam_encoder.blocks.0.norm1.bias grad: 1.4992569049354643e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.2353490294335643e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.797745418727573e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.582170736786793e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.8204327716375701e-06
sam_encoder.blocks.0.norm2.weight grad: 2.7024467271985486e-05
sam_encoder.blocks.0.norm2.bias grad: 2.2609099232795415e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.399898443807615e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.820417987299152e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.356473487452604e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.182118449440168e-07
sam_encoder.blocks.1.norm1.weight grad: -1.7714328350848518e-06
sam_encoder.blocks.1.norm1.bias grad: 5.371377369556285e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.597742180427304e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.174881785776961e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.0436190223117592e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.221311643159424e-07
sam_encoder.blocks.1.norm2.weight grad: 1.1826901754830033e-05
sam_encoder.blocks.1.norm2.bias grad: 1.003732450044481e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.64488732884638e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.909821195222321e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.1656611604848877e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.511731279104424e-07
sam_encoder.blocks.2.norm1.weight grad: -3.0361338758666534e-06
sam_encoder.blocks.2.norm1.bias grad: -1.5258600569723058e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.8014960687651183e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.381637038226472e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.8944764380867127e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.1274621505872346e-06
sam_encoder.blocks.2.norm2.weight grad: 2.9880327474529622e-06
sam_encoder.blocks.2.norm2.bias grad: 2.7768255677074194e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.590433612363995e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.110092236142009e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.82809069682844e-08
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.050860292816651e-07
sam_encoder.blocks.3.norm1.weight grad: -8.991608410724439e-06
sam_encoder.blocks.3.norm1.bias grad: -1.9433089164522244e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.650194230431225e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.771398943783424e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2970476745977066e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.216371146028905e-07
sam_encoder.blocks.3.norm2.weight grad: 1.1824096873169765e-05
sam_encoder.blocks.3.norm2.bias grad: 7.926822945591994e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 9.693907486507669e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.7530580812017433e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.4817973098834045e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.898253559484147e-07
sam_encoder.blocks.4.norm1.weight grad: -1.7814045349950902e-06
sam_encoder.blocks.4.norm1.bias grad: -1.9104895443433634e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.109539754106663e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.290898291652411e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.233461474243086e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.726561873118044e-08
sam_encoder.blocks.4.norm2.weight grad: -8.067110684351064e-06
sam_encoder.blocks.4.norm2.bias grad: -3.1609131383447675e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.819245754741132e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.345229404454585e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.0053905725726509e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.8538397600641474e-07
sam_encoder.blocks.5.norm1.weight grad: -3.237267264921684e-06
sam_encoder.blocks.5.norm1.bias grad: 5.208857487559726e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.97217514141812e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5537042941105028e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.994751172191172e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.740624591358937e-07
sam_encoder.blocks.5.norm2.weight grad: -3.1237486837198958e-06
sam_encoder.blocks.5.norm2.bias grad: 8.871287491274416e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.113987193297362e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.842799618629215e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.694059943081811e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.3406327898101154e-07
sam_encoder.blocks.6.norm1.weight grad: 2.9571519917226397e-06
sam_encoder.blocks.6.norm1.bias grad: 1.645523070692434e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.4285682254921994e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.4348721555943484e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.686923820278025e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.2425740553444484e-07
sam_encoder.blocks.6.norm2.weight grad: 1.17525144105457e-06
sam_encoder.blocks.6.norm2.bias grad: 3.636066026047047e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.941356099967379e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.747843943026965e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.4471079263530555e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.5067510616972868e-07
sam_encoder.blocks.7.norm1.weight grad: -1.0881687728669931e-07
sam_encoder.blocks.7.norm1.bias grad: 1.3929709439253202e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.58116448448709e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.946065814692702e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.743284532400139e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.20403387377155e-07
sam_encoder.blocks.7.norm2.weight grad: 3.191240239175386e-06
sam_encoder.blocks.7.norm2.bias grad: 7.576672942377627e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 8.98543248695205e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.565608939330559e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.4649970125901746e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.919071562246245e-07
sam_encoder.blocks.8.norm1.weight grad: -1.147504008258693e-06
sam_encoder.blocks.8.norm1.bias grad: 1.7570367845110013e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.7637305518292123e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.202753866091371e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.2037496333050512e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.023141570996813e-07
sam_encoder.blocks.8.norm2.weight grad: 2.3606053218827583e-06
sam_encoder.blocks.8.norm2.bias grad: -8.839197107590735e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.7908727159010596e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.722014056023909e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.1588389270400512e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.050132815791585e-07
sam_encoder.blocks.9.norm1.weight grad: -6.550835678353906e-07
sam_encoder.blocks.9.norm1.bias grad: -1.1322199355845441e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.817031644208328e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.57149860469508e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.261226654809434e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.659227895193908e-07
sam_encoder.blocks.9.norm2.weight grad: 1.924253638208029e-06
sam_encoder.blocks.9.norm2.bias grad: -2.369246629996269e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.2990385584998876e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.358092494134326e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1134572730497894e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.746600955561007e-07
sam_encoder.blocks.10.norm1.weight grad: 3.1281956580642145e-08
sam_encoder.blocks.10.norm1.bias grad: -3.9731889955874067e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.4670699783891905e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.329194318117516e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.864601012537605e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.291821144557616e-07
sam_encoder.blocks.10.norm2.weight grad: -1.6365752344427165e-06
sam_encoder.blocks.10.norm2.bias grad: -2.0170641619188245e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.873159926115477e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -8.925800898396119e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.367774302707403e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.779754701507045e-07
sam_encoder.blocks.11.norm1.weight grad: 7.738790372968651e-07
sam_encoder.blocks.11.norm1.bias grad: -1.3336224569115984e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.560355485707987e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.8040117661685144e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.776629793923348e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.6455738811346237e-07
sam_encoder.blocks.11.norm2.weight grad: -2.8853564799646847e-06
sam_encoder.blocks.11.norm2.bias grad: -2.63627930507937e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.6246183349721832e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.294317470041278e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0393063121227897e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.56927188249756e-07
sam_encoder.neck.conv1.trainable_scale grad: -7.736198313068599e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.084253926819656e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.007501850835979e-06
sam_encoder.neck.conv2.trainable_shift grad: 7.393332907668082e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019536595209501684
mask_decoder.transformer.layers.0.norm1.bias grad: -2.254681021440774e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003347744233906269
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00031467695953324437
mask_decoder.transformer.layers.0.norm3.weight grad: -3.530731191858649e-07
mask_decoder.transformer.layers.0.norm3.bias grad: 2.804955147439614e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.444974860642105e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.086746336426586e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 7.815995195414871e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.46559466177132e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.2620853239204735e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010712782386690378
mask_decoder.transformer.layers.1.norm3.weight grad: 4.763188189826906e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.99489755788818e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 9.052112091012532e-07
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010882514470722526
mask_decoder.transformer.norm_final_attn.weight grad: 1.3116807167534716e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.0464160368428566e-05
Text_Embedding_Affine.0.weight grad: -5.773996732127973e-12
Text_Embedding_Affine.0.bias grad: -2.155747663712404e-10
Text_Embedding_Affine.2.weight grad: 6.087197412796286e-11
Text_Embedding_Affine.2.bias grad: 4.917572368867695e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08049722015857697

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08049722015857697

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08221244812011719

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4044579863548279

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08040618896484375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08221244812011719

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.92152404785156
Max value: 92.46400451660156
Mean value: 65.3582763671875

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0807679146528244

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0807679146528244

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0807679146528244

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.38335737586021423

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6503297090530396
Max value: 16.70108413696289
Mean value: 1.0382755994796753

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.92152404785156
Max value: 92.46400451660156
Mean value: 65.3582763671875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.73200988769531
Max value: -65.73200988769531
Mean value: -65.73200988769531
sam_encoder.pos_embed grad: 1.9583115573595933e-08
sam_encoder.blocks.0.norm1.weight grad: -3.404077870072797e-05
sam_encoder.blocks.0.norm1.bias grad: -1.2330439858487807e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.5492790882708505e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1122419429909769e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.381700015685055e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0455186156832497e-06
sam_encoder.blocks.0.norm2.weight grad: -3.7158992199692875e-05
sam_encoder.blocks.0.norm2.bias grad: -1.7241370642295806e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.209064288967056e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.789133062236942e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.9953147784690373e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.1290146176179405e-05
sam_encoder.blocks.1.norm1.weight grad: -5.307210813043639e-06
sam_encoder.blocks.1.norm1.bias grad: 8.193183020921424e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.607482530147536e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.668763616180513e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.910740815626923e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.287445113324793e-06
sam_encoder.blocks.1.norm2.weight grad: 2.7394835342420265e-06
sam_encoder.blocks.1.norm2.bias grad: -7.142355570977088e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.181129042990506e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.057350284052518e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.799544851470273e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.9971431558806216e-06
sam_encoder.blocks.2.norm1.weight grad: -3.5788732475339202e-06
sam_encoder.blocks.2.norm1.bias grad: 7.032021585473558e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.976212843146641e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.630875865695998e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.553002559579909e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.9374326711840695e-06
sam_encoder.blocks.2.norm2.weight grad: 1.337178036919795e-05
sam_encoder.blocks.2.norm2.bias grad: 7.897278919699602e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.597673852113076e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.3795494093501475e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7377561764296843e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.79077731497091e-07
sam_encoder.blocks.3.norm1.weight grad: -1.0591480531729758e-05
sam_encoder.blocks.3.norm1.bias grad: 3.4280044474144233e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.5258794974215562e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.924163595707796e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.898259481298737e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.873663783655502e-08
sam_encoder.blocks.3.norm2.weight grad: 9.428867087990511e-06
sam_encoder.blocks.3.norm2.bias grad: 9.513410986983217e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.444067937787622e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.6157581487495918e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.094460670487024e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0134457397725782e-06
sam_encoder.blocks.4.norm1.weight grad: -3.827855834970251e-05
sam_encoder.blocks.4.norm1.bias grad: -2.645028871484101e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.1286232367856428e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.078378308098763e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0993928299285471e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -7.539911166531965e-06
sam_encoder.blocks.4.norm2.weight grad: 5.433159094536677e-05
sam_encoder.blocks.4.norm2.bias grad: 4.1162402339978144e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.590959022403695e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.3978703464090358e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.5003176940808771e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.33176604322216e-06
sam_encoder.blocks.5.norm1.weight grad: -3.049173392355442e-05
sam_encoder.blocks.5.norm1.bias grad: -1.7490026493760524e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.6848845916683786e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.018561756107374e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.211373253492638e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.7468924903078e-06
sam_encoder.blocks.5.norm2.weight grad: 2.4433251383015886e-05
sam_encoder.blocks.5.norm2.bias grad: 2.118195334332995e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.796520316740498e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.1732004117657198e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.508535873057554e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.107871849460935e-07
sam_encoder.blocks.6.norm1.weight grad: -9.401665010955185e-06
sam_encoder.blocks.6.norm1.bias grad: -8.88886188477045e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.874267117178533e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.677883574302541e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.2747452678449918e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.4864021977700759e-06
sam_encoder.blocks.6.norm2.weight grad: 1.9948762201238424e-05
sam_encoder.blocks.6.norm2.bias grad: 8.946164598455653e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.62262876983732e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.040383025014307e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.4180812943086494e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.2924350560060702e-06
sam_encoder.blocks.7.norm1.weight grad: -1.089945999410702e-05
sam_encoder.blocks.7.norm1.bias grad: -1.1116471796412952e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.635015440930147e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.42144687945256e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.421086148591712e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.13381463506812e-06
sam_encoder.blocks.7.norm2.weight grad: -2.570245669630822e-06
sam_encoder.blocks.7.norm2.bias grad: -3.216076720491401e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.7471961604751414e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.519239276603912e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.5094673244675505e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.556782636835123e-07
sam_encoder.blocks.8.norm1.weight grad: -7.965831173351035e-06
sam_encoder.blocks.8.norm1.bias grad: 5.301462806528434e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.1647479014936835e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.6445550272692344e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.2655176407133695e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.413268470671028e-06
sam_encoder.blocks.8.norm2.weight grad: -2.4925382149376674e-06
sam_encoder.blocks.8.norm2.bias grad: -1.081105764910717e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.8830186238337774e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.1869930176544585e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.5629890981472272e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.124909989717708e-07
sam_encoder.blocks.9.norm1.weight grad: -6.125621439423412e-06
sam_encoder.blocks.9.norm1.bias grad: -1.4417704505831352e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.4817437608580803e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.5354657989519183e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.3575991033576429e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.662688532633183e-06
sam_encoder.blocks.9.norm2.weight grad: -1.0675708836060949e-05
sam_encoder.blocks.9.norm2.bias grad: -2.7287487682770006e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.50316303310683e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.85266866942402e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8654156974662328e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.077499736216851e-07
sam_encoder.blocks.10.norm1.weight grad: -1.0358066901972052e-05
sam_encoder.blocks.10.norm1.bias grad: -2.6876314223045483e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.4511120904644486e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.0367065189930145e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.0998252239223802e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0570910262686084e-06
sam_encoder.blocks.10.norm2.weight grad: -1.725640868244227e-05
sam_encoder.blocks.10.norm2.bias grad: -5.31295154360123e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.177376341540366e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.573124897433445e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.4164110072888434e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.916994715946203e-07
sam_encoder.blocks.11.norm1.weight grad: -2.355674769205507e-05
sam_encoder.blocks.11.norm1.bias grad: 1.9763670024985913e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.695183287774853e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.938083636967349e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.372473772993544e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.4288361853687093e-06
sam_encoder.blocks.11.norm2.weight grad: -2.0548202883219346e-05
sam_encoder.blocks.11.norm2.bias grad: -4.256035026628524e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.0027058124251198e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.221060978830792e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.140651986337616e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.230248802945425e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0829644452314824e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.326794831082225e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.1196307039354e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.1506093617063016e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011908364831469953
mask_decoder.transformer.layers.0.norm1.bias grad: 9.092436812352389e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005085064098238945
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00032218743581324816
mask_decoder.transformer.layers.0.norm3.weight grad: -2.163635508622974e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.054761903826147e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -2.630699600558728e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.253910785540938e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.135564763098955e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.03780938743148e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00026736673316918314
mask_decoder.transformer.layers.1.norm2.bias grad: 5.7904544519260526e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 7.162083056755364e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.633646939415485e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00015362360863946378
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00014494422066491097
mask_decoder.transformer.norm_final_attn.weight grad: 1.1247465408814605e-05
mask_decoder.transformer.norm_final_attn.bias grad: 5.4835431910760235e-06
Text_Embedding_Affine.0.weight grad: -5.047351425702118e-12
Text_Embedding_Affine.0.bias grad: -1.4900622402613806e-10
Text_Embedding_Affine.2.weight grad: 6.421881082463443e-11
Text_Embedding_Affine.2.bias grad: -4.840216206503101e-06
Epoch 3 finished with average loss: -64.8861
Epoch 4/39
----------
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.5]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-64.5]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-68.5]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-68.5]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-66]  Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.37it/s, loss=-66]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08822232484817505

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08822232484817505

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08355093002319336

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.294363796710968

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08811235427856445

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08355093002319336

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.706817626953125
Max value: 78.76448059082031
Mean value: 64.52025604248047

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08822232484817505

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08822232484817505

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08822232484817505

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.294363796710968

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.706817626953125
Max value: 78.76448059082031
Mean value: 64.52025604248047

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.52046966552734
Max value: -64.52046966552734
Mean value: -64.52046966552734
sam_encoder.pos_embed grad: 1.5049963053570536e-08
sam_encoder.blocks.0.norm1.weight grad: -6.941437459317967e-05
sam_encoder.blocks.0.norm1.bias grad: -3.096854197792709e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.129498393012909e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.81230892748863e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.834315627202159e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0467185802554013e-06
sam_encoder.blocks.0.norm2.weight grad: -5.2256429626140743e-05
sam_encoder.blocks.0.norm2.bias grad: -3.6087083572056144e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.158328233141219e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.0707967703638133e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.0713880328694358e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.124596448993543e-06
sam_encoder.blocks.1.norm1.weight grad: -3.3134651857835706e-06
sam_encoder.blocks.1.norm1.bias grad: -1.7103545815189136e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.5022991419755272e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.179997171784635e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.353201125515625e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.7918411521786766e-07
sam_encoder.blocks.1.norm2.weight grad: -1.2539498129626736e-05
sam_encoder.blocks.1.norm2.bias grad: -3.159555944876047e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.5655408560633077e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0142888413611217e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.5610787563200574e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.1285486582200974e-06
sam_encoder.blocks.2.norm1.weight grad: 1.3941176803200506e-05
sam_encoder.blocks.2.norm1.bias grad: 3.0596615943068173e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 8.126642569550313e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.4269029406932532e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 9.86680606729351e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.532643172045937e-06
sam_encoder.blocks.2.norm2.weight grad: 1.6027337551349774e-05
sam_encoder.blocks.2.norm2.bias grad: 7.350453415710945e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.364307516079862e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.349355327169178e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.721076725720195e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.735902040119981e-07
sam_encoder.blocks.3.norm1.weight grad: -1.462906766391825e-06
sam_encoder.blocks.3.norm1.bias grad: 1.0466501407790929e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.7111677834691363e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.3698385146199143e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.063365157795488e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.643073101666232e-07
sam_encoder.blocks.3.norm2.weight grad: 5.687649604624312e-07
sam_encoder.blocks.3.norm2.bias grad: 6.9335046646301635e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.257864803657867e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.3858447118764161e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1248157534282655e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.689390723593533e-06
sam_encoder.blocks.4.norm1.weight grad: -2.7971727831754833e-05
sam_encoder.blocks.4.norm1.bias grad: 1.496282493462786e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.3749662684858777e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.197499381712987e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.061365067784209e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.457425686472561e-06
sam_encoder.blocks.4.norm2.weight grad: 2.8769023629138246e-05
sam_encoder.blocks.4.norm2.bias grad: 1.623432217456866e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.9756349502131343e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 7.4814120125665795e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.640281309140846e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.719509547612688e-07
sam_encoder.blocks.5.norm1.weight grad: -2.075151860481128e-05
sam_encoder.blocks.5.norm1.bias grad: 2.8109996037528617e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.0589974408503622e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.2755471036361996e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.7679419619962573e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.704512321040966e-06
sam_encoder.blocks.5.norm2.weight grad: 8.424651241512038e-06
sam_encoder.blocks.5.norm2.bias grad: 8.512269232596736e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.336766894790344e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.934778972819913e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4715604947923566e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6454108617836027e-06
sam_encoder.blocks.6.norm1.weight grad: -1.1765313502110075e-05
sam_encoder.blocks.6.norm1.bias grad: -4.2403685256431345e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.758070867363131e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.7278179029744933e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.153413561245543e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.419855142463348e-07
sam_encoder.blocks.6.norm2.weight grad: -2.910239800257841e-07
sam_encoder.blocks.6.norm2.bias grad: 2.4844514427968534e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.045941189659061e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.3774333019209735e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.997566177029512e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.981568958508433e-07
sam_encoder.blocks.7.norm1.weight grad: -9.609248081687838e-06
sam_encoder.blocks.7.norm1.bias grad: 6.117164730312652e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.181036380643491e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.9861034818168264e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.3379179765470326e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.431152668374125e-06
sam_encoder.blocks.7.norm2.weight grad: -5.805897217214806e-06
sam_encoder.blocks.7.norm2.bias grad: -2.3300281100091524e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.096440418128623e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.620786179046263e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.299808319454314e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.944029861533636e-07
sam_encoder.blocks.8.norm1.weight grad: -1.0784810910990927e-06
sam_encoder.blocks.8.norm1.bias grad: 2.684874516489799e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.4710858522448689e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.6966648672678275e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.2296097742801066e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.0887317734595854e-06
sam_encoder.blocks.8.norm2.weight grad: -6.741351171513088e-06
sam_encoder.blocks.8.norm2.bias grad: -1.237386641150806e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.65773495711619e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.7795562093378976e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0056799055746524e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.7063731522503076e-07
sam_encoder.blocks.9.norm1.weight grad: -3.213509216948296e-06
sam_encoder.blocks.9.norm1.bias grad: -1.127501491282601e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.1971743535686983e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.8776266870190739e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.988769195639179e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1818938219221309e-06
sam_encoder.blocks.9.norm2.weight grad: -1.321983836533036e-05
sam_encoder.blocks.9.norm2.bias grad: -4.440227712620981e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.273654202639591e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.717653155239532e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5621266129528522e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.195899118210946e-07
sam_encoder.blocks.10.norm1.weight grad: -4.778032689500833e-06
sam_encoder.blocks.10.norm1.bias grad: -2.1209236820141086e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.3234449599840445e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2999516911804676e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.444988341376302e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.786710405824124e-07
sam_encoder.blocks.10.norm2.weight grad: -1.817685188143514e-05
sam_encoder.blocks.10.norm2.bias grad: -5.27115844306536e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.957834324974101e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.98147301186691e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3578683137893677e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.413526421056304e-07
sam_encoder.blocks.11.norm1.weight grad: -1.362594684906071e-05
sam_encoder.blocks.11.norm1.bias grad: 2.1596365513687488e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.04356796934735e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.654829446806616e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.07500932244875e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.74903060876386e-07
sam_encoder.blocks.11.norm2.weight grad: -1.5624420484527946e-05
sam_encoder.blocks.11.norm2.bias grad: -4.525238182395697e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.74852651375113e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.5865836050797952e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.887071322125848e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.9103299564449117e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.5207297110464424e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.000139804498758e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.752523530740291e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.6008386814501137e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -5.066282756160945e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.108500095549971e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0055773900821805
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001446325914002955
mask_decoder.transformer.layers.0.norm3.weight grad: 5.461991531774402e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.0687169783050194e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -4.6155822928994894e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.296075298450887e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.121148984064348e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.6152621255023405e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00021529973309952766
mask_decoder.transformer.layers.1.norm2.bias grad: 3.324152930872515e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.986996307503432e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.287654494168237e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00015579586033709347
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00015780498506501317
mask_decoder.transformer.norm_final_attn.weight grad: 6.5053482103394344e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.878997631545644e-06
Text_Embedding_Affine.0.weight grad: -9.449462046173807e-12
Text_Embedding_Affine.0.bias grad: -3.1776364872726504e-10
Text_Embedding_Affine.2.weight grad: 5.6165946893393937e-11
Text_Embedding_Affine.2.bias grad: 3.1045165087562054e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09535229206085205

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09535229206085205

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08766365051269531

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.342673122882843

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0954585075378418

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08766365051269531

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 61.84721374511719
Max value: 91.45523834228516
Mean value: 72.023681640625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09480097889900208

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09480097889900208

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09480097889900208

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3332222104072571

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.48744216561317444
Max value: 4.0
Mean value: 1.011900544166565

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 61.84721374511719
Max value: 91.45523834228516
Mean value: 72.023681640625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -72.41102600097656
Max value: -72.41102600097656
Mean value: -72.41102600097656
sam_encoder.pos_embed grad: -5.706962680207539e-10
sam_encoder.blocks.0.norm1.weight grad: -2.2587570128962398e-05
sam_encoder.blocks.0.norm1.bias grad: 2.3002273792371852e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.387155063843238e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.429487532320309e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.093848135904409e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4315864973468706e-06
sam_encoder.blocks.0.norm2.weight grad: 1.0438674507895485e-05
sam_encoder.blocks.0.norm2.bias grad: -9.685301847639494e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.080033366131829e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.9256112864241004e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.670257789664902e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.90008025874522e-08
sam_encoder.blocks.1.norm1.weight grad: -1.3325355894266977e-06
sam_encoder.blocks.1.norm1.bias grad: 4.075483957421966e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.149556848962675e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.1304111303143145e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.020108922806685e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.1544638027771725e-06
sam_encoder.blocks.1.norm2.weight grad: 6.559242820003419e-07
sam_encoder.blocks.1.norm2.bias grad: -2.8269751055631787e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.0371363714511972e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.863328407125664e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.974387598442263e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.478110102150822e-07
sam_encoder.blocks.2.norm1.weight grad: 2.2084745978645515e-06
sam_encoder.blocks.2.norm1.bias grad: -2.448186933179386e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.869270924245939e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.06664617255592e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.8042717329080915e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.4073319789531524e-06
sam_encoder.blocks.2.norm2.weight grad: -6.341235234685882e-07
sam_encoder.blocks.2.norm2.bias grad: -3.8355510696419515e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.587905439417227e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.52452245774748e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.177887265337631e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.935894584283233e-07
sam_encoder.blocks.3.norm1.weight grad: -5.308764229994267e-06
sam_encoder.blocks.3.norm1.bias grad: 9.557115845382214e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.3261410408158554e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4829345218458911e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2402778111209045e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.344073024573845e-08
sam_encoder.blocks.3.norm2.weight grad: 5.24721690453589e-06
sam_encoder.blocks.3.norm2.bias grad: 2.81335337604105e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.65589346276829e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.33254559134366e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.8541963981988374e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.644108114211122e-07
sam_encoder.blocks.4.norm1.weight grad: -6.3888251133903395e-06
sam_encoder.blocks.4.norm1.bias grad: -3.244633148824505e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.095388703717617e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3237711300462252e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.4910741583662457e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2337756061242544e-06
sam_encoder.blocks.4.norm2.weight grad: -9.96943981590448e-06
sam_encoder.blocks.4.norm2.bias grad: 4.20533933720435e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.3836905610514805e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.1553296417332604e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.340146908063616e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.128758028329685e-08
sam_encoder.blocks.5.norm1.weight grad: -6.422250407922547e-06
sam_encoder.blocks.5.norm1.bias grad: 2.2969875317357946e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.510757207754068e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.330334478363511e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.8611599443829618e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.7014335753628984e-06
sam_encoder.blocks.5.norm2.weight grad: -4.163468020124128e-06
sam_encoder.blocks.5.norm2.bias grad: 4.142254965699976e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2634067136095837e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.104986596255912e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.7359361587950843e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.8612965391184844e-07
sam_encoder.blocks.6.norm1.weight grad: -1.0765114666355657e-06
sam_encoder.blocks.6.norm1.bias grad: -4.2508267483754025e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.90584226201463e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.81292044393922e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.0099176961375633e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.192961900022055e-07
sam_encoder.blocks.6.norm2.weight grad: 3.561877747415565e-06
sam_encoder.blocks.6.norm2.bias grad: 2.4056582788034575e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.2176662898564246e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.3688443232240388e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.140121639764402e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.693618956887804e-07
sam_encoder.blocks.7.norm1.weight grad: -2.466040996296215e-06
sam_encoder.blocks.7.norm1.bias grad: 1.5626177400918095e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -9.261842706109746e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.269547382307337e-09
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.4475303323233675e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.9294129742775112e-06
sam_encoder.blocks.7.norm2.weight grad: 3.196708803443471e-06
sam_encoder.blocks.7.norm2.bias grad: 9.540486871628673e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.3177043456380488e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.888535040161514e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.4362256567656004e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.1523911069843962e-07
sam_encoder.blocks.8.norm1.weight grad: -2.7048106403526617e-06
sam_encoder.blocks.8.norm1.bias grad: 2.2558019736607093e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.7942236303933896e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.3412334283202654e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.76743888764031e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3437461348075885e-06
sam_encoder.blocks.8.norm2.weight grad: 2.88301350792608e-07
sam_encoder.blocks.8.norm2.bias grad: -1.3541138059736113e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.784398418498313e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.5445525504183024e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.2165727386891376e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.315928402500504e-08
sam_encoder.blocks.9.norm1.weight grad: -6.898761739648762e-07
sam_encoder.blocks.9.norm1.bias grad: 1.261507094341141e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.3545466970299458e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.8185541484381247e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.9096662501615356e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.750434972171206e-07
sam_encoder.blocks.9.norm2.weight grad: 6.868604032206349e-07
sam_encoder.blocks.9.norm2.bias grad: -7.347637165366905e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.3138603662810056e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2197983778605703e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6486168874507712e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.778527002396004e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2153753914390109e-06
sam_encoder.blocks.10.norm1.bias grad: -2.1205062239459949e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.633447254789644e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.727671006956371e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.752886747563025e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.451095207969047e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3398191640590085e-06
sam_encoder.blocks.10.norm2.bias grad: -1.8001849184656749e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.1261318983742967e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.5851331265112094e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2292797464397154e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.490445573741454e-07
sam_encoder.blocks.11.norm1.weight grad: -1.4175806200000807e-06
sam_encoder.blocks.11.norm1.bias grad: 6.078970500311698e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.0027088964980067e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.6272689979123243e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.6419696180491883e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.546857633793479e-08
sam_encoder.blocks.11.norm2.weight grad: -7.03134787727322e-07
sam_encoder.blocks.11.norm2.bias grad: -9.231197282133508e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 9.771883924258873e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.77764848735751e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2095707688786206e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.252919663689681e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.011005098116584e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.627472011023201e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.239900696731638e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.817561496864073e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018710513541009277
mask_decoder.transformer.layers.0.norm1.bias grad: -2.376651536906138e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003936361521482468
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006298274965956807
mask_decoder.transformer.layers.0.norm3.weight grad: -1.802589395083487e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.025666592293419e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.809470167150721e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.2133623386034742e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.569718971149996e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.146274709957652e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.646323289605789e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.639380732551217e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.844690192840062e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.431097426684573e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.376135282451287e-07
mask_decoder.transformer.layers.1.norm4.bias grad: -9.662705269875005e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0523045602894854e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.805005225236528e-06
Text_Embedding_Affine.0.weight grad: -1.8519772521097266e-11
Text_Embedding_Affine.0.bias grad: -6.242883987539471e-10
Text_Embedding_Affine.2.weight grad: 3.168412060494674e-11
Text_Embedding_Affine.2.bias grad: 7.707129043410532e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07049785554409027

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07049785554409027

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07609176635742188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3869273364543915

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07046794891357422

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07609176635742188

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.09284591674805
Max value: 67.93052673339844
Mean value: 60.79930877685547

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0684288889169693

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0684288889169693

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0684288889169693

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3628808856010437

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.23679864406585693
Max value: 27.04500961303711
Mean value: 1.051551103591919

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.09284591674805
Max value: 67.93052673339844
Mean value: 60.79930877685547

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.087890625
Max value: -61.087890625
Mean value: -61.087890625
sam_encoder.pos_embed grad: -8.94813823038021e-09
sam_encoder.blocks.0.norm1.weight grad: -2.4005601062526694e-06
sam_encoder.blocks.0.norm1.bias grad: 2.6572593924356624e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.6644231588288676e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.278377900845953e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.188243332871934e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.361554258342949e-07
sam_encoder.blocks.0.norm2.weight grad: 6.649494025623426e-05
sam_encoder.blocks.0.norm2.bias grad: -2.535073144827038e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2458413038984872e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.116668226421098e-08
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.316504040005384e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.2592682853428414e-06
sam_encoder.blocks.1.norm1.weight grad: -4.253883162164129e-06
sam_encoder.blocks.1.norm1.bias grad: 1.8722652157521225e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.563516651818645e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0741246114776004e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.78593927557813e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2996210898563731e-06
sam_encoder.blocks.1.norm2.weight grad: -1.6959460481302813e-05
sam_encoder.blocks.1.norm2.bias grad: 4.270692443242297e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.826543878763914e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2702905678452225e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.6467452951474115e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.6683891266875435e-06
sam_encoder.blocks.2.norm1.weight grad: 6.978810688451631e-06
sam_encoder.blocks.2.norm1.bias grad: -6.941770607227227e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.4240888453496154e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.977353000867879e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.098102181160357e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.015501306435908e-06
sam_encoder.blocks.2.norm2.weight grad: -9.024664905155078e-06
sam_encoder.blocks.2.norm2.bias grad: -5.798539859824814e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.2497305154684e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.787149919138756e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.6579668782651424e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.484998165324214e-06
sam_encoder.blocks.3.norm1.weight grad: -5.517486897588242e-06
sam_encoder.blocks.3.norm1.bias grad: -1.9636613615148235e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0694390766730066e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8911687220679596e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.253679657675093e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.4935602596087847e-06
sam_encoder.blocks.3.norm2.weight grad: 3.878879795138346e-07
sam_encoder.blocks.3.norm2.bias grad: 9.086797945201397e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.8222143580715056e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.184689027577406e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.9385314519458916e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.15687144495314e-08
sam_encoder.blocks.4.norm1.weight grad: 1.887887265183963e-05
sam_encoder.blocks.4.norm1.bias grad: -7.211765478132293e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.478929092030739e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0246507144984207e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.2418261071143206e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.650724127306603e-06
sam_encoder.blocks.4.norm2.weight grad: -5.567889456870034e-05
sam_encoder.blocks.4.norm2.bias grad: -3.388734330656007e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.0791208448354155e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3767590644420125e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.6142885215231217e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.049683416771586e-06
sam_encoder.blocks.5.norm1.weight grad: 1.4220335287973285e-05
sam_encoder.blocks.5.norm1.bias grad: -1.6734493328840472e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.955020919325761e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.5596194771205774e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.265048002911499e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.65798905477277e-06
sam_encoder.blocks.5.norm2.weight grad: -2.6067405997309834e-05
sam_encoder.blocks.5.norm2.bias grad: -1.3726467841479462e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.195604090753477e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.133584297960624e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4524260905091069e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.029598817898659e-07
sam_encoder.blocks.6.norm1.weight grad: 8.266827535408083e-06
sam_encoder.blocks.6.norm1.bias grad: 8.372052434424404e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.606653419614304e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.837340045720339e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.4717620565061225e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.3102853699820116e-06
sam_encoder.blocks.6.norm2.weight grad: -1.4815028407610953e-05
sam_encoder.blocks.6.norm2.bias grad: -4.620074378181016e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.378514732816257e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.410264409671072e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.687494886937202e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.351116207450104e-07
sam_encoder.blocks.7.norm1.weight grad: 3.094940893788589e-06
sam_encoder.blocks.7.norm1.bias grad: 3.0883061299391557e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.3650381990591995e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3707519883610075e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.4177304567274405e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.703446840423567e-07
sam_encoder.blocks.7.norm2.weight grad: 3.396586180315353e-06
sam_encoder.blocks.7.norm2.bias grad: 2.7667279027809855e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.6720797450252576e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.118063815094501e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.801871687552193e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0773192116175778e-06
sam_encoder.blocks.8.norm1.weight grad: 2.94693086289044e-06
sam_encoder.blocks.8.norm1.bias grad: -9.411957648808311e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.216509973455686e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.548123004293302e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.6789475668920204e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.4957893199607497e-06
sam_encoder.blocks.8.norm2.weight grad: 8.25896677270066e-07
sam_encoder.blocks.8.norm2.bias grad: -1.4763134004169842e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.2124527276901063e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.887986844754778e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.996748425081023e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.958181196139776e-07
sam_encoder.blocks.9.norm1.weight grad: -2.7519824925548164e-06
sam_encoder.blocks.9.norm1.bias grad: 7.001477797530242e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.7833007152366918e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.513047180878857e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.1633869689831045e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.495187214270118e-07
sam_encoder.blocks.9.norm2.weight grad: 3.2555649340793025e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2458984883778612e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.0799327558052028e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.5284037380733935e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.816312504843154e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.376234249368281e-07
sam_encoder.blocks.10.norm1.weight grad: 4.712833288067486e-06
sam_encoder.blocks.10.norm1.bias grad: -1.7426222242988842e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.5014555831148755e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.211811763823789e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.089381041514571e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.3365510085350252e-06
sam_encoder.blocks.10.norm2.weight grad: 3.7630825318046845e-06
sam_encoder.blocks.10.norm2.bias grad: -1.604011458766763e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.62719436250336e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.207876416894578e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.43355653803701e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.4398575842733408e-07
sam_encoder.blocks.11.norm1.weight grad: 8.074075594777241e-06
sam_encoder.blocks.11.norm1.bias grad: -1.0535321592897162e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.843952072202228e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.568114597233944e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.0318582844302e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.456892265305214e-08
sam_encoder.blocks.11.norm2.weight grad: 3.362875531820464e-06
sam_encoder.blocks.11.norm2.bias grad: -7.62114439112338e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.819044195552124e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.98983695251809e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.88288480432675e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.5772526391374413e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.6782981876749545e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1618048119999003e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.473840817809105e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.522560993791558e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001649112964514643
mask_decoder.transformer.layers.0.norm1.bias grad: -1.8489845388103276e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004789536353200674
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003936312859877944
mask_decoder.transformer.layers.0.norm3.weight grad: -2.1179657778702676e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 3.596896567614749e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.854640716686845e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.097320248140022e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.2063300497829914e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.855830285232514e-08
mask_decoder.transformer.layers.1.norm2.weight grad: -8.875197818269953e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.124285573605448e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.940158472280018e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.266270141466521e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.7726924852468073e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015335310308728367
mask_decoder.transformer.norm_final_attn.weight grad: 1.5280476873158477e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.2057153981004376e-05
Text_Embedding_Affine.0.weight grad: -1.2290677156578944e-11
Text_Embedding_Affine.0.bias grad: -1.935330368185717e-10
Text_Embedding_Affine.2.weight grad: -1.543733058051444e-10
Text_Embedding_Affine.2.bias grad: 1.9462268028291874e-05
Epoch 4 finished with average loss: -66.0065
Epoch 5/39
----------
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, loss=-69.4]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-69.4]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-70]  Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-70]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-66.6]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-66.6]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09763438999652863

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09763438999652863

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08960962295532227

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.31238818168640137

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09779071807861328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08960962295532227

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 64.73912048339844
Max value: 82.28973388671875
Mean value: 69.41472625732422

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09763438999652863

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09763438999652863

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09763438999652863

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.31238818168640137

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 64.73912048339844
Max value: 82.28973388671875
Mean value: 69.41472625732422

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.41497802734375
Max value: -69.41497802734375
Mean value: -69.41497802734375
sam_encoder.pos_embed grad: -1.9346312996049164e-08
sam_encoder.blocks.0.norm1.weight grad: 0.00010493549052625895
sam_encoder.blocks.0.norm1.bias grad: 3.218990605091676e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.2518677219050005e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.847350965064834e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.141474609146826e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.460773071623407e-07
sam_encoder.blocks.0.norm2.weight grad: 9.093136759474874e-05
sam_encoder.blocks.0.norm2.bias grad: 1.0386555004515685e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.704549115151167e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.420201664994238e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.0222890523436945e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.450530574715231e-06
sam_encoder.blocks.1.norm1.weight grad: 4.7592093324055895e-06
sam_encoder.blocks.1.norm1.bias grad: 9.959661838365719e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3042252248851582e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.9961440709012095e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.675467865425162e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.388289643335156e-06
sam_encoder.blocks.1.norm2.weight grad: 2.599119397928007e-05
sam_encoder.blocks.1.norm2.bias grad: -7.97101529315114e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.9720554266532417e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.385183723978116e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.758852340572048e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.971051228290889e-06
sam_encoder.blocks.2.norm1.weight grad: -3.757220838451758e-05
sam_encoder.blocks.2.norm1.bias grad: -1.1971394997090101e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.1015532183810137e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.159775810170686e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.2310188796836883e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0858438145078253e-05
sam_encoder.blocks.2.norm2.weight grad: -2.1875630409340374e-05
sam_encoder.blocks.2.norm2.bias grad: -1.6518737311344012e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.6748905181884766e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.791615538124461e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.6540595879632747e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.727899398763839e-07
sam_encoder.blocks.3.norm1.weight grad: 2.4063651835604105e-06
sam_encoder.blocks.3.norm1.bias grad: -1.846532541094348e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.900492164480966e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4944225767976604e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.615248483081814e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.004833499493543e-06
sam_encoder.blocks.3.norm2.weight grad: 1.5983689081622288e-05
sam_encoder.blocks.3.norm2.bias grad: -4.441270448296564e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.0096280675497837e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.359865215519676e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.0497641596884932e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.1480155939789256e-06
sam_encoder.blocks.4.norm1.weight grad: 3.968251985497773e-05
sam_encoder.blocks.4.norm1.bias grad: -1.3742057490162551e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.9780924048973247e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 5.042135853727814e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.650626114103943e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.172837624442764e-06
sam_encoder.blocks.4.norm2.weight grad: -6.585082155652344e-05
sam_encoder.blocks.4.norm2.bias grad: -3.590001870179549e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.872303907177411e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.8248492779093795e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.679345470824046e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.154837931011571e-07
sam_encoder.blocks.5.norm1.weight grad: 2.835104169207625e-05
sam_encoder.blocks.5.norm1.bias grad: -1.856078415585216e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.3223114365246147e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.013113655470079e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.172160283313133e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.309129275905434e-06
sam_encoder.blocks.5.norm2.weight grad: -2.647445217007771e-05
sam_encoder.blocks.5.norm2.bias grad: -2.1391035261331126e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1488110430946108e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.477138989183004e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.244046736966993e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.239475977854454e-06
sam_encoder.blocks.6.norm1.weight grad: 1.6124853573273867e-05
sam_encoder.blocks.6.norm1.bias grad: 8.638532563054468e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 9.073837645701133e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.871360720746452e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.3705362056934973e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.974842451905715e-07
sam_encoder.blocks.6.norm2.weight grad: -1.1589398127398454e-05
sam_encoder.blocks.6.norm2.bias grad: -7.247015673783608e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.1035301213269122e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.591249307850376e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.038047336507589e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.4626297115682974e-06
sam_encoder.blocks.7.norm1.weight grad: 8.292116945085581e-06
sam_encoder.blocks.7.norm1.bias grad: 1.228492919835844e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.123568942304701e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6074844779723207e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.6736112229409628e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.4414567885978613e-06
sam_encoder.blocks.7.norm2.weight grad: 6.52629012165562e-07
sam_encoder.blocks.7.norm2.bias grad: 1.0757557902252302e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2769197585148504e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.180587999755517e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.422159468551399e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0152203913094127e-06
sam_encoder.blocks.8.norm1.weight grad: 3.66716130884015e-06
sam_encoder.blocks.8.norm1.bias grad: -5.983211849525105e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2512618923210539e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.8809935227181995e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9920024644525256e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.881112429051427e-06
sam_encoder.blocks.8.norm2.weight grad: 8.521964787178149e-07
sam_encoder.blocks.8.norm2.bias grad: -1.972835889318958e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.375330953123921e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.970788141799858e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.051646886997332e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.561662075910135e-07
sam_encoder.blocks.9.norm1.weight grad: 9.037818244905793e-07
sam_encoder.blocks.9.norm1.bias grad: 1.0667989727153326e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.411069423644221e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.674064252365497e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.305212707502506e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 8.611967672322862e-08
sam_encoder.blocks.9.norm2.weight grad: 9.928016879712231e-06
sam_encoder.blocks.9.norm2.bias grad: 2.0390302779560443e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.486741767730564e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.3859669201774523e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.6040467016864568e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.4469581439443573e-07
sam_encoder.blocks.10.norm1.weight grad: 1.0284747986588627e-05
sam_encoder.blocks.10.norm1.bias grad: 2.1205419216130394e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.165346919966396e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.9783451534749474e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.2482358872366603e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.4251652373786783e-06
sam_encoder.blocks.10.norm2.weight grad: 1.811796573747415e-05
sam_encoder.blocks.10.norm2.bias grad: 3.3951480418181745e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.26708435144974e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.64633103547385e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.7889401533466298e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.220381010280107e-07
sam_encoder.blocks.11.norm1.weight grad: 1.920499198604375e-05
sam_encoder.blocks.11.norm1.bias grad: -1.968098075622038e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.0524161047651432e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.5301537220911996e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.0572381370366202e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.2265677418763516e-07
sam_encoder.blocks.11.norm2.weight grad: 1.9055605662288144e-05
sam_encoder.blocks.11.norm2.bias grad: 2.9929792617622297e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0845620636246167e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.823560862452723e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.2772634363500401e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.7183768363793206e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.227369234082289e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.8742943211691454e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.647578629781492e-07
sam_encoder.neck.conv2.trainable_shift grad: 7.009696673776489e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 3.739500243682414e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.5625886337365955e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005134043283760548
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00018065539188683033
mask_decoder.transformer.layers.0.norm3.weight grad: -4.3538486352190375e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.3861448678653687e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.256969497073442e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.284612365765497e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.55714803643059e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.569636075757444e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00028656277572736144
mask_decoder.transformer.layers.1.norm2.bias grad: -8.947780588641763e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.5471788578433916e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.858135748188943e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.4665648601949215e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018191426352132112
mask_decoder.transformer.norm_final_attn.weight grad: 8.205084668588825e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.066608643275686e-06
Text_Embedding_Affine.0.weight grad: -7.96106323225354e-12
Text_Embedding_Affine.0.bias grad: -4.294360977930012e-10
Text_Embedding_Affine.2.weight grad: 2.554451268566016e-11
Text_Embedding_Affine.2.bias grad: 3.968734745285474e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07859010994434357

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07859010994434357

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07819271087646484

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.25645893812179565

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07847166061401367

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07819271087646484

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 59.466896057128906
Max value: 92.61651611328125
Mean value: 70.31941223144531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07843726873397827

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07843726873397827

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07843726873397827

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2469368875026703

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.512091875076294
Max value: 5.646437168121338
Mean value: 1.0130491256713867

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 59.466896057128906
Max value: 92.61651611328125
Mean value: 70.31941223144531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.63508605957031
Max value: -70.63508605957031
Mean value: -70.63508605957031
sam_encoder.pos_embed grad: 8.046562305352722e-10
sam_encoder.blocks.0.norm1.weight grad: -2.3075304852682166e-05
sam_encoder.blocks.0.norm1.bias grad: 2.3407414118992165e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.6415854083315935e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.6970652672607685e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.972583388327621e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.7513848433736712e-06
sam_encoder.blocks.0.norm2.weight grad: 2.1335761630325578e-05
sam_encoder.blocks.0.norm2.bias grad: -6.033363206370268e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.5425221135956235e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.1094388102937955e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.1788181331648957e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.807127773645334e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1449635621829657e-06
sam_encoder.blocks.1.norm1.bias grad: 5.069879080110695e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.495700925919664e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.597401582235761e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.60614251349034e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.0936516875735833e-07
sam_encoder.blocks.1.norm2.weight grad: 7.255785931192804e-06
sam_encoder.blocks.1.norm2.bias grad: -5.132902742843726e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.147427610703744e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.544936137383047e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.0692611713002407e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.5000264852460532e-07
sam_encoder.blocks.2.norm1.weight grad: 8.707098459126428e-06
sam_encoder.blocks.2.norm1.bias grad: -1.956338309128114e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.844408977078274e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.3429510090645636e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.985566531307995e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.4116016018306254e-06
sam_encoder.blocks.2.norm2.weight grad: -5.458823579829186e-06
sam_encoder.blocks.2.norm2.bias grad: -2.9064583486615447e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.107899035763694e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.5854830053285696e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.132307599822525e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3928404314356158e-06
sam_encoder.blocks.3.norm1.weight grad: -4.929852366331033e-06
sam_encoder.blocks.3.norm1.bias grad: 6.182859806358465e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.7247600630507804e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.490487531758845e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.8349946913076565e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.1902161506659468e-07
sam_encoder.blocks.3.norm2.weight grad: 4.97877454108675e-06
sam_encoder.blocks.3.norm2.bias grad: 7.489012205041945e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.631351202988299e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.228900029876968e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.2721270650217775e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.0080135243460973e-07
sam_encoder.blocks.4.norm1.weight grad: -2.2086644548835466e-06
sam_encoder.blocks.4.norm1.bias grad: 3.1887100249150535e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.325353989363066e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.95694893693144e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2382552085909992e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.4050647223484702e-06
sam_encoder.blocks.4.norm2.weight grad: -1.3492162906914018e-05
sam_encoder.blocks.4.norm2.bias grad: 1.0119101716554724e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0320013643649872e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.412827481952263e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.2330931440374115e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.23226391224307e-06
sam_encoder.blocks.5.norm1.weight grad: -7.472617198800435e-06
sam_encoder.blocks.5.norm1.bias grad: -7.057819857436698e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.6031894978805212e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.938413884607144e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.4919572777216672e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.4340446341520874e-06
sam_encoder.blocks.5.norm2.weight grad: -8.523371434421279e-06
sam_encoder.blocks.5.norm2.bias grad: 2.302493555816909e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.314483703637961e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6770148931755102e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.5364186601327674e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.884269510010199e-07
sam_encoder.blocks.6.norm1.weight grad: 2.8080589800083544e-06
sam_encoder.blocks.6.norm1.bias grad: 1.5429072846018244e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.3227762565293233e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.2539927613252075e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.442687201044464e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.0806844247545087e-07
sam_encoder.blocks.6.norm2.weight grad: 1.9067554148932686e-06
sam_encoder.blocks.6.norm2.bias grad: 3.0888963920006063e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.3805714590707794e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0146263775823172e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.566910025820107e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.595101532027911e-07
sam_encoder.blocks.7.norm1.weight grad: -2.8261254101380473e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4020487242305535e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.3805565686197951e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.962225036957534e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.886207823848963e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.0065642729605315e-06
sam_encoder.blocks.7.norm2.weight grad: 4.785763849213254e-06
sam_encoder.blocks.7.norm2.bias grad: 1.4488027773040812e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.2556715723330854e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.458825408917619e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.0699527542310534e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.727137484725972e-07
sam_encoder.blocks.8.norm1.weight grad: -6.701154688926181e-06
sam_encoder.blocks.8.norm1.bias grad: 2.2092337985668564e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.0730216066294815e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.9556283607234946e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3673610510522849e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.1117610938526923e-06
sam_encoder.blocks.8.norm2.weight grad: -5.053990435044398e-07
sam_encoder.blocks.8.norm2.bias grad: -7.665325369998754e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.682720072286429e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.216127417246753e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.5527805291858385e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.206576858540757e-08
sam_encoder.blocks.9.norm1.weight grad: -3.934786036552396e-06
sam_encoder.blocks.9.norm1.bias grad: -2.8164279797238123e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.746897507677204e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.104365191575198e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.485536126390798e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.6979978454401135e-06
sam_encoder.blocks.9.norm2.weight grad: -6.685576181553188e-07
sam_encoder.blocks.9.norm2.bias grad: -9.61844762059627e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.236685526848305e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.76047808003932e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.635814824880072e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.6080140830563323e-07
sam_encoder.blocks.10.norm1.weight grad: -4.6516134943885845e-07
sam_encoder.blocks.10.norm1.bias grad: -1.0042890608019661e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0200049018749269e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.737389645015355e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.713746643072227e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.743977228827134e-07
sam_encoder.blocks.10.norm2.weight grad: -5.332733962859493e-06
sam_encoder.blocks.10.norm2.bias grad: -3.3008295758918393e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.086656766347005e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.079273144772742e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6004141798475757e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.876287900719035e-07
sam_encoder.blocks.11.norm1.weight grad: -1.6773495872257627e-06
sam_encoder.blocks.11.norm1.bias grad: 3.844422167276207e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.6316361072531436e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.341116775525734e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.022494396049296e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.748127816535998e-07
sam_encoder.blocks.11.norm2.weight grad: -5.139585027791327e-06
sam_encoder.blocks.11.norm2.bias grad: -1.3132282674632734e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.3495341022462526e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4192962680681376e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.681997673586011e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.1819782710445e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.965762390289456e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3681543350685388e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1383572200429626e-06
sam_encoder.neck.conv2.trainable_shift grad: 3.36577431880869e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002755579771474004
mask_decoder.transformer.layers.0.norm1.bias grad: -5.189540388528258e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003054167842492461
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0012271006125956774
mask_decoder.transformer.layers.0.norm3.weight grad: -1.940281072165817e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.674711479106918e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.629734005196951e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.0639909052988514e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.624644447583705e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0335573935881257e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.2671413060161285e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.736273932503536e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.081943891127594e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.719439988955855e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.699370947491843e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011626902414718643
mask_decoder.transformer.norm_final_attn.weight grad: 1.2643229638342746e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.036231878970284e-05
Text_Embedding_Affine.0.weight grad: -8.415817522033908e-12
Text_Embedding_Affine.0.bias grad: -2.734549808813824e-10
Text_Embedding_Affine.2.weight grad: 3.161652883942878e-11
Text_Embedding_Affine.2.bias grad: 3.948010635212995e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0875018760561943

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0875018760561943

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08417797088623047

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.25183212757110596

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08743476867675781

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08417797088623047

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 38.06949996948242
Max value: 74.04039001464844
Mean value: 59.52947998046875

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671414852142334

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671414852142334

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671414852142334

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.23022837936878204

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5517798066139221
Max value: 24.087684631347656
Mean value: 1.0436513423919678

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 38.06949996948242
Max value: 74.04039001464844
Mean value: 59.52947998046875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.840110778808594
Max value: -59.840110778808594
Mean value: -59.840110778808594
sam_encoder.pos_embed grad: 4.451420121398542e-09
sam_encoder.blocks.0.norm1.weight grad: 1.1920371434825938e-05
sam_encoder.blocks.0.norm1.bias grad: 3.57469471055083e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.41435736825224e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.5455404067665768e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.837308213405777e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.0173966908696457e-07
sam_encoder.blocks.0.norm2.weight grad: 3.7676029023714364e-05
sam_encoder.blocks.0.norm2.bias grad: -2.247188149340218e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1444982192188036e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.2391039894719142e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.8816218673455296e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.369990503822919e-06
sam_encoder.blocks.1.norm1.weight grad: -8.575602805649396e-07
sam_encoder.blocks.1.norm1.bias grad: 1.7383590602548793e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.9935633847344434e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.4422929552893038e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.7255483625340275e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.9260668270580936e-06
sam_encoder.blocks.1.norm2.weight grad: -5.831508133269381e-06
sam_encoder.blocks.1.norm2.bias grad: -9.658826456870884e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.0598203011322767e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.1947033726755762e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.780431931474595e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.1033409919036785e-06
sam_encoder.blocks.2.norm1.weight grad: -4.382254701340571e-06
sam_encoder.blocks.2.norm1.bias grad: -3.3130208976217546e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.5844919971641502e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.1921133591386024e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.944370524142869e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.1693637134158053e-06
sam_encoder.blocks.2.norm2.weight grad: 1.581491596880369e-05
sam_encoder.blocks.2.norm2.bias grad: -1.476021111557202e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.922325261868536e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.914822744060075e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.318132363958284e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2156988304923289e-06
sam_encoder.blocks.3.norm1.weight grad: -1.4078544154472183e-05
sam_encoder.blocks.3.norm1.bias grad: 4.6356335587915964e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.106051270966418e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.04738205159083e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.159145646553952e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.474184839229565e-06
sam_encoder.blocks.3.norm2.weight grad: 1.5160323528107256e-05
sam_encoder.blocks.3.norm2.bias grad: 2.033772034337744e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.220655217883177e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.1990368875558488e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1966851161560044e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.920197403000202e-06
sam_encoder.blocks.4.norm1.weight grad: -3.328956518089399e-05
sam_encoder.blocks.4.norm1.bias grad: -5.4134902711666655e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.9364480976946652e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.535893706110073e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.014554623514414e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.879967607645085e-06
sam_encoder.blocks.4.norm2.weight grad: 4.286212970328052e-06
sam_encoder.blocks.4.norm2.bias grad: 6.538131856359541e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1583409786908305e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.916090574624832e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.824790721613681e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.9825954495900078e-06
sam_encoder.blocks.5.norm1.weight grad: -2.8387315978761762e-05
sam_encoder.blocks.5.norm1.bias grad: -1.1970219020440709e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.8134951460524462e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.5674290757015115e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.073992386111058e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.070685230952222e-06
sam_encoder.blocks.5.norm2.weight grad: -3.5227481021138374e-06
sam_encoder.blocks.5.norm2.bias grad: -8.1156576925423e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.7894078609970165e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.5174655838309263e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.890639737212041e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.312700760536245e-06
sam_encoder.blocks.6.norm1.weight grad: -1.0951827789540403e-05
sam_encoder.blocks.6.norm1.bias grad: -1.6635119663988007e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.685893367830431e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.60017259279266e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.17700198845705e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.6050171325332485e-06
sam_encoder.blocks.6.norm2.weight grad: -5.7731440392672084e-06
sam_encoder.blocks.6.norm2.bias grad: -4.5432543629431166e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.125017428828869e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.170578682125779e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.555958513374208e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.704971262181061e-07
sam_encoder.blocks.7.norm1.weight grad: -3.2451916922582313e-06
sam_encoder.blocks.7.norm1.bias grad: 2.9076898044877453e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.362344846711494e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.0559197600487096e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.8088478504505474e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.6721330098334874e-07
sam_encoder.blocks.7.norm2.weight grad: -2.813047103700228e-06
sam_encoder.blocks.7.norm2.bias grad: -1.7749487142282305e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.699703135382151e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7087353398892446e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.132874203335632e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.080876578882453e-07
sam_encoder.blocks.8.norm1.weight grad: 7.438015927618835e-06
sam_encoder.blocks.8.norm1.bias grad: 1.5778596207383089e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.32626097285538e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.3504994715040084e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.661260153530748e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.7948243566934252e-06
sam_encoder.blocks.8.norm2.weight grad: -5.787496775155887e-06
sam_encoder.blocks.8.norm2.bias grad: -3.3529108804941643e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.351224783429643e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.274999810149893e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.204141532682115e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.93921788802254e-07
sam_encoder.blocks.9.norm1.weight grad: -5.3228741307975724e-06
sam_encoder.blocks.9.norm1.bias grad: 3.409735995774099e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.316255737852771e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.1546625248447526e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.216723376273876e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4040419955563266e-06
sam_encoder.blocks.9.norm2.weight grad: -8.901591172616463e-06
sam_encoder.blocks.9.norm2.bias grad: -6.508883416245226e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.57783914700849e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.415086550579872e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.2044378056307323e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.966836387320654e-07
sam_encoder.blocks.10.norm1.weight grad: -1.574666839587735e-06
sam_encoder.blocks.10.norm1.bias grad: -1.752964976731164e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -8.593278835178353e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.404489110740542e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.8424165659780556e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.792772590964887e-07
sam_encoder.blocks.10.norm2.weight grad: -1.522965612821281e-05
sam_encoder.blocks.10.norm2.bias grad: -7.788006769260392e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.5894997785799205e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.242132374405628e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.2721759453124832e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.5318590840252e-06
sam_encoder.blocks.11.norm1.weight grad: -6.780544026696589e-06
sam_encoder.blocks.11.norm1.bias grad: 4.3604318307188805e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.069529720458377e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.301286710666318e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.650990821479354e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.167374522192404e-07
sam_encoder.blocks.11.norm2.weight grad: -1.1844763321278151e-05
sam_encoder.blocks.11.norm2.bias grad: -8.55265352583956e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.319427610724233e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.471040716045536e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.5497952265141066e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.660795517949737e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.1802840162999928e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.820802572183311e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.1819793144240975e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.6386296415003017e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012330300523899496
mask_decoder.transformer.layers.0.norm1.bias grad: 6.6813372541219e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00114022649358958
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00033570697996765375
mask_decoder.transformer.layers.0.norm3.weight grad: -3.100765752606094e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 8.566536416765302e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.1900006433716044e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.5074988368724007e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 0.00010085888061439618
mask_decoder.transformer.layers.1.norm1.bias grad: -9.447376214666292e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002826264826580882
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0002271039120387286
mask_decoder.transformer.layers.1.norm3.weight grad: 9.275446063838899e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00011609780631260946
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0001684454473434016
mask_decoder.transformer.layers.1.norm4.bias grad: 3.0043691367609426e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.5023240848677233e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.3582421161117963e-05
Text_Embedding_Affine.0.weight grad: -3.520595490483225e-12
Text_Embedding_Affine.0.bias grad: 1.242564662273793e-10
Text_Embedding_Affine.2.weight grad: 1.0244023684879977e-10
Text_Embedding_Affine.2.bias grad: -6.15958015259821e-07
Epoch 5 finished with average loss: -66.6301
Epoch 6/39
----------
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62.2]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-62.2]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-64.7]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-64.7]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-67.7]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-67.7]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078341044485569

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078341044485569

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0742340087890625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.28184011578559875

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07821178436279297

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0742340087890625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 56.30192947387695
Max value: 69.34961700439453
Mean value: 62.14996337890625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078341044485569

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078341044485569

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078341044485569

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.28184011578559875

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 56.30192947387695
Max value: 69.34961700439453
Mean value: 62.14996337890625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.15021514892578
Max value: -62.15021514892578
Mean value: -62.15021514892578
sam_encoder.pos_embed grad: 8.020140995768088e-09
sam_encoder.blocks.0.norm1.weight grad: -3.108700184384361e-05
sam_encoder.blocks.0.norm1.bias grad: -2.795625914586708e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.908048024139134e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.242878498596838e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.347771886794362e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0161882073589368e-06
sam_encoder.blocks.0.norm2.weight grad: -2.9272185201989487e-05
sam_encoder.blocks.0.norm2.bias grad: -3.656823901110329e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.114752861525631e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.528913218062371e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8205133528681472e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.1181715510465438e-06
sam_encoder.blocks.1.norm1.weight grad: -1.6790652352938196e-06
sam_encoder.blocks.1.norm1.bias grad: 9.869851055555046e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.8777308216376696e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5236809051421005e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.689938916475512e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.243970917945262e-06
sam_encoder.blocks.1.norm2.weight grad: -2.1904790628468618e-05
sam_encoder.blocks.1.norm2.bias grad: -3.465612053332734e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.4137621039699297e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.502285267880211e-09
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.7911339455167763e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6252773775704554e-06
sam_encoder.blocks.2.norm1.weight grad: 9.42508086154703e-06
sam_encoder.blocks.2.norm1.bias grad: 4.995669769414235e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.303556574493996e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.397374363587005e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.972046215494629e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.7733649403671734e-06
sam_encoder.blocks.2.norm2.weight grad: 3.3764542877179338e-06
sam_encoder.blocks.2.norm2.bias grad: -5.047245849709725e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.645160807584034e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.842574874899583e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3717180991079658e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.396213287487626e-06
sam_encoder.blocks.3.norm1.weight grad: 6.3083421082410496e-06
sam_encoder.blocks.3.norm1.bias grad: 1.0223512617812958e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 8.954049235398998e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.3338637927517993e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.705112921030377e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.519886950518412e-06
sam_encoder.blocks.3.norm2.weight grad: -5.256403710518498e-06
sam_encoder.blocks.3.norm2.bias grad: 4.696811629401054e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.3583564800210297e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.3556061680428684e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.026722182170488e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.7336907351127593e-06
sam_encoder.blocks.4.norm1.weight grad: -1.9032680938835256e-05
sam_encoder.blocks.4.norm1.bias grad: -5.854105893376982e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.904196874937043e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.1515718344744528e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -5.543065526580904e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.667932787720929e-06
sam_encoder.blocks.4.norm2.weight grad: -5.701938903257542e-07
sam_encoder.blocks.4.norm2.bias grad: 2.0274733287806157e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.262430467060767e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.0546244766374002e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.850175628234865e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.523564929419081e-07
sam_encoder.blocks.5.norm1.weight grad: -1.0290952559444122e-05
sam_encoder.blocks.5.norm1.bias grad: -5.255996711639455e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.2948294170200825e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2793619816875434e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.749376051269792e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.018598706854391e-06
sam_encoder.blocks.5.norm2.weight grad: -9.450543075217865e-06
sam_encoder.blocks.5.norm2.bias grad: 2.656918468346703e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.546073225559667e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.239900595668587e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4257323073252337e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.602386631333502e-07
sam_encoder.blocks.6.norm1.weight grad: -8.404278560192324e-06
sam_encoder.blocks.6.norm1.bias grad: -4.120481094105344e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.477140580798732e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.715445124427788e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.606322517337503e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.057979812292615e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0660012776497751e-05
sam_encoder.blocks.6.norm2.bias grad: 3.562947767932201e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.602559667750029e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.6663255994208157e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.2408330576363369e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.453519011349272e-07
sam_encoder.blocks.7.norm1.weight grad: 4.1498634573144955e-07
sam_encoder.blocks.7.norm1.bias grad: 9.063189736480126e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.271080402100779e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3400699572230224e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.417480007148697e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1386505320842844e-06
sam_encoder.blocks.7.norm2.weight grad: -5.194605364522431e-06
sam_encoder.blocks.7.norm2.bias grad: -5.126245739006663e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.463821824174374e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1695601642713882e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.388606041378807e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.878928396261472e-07
sam_encoder.blocks.8.norm1.weight grad: 5.455105110740988e-06
sam_encoder.blocks.8.norm1.bias grad: 2.7783842142525828e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.9329848884081e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.6836178221856244e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.6678626479915692e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.6866340502019739e-06
sam_encoder.blocks.8.norm2.weight grad: -4.003096364613157e-06
sam_encoder.blocks.8.norm2.bias grad: 2.303754484955789e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.873426067002583e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.925472017523134e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.483925633598119e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.5307483042524836e-07
sam_encoder.blocks.9.norm1.weight grad: 8.557245791962487e-07
sam_encoder.blocks.9.norm1.bias grad: -1.1185728681084584e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.841658427627408e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.695847443756065e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.057523821960785e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.969335236637562e-07
sam_encoder.blocks.9.norm2.weight grad: -7.888727850513533e-06
sam_encoder.blocks.9.norm2.bias grad: -3.2700636438676156e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.400165380502585e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.8954818844795227e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.6572138267511036e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.68688101054704e-08
sam_encoder.blocks.10.norm1.weight grad: -1.13836483706109e-06
sam_encoder.blocks.10.norm1.bias grad: -2.8414394819265e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.097273737599608e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.817296475172043e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1610113404003641e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.026408646495838e-07
sam_encoder.blocks.10.norm2.weight grad: -1.099053679354256e-05
sam_encoder.blocks.10.norm2.bias grad: -2.2924814402358606e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.733576472266577e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.5203181596443756e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.17286571519071e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.677107424162386e-07
sam_encoder.blocks.11.norm1.weight grad: -2.1815785657963715e-06
sam_encoder.blocks.11.norm1.bias grad: 2.3668235371587798e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.4100929749693023e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.7287214265925286e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.206094778666738e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.319644174051064e-07
sam_encoder.blocks.11.norm2.weight grad: -4.194181656203e-06
sam_encoder.blocks.11.norm2.bias grad: -2.7490677894093096e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.659959136508405e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.831941045173153e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.3478871702973265e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.406241143646184e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.893831934779882e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1882101716764737e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.1661395546980202e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.163477231282741e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 6.746587314410135e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 7.170638127718121e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00402973685413599
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0007840690668672323
mask_decoder.transformer.layers.0.norm3.weight grad: -6.49006906314753e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.7361328799743205e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.074228000827134e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.7951246011070907e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.853261867130641e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.7892812037607655e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00024715453037060797
mask_decoder.transformer.layers.1.norm2.bias grad: 8.218424045480788e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.5647066144738346e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.080912473611534e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.932367589091882e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001877020695246756
mask_decoder.transformer.norm_final_attn.weight grad: 2.4799012408038834e-06
mask_decoder.transformer.norm_final_attn.bias grad: -5.279340484776185e-07
Text_Embedding_Affine.0.weight grad: 2.159347353702934e-12
Text_Embedding_Affine.0.bias grad: -9.124714872577044e-13
Text_Embedding_Affine.2.weight grad: 1.513760644611395e-11
Text_Embedding_Affine.2.bias grad: -3.809896588791162e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09554869681596756

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09554869681596756

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09127283096313477

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2777129113674164

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09538459777832031

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09127283096313477

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 50.208351135253906
Max value: 80.17093658447266
Mean value: 66.93032836914062

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0943390354514122

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0943390354514122

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0943390354514122

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2662874758243561

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6492159366607666
Max value: 4.333333969116211
Mean value: 1.014855980873108

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 50.208351135253906
Max value: 80.17093658447266
Mean value: 66.93032836914062

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.34602355957031
Max value: -67.34602355957031
Mean value: -67.34602355957031
sam_encoder.pos_embed grad: -5.509495082378635e-10
sam_encoder.blocks.0.norm1.weight grad: 1.4993165677879006e-05
sam_encoder.blocks.0.norm1.bias grad: 3.020252552232705e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.7942405747817247e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.375093875021776e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.3339302401836903e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4304287105915137e-06
sam_encoder.blocks.0.norm2.weight grad: 2.4240140191977844e-05
sam_encoder.blocks.0.norm2.bias grad: -2.411295281490311e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.708726803277386e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.916507355621434e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.203376869962085e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.0995668112154817e-06
sam_encoder.blocks.1.norm1.weight grad: 9.918827345245518e-06
sam_encoder.blocks.1.norm1.bias grad: 3.091428425250342e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.6013807169201755e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.3164412255027855e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1776456858569873e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.7170578909572214e-07
sam_encoder.blocks.1.norm2.weight grad: 1.683716504885524e-06
sam_encoder.blocks.1.norm2.bias grad: -7.057935249576985e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.806399035966024e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.837194738793187e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.187450607176288e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.7562185778151616e-07
sam_encoder.blocks.2.norm1.weight grad: -1.5091607110662153e-06
sam_encoder.blocks.2.norm1.bias grad: -1.6331399592672824e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.423510920834815e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.2635650743250153e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.137672936441959e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.2474348523028311e-06
sam_encoder.blocks.2.norm2.weight grad: -6.772024789825082e-06
sam_encoder.blocks.2.norm2.bias grad: -3.631117579061538e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.924979293718934e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.7940022871698602e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7983014661003835e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2848502137785545e-06
sam_encoder.blocks.3.norm1.weight grad: -1.3074294656689744e-05
sam_encoder.blocks.3.norm1.bias grad: -2.8484519134508446e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.692614417464938e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5872856238274835e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.978534666908672e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.068082249541476e-07
sam_encoder.blocks.3.norm2.weight grad: 8.062934284680523e-06
sam_encoder.blocks.3.norm2.bias grad: 7.3974724728032015e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.758507541031577e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.5164267754007597e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.7656235463146004e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.721049779414898e-07
sam_encoder.blocks.4.norm1.weight grad: -4.066113433509599e-06
sam_encoder.blocks.4.norm1.bias grad: 1.4405685533347423e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.643137461040169e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2390640904413885e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0281536333422991e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.1683964658004697e-06
sam_encoder.blocks.4.norm2.weight grad: -1.5239023014146369e-05
sam_encoder.blocks.4.norm2.bias grad: -5.021655624659616e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0476293937244918e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.1661872981203487e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.2269902072148398e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.3712914324059966e-06
sam_encoder.blocks.5.norm1.weight grad: -7.633761924807914e-06
sam_encoder.blocks.5.norm1.bias grad: 2.578819476184435e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.969137651438359e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5920880969133577e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7044783362507587e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.9986266579508083e-06
sam_encoder.blocks.5.norm2.weight grad: -8.0773379522725e-06
sam_encoder.blocks.5.norm2.bias grad: -6.571484618689283e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.632437594409566e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.7899959630085505e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.437759682536125e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.8269317315098306e-07
sam_encoder.blocks.6.norm1.weight grad: 1.7046539824150386e-06
sam_encoder.blocks.6.norm1.bias grad: 1.2019713722111192e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.688270799604652e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.607006189871754e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.82626943368814e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.48532694260939e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1894143199242535e-06
sam_encoder.blocks.6.norm2.bias grad: 2.11486349144252e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.003005536404089e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.610660309685045e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.0398116501164623e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.426305046465131e-07
sam_encoder.blocks.7.norm1.weight grad: -6.201662472449243e-08
sam_encoder.blocks.7.norm1.bias grad: 2.0137317733315285e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.450538083096035e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.1268513112081564e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.809149913853616e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.3102951470500557e-06
sam_encoder.blocks.7.norm2.weight grad: 3.2406721857114462e-06
sam_encoder.blocks.7.norm2.bias grad: 1.3400134548646747e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.222437845171953e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.372487177941366e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6569856597925536e-09
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.736529828936909e-08
sam_encoder.blocks.8.norm1.weight grad: 2.3723241611151025e-06
sam_encoder.blocks.8.norm1.bias grad: 1.489135001975228e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.88906949460943e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.6374200956524874e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.497902518276533e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.408017619221937e-07
sam_encoder.blocks.8.norm2.weight grad: -3.533166932356835e-07
sam_encoder.blocks.8.norm2.bias grad: -9.143285524260136e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.1900005243178384e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.983248456686852e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.126231919419297e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.394487298966851e-07
sam_encoder.blocks.9.norm1.weight grad: -1.4639839491792372e-06
sam_encoder.blocks.9.norm1.bias grad: 4.9017312875321295e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0938379091385286e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.9193419120711042e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.6667684121784987e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1804253290392808e-06
sam_encoder.blocks.9.norm2.weight grad: -5.947603654021805e-07
sam_encoder.blocks.9.norm2.bias grad: -9.589161891199183e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0688196283581419e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.155213441161322e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.3076943256892264e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.2349151979360613e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4075237686483888e-06
sam_encoder.blocks.10.norm1.bias grad: -1.0602077509247465e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.7254573094760417e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.553616458404576e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.278605380633962e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.971613745714421e-07
sam_encoder.blocks.10.norm2.weight grad: -5.150373453943757e-06
sam_encoder.blocks.10.norm2.bias grad: -2.680179022718221e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.2283057913009543e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.967107436939841e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.7711345208226703e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.028129402897321e-07
sam_encoder.blocks.11.norm1.weight grad: 3.044685172426398e-06
sam_encoder.blocks.11.norm1.bias grad: -3.738697955668613e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.146223879317404e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.998858902486973e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.513033218245255e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.953830377487975e-07
sam_encoder.blocks.11.norm2.weight grad: -3.5654607017931994e-06
sam_encoder.blocks.11.norm2.bias grad: -1.67534082606835e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.1273066269932315e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3247412198325037e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6051034208430792e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.635479389340617e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0420098988106474e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.1200108019693289e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.910468073328957e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.680327063193545e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002493031497579068
mask_decoder.transformer.layers.0.norm1.bias grad: -4.1167004383169115e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004147067666053772
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0010782638564705849
mask_decoder.transformer.layers.0.norm3.weight grad: -3.503492916934192e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.21577860834077e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.7981964346254244e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.7319365472067147e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.571848669205792e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0257630239939317e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.0029320037574507e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 8.845949196256697e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.7781904868315905e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.629623046843335e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.437935215013567e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001227264292538166
mask_decoder.transformer.norm_final_attn.weight grad: 8.632325261714868e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.12621510704048e-06
Text_Embedding_Affine.0.weight grad: -1.3857819405882488e-11
Text_Embedding_Affine.0.bias grad: -4.428030997427612e-10
Text_Embedding_Affine.2.weight grad: 1.4268952686080638e-10
Text_Embedding_Affine.2.bias grad: 4.020711639896035e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09259727597236633

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09259727597236633

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08841228485107422

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19787460565567017

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09255504608154297

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08841228485107422

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 62.30929946899414
Max value: 90.80585479736328
Mean value: 73.36074829101562

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09102189540863037

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09102189540863037

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09102189540863037

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18364495038986206

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.48086485266685486
Max value: 12.57231330871582
Mean value: 1.0234183073043823

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 62.30929946899414
Max value: 90.80585479736328
Mean value: 73.36074829101562

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -73.6756591796875
Max value: -73.6756591796875
Mean value: -73.6756591796875
sam_encoder.pos_embed grad: -1.3270358145689443e-08
sam_encoder.blocks.0.norm1.weight grad: -1.6635784049867652e-05
sam_encoder.blocks.0.norm1.bias grad: 4.405467916512862e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.270614787557861e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.6441069305983547e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.792846993950661e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.725827112561092e-07
sam_encoder.blocks.0.norm2.weight grad: 2.3697275537415408e-05
sam_encoder.blocks.0.norm2.bias grad: 6.517925794469193e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.329587732674554e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.0435111107653938e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.3039385268930346e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.184787475329358e-06
sam_encoder.blocks.1.norm1.weight grad: 3.307229007987189e-06
sam_encoder.blocks.1.norm1.bias grad: 1.652625905990135e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.745781214092858e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.313835107604973e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.209785172155534e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.680450835323427e-07
sam_encoder.blocks.1.norm2.weight grad: 1.7082049453165382e-05
sam_encoder.blocks.1.norm2.bias grad: -9.243351087206975e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.7885096187674208e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6023740272430587e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.14131534146145e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.187156158266589e-06
sam_encoder.blocks.2.norm1.weight grad: 1.4244629710447043e-05
sam_encoder.blocks.2.norm1.bias grad: -5.0364096750854515e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.571984274865827e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.374644954121322e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.55720180273056e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.717014457535697e-06
sam_encoder.blocks.2.norm2.weight grad: -1.8105474737240002e-06
sam_encoder.blocks.2.norm2.bias grad: 2.9593078920697735e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.531785528641194e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.0843264084978728e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.0305134209338576e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0177268450206611e-06
sam_encoder.blocks.3.norm1.weight grad: 3.060736617044313e-06
sam_encoder.blocks.3.norm1.bias grad: -1.1213286597921979e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.3888482044421835e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.9667663764266763e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.335984279648983e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.9689326765947044e-06
sam_encoder.blocks.3.norm2.weight grad: 1.9828297808999196e-05
sam_encoder.blocks.3.norm2.bias grad: -9.331822070635098e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.6290414350805804e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.461963726498652e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.0724235835368745e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.191862677136669e-06
sam_encoder.blocks.4.norm1.weight grad: 2.6202767912764102e-05
sam_encoder.blocks.4.norm1.bias grad: -2.1854091301065637e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.2163639439677354e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.7823956517968327e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.53221866034437e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.973315066716168e-06
sam_encoder.blocks.4.norm2.weight grad: -5.147322008269839e-05
sam_encoder.blocks.4.norm2.bias grad: -2.8876649594167247e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.4319171390961856e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3609760571853258e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.566239345469512e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.597215466783382e-08
sam_encoder.blocks.5.norm1.weight grad: 1.3734173080592882e-05
sam_encoder.blocks.5.norm1.bias grad: -2.2400713532988448e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.016948984528426e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.3884217651138897e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.674758656619815e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.191994776192587e-06
sam_encoder.blocks.5.norm2.weight grad: -2.1000412743887864e-05
sam_encoder.blocks.5.norm2.bias grad: -1.5810208424227312e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.198525392799638e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.454754732956644e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.158906095763086e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.107770905648067e-07
sam_encoder.blocks.6.norm1.weight grad: 6.9658472057199106e-06
sam_encoder.blocks.6.norm1.bias grad: 8.467844054393936e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.892663698934484e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.536557417442964e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.865454689526814e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.7206390263454523e-07
sam_encoder.blocks.6.norm2.weight grad: -5.619829153147293e-06
sam_encoder.blocks.6.norm2.bias grad: -7.852515409467742e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.501307901387918e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.0428260540938936e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.0609756745670893e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.706034081256803e-07
sam_encoder.blocks.7.norm1.weight grad: 3.844108050543582e-06
sam_encoder.blocks.7.norm1.bias grad: 2.387939957770868e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.9731741051364224e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.7560113292347523e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5772654933243757e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.087789756747952e-07
sam_encoder.blocks.7.norm2.weight grad: 8.46266993903555e-06
sam_encoder.blocks.7.norm2.bias grad: -8.614703972398274e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 8.30735189083498e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.7594281871424755e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.7125889826274943e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.215496904995234e-07
sam_encoder.blocks.8.norm1.weight grad: -3.4403892641421407e-06
sam_encoder.blocks.8.norm1.bias grad: -2.7698129088093992e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.010227596358163e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.231098278571153e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.696261961114942e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.168692051578546e-06
sam_encoder.blocks.8.norm2.weight grad: 3.207702775398502e-06
sam_encoder.blocks.8.norm2.bias grad: -2.298387244081823e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.450641997915227e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.078962441170006e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.7236941946284787e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.97049040102138e-07
sam_encoder.blocks.9.norm1.weight grad: -1.468210371058376e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0094829576701159e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.412667054675694e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.595332706638146e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.720445071550785e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1099809853476472e-06
sam_encoder.blocks.9.norm2.weight grad: 9.661139301897492e-06
sam_encoder.blocks.9.norm2.bias grad: 7.220963738063801e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.116542292351369e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.1261940875992877e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.279636520252097e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.335687495109596e-07
sam_encoder.blocks.10.norm1.weight grad: 4.901773536403198e-06
sam_encoder.blocks.10.norm1.bias grad: 1.8643586372490972e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.4228669392177835e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.1549409464350902e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.314704943273682e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.394981361765531e-07
sam_encoder.blocks.10.norm2.weight grad: 1.2733586117974482e-05
sam_encoder.blocks.10.norm2.bias grad: 8.440663350484101e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.950574515940389e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.8910151286254404e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.1717635689810777e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.584254374000011e-08
sam_encoder.blocks.11.norm1.weight grad: 1.8038890630123205e-05
sam_encoder.blocks.11.norm1.bias grad: 1.613408358025481e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.002506110125978e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.4336943599555525e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.0662250790337566e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.5697258365653397e-07
sam_encoder.blocks.11.norm2.weight grad: 9.713445251691155e-06
sam_encoder.blocks.11.norm2.bias grad: 1.8517735043133143e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.7053697421215475e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.188892611025949e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.051754907166469e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.142445272416808e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0464646038599312e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.0531198212411255e-06
sam_encoder.neck.conv2.trainable_scale grad: -8.903371053747833e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.835936852032319e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00023562725982628763
mask_decoder.transformer.layers.0.norm1.bias grad: -5.551271897275001e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004232184961438179
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0007211788324639201
mask_decoder.transformer.layers.0.norm3.weight grad: -4.3913933041039854e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.1648738260846585e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011109537445008755
mask_decoder.transformer.layers.0.norm4.bias grad: 2.1482264855876565e-08
mask_decoder.transformer.layers.1.norm1.weight grad: 4.213007559883408e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 8.423403414781205e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00014967727474868298
mask_decoder.transformer.layers.1.norm2.bias grad: -1.4878587535349652e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.0863551981165074e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.4485140127362683e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -1.887132202682551e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00024076772388070822
mask_decoder.transformer.norm_final_attn.weight grad: 1.5412801076308824e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.6298781702062115e-05
Text_Embedding_Affine.0.weight grad: -3.757678890270455e-11
Text_Embedding_Affine.0.bias grad: -1.0246177239991994e-09
Text_Embedding_Affine.2.weight grad: 1.103819952108509e-10
Text_Embedding_Affine.2.bias grad: 4.7200162953231484e-05
Epoch 6 finished with average loss: -67.7240
Epoch 7/39
----------
Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/3 [00:01<?, ?it/s, loss=-54.8]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it, loss=-54.8]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it, loss=-60.6]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-60.6]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-63]  Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.20it/s, loss=-63]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06577993184328079

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06577993184328079

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0727996826171875

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2525530457496643

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06452226638793945

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0727996826171875

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 32.323944091796875
Max value: 81.23946380615234
Mean value: 54.84773254394531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06577993184328079

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06577993184328079

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06577993184328079

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2525530457496643

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 32.323944091796875
Max value: 81.23946380615234
Mean value: 54.84773254394531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.84807205200195
Max value: -54.84807205200195
Mean value: -54.84807205200195
sam_encoder.pos_embed grad: -1.170811714246156e-08
sam_encoder.blocks.0.norm1.weight grad: -5.572603549808264e-05
sam_encoder.blocks.0.norm1.bias grad: -3.65281812264584e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.0463171747687738e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.6166177374543622e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.716489901416935e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.8771014513040427e-06
sam_encoder.blocks.0.norm2.weight grad: -6.18279300397262e-05
sam_encoder.blocks.0.norm2.bias grad: 6.560330803040415e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.773060810402967e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.193752364604734e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.1281904992065392e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.058123234543018e-05
sam_encoder.blocks.1.norm1.weight grad: -9.94069705484435e-06
sam_encoder.blocks.1.norm1.bias grad: 3.462409949861467e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.223669733008137e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.6888869822651031e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 7.890888809924945e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.34020455738937e-06
sam_encoder.blocks.1.norm2.weight grad: 3.554170689312741e-05
sam_encoder.blocks.1.norm2.bias grad: -2.0111633602937218e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.860376141848974e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.079956852365285e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.932188403472537e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.820769264479168e-07
sam_encoder.blocks.2.norm1.weight grad: 2.6023990358226e-06
sam_encoder.blocks.2.norm1.bias grad: -1.8805127183441073e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 9.378514732816257e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.0327959216738236e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.458186024043243e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 4.318113042245386e-06
sam_encoder.blocks.2.norm2.weight grad: -2.018345867327298e-06
sam_encoder.blocks.2.norm2.bias grad: 2.4940109142335132e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.887993322379771e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.2621956102520926e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.746123522636481e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.116606871524709e-07
sam_encoder.blocks.3.norm1.weight grad: 2.0143201254541054e-05
sam_encoder.blocks.3.norm1.bias grad: -1.0831286999746226e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 6.216162546479609e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.514222276455257e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.274584171071183e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.375071385875344e-09
sam_encoder.blocks.3.norm2.weight grad: -9.277342542191036e-06
sam_encoder.blocks.3.norm2.bias grad: -2.8572608243848663e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.555217391403858e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.7558766052825376e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.2825437352148583e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.959841130083078e-07
sam_encoder.blocks.4.norm1.weight grad: 1.322487059951527e-05
sam_encoder.blocks.4.norm1.bias grad: -8.097244972304907e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.803276275808457e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.8061740547636873e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.754196536145173e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.82457471662201e-06
sam_encoder.blocks.4.norm2.weight grad: -2.2664316929876804e-05
sam_encoder.blocks.4.norm2.bias grad: -3.2161915441975e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.133843670686474e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.241714800125919e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.037860324184294e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.4688970395582146e-06
sam_encoder.blocks.5.norm1.weight grad: 4.4126500142738223e-07
sam_encoder.blocks.5.norm1.bias grad: -2.8694747015833855e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.5655273222801043e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.658862962969579e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.0759462131536566e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.526813770804438e-06
sam_encoder.blocks.5.norm2.weight grad: -7.77293917053612e-06
sam_encoder.blocks.5.norm2.bias grad: -1.9624792912509292e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.682489594008075e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.899374630440434e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.899782991036773e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.21701236316585e-07
sam_encoder.blocks.6.norm1.weight grad: 5.481718744704267e-06
sam_encoder.blocks.6.norm1.bias grad: 4.710038410848938e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.554844730999321e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.479283921275055e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.052920758113032e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.301697572373087e-06
sam_encoder.blocks.6.norm2.weight grad: -3.312774788355455e-05
sam_encoder.blocks.6.norm2.bias grad: -6.497098183899652e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.4366736397496425e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.0439440302434377e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.257161438341427e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.623699972697068e-06
sam_encoder.blocks.7.norm1.weight grad: 1.584085839567706e-05
sam_encoder.blocks.7.norm1.bias grad: -1.9105098090221873e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.184824193653185e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.3048488603526494e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.224197138886666e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.010344815062126e-06
sam_encoder.blocks.7.norm2.weight grad: -1.3677572496817447e-06
sam_encoder.blocks.7.norm2.bias grad: 1.8549881133367307e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.986679406712938e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5707125839981018e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.215414482037886e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.193851618263579e-07
sam_encoder.blocks.8.norm1.weight grad: 7.914412890386302e-06
sam_encoder.blocks.8.norm1.bias grad: -5.09718302055262e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.5604812082019635e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.910045395765337e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.86227940605022e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.524697376633412e-06
sam_encoder.blocks.8.norm2.weight grad: -2.508845454940456e-06
sam_encoder.blocks.8.norm2.bias grad: -3.145156370010227e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.2854261512984522e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.5706567637607804e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.050032652638038e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.995558123890078e-07
sam_encoder.blocks.9.norm1.weight grad: 7.963252755871508e-06
sam_encoder.blocks.9.norm1.bias grad: 1.35802088152559e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.174383088364266e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4984034351073205e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.90955176751595e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.8963877412024885e-06
sam_encoder.blocks.9.norm2.weight grad: 2.2332603748509428e-06
sam_encoder.blocks.9.norm2.bias grad: -1.0394091987109277e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.249451310693985e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.423944788977678e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.038029717572499e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.371936708797875e-07
sam_encoder.blocks.10.norm1.weight grad: 6.663114618277177e-06
sam_encoder.blocks.10.norm1.bias grad: 2.2001713659847155e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.3043132791353855e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.6811725345178274e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.5428821572859306e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.625175951237907e-07
sam_encoder.blocks.10.norm2.weight grad: 1.0303308954462409e-05
sam_encoder.blocks.10.norm2.bias grad: 9.865631227512495e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.785508619737811e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.297555056429701e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.4511887204425875e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.052553753628672e-07
sam_encoder.blocks.11.norm1.weight grad: 1.3267191206978168e-05
sam_encoder.blocks.11.norm1.bias grad: 2.3576926651003305e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.0092524007632164e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.0730647065647645e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.999855380243389e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2757070635416312e-06
sam_encoder.blocks.11.norm2.weight grad: 1.4920478861313313e-05
sam_encoder.blocks.11.norm2.bias grad: -1.9597841856011655e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 9.361194315715693e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.252023023174843e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.441120952629717e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0852500054170378e-06
sam_encoder.neck.conv1.trainable_scale grad: -4.4406351662473753e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.431833101785742e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.673058229964226e-07
sam_encoder.neck.conv2.trainable_shift grad: -0.00011543779692146927
mask_decoder.transformer.layers.0.norm1.weight grad: 9.152088750852272e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.116445779800415e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0034961539786309004
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0010143318213522434
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00010003412171499804
mask_decoder.transformer.layers.0.norm3.bias grad: -3.079889575019479e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.001436071936041e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1113337677670643e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.8441618522047065e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.867501386092044e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001792025868780911
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00012056344712618738
mask_decoder.transformer.layers.1.norm3.weight grad: -1.6802636309876107e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.5204473533667624e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.8334052078425884e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010477986506884918
mask_decoder.transformer.norm_final_attn.weight grad: 5.043527380621526e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.697316282748943e-06
Text_Embedding_Affine.0.weight grad: -1.0452877279021333e-11
Text_Embedding_Affine.0.bias grad: -2.0082373264340703e-10
Text_Embedding_Affine.2.weight grad: -9.795916855459552e-11
Text_Embedding_Affine.2.bias grad: -1.783438347047195e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08295593410730362

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08295593410730362

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0829019546508789

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2072874903678894

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08283805847167969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0829019546508789

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.497432708740234
Max value: 91.18746948242188
Mean value: 66.114990234375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08273962885141373

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08273962885141373

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08273962885141373

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19904327392578125

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6825869083404541
Max value: 4.983105659484863
Mean value: 1.0114468336105347

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.497432708740234
Max value: 91.18746948242188
Mean value: 66.114990234375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.38108825683594
Max value: -66.38108825683594
Mean value: -66.38108825683594
sam_encoder.pos_embed grad: -3.314448715485696e-09
sam_encoder.blocks.0.norm1.weight grad: 2.7408670575823635e-05
sam_encoder.blocks.0.norm1.bias grad: 2.291215605509933e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.3959571535669966e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.354186878188557e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.2880250273592537e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.582205527483893e-06
sam_encoder.blocks.0.norm2.weight grad: 4.076318509760313e-05
sam_encoder.blocks.0.norm2.bias grad: -1.5818905012565665e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0262825526297092e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.720430635847151e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.041549451969331e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.310818439989816e-06
sam_encoder.blocks.1.norm1.weight grad: 8.217833965318277e-06
sam_encoder.blocks.1.norm1.bias grad: 6.306036084424704e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.523969437286723e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.650731615489349e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.1957808864244726e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.5169597392959986e-06
sam_encoder.blocks.1.norm2.weight grad: 1.3045608284301125e-05
sam_encoder.blocks.1.norm2.bias grad: 9.556673603583477e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3004400898353197e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.432732106986805e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.718456577596953e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.874805424355145e-07
sam_encoder.blocks.2.norm1.weight grad: -7.608362466271501e-06
sam_encoder.blocks.2.norm1.bias grad: -1.9642866391222924e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.022778284706874e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0486704695722437e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.979143224976724e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.655957814567955e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1146871656819712e-05
sam_encoder.blocks.2.norm2.bias grad: 7.226800335047301e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0233807188342325e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.702666051845881e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.4913657651050016e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.703772778062557e-07
sam_encoder.blocks.3.norm1.weight grad: -9.583141945768148e-06
sam_encoder.blocks.3.norm1.bias grad: -7.049453415675089e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.532963430392556e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.971304920469265e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.3097486518963706e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.1077768742070475e-07
sam_encoder.blocks.3.norm2.weight grad: 2.6719008019426838e-06
sam_encoder.blocks.3.norm2.bias grad: 4.180347787041683e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.104974323126953e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.0998536456318107e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.6340986803697888e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.858055374119431e-07
sam_encoder.blocks.4.norm1.weight grad: -5.832453098264523e-07
sam_encoder.blocks.4.norm1.bias grad: -2.5395388547622133e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.3958400561241433e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.975103138349368e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.985969088826096e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.7283932152167836e-07
sam_encoder.blocks.4.norm2.weight grad: -1.4467666915152222e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0131836461368948e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1297636774543207e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.3774543883046135e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.320735330220487e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.310866981744766e-07
sam_encoder.blocks.5.norm1.weight grad: -5.427973064797698e-06
sam_encoder.blocks.5.norm1.bias grad: 1.505725549577619e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.879606422036886e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.3529790976463119e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0581387641650508e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.8116802493750583e-06
sam_encoder.blocks.5.norm2.weight grad: -1.0454502444190439e-05
sam_encoder.blocks.5.norm2.bias grad: -4.735578841064125e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.969697783963056e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.7882121028378606e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.478241622673522e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.460815704187553e-07
sam_encoder.blocks.6.norm1.weight grad: 9.300982810600544e-07
sam_encoder.blocks.6.norm1.bias grad: 3.976991138188168e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.620498425036203e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.5571898731868714e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.417789902319782e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.8469249596364534e-07
sam_encoder.blocks.6.norm2.weight grad: -1.685070287749113e-06
sam_encoder.blocks.6.norm2.bias grad: -6.35167452855967e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.929070094774943e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.909679205411521e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.4447567764364067e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.19083050928748e-07
sam_encoder.blocks.7.norm1.weight grad: 3.8007462990208296e-06
sam_encoder.blocks.7.norm1.bias grad: 1.9661381429614266e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.3506876206956804e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.1933170753763989e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9882008928107098e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.0475754897452134e-07
sam_encoder.blocks.7.norm2.weight grad: 2.5092822397709824e-06
sam_encoder.blocks.7.norm2.bias grad: 8.859122857529655e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.583516202837927e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.390397283619677e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.838017831498291e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.975077783659799e-07
sam_encoder.blocks.8.norm1.weight grad: 2.076365490211174e-06
sam_encoder.blocks.8.norm1.bias grad: -6.494610715890303e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.5017185432952829e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.650486739090411e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.9167155187460594e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.060850192719954e-06
sam_encoder.blocks.8.norm2.weight grad: 1.1168212949996814e-06
sam_encoder.blocks.8.norm2.bias grad: -1.3914894907429698e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.819267254177248e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.281911050289636e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.957255660466899e-09
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.0067351158559177e-07
sam_encoder.blocks.9.norm1.weight grad: -5.703564056602772e-07
sam_encoder.blocks.9.norm1.bias grad: 4.794549681719218e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.961240508942865e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.292648772112443e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.430317351809208e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.520713557416457e-07
sam_encoder.blocks.9.norm2.weight grad: 1.4953818663343554e-06
sam_encoder.blocks.9.norm2.bias grad: -7.507014743168838e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.381492211294244e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.3000494309144415e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.152654006858938e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.945610498907627e-07
sam_encoder.blocks.10.norm1.weight grad: 3.5939533518103417e-06
sam_encoder.blocks.10.norm1.bias grad: -3.5712417911781813e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.018436018464854e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0440953701618128e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2494981547206407e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.411402288606041e-07
sam_encoder.blocks.10.norm2.weight grad: 3.3124405263151857e-07
sam_encoder.blocks.10.norm2.bias grad: -1.600208634044975e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.664047658778145e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.792600639622833e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0265151786370552e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.237395785366971e-07
sam_encoder.blocks.11.norm1.weight grad: 8.543210242351051e-06
sam_encoder.blocks.11.norm1.bias grad: -9.66102561505977e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -9.494590358372079e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.475113588701788e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.7556723125599092e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.845969504505774e-07
sam_encoder.blocks.11.norm2.weight grad: -1.802916131055099e-06
sam_encoder.blocks.11.norm2.bias grad: -9.001225294014148e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.198562469857279e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.454931510939787e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4661900422652252e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.616138534809579e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.072444426128641e-07
sam_encoder.neck.conv1.trainable_shift grad: -8.580522262491286e-06
sam_encoder.neck.conv2.trainable_scale grad: -8.264923962997273e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.031938806292601e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001718315324978903
mask_decoder.transformer.layers.0.norm1.bias grad: -2.330241841264069e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005091824568808079
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006467544008046389
mask_decoder.transformer.layers.0.norm3.weight grad: -5.020757089368999e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.337825182825327e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.943417585920542e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.0379069357877597e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.720388460555114e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.8178161553805694e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.793198266066611e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 8.309798431582749e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.20564426551573e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.537584027275443e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.6134163161041215e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014220376033335924
mask_decoder.transformer.norm_final_attn.weight grad: 7.915179594419897e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.468318239669316e-06
Text_Embedding_Affine.0.weight grad: 9.559315145013514e-12
Text_Embedding_Affine.0.bias grad: 2.7584307060735114e-10
Text_Embedding_Affine.2.weight grad: 1.1330197891012972e-10
Text_Embedding_Affine.2.bias grad: 2.950597627204843e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11076059192419052

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11076059192419052

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10772037506103516

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2941151261329651

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11116790771484375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10772037506103516

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.89691925048828
Max value: 78.6416244506836
Mean value: 67.24591064453125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11078624427318573

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11078624427318573

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11078624427318573

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.26550716161727905

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6815678477287292
Max value: 36.46071243286133
Mean value: 1.0608220100402832

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.89691925048828
Max value: 78.6416244506836
Mean value: 67.24591064453125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.67692565917969
Max value: -67.67692565917969
Mean value: -67.67692565917969
sam_encoder.pos_embed grad: 5.197544616919458e-09
sam_encoder.blocks.0.norm1.weight grad: 8.981279097497463e-05
sam_encoder.blocks.0.norm1.bias grad: 1.46833681355929e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.3658805023151217e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.4989217684587857e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.089614655342302e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.3580782933786395e-06
sam_encoder.blocks.0.norm2.weight grad: 9.13800613489002e-06
sam_encoder.blocks.0.norm2.bias grad: -7.0180408329179045e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.909731615043711e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.418756596649473e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.0457684766151942e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.5150288163567893e-05
sam_encoder.blocks.1.norm1.weight grad: -4.149161213717889e-06
sam_encoder.blocks.1.norm1.bias grad: 1.83417578227818e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2455979231162928e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.169849944446469e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.3196614418120589e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.602447683690116e-06
sam_encoder.blocks.1.norm2.weight grad: -3.347971505718306e-05
sam_encoder.blocks.1.norm2.bias grad: -4.333880042395322e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.6850353858899325e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.3556020753167104e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.685032475506887e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.8005962374445517e-06
sam_encoder.blocks.2.norm1.weight grad: -8.150836038112175e-06
sam_encoder.blocks.2.norm1.bias grad: 2.3832590159145184e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.921372005308513e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.143574857262138e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.1730905902804807e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.813752525478776e-07
sam_encoder.blocks.2.norm2.weight grad: -1.4213862868928118e-06
sam_encoder.blocks.2.norm2.bias grad: -7.028986146906391e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.1712501165893627e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.386616178133409e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.414244070474524e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.993921836809022e-06
sam_encoder.blocks.3.norm1.weight grad: 3.2229690987151116e-06
sam_encoder.blocks.3.norm1.bias grad: -1.5572744587188936e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.1509258683872758e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.716823233749892e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.5174299505815725e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.1018950090146973e-06
sam_encoder.blocks.3.norm2.weight grad: 3.611608008213807e-07
sam_encoder.blocks.3.norm2.bias grad: 1.0332218153052963e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3392176470006234e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7751706309354631e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1027032996935304e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.7337613371637417e-06
sam_encoder.blocks.4.norm1.weight grad: -1.5137071386561729e-05
sam_encoder.blocks.4.norm1.bias grad: -1.2015625543426722e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.810409442754462e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3307601420819992e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.965276730217738e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.4566401154734194e-06
sam_encoder.blocks.4.norm2.weight grad: 2.008492265304085e-05
sam_encoder.blocks.4.norm2.bias grad: 2.3606335162185133e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.1754484148696065e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.663998308591545e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.057235623302404e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.678911171955406e-07
sam_encoder.blocks.5.norm1.weight grad: -1.4939398170099594e-05
sam_encoder.blocks.5.norm1.bias grad: -9.149618563242257e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.431194833567133e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.3989373428557883e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.9414709388220217e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.9210727916506585e-06
sam_encoder.blocks.5.norm2.weight grad: -7.105281838448718e-07
sam_encoder.blocks.5.norm2.bias grad: 1.1905281098734122e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.2990940376766957e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.948236440010078e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.1127228794503026e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.547857083205599e-07
sam_encoder.blocks.6.norm1.weight grad: -8.57747727422975e-06
sam_encoder.blocks.6.norm1.bias grad: -5.9618464547384065e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.77121090827859e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.8255630038765958e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -9.970506198442308e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.381828150850197e-07
sam_encoder.blocks.6.norm2.weight grad: 1.2011178114335053e-06
sam_encoder.blocks.6.norm2.bias grad: 1.0840785762411542e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.4825648122496204e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.296422950275883e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.345108330497169e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.9711601453309413e-06
sam_encoder.blocks.7.norm1.weight grad: -5.261746991891414e-06
sam_encoder.blocks.7.norm1.bias grad: 2.2455278667621315e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.1114135456155054e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.490878048571176e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.146307888840965e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.31375236378517e-06
sam_encoder.blocks.7.norm2.weight grad: -5.812252311443444e-06
sam_encoder.blocks.7.norm2.bias grad: 3.682495730572555e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.588404282112606e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.7849519028677605e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.238434586222866e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.206776793580502e-08
sam_encoder.blocks.8.norm1.weight grad: -3.7072757095302222e-06
sam_encoder.blocks.8.norm1.bias grad: 2.808480530802626e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.3979565614572493e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.180627340450883e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.2000101580488263e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.9505118871165905e-06
sam_encoder.blocks.8.norm2.weight grad: -3.8063717511249706e-06
sam_encoder.blocks.8.norm2.bias grad: -2.133502448486979e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.744606485473923e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.2029502108343877e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.871858661521401e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.0059804935735883e-06
sam_encoder.blocks.9.norm1.weight grad: -2.41083057517244e-06
sam_encoder.blocks.9.norm1.bias grad: -5.287226301220471e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.7781297831097618e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3730890486840508e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.2204418453620747e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.110238537828991e-07
sam_encoder.blocks.9.norm2.weight grad: -5.956454515398946e-06
sam_encoder.blocks.9.norm2.bias grad: -2.623255113576306e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.091936145618092e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.187450374753098e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.730077307613101e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.0264023703475686e-07
sam_encoder.blocks.10.norm1.weight grad: -2.5149195153062465e-06
sam_encoder.blocks.10.norm1.bias grad: -3.922263204003684e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.1677203701765393e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.390228802250931e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.118042167850945e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.103765943204053e-07
sam_encoder.blocks.10.norm2.weight grad: -6.848994871688774e-06
sam_encoder.blocks.10.norm2.bias grad: -1.2077966857759748e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.1037909543083515e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.8317724627413554e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.2627232106679e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.327067356120097e-07
sam_encoder.blocks.11.norm1.weight grad: -1.877185241028201e-05
sam_encoder.blocks.11.norm1.bias grad: -1.1770275705202948e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.9290525870019337e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6068354113940586e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1428331845309003e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.482775122800376e-07
sam_encoder.blocks.11.norm2.weight grad: -9.831356692302506e-06
sam_encoder.blocks.11.norm2.bias grad: -5.186245289223734e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.935704626201186e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.1419650693133008e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4623926745116478e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.0993165605887043e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.6216548576485366e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2020134818158112e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.5890479921363294e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.280642704339698e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00013620973913930357
mask_decoder.transformer.layers.0.norm1.bias grad: 4.924288077745587e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0008094159420579672
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00031086604576557875
mask_decoder.transformer.layers.0.norm3.weight grad: -4.099159559700638e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.733118349686265e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -3.081355316680856e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.821502443519421e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.269571895245463e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.0908639524132013e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0004320329171605408
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00020002463134005666
mask_decoder.transformer.layers.1.norm3.weight grad: 8.523483120370656e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00010284869495080784
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0001123466354329139
mask_decoder.transformer.layers.1.norm4.bias grad: 7.83132272772491e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.1397005437174812e-05
mask_decoder.transformer.norm_final_attn.bias grad: 9.868956112768501e-06
Text_Embedding_Affine.0.weight grad: -6.514385385292254e-12
Text_Embedding_Affine.0.bias grad: -2.0232998609870378e-10
Text_Embedding_Affine.2.weight grad: -1.468948400418224e-11
Text_Embedding_Affine.2.bias grad: -1.3285094610182568e-05
Epoch 7 finished with average loss: -62.9687
Epoch 8/39
----------
Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/3 [00:01<?, ?it/s, loss=-68.4]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it, loss=-68.4]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it, loss=-67.3]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s, loss=-67.3]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s, loss=-64.2]Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.15it/s, loss=-64.2]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08302763849496841

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08302763849496841

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08184099197387695

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20388972759246826

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08310222625732422

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08184099197387695

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 56.86455535888672
Max value: 84.79720306396484
Mean value: 68.37830352783203

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08302763849496841

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08302763849496841

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08302763849496841

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20388972759246826

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 56.86455535888672
Max value: 84.79720306396484
Mean value: 68.37830352783203

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.37866973876953
Max value: -68.37866973876953
Mean value: -68.37866973876953
sam_encoder.pos_embed grad: 9.263612099630336e-10
sam_encoder.blocks.0.norm1.weight grad: 9.940783456841018e-06
sam_encoder.blocks.0.norm1.bias grad: -5.261399201117456e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.4838190003938507e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.790534381347243e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.848034339171136e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.243726212076581e-07
sam_encoder.blocks.0.norm2.weight grad: -6.461767770815641e-05
sam_encoder.blocks.0.norm2.bias grad: -2.4347653379663825e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.908311540129944e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.1894884412176907e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.503417014551815e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.764749185895198e-06
sam_encoder.blocks.1.norm1.weight grad: -1.029346003633691e-05
sam_encoder.blocks.1.norm1.bias grad: 2.953233888547402e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.727272996911779e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.458013116462098e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.592430509044789e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.014235855720472e-06
sam_encoder.blocks.1.norm2.weight grad: -2.2883727069711313e-05
sam_encoder.blocks.1.norm2.bias grad: 8.739971235627308e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.594579877448268e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.61996068629378e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.732053644649568e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.111145249727997e-06
sam_encoder.blocks.2.norm1.weight grad: 2.835933173628291e-06
sam_encoder.blocks.2.norm1.bias grad: -6.194238267198671e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.7881493477034383e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.850024642015342e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.939887614658801e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.423109541879967e-06
sam_encoder.blocks.2.norm2.weight grad: 7.854168870835565e-06
sam_encoder.blocks.2.norm2.bias grad: 1.4260778698371723e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.5540542739909142e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.550134922785219e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.949262463720515e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0071197493743966e-06
sam_encoder.blocks.3.norm1.weight grad: 1.2445449101505801e-05
sam_encoder.blocks.3.norm1.bias grad: 3.7161978525546147e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.112350198847707e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.2545641538963537e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.378942205425119e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.3023816336499294e-06
sam_encoder.blocks.3.norm2.weight grad: -7.009720320638735e-06
sam_encoder.blocks.3.norm2.bias grad: -7.225461558846291e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.381024832080584e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.524682935880264e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.559611402830342e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.803927021792333e-07
sam_encoder.blocks.4.norm1.weight grad: -3.88902435588534e-06
sam_encoder.blocks.4.norm1.bias grad: -1.1942453966184985e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.0003687950520543e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1530614756338764e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.1078199097246397e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.087673240363074e-06
sam_encoder.blocks.4.norm2.weight grad: 3.734184429049492e-05
sam_encoder.blocks.4.norm2.bias grad: 2.480926923453808e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.6259764126734808e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.0504380043130368e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.9022839953540824e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.6353018256486394e-06
sam_encoder.blocks.5.norm1.weight grad: -9.664343451731838e-06
sam_encoder.blocks.5.norm1.bias grad: -6.859372206236003e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.508338396495674e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.9965461888205027e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.992245395551436e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.3320831132878084e-06
sam_encoder.blocks.5.norm2.weight grad: 2.2318756236927584e-05
sam_encoder.blocks.5.norm2.bias grad: 7.561996426375117e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.882887752610259e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.567543328448664e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.8733002181979828e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.9164981495123357e-06
sam_encoder.blocks.6.norm1.weight grad: -6.236887202248909e-07
sam_encoder.blocks.6.norm1.bias grad: -7.354817171290051e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.414627299975109e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.2431580387328722e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.874263019402861e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.6649760254949797e-06
sam_encoder.blocks.6.norm2.weight grad: 2.9225363959994866e-06
sam_encoder.blocks.6.norm2.bias grad: 2.7514058729138924e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.6754047262948e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.7032450589103973e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.2804846392100444e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.049002768624632e-07
sam_encoder.blocks.7.norm1.weight grad: -7.77816694608191e-06
sam_encoder.blocks.7.norm1.bias grad: -1.8240270946989767e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.007478077663109e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.5554235182644334e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.4898339486535406e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.646282612455252e-06
sam_encoder.blocks.7.norm2.weight grad: -1.0934088550129673e-06
sam_encoder.blocks.7.norm2.bias grad: 1.5134631894397899e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.996270490664756e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.6272034574503778e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.202360064984532e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.276716367712652e-07
sam_encoder.blocks.8.norm1.weight grad: 8.906139896680543e-07
sam_encoder.blocks.8.norm1.bias grad: 1.1628242191363825e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.6061351288954029e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.554741508400184e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.6131530123384437e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.2294317381674773e-07
sam_encoder.blocks.8.norm2.weight grad: 3.4267784485564334e-06
sam_encoder.blocks.8.norm2.bias grad: 2.763941211014753e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.1479941122161108e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -9.074366147387991e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.2176094464375637e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.3330817409951123e-06
sam_encoder.blocks.9.norm1.weight grad: 3.83215410693083e-06
sam_encoder.blocks.9.norm1.bias grad: 3.994533415152546e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.009558329518768e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.952949433980393e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.7136114744716906e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.3982261179990019e-06
sam_encoder.blocks.9.norm2.weight grad: 1.9622973468358396e-06
sam_encoder.blocks.9.norm2.bias grad: 1.9565891307138372e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.087190733225725e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.152264368594842e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.923744204963441e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.6374636970795109e-06
sam_encoder.blocks.10.norm1.weight grad: -1.50017035593919e-06
sam_encoder.blocks.10.norm1.bias grad: -9.96383278106805e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.4740973003645195e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.711885447430177e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4870663562760456e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.685391784027161e-07
sam_encoder.blocks.10.norm2.weight grad: -8.00071461526386e-07
sam_encoder.blocks.10.norm2.bias grad: 3.057733692912734e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.9046331090066815e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.525159506054479e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.7473973912274232e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.7014503934406093e-07
sam_encoder.blocks.11.norm1.weight grad: -9.466127266932745e-06
sam_encoder.blocks.11.norm1.bias grad: -5.49351398149156e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.872073880804237e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.2936131952301366e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.116461458484991e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.684421466867207e-07
sam_encoder.blocks.11.norm2.weight grad: 3.2558041311858688e-06
sam_encoder.blocks.11.norm2.bias grad: -5.546888132812455e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.147792757677962e-08
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.769094286733889e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.495154831194668e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.6555977708776481e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.963752194773406e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.797849007649347e-05
sam_encoder.neck.conv2.trainable_scale grad: 5.384645191952586e-07
sam_encoder.neck.conv2.trainable_shift grad: -0.0001220845733769238
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00020071043400093913
mask_decoder.transformer.layers.0.norm1.bias grad: 9.667426638770849e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004444713704288006
mask_decoder.transformer.layers.0.norm2.bias grad: -0.001351566519588232
mask_decoder.transformer.layers.0.norm3.weight grad: 7.482340151909739e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 4.640933548216708e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010665098670870066
mask_decoder.transformer.layers.0.norm4.bias grad: 4.487767000682652e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.3523325833375566e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.484929831960471e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002568030613474548
mask_decoder.transformer.layers.1.norm2.bias grad: 9.380582196172327e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.869484423077665e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 1.8215003365185112e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 8.505831647198647e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.000183630152605474
mask_decoder.transformer.norm_final_attn.weight grad: 4.798592954102787e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.6976241568045225e-07
Text_Embedding_Affine.0.weight grad: 2.951013738927699e-11
Text_Embedding_Affine.0.bias grad: 1.1316370063241266e-09
Text_Embedding_Affine.2.weight grad: -1.065772747832483e-10
Text_Embedding_Affine.2.bias grad: -8.005641575437039e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0899636372923851

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0899636372923851

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0905003547668457

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2188776582479477

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08965539932250977

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0905003547668457

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.59671401977539
Max value: 77.92706298828125
Mean value: 65.98038482666016

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08908426761627197

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08908426761627197

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08908426761627197

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2114163190126419

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8214090466499329
Max value: 4.129827976226807
Mean value: 1.0093457698822021

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.59671401977539
Max value: 77.92706298828125
Mean value: 65.98038482666016

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.2997055053711
Max value: -66.2997055053711
Mean value: -66.2997055053711
sam_encoder.pos_embed grad: 3.496278822012755e-10
sam_encoder.blocks.0.norm1.weight grad: -3.8542850234080106e-05
sam_encoder.blocks.0.norm1.bias grad: 3.6140085285296664e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.347638658444339e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.713635431447983e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.64143988917931e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.846357690737932e-06
sam_encoder.blocks.0.norm2.weight grad: 5.1883573178201914e-05
sam_encoder.blocks.0.norm2.bias grad: -9.730420060805045e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.26260430685943e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.5342867451836355e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.216074451804161e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.810284970815701e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1921477380383294e-05
sam_encoder.blocks.1.norm1.bias grad: 5.4486736189574e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.1521086637221742e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1090868383689667e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.1608008207986131e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.0749029039943707e-07
sam_encoder.blocks.1.norm2.weight grad: 8.493030691170134e-06
sam_encoder.blocks.1.norm2.bias grad: -1.7561876575200586e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.129199401679216e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.699969100689486e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.096095042565139e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.832832339232482e-07
sam_encoder.blocks.2.norm1.weight grad: -3.9782567000656854e-06
sam_encoder.blocks.2.norm1.bias grad: -4.5128062993171625e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.6112165869562887e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0439653124194592e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.3925983845838346e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.9189957331254845e-06
sam_encoder.blocks.2.norm2.weight grad: -1.2680072359216865e-05
sam_encoder.blocks.2.norm2.bias grad: 1.8465159428160405e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.328039595857263e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.1974545890989248e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.522842234815471e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.1150367527079652e-06
sam_encoder.blocks.3.norm1.weight grad: -8.541004717699252e-06
sam_encoder.blocks.3.norm1.bias grad: -4.513614840107039e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.430787379940739e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.541153313970426e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.9829628804000095e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.5522995227001957e-06
sam_encoder.blocks.3.norm2.weight grad: 8.688583875482436e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1237751095904969e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.467411251127487e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.5395105442148633e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.3805922662868397e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5037434408782246e-08
sam_encoder.blocks.4.norm1.weight grad: -2.996036300828564e-06
sam_encoder.blocks.4.norm1.bias grad: 4.278172127669677e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.759419658104889e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3747676348430105e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2633640835701954e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.0879300589294871e-06
sam_encoder.blocks.4.norm2.weight grad: -2.2553589587914757e-05
sam_encoder.blocks.4.norm2.bias grad: -6.174013833515346e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.607828016858548e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.545851308852434e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.1387139642902184e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.5518534130242188e-06
sam_encoder.blocks.5.norm1.weight grad: -6.668606147286482e-06
sam_encoder.blocks.5.norm1.bias grad: 3.090314748988021e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.7002843125956133e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.1272397841821657e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.2863870324508753e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2936125131091103e-06
sam_encoder.blocks.5.norm2.weight grad: -1.8244467355543748e-05
sam_encoder.blocks.5.norm2.bias grad: -2.613501010273467e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.492681783740409e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.6407552670425503e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.483389496570453e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.321531613029947e-06
sam_encoder.blocks.6.norm1.weight grad: 2.929313268396072e-06
sam_encoder.blocks.6.norm1.bias grad: 2.0225422758812783e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.525914624129655e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.410141514199495e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.80511358394142e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.236757599253906e-07
sam_encoder.blocks.6.norm2.weight grad: -1.278409399674274e-06
sam_encoder.blocks.6.norm2.bias grad: 1.8213977455161512e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.991967562593345e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.620183809336595e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.681268540527526e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.473621177363384e-07
sam_encoder.blocks.7.norm1.weight grad: -5.978992589916743e-07
sam_encoder.blocks.7.norm1.bias grad: 2.2454105419456027e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.774268399567518e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.861511347873602e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.2651964804463205e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.982324647542555e-06
sam_encoder.blocks.7.norm2.weight grad: 1.632343810342718e-06
sam_encoder.blocks.7.norm2.bias grad: 1.130809323512949e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.3716338571612141e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.0055741768155713e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.505401764414273e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.91410310385254e-07
sam_encoder.blocks.8.norm1.weight grad: 1.4298096857601195e-06
sam_encoder.blocks.8.norm1.bias grad: 1.0129360816790722e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.4030187003299943e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.930702849989757e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.047613068294595e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.25897196060032e-07
sam_encoder.blocks.8.norm2.weight grad: -2.5191106942656916e-06
sam_encoder.blocks.8.norm2.bias grad: -1.026380914481706e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.140671315624786e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -8.967253961600363e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.2190832876513014e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.221657713467721e-07
sam_encoder.blocks.9.norm1.weight grad: -2.377779992457363e-06
sam_encoder.blocks.9.norm1.bias grad: 1.462403247387556e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.4323588857223513e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.299855393379403e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1566184809908009e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.3839616030963953e-06
sam_encoder.blocks.9.norm2.weight grad: -3.6710459880850976e-06
sam_encoder.blocks.9.norm2.bias grad: -2.027077016464318e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.704928061182727e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.4153063148114597e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.272349987237249e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.441078201329219e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2166250371592469e-06
sam_encoder.blocks.10.norm1.bias grad: -7.48716274756589e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.5162052022787975e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.440616632768069e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2224627425894141e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.315585884905886e-07
sam_encoder.blocks.10.norm2.weight grad: -6.66885125610861e-06
sam_encoder.blocks.10.norm2.bias grad: -3.7702109239035053e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.478909553043195e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8865706579163088e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.361976501357276e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.415360876919294e-07
sam_encoder.blocks.11.norm1.weight grad: 3.6972160160075873e-06
sam_encoder.blocks.11.norm1.bias grad: -7.538109798588266e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.3827066065205145e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.650959629590943e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.337178438618139e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.897484361914394e-07
sam_encoder.blocks.11.norm2.weight grad: -9.761350156622939e-06
sam_encoder.blocks.11.norm2.bias grad: -1.2641119155887282e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.3411274721875088e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.136316197720589e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.7372479962650687e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.286041651837877e-06
sam_encoder.neck.conv1.trainable_scale grad: -9.255272743757814e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.261129702674225e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.2766122381435707e-06
sam_encoder.neck.conv2.trainable_shift grad: 6.675953773083165e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00026890821754932404
mask_decoder.transformer.layers.0.norm1.bias grad: -5.773777957074344e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004262873902916908
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0014936629449948668
mask_decoder.transformer.layers.0.norm3.weight grad: -6.0974307416472584e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.1206418245565146e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.716315692756325e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.9224057622486725e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.570611781673506e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.9752845875918865e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 4.485970930545591e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011897317017428577
mask_decoder.transformer.layers.1.norm3.weight grad: 6.142058555269614e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.746793976868503e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.1198946594959125e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014407208072952926
mask_decoder.transformer.norm_final_attn.weight grad: 7.589067536173388e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.525499990559183e-06
Text_Embedding_Affine.0.weight grad: -1.129427627810653e-11
Text_Embedding_Affine.0.bias grad: -2.606170002028563e-10
Text_Embedding_Affine.2.weight grad: 6.589954970603884e-11
Text_Embedding_Affine.2.bias grad: 6.59896686556749e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06490089744329453

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06490089744329453

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07281494140625

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18914927542209625

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06393814086914062

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07281494140625

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 34.5189094543457
Max value: 78.5177001953125
Mean value: 57.75809860229492

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06441016495227814

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06441016495227814

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06441016495227814

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1774696558713913

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.563739001750946
Max value: 19.838285446166992
Mean value: 1.020021915435791

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 34.5189094543457
Max value: 78.5177001953125
Mean value: 57.75809860229492

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.95429229736328
Max value: -57.95429229736328
Mean value: -57.95429229736328
sam_encoder.pos_embed grad: -1.6497407884230597e-09
sam_encoder.blocks.0.norm1.weight grad: -2.7335117920301855e-05
sam_encoder.blocks.0.norm1.bias grad: 6.193789886310697e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.160954515304184e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.2235096253098163e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.142801794339903e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.6276225046094623e-07
sam_encoder.blocks.0.norm2.weight grad: 4.503366653807461e-05
sam_encoder.blocks.0.norm2.bias grad: -9.051112101587933e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.057628651324194e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.0311719001474557e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.4873086001898628e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.4097984098480083e-06
sam_encoder.blocks.1.norm1.weight grad: 8.865201834851177e-07
sam_encoder.blocks.1.norm1.bias grad: -3.7068239180371165e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.5425561059601023e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.658654794795439e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.2693906228378182e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.5024620476397104e-07
sam_encoder.blocks.1.norm2.weight grad: -3.320491259728442e-06
sam_encoder.blocks.1.norm2.bias grad: 6.290555347732152e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3094121413814719e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.26286645608343e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.6579021980287507e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.143399344982754e-06
sam_encoder.blocks.2.norm1.weight grad: 9.821065759751946e-06
sam_encoder.blocks.2.norm1.bias grad: -2.169012077501975e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.076948698639171e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.607886350844637e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.6952820942606195e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3969156498205848e-06
sam_encoder.blocks.2.norm2.weight grad: 4.5858032535761595e-06
sam_encoder.blocks.2.norm2.bias grad: -7.110724254744127e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.0834415863646427e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.771243311552098e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3567872656494728e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.1424485801825313e-09
sam_encoder.blocks.3.norm1.weight grad: -1.1323845683364198e-05
sam_encoder.blocks.3.norm1.bias grad: -1.3884435929867323e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.182017493003514e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6970938077065512e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.462126071302919e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.1691961882861506e-07
sam_encoder.blocks.3.norm2.weight grad: 6.295708772086073e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1207422176084947e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.651020728691947e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.5996839667641325e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.399956866218417e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.685871648594912e-07
sam_encoder.blocks.4.norm1.weight grad: 5.3780267990077846e-06
sam_encoder.blocks.4.norm1.bias grad: 3.406505811653915e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1760168945329497e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.735400812525768e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.1303034170850879e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.074522727634758e-07
sam_encoder.blocks.4.norm2.weight grad: -3.226700937375426e-05
sam_encoder.blocks.4.norm2.bias grad: -1.9508759578457102e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.2857326257508248e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.450787390756886e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.9557437553885393e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.217949713667622e-06
sam_encoder.blocks.5.norm1.weight grad: 5.495270215760684e-06
sam_encoder.blocks.5.norm1.bias grad: -5.672459337802138e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.030267857364379e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.756498684510007e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.0958681236370467e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.3043049307270849e-07
sam_encoder.blocks.5.norm2.weight grad: -1.976439671125263e-05
sam_encoder.blocks.5.norm2.bias grad: -8.736121344554704e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.383010026591364e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.404483777558198e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.3061352294462267e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.699400252799023e-08
sam_encoder.blocks.6.norm1.weight grad: 3.0555081593774958e-06
sam_encoder.blocks.6.norm1.bias grad: 4.152104338572826e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2674796607825556e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.912904679102212e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.792441935322131e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.5755184651643503e-07
sam_encoder.blocks.6.norm2.weight grad: -1.3933530453869025e-06
sam_encoder.blocks.6.norm2.bias grad: -1.345268401564681e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.155143195319397e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.6720444762086117e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.73121018432721e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.080936548689351e-07
sam_encoder.blocks.7.norm1.weight grad: 3.2091445518744877e-06
sam_encoder.blocks.7.norm1.bias grad: 1.8557082057668595e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.1097874853003304e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.4916120107955066e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.803783314055181e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.192595259970403e-07
sam_encoder.blocks.7.norm2.weight grad: 3.6161954994895495e-06
sam_encoder.blocks.7.norm2.bias grad: 5.232199669080728e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.366185748949647e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.537059006295749e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.869801604305394e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.150736453491845e-08
sam_encoder.blocks.8.norm1.weight grad: 4.881761469732737e-06
sam_encoder.blocks.8.norm1.bias grad: 2.539688352953817e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.483750333543867e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.983419661490188e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.652636557191727e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.990756335449987e-07
sam_encoder.blocks.8.norm2.weight grad: -3.3445655844843714e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2805030564777553e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.5645853181922575e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3109960264046094e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8248981632495997e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.980264626894495e-07
sam_encoder.blocks.9.norm1.weight grad: -5.075707122159656e-06
sam_encoder.blocks.9.norm1.bias grad: 1.5279140086477128e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.4709868234349415e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.093824597679486e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0079450021294178e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.2749622985429596e-06
sam_encoder.blocks.9.norm2.weight grad: -1.6302468566209427e-06
sam_encoder.blocks.9.norm2.bias grad: -2.901670768551412e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.1567502389862057e-08
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.608235131963738e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.4302973972444306e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.56117431263192e-07
sam_encoder.blocks.10.norm1.weight grad: 9.674852208263474e-07
sam_encoder.blocks.10.norm1.bias grad: -4.6562098532376694e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.624853649052966e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.888904700488638e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1110336117781117e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.22507467748801e-07
sam_encoder.blocks.10.norm2.weight grad: -2.79558071270003e-06
sam_encoder.blocks.10.norm2.bias grad: -4.015797003376065e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.3691352168953017e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1929632819374092e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.459783665173745e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.688256431492846e-08
sam_encoder.blocks.11.norm1.weight grad: 9.668957318353932e-06
sam_encoder.blocks.11.norm1.bias grad: -1.3650424079969525e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -8.278979635178985e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.080587695578288e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.273237656590936e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.241741630219622e-07
sam_encoder.blocks.11.norm2.weight grad: -4.377835466584656e-06
sam_encoder.blocks.11.norm2.bias grad: -3.8917733036214486e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.470162929872458e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.5551040632999502e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.63618585702352e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.82125015980273e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.047932063462213e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3234332982392516e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.758400559192523e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.848120392533019e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00021483880118466914
mask_decoder.transformer.layers.0.norm1.bias grad: -2.9530201572924852e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005223513580858707
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0009765704162418842
mask_decoder.transformer.layers.0.norm3.weight grad: -5.141879228176549e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.9582926799776033e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.943986565805972e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.510469004046172e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.5382275857264176e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.59108695294708e-08
mask_decoder.transformer.layers.1.norm2.weight grad: 4.2045146983582526e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.489068957511336e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.6542728998465464e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.713618545792997e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 8.517723472323269e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014649427612312138
mask_decoder.transformer.norm_final_attn.weight grad: 1.0730156645877287e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.0634457794367336e-05
Text_Embedding_Affine.0.weight grad: -2.6800861877007698e-11
Text_Embedding_Affine.0.bias grad: -8.241342053239009e-10
Text_Embedding_Affine.2.weight grad: -1.5932224983750132e-10
Text_Embedding_Affine.2.bias grad: 4.098971839994192e-05
Epoch 8 finished with average loss: -64.2109
Epoch 9/39
----------
Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.1]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-61.1]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-62.1]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-62.1]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-63.4]Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-63.4]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928938210010529

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928938210010529

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09145307540893555

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18782740831375122

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08685159683227539

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09145307540893555

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 23.68421173095703
Max value: 86.25798797607422
Mean value: 61.107322692871094

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928938210010529

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928938210010529

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928938210010529

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18782740831375122

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 23.68421173095703
Max value: 86.25798797607422
Mean value: 61.107322692871094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.10792541503906
Max value: -61.10792541503906
Mean value: -61.10792541503906
sam_encoder.pos_embed grad: -3.104084767002746e-09
sam_encoder.blocks.0.norm1.weight grad: -1.7321346604148857e-05
sam_encoder.blocks.0.norm1.bias grad: 3.284101694589481e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.666327979270136e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.6862570595985744e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.5309565191710135e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.1026988835947122e-06
sam_encoder.blocks.0.norm2.weight grad: -2.204025804530829e-06
sam_encoder.blocks.0.norm2.bias grad: 0.00011110116611234844
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.068900569924153e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.14288797401241e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.973705133830663e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.7455795386922546e-07
sam_encoder.blocks.1.norm1.weight grad: -4.753655503009213e-06
sam_encoder.blocks.1.norm1.bias grad: 2.2669903046335094e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.0917793739936315e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.4192321486916626e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.688174837814586e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.6202403660136042e-06
sam_encoder.blocks.1.norm2.weight grad: 3.715943603310734e-05
sam_encoder.blocks.1.norm2.bias grad: -4.835766503674677e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.306872556800954e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.026423878007336e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.0824618584592827e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.4149536582408473e-06
sam_encoder.blocks.2.norm1.weight grad: -2.0971507183276117e-05
sam_encoder.blocks.2.norm1.bias grad: -4.188013917882927e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3235368896857835e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.33152218243049e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1098634786321782e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.1872596587636508e-05
sam_encoder.blocks.2.norm2.weight grad: 9.150832624982286e-07
sam_encoder.blocks.2.norm2.bias grad: 7.868544344091788e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.6463437683996744e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.261843059794046e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.142671398061793e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.112556540458172e-07
sam_encoder.blocks.3.norm1.weight grad: 1.090448768081842e-05
sam_encoder.blocks.3.norm1.bias grad: -7.336414455494378e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.0192976333200932e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.082041075685993e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.187916950584622e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.2966114556766115e-06
sam_encoder.blocks.3.norm2.weight grad: -4.6056775317993015e-06
sam_encoder.blocks.3.norm2.bias grad: -7.223605962280999e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.386168944212841e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.4502642190782353e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1015310974471504e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.144623406114988e-07
sam_encoder.blocks.4.norm1.weight grad: 1.9059734768234193e-07
sam_encoder.blocks.4.norm1.bias grad: -2.6812226678885054e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.27839688907261e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.3010106764995726e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.5124505807762034e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.262093509372789e-06
sam_encoder.blocks.4.norm2.weight grad: 5.087137651571538e-06
sam_encoder.blocks.4.norm2.bias grad: -2.1654414013028145e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.276209670526441e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.771230128928437e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.197973107191501e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.6752999272284796e-06
sam_encoder.blocks.5.norm1.weight grad: 1.179345326818293e-05
sam_encoder.blocks.5.norm1.bias grad: -7.692563485761639e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.214636181946844e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.738204319844954e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.2315402828971855e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.897924787248485e-06
sam_encoder.blocks.5.norm2.weight grad: 1.408844309480628e-05
sam_encoder.blocks.5.norm2.bias grad: -2.4412156562902965e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.97962844040012e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.1865869257453596e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.842463229375426e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4673148598376429e-06
sam_encoder.blocks.6.norm1.weight grad: 1.2220162716403138e-05
sam_encoder.blocks.6.norm1.bias grad: 1.7004167602863163e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.516808520653285e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.108173359578359e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.025827145895164e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.9095772333675995e-06
sam_encoder.blocks.6.norm2.weight grad: 1.932014811245608e-06
sam_encoder.blocks.6.norm2.bias grad: -2.5244903554266784e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.380260982841719e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.650920182783011e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7438194390706485e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.2399106569537253e-07
sam_encoder.blocks.7.norm1.weight grad: -1.0110254322626133e-07
sam_encoder.blocks.7.norm1.bias grad: 8.757061777941999e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.562827875062794e-08
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.2916584068989323e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.338457746503991e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.188682846186566e-07
sam_encoder.blocks.7.norm2.weight grad: -6.1069831644999795e-06
sam_encoder.blocks.7.norm2.bias grad: -4.274493221601006e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.868903826922178e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.8789959287678357e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.0035943129623774e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.4260132249764865e-06
sam_encoder.blocks.8.norm1.weight grad: 3.2008647394832224e-06
sam_encoder.blocks.8.norm1.bias grad: -3.801828825089615e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.7413653848925605e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.0930405046092346e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.3777028016193071e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.339489921927452e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0655983260221547e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0525363904889673e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.350781696553895e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.036937530647265e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.94604854186764e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.87549219896755e-07
sam_encoder.blocks.9.norm1.weight grad: 3.79501898351009e-06
sam_encoder.blocks.9.norm1.bias grad: 7.42917677598598e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.5893485801352654e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.6415549453085987e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.950426273353514e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.2881495194960735e-06
sam_encoder.blocks.9.norm2.weight grad: 4.7844023356447e-06
sam_encoder.blocks.9.norm2.bias grad: 3.2701252621336607e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.695699549803976e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.9653930394269992e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.1678960112913046e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.898272199076018e-07
sam_encoder.blocks.10.norm1.weight grad: 7.949680593810626e-07
sam_encoder.blocks.10.norm1.bias grad: 3.053138698305702e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.926416406509816e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3117983144184109e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.604196988111653e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.011497705709189e-07
sam_encoder.blocks.10.norm2.weight grad: 8.439839803031646e-06
sam_encoder.blocks.10.norm2.bias grad: 2.7048270112572936e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.316728685196722e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.1612827367789578e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.760174192597333e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.893783736610203e-07
sam_encoder.blocks.11.norm1.weight grad: 9.19536341825733e-06
sam_encoder.blocks.11.norm1.bias grad: 2.892168993184896e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.969354111177381e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.029970111536386e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.467725021750084e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.813578571993276e-07
sam_encoder.blocks.11.norm2.weight grad: -3.936505436286097e-06
sam_encoder.blocks.11.norm2.bias grad: -3.3623500712565146e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.8355326574237552e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 6.154855327622499e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.973109071215731e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.296514124594978e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.856957507901825e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.4280477444117423e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8167311282013543e-06
sam_encoder.neck.conv2.trainable_shift grad: 1.7984693840844557e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 4.643111606128514e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.382170689292252e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0012333833146840334
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0012368381721898913
mask_decoder.transformer.layers.0.norm3.weight grad: 2.2622232791036367e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -7.939829811220989e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.996226875344291e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.4703402232262306e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -5.694660285371356e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.4589792044716887e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0004275806713849306
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00020029189181514084
mask_decoder.transformer.layers.1.norm3.weight grad: -7.287302287295461e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -8.535613596905023e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.278921526041813e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 3.6758254282176495e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.682393293682253e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.462273399345577e-06
Text_Embedding_Affine.0.weight grad: 4.044724971619118e-11
Text_Embedding_Affine.0.bias grad: 9.63368051998259e-10
Text_Embedding_Affine.2.weight grad: 1.9717069643654384e-10
Text_Embedding_Affine.2.bias grad: -2.860934728232678e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07892664521932602

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07892664521932602

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08167219161987305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20135650038719177

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07769012451171875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08167219161987305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.68244934082031
Max value: 72.28276062011719
Mean value: 62.72106170654297

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07902230322360992

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07902230322360992

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07902230322360992

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19231221079826355

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8129026293754578
Max value: 8.027708053588867
Mean value: 1.0125839710235596

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.68244934082031
Max value: 72.28276062011719
Mean value: 62.72106170654297

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.00407409667969
Max value: -63.00407409667969
Mean value: -63.00407409667969
sam_encoder.pos_embed grad: -1.4745318299702603e-09
sam_encoder.blocks.0.norm1.weight grad: -6.282683170866221e-05
sam_encoder.blocks.0.norm1.bias grad: 2.3581621633184113e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.772179636347573e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.238315215043258e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.461159394646529e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.499302181353414e-07
sam_encoder.blocks.0.norm2.weight grad: 2.149958163499832e-05
sam_encoder.blocks.0.norm2.bias grad: 1.8651637219591066e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.411401510471478e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.071019591516233e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.8372205633786507e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.524226374589489e-07
sam_encoder.blocks.1.norm1.weight grad: 8.983521183836274e-06
sam_encoder.blocks.1.norm1.bias grad: 5.232655894360505e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.9061175155220553e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.5131485042729764e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.5554819583485369e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.534480583766708e-07
sam_encoder.blocks.1.norm2.weight grad: 1.4996816389611922e-05
sam_encoder.blocks.1.norm2.bias grad: -9.450290008317097e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.1065586628974415e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.863449127398781e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.1220944315937231e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.372390497384913e-07
sam_encoder.blocks.2.norm1.weight grad: 9.38454775223363e-07
sam_encoder.blocks.2.norm1.bias grad: 2.354197931708768e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 8.409426186517521e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.4001622023206437e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5970863387337886e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.1278465283103287e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1282229024800472e-05
sam_encoder.blocks.2.norm2.bias grad: 4.98474037158303e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.863921498734271e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.540274863349623e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.27934024730348e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.211229005093628e-06
sam_encoder.blocks.3.norm1.weight grad: -5.57936800760217e-06
sam_encoder.blocks.3.norm1.bias grad: -1.8394921426079236e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.0954359974421095e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.496915491676191e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.365786715723516e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.812972065337817e-07
sam_encoder.blocks.3.norm2.weight grad: 6.920697046552959e-07
sam_encoder.blocks.3.norm2.bias grad: 6.748131454514805e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.0477377802308183e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4441291114053456e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.116814350003551e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.892391072848113e-07
sam_encoder.blocks.4.norm1.weight grad: 4.902589125777013e-07
sam_encoder.blocks.4.norm1.bias grad: 4.310130861995276e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 9.62113517744001e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.949875093667288e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.390256774262525e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.8869006857567e-07
sam_encoder.blocks.4.norm2.weight grad: -9.575269359629601e-06
sam_encoder.blocks.4.norm2.bias grad: -8.271178558061365e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.865341103752144e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.136728992103599e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.1010781690856675e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.227435632245033e-06
sam_encoder.blocks.5.norm1.weight grad: -6.277046850300394e-06
sam_encoder.blocks.5.norm1.bias grad: -1.9009257812285796e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.049688302780851e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.2448177787737222e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.204384602715436e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.88867475623556e-07
sam_encoder.blocks.5.norm2.weight grad: -1.0444477084092796e-05
sam_encoder.blocks.5.norm2.bias grad: -2.360235839660163e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.480089955904987e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6684959973645164e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.1440356502134819e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0246398005619994e-06
sam_encoder.blocks.6.norm1.weight grad: -1.259537327769067e-07
sam_encoder.blocks.6.norm1.bias grad: 2.3074107957654633e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.3658829800533567e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.776963239943143e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.248589438153431e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.425243330137164e-07
sam_encoder.blocks.6.norm2.weight grad: 7.175500371658927e-08
sam_encoder.blocks.6.norm2.bias grad: 8.946626621764153e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.0490960988818188e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.8746132468550059e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.960516311162792e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.754905494839477e-07
sam_encoder.blocks.7.norm1.weight grad: -1.1544003655217239e-06
sam_encoder.blocks.7.norm1.bias grad: 4.988393698113214e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.305978945102652e-08
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.142094667258789e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.573231641799794e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.3351099116553087e-06
sam_encoder.blocks.7.norm2.weight grad: 2.1407388430816354e-06
sam_encoder.blocks.7.norm2.bias grad: -6.743397307218402e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.331767973373644e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.595774723587965e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.232558007468469e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.1993096172300284e-07
sam_encoder.blocks.8.norm1.weight grad: -3.0712967600265983e-06
sam_encoder.blocks.8.norm1.bias grad: 3.8975389315965003e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.9898910725023597e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.7810396002460038e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.1646641218685545e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.499102826433955e-07
sam_encoder.blocks.8.norm2.weight grad: -1.520588170933479e-06
sam_encoder.blocks.8.norm2.bias grad: -1.6198275716305943e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.320188046833209e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.390847602233407e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.951261290552793e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.8548122915926797e-07
sam_encoder.blocks.9.norm1.weight grad: -2.964872237498639e-06
sam_encoder.blocks.9.norm1.bias grad: 1.7942787167157803e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.7962386209546821e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.4048836166912224e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.9163035602787204e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.364713721675798e-07
sam_encoder.blocks.9.norm2.weight grad: -1.6070838455561898e-06
sam_encoder.blocks.9.norm2.bias grad: -2.1013051991758402e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.5845699863348273e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.499061212001834e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.056723916321062e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.842498810830875e-07
sam_encoder.blocks.10.norm1.weight grad: 6.180857212711999e-07
sam_encoder.blocks.10.norm1.bias grad: 1.5607611203449778e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.2427997262420831e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.055771907791495e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.990689022743027e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.840158792125294e-07
sam_encoder.blocks.10.norm2.weight grad: -3.7277673072821926e-06
sam_encoder.blocks.10.norm2.bias grad: -3.926474164472893e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.2099739876703097e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -7.501274694732274e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0585165455267997e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.1484069040743634e-07
sam_encoder.blocks.11.norm1.weight grad: -8.417325148002419e-07
sam_encoder.blocks.11.norm1.bias grad: 3.54562871507369e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.3720505194214638e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.797167770855594e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.035445104160317e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.2522411313730117e-07
sam_encoder.blocks.11.norm2.weight grad: -6.954378477530554e-06
sam_encoder.blocks.11.norm2.bias grad: -1.8301342379345442e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.6830344407026132e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4273628039518371e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.4572352685936494e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.144499492511386e-06
sam_encoder.neck.conv1.trainable_scale grad: -8.532842912245542e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.137925083748996e-06
sam_encoder.neck.conv2.trainable_scale grad: -9.59646058618091e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.07535771955736e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00025826736236922443
mask_decoder.transformer.layers.0.norm1.bias grad: -5.63391949981451e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004671206697821617
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0014623547904193401
mask_decoder.transformer.layers.0.norm3.weight grad: -4.8984169552568346e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.960167517419904e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 8.353665180038661e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.585635335592087e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.632632433436811e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.4217584975995123e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -4.818505112780258e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.276469164527953e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.454496593098156e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.926429053535685e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.983100785058923e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015593110583722591
mask_decoder.transformer.norm_final_attn.weight grad: 7.036323040665593e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0506719263503328e-05
Text_Embedding_Affine.0.weight grad: -1.7775239613548877e-11
Text_Embedding_Affine.0.bias grad: -3.0608526824238425e-10
Text_Embedding_Affine.2.weight grad: 4.150907048638963e-11
Text_Embedding_Affine.2.bias grad: 6.690795999020338e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07357022166252136

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07357022166252136

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07230472564697266

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2015947699546814

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07296180725097656

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07230472564697266

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 59.25066375732422
Max value: 78.47827911376953
Mean value: 65.95335388183594

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999998807907104
Mean value: 0.07235683500766754

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999998807907104
Mean value: 0.07235683500766754

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999998807907104
Mean value: 0.07235683500766754

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18451307713985443

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.697125256061554
Max value: 34.63414001464844
Mean value: 1.0367790460586548

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 59.25066375732422
Max value: 78.47827911376953
Mean value: 65.95335388183594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.23018646240234
Max value: -66.23018646240234
Mean value: -66.23018646240234
sam_encoder.pos_embed grad: 6.6749201721449936e-09
sam_encoder.blocks.0.norm1.weight grad: 2.6933688786812127e-05
sam_encoder.blocks.0.norm1.bias grad: 1.977192732738331e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.2434282881440595e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.988347311358666e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.780992301471997e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.4183540315571008e-06
sam_encoder.blocks.0.norm2.weight grad: 4.040620115119964e-05
sam_encoder.blocks.0.norm2.bias grad: -4.5699693146161735e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.3335360310738906e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.608401806966867e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -8.447775030617777e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.619428803678602e-05
sam_encoder.blocks.1.norm1.weight grad: 7.11066923031467e-06
sam_encoder.blocks.1.norm1.bias grad: 1.8362496120971628e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.6617013898212463e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -6.393752300937194e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.888102815428283e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.113525104301516e-05
sam_encoder.blocks.1.norm2.weight grad: -9.840226994128898e-06
sam_encoder.blocks.1.norm2.bias grad: -3.89757587981876e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.78029131348012e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.316195150342537e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.8174650651635602e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.357114448794164e-06
sam_encoder.blocks.2.norm1.weight grad: -4.172902208665619e-06
sam_encoder.blocks.2.norm1.bias grad: -6.994263230808428e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.88619264413137e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2854120541305747e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.5631112344563e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.651975364642567e-06
sam_encoder.blocks.2.norm2.weight grad: -2.369476351304911e-05
sam_encoder.blocks.2.norm2.bias grad: 5.4069932957645506e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.595191133674234e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.3111022023367696e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.6248714018729515e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.613217126665404e-06
sam_encoder.blocks.3.norm1.weight grad: -2.7057581064582337e-06
sam_encoder.blocks.3.norm1.bias grad: -6.364854016283061e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.791529580776114e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8145606190955732e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.327215826080646e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.656500434270129e-06
sam_encoder.blocks.3.norm2.weight grad: 6.1434511735569686e-06
sam_encoder.blocks.3.norm2.bias grad: 1.5160519069468137e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.3664639381167945e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.506516466382891e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.575390216312371e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.420424380034092e-06
sam_encoder.blocks.4.norm1.weight grad: -3.864101927320007e-06
sam_encoder.blocks.4.norm1.bias grad: -1.2069202057318762e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.182373231742531e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.393899253798736e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.510108738031704e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.603591156002949e-06
sam_encoder.blocks.4.norm2.weight grad: -3.847898915410042e-05
sam_encoder.blocks.4.norm2.bias grad: -2.928709363914095e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.8292033675825223e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.394410881213844e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.77817218072596e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6461891593498876e-06
sam_encoder.blocks.5.norm1.weight grad: -2.2498284124594647e-06
sam_encoder.blocks.5.norm1.bias grad: -2.3888162104412913e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.619979568407871e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.957922545960173e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.75116610484838e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.602951512808431e-08
sam_encoder.blocks.5.norm2.weight grad: -1.1661456483125221e-05
sam_encoder.blocks.5.norm2.bias grad: -2.3540806068922393e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.106704965233803e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.621176463435404e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1688497326977085e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.262414907112543e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7697848306852393e-06
sam_encoder.blocks.6.norm1.bias grad: -5.326894097379409e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.4382185327121988e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.9710273591044825e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -9.848564559433726e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.0870162441278808e-06
sam_encoder.blocks.6.norm2.weight grad: -3.7104723560332786e-06
sam_encoder.blocks.6.norm2.bias grad: -8.635949484414596e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.889067440672079e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.225518983323127e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.0749461075174622e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.6610017610219074e-06
sam_encoder.blocks.7.norm1.weight grad: -3.5884518183593173e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0527564882067963e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.986498541053152e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.4970873962738551e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.4839504274277715e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.967342306372302e-07
sam_encoder.blocks.7.norm2.weight grad: -4.578843800118193e-06
sam_encoder.blocks.7.norm2.bias grad: 7.707362783548888e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.880252840346657e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.1357546959043248e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.349070756390574e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.0749793583927385e-07
sam_encoder.blocks.8.norm1.weight grad: 7.1332306106342e-06
sam_encoder.blocks.8.norm1.bias grad: 4.154144335188903e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.518747457244899e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.6762759262055624e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.315034180355724e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.7504592051409418e-06
sam_encoder.blocks.8.norm2.weight grad: -8.445020284852944e-06
sam_encoder.blocks.8.norm2.bias grad: -3.5852094697474968e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.970870451070368e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.101774488342926e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.474708142268355e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.3877338384845643e-07
sam_encoder.blocks.9.norm1.weight grad: -5.2416698963497765e-06
sam_encoder.blocks.9.norm1.bias grad: -1.3179005691199563e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.519460617302684e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.375169060542248e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0028388714999892e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0687881513149478e-06
sam_encoder.blocks.9.norm2.weight grad: -8.874625564203598e-06
sam_encoder.blocks.9.norm2.bias grad: -2.651354179761256e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.67575329518877e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.081786184746306e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.6164331851960014e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.0415379253790888e-07
sam_encoder.blocks.10.norm1.weight grad: 2.686417417407938e-07
sam_encoder.blocks.10.norm1.bias grad: -1.7124311852967367e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.958817261373042e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.777390547720643e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.695203182971454e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2190888583063497e-06
sam_encoder.blocks.10.norm2.weight grad: -1.3080560165690258e-05
sam_encoder.blocks.10.norm2.bias grad: -2.9248453756736126e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.958913895185106e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.228695044934284e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.9535534647729946e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.3573117030318826e-06
sam_encoder.blocks.11.norm1.weight grad: -1.3071133253106382e-05
sam_encoder.blocks.11.norm1.bias grad: 9.745411944095395e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.5374034774140455e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.20030755019252e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.384829103784796e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2329084597695328e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3188435332267545e-05
sam_encoder.blocks.11.norm2.bias grad: -5.213850727159297e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.7018685361545067e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.4473005143809132e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.03415799105278e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.131312666937447e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.082296876120381e-06
sam_encoder.neck.conv1.trainable_shift grad: -2.466508340148721e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.449408829212189e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.1203100914135575e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019675045041367412
mask_decoder.transformer.layers.0.norm1.bias grad: 2.282868081238121e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.000150516745634377
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006442615995183587
mask_decoder.transformer.layers.0.norm3.weight grad: -2.026355650741607e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.376941746566445e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.109880243660882e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0965988622047007e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 7.360966264968738e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.944272172404453e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00026156118838116527
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001544887782074511
mask_decoder.transformer.layers.1.norm3.weight grad: 9.337488882010803e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.948957838583738e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00011348256521159783
mask_decoder.transformer.layers.1.norm4.bias grad: -7.223963621072471e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.6075568055384792e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.9140152289764956e-05
Text_Embedding_Affine.0.weight grad: 2.973448961010594e-12
Text_Embedding_Affine.0.bias grad: 1.6452503248665096e-10
Text_Embedding_Affine.2.weight grad: 8.405116880272345e-11
Text_Embedding_Affine.2.bias grad: -2.237771695945412e-06
Epoch 9 finished with average loss: -63.4474
Epoch 10/39
----------
Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.9]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-59.9]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-63.3]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-63.3]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-63.8]Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-63.8]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1967107102213974e-38
Max value: 1.0
Mean value: 0.07671062648296356

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1967107102213974e-38
Max value: 1.0
Mean value: 0.07671062648296356

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07969999313354492

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1739664375782013

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.075958251953125

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07969999313354492

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.7980842590332
Max value: 84.37677001953125
Mean value: 59.86748504638672

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1967107102213974e-38
Max value: 1.0
Mean value: 0.07671062648296356

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1967107102213974e-38
Max value: 1.0
Mean value: 0.07671062648296356

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1967107102213974e-38
Max value: 1.0
Mean value: 0.07671062648296356

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1739664375782013

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.7980842590332
Max value: 84.37677001953125
Mean value: 59.86748504638672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.86793899536133
Max value: -59.86793899536133
Mean value: -59.86793899536133
sam_encoder.pos_embed grad: 6.215697956335475e-10
sam_encoder.blocks.0.norm1.weight grad: -5.0625989388208836e-05
sam_encoder.blocks.0.norm1.bias grad: -2.316481368325185e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.951758794253692e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.0058938566289726e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.2754109017550945e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.5470149012107868e-06
sam_encoder.blocks.0.norm2.weight grad: -1.6881591363926418e-05
sam_encoder.blocks.0.norm2.bias grad: 2.086714630422648e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.2837825781607535e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.6127636374440044e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.387572734136484e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.3665796814166242e-06
sam_encoder.blocks.1.norm1.weight grad: -6.201656105986331e-06
sam_encoder.blocks.1.norm1.bias grad: -4.6252316678874195e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.7481104350736132e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.469190563824668e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.3096354223307571e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1612613661782234e-06
sam_encoder.blocks.1.norm2.weight grad: -9.51984020503005e-06
sam_encoder.blocks.1.norm2.bias grad: -1.8885961026171572e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.1425419163279003e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.667932149819535e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.528472684090957e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.222078354767291e-07
sam_encoder.blocks.2.norm1.weight grad: 4.65166613139445e-06
sam_encoder.blocks.2.norm1.bias grad: -6.549777936015744e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.9519305826397613e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.857517397904303e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.3869545202614972e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.6800404409877956e-06
sam_encoder.blocks.2.norm2.weight grad: 8.321174391312525e-06
sam_encoder.blocks.2.norm2.bias grad: 4.407471351441927e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.517333531519398e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.4963346757213003e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.3236624403798487e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 9.26618213270558e-07
sam_encoder.blocks.3.norm1.weight grad: 9.846822649706155e-06
sam_encoder.blocks.3.norm1.bias grad: 2.6123998395632952e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 8.136436917993706e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.055371161688527e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.087899585807463e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1984969887635089e-06
sam_encoder.blocks.3.norm2.weight grad: 2.8441916128940647e-06
sam_encoder.blocks.3.norm2.bias grad: 2.0626309833460255e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.993209247710183e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.9313937375263777e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.454978923400631e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5727998459169612e-07
sam_encoder.blocks.4.norm1.weight grad: -1.1856553101097234e-05
sam_encoder.blocks.4.norm1.bias grad: -5.178298579266993e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.286696134338854e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4739498510607518e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.6463250176457223e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.1089077815995552e-06
sam_encoder.blocks.4.norm2.weight grad: 1.268077721761074e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3897558801545529e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.762901987007353e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.191706244047964e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.2493530852661934e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.812682967283763e-06
sam_encoder.blocks.5.norm1.weight grad: 4.4362886910676025e-06
sam_encoder.blocks.5.norm1.bias grad: 3.91054436477134e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.6271623028151225e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.049863835258293e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.353094825797598e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.983050985174486e-07
sam_encoder.blocks.5.norm2.weight grad: 1.1648163308564108e-05
sam_encoder.blocks.5.norm2.bias grad: -4.653807081922423e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.470494554378092e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.1967441625747597e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.421642193439766e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.8619139154907316e-06
sam_encoder.blocks.6.norm1.weight grad: -7.77858258516062e-06
sam_encoder.blocks.6.norm1.bias grad: 6.395974196493626e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.071264579077251e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.2029876163287554e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.425685579510173e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1465558600320946e-06
sam_encoder.blocks.6.norm2.weight grad: -7.01299086358631e-06
sam_encoder.blocks.6.norm2.bias grad: -4.414192062540678e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.52927940589143e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.826555601131986e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.6141309439917677e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.450405519193737e-07
sam_encoder.blocks.7.norm1.weight grad: -1.1410812561507555e-07
sam_encoder.blocks.7.norm1.bias grad: 1.0902529083978152e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.6771735051056567e-08
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.706012125486268e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4686074791825376e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.116148945991881e-06
sam_encoder.blocks.7.norm2.weight grad: -5.2370960474945605e-06
sam_encoder.blocks.7.norm2.bias grad: -1.6898873127502156e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.132847374828998e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7203872175741708e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.580312698479247e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.049380493142962e-07
sam_encoder.blocks.8.norm1.weight grad: 2.8304334591666702e-06
sam_encoder.blocks.8.norm1.bias grad: 4.797033170689247e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.9917215468012728e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.595417059746978e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.879081411170773e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.565089165633253e-07
sam_encoder.blocks.8.norm2.weight grad: 2.914399146902724e-06
sam_encoder.blocks.8.norm2.bias grad: -6.773980203433894e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.450402123737149e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.0627779829519568e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.5356653168273624e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.427952156518586e-06
sam_encoder.blocks.9.norm1.weight grad: 3.844938873953652e-06
sam_encoder.blocks.9.norm1.bias grad: -2.6289154675396276e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.2499610824743286e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.1733914934429777e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.829952331419918e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.79715537141601e-07
sam_encoder.blocks.9.norm2.weight grad: 1.0522210232011275e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2998733609492774e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.077769671402166e-08
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.156785552022484e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.488874031314481e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.0874253436886647e-07
sam_encoder.blocks.10.norm1.weight grad: -6.301663120211742e-07
sam_encoder.blocks.10.norm1.bias grad: -3.9129167817009147e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.2831593443916063e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.258909823169233e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.311102988045604e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.857283440491301e-07
sam_encoder.blocks.10.norm2.weight grad: 6.89257649355568e-06
sam_encoder.blocks.10.norm2.bias grad: 1.790149326552637e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.2036010730298585e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.3175383628549753e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.360656238437514e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.114929256753385e-07
sam_encoder.blocks.11.norm1.weight grad: 4.084346073796041e-06
sam_encoder.blocks.11.norm1.bias grad: 2.067489731416572e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.7385947848633805e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.033269872001256e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.684285789200658e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.624781351798447e-08
sam_encoder.blocks.11.norm2.weight grad: 8.713574061403051e-06
sam_encoder.blocks.11.norm2.bias grad: -2.413356469332939e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.6341671147965826e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.066255092358915e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.4749413114477647e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.7679647044133162e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.4691140677314252e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.2628435797523707e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.348318619420752e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.102420305367559e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00027110002702102065
mask_decoder.transformer.layers.0.norm1.bias grad: 8.27762414701283e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0020726227667182684
mask_decoder.transformer.layers.0.norm2.bias grad: -0.002108990680426359
mask_decoder.transformer.layers.0.norm3.weight grad: 2.7765425329562277e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -9.065843187272549e-07
mask_decoder.transformer.layers.0.norm4.weight grad: -3.2426811230834574e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.387028871453367e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.368708464928204e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.314600457495544e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 9.143850911641493e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.0547078747767955e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.402108632144518e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 4.335774519859115e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 1.4283394193626009e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 8.286532101919875e-05
mask_decoder.transformer.norm_final_attn.weight grad: -1.4922989066690207e-07
mask_decoder.transformer.norm_final_attn.bias grad: -2.262157750010374e-07
Text_Embedding_Affine.0.weight grad: 1.940908198050373e-11
Text_Embedding_Affine.0.bias grad: 6.665079599343926e-10
Text_Embedding_Affine.2.weight grad: -1.2865677967432987e-10
Text_Embedding_Affine.2.bias grad: -8.61432054080069e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08057955652475357

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08057955652475357

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0893716812133789

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17819653451442719

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07950067520141602

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0893716812133789

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.94648742675781
Max value: 78.61091613769531
Mean value: 66.5990982055664

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07950291782617569

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07950291782617569

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07950291782617569

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17276440560817719

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7836103439331055
Max value: 4.489697456359863
Mean value: 1.0070778131484985

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.94648742675781
Max value: 78.61091613769531
Mean value: 66.5990982055664

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.8116683959961
Max value: -66.8116683959961
Mean value: -66.8116683959961
sam_encoder.pos_embed grad: -3.6504577138884997e-10
sam_encoder.blocks.0.norm1.weight grad: -3.0730295748071512e-06
sam_encoder.blocks.0.norm1.bias grad: 1.8311558960704133e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.025904106834787e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.430076276345062e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.709004770120373e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.075986564406776e-07
sam_encoder.blocks.0.norm2.weight grad: 3.477302016108297e-05
sam_encoder.blocks.0.norm2.bias grad: 8.36269373394316e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0574962061582482e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.937302946927957e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.028792323471862e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.991187102452386e-06
sam_encoder.blocks.1.norm1.weight grad: 9.317844160250388e-06
sam_encoder.blocks.1.norm1.bias grad: -1.930359758262057e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.1242552773182979e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.88761326475651e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.8870001617397065e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.4977783280301082e-07
sam_encoder.blocks.1.norm2.weight grad: 6.58331509839627e-06
sam_encoder.blocks.1.norm2.bias grad: -1.0577635976005695e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.87524425554875e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.4291390111084183e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.4711392800090834e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.962211738122278e-07
sam_encoder.blocks.2.norm1.weight grad: 5.838388460688293e-06
sam_encoder.blocks.2.norm1.bias grad: -3.5580677604230004e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.7733129829575773e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.492972607295087e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7940210454980843e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.56422059819306e-07
sam_encoder.blocks.2.norm2.weight grad: -1.2884243005828466e-05
sam_encoder.blocks.2.norm2.bias grad: 6.825380296504591e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.779344741720706e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.9085631467751227e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.2349585176707478e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.588775474687282e-07
sam_encoder.blocks.3.norm1.weight grad: -7.855103831388988e-06
sam_encoder.blocks.3.norm1.bias grad: -4.884298505203333e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.294946964160772e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5892541682660521e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.1185782113898313e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.892894480690302e-07
sam_encoder.blocks.3.norm2.weight grad: 3.738864961633226e-06
sam_encoder.blocks.3.norm2.bias grad: 4.797581823368091e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.4534672269946896e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.8202672436018474e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.463980308675673e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.995980932813836e-07
sam_encoder.blocks.4.norm1.weight grad: -2.4143769223883282e-06
sam_encoder.blocks.4.norm1.bias grad: 2.079121259157546e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.8909358914243057e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.9324583888646885e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.58865417335619e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.289581051532878e-07
sam_encoder.blocks.4.norm2.weight grad: -1.323524338658899e-05
sam_encoder.blocks.4.norm2.bias grad: -3.4540398701210506e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.129998604999855e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.747279268078273e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.2455363673780084e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.698077067492704e-07
sam_encoder.blocks.5.norm1.weight grad: -6.502380529127549e-06
sam_encoder.blocks.5.norm1.bias grad: 3.898217528330861e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.270435510989046e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.0317769465473248e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.812108719917887e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.7827885535079986e-07
sam_encoder.blocks.5.norm2.weight grad: -7.640092007932253e-06
sam_encoder.blocks.5.norm2.bias grad: -5.989986675558612e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.248257144150557e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.0952569482469698e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.6952826576452935e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.028302431739576e-07
sam_encoder.blocks.6.norm1.weight grad: -2.3589905140397605e-07
sam_encoder.blocks.6.norm1.bias grad: 2.438028786855284e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.01420424573007e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.049031415182981e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.8387100314830604e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.8311578148532135e-07
sam_encoder.blocks.6.norm2.weight grad: 8.390448869022293e-08
sam_encoder.blocks.6.norm2.bias grad: -3.7977528677402006e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.3999417660670588e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.310755568643799e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.3315512837361894e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.2939619864482665e-07
sam_encoder.blocks.7.norm1.weight grad: -1.431926079931145e-06
sam_encoder.blocks.7.norm1.bias grad: 7.745530865577166e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.7413587727332924e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.312446187284877e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.6637480371173297e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.607513220544206e-07
sam_encoder.blocks.7.norm2.weight grad: 3.367920726304874e-06
sam_encoder.blocks.7.norm2.bias grad: -4.0546191826251743e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.8175631996418815e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.1386457572371e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.585746182783623e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.819240176511812e-08
sam_encoder.blocks.8.norm1.weight grad: -4.268947122909594e-06
sam_encoder.blocks.8.norm1.bias grad: 1.1282461400696775e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.296940005588112e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.420146759301133e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -9.155110092251562e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.731198011611923e-07
sam_encoder.blocks.8.norm2.weight grad: -4.97353425998881e-07
sam_encoder.blocks.8.norm2.bias grad: -1.1267734407738317e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.5997588320715295e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.213017407688312e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.600757167987467e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.7019189019483747e-07
sam_encoder.blocks.9.norm1.weight grad: -2.1124933482497e-06
sam_encoder.blocks.9.norm1.bias grad: -3.214671551177162e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.8450895140631474e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.1907379021968154e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.1566454456187785e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5244793303281767e-06
sam_encoder.blocks.9.norm2.weight grad: -6.078192882341682e-07
sam_encoder.blocks.9.norm2.bias grad: -1.7723405107972212e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.631192496162839e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.105977945480845e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.775961883751734e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.3427392054363736e-07
sam_encoder.blocks.10.norm1.weight grad: 7.599286391268834e-07
sam_encoder.blocks.10.norm1.bias grad: -3.537010968557297e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0173141617997317e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.4085228978474333e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.991674013079319e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.589747047451965e-07
sam_encoder.blocks.10.norm2.weight grad: -4.250717211107258e-06
sam_encoder.blocks.10.norm2.bias grad: -2.1683495106117334e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.070477406363352e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.193432581203524e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.740338575473288e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.96071856762137e-07
sam_encoder.blocks.11.norm1.weight grad: -8.832557796267793e-08
sam_encoder.blocks.11.norm1.bias grad: -6.800667051720666e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.23730637319386e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.594121148533304e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.6208623416532646e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.034992630546185e-07
sam_encoder.blocks.11.norm2.weight grad: -3.7379274999693735e-06
sam_encoder.blocks.11.norm2.bias grad: -1.229332156071905e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.2124709175841417e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.245659728345345e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7301471189057338e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.308229553222191e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.248362064477988e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.094248000299558e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.432133083464578e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.737477916525677e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00023665998014621437
mask_decoder.transformer.layers.0.norm1.bias grad: -4.138091753702611e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004392161965370178
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0012674720492213964
mask_decoder.transformer.layers.0.norm3.weight grad: -6.576927989954129e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.6978083294816315e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.40228861104697e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3045528248767368e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.236504901200533e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.204295565723442e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 1.6211639376706444e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.141815199749544e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.145914135733619e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.676335472846404e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.3583976397057995e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014479245874099433
mask_decoder.transformer.norm_final_attn.weight grad: 5.5100304052757565e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.791005140868947e-06
Text_Embedding_Affine.0.weight grad: -1.991952609803338e-11
Text_Embedding_Affine.0.bias grad: -6.174232791700263e-10
Text_Embedding_Affine.2.weight grad: 1.9240127546726882e-10
Text_Embedding_Affine.2.bias grad: 5.958039764664136e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07786364108324051

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07786364108324051

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07968807220458984

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19617322087287903

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07832622528076172

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07968807220458984

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.140167236328125
Max value: 76.80428314208984
Mean value: 64.51539611816406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999997615814209
Mean value: 0.07699191570281982

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999997615814209
Mean value: 0.07699191570281982

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999997615814209
Mean value: 0.07699191570281982

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18431702256202698

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.777194619178772
Max value: 8.082334518432617
Mean value: 1.018547534942627

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.140167236328125
Max value: 76.80428314208984
Mean value: 64.51539611816406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.82039642333984
Max value: -64.82039642333984
Mean value: -64.82039642333984
sam_encoder.pos_embed grad: -5.7539568665276875e-09
sam_encoder.blocks.0.norm1.weight grad: -5.7409877626923844e-05
sam_encoder.blocks.0.norm1.bias grad: 6.143847713246942e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.422727089258842e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.21153083354875e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.51725258649094e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.8127985842729686e-06
sam_encoder.blocks.0.norm2.weight grad: 1.776965473254677e-05
sam_encoder.blocks.0.norm2.bias grad: 3.9883652789285406e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2097356375306845e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.638545985675592e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.214202246861532e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.570474852196639e-06
sam_encoder.blocks.1.norm1.weight grad: 1.6090075405372772e-07
sam_encoder.blocks.1.norm1.bias grad: 6.837643013568595e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.4579740056651644e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.2303007679292932e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.7915336886508157e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.612038868704985e-07
sam_encoder.blocks.1.norm2.weight grad: 1.9672821508720517e-05
sam_encoder.blocks.1.norm2.bias grad: -8.068658644333482e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.814585281565087e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.0005072656203993e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.75571630684135e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6050321391958278e-06
sam_encoder.blocks.2.norm1.weight grad: -3.6700384953292087e-06
sam_encoder.blocks.2.norm1.bias grad: -1.397417463522288e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.323756911617238e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8632224509929074e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.274899765732698e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.680948222812731e-06
sam_encoder.blocks.2.norm2.weight grad: -9.787730959942564e-06
sam_encoder.blocks.2.norm2.bias grad: -7.466510396625381e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.6034062911057845e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.49653305420361e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.781144187087193e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5549071008535975e-07
sam_encoder.blocks.3.norm1.weight grad: -8.446742867818102e-06
sam_encoder.blocks.3.norm1.bias grad: -2.697728405109956e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.201481260679429e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.527854346430104e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.569609354301065e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.7799949293694226e-06
sam_encoder.blocks.3.norm2.weight grad: 8.63376226334367e-06
sam_encoder.blocks.3.norm2.bias grad: 6.884585673105903e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.989798410155345e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.9935005184379406e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.9349504226702265e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.188200589145708e-07
sam_encoder.blocks.4.norm1.weight grad: 1.277073079108959e-05
sam_encoder.blocks.4.norm1.bias grad: 6.245339136512484e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.947461770323571e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.299239541680436e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.492924745136406e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.4969580156030133e-06
sam_encoder.blocks.4.norm2.weight grad: -3.093269333476201e-05
sam_encoder.blocks.4.norm2.bias grad: -2.5358522179885767e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.180082447011955e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.359105777344666e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.155590633241445e-08
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1044868390163174e-06
sam_encoder.blocks.5.norm1.weight grad: 1.3719522030442022e-05
sam_encoder.blocks.5.norm1.bias grad: 1.3076499953967868e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.931551747082267e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.416404746938497e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.146662831772119e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.1814222489192616e-06
sam_encoder.blocks.5.norm2.weight grad: -1.6696034435881302e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0830680366780143e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.337766874115914e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.268602768002893e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.011149823985761e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.5251532659021905e-06
sam_encoder.blocks.6.norm1.weight grad: 3.636829205788672e-06
sam_encoder.blocks.6.norm1.bias grad: 3.501688070173259e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.8746827663562726e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.635465948396813e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.76786022620945e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.1493891349800833e-07
sam_encoder.blocks.6.norm2.weight grad: 2.4050902993622003e-06
sam_encoder.blocks.6.norm2.bias grad: -1.7676615016171127e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.707247628881305e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.1146378255944e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.698674729297636e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1379415809642524e-07
sam_encoder.blocks.7.norm1.weight grad: 3.6719873151014326e-06
sam_encoder.blocks.7.norm1.bias grad: 3.302613549749367e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.663658162622596e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.653876893215056e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.106940658246458e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.3431298359355424e-06
sam_encoder.blocks.7.norm2.weight grad: 1.4131940133665921e-06
sam_encoder.blocks.7.norm2.bias grad: -1.942735707416432e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.8746235355138197e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.048680869393138e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.30393607125734e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.997383247333346e-07
sam_encoder.blocks.8.norm1.weight grad: 5.75618014408974e-06
sam_encoder.blocks.8.norm1.bias grad: -3.007785380759742e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.6502043510845397e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.807796009728918e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.3861302906880155e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 6.997715900070034e-07
sam_encoder.blocks.8.norm2.weight grad: -2.467263584549073e-07
sam_encoder.blocks.8.norm2.bias grad: -1.583022367412923e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.9548143604406505e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.842498810830875e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.756352503434755e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2527679018603521e-06
sam_encoder.blocks.9.norm1.weight grad: 1.347458919553901e-06
sam_encoder.blocks.9.norm1.bias grad: 2.3120421133171476e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.59907619945443e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.260818731287145e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.0321158444858156e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.348214027530048e-06
sam_encoder.blocks.9.norm2.weight grad: 2.604721885290928e-06
sam_encoder.blocks.9.norm2.bias grad: -1.627437882234517e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.442173126837588e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.0995316870321403e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.107520574805676e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.1903732684004353e-06
sam_encoder.blocks.10.norm1.weight grad: 4.277816969988635e-06
sam_encoder.blocks.10.norm1.bias grad: 3.179579266543442e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.988636879308615e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0933413250313606e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.4655291806775494e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.7886798054387327e-07
sam_encoder.blocks.10.norm2.weight grad: 3.03557817460387e-06
sam_encoder.blocks.10.norm2.bias grad: -2.744417315625469e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.3924194465507753e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2125212833780097e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.96956726389908e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.0735387213098875e-07
sam_encoder.blocks.11.norm1.weight grad: 3.2662941521266475e-05
sam_encoder.blocks.11.norm1.bias grad: 1.442679149477044e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.6419499994954094e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.878108998378593e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.9690107819769764e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.192342319380259e-07
sam_encoder.blocks.11.norm2.weight grad: -2.949932877527317e-06
sam_encoder.blocks.11.norm2.bias grad: 8.641638373774185e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.433681291018729e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.4729580395141966e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.7223763936490286e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2228449577378342e-06
sam_encoder.neck.conv1.trainable_scale grad: -1.8799255485646427e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.847671905532479e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.071248546708375e-07
sam_encoder.neck.conv2.trainable_shift grad: 0.00011610410729190335
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001908371050376445
mask_decoder.transformer.layers.0.norm1.bias grad: -6.061876774765551e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00538148358464241
mask_decoder.transformer.layers.0.norm2.bias grad: 0.000515309686306864
mask_decoder.transformer.layers.0.norm3.weight grad: -5.8135738072451204e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.286986222723499e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00012609385885298252
mask_decoder.transformer.layers.0.norm4.bias grad: -8.633909601485357e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -7.104136784619186e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 8.50139076646883e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0002523604198358953
mask_decoder.transformer.layers.1.norm2.bias grad: -9.418803529115394e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.305609298986383e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -2.0195317119942047e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.633382948464714e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00020543954451568425
mask_decoder.transformer.norm_final_attn.weight grad: 9.026725820149295e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.6453303032903932e-05
Text_Embedding_Affine.0.weight grad: -3.9412004909644693e-11
Text_Embedding_Affine.0.bias grad: -1.4322815156120328e-09
Text_Embedding_Affine.2.weight grad: 2.997181322572651e-11
Text_Embedding_Affine.2.bias grad: 6.049990770407021e-05
Epoch 10 finished with average loss: -63.8333
Epoch 11/39
----------
Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.7]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-57.7]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-60.8]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-60.8]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-61.2]Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.26it/s, loss=-61.2]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999984502792358
Mean value: 0.08938150852918625

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999984502792358
Mean value: 0.08938150852918625

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08187150955200195

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1494010090827942

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08666753768920898

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08187150955200195

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.59724426269531
Max value: 70.19802856445312
Mean value: 57.70116424560547

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999984502792358
Mean value: 0.08938150852918625

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999984502792358
Mean value: 0.08938150852918625

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 0.9999984502792358
Mean value: 0.08938150852918625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1494010090827942

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.59724426269531
Max value: 70.19802856445312
Mean value: 57.70116424560547

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.70195388793945
Max value: -57.70195388793945
Mean value: -57.70195388793945
sam_encoder.pos_embed grad: 1.9501358305973326e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00011143251322209835
sam_encoder.blocks.0.norm1.bias grad: 2.8420395210559946e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.447560503554996e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.001193924021209e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.7258930711250287e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.110387857916066e-07
sam_encoder.blocks.0.norm2.weight grad: -5.016598151996732e-06
sam_encoder.blocks.0.norm2.bias grad: -3.368076795595698e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.185826815548353e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.383391443407163e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8742914107860997e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.4518099305860233e-05
sam_encoder.blocks.1.norm1.weight grad: 1.567895378684625e-05
sam_encoder.blocks.1.norm1.bias grad: -7.271151389431907e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.4678915931654046e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.0676269489049446e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.5545449362834916e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.2886928238440305e-06
sam_encoder.blocks.1.norm2.weight grad: -9.362315722682979e-06
sam_encoder.blocks.1.norm2.bias grad: -3.954554813390132e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.220666702778544e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.9774233805947006e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.619720352318836e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.63626770144765e-07
sam_encoder.blocks.2.norm1.weight grad: -1.8401124179945327e-05
sam_encoder.blocks.2.norm1.bias grad: -2.0398987544467673e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.064334805458202e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.703276535015902e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.2229687601793557e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 4.110393092560116e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0966871741402429e-05
sam_encoder.blocks.2.norm2.bias grad: 1.3910306734032929e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.442360482746153e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.7436624350229977e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.444996637990698e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.160765562730376e-07
sam_encoder.blocks.3.norm1.weight grad: -4.733347850560676e-06
sam_encoder.blocks.3.norm1.bias grad: 3.617102265707217e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.646766344900243e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.781914190563839e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.403921932156663e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.57890359434532e-06
sam_encoder.blocks.3.norm2.weight grad: 3.440300133661367e-06
sam_encoder.blocks.3.norm2.bias grad: 7.426981028402224e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.5791456462466158e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.202725787967211e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.2689862160186749e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8909015579993138e-06
sam_encoder.blocks.4.norm1.weight grad: -5.260512261884287e-05
sam_encoder.blocks.4.norm1.bias grad: -1.6987287381198257e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.9201415600255132e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.96146048035007e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.915589544107206e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.492073458095547e-06
sam_encoder.blocks.4.norm2.weight grad: 1.1717420420609415e-05
sam_encoder.blocks.4.norm2.bias grad: 2.0104977011214942e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.549978141061729e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.181217607561848e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.2776189325668383e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.845995368261356e-07
sam_encoder.blocks.5.norm1.weight grad: -2.0797622710233554e-05
sam_encoder.blocks.5.norm1.bias grad: -1.3403963521341211e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.3577604477177374e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.1741789194275043e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.957230208266992e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.33954255640856e-06
sam_encoder.blocks.5.norm2.weight grad: 8.894209599930036e-07
sam_encoder.blocks.5.norm2.bias grad: -1.2638369639716984e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.3001554179936647e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.2045578614561236e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3895360098103993e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.7014788227243116e-06
sam_encoder.blocks.6.norm1.weight grad: -5.895466529182158e-06
sam_encoder.blocks.6.norm1.bias grad: 2.5171900688292226e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.1548378299485194e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.2172994274806115e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.0597362865592004e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.9914838250988396e-07
sam_encoder.blocks.6.norm2.weight grad: -1.1405934856156819e-05
sam_encoder.blocks.6.norm2.bias grad: -5.651956598740071e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.159790351986885e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.1383368625247385e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.991908554075053e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.098402546835132e-06
sam_encoder.blocks.7.norm1.weight grad: -1.7229885997949168e-06
sam_encoder.blocks.7.norm1.bias grad: 2.483192929503275e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.55165412252245e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.1303598057565978e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.150584113129298e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0546893918217393e-06
sam_encoder.blocks.7.norm2.weight grad: -8.055118087213486e-06
sam_encoder.blocks.7.norm2.bias grad: -3.368092507116671e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.211140084313229e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.0166524993546773e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.657765420139185e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.509318263349996e-07
sam_encoder.blocks.8.norm1.weight grad: -5.452889126900118e-07
sam_encoder.blocks.8.norm1.bias grad: -3.428949639783241e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.2220735900191357e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.8640974392146745e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.4274377235778957e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.846841536869761e-06
sam_encoder.blocks.8.norm2.weight grad: -5.3693756854045205e-06
sam_encoder.blocks.8.norm2.bias grad: -4.50326342615881e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.930171705083922e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.306022558215773e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.5451936380704865e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.4151992406018508e-08
sam_encoder.blocks.9.norm1.weight grad: -1.917135932671954e-06
sam_encoder.blocks.9.norm1.bias grad: 6.29726969236799e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.130359229748137e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.256221932839253e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.0407760530360974e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.184769058061647e-07
sam_encoder.blocks.9.norm2.weight grad: -5.289183718559798e-06
sam_encoder.blocks.9.norm2.bias grad: -3.6580190680979285e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.936272150895093e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.647938117661397e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1681994465106982e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.2136821914718894e-07
sam_encoder.blocks.10.norm1.weight grad: -2.7603698526945664e-06
sam_encoder.blocks.10.norm1.bias grad: -2.0656023025367176e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.5314209324278636e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1597326192713808e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.5716935877208016e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.5749278494186e-07
sam_encoder.blocks.10.norm2.weight grad: -1.664054593675246e-06
sam_encoder.blocks.10.norm2.bias grad: -1.7188301626447355e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.5448672406346304e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.7731218779081246e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3402366221271222e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.338052109342243e-07
sam_encoder.blocks.11.norm1.weight grad: -1.258492011402268e-05
sam_encoder.blocks.11.norm1.bias grad: 3.7363679439295083e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.369431164581329e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2980424344277708e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.5182844208538882e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.478471745031129e-06
sam_encoder.blocks.11.norm2.weight grad: 5.309271273290506e-06
sam_encoder.blocks.11.norm2.bias grad: -5.672232418874046e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.276128498124308e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.0678628465684596e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.09854975361668e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0172313977818703e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.4724610082339495e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.6618369045318104e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0991501514799893e-06
sam_encoder.neck.conv2.trainable_shift grad: -4.476878166315146e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00016315517132170498
mask_decoder.transformer.layers.0.norm1.bias grad: 8.269737008959055e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003129225689917803
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0016917295288294554
mask_decoder.transformer.layers.0.norm3.weight grad: -8.672571129864082e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.901303716702387e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.8352241467218846e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.4865029192587826e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.1145497157704085e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.514474545023404e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001279846765100956
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001264528837054968
mask_decoder.transformer.layers.1.norm3.weight grad: -5.141449946677312e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 9.530049283057451e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 8.503075514454395e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00014209907385520637
mask_decoder.transformer.norm_final_attn.weight grad: 5.685050382453483e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.769281521381345e-06
Text_Embedding_Affine.0.weight grad: 3.9301596699292674e-11
Text_Embedding_Affine.0.bias grad: 1.273773753140972e-09
Text_Embedding_Affine.2.weight grad: -9.941670403579295e-11
Text_Embedding_Affine.2.bias grad: -6.531090184580535e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0432547261036342e-33
Max value: 1.0
Mean value: 0.07628826797008514

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0432547261036342e-33
Max value: 1.0
Mean value: 0.07628826797008514

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08847808837890625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16149623692035675

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07506084442138672

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08847808837890625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.72994613647461
Max value: 78.75833129882812
Mean value: 63.763343811035156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.429372817041431e-32
Max value: 0.9999998807907104
Mean value: 0.07539844512939453

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.429372817041431e-32
Max value: 0.9999998807907104
Mean value: 0.07539844512939453

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.429372817041431e-32
Max value: 0.9999998807907104
Mean value: 0.07539844512939453

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15681536495685577

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8877584338188171
Max value: 3.7398767471313477
Mean value: 1.0061062574386597

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.72994613647461
Max value: 78.75833129882812
Mean value: 63.763343811035156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.94013214111328
Max value: -63.94013214111328
Mean value: -63.94013214111328
sam_encoder.pos_embed grad: 3.1275271261677062e-09
sam_encoder.blocks.0.norm1.weight grad: -3.444105459493585e-05
sam_encoder.blocks.0.norm1.bias grad: 1.4383082088897936e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.917742894074763e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.7429198351237574e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.481084609622485e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.0538859644148033e-06
sam_encoder.blocks.0.norm2.weight grad: 3.623479278758168e-05
sam_encoder.blocks.0.norm2.bias grad: -3.329503670101985e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.160039225098444e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.2882895791553892e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.72667295273277e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.12132192448189e-06
sam_encoder.blocks.1.norm1.weight grad: 1.9366088963579386e-05
sam_encoder.blocks.1.norm1.bias grad: 5.76666570850648e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.8194902875548e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.2032078795273264e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.381297825593265e-08
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.3359450551652117e-07
sam_encoder.blocks.1.norm2.weight grad: -2.807694500006619e-06
sam_encoder.blocks.1.norm2.bias grad: 1.6323195950462832e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.060831194394268e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.8765662161968066e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.229787348071113e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.800295177024964e-07
sam_encoder.blocks.2.norm1.weight grad: 1.0251918865833431e-05
sam_encoder.blocks.2.norm1.bias grad: 2.258009772049263e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.3787239266966935e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.2815167710632522e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.007123273666366e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 9.065731205737393e-07
sam_encoder.blocks.2.norm2.weight grad: -1.243784572579898e-05
sam_encoder.blocks.2.norm2.bias grad: -5.913863788009621e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.562939572380856e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.6351560791226802e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.079014615854248e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.239575226463785e-06
sam_encoder.blocks.3.norm1.weight grad: -1.605744728294667e-05
sam_encoder.blocks.3.norm1.bias grad: 2.9606812859128695e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.323444828623906e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1215715858270414e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.68806058759219e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.585369202279253e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1492284102132544e-06
sam_encoder.blocks.3.norm2.bias grad: 1.4495119103230536e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.1146942092163954e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.201358827529475e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.739307435855153e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.6192675502679776e-06
sam_encoder.blocks.4.norm1.weight grad: -3.209706392226508e-06
sam_encoder.blocks.4.norm1.bias grad: 7.225485660455888e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.705884980969131e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1611315358095453e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0196579296462005e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.1559976630669553e-06
sam_encoder.blocks.4.norm2.weight grad: -1.469900871597929e-05
sam_encoder.blocks.4.norm2.bias grad: -2.391862608419615e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1362315490259789e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.036741302115843e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.381857252155896e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.2424801500164904e-06
sam_encoder.blocks.5.norm1.weight grad: 1.4742607845619204e-06
sam_encoder.blocks.5.norm1.bias grad: 3.432081484788796e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.702681508206297e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.0120745628228178e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.4411014035431435e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.8505746766095399e-06
sam_encoder.blocks.5.norm2.weight grad: -1.37847628138843e-05
sam_encoder.blocks.5.norm2.bias grad: -2.23149163502967e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.926354894356336e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.764320126720122e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.508995511467219e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.63251364332973e-07
sam_encoder.blocks.6.norm1.weight grad: 8.100915920294938e-07
sam_encoder.blocks.6.norm1.bias grad: 2.444950951030478e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.4705690318805864e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.511058193656936e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.338186621069326e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.00819802798469e-08
sam_encoder.blocks.6.norm2.weight grad: 4.135259132453939e-06
sam_encoder.blocks.6.norm2.bias grad: 2.18857485378976e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.1321524147642776e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.2230816537339706e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.722078751408844e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0773937901831232e-06
sam_encoder.blocks.7.norm1.weight grad: -4.980292374057171e-07
sam_encoder.blocks.7.norm1.bias grad: 2.425244474579813e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.0572244352479174e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.420175052175182e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.263341395471798e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.1428240870591253e-06
sam_encoder.blocks.7.norm2.weight grad: -2.043585027422523e-06
sam_encoder.blocks.7.norm2.bias grad: 5.133568947712774e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.468709681124892e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.02709850075189e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1691556665027747e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.478323110239216e-08
sam_encoder.blocks.8.norm1.weight grad: -5.225531367614167e-07
sam_encoder.blocks.8.norm1.bias grad: 9.341799227513548e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.5982250261004083e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.756479701332864e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.926325338303286e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.6105707345559495e-06
sam_encoder.blocks.8.norm2.weight grad: -3.971095793531276e-06
sam_encoder.blocks.8.norm2.bias grad: -2.106681677105371e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.0006095837743487e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.103966380673228e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8271045973961009e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.148025365997455e-07
sam_encoder.blocks.9.norm1.weight grad: -3.3234198326681508e-06
sam_encoder.blocks.9.norm1.bias grad: -3.620708355356328e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.2055983208701946e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.080873571230768e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.0719607480023114e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4587915302399779e-06
sam_encoder.blocks.9.norm2.weight grad: -4.356737463240279e-06
sam_encoder.blocks.9.norm2.bias grad: -2.787477569654584e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.7813708836911246e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.5107370927580632e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.829999167872302e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.812061433767667e-07
sam_encoder.blocks.10.norm1.weight grad: 1.3105197922413936e-06
sam_encoder.blocks.10.norm1.bias grad: -1.3078117717668647e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1336113630022737e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.804971981935523e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5155783330556005e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.865357242233586e-07
sam_encoder.blocks.10.norm2.weight grad: -9.188112017000094e-06
sam_encoder.blocks.10.norm2.bias grad: -4.79861728308606e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.6439814721234143e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.01036470773397e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.191517523897346e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.694883947806375e-07
sam_encoder.blocks.11.norm1.weight grad: -1.7774934804037912e-06
sam_encoder.blocks.11.norm1.bias grad: -1.7311019462340482e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.79895766905247e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.118319444998633e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.0360397340036798e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.0885629459808115e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3139191651134752e-05
sam_encoder.blocks.11.norm2.bias grad: -1.6647866232233355e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.488659785944037e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.833678536262596e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.873245421142201e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.3982935342937708e-06
sam_encoder.neck.conv1.trainable_scale grad: -2.568394847912714e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.1555609641363844e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.895379556226544e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.547570617636666e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00029645758331753314
mask_decoder.transformer.layers.0.norm1.bias grad: -5.345631507225335e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003441587323322892
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0016709842020645738
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00010385604400653392
mask_decoder.transformer.layers.0.norm3.bias grad: 2.6408833946334198e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.037934508640319e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.7162877813680097e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.4478085833834484e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.8625436243601143e-08
mask_decoder.transformer.layers.1.norm2.weight grad: 6.8910580012016e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.103537452872843e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.595149221131578e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.826139072771184e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.8412443751003593e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00012552989937830716
mask_decoder.transformer.norm_final_attn.weight grad: 7.021584224276012e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0624759852362331e-05
Text_Embedding_Affine.0.weight grad: -3.879660481764802e-11
Text_Embedding_Affine.0.bias grad: -1.2529547399608987e-09
Text_Embedding_Affine.2.weight grad: 1.8886482655577908e-10
Text_Embedding_Affine.2.bias grad: 7.870390254538506e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.038781821150088e-23
Max value: 0.9999988079071045
Mean value: 0.07555896043777466

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.038781821150088e-23
Max value: 0.9999988079071045
Mean value: 0.07555896043777466

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07860183715820312

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14142736792564392

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07444190979003906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07860183715820312

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 44.754024505615234
Max value: 84.70587921142578
Mean value: 61.659156799316406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.0175346162853164e-21
Max value: 0.9999958276748657
Mean value: 0.07610242068767548

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.0175346162853164e-21
Max value: 0.9999958276748657
Mean value: 0.07610242068767548

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.0175346162853164e-21
Max value: 0.9999958276748657
Mean value: 0.07610242068767548

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13397662341594696

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8188599944114685
Max value: 10.840141296386719
Mean value: 1.011472463607788

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 44.754024505615234
Max value: 84.70587921142578
Mean value: 61.659156799316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.819149017333984
Max value: -61.819149017333984
Mean value: -61.819149017333984
sam_encoder.pos_embed grad: -6.646514449926144e-09
sam_encoder.blocks.0.norm1.weight grad: -1.756737617597537e-07
sam_encoder.blocks.0.norm1.bias grad: 1.5973746485542506e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.104040272068232e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.596127365478878e-09
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2939646865106624e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.966107429841941e-07
sam_encoder.blocks.0.norm2.weight grad: 1.7470780221628956e-05
sam_encoder.blocks.0.norm2.bias grad: 5.071869964012876e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.454397185327252e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.878128260723315e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.729718132992275e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.6662421482324135e-06
sam_encoder.blocks.1.norm1.weight grad: 1.0358377039665356e-05
sam_encoder.blocks.1.norm1.bias grad: 4.594689016812481e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.61809099256061e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.042592430167133e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.1687877758959075e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1380605968724922e-07
sam_encoder.blocks.1.norm2.weight grad: 2.2746133254258893e-05
sam_encoder.blocks.1.norm2.bias grad: 1.652896344239707e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.447308128874283e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5697950175308506e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.612208380829543e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.3709246761427494e-06
sam_encoder.blocks.2.norm1.weight grad: -1.4299661188488244e-06
sam_encoder.blocks.2.norm1.bias grad: -1.0377398211858235e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0569059440967976e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.382689434758504e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.135921921668341e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.951742084813304e-06
sam_encoder.blocks.2.norm2.weight grad: -9.877448974293657e-06
sam_encoder.blocks.2.norm2.bias grad: -1.3191104244469898e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.813629053998739e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.8010780372133013e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1266004094068194e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.494528871466173e-06
sam_encoder.blocks.3.norm1.weight grad: 1.5838315448490903e-05
sam_encoder.blocks.3.norm1.bias grad: -7.1288841354544275e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.2994067876425106e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.3163164415746e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.744231667544227e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.9783450966315286e-07
sam_encoder.blocks.3.norm2.weight grad: 3.0880710255587474e-06
sam_encoder.blocks.3.norm2.bias grad: 6.380506874847924e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.763209522527177e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.966517740787822e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.6049808588577434e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0351136552344542e-06
sam_encoder.blocks.4.norm1.weight grad: 2.1090880181873217e-05
sam_encoder.blocks.4.norm1.bias grad: -5.122354195918888e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 9.954297638614662e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.522877821320435e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.3266637728956994e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.838469754351536e-06
sam_encoder.blocks.4.norm2.weight grad: -6.0501664847834036e-05
sam_encoder.blocks.4.norm2.bias grad: -3.4976270399056375e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.9575970731675625e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.4714801181980874e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.444874892011285e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.2947577892628033e-06
sam_encoder.blocks.5.norm1.weight grad: 1.6455200579912344e-07
sam_encoder.blocks.5.norm1.bias grad: -2.0469669834710658e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.942687266724533e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.902004780480638e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.072491712278861e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.7789377579902066e-06
sam_encoder.blocks.5.norm2.weight grad: -2.993679663632065e-05
sam_encoder.blocks.5.norm2.bias grad: -1.5209314369712956e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.3946251783636399e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.107826837047469e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.01537932298379e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.028138841429609e-07
sam_encoder.blocks.6.norm1.weight grad: 5.136094841873273e-06
sam_encoder.blocks.6.norm1.bias grad: -1.1724262094503501e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.281652192934416e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.1503394691535505e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.5833694508037297e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.7140316685981816e-06
sam_encoder.blocks.6.norm2.weight grad: -1.9409984815865755e-05
sam_encoder.blocks.6.norm2.bias grad: -4.222638381179422e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3832721379003488e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.96862992097158e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.726468318949628e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.733433792760479e-07
sam_encoder.blocks.7.norm1.weight grad: 8.7387870735256e-06
sam_encoder.blocks.7.norm1.bias grad: 1.9519992733307845e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.156001068622572e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.0173438315396197e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2432245739546488e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.7177434276381973e-06
sam_encoder.blocks.7.norm2.weight grad: -2.2213625925360247e-06
sam_encoder.blocks.7.norm2.bias grad: 1.61509746021693e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.207251542240556e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.2528205388662172e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1061930536016007e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.833670340711251e-07
sam_encoder.blocks.8.norm1.weight grad: 5.8571313275024295e-06
sam_encoder.blocks.8.norm1.bias grad: -4.7362068471556995e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.225906766601838e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.272409662078644e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.6171487661486026e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.6126160719286418e-06
sam_encoder.blocks.8.norm2.weight grad: -1.1587049812078476e-05
sam_encoder.blocks.8.norm2.bias grad: -4.3092040868941694e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.566184078517836e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.405961474025389e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.729066975211026e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.9823853563138982e-06
sam_encoder.blocks.9.norm1.weight grad: -5.166642154108558e-07
sam_encoder.blocks.9.norm1.bias grad: 5.5086580630359094e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.1773677013407e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.561771664972184e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.930059667643036e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.8036917026620358e-07
sam_encoder.blocks.9.norm2.weight grad: -4.669885129260365e-06
sam_encoder.blocks.9.norm2.bias grad: -3.2047882996266708e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.9999897631350905e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.184356162615586e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.887389751384035e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.2237835512205493e-07
sam_encoder.blocks.10.norm1.weight grad: 5.831166163261514e-06
sam_encoder.blocks.10.norm1.bias grad: 1.4046889873498003e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.7854416657646652e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0646974715200486e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.3512689040217083e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.7332853127009e-07
sam_encoder.blocks.10.norm2.weight grad: -1.52602001435298e-06
sam_encoder.blocks.10.norm2.bias grad: -3.73551461052557e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.0200257466740368e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.7372522026780644e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.124961479756166e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.528886398067698e-07
sam_encoder.blocks.11.norm1.weight grad: 1.672513099038042e-05
sam_encoder.blocks.11.norm1.bias grad: 1.4454453776124865e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -9.772346487579853e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.100598971490399e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.3838874767534435e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.246804567424988e-07
sam_encoder.blocks.11.norm2.weight grad: 1.8380358142167097e-06
sam_encoder.blocks.11.norm2.bias grad: -9.261651712222374e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.3997371247096453e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.3363142531707126e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.862055977942873e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.226493951544398e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.294337021652609e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.304365625604987e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.115945451601874e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.5528550395392813e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010296455002389848
mask_decoder.transformer.layers.0.norm1.bias grad: -5.58616011403501e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004819350317120552
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005232987459748983
mask_decoder.transformer.layers.0.norm3.weight grad: -3.383991133887321e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.0685149946948513e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001791016838978976
mask_decoder.transformer.layers.0.norm4.bias grad: -1.2303207768127322e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -6.603993369935779e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.727716597903054e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00029534444911405444
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00011070130858570337
mask_decoder.transformer.layers.1.norm3.weight grad: 1.8710692529566586e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.5054461730178446e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.501317405607551e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002713325375225395
mask_decoder.transformer.norm_final_attn.weight grad: 8.764425729168579e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.440375101286918e-05
Text_Embedding_Affine.0.weight grad: 5.112094081383134e-11
Text_Embedding_Affine.0.bias grad: 1.5229983940656666e-09
Text_Embedding_Affine.2.weight grad: -4.193034461308365e-11
Text_Embedding_Affine.2.bias grad: 5.6231216149171814e-05
Epoch 11 finished with average loss: -61.1537
Epoch 12/39
----------
Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62.1]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.19it/s, loss=-62.1]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.19it/s, loss=-63.9]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.77it/s, loss=-63.9]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.77it/s, loss=-62.5]Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.42it/s, loss=-62.5]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.8997175520095525e-30
Max value: 0.9999988079071045
Mean value: 0.09007635712623596

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8997175520095525e-30
Max value: 0.9999988079071045
Mean value: 0.09007635712623596

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08694982528686523

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15109534561634064

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08149433135986328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08694982528686523

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.74174118041992
Max value: 81.646728515625
Mean value: 62.07356643676758

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.8997175520095525e-30
Max value: 0.9999988079071045
Mean value: 0.09007635712623596

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8997175520095525e-30
Max value: 0.9999988079071045
Mean value: 0.09007635712623596

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8997175520095525e-30
Max value: 0.9999988079071045
Mean value: 0.09007635712623596

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15109534561634064

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.74174118041992
Max value: 81.646728515625
Mean value: 62.07356643676758

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.07456970214844
Max value: -62.07456970214844
Mean value: -62.07456970214844
sam_encoder.pos_embed grad: 4.0114520039047363e-10
sam_encoder.blocks.0.norm1.weight grad: -6.8684103098348714e-06
sam_encoder.blocks.0.norm1.bias grad: -1.9964638340752572e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.1020895221445244e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.315451853173727e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.2080413297517225e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.442959481020807e-07
sam_encoder.blocks.0.norm2.weight grad: 1.4883054063830059e-05
sam_encoder.blocks.0.norm2.bias grad: -3.473908145679161e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.896685929154046e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.707613465550821e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.991377737605944e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.2404842638934497e-06
sam_encoder.blocks.1.norm1.weight grad: -8.562677976442501e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4296207154984586e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.2787788667483255e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.122898306173738e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.691697540692985e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.705727405962534e-06
sam_encoder.blocks.1.norm2.weight grad: -1.3409665371000301e-05
sam_encoder.blocks.1.norm2.bias grad: -1.1916656148969196e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.1337832549761515e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.76912215010816e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3950841093901545e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.714625892025651e-07
sam_encoder.blocks.2.norm1.weight grad: -7.259342055476736e-06
sam_encoder.blocks.2.norm1.bias grad: 8.479626558255404e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.305320079671219e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3922328889748314e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.4283613129227888e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.665167120445403e-07
sam_encoder.blocks.2.norm2.weight grad: 5.674610292771831e-06
sam_encoder.blocks.2.norm2.bias grad: -4.6161071054484637e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.2729846048387117e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.131908675233717e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0336225386708975e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.2930605609872146e-06
sam_encoder.blocks.3.norm1.weight grad: 6.933723852853291e-06
sam_encoder.blocks.3.norm1.bias grad: 5.818578756588977e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.0026415111497045e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.366352979763178e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2044595223414944e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8805319541570498e-06
sam_encoder.blocks.3.norm2.weight grad: -1.688783595454879e-05
sam_encoder.blocks.3.norm2.bias grad: -1.1639507647487335e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.230528414453147e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.316967417456908e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.9782120186137035e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1626158311628387e-06
sam_encoder.blocks.4.norm1.weight grad: 4.30033469456248e-06
sam_encoder.blocks.4.norm1.bias grad: -6.54823725199094e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.821871021296829e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.998544348680298e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.772997261985438e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.3612665245309472e-07
sam_encoder.blocks.4.norm2.weight grad: 1.0880611398533802e-06
sam_encoder.blocks.4.norm2.bias grad: -4.0614067984279245e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.931353186383603e-08
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 7.663344945285644e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.9349822650838178e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.609656111322693e-07
sam_encoder.blocks.5.norm1.weight grad: 1.031081956170965e-05
sam_encoder.blocks.5.norm1.bias grad: -7.5392890721559525e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.975862106628483e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.3663061458355514e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.336766654792882e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.1961963082285365e-06
sam_encoder.blocks.5.norm2.weight grad: 8.939375220506918e-06
sam_encoder.blocks.5.norm2.bias grad: -1.116134171752492e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.904395271092653e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.4800050394114805e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.8530307645269204e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.267919626319781e-06
sam_encoder.blocks.6.norm1.weight grad: -5.754260200774297e-06
sam_encoder.blocks.6.norm1.bias grad: -3.710439159476664e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.757121026457753e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0595506410027156e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.299922928410524e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.221786582547793e-07
sam_encoder.blocks.6.norm2.weight grad: -1.7622758150537265e-06
sam_encoder.blocks.6.norm2.bias grad: 2.3165966922533698e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.8940519314346602e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.7080592442653142e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6119900010380661e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1939392834392493e-06
sam_encoder.blocks.7.norm1.weight grad: 6.441445634663978e-07
sam_encoder.blocks.7.norm1.bias grad: -1.5578577858832432e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.475667871403857e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.1868553068979963e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.2747632354148664e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.760919515931164e-07
sam_encoder.blocks.7.norm2.weight grad: -2.9298648769326974e-06
sam_encoder.blocks.7.norm2.bias grad: 5.013821464672219e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.829032266366994e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.8648182731340057e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0668865790819382e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.989447125401057e-07
sam_encoder.blocks.8.norm1.weight grad: 7.957492016430479e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0265101764161955e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.239971404895186e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.560783509077737e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.2942534510784753e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.4579875369236106e-06
sam_encoder.blocks.8.norm2.weight grad: -2.976096311613219e-06
sam_encoder.blocks.8.norm2.bias grad: 3.6352068377709656e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.349979917606106e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0563120415317826e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.197789268000633e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.0618218715972034e-07
sam_encoder.blocks.9.norm1.weight grad: 1.340440462627157e-06
sam_encoder.blocks.9.norm1.bias grad: 5.17459682214394e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.537754989542009e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.140257475337421e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.6429610733866866e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.2085779960434593e-07
sam_encoder.blocks.9.norm2.weight grad: -2.2100105070421705e-06
sam_encoder.blocks.9.norm2.bias grad: 1.191139517686679e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.433852154761553e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.4415076066143229e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.1539987926644244e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.3598676079927827e-07
sam_encoder.blocks.10.norm1.weight grad: -7.865709221732686e-07
sam_encoder.blocks.10.norm1.bias grad: 4.383954177455962e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.080888053678791e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.037436269754835e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.405968401348218e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.6920013712915534e-07
sam_encoder.blocks.10.norm2.weight grad: -3.238017370676971e-06
sam_encoder.blocks.10.norm2.bias grad: 1.2394260693326942e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.14532951253932e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.5148323200264713e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.696092214042437e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.008983260448076e-08
sam_encoder.blocks.11.norm1.weight grad: -9.708784091344569e-06
sam_encoder.blocks.11.norm1.bias grad: -2.947414827758621e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.9874401004926767e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.137632564990781e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.922292416471464e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.395559128373861e-07
sam_encoder.blocks.11.norm2.weight grad: -4.99230736750178e-06
sam_encoder.blocks.11.norm2.bias grad: -3.8346979636116885e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.74365334007598e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.1054546575905988e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.0507319530006498e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.154211635272077e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.2066084309481084e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.5591818737448193e-05
sam_encoder.neck.conv2.trainable_scale grad: 8.774804882705212e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.968181095435284e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001749363000271842
mask_decoder.transformer.layers.0.norm1.bias grad: 6.059417501091957e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004678437486290932
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0013409991515800357
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00010815451969392598
mask_decoder.transformer.layers.0.norm3.bias grad: 5.9294732636772096e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010572048631729558
mask_decoder.transformer.layers.0.norm4.bias grad: 1.4820709111518227e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.2057319509040099e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.711488600150915e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00012195783347124234
mask_decoder.transformer.layers.1.norm2.bias grad: 2.296108505106531e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.951189162558876e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.965324190678075e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.373165913624689e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00014802995428908616
mask_decoder.transformer.norm_final_attn.weight grad: 6.424633056667517e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.2214694606882404e-06
Text_Embedding_Affine.0.weight grad: 3.669094542080309e-11
Text_Embedding_Affine.0.bias grad: 6.665561436136613e-10
Text_Embedding_Affine.2.weight grad: 1.1266584887259512e-11
Text_Embedding_Affine.2.bias grad: -6.609428965020925e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.039001950936797e-27
Max value: 1.0
Mean value: 0.07170390337705612

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.039001950936797e-27
Max value: 1.0
Mean value: 0.07170390337705612

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07820987701416016

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12775292992591858

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06993961334228516

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07820987701416016

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.90723419189453
Max value: 90.55561828613281
Mean value: 65.571044921875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.008837143645038e-26
Max value: 1.0
Mean value: 0.07158707082271576

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.008837143645038e-26
Max value: 1.0
Mean value: 0.07158707082271576

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.008837143645038e-26
Max value: 1.0
Mean value: 0.07158707082271576

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1254541575908661

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9208213090896606
Max value: 3.0331594944000244
Mean value: 1.0027669668197632

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.90723419189453
Max value: 90.55561828613281
Mean value: 65.571044921875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.69927215576172
Max value: -65.69927215576172
Mean value: -65.69927215576172
sam_encoder.pos_embed grad: -2.1272712480424616e-09
sam_encoder.blocks.0.norm1.weight grad: -1.1069894753745757e-05
sam_encoder.blocks.0.norm1.bias grad: 1.0693431249819696e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.478627152413537e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.056207896814158e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.747154773416696e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0875876341742696e-06
sam_encoder.blocks.0.norm2.weight grad: 3.74074988940265e-05
sam_encoder.blocks.0.norm2.bias grad: -3.1974391276889946e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 8.626177077530883e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.1389444125597947e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.562081918877084e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.447596317433636e-07
sam_encoder.blocks.1.norm1.weight grad: -6.6482934926170856e-06
sam_encoder.blocks.1.norm1.bias grad: 5.433269961940823e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.899876436567865e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.0487541405600496e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.439694516302552e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.2956900213321205e-06
sam_encoder.blocks.1.norm2.weight grad: 6.937288162589539e-06
sam_encoder.blocks.1.norm2.bias grad: -2.5775329959287774e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.2353865486147697e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.840568811279809e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1364421879989095e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.597151024019695e-06
sam_encoder.blocks.2.norm1.weight grad: 3.6391666071722284e-06
sam_encoder.blocks.2.norm1.bias grad: 1.2881440625278628e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.4170248852660734e-08
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.1309944859003735e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.028601324534975e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.311845375719713e-06
sam_encoder.blocks.2.norm2.weight grad: 3.1274516913981643e-06
sam_encoder.blocks.2.norm2.bias grad: -1.3520523225452052e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.2611940292117652e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.090704568530782e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.081725248601288e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3527917417377466e-06
sam_encoder.blocks.3.norm1.weight grad: 1.2566495115606813e-06
sam_encoder.blocks.3.norm1.bias grad: -1.4721035768161528e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.94829282615683e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.893520089259255e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.2754933272372e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.517647774562647e-06
sam_encoder.blocks.3.norm2.weight grad: 2.793988414850901e-06
sam_encoder.blocks.3.norm2.bias grad: 9.899805263557937e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.805669050256256e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.3839114621514454e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.492187362207915e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.80820915527147e-07
sam_encoder.blocks.4.norm1.weight grad: 1.6822317547848797e-06
sam_encoder.blocks.4.norm1.bias grad: -1.3781525467493339e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 9.504311719865655e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.1652325560571626e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.3697572285309434e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.1871645710925804e-06
sam_encoder.blocks.4.norm2.weight grad: -2.8698399546556175e-05
sam_encoder.blocks.4.norm2.bias grad: -6.626613867410924e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.947775308508426e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.831922862853389e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.111781090112345e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.67411200083734e-07
sam_encoder.blocks.5.norm1.weight grad: -6.651765033893753e-06
sam_encoder.blocks.5.norm1.bias grad: -5.644094017043244e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.839268513023853e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.0567353001533775e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.109372988139512e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.0311762252968038e-06
sam_encoder.blocks.5.norm2.weight grad: -1.994651938730385e-05
sam_encoder.blocks.5.norm2.bias grad: -4.808119228982832e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.006826278171502e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.4411746128171217e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.97300048766192e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.736512432325981e-07
sam_encoder.blocks.6.norm1.weight grad: 1.985442168006557e-06
sam_encoder.blocks.6.norm1.bias grad: 1.951604872374446e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.8409700430765952e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.70718133430637e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.165147846739274e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.7455563390030875e-07
sam_encoder.blocks.6.norm2.weight grad: -3.690260200528428e-06
sam_encoder.blocks.6.norm2.bias grad: -5.56172707888436e-08
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.9678500393638387e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.044207124323293e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.8626896993228e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.625230024477787e-07
sam_encoder.blocks.7.norm1.weight grad: 1.0948951967293397e-07
sam_encoder.blocks.7.norm1.bias grad: 8.627180250186939e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.291802835927228e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.385211471140792e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.7831952681699477e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2206642168166582e-06
sam_encoder.blocks.7.norm2.weight grad: -1.436160573575762e-06
sam_encoder.blocks.7.norm2.bias grad: 1.9220019567001145e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.3557955753640272e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.296632015320938e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.504996134826797e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.519505291180394e-07
sam_encoder.blocks.8.norm1.weight grad: 7.745913421786099e-07
sam_encoder.blocks.8.norm1.bias grad: 5.556835276365746e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.820549186959397e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.046076800383162e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.873407988270628e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.134067002174561e-07
sam_encoder.blocks.8.norm2.weight grad: -3.2924793913480244e-07
sam_encoder.blocks.8.norm2.bias grad: -1.347513261862332e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.041575832365197e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.6136423631205616e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.896004490248743e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.947738764191854e-08
sam_encoder.blocks.9.norm1.weight grad: -3.2142811505764257e-06
sam_encoder.blocks.9.norm1.bias grad: 5.768259825345012e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.0767257612751564e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.29686155662057e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.74286661453516e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2935537370140082e-06
sam_encoder.blocks.9.norm2.weight grad: 1.3010319435124984e-06
sam_encoder.blocks.9.norm2.bias grad: -9.477091111875779e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.3913454495195765e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.48430932667543e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.0937658316834131e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.1466189537022728e-07
sam_encoder.blocks.10.norm1.weight grad: 1.015109205582121e-06
sam_encoder.blocks.10.norm1.bias grad: 2.0685040169610147e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0174383078265237e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.458941470555146e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.810425361436501e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.749712954639108e-07
sam_encoder.blocks.10.norm2.weight grad: -9.211700557898439e-07
sam_encoder.blocks.10.norm2.bias grad: -1.911064828163944e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.5668699404614017e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.415488774611731e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.8896943743129668e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.396800198312121e-07
sam_encoder.blocks.11.norm1.weight grad: 4.6454960056507844e-07
sam_encoder.blocks.11.norm1.bias grad: 3.371009142938419e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.915269533332321e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.016121124550409e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.175096796008802e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.121397185168462e-07
sam_encoder.blocks.11.norm2.weight grad: -4.8336805775761604e-06
sam_encoder.blocks.11.norm2.bias grad: -3.693549615491065e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.473415166714403e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.0402599173175986e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.136366563514457e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.334217240080761e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.671486284583807e-08
sam_encoder.neck.conv1.trainable_shift grad: -6.789642611693125e-06
sam_encoder.neck.conv2.trainable_scale grad: -3.046061465283856e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.8487397028366104e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -9.362453420180827e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -9.90206899587065e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0048565734177827835
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00019973618327639997
mask_decoder.transformer.layers.0.norm3.weight grad: -2.0461142412386835e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.5253546482417732e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.2761555707547814e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.646157089562621e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.531635153805837e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.795500222418923e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.818295075092465e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001210129339597188
mask_decoder.transformer.layers.1.norm3.weight grad: 5.8410158089827746e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.693812611047179e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.9399068807833828e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013319432036951184
mask_decoder.transformer.norm_final_attn.weight grad: 5.829490874020848e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.417813892767299e-06
Text_Embedding_Affine.0.weight grad: 2.589771799788032e-11
Text_Embedding_Affine.0.bias grad: 5.81758308193514e-10
Text_Embedding_Affine.2.weight grad: 6.919702311147802e-11
Text_Embedding_Affine.2.bias grad: 3.4350227906543296e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.4007899611380829e-37
Max value: 0.9999868869781494
Mean value: 0.08271512389183044

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.4007899611380829e-37
Max value: 0.9999868869781494
Mean value: 0.08271512389183044

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08840751647949219

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16335800290107727

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07694053649902344

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08840751647949219

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.583839416503906
Max value: 62.7683219909668
Mean value: 59.547828674316406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.63731797959854e-33
Max value: 0.9999572038650513
Mean value: 0.08503206819295883

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.63731797959854e-33
Max value: 0.9999572038650513
Mean value: 0.08503206819295883

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.63731797959854e-33
Max value: 0.9999572038650513
Mean value: 0.08503206819295883

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1587073802947998

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8721685409545898
Max value: 10.073275566101074
Mean value: 1.0085182189941406

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.583839416503906
Max value: 62.7683219909668
Mean value: 59.547828674316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.59450149536133
Max value: -59.59450149536133
Mean value: -59.59450149536133
sam_encoder.pos_embed grad: -2.513382835189759e-09
sam_encoder.blocks.0.norm1.weight grad: -6.562568887602538e-05
sam_encoder.blocks.0.norm1.bias grad: 1.5047578926896676e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1960346455452964e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.625331513821493e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.9638291632873006e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5327414075727575e-06
sam_encoder.blocks.0.norm2.weight grad: 1.32874702103436e-05
sam_encoder.blocks.0.norm2.bias grad: -6.661930001428118e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.05840557202464e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.9442722987150773e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.155692633707076e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.984781298844609e-06
sam_encoder.blocks.1.norm1.weight grad: 1.0979189937643241e-05
sam_encoder.blocks.1.norm1.bias grad: -3.0500184493575944e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.551197424822021e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.623467935336521e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 7.4311492426204495e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.4682768728089286e-06
sam_encoder.blocks.1.norm2.weight grad: 2.1337929865694605e-05
sam_encoder.blocks.1.norm2.bias grad: 2.3260149646375794e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.820479706628248e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.911794697662117e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.93828144701547e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.470344955123437e-06
sam_encoder.blocks.2.norm1.weight grad: 5.197128302825149e-06
sam_encoder.blocks.2.norm1.bias grad: -3.940785518352641e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.836939635628369e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.154552127351053e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.342419732798589e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.1532059690798633e-06
sam_encoder.blocks.2.norm2.weight grad: -1.133987279899884e-05
sam_encoder.blocks.2.norm2.bias grad: 3.787937203014735e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.893372533842921e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.6822526706382632e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.5363607417384628e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.591362320141343e-06
sam_encoder.blocks.3.norm1.weight grad: -4.788935257238336e-06
sam_encoder.blocks.3.norm1.bias grad: -4.492896550800651e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.635084330104291e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.026245965680573e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.9510463264159625e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.620189990120707e-07
sam_encoder.blocks.3.norm2.weight grad: -4.67219615529757e-06
sam_encoder.blocks.3.norm2.bias grad: -4.826542863156646e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.322979293647222e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.87913381322869e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.0285340269765584e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.151067731887451e-07
sam_encoder.blocks.4.norm1.weight grad: 8.320024790009484e-06
sam_encoder.blocks.4.norm1.bias grad: -9.53476671838871e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.852978241207893e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3529449915949954e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 9.235470201929274e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.4474162526312284e-06
sam_encoder.blocks.4.norm2.weight grad: -2.0332809071987867e-05
sam_encoder.blocks.4.norm2.bias grad: -1.6821104509290308e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3407507140072994e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.736356797569897e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.50626006404309e-08
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.16306589715532e-07
sam_encoder.blocks.5.norm1.weight grad: -1.1511039701872505e-05
sam_encoder.blocks.5.norm1.bias grad: -1.5376666851807386e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.665576281899121e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.550698238541372e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.288931566203246e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.8655268263501057e-07
sam_encoder.blocks.5.norm2.weight grad: -1.0185696737607941e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0400734026916325e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.822599294129759e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9845513179461705e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3418125490716193e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.50770983206894e-07
sam_encoder.blocks.6.norm1.weight grad: -1.3165747532184469e-06
sam_encoder.blocks.6.norm1.bias grad: -1.1627101912381477e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.476007688936079e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.7677941122638003e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.459767239950452e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.133376876325201e-07
sam_encoder.blocks.6.norm2.weight grad: -7.684071533731185e-06
sam_encoder.blocks.6.norm2.bias grad: 6.370404204147917e-09
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.011270332033746e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.6562497623672243e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.0805330197836156e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.567140158926122e-08
sam_encoder.blocks.7.norm1.weight grad: 3.0459550544037484e-06
sam_encoder.blocks.7.norm1.bias grad: -9.417984614401576e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.6426122328994097e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.199945338878024e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.157193747138081e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.2119714887812734e-06
sam_encoder.blocks.7.norm2.weight grad: -7.184692094597267e-07
sam_encoder.blocks.7.norm2.bias grad: 5.751435878664779e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.1644113985530566e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.771256220057694e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.801095532362524e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.389456194076047e-07
sam_encoder.blocks.8.norm1.weight grad: 6.194036814122228e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0943755341941142e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.927054982952541e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.9764429453061894e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.2863464437250514e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.4686862616363214e-06
sam_encoder.blocks.8.norm2.weight grad: -8.545416676497553e-06
sam_encoder.blocks.8.norm2.bias grad: -1.7431741525797406e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.918085662415251e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.4526378840382677e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.5662585560203297e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.6350711575796595e-06
sam_encoder.blocks.9.norm1.weight grad: -1.803480131457036e-06
sam_encoder.blocks.9.norm1.bias grad: 1.7076885683309229e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.822536301522632e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.3402255894543487e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.2438702390891194e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.0425857744376117e-07
sam_encoder.blocks.9.norm2.weight grad: -7.760965672787279e-06
sam_encoder.blocks.9.norm2.bias grad: -3.1973056593415095e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.933952484658221e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.8998590551054804e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.0784941650854307e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.654206228835392e-07
sam_encoder.blocks.10.norm1.weight grad: 3.4458334994269535e-06
sam_encoder.blocks.10.norm1.bias grad: 1.0253233995172195e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0028917333547724e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.600418606059975e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.8807363630912732e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0526912319619441e-06
sam_encoder.blocks.10.norm2.weight grad: -1.2026047443214338e-05
sam_encoder.blocks.10.norm2.bias grad: -6.476435373770073e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.736028702405747e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.5880626708385535e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.9072108443651814e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.562376478948863e-07
sam_encoder.blocks.11.norm1.weight grad: 1.6480328213219764e-06
sam_encoder.blocks.11.norm1.bias grad: 1.2378040992189199e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.8713143365166616e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.3935491551819723e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3103854143992066e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0383887172338291e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3735631910094526e-05
sam_encoder.blocks.11.norm2.bias grad: -3.6475289562076796e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.979326725631836e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.6032030291389674e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.4600896015035687e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.630153633414011e-06
sam_encoder.neck.conv1.trainable_scale grad: -5.551883077714592e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.0973660866729915e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.062406777753495e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.396340202423744e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00025518564507365227
mask_decoder.transformer.layers.0.norm1.bias grad: -6.205278623383492e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0047281114384531975
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0012974825222045183
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00014242928591556847
mask_decoder.transformer.layers.0.norm3.bias grad: -7.076676411088556e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00012860096467193216
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0258671863994095e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.652576586115174e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.688446329557337e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.988714060047641e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -9.216622856911272e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 6.59679644741118e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.7437567041488364e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.118920282460749e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002022515400312841
mask_decoder.transformer.norm_final_attn.weight grad: 9.418416084372438e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.0757748643518426e-05
Text_Embedding_Affine.0.weight grad: 1.5118196625141245e-11
Text_Embedding_Affine.0.bias grad: 6.480545544640393e-10
Text_Embedding_Affine.2.weight grad: -2.3205812271775983e-11
Text_Embedding_Affine.2.bias grad: 8.335624443134293e-05
Epoch 12 finished with average loss: -62.4561
Epoch 13/39
----------
Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, loss=-67]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-67]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-63.5]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-63.5]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-60]  Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-60]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4801981904252674e-33
Max value: 0.9999998807907104
Mean value: 0.10101689398288727

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4801981904252674e-33
Max value: 0.9999998807907104
Mean value: 0.10101689398288727

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09635496139526367

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15467104315757751

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09765386581420898

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09635496139526367

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.68608856201172
Max value: 84.5897216796875
Mean value: 67.00120544433594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4801981904252674e-33
Max value: 0.9999998807907104
Mean value: 0.10101689398288727

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4801981904252674e-33
Max value: 0.9999998807907104
Mean value: 0.10101689398288727

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4801981904252674e-33
Max value: 0.9999998807907104
Mean value: 0.10101689398288727

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15467104315757751

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.68608856201172
Max value: 84.5897216796875
Mean value: 67.00120544433594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.00218963623047
Max value: -67.00218963623047
Mean value: -67.00218963623047
sam_encoder.pos_embed grad: -1.0923812965302204e-09
sam_encoder.blocks.0.norm1.weight grad: -6.594245496671647e-05
sam_encoder.blocks.0.norm1.bias grad: -2.5965618988266215e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.597687161047361e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.8951777747133747e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.6181345320947e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.5438716875214595e-06
sam_encoder.blocks.0.norm2.weight grad: 3.1378505809698254e-05
sam_encoder.blocks.0.norm2.bias grad: 2.7347470677341335e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.418584234779701e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.5076507224875968e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.128971214522608e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0487347026355565e-06
sam_encoder.blocks.1.norm1.weight grad: 4.887015165877528e-07
sam_encoder.blocks.1.norm1.bias grad: 6.66163350615534e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.4529949769203085e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.6055064406828023e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.8823528762368369e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.3642354588228045e-06
sam_encoder.blocks.1.norm2.weight grad: -9.712304745335132e-06
sam_encoder.blocks.1.norm2.bias grad: 2.5727047159307403e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.784450583083526e-08
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.168115879110701e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0983220818161499e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6134085853991564e-06
sam_encoder.blocks.2.norm1.weight grad: 1.6830699678394012e-07
sam_encoder.blocks.2.norm1.bias grad: 2.009728632401675e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.687661892901815e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.800421937849023e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.285124764966895e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.193479533867503e-06
sam_encoder.blocks.2.norm2.weight grad: 7.14938209966931e-07
sam_encoder.blocks.2.norm2.bias grad: 7.2745815486996435e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.6793594517803285e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.98277136323577e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.361158971732948e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.1819262226708815e-06
sam_encoder.blocks.3.norm1.weight grad: 1.2055195838911459e-05
sam_encoder.blocks.3.norm1.bias grad: -5.374553211368038e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.065029573510401e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.5138250546442578e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.00952558265999e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.196992666853475e-07
sam_encoder.blocks.3.norm2.weight grad: -1.2116436664655339e-05
sam_encoder.blocks.3.norm2.bias grad: 1.5508787328144535e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.76976412453223e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.1950812626746483e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.69193082608399e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.089307013709913e-07
sam_encoder.blocks.4.norm1.weight grad: 6.54348150419537e-06
sam_encoder.blocks.4.norm1.bias grad: -1.5966841147019295e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.796141638507834e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.496376840914309e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.8777934656100115e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.795703378273174e-06
sam_encoder.blocks.4.norm2.weight grad: 8.441941645287443e-06
sam_encoder.blocks.4.norm2.bias grad: -5.476154910866171e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.1054764804139268e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.438915084392647e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 8.602891057307716e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.57347829549326e-07
sam_encoder.blocks.5.norm1.weight grad: 1.533885733806528e-05
sam_encoder.blocks.5.norm1.bias grad: -5.127025360707194e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.311395135417115e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.251583959558047e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.58786553281243e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.472028649615822e-06
sam_encoder.blocks.5.norm2.weight grad: -1.0308561968486174e-06
sam_encoder.blocks.5.norm2.bias grad: 3.0604846870119218e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.5272404400311643e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.034774966996338e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.3123888581721985e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.777754216116591e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7340130398224574e-07
sam_encoder.blocks.6.norm1.bias grad: 1.6820130213091034e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.759592115988198e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.9461989470291883e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.8163504478252435e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.1434429982036818e-06
sam_encoder.blocks.6.norm2.weight grad: -7.639218893018551e-06
sam_encoder.blocks.6.norm2.bias grad: -3.0783539841650054e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.651521289313678e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.0302890081657097e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.558783406442672e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.940562116142246e-07
sam_encoder.blocks.7.norm1.weight grad: 2.0177142232569167e-06
sam_encoder.blocks.7.norm1.bias grad: -5.666729521180969e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.0768505894229747e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.6331752539808804e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.8853655774364597e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.0848221942724194e-06
sam_encoder.blocks.7.norm2.weight grad: -1.2990349205210805e-05
sam_encoder.blocks.7.norm2.bias grad: -8.84567612047249e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0315468898625113e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.052890290040523e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.127323341483134e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.5021212220744928e-06
sam_encoder.blocks.8.norm1.weight grad: 5.084017629997106e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0053099686047062e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.408121746266261e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.673406470421469e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.8471163230060483e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.777984597443719e-07
sam_encoder.blocks.8.norm2.weight grad: -1.0279962907588924e-06
sam_encoder.blocks.8.norm2.bias grad: -4.615093018855987e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.122662282199599e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.699721560224134e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.384787421760848e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.3224625945440494e-06
sam_encoder.blocks.9.norm1.weight grad: 3.309638486825861e-06
sam_encoder.blocks.9.norm1.bias grad: -8.801684714399016e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.2734889171260875e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.1846480180442995e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.678461044069991e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.2615896594070364e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4129291230347008e-06
sam_encoder.blocks.9.norm2.bias grad: -4.0755094232736155e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.091072689036082e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.870205750265086e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.035118202707963e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.0110616130987182e-06
sam_encoder.blocks.10.norm1.weight grad: -1.1173142411280423e-07
sam_encoder.blocks.10.norm1.bias grad: 6.577026283594023e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.7489016929393983e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.065299575804147e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.4439556745601294e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.1409684336504142e-07
sam_encoder.blocks.10.norm2.weight grad: 7.075740541040432e-06
sam_encoder.blocks.10.norm2.bias grad: 1.4092775018070824e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.0370113159297034e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.109105025738245e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.8175759325677063e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.09905317913217e-06
sam_encoder.blocks.11.norm1.weight grad: -1.8580391042632982e-05
sam_encoder.blocks.11.norm1.bias grad: -6.010028528180555e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.055839331660536e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.375741238822229e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.6331464886861795e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.6031102606793866e-08
sam_encoder.blocks.11.norm2.weight grad: -1.5743717085570097e-07
sam_encoder.blocks.11.norm2.bias grad: -6.026994924468454e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0924256912403507e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.350959544462967e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.780418415364693e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.473837073717732e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.7707570805214345e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.7782194845494814e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.782398612704128e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.39851316716522e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00029328855453059077
mask_decoder.transformer.layers.0.norm1.bias grad: 1.0390649549663067e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0019438968738541007
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0017711592372506857
mask_decoder.transformer.layers.0.norm3.weight grad: 8.12114158179611e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.3969540304969996e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.142413910012692e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 9.115899047174025e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.0530342478887178e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.018675670318771e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001123119582189247
mask_decoder.transformer.layers.1.norm2.bias grad: 4.0590788557892665e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.809643410728313e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.970448465726804e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -2.928825779235922e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001229365007020533
mask_decoder.transformer.norm_final_attn.weight grad: 1.3694511835637968e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.2090882592019625e-05
Text_Embedding_Affine.0.weight grad: 1.6451497282521377e-12
Text_Embedding_Affine.0.bias grad: 2.354919592661986e-10
Text_Embedding_Affine.2.weight grad: 2.8105379135112685e-10
Text_Embedding_Affine.2.bias grad: -8.982951112557203e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.3989918529003577e-25
Max value: 0.9999845027923584
Mean value: 0.07646240293979645

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.3989918529003577e-25
Max value: 0.9999845027923584
Mean value: 0.07646240293979645

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07568502426147461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1157049909234047

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07127237319946289

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07568502426147461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.27284240722656
Max value: 77.7508544921875
Mean value: 59.88568878173828

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.577058456586658e-24
Max value: 0.999976634979248
Mean value: 0.07709594815969467

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.577058456586658e-24
Max value: 0.999976634979248
Mean value: 0.07709594815969467

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.577058456586658e-24
Max value: 0.999976634979248
Mean value: 0.07709594815969467

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11436453461647034

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9317458868026733
Max value: 2.8122079372406006
Mean value: 1.0016931295394897

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.27284240722656
Max value: 77.7508544921875
Mean value: 59.88568878173828

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.95389175415039
Max value: -59.95389175415039
Mean value: -59.95389175415039
sam_encoder.pos_embed grad: -1.383881342853499e-09
sam_encoder.blocks.0.norm1.weight grad: -9.19533795240568e-06
sam_encoder.blocks.0.norm1.bias grad: -2.9640217690030113e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.215884812059812e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.0577196007943712e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.900657808728283e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.9034940780547913e-06
sam_encoder.blocks.0.norm2.weight grad: 2.593532371975016e-05
sam_encoder.blocks.0.norm2.bias grad: -2.2126267140265554e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.09405918919947e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.5240823308413383e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.3796287577133626e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.145825525687542e-06
sam_encoder.blocks.1.norm1.weight grad: 2.5124227249762043e-05
sam_encoder.blocks.1.norm1.bias grad: 2.072103052341845e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.1455731409078e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.7604164668227895e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.194600923161488e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.049852461525006e-06
sam_encoder.blocks.1.norm2.weight grad: -2.9947755137982313e-06
sam_encoder.blocks.1.norm2.bias grad: -2.551854549892596e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.155292001290945e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.959199936318328e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.5078024262038525e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3767315749646514e-06
sam_encoder.blocks.2.norm1.weight grad: -4.055405952385627e-06
sam_encoder.blocks.2.norm1.bias grad: -4.005373739346396e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.40819621871924e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.738672835926991e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.75017054163618e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.7469817470991984e-06
sam_encoder.blocks.2.norm2.weight grad: -1.5280902516678907e-05
sam_encoder.blocks.2.norm2.bias grad: -3.5899754493584624e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0353745892643929e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.6302953958511353e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.308456017402932e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6363295546616428e-06
sam_encoder.blocks.3.norm1.weight grad: -1.1195883189429878e-06
sam_encoder.blocks.3.norm1.bias grad: 2.1805058167956304e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.130176421313081e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.4530830816947855e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.905677774833748e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.0522593331406824e-06
sam_encoder.blocks.3.norm2.weight grad: 1.8112884845322696e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0179703167523257e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.9051002456981223e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.056307721431949e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.741093324715621e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.4466280024171283e-07
sam_encoder.blocks.4.norm1.weight grad: -2.9641973924299236e-06
sam_encoder.blocks.4.norm1.bias grad: 2.5066235593840247e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.667659375925723e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.359641702147201e-10
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.901991582708433e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.0040747585881036e-06
sam_encoder.blocks.4.norm2.weight grad: -2.3235916160047054e-05
sam_encoder.blocks.4.norm2.bias grad: 2.295612375746714e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5724868717370555e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.379924575914629e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.884548621295835e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.2379744021018269e-06
sam_encoder.blocks.5.norm1.weight grad: -3.7228055589366704e-06
sam_encoder.blocks.5.norm1.bias grad: 9.987282965084887e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.8863987634176738e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.7561594606595463e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.3062672223895788e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.4473764622380259e-06
sam_encoder.blocks.5.norm2.weight grad: -1.6193869669223204e-05
sam_encoder.blocks.5.norm2.bias grad: 1.2237063629072509e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.697929272078909e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.150187694700435e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -7.452240424754564e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.124828703628737e-07
sam_encoder.blocks.6.norm1.weight grad: 1.9881504158547614e-06
sam_encoder.blocks.6.norm1.bias grad: 1.0477214118509437e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.334625949311885e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.645099511118133e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.722072511256556e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.902593435777817e-07
sam_encoder.blocks.6.norm2.weight grad: -7.790679035224457e-08
sam_encoder.blocks.6.norm2.bias grad: 2.047862835752312e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.597427611472085e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.051451583109156e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.1797253779709536e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.8180576211743755e-07
sam_encoder.blocks.7.norm1.weight grad: 5.183809435038711e-07
sam_encoder.blocks.7.norm1.bias grad: 9.79934839051566e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.6028625888538954e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.927428669063374e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.340344604424899e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.913801497721579e-06
sam_encoder.blocks.7.norm2.weight grad: -3.048263295113429e-07
sam_encoder.blocks.7.norm2.bias grad: 2.3309407879423816e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.77790637837461e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.027775836832006e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6838287137943553e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.815077664308774e-07
sam_encoder.blocks.8.norm1.weight grad: -4.295965482015163e-06
sam_encoder.blocks.8.norm1.bias grad: 1.105139290302759e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.130968813522486e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.4068494894891046e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.0632850262481952e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.0639732863637619e-06
sam_encoder.blocks.8.norm2.weight grad: -1.5572098845950677e-06
sam_encoder.blocks.8.norm2.bias grad: -2.0624315766326617e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.669301910733338e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.2802632909370004e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.368466725665712e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.822826996241929e-09
sam_encoder.blocks.9.norm1.weight grad: -1.9805847841780633e-06
sam_encoder.blocks.9.norm1.bias grad: 8.239571229751164e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.7677909909252776e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.164038772269123e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.306158522624173e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.825853339862078e-07
sam_encoder.blocks.9.norm2.weight grad: 8.593463007855462e-07
sam_encoder.blocks.9.norm2.bias grad: -1.9440553842287045e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7452351812607958e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.791056203932385e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.2752441307384288e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.700354452324973e-07
sam_encoder.blocks.10.norm1.weight grad: 3.067309535254026e-06
sam_encoder.blocks.10.norm1.bias grad: 3.579468055292523e-09
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.796549895516364e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.201649623311823e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2656219041673467e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.426006274930842e-07
sam_encoder.blocks.10.norm2.weight grad: -3.430153810768388e-06
sam_encoder.blocks.10.norm2.bias grad: -2.5595106762921205e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.4421972827658465e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.2330017398198834e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.220030071635847e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.012638553125726e-07
sam_encoder.blocks.11.norm1.weight grad: -8.310915291076526e-06
sam_encoder.blocks.11.norm1.bias grad: 4.214496982513083e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.4637378121260554e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.328707857188419e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.5111100399044517e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.0133253403619165e-07
sam_encoder.blocks.11.norm2.weight grad: -6.20544142293511e-06
sam_encoder.blocks.11.norm2.bias grad: -2.752080717982608e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.799509944561578e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3978063861941337e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4149402431939961e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.33520380435948e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.382600309327245e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.401448445103597e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.181729309493676e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.4505973013001494e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00025382800959050655
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6908743418753147e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0037084545474499464
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0014469220768660307
mask_decoder.transformer.layers.0.norm3.weight grad: -8.31626239232719e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.3859178074635565e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.998506483389065e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.222862455411814e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.9456223021261394e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.8622395145939663e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 8.651451935293153e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 8.568563498556614e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.692509173764847e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.006924766348675e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.2197378055134322e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011296879529254511
mask_decoder.transformer.norm_final_attn.weight grad: 7.078279850247782e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.20510831545107e-06
Text_Embedding_Affine.0.weight grad: -5.039810582752047e-11
Text_Embedding_Affine.0.bias grad: -1.2466077059514191e-09
Text_Embedding_Affine.2.weight grad: 2.0538590272956014e-10
Text_Embedding_Affine.2.bias grad: 7.281502621481195e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.8890561876889908e-16
Max value: 0.9998962879180908
Mean value: 0.06943777203559875

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.8890561876889908e-16
Max value: 0.9998962879180908
Mean value: 0.06943777203559875

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0746297836303711

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12068779766559601

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06345558166503906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0746297836303711

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 40.9625244140625
Max value: 65.53848266601562
Mean value: 52.948753356933594

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.0653975152883607e-15
Max value: 0.9995365142822266
Mean value: 0.06982124596834183

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.0653975152883607e-15
Max value: 0.9995365142822266
Mean value: 0.06982124596834183

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.0653975152883607e-15
Max value: 0.9995365142822266
Mean value: 0.06982124596834183

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11815926432609558

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8234674334526062
Max value: 11.637794494628906
Mean value: 1.0053170919418335

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 40.9625244140625
Max value: 65.53848266601562
Mean value: 52.948753356933594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.966461181640625
Max value: -52.966461181640625
Mean value: -52.966461181640625
sam_encoder.pos_embed grad: 4.90040941159009e-09
sam_encoder.blocks.0.norm1.weight grad: 0.0001027459220495075
sam_encoder.blocks.0.norm1.bias grad: -3.1646784918848425e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.987143696169369e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.0476505849510431e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.66716392111266e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.538411538604123e-06
sam_encoder.blocks.0.norm2.weight grad: -2.1961509446555283e-06
sam_encoder.blocks.0.norm2.bias grad: -7.632047345396131e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9902197891497053e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.1250343706924468e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.1282028935966082e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.5551358956145123e-05
sam_encoder.blocks.1.norm1.weight grad: 1.3626605323224794e-05
sam_encoder.blocks.1.norm1.bias grad: 1.0595157618809026e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.137280358118005e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.817256467504194e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.433207196707372e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.146358944330132e-06
sam_encoder.blocks.1.norm2.weight grad: -3.1879666494205594e-05
sam_encoder.blocks.1.norm2.bias grad: 8.266076179097581e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.9137274648528546e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.608158294809982e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.355939614062663e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.8307164282305166e-06
sam_encoder.blocks.2.norm1.weight grad: -5.267082997306716e-06
sam_encoder.blocks.2.norm1.bias grad: -1.9962506030424265e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.08199286236777e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.2898174140427727e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.548974397446727e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.546934294718085e-06
sam_encoder.blocks.2.norm2.weight grad: -1.737745833452209e-06
sam_encoder.blocks.2.norm2.bias grad: 2.2918782178749098e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.943520939879818e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.008311063647852e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.352915569441393e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.5513140826660674e-06
sam_encoder.blocks.3.norm1.weight grad: -1.3728266594625893e-06
sam_encoder.blocks.3.norm1.bias grad: -1.1993931821052684e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.113327122468036e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.818046257540118e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.674403953686124e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.505538865691051e-06
sam_encoder.blocks.3.norm2.weight grad: -1.8045855540549383e-05
sam_encoder.blocks.3.norm2.bias grad: 1.454298308090074e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1114934750366956e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.596321903387434e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.587385895618354e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.3362085244116315e-07
sam_encoder.blocks.4.norm1.weight grad: 3.198284275640617e-06
sam_encoder.blocks.4.norm1.bias grad: -1.1182048183400184e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.599777187446307e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.524550270914915e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.474688133384916e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.119290340691805e-06
sam_encoder.blocks.4.norm2.weight grad: -7.785816706018522e-06
sam_encoder.blocks.4.norm2.bias grad: 2.2961283320910297e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.841612386982888e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.68957274127024e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.172470875753788e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.8397616941001615e-06
sam_encoder.blocks.5.norm1.weight grad: -7.09051892044954e-06
sam_encoder.blocks.5.norm1.bias grad: -8.883662303560413e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.2882054508954752e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.1279182672296884e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.672316557232989e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.6754872212441114e-07
sam_encoder.blocks.5.norm2.weight grad: -8.093793439911678e-06
sam_encoder.blocks.5.norm2.bias grad: 1.0074718375108205e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0091589501826093e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.63110337073158e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.3752485301665729e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.3421330891105754e-07
sam_encoder.blocks.6.norm1.weight grad: 3.678991333799786e-06
sam_encoder.blocks.6.norm1.bias grad: -4.940312464896124e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.8786320146755315e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4713755263073836e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.7414485000699642e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.2028161791022285e-06
sam_encoder.blocks.6.norm2.weight grad: 5.134349407853733e-07
sam_encoder.blocks.6.norm2.bias grad: 1.044887540047057e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0703377029130934e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.408062466154661e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.375899046252016e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.7880105360745802e-06
sam_encoder.blocks.7.norm1.weight grad: -7.27941733202897e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3016424418310635e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.570671990222763e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.7758247849997133e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.867237622529501e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1371893151590484e-06
sam_encoder.blocks.7.norm2.weight grad: -8.201672244467773e-06
sam_encoder.blocks.7.norm2.bias grad: 2.256644620501902e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.572326234774664e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.6735873436555266e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.997244549391326e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.7456133605264768e-07
sam_encoder.blocks.8.norm1.weight grad: 5.547772161662579e-06
sam_encoder.blocks.8.norm1.bias grad: 1.7354957435600227e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.6404879867623094e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.744788500625873e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.360598045925144e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3290355127537623e-07
sam_encoder.blocks.8.norm2.weight grad: -2.7533787942957133e-06
sam_encoder.blocks.8.norm2.bias grad: -2.3770675738887803e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.210639417578932e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.6088480353791965e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.552738808641152e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.461024908167019e-06
sam_encoder.blocks.9.norm1.weight grad: -5.546374268305954e-06
sam_encoder.blocks.9.norm1.bias grad: 5.5756952832553e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.005962520954199e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.3587417672388256e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7617256844459916e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0909297998296097e-07
sam_encoder.blocks.9.norm2.weight grad: -4.825623364013154e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6146324810506485e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.74690557186841e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.128369371552253e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.9737785805773456e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.4317772638605675e-06
sam_encoder.blocks.10.norm1.weight grad: -3.3453288779128343e-06
sam_encoder.blocks.10.norm1.bias grad: -3.024876150448108e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.5296749324988923e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.95842050693318e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.025298600638052e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.704858606099151e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0278384252160322e-05
sam_encoder.blocks.10.norm2.bias grad: -5.393994797486812e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.867812539392617e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.554254246613709e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.670956160334754e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.263508858708519e-07
sam_encoder.blocks.11.norm1.weight grad: -3.143114008707926e-05
sam_encoder.blocks.11.norm1.bias grad: -1.903919837786816e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.36972424419946e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.3756869066128274e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.035332838408067e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.1212971458007814e-06
sam_encoder.blocks.11.norm2.weight grad: -1.9795788830379024e-05
sam_encoder.blocks.11.norm2.bias grad: -7.641190677531995e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.481137345166644e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.7334291391744046e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.14625333683216e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.6784293772361707e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0962503438349813e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.038679329212755e-07
sam_encoder.neck.conv2.trainable_scale grad: 4.503817763179541e-09
sam_encoder.neck.conv2.trainable_shift grad: -6.0948099417146295e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017207468044944108
mask_decoder.transformer.layers.0.norm1.bias grad: 5.2296018111519516e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003378769848495722
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00070445571327582
mask_decoder.transformer.layers.0.norm3.weight grad: -2.421537647023797e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0001044505916070193
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001284468307858333
mask_decoder.transformer.layers.0.norm4.bias grad: 2.1918178390478715e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.5501809432171285e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.4921324691385962e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0004438290779944509
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00023794281878508627
mask_decoder.transformer.layers.1.norm3.weight grad: 5.203893670113757e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.079333590809256e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.947591903852299e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 5.3607462177751586e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.620689757459331e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.988797288911883e-06
Text_Embedding_Affine.0.weight grad: -1.0103053810217588e-11
Text_Embedding_Affine.0.bias grad: 5.082789744648153e-10
Text_Embedding_Affine.2.weight grad: -1.980056743566827e-12
Text_Embedding_Affine.2.bias grad: -1.259475902770646e-05
Epoch 13 finished with average loss: -59.9742
Epoch 14/39
----------
Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.9]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-61.9]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-58.9]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-58.9]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-61.1]Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-61.1]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.097589122501925e-20
Max value: 0.999962568283081
Mean value: 0.0747685432434082

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.097589122501925e-20
Max value: 0.999962568283081
Mean value: 0.0747685432434082

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07701969146728516

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12247955799102783

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07207822799682617

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07701969146728516

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 53.861385345458984
Max value: 77.28121948242188
Mean value: 61.935760498046875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.097589122501925e-20
Max value: 0.999962568283081
Mean value: 0.0747685432434082

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.097589122501925e-20
Max value: 0.999962568283081
Mean value: 0.0747685432434082

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.097589122501925e-20
Max value: 0.999962568283081
Mean value: 0.0747685432434082

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12247955799102783

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 53.861385345458984
Max value: 77.28121948242188
Mean value: 61.935760498046875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.93658447265625
Max value: -61.93658447265625
Mean value: -61.93658447265625
sam_encoder.pos_embed grad: -7.96836197025641e-09
sam_encoder.blocks.0.norm1.weight grad: 3.511250179144554e-05
sam_encoder.blocks.0.norm1.bias grad: -5.483320273924619e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.30272199184401e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.0725551053146773e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.992293492658064e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.3452013263304252e-06
sam_encoder.blocks.0.norm2.weight grad: -2.6622508812579326e-05
sam_encoder.blocks.0.norm2.bias grad: 2.629893242556136e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.3911055652424693e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.645884018827928e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.9032381715078373e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.386484763723274e-07
sam_encoder.blocks.1.norm1.weight grad: -7.0382475314545445e-06
sam_encoder.blocks.1.norm1.bias grad: 2.8692977139144205e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.907593620373518e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.464216438762378e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.183574790455168e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.138050942652626e-06
sam_encoder.blocks.1.norm2.weight grad: -6.2167928263079375e-06
sam_encoder.blocks.1.norm2.bias grad: -5.015938768337946e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.906140465114731e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7679046777629992e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1040788194804918e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.1799594378535403e-06
sam_encoder.blocks.2.norm1.weight grad: -1.3640890017541096e-07
sam_encoder.blocks.2.norm1.bias grad: -6.643158030783525e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.4595678382866026e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.68967810877075e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.9611056814028416e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.4969773474149406e-06
sam_encoder.blocks.2.norm2.weight grad: 6.619727059842262e-07
sam_encoder.blocks.2.norm2.bias grad: 1.1951876786042703e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.272557584452443e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.805822418849857e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.1736320781637914e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.9818844521068968e-07
sam_encoder.blocks.3.norm1.weight grad: 1.4490608009509742e-05
sam_encoder.blocks.3.norm1.bias grad: -1.8256386624670995e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.466220035392325e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.195919594465522e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.752049790113233e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.655026949265448e-06
sam_encoder.blocks.3.norm2.weight grad: -1.5636458556400612e-05
sam_encoder.blocks.3.norm2.bias grad: -1.4711007452206104e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.002660792437382e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.935844455962069e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.932153958885465e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.8357893810948553e-08
sam_encoder.blocks.4.norm1.weight grad: 2.286225708303391e-06
sam_encoder.blocks.4.norm1.bias grad: -6.222235242603347e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.919681835715892e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.786024636719958e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.0114326869370416e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.2784095108363545e-06
sam_encoder.blocks.4.norm2.weight grad: 1.0540697076066863e-05
sam_encoder.blocks.4.norm2.bias grad: -9.155839507002383e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.026407390891109e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.2918561626283918e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.1433025924343383e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.260660949104931e-06
sam_encoder.blocks.5.norm1.weight grad: -1.2171420848972048e-06
sam_encoder.blocks.5.norm1.bias grad: -5.160663931746967e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.4021808258112287e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.366384124907199e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.4828096886485582e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.5934978111763485e-06
sam_encoder.blocks.5.norm2.weight grad: 7.522201485699043e-06
sam_encoder.blocks.5.norm2.bias grad: -3.982743692176882e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.9311698856181465e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.6549378187846742e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.063464646402281e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.0972457857860718e-06
sam_encoder.blocks.6.norm1.weight grad: 6.835242857050616e-06
sam_encoder.blocks.6.norm1.bias grad: -1.7894266193252406e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.119562269508606e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.9202028599684127e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.0371262507978827e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.0569967748306226e-06
sam_encoder.blocks.6.norm2.weight grad: -3.1758725071995286e-06
sam_encoder.blocks.6.norm2.bias grad: -1.3602814306068467e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.9800621632602997e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.320843125540705e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.228658205349348e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.826462832672405e-07
sam_encoder.blocks.7.norm1.weight grad: -6.107529770815745e-07
sam_encoder.blocks.7.norm1.bias grad: -4.79279265164223e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.317931931538624e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.620793868705732e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4030696320332936e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.050248662679223e-06
sam_encoder.blocks.7.norm2.weight grad: -1.673888846198679e-06
sam_encoder.blocks.7.norm2.bias grad: 2.6928034912998555e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.7361020329408348e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.682380669393751e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5513923017351772e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.232954900842742e-06
sam_encoder.blocks.8.norm1.weight grad: -3.728075057551905e-07
sam_encoder.blocks.8.norm1.bias grad: -2.715557911869837e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.8212643908555037e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.0247708814858925e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.1119066079554614e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.5755128970340593e-06
sam_encoder.blocks.8.norm2.weight grad: 4.521901701082243e-06
sam_encoder.blocks.8.norm2.bias grad: 2.034296812780667e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.1364533040468814e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.972024392671301e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.534522994006693e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.405036856449442e-07
sam_encoder.blocks.9.norm1.weight grad: 1.980253273359267e-06
sam_encoder.blocks.9.norm1.bias grad: 1.6058282881203922e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.970315217178722e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.12265012023272e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.251379254720632e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.776078079274157e-06
sam_encoder.blocks.9.norm2.weight grad: 5.704459908884019e-06
sam_encoder.blocks.9.norm2.bias grad: 2.6497450562601443e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 9.987570592784323e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.1898687262146268e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.5966235145679093e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.3164713525147818e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2022514965792652e-06
sam_encoder.blocks.10.norm1.bias grad: -3.433876258895907e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.2877605349312944e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.537673703453038e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.6225174565297493e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.0680371903836203e-07
sam_encoder.blocks.10.norm2.weight grad: 7.581191312056035e-06
sam_encoder.blocks.10.norm2.bias grad: 4.114474904781673e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.6152326881856425e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.6399048945459072e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.5580908439005725e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.068390578344406e-07
sam_encoder.blocks.11.norm1.weight grad: 5.923859021095268e-07
sam_encoder.blocks.11.norm1.bias grad: -1.1181396075699013e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.558340797686469e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.668100584443891e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.0557346286077518e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.6899711852147448e-07
sam_encoder.blocks.11.norm2.weight grad: 9.56623534875689e-06
sam_encoder.blocks.11.norm2.bias grad: -1.1887748314620694e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.457722297956934e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.7970187400351278e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.9011451968253823e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.5908443629086833e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.6136018530232832e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.26810113620013e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.830911060096696e-06
sam_encoder.neck.conv2.trainable_shift grad: -4.206723679089919e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0002590877702459693
mask_decoder.transformer.layers.0.norm1.bias grad: 8.945906301960349e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0017738932510837913
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0020037093199789524
mask_decoder.transformer.layers.0.norm3.weight grad: 4.264120070729405e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2681462976615876e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.450744356494397e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.630695912055671e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.0085695723537356e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.9463823264231905e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 1.379559762426652e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -4.0038903534878045e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -4.336253186920658e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.1478596206870861e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.4367196601815522e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 5.283383507048711e-05
mask_decoder.transformer.norm_final_attn.weight grad: -1.1838156979138148e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.944022738432977e-06
Text_Embedding_Affine.0.weight grad: 9.3389011801559e-13
Text_Embedding_Affine.0.bias grad: 1.1233125540854871e-10
Text_Embedding_Affine.2.weight grad: -1.1857209658572287e-10
Text_Embedding_Affine.2.bias grad: -8.84565815795213e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.075601791135009e-19
Max value: 0.9999724626541138
Mean value: 0.10672158747911453

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.075601791135009e-19
Max value: 0.9999724626541138
Mean value: 0.10672158747911453

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08478355407714844

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13242347538471222

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0912466049194336

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08478355407714844

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.7117919921875
Max value: 89.35424041748047
Mean value: 55.967689514160156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.0907691017846913e-18
Max value: 0.9999638795852661
Mean value: 0.1073124036192894

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.0907691017846913e-18
Max value: 0.9999638795852661
Mean value: 0.1073124036192894

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.0907691017846913e-18
Max value: 0.9999638795852661
Mean value: 0.1073124036192894

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13269585371017456

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9401112198829651
Max value: 1.9884852170944214
Mean value: 0.9997920989990234

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.7117919921875
Max value: 89.35424041748047
Mean value: 55.967689514160156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.956016540527344
Max value: -55.956016540527344
Mean value: -55.956016540527344
sam_encoder.pos_embed grad: -2.7436838911931716e-10
sam_encoder.blocks.0.norm1.weight grad: 2.973898153868504e-05
sam_encoder.blocks.0.norm1.bias grad: 5.303558282321319e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0575649866950698e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1557750667634537e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.974715587493847e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.706440641186418e-08
sam_encoder.blocks.0.norm2.weight grad: 3.918219226761721e-05
sam_encoder.blocks.0.norm2.bias grad: 1.5072280802996829e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.9593079489131924e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.616193796711741e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.531578724709107e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0996002401952865e-06
sam_encoder.blocks.1.norm1.weight grad: 8.075168807408772e-06
sam_encoder.blocks.1.norm1.bias grad: -8.735348160371359e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.8722897721090703e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.550250297252205e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 6.839138677605661e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.651183639405644e-07
sam_encoder.blocks.1.norm2.weight grad: 1.2860894457844552e-05
sam_encoder.blocks.1.norm2.bias grad: -7.469061529263854e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.9756650949129835e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.519859094718413e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.3611942222269136e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.000923811669054e-07
sam_encoder.blocks.2.norm1.weight grad: 2.9891152735217474e-06
sam_encoder.blocks.2.norm1.bias grad: -3.343148591739009e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.5926483456496499e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.458893236389486e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.5124148780596443e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.3549901015940122e-06
sam_encoder.blocks.2.norm2.weight grad: -1.5264347894117236e-05
sam_encoder.blocks.2.norm2.bias grad: 1.0715232292568544e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0781756827782374e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.828321951004909e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.7747025771750486e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.056760745806969e-07
sam_encoder.blocks.3.norm1.weight grad: -5.758424777013715e-07
sam_encoder.blocks.3.norm1.bias grad: -6.744403435732238e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.857079253881238e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.3638414126689895e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3536008509618114e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.784015221863228e-07
sam_encoder.blocks.3.norm2.weight grad: 9.722903996589594e-06
sam_encoder.blocks.3.norm2.bias grad: 1.2609316399903037e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 9.111861800192855e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.028122020827141e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.519668313056172e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.792037889776111e-07
sam_encoder.blocks.4.norm1.weight grad: -7.827113222447224e-06
sam_encoder.blocks.4.norm1.bias grad: 4.33689547207905e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.549281468120171e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.031725671258755e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.887324949886533e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.612391073053004e-08
sam_encoder.blocks.4.norm2.weight grad: -1.1738443390640896e-05
sam_encoder.blocks.4.norm2.bias grad: -8.201604941859841e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.620843800599687e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.2330251542589394e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.642983929490583e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.47792386796209e-07
sam_encoder.blocks.5.norm1.weight grad: -8.361630534636788e-06
sam_encoder.blocks.5.norm1.bias grad: -2.897891135944519e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.698964741895907e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.2613730834564194e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.778257789439522e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.7849251889856532e-06
sam_encoder.blocks.5.norm2.weight grad: -9.310746463597752e-06
sam_encoder.blocks.5.norm2.bias grad: -4.857125077251112e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.453806700941641e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.021029541145253e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7398528484591225e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.051143029457307e-07
sam_encoder.blocks.6.norm1.weight grad: -2.94779010800994e-06
sam_encoder.blocks.6.norm1.bias grad: 2.432032943033846e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.279355157952523e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.6680268117852393e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.472742140635091e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.4093340894305584e-07
sam_encoder.blocks.6.norm2.weight grad: 7.945492939143151e-07
sam_encoder.blocks.6.norm2.bias grad: 2.5530889047331584e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.4267725418903865e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.408351171354298e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.5242184403518877e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.76467867780184e-09
sam_encoder.blocks.7.norm1.weight grad: 7.991401389517705e-07
sam_encoder.blocks.7.norm1.bias grad: 1.1665597412502393e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.7898692021844909e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.819133654469624e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.337173085237737e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0366323976995773e-06
sam_encoder.blocks.7.norm2.weight grad: 5.493954631674569e-06
sam_encoder.blocks.7.norm2.bias grad: -4.676991807173181e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.359477770776721e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.1184159777476452e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.193996616663753e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.5454756407962122e-07
sam_encoder.blocks.8.norm1.weight grad: -1.6705039342923556e-06
sam_encoder.blocks.8.norm1.bias grad: -5.704766863345867e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.0819695691898232e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.100083065670333e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.128804438456427e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.34140678307449e-07
sam_encoder.blocks.8.norm2.weight grad: 1.3841327017871663e-06
sam_encoder.blocks.8.norm2.bias grad: -1.5658573602195247e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.4631146970932605e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.0215303518634755e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.284537169496616e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.418307983338309e-07
sam_encoder.blocks.9.norm1.weight grad: -3.854659553326201e-06
sam_encoder.blocks.9.norm1.bias grad: -9.802822376059339e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.577366558398353e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.910570616800669e-09
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.270764743021573e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5843652363400906e-06
sam_encoder.blocks.9.norm2.weight grad: 2.995444106090872e-07
sam_encoder.blocks.9.norm2.bias grad: -1.9973413145635277e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7925385691341944e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2529487491974578e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1088869769082521e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.949645469627285e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2952640418006922e-06
sam_encoder.blocks.10.norm1.bias grad: -5.26805479239556e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.2465432064345805e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.018559991436632e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0166779702558415e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.577041287731845e-07
sam_encoder.blocks.10.norm2.weight grad: -3.3173949987030937e-07
sam_encoder.blocks.10.norm2.bias grad: -2.6302177502657287e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.7627155557420338e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.3736988314103655e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.888881560167647e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.1986731724155106e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0311241567251272e-05
sam_encoder.blocks.11.norm1.bias grad: -7.35902062842797e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.063326279421744e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.147529750753165e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.832581967344595e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.45689556979778e-07
sam_encoder.blocks.11.norm2.weight grad: -2.053963726211805e-06
sam_encoder.blocks.11.norm2.bias grad: 4.888963189841888e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.8779467154672602e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.075664262221835e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6920110965656932e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.345797937181487e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.728056855034083e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.786782559065614e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.034039638005197e-07
sam_encoder.neck.conv2.trainable_shift grad: 9.359810792375356e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00022989604622125626
mask_decoder.transformer.layers.0.norm1.bias grad: -4.8728761612437665e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004845211282372475
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0011475214269012213
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00010258842667099088
mask_decoder.transformer.layers.0.norm3.bias grad: -4.404555511428043e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 8.563991286791861e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1391191037546378e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.8256734367460012e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.3924501369474456e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 3.94962407881394e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.511927105952054e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.048957584425807e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.282014924683608e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.4456050848821178e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001559496740810573
mask_decoder.transformer.norm_final_attn.weight grad: 6.116282747825608e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0972398740705103e-05
Text_Embedding_Affine.0.weight grad: 3.1020121367408837e-12
Text_Embedding_Affine.0.bias grad: 9.059197836336352e-11
Text_Embedding_Affine.2.weight grad: -8.146788799123783e-11
Text_Embedding_Affine.2.bias grad: 7.221825944725424e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.80656641465613e-33
Max value: 0.9999984502792358
Mean value: 0.09052886068820953

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.80656641465613e-33
Max value: 0.9999984502792358
Mean value: 0.09052886068820953

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09527015686035156

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16984394192695618

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08932304382324219

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09527015686035156

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 58.72679901123047
Max value: 72.48748779296875
Mean value: 65.2986831665039

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6563753161209705e-31
Max value: 0.9999963045120239
Mean value: 0.09001053124666214

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6563753161209705e-31
Max value: 0.9999963045120239
Mean value: 0.09001053124666214

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6563753161209705e-31
Max value: 0.9999963045120239
Mean value: 0.09001053124666214

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1652171015739441

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8363832831382751
Max value: 5.083695888519287
Mean value: 1.0062494277954102

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 58.72679901123047
Max value: 72.48748779296875
Mean value: 65.2986831665039

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.46578216552734
Max value: -65.46578216552734
Mean value: -65.46578216552734
sam_encoder.pos_embed grad: -4.046084356446045e-09
sam_encoder.blocks.0.norm1.weight grad: 4.540959344012663e-05
sam_encoder.blocks.0.norm1.bias grad: -2.9926897695986554e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.7182921914791223e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.3416838479970465e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.1551944630336948e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.712356134310539e-07
sam_encoder.blocks.0.norm2.weight grad: -2.9466416435752762e-06
sam_encoder.blocks.0.norm2.bias grad: -7.828952220734209e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.68900969583774e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.09708048007451e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.979613549949136e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.523500011709984e-06
sam_encoder.blocks.1.norm1.weight grad: -2.1349862890929217e-06
sam_encoder.blocks.1.norm1.bias grad: -7.000235200393945e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.889520823780913e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.921433749885182e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.248577276186552e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.677150172938127e-06
sam_encoder.blocks.1.norm2.weight grad: -2.4988707082229666e-05
sam_encoder.blocks.1.norm2.bias grad: 6.2050530686974525e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.5303616237360984e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.452928922342835e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.536762263451237e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.035212886170484e-07
sam_encoder.blocks.2.norm1.weight grad: 4.989774424757343e-06
sam_encoder.blocks.2.norm1.bias grad: -2.4294029117299942e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.4873047550499905e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.569996114398236e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.6468773083033739e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.2389954210666474e-06
sam_encoder.blocks.2.norm2.weight grad: 5.682105438609142e-06
sam_encoder.blocks.2.norm2.bias grad: -1.7058155208360404e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.495688583323499e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.312993956365972e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.734728569630533e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5362996919066063e-06
sam_encoder.blocks.3.norm1.weight grad: 1.3328861314221285e-05
sam_encoder.blocks.3.norm1.bias grad: 6.437462616304401e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.626987902156543e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.993346571311122e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.26261583597443e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.9682094009331195e-06
sam_encoder.blocks.3.norm2.weight grad: -8.778380106377881e-06
sam_encoder.blocks.3.norm2.bias grad: -4.195665496808942e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.692155799712054e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.118016815686133e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.75455396756297e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.944976232465706e-07
sam_encoder.blocks.4.norm1.weight grad: 6.457684321503621e-06
sam_encoder.blocks.4.norm1.bias grad: -1.4518633179250173e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.523884288370027e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.470015715516638e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.55029020638176e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.553869651615969e-06
sam_encoder.blocks.4.norm2.weight grad: 1.6971964214462787e-05
sam_encoder.blocks.4.norm2.bias grad: 1.1854419426526874e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.771161108394153e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.8821830255765235e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.312913011337514e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.0043224847322563e-06
sam_encoder.blocks.5.norm1.weight grad: 8.664344932185486e-06
sam_encoder.blocks.5.norm1.bias grad: -1.3334782124729827e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.0438266094279243e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.876032224070514e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.021411422807432e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.063136437551293e-06
sam_encoder.blocks.5.norm2.weight grad: 1.435333069821354e-05
sam_encoder.blocks.5.norm2.bias grad: 1.4815668691881e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.264835635898635e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.291523287567543e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.6009171304176562e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.3668311567016644e-06
sam_encoder.blocks.6.norm1.weight grad: -1.1174905694133486e-06
sam_encoder.blocks.6.norm1.bias grad: -2.9698048820137046e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.9527918741223402e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.798940598353511e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.4960776297812117e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.4571731981050107e-06
sam_encoder.blocks.6.norm2.weight grad: -5.379815775086172e-06
sam_encoder.blocks.6.norm2.bias grad: -1.3365340691962047e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.072052201488987e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.8800814106944017e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.7151219228471746e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.500224915522267e-07
sam_encoder.blocks.7.norm1.weight grad: -8.59813553688582e-09
sam_encoder.blocks.7.norm1.bias grad: -3.3796104048633424e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.6313133528456092e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.631690550624626e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.0131093353702454e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.109944944095332e-06
sam_encoder.blocks.7.norm2.weight grad: -4.0041545616986696e-06
sam_encoder.blocks.7.norm2.bias grad: 2.6341485863667913e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.957888217584696e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.882656872316147e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.1720340726005816e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.2202008292661048e-06
sam_encoder.blocks.8.norm1.weight grad: -3.532686605467461e-06
sam_encoder.blocks.8.norm1.bias grad: 2.1064050059749206e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.063078682112973e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.0984255115763517e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.303143449149502e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.1384987576311687e-06
sam_encoder.blocks.8.norm2.weight grad: 1.215586706848626e-07
sam_encoder.blocks.8.norm2.bias grad: 2.4242408471764065e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.848903934842383e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.1016379630746087e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.0500519894994795e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.5053046809043735e-06
sam_encoder.blocks.9.norm1.weight grad: 2.659631263668416e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0537163319668252e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.6750982467783615e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.794148354558274e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.083277360678039e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.328052235294308e-06
sam_encoder.blocks.9.norm2.weight grad: 3.6245296541892458e-06
sam_encoder.blocks.9.norm2.bias grad: 2.8273643692955375e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.3270840781842708e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3977812614029972e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.808949946280336e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.4642776022810722e-06
sam_encoder.blocks.10.norm1.weight grad: -9.54162715061102e-07
sam_encoder.blocks.10.norm1.bias grad: -8.739822874304082e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.9451931621006224e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.085728720492625e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.2989494280191138e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.391379431785026e-07
sam_encoder.blocks.10.norm2.weight grad: 3.831856247415999e-06
sam_encoder.blocks.10.norm2.bias grad: 3.4966124076163396e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.202505341614597e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.7304087047450594e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.0530010285947355e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.785684263377334e-07
sam_encoder.blocks.11.norm1.weight grad: -1.754232835082803e-05
sam_encoder.blocks.11.norm1.bias grad: -6.629771860389155e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.159798097840394e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.722317197864868e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.1375115011323942e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.193176212334947e-07
sam_encoder.blocks.11.norm2.weight grad: 6.9079824243090115e-06
sam_encoder.blocks.11.norm2.bias grad: -2.592470536910696e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.287589268235024e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.3131074183547753e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.4200033951492514e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.9077040178672178e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.8689170246943831e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.0325893274275586e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0505576685536653e-06
sam_encoder.neck.conv2.trainable_shift grad: -7.246895256685093e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00025993649614974856
mask_decoder.transformer.layers.0.norm1.bias grad: 1.353774860035628e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003261853475123644
mask_decoder.transformer.layers.0.norm2.bias grad: -0.001653140876442194
mask_decoder.transformer.layers.0.norm3.weight grad: 6.737816147506237e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.080437429365702e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012682996748480946
mask_decoder.transformer.layers.0.norm4.bias grad: 9.179467269859742e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.1083628123742528e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.211755706113763e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001915792963700369
mask_decoder.transformer.layers.1.norm2.bias grad: 3.260673474869691e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.186500493437052e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.4225024642655626e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.1353035006322898e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00012847731704823673
mask_decoder.transformer.norm_final_attn.weight grad: 3.014256208189181e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.30661155708367e-05
Text_Embedding_Affine.0.weight grad: 7.712623942279784e-13
Text_Embedding_Affine.0.bias grad: -6.940416574785502e-10
Text_Embedding_Affine.2.weight grad: 2.735439826040409e-11
Text_Embedding_Affine.2.bias grad: -9.473564568907022e-05
Epoch 14 finished with average loss: -61.1195
Epoch 15/39
----------
Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.2]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-61.2]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-59]  Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.71it/s, loss=-59]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.71it/s, loss=-60.3]Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-60.3]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.511647554567182e-26
Max value: 0.9999873638153076
Mean value: 0.074233278632164

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.511647554567182e-26
Max value: 0.9999873638153076
Mean value: 0.074233278632164

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08065414428710938

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12468357384204865

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07035017013549805

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08065414428710938

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.97005844116211
Max value: 79.69261932373047
Mean value: 61.220306396484375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.511647554567182e-26
Max value: 0.9999873638153076
Mean value: 0.074233278632164

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.511647554567182e-26
Max value: 0.9999873638153076
Mean value: 0.074233278632164

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.511647554567182e-26
Max value: 0.9999873638153076
Mean value: 0.074233278632164

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12468357384204865

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.97005844116211
Max value: 79.69261932373047
Mean value: 61.220306396484375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.22111511230469
Max value: -61.22111511230469
Mean value: -61.22111511230469
sam_encoder.pos_embed grad: 2.382953390167586e-09
sam_encoder.blocks.0.norm1.weight grad: 4.476007234188728e-05
sam_encoder.blocks.0.norm1.bias grad: -0.0001407616218784824
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.988025542232208e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2541138403321384e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.521491402760148e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.1950721727771452e-06
sam_encoder.blocks.0.norm2.weight grad: -3.819786797976121e-05
sam_encoder.blocks.0.norm2.bias grad: 3.535840005497448e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.797959031246137e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.415477181079041e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.7930849682888947e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.411010609648656e-05
sam_encoder.blocks.1.norm1.weight grad: 4.498288035392761e-05
sam_encoder.blocks.1.norm1.bias grad: 7.945804827613756e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3787870557280257e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -6.0896882132510655e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.3581014829687774e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4750490663573146e-05
sam_encoder.blocks.1.norm2.weight grad: 2.320593921467662e-05
sam_encoder.blocks.1.norm2.bias grad: 2.973495611513499e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.9792007151409052e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.3713920402078656e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.5238591004163027e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.328539838141296e-06
sam_encoder.blocks.2.norm1.weight grad: -5.0212191126774997e-05
sam_encoder.blocks.2.norm1.bias grad: 8.15104431239888e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.2511881727259606e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.604770881793229e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.8023258235189132e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.389461421145825e-06
sam_encoder.blocks.2.norm2.weight grad: -8.882029760570731e-06
sam_encoder.blocks.2.norm2.bias grad: 1.1696773981384467e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.549607966619078e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.227454214993486e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.145981852663681e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.254737177689094e-06
sam_encoder.blocks.3.norm1.weight grad: 4.356298450147733e-05
sam_encoder.blocks.3.norm1.bias grad: -1.6910998965613544e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.0387436709133908e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.81662038207287e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.0318903150619008e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.3735568649717607e-06
sam_encoder.blocks.3.norm2.weight grad: 2.4717510314076208e-05
sam_encoder.blocks.3.norm2.bias grad: 3.261050005676225e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.8716786144068465e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.2968093869858421e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.3157481336966157e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.9714248082891572e-06
sam_encoder.blocks.4.norm1.weight grad: 3.3453811738581862e-06
sam_encoder.blocks.4.norm1.bias grad: -2.6358622562838718e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.576089855210739e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.152886958763702e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.352328109140217e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.3282458389294334e-06
sam_encoder.blocks.4.norm2.weight grad: -2.2180661289894488e-06
sam_encoder.blocks.4.norm2.bias grad: 2.0527411834336817e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.721805337088881e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.0167197451191896e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.184661008821422e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.322910278162453e-07
sam_encoder.blocks.5.norm1.weight grad: -4.012540739495307e-05
sam_encoder.blocks.5.norm1.bias grad: -1.9544653696357273e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.462418342474848e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.426365532912314e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.3864095308235846e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.395523087121546e-06
sam_encoder.blocks.5.norm2.weight grad: -1.5353971321019344e-05
sam_encoder.blocks.5.norm2.bias grad: 1.9305498426547274e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.962245733011514e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.490619398391573e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.053698724717833e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.6246666493534576e-06
sam_encoder.blocks.6.norm1.weight grad: -6.1122018450987525e-06
sam_encoder.blocks.6.norm1.bias grad: -1.3162787581677549e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.9725607671716716e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.426585165783763e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.074335144352517e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.523208415070258e-07
sam_encoder.blocks.6.norm2.weight grad: -2.8629438020288944e-07
sam_encoder.blocks.6.norm2.bias grad: 8.748146683501545e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.103444997686893e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.882816145051038e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.875182758543815e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.460855044882919e-07
sam_encoder.blocks.7.norm1.weight grad: -1.4685151654703077e-05
sam_encoder.blocks.7.norm1.bias grad: 3.2053176255431026e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.5660478311474435e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.6860279730462935e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.6513541747117415e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.914571481000166e-06
sam_encoder.blocks.7.norm2.weight grad: -5.006577339372598e-06
sam_encoder.blocks.7.norm2.bias grad: 4.1134962884825654e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0777575880638324e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.030655524431495e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.3551808630581945e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.091744024961372e-06
sam_encoder.blocks.8.norm1.weight grad: 1.1771985555242281e-05
sam_encoder.blocks.8.norm1.bias grad: 1.1063409601774765e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.394490007252898e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.637162762970547e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.511722181632649e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.984981589155723e-08
sam_encoder.blocks.8.norm2.weight grad: -2.998905529238982e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5544177358606248e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.408097993291449e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.974199327989481e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.839234174549347e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.169542388079208e-08
sam_encoder.blocks.9.norm1.weight grad: 3.480691475488129e-06
sam_encoder.blocks.9.norm1.bias grad: 1.8415088334222673e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.923334017803427e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.633897780578991e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.5312753021134995e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.834828809587634e-07
sam_encoder.blocks.9.norm2.weight grad: 2.088594101223862e-06
sam_encoder.blocks.9.norm2.bias grad: 5.890782631468028e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.0857613688131096e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.851796913702856e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5303664895327529e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.5969061450959998e-06
sam_encoder.blocks.10.norm1.weight grad: 3.5888613183487905e-06
sam_encoder.blocks.10.norm1.bias grad: 6.960829068702878e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.854124770441558e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.031925760093145e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.274850647969288e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.8472732108421042e-06
sam_encoder.blocks.10.norm2.weight grad: -8.493775567330886e-06
sam_encoder.blocks.10.norm2.bias grad: -2.1649854886618414e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.216459612711333e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -8.794769996711693e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.134826435300056e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.578450332497596e-06
sam_encoder.blocks.11.norm1.weight grad: -4.7087987695704214e-06
sam_encoder.blocks.11.norm1.bias grad: 5.013653208152391e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.7476613720646128e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.087567271606531e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.608042788982857e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.238654239292373e-07
sam_encoder.blocks.11.norm2.weight grad: -8.308508768095635e-06
sam_encoder.blocks.11.norm2.bias grad: 1.221230718329025e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -8.927161616156809e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4210684184945421e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.395782060688362e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.612773641885724e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.3356548151932657e-06
sam_encoder.neck.conv1.trainable_shift grad: -7.772562821628526e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.1937536328332499e-06
sam_encoder.neck.conv2.trainable_shift grad: -8.370154682779685e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00025872839614748955
mask_decoder.transformer.layers.0.norm1.bias grad: -4.12099325330928e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003363859374076128
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0009097897564060986
mask_decoder.transformer.layers.0.norm3.weight grad: -5.617940041702241e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00010434188152430579
mask_decoder.transformer.layers.0.norm4.weight grad: 1.0721851140260696e-06
mask_decoder.transformer.layers.0.norm4.bias grad: -5.345180397853255e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.796680175582878e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2504533515311778e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00024067220510914922
mask_decoder.transformer.layers.1.norm2.bias grad: -6.321164255496114e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.3387125111185014e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.3348060747375712e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.3441236660582945e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015935981355141848
mask_decoder.transformer.norm_final_attn.weight grad: 2.0383409719215706e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.9246434021624736e-05
Text_Embedding_Affine.0.weight grad: -5.9352748410512746e-12
Text_Embedding_Affine.0.bias grad: -3.289810923678971e-10
Text_Embedding_Affine.2.weight grad: -2.645973717907424e-11
Text_Embedding_Affine.2.bias grad: 5.114731902722269e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0908528634291084e-15
Max value: 0.9997642636299133
Mean value: 0.08668755739927292

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0908528634291084e-15
Max value: 0.9997642636299133
Mean value: 0.08668755739927292

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09017181396484375

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1373339295387268

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07485771179199219

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09017181396484375

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.95351791381836
Max value: 74.8014907836914
Mean value: 56.78488540649414

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.886265089033877e-15
Max value: 0.9996684789657593
Mean value: 0.08734351396560669

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.886265089033877e-15
Max value: 0.9996684789657593
Mean value: 0.08734351396560669

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.886265089033877e-15
Max value: 0.9996684789657593
Mean value: 0.08734351396560669

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13672204315662384

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9356560111045837
Max value: 2.882397413253784
Mean value: 1.0007669925689697

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.95351791381836
Max value: 74.8014907836914
Mean value: 56.78488540649414

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.81850051879883
Max value: -56.81850051879883
Mean value: -56.81850051879883
sam_encoder.pos_embed grad: -1.7025997278707905e-09
sam_encoder.blocks.0.norm1.weight grad: -4.265074312570505e-05
sam_encoder.blocks.0.norm1.bias grad: -4.6865656599948124e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1519044821616262e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.4189524222274486e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.6205543690593913e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4174842135616927e-06
sam_encoder.blocks.0.norm2.weight grad: 8.052092198340688e-06
sam_encoder.blocks.0.norm2.bias grad: -2.0335173758212477e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.6924997200694634e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.6065100680862088e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.4124980225460604e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.885310318059055e-06
sam_encoder.blocks.1.norm1.weight grad: 1.0452740752953105e-05
sam_encoder.blocks.1.norm1.bias grad: 7.520433427998796e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.2661080240359297e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.299914960232854e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.032275171539368e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.4839416684917524e-07
sam_encoder.blocks.1.norm2.weight grad: 1.046593206410762e-05
sam_encoder.blocks.1.norm2.bias grad: 4.704711500380654e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.641543233039556e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.05721936608461e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.617436166474363e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3380765722104115e-06
sam_encoder.blocks.2.norm1.weight grad: 3.645756805781275e-06
sam_encoder.blocks.2.norm1.bias grad: -9.382265488966368e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.0561136605247157e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.508765070771915e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.5431467040325515e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.40142230722995e-06
sam_encoder.blocks.2.norm2.weight grad: -1.3403585398918949e-05
sam_encoder.blocks.2.norm2.bias grad: -2.843041102096322e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.840812031645328e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.204647782695247e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.196316573754302e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2673638138949173e-06
sam_encoder.blocks.3.norm1.weight grad: -5.402172064350452e-06
sam_encoder.blocks.3.norm1.bias grad: -3.309529120087973e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.4167539979534922e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1866662674719919e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.261303499537462e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.5866241887561046e-07
sam_encoder.blocks.3.norm2.weight grad: 8.903925845515914e-06
sam_encoder.blocks.3.norm2.bias grad: 7.466890565410722e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.5962407208862714e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.487182311801007e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.667072062147781e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.71770692406426e-07
sam_encoder.blocks.4.norm1.weight grad: 7.19771833246341e-06
sam_encoder.blocks.4.norm1.bias grad: 3.560004870450939e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.658100922621088e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.873649560177e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.0627926460292656e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3350903600439779e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5356877813464962e-05
sam_encoder.blocks.4.norm2.bias grad: -1.2355691978882533e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.56155219883658e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.642893484036904e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.648228574907989e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.776332265370002e-07
sam_encoder.blocks.5.norm1.weight grad: 5.5878899729577824e-08
sam_encoder.blocks.5.norm1.bias grad: 1.960307145054685e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.2697002438908385e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.6985759430099279e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.566636787079915e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.913379830715712e-07
sam_encoder.blocks.5.norm2.weight grad: -1.5217686268442776e-05
sam_encoder.blocks.5.norm2.bias grad: -6.159596523502842e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.841063052183017e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.1294653126678895e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.0119236054938483e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.327460025408072e-07
sam_encoder.blocks.6.norm1.weight grad: 4.132349658902967e-06
sam_encoder.blocks.6.norm1.bias grad: 3.639504939201288e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.471362904543639e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.5663595693004027e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.5640741821698612e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.649417052060016e-07
sam_encoder.blocks.6.norm2.weight grad: -1.8253483631269773e-06
sam_encoder.blocks.6.norm2.bias grad: 6.391812803485664e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4712876463818247e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.162406063798699e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.4864837061832077e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.592280664743157e-08
sam_encoder.blocks.7.norm1.weight grad: 3.3094920581788756e-06
sam_encoder.blocks.7.norm1.bias grad: 1.2712082479993114e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.462774773448473e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.476861143601127e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5255807284120237e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0884120911214268e-06
sam_encoder.blocks.7.norm2.weight grad: -9.863622381089954e-07
sam_encoder.blocks.7.norm2.bias grad: 1.520913656349876e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.347167982312385e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.245192369329743e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.700680271227611e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.817711101168243e-07
sam_encoder.blocks.8.norm1.weight grad: 1.7341401417070301e-06
sam_encoder.blocks.8.norm1.bias grad: -2.94438905257266e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.5153138355781266e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.729113799039624e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.8257782130604028e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 7.334637643907627e-07
sam_encoder.blocks.8.norm2.weight grad: -2.15838554140646e-06
sam_encoder.blocks.8.norm2.bias grad: -1.8698750636758632e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.262628519631107e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -9.027882583723112e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.20336629456142e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.595592705911258e-07
sam_encoder.blocks.9.norm1.weight grad: 1.4308113804872846e-07
sam_encoder.blocks.9.norm1.bias grad: -1.4445819829234097e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.220619409054052e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.258032160782022e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.7003866282248055e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.89737817083369e-07
sam_encoder.blocks.9.norm2.weight grad: 3.157497303618584e-07
sam_encoder.blocks.9.norm2.bias grad: -2.003484041779302e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.802154883989715e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.3995431181210733e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.110803158459021e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.0806872902976465e-07
sam_encoder.blocks.10.norm1.weight grad: 6.150337412691442e-06
sam_encoder.blocks.10.norm1.bias grad: -3.570327677948626e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.2535257307463326e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5991903410395025e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.0806871816603234e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.997127108363202e-07
sam_encoder.blocks.10.norm2.weight grad: -4.0045074456429575e-07
sam_encoder.blocks.10.norm2.bias grad: -2.3439583856088575e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.1956891512454604e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.127591944959931e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.666290914836281e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.107231118017808e-07
sam_encoder.blocks.11.norm1.weight grad: 1.606118712516036e-05
sam_encoder.blocks.11.norm1.bias grad: 3.130793118089059e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.3816204449976794e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.515705758327385e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.2703295599058038e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.95050857757451e-07
sam_encoder.blocks.11.norm2.weight grad: -1.2350382121439907e-06
sam_encoder.blocks.11.norm2.bias grad: -1.8291136427706078e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.1889454754054896e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.337585093911912e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6628404182483791e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.10624442237895e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.106303433421999e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.80858260137029e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.41058398084715e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.4790784664219245e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018225732492282987
mask_decoder.transformer.layers.0.norm1.bias grad: -3.901121090166271e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005379852373152971
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0007926627295091748
mask_decoder.transformer.layers.0.norm3.weight grad: -7.808583904989064e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.596276499389205e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013223120186012238
mask_decoder.transformer.layers.0.norm4.bias grad: -7.82527968112845e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.81450759555446e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.513032763497904e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00012561705079860985
mask_decoder.transformer.layers.1.norm2.bias grad: 2.3028769646771252e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.799647311097942e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.8907699995907024e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.332916043698788e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018596244626678526
mask_decoder.transformer.norm_final_attn.weight grad: 3.551811914803693e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0106512490892783e-05
Text_Embedding_Affine.0.weight grad: -3.3989311365445474e-11
Text_Embedding_Affine.0.bias grad: -1.1711382974510798e-09
Text_Embedding_Affine.2.weight grad: -2.1004109562738904e-10
Text_Embedding_Affine.2.bias grad: 6.66298292344436e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0196733766917166e-21
Max value: 0.9999904632568359
Mean value: 0.06178321689367294

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0196733766917166e-21
Max value: 0.9999904632568359
Mean value: 0.06178321689367294

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07683849334716797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11019409447908401

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05791473388671875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07683849334716797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 36.034698486328125
Max value: 90.2872085571289
Mean value: 62.77583312988281

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.917488480022016e-20
Max value: 0.9999703168869019
Mean value: 0.061855632811784744

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.917488480022016e-20
Max value: 0.9999703168869019
Mean value: 0.061855632811784744

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.917488480022016e-20
Max value: 0.9999703168869019
Mean value: 0.061855632811784744

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1084427684545517

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6916602253913879
Max value: 6.411561965942383
Mean value: 1.002889633178711

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 36.034698486328125
Max value: 90.2872085571289
Mean value: 62.77583312988281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.83205795288086
Max value: -62.83205795288086
Mean value: -62.83205795288086
sam_encoder.pos_embed grad: 4.473865722331993e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00025462984922342
sam_encoder.blocks.0.norm1.bias grad: -4.389131208881736e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1571213690331206e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0956563301078859e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.685784081928432e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.513357559219003e-06
sam_encoder.blocks.0.norm2.weight grad: 9.20962993404828e-05
sam_encoder.blocks.0.norm2.bias grad: 4.809044185094535e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.859211341885384e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.0691331883426756e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.102637078380212e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.4444219889119267e-05
sam_encoder.blocks.1.norm1.weight grad: -1.2104041161364876e-05
sam_encoder.blocks.1.norm1.bias grad: -1.8356025975663215e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.439957097521983e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.445763680560049e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.074317671940662e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.470328233059263e-06
sam_encoder.blocks.1.norm2.weight grad: -4.8015936044976115e-06
sam_encoder.blocks.1.norm2.bias grad: 1.571937173139304e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.905432691273745e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.1190193112706766e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.18877503357362e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.869052190770162e-06
sam_encoder.blocks.2.norm1.weight grad: 1.5998950402718037e-05
sam_encoder.blocks.2.norm1.bias grad: 1.226445056090597e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.893357749504503e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.063863568466331e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.6991134442796465e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.186387402820401e-07
sam_encoder.blocks.2.norm2.weight grad: 2.062079875031486e-05
sam_encoder.blocks.2.norm2.bias grad: -4.577304480335442e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.707460099481978e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.919979467857047e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1926756997127086e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.2971851194597548e-06
sam_encoder.blocks.3.norm1.weight grad: 2.7902988222194836e-06
sam_encoder.blocks.3.norm1.bias grad: -1.4205250408849679e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1035974239348434e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.532769475597888e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.221171017590677e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.795217010832857e-06
sam_encoder.blocks.3.norm2.weight grad: -1.4932185877114534e-05
sam_encoder.blocks.3.norm2.bias grad: -1.6369051081710495e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3346550986170769e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.7105652407044545e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.164950486388989e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.4797063840887859e-06
sam_encoder.blocks.4.norm1.weight grad: 1.907269688672386e-05
sam_encoder.blocks.4.norm1.bias grad: -1.5139320566959213e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.010589691461064e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.2514251415705075e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 9.293856919612153e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.956744876632001e-06
sam_encoder.blocks.4.norm2.weight grad: -3.5630815546028316e-05
sam_encoder.blocks.4.norm2.bias grad: -2.4174469217541628e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.7774554837378673e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.32214879867388e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.3715590436477214e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.010510216787225e-08
sam_encoder.blocks.5.norm1.weight grad: 2.754857632680796e-06
sam_encoder.blocks.5.norm1.bias grad: -3.436900078668259e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.681445145455655e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.838574230030645e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.627685252169613e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 9.294576557294931e-06
sam_encoder.blocks.5.norm2.weight grad: -2.7829088139696978e-05
sam_encoder.blocks.5.norm2.bias grad: -1.6031364793889225e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.6413236153312027e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.752177003159886e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.478028069523134e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.313323635571578e-07
sam_encoder.blocks.6.norm1.weight grad: 5.416633939603344e-06
sam_encoder.blocks.6.norm1.bias grad: -9.963247066480108e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.352287181878637e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.198466972913593e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.7438228496757802e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.2388958313968033e-06
sam_encoder.blocks.6.norm2.weight grad: -1.805646752472967e-05
sam_encoder.blocks.6.norm2.bias grad: 9.478961146669462e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.331233488599537e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.6252711146953516e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -6.00664122885064e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.295579962374177e-08
sam_encoder.blocks.7.norm1.weight grad: -4.777595677296631e-06
sam_encoder.blocks.7.norm1.bias grad: -2.2636027097178157e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.68780625751242e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.183578428433975e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.7897652873652987e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.1802057997556403e-07
sam_encoder.blocks.7.norm2.weight grad: -6.698215202050051e-06
sam_encoder.blocks.7.norm2.bias grad: 3.624908913479885e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.4281059672357515e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.4281912374135572e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1933836958633037e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.379919904655253e-07
sam_encoder.blocks.8.norm1.weight grad: 2.302657230757177e-05
sam_encoder.blocks.8.norm1.bias grad: -7.117428140190896e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.9658134988276288e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.952683517942205e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.822733560809866e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.8262369394506095e-06
sam_encoder.blocks.8.norm2.weight grad: -4.7641037781431805e-06
sam_encoder.blocks.8.norm2.bias grad: 1.963339400390396e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.863768248877022e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.2613961593597196e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.3965884565768647e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.0933126759482548e-07
sam_encoder.blocks.9.norm1.weight grad: -2.0480078092077747e-05
sam_encoder.blocks.9.norm1.bias grad: 1.9512306153046666e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.1329429728211835e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.833248673705384e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.892095825605793e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.7657741864240961e-06
sam_encoder.blocks.9.norm2.weight grad: -1.1125746823381633e-05
sam_encoder.blocks.9.norm2.bias grad: 1.5809182514203712e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.1784827620431315e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.4147559492557775e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.6397256104028202e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.1125318906124448e-06
sam_encoder.blocks.10.norm1.weight grad: -5.489179784490261e-06
sam_encoder.blocks.10.norm1.bias grad: -3.1647323339711875e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.904702109342907e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.316916950599989e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.9905476165149594e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.313104444823693e-07
sam_encoder.blocks.10.norm2.weight grad: -2.5197074137395248e-05
sam_encoder.blocks.10.norm2.bias grad: 1.1397836487958557e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.5885623724898323e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.999574452493107e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.1707742260114173e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.659058726654621e-07
sam_encoder.blocks.11.norm1.weight grad: -5.271180998533964e-05
sam_encoder.blocks.11.norm1.bias grad: 2.6757249997899635e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.366167973377742e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.330628482624888e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.03059901954839e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.1300921818910865e-06
sam_encoder.blocks.11.norm2.weight grad: -2.1973690309096128e-05
sam_encoder.blocks.11.norm2.bias grad: -7.836160875740461e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.344249413814396e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.964779352827463e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.1613228707574308e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.199482312586042e-06
sam_encoder.neck.conv1.trainable_scale grad: 7.939270290080458e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.486454028869048e-06
sam_encoder.neck.conv2.trainable_scale grad: 6.639384082518518e-07
sam_encoder.neck.conv2.trainable_shift grad: -0.00011053538037231192
mask_decoder.transformer.layers.0.norm1.weight grad: 2.8915383154526353e-06
mask_decoder.transformer.layers.0.norm1.bias grad: 1.1247480870224535e-05
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0002955759409815073
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0007340172305703163
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011366997205186635
mask_decoder.transformer.layers.0.norm3.bias grad: 2.995563409058377e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013065472012385726
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2030812285956927e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.448748950380832e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.820244299073238e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0005871196044608951
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00018700436339713633
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00010919780470430851
mask_decoder.transformer.layers.1.norm3.bias grad: 7.43143173167482e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00014739319158252329
mask_decoder.transformer.layers.1.norm4.bias grad: -1.3340695659280755e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.648245395510457e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.1793110691942275e-06
Text_Embedding_Affine.0.weight grad: -3.858349750807122e-11
Text_Embedding_Affine.0.bias grad: -1.0624479074294868e-09
Text_Embedding_Affine.2.weight grad: -1.35466134837392e-11
Text_Embedding_Affine.2.bias grad: 5.2588129619834945e-06
Epoch 15 finished with average loss: -60.2906
Epoch 16/39
----------
Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.2]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-58.2]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-62]  Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-62]Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-56]Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-56]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.64082914350232e-15
Max value: 0.9998912811279297
Mean value: 0.06721215695142746

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.64082914350232e-15
Max value: 0.9998912811279297
Mean value: 0.06721215695142746

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07194185256958008

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10684061050415039

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.061804771423339844

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07194185256958008

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.10466766357422
Max value: 69.20169830322266
Mean value: 58.194374084472656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.64082914350232e-15
Max value: 0.9998912811279297
Mean value: 0.06721215695142746

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.64082914350232e-15
Max value: 0.9998912811279297
Mean value: 0.06721215695142746

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.64082914350232e-15
Max value: 0.9998912811279297
Mean value: 0.06721215695142746

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10684061050415039

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.10466766357422
Max value: 69.20169830322266
Mean value: 58.194374084472656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.195194244384766
Max value: -58.195194244384766
Mean value: -58.195194244384766
sam_encoder.pos_embed grad: -7.566814730353144e-09
sam_encoder.blocks.0.norm1.weight grad: -8.79497965797782e-05
sam_encoder.blocks.0.norm1.bias grad: 1.3877262972528115e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.113653504755348e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.612671879542177e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.2561596324521815e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1299334801151417e-06
sam_encoder.blocks.0.norm2.weight grad: 2.338455260542105e-06
sam_encoder.blocks.0.norm2.bias grad: 7.663643918931484e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.539611184853129e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.6013168482895708e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.558109033794608e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.43604920594953e-05
sam_encoder.blocks.1.norm1.weight grad: -2.4142796974047087e-05
sam_encoder.blocks.1.norm1.bias grad: -1.1634953978045814e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.15773819340393e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.262656835227972e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.0444960935274139e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.906953108729795e-06
sam_encoder.blocks.1.norm2.weight grad: 1.9825533854600508e-06
sam_encoder.blocks.1.norm2.bias grad: -1.1196365448995493e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3459036381391343e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.992344323298312e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.695397077128291e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.724511306150816e-07
sam_encoder.blocks.2.norm1.weight grad: 7.149139491957612e-06
sam_encoder.blocks.2.norm1.bias grad: -6.9846682890783995e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.268631412036484e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.4288871170720086e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.15647911420092e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.8862773433502298e-06
sam_encoder.blocks.2.norm2.weight grad: 1.4767515494895633e-05
sam_encoder.blocks.2.norm2.bias grad: -7.660288247279823e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.0966594345518388e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.46784691423818e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 9.881781807052903e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.1446688808500767e-06
sam_encoder.blocks.3.norm1.weight grad: 7.990305675775744e-06
sam_encoder.blocks.3.norm1.bias grad: -5.2924297051504254e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.845202839642297e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.833014150382951e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 6.502913947770139e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.864347374677891e-06
sam_encoder.blocks.3.norm2.weight grad: 1.20928189062397e-05
sam_encoder.blocks.3.norm2.bias grad: 2.1457888124132296e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.832643859728705e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4881801462252042e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.88348381522519e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.56724170716916e-07
sam_encoder.blocks.4.norm1.weight grad: 5.170059921510983e-06
sam_encoder.blocks.4.norm1.bias grad: 2.8187801035528537e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.13478028854297e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.692324585495953e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.756752787216101e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.109928224555915e-06
sam_encoder.blocks.4.norm2.weight grad: 8.538226211385336e-06
sam_encoder.blocks.4.norm2.bias grad: -1.8861479475162923e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.854748451383784e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.2641872899621376e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.4149401219328865e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.916025192069355e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4732503586856183e-05
sam_encoder.blocks.5.norm1.bias grad: -5.241257667876198e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.443002232321305e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.3848513137636473e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.8604313128162175e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.3020897970127407e-06
sam_encoder.blocks.5.norm2.weight grad: 9.434956155018881e-06
sam_encoder.blocks.5.norm2.bias grad: -9.10329254111275e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.017443178687245e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.767827027128078e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.30599686246569e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.4081460853485623e-07
sam_encoder.blocks.6.norm1.weight grad: -2.025338652344999e-08
sam_encoder.blocks.6.norm1.bias grad: 3.4652455269679194e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.2228847481310368e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.469492970813008e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.672198958947774e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.309135187620996e-07
sam_encoder.blocks.6.norm2.weight grad: 2.577415898485924e-06
sam_encoder.blocks.6.norm2.bias grad: -5.507347850652877e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.710981885291403e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.821988118739682e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.9656234801223036e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0121381137651042e-06
sam_encoder.blocks.7.norm1.weight grad: 6.628522442042595e-06
sam_encoder.blocks.7.norm1.bias grad: 1.584637516316434e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.971468570147408e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.210741286035045e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.422369789201184e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.2753879420633893e-06
sam_encoder.blocks.7.norm2.weight grad: 5.175724254513625e-06
sam_encoder.blocks.7.norm2.bias grad: -3.0781734494667035e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.1735271477373317e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.2051775684085442e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3137222367731738e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.387202587466163e-06
sam_encoder.blocks.8.norm1.weight grad: 6.295492767094402e-06
sam_encoder.blocks.8.norm1.bias grad: -9.9850967671955e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.369033715396654e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.598865082996781e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.444630121724913e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.714650463531143e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0045101589639671e-05
sam_encoder.blocks.8.norm2.bias grad: 1.44197429108317e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 8.292383427033201e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.0231996030779555e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.5397112065329566e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.950253019662341e-07
sam_encoder.blocks.9.norm1.weight grad: 6.136229444564378e-07
sam_encoder.blocks.9.norm1.bias grad: 7.701005415583495e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.54099244709505e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.809401955048088e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1583008330262601e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.183068196856766e-08
sam_encoder.blocks.9.norm2.weight grad: 9.308910193794873e-06
sam_encoder.blocks.9.norm2.bias grad: 2.0880379452137277e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.257248176349094e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.053104930790141e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.323391860656557e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.8114262679300737e-07
sam_encoder.blocks.10.norm1.weight grad: 1.8664117078515119e-06
sam_encoder.blocks.10.norm1.bias grad: 1.3327635315363295e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1152812930959044e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.75983926612389e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.253868214869726e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.8343751406746378e-08
sam_encoder.blocks.10.norm2.weight grad: 1.2166199667262845e-05
sam_encoder.blocks.10.norm2.bias grad: 1.2689106370089576e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.7929410104407e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.7286818042048253e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.145931719293003e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.500870431911608e-07
sam_encoder.blocks.11.norm1.weight grad: 2.8120948627474718e-05
sam_encoder.blocks.11.norm1.bias grad: 6.001403107802616e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.052450438190135e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.995133278702269e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.4166920411516912e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.47486910263251e-07
sam_encoder.blocks.11.norm2.weight grad: 9.217799743055366e-06
sam_encoder.blocks.11.norm2.bias grad: 1.5419221881529666e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.454103873285931e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.8094104916599463e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.141473901128848e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.4825677504341e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.818644007784314e-07
sam_encoder.neck.conv1.trainable_shift grad: 9.531052455713507e-06
sam_encoder.neck.conv2.trainable_scale grad: 5.113524821354076e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.725718412781134e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00011213283869437873
mask_decoder.transformer.layers.0.norm1.bias grad: 2.38636857829988e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003065193071961403
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0018610861152410507
mask_decoder.transformer.layers.0.norm3.weight grad: 2.7475347451400012e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.319232488749549e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.7015779273351654e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0876390660996549e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.7186986951855943e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 7.322573765122797e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00018653426377568394
mask_decoder.transformer.layers.1.norm2.bias grad: -8.44393580337055e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.6972571251681075e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.329919127281755e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.085454126354307e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014413869939744473
mask_decoder.transformer.norm_final_attn.weight grad: 7.583799970234395e-07
mask_decoder.transformer.norm_final_attn.bias grad: 3.158657364110695e-06
Text_Embedding_Affine.0.weight grad: 4.022249200374972e-11
Text_Embedding_Affine.0.bias grad: 1.445163100299851e-09
Text_Embedding_Affine.2.weight grad: -1.4254734892471532e-10
Text_Embedding_Affine.2.bias grad: -3.273834227002226e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.436552196155193e-19
Max value: 0.999313235282898
Mean value: 0.08304981142282486

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.436552196155193e-19
Max value: 0.999313235282898
Mean value: 0.08304981142282486

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09362411499023438

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12469489872455597

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07635927200317383

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09362411499023438

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.45405578613281
Max value: 84.66807556152344
Mean value: 65.81813049316406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.90599648331215e-18
Max value: 0.9992793202400208
Mean value: 0.08445064723491669

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.90599648331215e-18
Max value: 0.9992793202400208
Mean value: 0.08445064723491669

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.90599648331215e-18
Max value: 0.9992793202400208
Mean value: 0.08445064723491669

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12354287505149841

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8927833437919617
Max value: 3.065345048904419
Mean value: 1.0014255046844482

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.45405578613281
Max value: 84.66807556152344
Mean value: 65.81813049316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.88050842285156
Max value: -65.88050842285156
Mean value: -65.88050842285156
sam_encoder.pos_embed grad: -1.863502060994726e-11
sam_encoder.blocks.0.norm1.weight grad: 1.9868606614181772e-05
sam_encoder.blocks.0.norm1.bias grad: 3.551973350113258e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0363069072336657e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.494526244045119e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.771976586605888e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.1501732413235e-07
sam_encoder.blocks.0.norm2.weight grad: 2.2847501895739697e-05
sam_encoder.blocks.0.norm2.bias grad: 4.008548330602935e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.597368695793193e-08
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.068453570951533e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.735892616736237e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.068442427116679e-06
sam_encoder.blocks.1.norm1.weight grad: 1.3919229786552023e-05
sam_encoder.blocks.1.norm1.bias grad: -5.810915354231838e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.78812671644846e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1466285059213988e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.9878908662794856e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.6339535022780183e-06
sam_encoder.blocks.1.norm2.weight grad: 1.4291934348875657e-05
sam_encoder.blocks.1.norm2.bias grad: -4.982853170076851e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.737490260391496e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.936533741783933e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.0938745112507604e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.896092230590511e-08
sam_encoder.blocks.2.norm1.weight grad: 4.170434294792358e-06
sam_encoder.blocks.2.norm1.bias grad: -4.630369403457735e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.774033411398705e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0412724549269115e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.414101567817852e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.588305273500737e-06
sam_encoder.blocks.2.norm2.weight grad: -1.074272131518228e-05
sam_encoder.blocks.2.norm2.bias grad: -5.290048648021184e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.186100901890313e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.187380116287386e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.876851787434134e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3290022025103099e-06
sam_encoder.blocks.3.norm1.weight grad: -2.1622540202770324e-07
sam_encoder.blocks.3.norm1.bias grad: -2.831827714544488e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.806650056503713e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2554771444683865e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.742836275298032e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.479260825173697e-07
sam_encoder.blocks.3.norm2.weight grad: 1.4015871784067713e-05
sam_encoder.blocks.3.norm2.bias grad: 6.28295447313576e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2176276868558489e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.093147592560854e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.1666307879495434e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.738884851780313e-07
sam_encoder.blocks.4.norm1.weight grad: 2.1819403173140017e-06
sam_encoder.blocks.4.norm1.bias grad: 6.470244898082456e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.190262004044598e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.492017981443496e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.162084792369569e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.954263535088103e-07
sam_encoder.blocks.4.norm2.weight grad: -2.5870494937407784e-05
sam_encoder.blocks.4.norm2.bias grad: -1.957607310032472e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6529535059817135e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.879455784452148e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.89188972399279e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.091469468723517e-06
sam_encoder.blocks.5.norm1.weight grad: -7.951112820592243e-06
sam_encoder.blocks.5.norm1.bias grad: 4.420845471031498e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.210501619032584e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.939995505992556e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.352797067345819e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.9982983303634683e-06
sam_encoder.blocks.5.norm2.weight grad: -1.7641297745285556e-05
sam_encoder.blocks.5.norm2.bias grad: -9.651672371546738e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.65977347327862e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.146706148982048e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.486138772743288e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.577602226163435e-07
sam_encoder.blocks.6.norm1.weight grad: -4.552885911834892e-06
sam_encoder.blocks.6.norm1.bias grad: 7.78906468212881e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.906359102576971e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.2893531220470322e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.638855676195817e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.2246968594809005e-07
sam_encoder.blocks.6.norm2.weight grad: 7.003435484875808e-07
sam_encoder.blocks.6.norm2.bias grad: 6.469368827310973e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.2434777545422548e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.810513019037899e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.455998810546589e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.087175385502633e-07
sam_encoder.blocks.7.norm1.weight grad: 3.2755269785411656e-07
sam_encoder.blocks.7.norm1.bias grad: 4.563735274132341e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.112183766366797e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.9847802807125845e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.800550985033624e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.5637715478078462e-06
sam_encoder.blocks.7.norm2.weight grad: 1.3682870303455275e-06
sam_encoder.blocks.7.norm2.bias grad: 4.705469507371163e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.900060624393518e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.910163511340215e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5400067923110328e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.597280955451424e-07
sam_encoder.blocks.8.norm1.weight grad: 2.9777766030747443e-06
sam_encoder.blocks.8.norm1.bias grad: -1.5629766494384967e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.277029681063141e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.84120788416476e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.2519350320872036e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.785154932411388e-07
sam_encoder.blocks.8.norm2.weight grad: -1.5844742620174657e-06
sam_encoder.blocks.8.norm2.bias grad: -2.0124132333876332e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.36204891482339e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -8.772666433287668e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.3289131857163738e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1131774044770282e-06
sam_encoder.blocks.9.norm1.weight grad: -3.1791093988431385e-06
sam_encoder.blocks.9.norm1.bias grad: 3.9533915696665645e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.392606575085665e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.587555935131604e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.130671390432326e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.801377475720074e-07
sam_encoder.blocks.9.norm2.weight grad: -4.956142447554157e-07
sam_encoder.blocks.9.norm2.bias grad: -2.1861524146515876e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 9.506711649009958e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.005031198379584e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.7888321934833584e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.5835074047317903e-07
sam_encoder.blocks.10.norm1.weight grad: 1.742369931889698e-06
sam_encoder.blocks.10.norm1.bias grad: 5.182655513635837e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.3079652489977889e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.944765118532814e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.4186775842972565e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0579529998722137e-06
sam_encoder.blocks.10.norm2.weight grad: -2.916613084380515e-06
sam_encoder.blocks.10.norm2.bias grad: -2.6402410640002927e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.634603894577594e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1385559446353e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.380149552067451e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.227141173236305e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1859317964990623e-05
sam_encoder.blocks.11.norm1.bias grad: 3.968555688516062e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.886052889536586e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.132208116265247e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.607795851072297e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.7606054331386076e-08
sam_encoder.blocks.11.norm2.weight grad: -2.586153186712181e-06
sam_encoder.blocks.11.norm2.bias grad: -3.830488637390772e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.858022286200139e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.524358463546378e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7437135966247297e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.877201480572694e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.2960499589098617e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.8065309632220306e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1302390703349374e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.9652022931259125e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00021174346329644322
mask_decoder.transformer.layers.0.norm1.bias grad: -5.404668627306819e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005090952850878239
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0011539148399606347
mask_decoder.transformer.layers.0.norm3.weight grad: -3.892931272275746e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.356520316330716e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00012541220348794013
mask_decoder.transformer.layers.0.norm4.bias grad: -9.990104445023462e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.3959237043745816e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.3515091268345714e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -3.173853474436328e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.280693196458742e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 7.117183849914e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.67456377716735e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.830233127810061e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002203452750109136
mask_decoder.transformer.norm_final_attn.weight grad: 6.363032753142761e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4373730664374307e-05
Text_Embedding_Affine.0.weight grad: 4.5582163044066704e-11
Text_Embedding_Affine.0.bias grad: 1.2448064801162673e-09
Text_Embedding_Affine.2.weight grad: -4.127425484723446e-11
Text_Embedding_Affine.2.bias grad: 7.49475002521649e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1266955250721633e-12
Max value: 0.9979208111763
Mean value: 0.08824842423200607

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1266955250721633e-12
Max value: 0.9979208111763
Mean value: 0.08824842423200607

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08756637573242188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15473929047584534

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07116222381591797

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08756637573242188

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 26.55384635925293
Max value: 66.33772277832031
Mean value: 43.790679931640625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.797516097032055e-12
Max value: 0.9969358444213867
Mean value: 0.09295003861188889

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.797516097032055e-12
Max value: 0.9969358444213867
Mean value: 0.09295003861188889

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.797516097032055e-12
Max value: 0.9969358444213867
Mean value: 0.09295003861188889

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15314733982086182

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8727856278419495
Max value: 4.017141819000244
Mean value: 1.0029289722442627

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 26.55384635925293
Max value: 66.33772277832031
Mean value: 43.790679931640625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -43.79869079589844
Max value: -43.79869079589844
Mean value: -43.79869079589844
sam_encoder.pos_embed grad: -9.489119712213778e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00011222125613130629
sam_encoder.blocks.0.norm1.bias grad: 3.8916456105653197e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -8.714057003089692e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.395615509471099e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.985426577761245e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8060882212012075e-07
sam_encoder.blocks.0.norm2.weight grad: 1.610035906196572e-05
sam_encoder.blocks.0.norm2.bias grad: 5.482938649947755e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.425401023880113e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.773609700554516e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.7851452867034823e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.9563851310522296e-05
sam_encoder.blocks.1.norm1.weight grad: -2.746653262875043e-05
sam_encoder.blocks.1.norm1.bias grad: -8.639550287625752e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.997779458586592e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0479484444658738e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.396922567044385e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.567653038771823e-06
sam_encoder.blocks.1.norm2.weight grad: 1.585597055964172e-05
sam_encoder.blocks.1.norm2.bias grad: -6.574981853191275e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.2022219178034e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.950902515091002e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.091694664675742e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.9817462089122273e-06
sam_encoder.blocks.2.norm1.weight grad: 7.44217868486885e-06
sam_encoder.blocks.2.norm1.bias grad: -9.334998139820527e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.305385911924532e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0725401580202742e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.3424317987519316e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.7234823392063845e-06
sam_encoder.blocks.2.norm2.weight grad: 9.425474672752898e-06
sam_encoder.blocks.2.norm2.bias grad: 7.69113285059575e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.691220733046066e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.1414081200200599e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 7.5994007602275815e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.2631495565074147e-06
sam_encoder.blocks.3.norm1.weight grad: -4.159956006333232e-07
sam_encoder.blocks.3.norm1.bias grad: -5.476192200148944e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.2605041774804704e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.711154014737986e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.373940787947504e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.5146126770559931e-06
sam_encoder.blocks.3.norm2.weight grad: 6.013097845425364e-06
sam_encoder.blocks.3.norm2.bias grad: 7.0958719788905e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.769258339365479e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.146477850663359e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.800598955829628e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.263843831926351e-07
sam_encoder.blocks.4.norm1.weight grad: 2.1171319531276822e-05
sam_encoder.blocks.4.norm1.bias grad: 3.8034338558645686e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1071530025219545e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.036159912677249e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 9.289290574088227e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.76952765590977e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5562443624949083e-05
sam_encoder.blocks.4.norm2.bias grad: -3.727242074091919e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.659163535805419e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.618989911861718e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.6035390899560298e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.734265636827331e-07
sam_encoder.blocks.5.norm1.weight grad: 2.2140286091598682e-05
sam_encoder.blocks.5.norm1.bias grad: -8.948358299676329e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.1765816452680156e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.7263398603972746e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.571579094976187e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.2945204111456405e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1079522664658725e-05
sam_encoder.blocks.5.norm2.bias grad: -1.9059954865952022e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0399133998362231e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.2533256444367e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.254073691205122e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.642242962901946e-07
sam_encoder.blocks.6.norm1.weight grad: 4.526714292296674e-06
sam_encoder.blocks.6.norm1.bias grad: 7.335479949688306e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.8540677046985365e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.1730232308291306e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.165919340768596e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.351421456609387e-07
sam_encoder.blocks.6.norm2.weight grad: -1.2059117580065504e-05
sam_encoder.blocks.6.norm2.bias grad: -9.482553650741465e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0096944606630132e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.3106019802507944e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.2403326599705906e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.365210437143105e-06
sam_encoder.blocks.7.norm1.weight grad: 1.1987242032773793e-05
sam_encoder.blocks.7.norm1.bias grad: 1.7158458831545431e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.486775757570285e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.8004973248462193e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.6971739518776303e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0952717275358737e-06
sam_encoder.blocks.7.norm2.weight grad: 2.36059076996753e-06
sam_encoder.blocks.7.norm2.bias grad: -2.9500140499294503e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.1564886739943177e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.84009547108144e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.1622848837287165e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.8781863673211774e-06
sam_encoder.blocks.8.norm1.weight grad: 7.042867764539551e-06
sam_encoder.blocks.8.norm1.bias grad: -4.417044237925438e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.6707200453965925e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.74191834757221e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.463895947992569e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.8813447013599216e-06
sam_encoder.blocks.8.norm2.weight grad: 3.286083028797293e-06
sam_encoder.blocks.8.norm2.bias grad: -2.097644937748555e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.432922767387936e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.962961843877565e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.843964980707824e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.166861900666845e-07
sam_encoder.blocks.9.norm1.weight grad: 2.975010829686653e-06
sam_encoder.blocks.9.norm1.bias grad: -1.0993942112236255e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.4310775188496336e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.6813876274900394e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.324410269873624e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.523658152626012e-07
sam_encoder.blocks.9.norm2.weight grad: 6.4881569414865226e-06
sam_encoder.blocks.9.norm2.bias grad: -4.435883056430612e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.272282239980996e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.3024198273778893e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.487772796186619e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.285215820549638e-07
sam_encoder.blocks.10.norm1.weight grad: 6.336464139167219e-06
sam_encoder.blocks.10.norm1.bias grad: 1.5951209206832573e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.865722192131216e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.4087885347180418e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.3139234599511838e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.196569526968233e-07
sam_encoder.blocks.10.norm2.weight grad: 1.1912361514987424e-05
sam_encoder.blocks.10.norm2.bias grad: -3.2435613661618845e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.23984806225053e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.835310053545982e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.22192966248258e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.514783651960897e-07
sam_encoder.blocks.11.norm1.weight grad: 2.4743107132962905e-05
sam_encoder.blocks.11.norm1.bias grad: 2.126742174368701e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.4537966964999214e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.650884761758789e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.3293263186351396e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.605585091776447e-07
sam_encoder.blocks.11.norm2.weight grad: 5.7821957852866035e-06
sam_encoder.blocks.11.norm2.bias grad: -6.13539555160969e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.011313416820485e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.11297822513734e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4015722626936622e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.409311150586291e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.46098521631211e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.636760761262849e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.533251972636208e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.5400392739102244e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 5.5271750170504674e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.539833076298237e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003956409636884928
mask_decoder.transformer.layers.0.norm2.bias grad: -0.001338796690106392
mask_decoder.transformer.layers.0.norm3.weight grad: -3.636681867646985e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -9.449259960092604e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.86828381428495e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0941985237877816e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.9354967662366107e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 7.004481631156523e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00020244618644937873
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00013099325587972999
mask_decoder.transformer.layers.1.norm3.weight grad: 2.710155058593955e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -4.304153117118403e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.053936522221193e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002215192944277078
mask_decoder.transformer.norm_final_attn.weight grad: -5.036021661908308e-07
mask_decoder.transformer.norm_final_attn.bias grad: 2.200473318225704e-06
Text_Embedding_Affine.0.weight grad: 4.8980090816552746e-11
Text_Embedding_Affine.0.bias grad: 1.558182582961365e-09
Text_Embedding_Affine.2.weight grad: -2.2120590081886604e-10
Text_Embedding_Affine.2.bias grad: -5.206748028285801e-06
Epoch 16 finished with average loss: -55.9581
Epoch 17/39
----------
Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-56]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-59.8]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-59.8]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-58.9]Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.20it/s, loss=-58.9]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.10714317773228e-14
Max value: 0.9998190999031067
Mean value: 0.07881206274032593

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.10714317773228e-14
Max value: 0.9998190999031067
Mean value: 0.07881206274032593

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0797266960144043

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11504487693309784

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06529569625854492

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0797266960144043

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 30.080692291259766
Max value: 76.14707946777344
Mean value: 55.97684097290039

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.10714317773228e-14
Max value: 0.9998190999031067
Mean value: 0.07881206274032593

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.10714317773228e-14
Max value: 0.9998190999031067
Mean value: 0.07881206274032593

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.10714317773228e-14
Max value: 0.9998190999031067
Mean value: 0.07881206274032593

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11504487693309784

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 30.080692291259766
Max value: 76.14707946777344
Mean value: 55.97684097290039

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.97806930541992
Max value: -55.97806930541992
Mean value: -55.97806930541992
sam_encoder.pos_embed grad: 8.803743151153398e-11
sam_encoder.blocks.0.norm1.weight grad: 1.0878163266170304e-05
sam_encoder.blocks.0.norm1.bias grad: 1.8698519852478057e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.249294084322173e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.03157958619704e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.000335815770086e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.348308036445815e-07
sam_encoder.blocks.0.norm2.weight grad: 4.2642085418265196e-07
sam_encoder.blocks.0.norm2.bias grad: 2.312830474693328e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.709741238504648e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.108514415042009e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.514967945899116e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.0309584013157291e-06
sam_encoder.blocks.1.norm1.weight grad: -7.132182417990407e-06
sam_encoder.blocks.1.norm1.bias grad: 4.385553893371252e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.7980564734898508e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.2682041134203246e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.56578367347538e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.9394244077375333e-07
sam_encoder.blocks.1.norm2.weight grad: -8.800790055829566e-06
sam_encoder.blocks.1.norm2.bias grad: -7.031453606032301e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.3695314414217137e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.0632591056491947e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.084493975322403e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3473315618739434e-07
sam_encoder.blocks.2.norm1.weight grad: -3.5191351344110444e-06
sam_encoder.blocks.2.norm1.bias grad: 1.0735069508882589e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.6159954106551595e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.372896450557164e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.052997842838522e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.392524589202367e-07
sam_encoder.blocks.2.norm2.weight grad: 5.527308076125337e-06
sam_encoder.blocks.2.norm2.bias grad: -9.402522664458957e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.14837177231675e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.439667110200389e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.7705218624541885e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0206129985590451e-07
sam_encoder.blocks.3.norm1.weight grad: 1.0036325875262264e-05
sam_encoder.blocks.3.norm1.bias grad: 4.886028364126105e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.2384339142008685e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.5177755585682462e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.827402098177117e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.159505927716964e-06
sam_encoder.blocks.3.norm2.weight grad: -8.878875519258145e-07
sam_encoder.blocks.3.norm2.bias grad: -6.547017164848512e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.1570756416622316e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -8.040710213208513e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.3760139811201952e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.523078646594513e-07
sam_encoder.blocks.4.norm1.weight grad: 6.905694135639351e-06
sam_encoder.blocks.4.norm1.bias grad: 6.158204541861778e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.051814696344081e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.713630788610317e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.1344839094817871e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.418759082611359e-07
sam_encoder.blocks.4.norm2.weight grad: -2.8938382001797436e-07
sam_encoder.blocks.4.norm2.bias grad: 5.586588486039545e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.3066567084460985e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 6.1594583655733e-08
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.759071437845705e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.56601707507798e-07
sam_encoder.blocks.5.norm1.weight grad: 3.8358516576408874e-06
sam_encoder.blocks.5.norm1.bias grad: -3.051257181141409e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.938798494753428e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.2984932002145797e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.59915081971485e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.676764823827398e-08
sam_encoder.blocks.5.norm2.weight grad: 2.8562797069753287e-06
sam_encoder.blocks.5.norm2.bias grad: 3.1526847124041524e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.0508650660767671e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.2275277678527345e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.837509201635839e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.111930469567596e-07
sam_encoder.blocks.6.norm1.weight grad: 6.934062071195513e-07
sam_encoder.blocks.6.norm1.bias grad: -1.7095305793191073e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.6051857301135897e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4995752053437172e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.4315246466576355e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.922508989897324e-07
sam_encoder.blocks.6.norm2.weight grad: 8.395110171477427e-07
sam_encoder.blocks.6.norm2.bias grad: 2.559107770139235e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3705706791711236e-08
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.7640847715938435e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.257797180187481e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.155985031204182e-07
sam_encoder.blocks.7.norm1.weight grad: -2.518117753425031e-06
sam_encoder.blocks.7.norm1.bias grad: -9.216614103024767e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.6084936760307755e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.524039584590355e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.633048668736592e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.9935525819601025e-07
sam_encoder.blocks.7.norm2.weight grad: -3.897835540556116e-06
sam_encoder.blocks.7.norm2.bias grad: 2.3017477701614553e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.097040462307632e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.9222973151045153e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.957124807944638e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.293388080142904e-07
sam_encoder.blocks.8.norm1.weight grad: 1.8114873228114448e-06
sam_encoder.blocks.8.norm1.bias grad: 8.574349408263515e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.287356776127126e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.4451943570747972e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.296397939171584e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.1583265404624399e-06
sam_encoder.blocks.8.norm2.weight grad: -2.0613392734958325e-06
sam_encoder.blocks.8.norm2.bias grad: 7.991422421582683e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.343659045640379e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.6858234630490188e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.042671998329752e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.7854185330179462e-07
sam_encoder.blocks.9.norm1.weight grad: -1.3798779718854348e-06
sam_encoder.blocks.9.norm1.bias grad: -8.062570486799814e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.722302714479156e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.5125268646443146e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.536558091989718e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.690334768994944e-08
sam_encoder.blocks.9.norm2.weight grad: -9.150553523795679e-07
sam_encoder.blocks.9.norm2.bias grad: 6.590476004930679e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.881948151094548e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.99078725574509e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.219388973884634e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.800015401291603e-07
sam_encoder.blocks.10.norm1.weight grad: -3.0310234251373913e-06
sam_encoder.blocks.10.norm1.bias grad: 3.4579898056108505e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.8314698283793405e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.068168558049365e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1096406069555087e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.589816052837705e-07
sam_encoder.blocks.10.norm2.weight grad: 9.679142465301993e-08
sam_encoder.blocks.10.norm2.bias grad: 7.182524086601916e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.284402401324769e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.823566944698541e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.1723191164492164e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.080636924503779e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0206777005805634e-05
sam_encoder.blocks.11.norm1.bias grad: 7.335993359447457e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.717276518320432e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.275729199003763e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.946667786498438e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.2835174579304294e-07
sam_encoder.blocks.11.norm2.weight grad: 1.6434098597528646e-06
sam_encoder.blocks.11.norm2.bias grad: -4.3785654213479575e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.2478440112317912e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.340820325410277e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.4162900470182649e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.252056780591374e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.862143446691334e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.1104059012723155e-05
sam_encoder.neck.conv2.trainable_scale grad: 5.157874056749279e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.8437625587685034e-07
mask_decoder.transformer.layers.0.norm1.weight grad: 8.552868530387059e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.3725442588329315e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005302755162119865
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003821635036729276
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00013361933815758675
mask_decoder.transformer.layers.0.norm3.bias grad: -2.061373379547149e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011694980639731511
mask_decoder.transformer.layers.0.norm4.bias grad: 7.313463811442489e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.754787030629814e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2561049516079947e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.9206334400223568e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -7.568182627437636e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.862934242235497e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.536601772997528e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.7813537851907313e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001512184098828584
mask_decoder.transformer.norm_final_attn.weight grad: -2.2587541934626643e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2923146641696803e-05
Text_Embedding_Affine.0.weight grad: 6.358237721049154e-12
Text_Embedding_Affine.0.bias grad: -2.959296696580793e-11
Text_Embedding_Affine.2.weight grad: -6.916331223016936e-12
Text_Embedding_Affine.2.bias grad: -1.952673301275354e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0865123886746915e-16
Max value: 0.9997807145118713
Mean value: 0.1034102663397789

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0865123886746915e-16
Max value: 0.9997807145118713
Mean value: 0.1034102663397789

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09241294860839844

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13017868995666504

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09689760208129883

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09241294860839844

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 49.84264373779297
Max value: 86.60276794433594
Mean value: 63.70915222167969

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.419243939739745e-17
Max value: 0.9998446702957153
Mean value: 0.10371898114681244

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.419243939739745e-17
Max value: 0.9998446702957153
Mean value: 0.10371898114681244

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.419243939739745e-17
Max value: 0.9998446702957153
Mean value: 0.10371898114681244

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13044282793998718

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.59546959400177
Max value: 2.305401086807251
Mean value: 0.9997757077217102

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 49.84264373779297
Max value: 86.60276794433594
Mean value: 63.70915222167969

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.6956672668457
Max value: -63.6956672668457
Mean value: -63.6956672668457
sam_encoder.pos_embed grad: 3.299070738815857e-10
sam_encoder.blocks.0.norm1.weight grad: 6.725899584125727e-05
sam_encoder.blocks.0.norm1.bias grad: -7.109711987141054e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.575666030679713e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.491916882898295e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -9.143913302978035e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.3234629225044046e-06
sam_encoder.blocks.0.norm2.weight grad: 1.7096055671572685e-05
sam_encoder.blocks.0.norm2.bias grad: 5.720015906263143e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.715288458915893e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.055703695688862e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.7915339185492485e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.795523065899033e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2347945812507533e-05
sam_encoder.blocks.1.norm1.bias grad: 2.142905486834934e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.276018338103313e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.501877247595985e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.4606219994893763e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.356500392712405e-08
sam_encoder.blocks.1.norm2.weight grad: -1.3814293197356164e-05
sam_encoder.blocks.1.norm2.bias grad: -3.373533900230541e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.977328328299336e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.298070153818117e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.550940047920449e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.616800641902955e-07
sam_encoder.blocks.2.norm1.weight grad: -6.125964773673331e-06
sam_encoder.blocks.2.norm1.bias grad: -1.932975465024356e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.9501711651391815e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.512018788067508e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.1500615073600784e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0799606116052018e-06
sam_encoder.blocks.2.norm2.weight grad: 1.5468311175936833e-05
sam_encoder.blocks.2.norm2.bias grad: -1.4047323020349722e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.905902409926057e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.2085267775983084e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1596879403441562e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.5976549384031387e-07
sam_encoder.blocks.3.norm1.weight grad: 9.678131391410716e-06
sam_encoder.blocks.3.norm1.bias grad: 5.280471668811515e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.0138205652765464e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.4988111161073903e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.982402631663717e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.0568230379703891e-07
sam_encoder.blocks.3.norm2.weight grad: 2.587645894891466e-06
sam_encoder.blocks.3.norm2.bias grad: -1.3189826859161258e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1136637567688012e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.258109700254863e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.272760068284697e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8386603528597334e-07
sam_encoder.blocks.4.norm1.weight grad: 1.1525257832545321e-05
sam_encoder.blocks.4.norm1.bias grad: -1.090159457817208e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.826249551115325e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.3894255062041339e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4372196801559767e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.0632716061518295e-06
sam_encoder.blocks.4.norm2.weight grad: 2.124647653545253e-05
sam_encoder.blocks.4.norm2.bias grad: 2.717113375183544e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.187108409794746e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.5991452023154125e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1247997210593894e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.0622394458769122e-06
sam_encoder.blocks.5.norm1.weight grad: 1.1620395525824279e-05
sam_encoder.blocks.5.norm1.bias grad: -1.1568909030756913e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.94356492406223e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.681427748844726e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.749353598119342e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.2935643098899163e-06
sam_encoder.blocks.5.norm2.weight grad: 2.3099963073036633e-05
sam_encoder.blocks.5.norm2.bias grad: 7.534382802987238e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.2897093256469816e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.39715892955428e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.0469286684819963e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.3465087249642238e-06
sam_encoder.blocks.6.norm1.weight grad: -4.323174835008103e-06
sam_encoder.blocks.6.norm1.bias grad: 3.5123943575854355e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.4462933652102947e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.916702481405082e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.1613616354443366e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.7564607333042659e-06
sam_encoder.blocks.6.norm2.weight grad: -8.385017054024502e-07
sam_encoder.blocks.6.norm2.bias grad: -9.222779908668599e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.7538744689081796e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.2055445495207096e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.479220256645931e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.854049274807039e-07
sam_encoder.blocks.7.norm1.weight grad: -1.2105442692700308e-07
sam_encoder.blocks.7.norm1.bias grad: -5.473544888445758e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.3541418866225285e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.321479423197161e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.109068865749578e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.2048866412660573e-06
sam_encoder.blocks.7.norm2.weight grad: 1.6310323189827614e-06
sam_encoder.blocks.7.norm2.bias grad: 7.621945030678035e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.425730710659991e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.359487194160465e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.8630089471116662e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.5987708340835525e-07
sam_encoder.blocks.8.norm1.weight grad: 1.2769085060426733e-06
sam_encoder.blocks.8.norm1.bias grad: 3.096984073636122e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.040718860982452e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.6444356535648694e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.6511714875377947e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.6558900597374304e-06
sam_encoder.blocks.8.norm2.weight grad: 8.049308235058561e-06
sam_encoder.blocks.8.norm2.bias grad: 5.176493687031325e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.478749360714573e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.9962252483528573e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.7397286430641543e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.2488228549045743e-06
sam_encoder.blocks.9.norm1.weight grad: 1.706045622995589e-06
sam_encoder.blocks.9.norm1.bias grad: -1.6513013179064728e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.6570940886140306e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.126639166519453e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.851372246619576e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.3068665793980472e-06
sam_encoder.blocks.9.norm2.weight grad: 5.20075036547496e-06
sam_encoder.blocks.9.norm2.bias grad: 5.066863195679616e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.5676776001782855e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.194674834754551e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.042776602844242e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.83839607770642e-07
sam_encoder.blocks.10.norm1.weight grad: -5.258731107460335e-06
sam_encoder.blocks.10.norm1.bias grad: -1.2248900702616083e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.711349336299463e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.4028773875907063e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.3400525606120937e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.4009747246745974e-06
sam_encoder.blocks.10.norm2.weight grad: 4.166803137195529e-06
sam_encoder.blocks.10.norm2.bias grad: 5.333116860128939e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.6522944861208089e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.657639914919855e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.374110401135113e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.388841432501067e-07
sam_encoder.blocks.11.norm1.weight grad: -7.173127869464224e-06
sam_encoder.blocks.11.norm1.bias grad: -7.050797279362087e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.3034635887597688e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.476475391536951e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.8412706026538217e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.39714721476048e-07
sam_encoder.blocks.11.norm2.weight grad: 1.3839252460456919e-05
sam_encoder.blocks.11.norm2.bias grad: 5.224822416494135e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.129420974801178e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.9014991014264524e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.4199993024230935e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.8073700402965187e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.968297849292867e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.630438600841444e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.963952283607796e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.3821811484813225e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0002713740977924317
mask_decoder.transformer.layers.0.norm1.bias grad: 8.303995855385438e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002698372583836317
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0014764309162274003
mask_decoder.transformer.layers.0.norm3.weight grad: 1.746589259710163e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.0130358936730772e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001516344927949831
mask_decoder.transformer.layers.0.norm4.bias grad: 1.905357203213498e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -8.949709808803163e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.7422660170705058e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00010048577678389847
mask_decoder.transformer.layers.1.norm2.bias grad: 6.775902875233442e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.8998774723731913e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.45596560894046e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -4.316325794206932e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 9.671541192801669e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.196717559854733e-06
mask_decoder.transformer.norm_final_attn.bias grad: -2.020193642238155e-05
Text_Embedding_Affine.0.weight grad: -1.1370709929181544e-11
Text_Embedding_Affine.0.bias grad: 3.247505597769873e-10
Text_Embedding_Affine.2.weight grad: -1.1368854468951639e-10
Text_Embedding_Affine.2.bias grad: -9.616707393433899e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6182519693995765e-12
Max value: 0.9998562335968018
Mean value: 0.07199817895889282

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6182519693995765e-12
Max value: 0.9998562335968018
Mean value: 0.07199817895889282

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07330608367919922

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11396927386522293

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06118488311767578

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07330608367919922

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.03546142578125
Max value: 59.06946563720703
Mean value: 57.10236358642578

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.070034681861399e-12
Max value: 0.9998227953910828
Mean value: 0.0727129727602005

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.070034681861399e-12
Max value: 0.9998227953910828
Mean value: 0.0727129727602005

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.070034681861399e-12
Max value: 0.9998227953910828
Mean value: 0.0727129727602005

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11306197941303253

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7147598266601562
Max value: 1.7328583002090454
Mean value: 1.0010058879852295

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.03546142578125
Max value: 59.06946563720703
Mean value: 57.10236358642578

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.156532287597656
Max value: -57.156532287597656
Mean value: -57.156532287597656
sam_encoder.pos_embed grad: 3.984480745344854e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00010076331091113389
sam_encoder.blocks.0.norm1.bias grad: 1.856067137850914e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.538959041790804e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.788224370917305e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.877574949408881e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.0845504877797794e-06
sam_encoder.blocks.0.norm2.weight grad: 5.060428520664573e-05
sam_encoder.blocks.0.norm2.bias grad: -4.481995347305201e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.260213270550594e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.0816824214998633e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.07000757654896e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.442040780209936e-06
sam_encoder.blocks.1.norm1.weight grad: 2.2020674805389717e-05
sam_encoder.blocks.1.norm1.bias grad: 1.3928768566984218e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.709771802590694e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.829144705174258e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.968865015252959e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.787687885254854e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0353502148063853e-05
sam_encoder.blocks.1.norm2.bias grad: 6.051333457435248e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.6178988100109564e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.208332822803641e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.5449197235284373e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.619202288973611e-07
sam_encoder.blocks.2.norm1.weight grad: -1.9876661099260673e-05
sam_encoder.blocks.2.norm1.bias grad: 1.0043646398116834e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.507751403551083e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.533967396331718e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.238192443357548e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.905320333316922e-06
sam_encoder.blocks.2.norm2.weight grad: -1.192268064187374e-05
sam_encoder.blocks.2.norm2.bias grad: 3.8221128306759056e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0328787539037876e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.1561879748333013e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1850692317239009e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.093229553196579e-07
sam_encoder.blocks.3.norm1.weight grad: -3.2314190320903435e-05
sam_encoder.blocks.3.norm1.bias grad: 1.0063718036690261e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.2655829777941108e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.7858511657541385e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.253127488278551e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.4252977861324325e-06
sam_encoder.blocks.3.norm2.weight grad: -1.2499981494329404e-05
sam_encoder.blocks.3.norm2.bias grad: 4.652974894270301e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.729627562483074e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.921993076502986e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.235311164142331e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.927489266672637e-07
sam_encoder.blocks.4.norm1.weight grad: -1.8787089857141837e-06
sam_encoder.blocks.4.norm1.bias grad: -3.714442527780193e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.5768513296497986e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.0785695394588402e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.894820904155495e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.321926098782569e-06
sam_encoder.blocks.4.norm2.weight grad: 1.8934759282274172e-05
sam_encoder.blocks.4.norm2.bias grad: 4.184448698651977e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 8.315286322613247e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.8001629743812373e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.171650172997033e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.1630418157437816e-06
sam_encoder.blocks.5.norm1.weight grad: 7.009600722085452e-06
sam_encoder.blocks.5.norm1.bias grad: 4.523265488387551e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.162154512712732e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.6623379199008923e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.5040835705804056e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.197165530214988e-08
sam_encoder.blocks.5.norm2.weight grad: 8.627876923128497e-06
sam_encoder.blocks.5.norm2.bias grad: -2.188746748288395e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.8199036705700564e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.213335790202109e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.959580231414293e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.229254717662116e-07
sam_encoder.blocks.6.norm1.weight grad: -1.1822089618362952e-06
sam_encoder.blocks.6.norm1.bias grad: 3.872598313137132e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.889500476361718e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.012507931998698e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.644779778573138e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.793498078470293e-07
sam_encoder.blocks.6.norm2.weight grad: 9.203528861689847e-06
sam_encoder.blocks.6.norm2.bias grad: 2.0603538359864615e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.5392808968026657e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.993665238042013e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7944702790373412e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.433412194273842e-06
sam_encoder.blocks.7.norm1.weight grad: 2.0775050870724954e-06
sam_encoder.blocks.7.norm1.bias grad: -1.7308905171375955e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.4353706723777577e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6038692365327734e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.685654625471216e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 9.884292921924498e-07
sam_encoder.blocks.7.norm2.weight grad: 1.188974692922784e-06
sam_encoder.blocks.7.norm2.bias grad: 2.0260738864408268e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.027044959300838e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.937628652143758e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.252341002735193e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.1171823643962853e-07
sam_encoder.blocks.8.norm1.weight grad: -6.708780347253196e-06
sam_encoder.blocks.8.norm1.bias grad: 1.2254923831278575e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.8997847064383677e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.152064990303188e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.1033674784121104e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5572435358990333e-06
sam_encoder.blocks.8.norm2.weight grad: -5.721099114452954e-06
sam_encoder.blocks.8.norm2.bias grad: 1.4989240071372478e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.752882654836867e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.971190380980261e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.873726993537275e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.3530791420635069e-06
sam_encoder.blocks.9.norm1.weight grad: -5.053872698113082e-08
sam_encoder.blocks.9.norm1.bias grad: 1.1751853890018538e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.723656605980068e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.307171922046109e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.089388880856859e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.736989929668198e-07
sam_encoder.blocks.9.norm2.weight grad: -4.162809091212694e-06
sam_encoder.blocks.9.norm2.bias grad: 6.782149739592569e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.751131877535954e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.4834765756386332e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.514889956728439e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.769108923914246e-08
sam_encoder.blocks.10.norm1.weight grad: -1.2061623237968888e-06
sam_encoder.blocks.10.norm1.bias grad: -9.596448080628761e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.5477211263714707e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.54233428274165e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.466157280257903e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.387758506003593e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0538926289882511e-05
sam_encoder.blocks.10.norm2.bias grad: -1.6097967545647407e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.538517820648849e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.394415554997977e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.062729208773817e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.078661378225661e-08
sam_encoder.blocks.11.norm1.weight grad: -2.6629501007846557e-05
sam_encoder.blocks.11.norm1.bias grad: -2.3247239369084127e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.660849531821441e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.5293966245953925e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.004220732487738e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.53169183301361e-07
sam_encoder.blocks.11.norm2.weight grad: -2.156234040739946e-05
sam_encoder.blocks.11.norm2.bias grad: -3.7713077745138435e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.068054062779993e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.502799583860906e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.9331649784580804e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.327264499195735e-06
sam_encoder.neck.conv1.trainable_scale grad: -4.376488504931331e-09
sam_encoder.neck.conv1.trainable_shift grad: 2.1008363546570763e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.0513940651435405e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.66793826490175e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019537864136509597
mask_decoder.transformer.layers.0.norm1.bias grad: -1.57160684466362e-09
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0037224036641418934
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0013427991652861238
mask_decoder.transformer.layers.0.norm3.weight grad: 3.322292468510568e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.8037407901138067e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.790956391952932e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.223988121841103e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 1.0323292372049764e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.0665655685879756e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.62356222467497e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.1606311090872623e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.079947393620387e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.30871966475388e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 6.229527207324281e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00020217968267388642
mask_decoder.transformer.norm_final_attn.weight grad: 4.728714429802494e-06
mask_decoder.transformer.norm_final_attn.bias grad: -7.290187113540014e-06
Text_Embedding_Affine.0.weight grad: 5.031248855036363e-12
Text_Embedding_Affine.0.bias grad: 8.324291811412365e-10
Text_Embedding_Affine.2.weight grad: 4.443171872092755e-11
Text_Embedding_Affine.2.bias grad: 2.180604133172892e-05
Epoch 17 finished with average loss: -58.9434
Epoch 18/39
----------
Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.5]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-59.5]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-58.4]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-58.4]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-59]  Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-59]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.434496488490733e-16
Max value: 0.9984153509140015
Mean value: 0.0852464810013771

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.434496488490733e-16
Max value: 0.9984153509140015
Mean value: 0.0852464810013771

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08019590377807617

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11858122050762177

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0751500129699707

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08019590377807617

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.39762878417969
Max value: 75.83744812011719
Mean value: 59.513404846191406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.434496488490733e-16
Max value: 0.9984153509140015
Mean value: 0.0852464810013771

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.434496488490733e-16
Max value: 0.9984153509140015
Mean value: 0.0852464810013771

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.434496488490733e-16
Max value: 0.9984153509140015
Mean value: 0.0852464810013771

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11858122050762177

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.39762878417969
Max value: 75.83744812011719
Mean value: 59.513404846191406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.51462936401367
Max value: -59.51462936401367
Mean value: -59.51462936401367
sam_encoder.pos_embed grad: -3.4647136271104273e-09
sam_encoder.blocks.0.norm1.weight grad: 6.587349344044924e-05
sam_encoder.blocks.0.norm1.bias grad: 5.01283193443669e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.0759225915535353e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.643769327434711e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.4113445558905369e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.1171861135371728e-06
sam_encoder.blocks.0.norm2.weight grad: 2.370028778386768e-05
sam_encoder.blocks.0.norm2.bias grad: -1.4764423212909605e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.247712114301976e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.2703625316135003e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.2790143702877685e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.7396852146921447e-06
sam_encoder.blocks.1.norm1.weight grad: -2.786389586617588e-06
sam_encoder.blocks.1.norm1.bias grad: 7.779938641760964e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.8460862065694528e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.6136767726493417e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.5419457162788603e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.3110978872864507e-06
sam_encoder.blocks.1.norm2.weight grad: -1.682437869021669e-06
sam_encoder.blocks.1.norm2.bias grad: 2.1539904082601424e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3350577319215517e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.193083888523688e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0798665243783034e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.2192079995875247e-06
sam_encoder.blocks.2.norm1.weight grad: -4.904703473584959e-06
sam_encoder.blocks.2.norm1.bias grad: -2.9877246561227366e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.678862286615185e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.8277119312747345e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.394819595494482e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.05654419005441e-06
sam_encoder.blocks.2.norm2.weight grad: 3.506965867927647e-06
sam_encoder.blocks.2.norm2.bias grad: -6.056226993678138e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.727246965150698e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.666994470881036e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.664809577865526e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5036564491310855e-06
sam_encoder.blocks.3.norm1.weight grad: -3.220786084057181e-06
sam_encoder.blocks.3.norm1.bias grad: 1.591954855939548e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.3020097513799556e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.7448869584768545e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.0152849629084812e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.9851459001074545e-06
sam_encoder.blocks.3.norm2.weight grad: 7.364194516412681e-06
sam_encoder.blocks.3.norm2.bias grad: -4.439679742063163e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.0589638956589624e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 8.346938784598024e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.1096315069589764e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.668818847785587e-07
sam_encoder.blocks.4.norm1.weight grad: -2.565104068708024e-06
sam_encoder.blocks.4.norm1.bias grad: -2.768552349152742e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.914710643788567e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5834643818379845e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2027207674236706e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.986441232787911e-07
sam_encoder.blocks.4.norm2.weight grad: -1.8327682482777163e-05
sam_encoder.blocks.4.norm2.bias grad: -1.1690330211422406e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.2818411050830036e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.332031494413968e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.5652041674438806e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.2645706110324682e-07
sam_encoder.blocks.5.norm1.weight grad: 9.194912991006277e-07
sam_encoder.blocks.5.norm1.bias grad: -6.510517323476961e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.759995585525758e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.098838765756227e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.6995620575908106e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.902655071717163e-06
sam_encoder.blocks.5.norm2.weight grad: -7.303673555725254e-06
sam_encoder.blocks.5.norm2.bias grad: -9.70713244896615e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.468869065021863e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6341898572136415e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.011998049056274e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6834017912970012e-07
sam_encoder.blocks.6.norm1.weight grad: -2.235304236819502e-06
sam_encoder.blocks.6.norm1.bias grad: -1.2182450745967799e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.7810582398378756e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.2718932629904884e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.700896513691987e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.760293847994035e-07
sam_encoder.blocks.6.norm2.weight grad: -4.478999471757561e-06
sam_encoder.blocks.6.norm2.bias grad: -5.776435045845574e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.924897100660019e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.6504468476341572e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4684541156384512e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0437229864000983e-07
sam_encoder.blocks.7.norm1.weight grad: 5.606968898064224e-06
sam_encoder.blocks.7.norm1.bias grad: -8.688793968758546e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.408342990951496e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.7239651697309455e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3798620557281538e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.1598709736281307e-06
sam_encoder.blocks.7.norm2.weight grad: 2.0080487956875004e-06
sam_encoder.blocks.7.norm2.bias grad: 1.915233724503196e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.735593627927301e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.150912621345924e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.595879777800292e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.128810016685748e-07
sam_encoder.blocks.8.norm1.weight grad: 2.493962711014319e-06
sam_encoder.blocks.8.norm1.bias grad: -2.7245846467849333e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.17985416384181e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.9204317140975036e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3129165381542407e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5165128388616722e-06
sam_encoder.blocks.8.norm2.weight grad: 4.66516303276876e-06
sam_encoder.blocks.8.norm2.bias grad: -8.200405545721878e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.490133738319855e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2903424249088857e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.1297696573819849e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.0552704310384797e-07
sam_encoder.blocks.9.norm1.weight grad: -1.910664650495164e-06
sam_encoder.blocks.9.norm1.bias grad: 9.285483315579768e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.755483365035616e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.935253178293351e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.392580070903932e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.113947291742079e-06
sam_encoder.blocks.9.norm2.weight grad: 4.3917534640058875e-06
sam_encoder.blocks.9.norm2.bias grad: 7.893274300840858e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.471670086379163e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.288442945224233e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.78482605406316e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.084909500714275e-07
sam_encoder.blocks.10.norm1.weight grad: -2.5319216092611896e-06
sam_encoder.blocks.10.norm1.bias grad: 1.452468495699577e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.008097908401396e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.865666282048096e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.491916231723735e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.4459076775638096e-07
sam_encoder.blocks.10.norm2.weight grad: 2.502775714674499e-06
sam_encoder.blocks.10.norm2.bias grad: 1.140106178354472e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.2309797057241667e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.686677132463956e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.0586398957457277e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.3082788186125072e-08
sam_encoder.blocks.11.norm1.weight grad: 1.0252908850816311e-06
sam_encoder.blocks.11.norm1.bias grad: 1.3375524758885149e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -9.119694368564524e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.224085033565643e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.287289812054951e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.293324750217266e-10
sam_encoder.blocks.11.norm2.weight grad: 9.537364348943811e-06
sam_encoder.blocks.11.norm2.bias grad: -1.830205746955471e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.667790562962182e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.100759845940047e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.9544438600860303e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0139349342352943e-06
sam_encoder.neck.conv1.trainable_scale grad: 3.156219463562593e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.9655087726277998e-06
sam_encoder.neck.conv2.trainable_scale grad: 8.186798368114978e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.1759633455076255e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00015968206571415067
mask_decoder.transformer.layers.0.norm1.bias grad: 3.0549053917638958e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004190834239125252
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0011703850468620658
mask_decoder.transformer.layers.0.norm3.weight grad: -4.2925821617245674e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.845737981260754e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 3.16699588438496e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.4590785768814385e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.048309685662389e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.5997266018530354e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00011829609866254032
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00012926285853609443
mask_decoder.transformer.layers.1.norm3.weight grad: 4.103546234546229e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.0263006414752454e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.205006113508716e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -9.757949010236189e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.021175628731726e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.393815523442754e-06
Text_Embedding_Affine.0.weight grad: -3.1068836739422956e-12
Text_Embedding_Affine.0.bias grad: 1.7586079814613242e-10
Text_Embedding_Affine.2.weight grad: 3.22024351628869e-11
Text_Embedding_Affine.2.bias grad: -5.724059883505106e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6965429712120783e-12
Max value: 0.9986421465873718
Mean value: 0.09198223054409027

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6965429712120783e-12
Max value: 0.9986421465873718
Mean value: 0.09198223054409027

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09208202362060547

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12659719586372375

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08461427688598633

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09208202362060547

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.235504150390625
Max value: 71.1806869506836
Mean value: 57.17090606689453

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1906360229338442e-12
Max value: 0.9987894892692566
Mean value: 0.0922495424747467

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1906360229338442e-12
Max value: 0.9987894892692566
Mean value: 0.0922495424747467

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1906360229338442e-12
Max value: 0.9987894892692566
Mean value: 0.0922495424747467

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12637709081172943

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6879279613494873
Max value: 1.1596840620040894
Mean value: 1.0002515316009521

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.235504150390625
Max value: 71.1806869506836
Mean value: 57.17090606689453

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.185855865478516
Max value: -57.185855865478516
Mean value: -57.185855865478516
sam_encoder.pos_embed grad: -7.977577709539219e-09
sam_encoder.blocks.0.norm1.weight grad: -3.407639087527059e-05
sam_encoder.blocks.0.norm1.bias grad: -1.9991955923615023e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -8.893532594811404e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8595756046124734e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.0885562460316578e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.643656787564396e-06
sam_encoder.blocks.0.norm2.weight grad: 3.5651806683745235e-05
sam_encoder.blocks.0.norm2.bias grad: 3.0357941795955412e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.617124212316412e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.073014684356167e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.321282863704255e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.258930741547374e-06
sam_encoder.blocks.1.norm1.weight grad: -8.581278052588459e-07
sam_encoder.blocks.1.norm1.bias grad: 9.796718586585484e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.079030185901502e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.2123211945436196e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.2025788009850658e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.2508524466502422e-07
sam_encoder.blocks.1.norm2.weight grad: -7.162810561567312e-06
sam_encoder.blocks.1.norm2.bias grad: -4.1351694335389766e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.784355951414909e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.322727242353722e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.7372562878299505e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2863150686825975e-06
sam_encoder.blocks.2.norm1.weight grad: 4.208604877931066e-07
sam_encoder.blocks.2.norm1.bias grad: -1.5824798538233154e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.25131026102099e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.1879861716579398e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.877099399891449e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 9.408792038811953e-07
sam_encoder.blocks.2.norm2.weight grad: -1.6378847931264318e-06
sam_encoder.blocks.2.norm2.bias grad: 1.8665127754502464e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.4375332234048983e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.919601779984077e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.5544226243946468e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.127229319943581e-07
sam_encoder.blocks.3.norm1.weight grad: 9.995577784138732e-06
sam_encoder.blocks.3.norm1.bias grad: -3.1246995604305994e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.0529680366744287e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.8653489632924902e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.952848601329606e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.778590899448318e-06
sam_encoder.blocks.3.norm2.weight grad: -7.810354873072356e-06
sam_encoder.blocks.3.norm2.bias grad: 1.4339691915665753e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.3082744670973625e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.7026753741665743e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.933491487056017e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.284800863591954e-08
sam_encoder.blocks.4.norm1.weight grad: 5.035057256463915e-06
sam_encoder.blocks.4.norm1.bias grad: 5.230915007814474e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.191806404676754e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.0292623073837603e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.418409394522314e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.613419150700793e-06
sam_encoder.blocks.4.norm2.weight grad: 1.0189040040131658e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0165028470510151e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.2684979487385135e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 9.027023395447031e-08
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.379459485586267e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.475097507063765e-07
sam_encoder.blocks.5.norm1.weight grad: 1.5089942280610558e-05
sam_encoder.blocks.5.norm1.bias grad: -1.0281995628247387e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.2225427781231701e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.297937605064362e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.052552180335624e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.8488316274888348e-06
sam_encoder.blocks.5.norm2.weight grad: -2.2381309463526122e-06
sam_encoder.blocks.5.norm2.bias grad: -1.642262532186578e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.5262819488270907e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.678822046524147e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.936543239684397e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.8409768876590533e-07
sam_encoder.blocks.6.norm1.weight grad: 1.799310098249407e-06
sam_encoder.blocks.6.norm1.bias grad: 3.717284471349558e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.2795309178036405e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.65305844147224e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.403930355081684e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.2588051251659635e-06
sam_encoder.blocks.6.norm2.weight grad: -4.516930857789703e-06
sam_encoder.blocks.6.norm2.bias grad: -2.256680545542622e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.4074619179591537e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.8406315120955696e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.133583039831137e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.157059596669569e-07
sam_encoder.blocks.7.norm1.weight grad: 5.510451501322677e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0832165742158395e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.768648068420589e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.1387087397451978e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.1289482649299316e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.6820736113440944e-06
sam_encoder.blocks.7.norm2.weight grad: -3.3135061130451504e-06
sam_encoder.blocks.7.norm2.bias grad: -1.5889324913587188e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.055975755865802e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.530596803917433e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.9081198843196034e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.7264059124499909e-06
sam_encoder.blocks.8.norm1.weight grad: 5.198577127885073e-06
sam_encoder.blocks.8.norm1.bias grad: -4.5753250788038713e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.533756732096663e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.0491720533755142e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.5946038678957848e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.107782261708053e-07
sam_encoder.blocks.8.norm2.weight grad: 4.001092747785151e-06
sam_encoder.blocks.8.norm2.bias grad: 8.399351258958632e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.4572983622638276e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.7189460070076166e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.7127056253229966e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.7459656116188853e-07
sam_encoder.blocks.9.norm1.weight grad: 6.226832738320809e-06
sam_encoder.blocks.9.norm1.bias grad: 8.579733616898011e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.098513727512909e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.6552046417928068e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.4075474155106349e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6254602996923495e-06
sam_encoder.blocks.9.norm2.weight grad: 5.91358093515737e-06
sam_encoder.blocks.9.norm2.bias grad: 4.803712272405392e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.8381700758473016e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.838221123762196e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6592927920555667e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.60277617423344e-08
sam_encoder.blocks.10.norm1.weight grad: 2.4952037165348884e-06
sam_encoder.blocks.10.norm1.bias grad: 6.936982117622392e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.363300498269382e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.53914582926518e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.137140644568717e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.440857754976605e-07
sam_encoder.blocks.10.norm2.weight grad: 9.728963050292805e-06
sam_encoder.blocks.10.norm2.bias grad: 4.6593339675382595e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.773615273734322e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.6827597139345016e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.8887008081946988e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.693000500490598e-07
sam_encoder.blocks.11.norm1.weight grad: 8.632481694803573e-06
sam_encoder.blocks.11.norm1.bias grad: -1.5482148683076957e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.1640347515349276e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.049270832088951e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.0910728178714635e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4406866455374256e-07
sam_encoder.blocks.11.norm2.weight grad: 7.361400093941484e-06
sam_encoder.blocks.11.norm2.bias grad: -2.2035196707292926e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.767091013491154e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.617774387341342e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.1049467047996586e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.262647970179387e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.6010162653401494e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.1250849385978654e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.7424513316655066e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.8343803933239542e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00014541108976118267
mask_decoder.transformer.layers.0.norm1.bias grad: 6.887734343763441e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0016705606831237674
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00148167391307652
mask_decoder.transformer.layers.0.norm3.weight grad: 2.254366881970782e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.209110920783132e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -4.92078106617555e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.7309048416791484e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.6283653167192824e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.826742951991037e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -4.596326107275672e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -9.998020686907694e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -6.936217687325552e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.219842644990422e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.045961683616042e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 9.439549103262834e-06
mask_decoder.transformer.norm_final_attn.weight grad: 2.365027057749103e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.872641046764329e-06
Text_Embedding_Affine.0.weight grad: -3.808972234842223e-12
Text_Embedding_Affine.0.bias grad: 7.804834556424112e-11
Text_Embedding_Affine.2.weight grad: -8.319819833069175e-11
Text_Embedding_Affine.2.bias grad: -5.481233529280871e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.643963588923635e-15
Max value: 0.9990707039833069
Mean value: 0.07291405647993088

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.643963588923635e-15
Max value: 0.9990707039833069
Mean value: 0.07291405647993088

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0756540298461914

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11529646813869476

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06714534759521484

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0756540298461914

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 27.66765022277832
Max value: 84.24278259277344
Mean value: 60.172203063964844

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.006974578794304e-15
Max value: 0.9993922710418701
Mean value: 0.07389353215694427

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.006974578794304e-15
Max value: 0.9993922710418701
Mean value: 0.07389353215694427

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.006974578794304e-15
Max value: 0.9993922710418701
Mean value: 0.07389353215694427

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11510703712701797

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.3646484613418579
Max value: 1.4051474332809448
Mean value: 1.0004063844680786

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 27.66765022277832
Max value: 84.24278259277344
Mean value: 60.172203063964844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.181575775146484
Max value: -60.181575775146484
Mean value: -60.181575775146484
sam_encoder.pos_embed grad: -2.4995290281992766e-09
sam_encoder.blocks.0.norm1.weight grad: 6.815834785811603e-05
sam_encoder.blocks.0.norm1.bias grad: 7.282548176590353e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.96515393833397e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.298097107697686e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.707448276050854e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.019144341782521e-07
sam_encoder.blocks.0.norm2.weight grad: 4.119583172723651e-05
sam_encoder.blocks.0.norm2.bias grad: -6.7215833041700535e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.915960274345707e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.1163332348805852e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.871754284366034e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.526817070247489e-06
sam_encoder.blocks.1.norm1.weight grad: -2.6741358851722907e-06
sam_encoder.blocks.1.norm1.bias grad: -1.0597708751447499e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.6343677745899186e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.266836069495184e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.27975487329968e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.949396720301593e-07
sam_encoder.blocks.1.norm2.weight grad: 3.5816362924379064e-06
sam_encoder.blocks.1.norm2.bias grad: -1.866985030574142e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.081003564555431e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5343066479545087e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.421778728807112e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2744146715704119e-06
sam_encoder.blocks.2.norm1.weight grad: 2.4241066931551813e-09
sam_encoder.blocks.2.norm1.bias grad: 6.973290282985545e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.388286131666973e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.645509996706096e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1380101341273985e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.9604681256168988e-06
sam_encoder.blocks.2.norm2.weight grad: -1.3702587011721334e-06
sam_encoder.blocks.2.norm2.bias grad: -5.815374606754631e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.2981652111629955e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.8072537386615295e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.207558049529325e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4066217772779055e-06
sam_encoder.blocks.3.norm1.weight grad: -2.0844494429184124e-05
sam_encoder.blocks.3.norm1.bias grad: -1.0333208592783194e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.2718413927359506e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.008735802723095e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.532354639901314e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -8.224317298299866e-07
sam_encoder.blocks.3.norm2.weight grad: 1.3359876902541146e-06
sam_encoder.blocks.3.norm2.bias grad: -7.452975978594623e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.670449248398654e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.4899389217125645e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.027322125286446e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2372559012874262e-06
sam_encoder.blocks.4.norm1.weight grad: 1.1607153282966465e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1982187061221339e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.355540906748502e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.4365506305912277e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.1875656532065477e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.5806016310525592e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5947341782739386e-05
sam_encoder.blocks.4.norm2.bias grad: -1.6476024029543623e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.7235399354831316e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.75204558117548e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.7502293303550687e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.088345354422927e-06
sam_encoder.blocks.5.norm1.weight grad: 9.739370398165192e-06
sam_encoder.blocks.5.norm1.bias grad: -9.380675692227669e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.11784081836231e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2419844779287814e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.482899723574519e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.0209370126831345e-06
sam_encoder.blocks.5.norm2.weight grad: -5.821190711685631e-07
sam_encoder.blocks.5.norm2.bias grad: -1.0927809853455983e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.263738108216785e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.413132395100547e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.625149020081153e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.678671411464165e-07
sam_encoder.blocks.6.norm1.weight grad: -1.4076204024604522e-06
sam_encoder.blocks.6.norm1.bias grad: 1.094598587769724e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.440412458781793e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.071749238690245e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.4721096874836803e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.990213586912432e-07
sam_encoder.blocks.6.norm2.weight grad: -3.0102518167041126e-07
sam_encoder.blocks.6.norm2.bias grad: -2.9179682314861566e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.840746659188881e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.7396909868239163e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.5420940801268443e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.4380055972651462e-06
sam_encoder.blocks.7.norm1.weight grad: 7.805508175806608e-06
sam_encoder.blocks.7.norm1.bias grad: -1.670970704026331e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.45316458758316e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.187721060588956e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.7079095161752775e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.3942661755427253e-06
sam_encoder.blocks.7.norm2.weight grad: 5.726165909436531e-06
sam_encoder.blocks.7.norm2.bias grad: 7.475477445950673e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.929324520868249e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.6977016912278486e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.250560424334253e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.7046331751989783e-07
sam_encoder.blocks.8.norm1.weight grad: 1.4042313523532357e-05
sam_encoder.blocks.8.norm1.bias grad: -1.5002892723714467e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.4341271707962733e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.208479589986382e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.8745053012025892e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3456278793455567e-06
sam_encoder.blocks.8.norm2.weight grad: -4.096875727555016e-06
sam_encoder.blocks.8.norm2.bias grad: -8.538390261492168e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.479216840991285e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.3528182282461785e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.2187825859655277e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.029795708353049e-07
sam_encoder.blocks.9.norm1.weight grad: 4.627668204193469e-08
sam_encoder.blocks.9.norm1.bias grad: 3.197086186901288e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.1554166121641174e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.7430452809749113e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.3650080745719606e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0526540563660092e-06
sam_encoder.blocks.9.norm2.weight grad: -1.4329488067232887e-06
sam_encoder.blocks.9.norm2.bias grad: -6.986246603446489e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.2285100840235827e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.4418792488868348e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.956821157975355e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.151824294420294e-08
sam_encoder.blocks.10.norm1.weight grad: 5.38909489478101e-07
sam_encoder.blocks.10.norm1.bias grad: 8.463503036182374e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.836649173332262e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.235476645433664e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.578030257107457e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.675785246239684e-07
sam_encoder.blocks.10.norm2.weight grad: -4.524647920334246e-06
sam_encoder.blocks.10.norm2.bias grad: -2.502513098079362e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.2556971569210873e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.4495822142635006e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.157632009897497e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.058183099507005e-07
sam_encoder.blocks.11.norm1.weight grad: 9.389978004037403e-06
sam_encoder.blocks.11.norm1.bias grad: 5.273834631225327e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.3757418148306897e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.424339188815793e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3065699704384315e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.924408696955652e-07
sam_encoder.blocks.11.norm2.weight grad: -3.7539625736826565e-06
sam_encoder.blocks.11.norm2.bias grad: -4.6656018071189465e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4036263564776164e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4386071143235313e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4620391084463336e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.861037261136516e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0854764695977792e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.187083762488328e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.108624125365168e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.8902249798411503e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 2.2447900846600533e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -5.376350600272417e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005423886235803366
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001428271789336577
mask_decoder.transformer.layers.0.norm3.weight grad: 2.9545182769652456e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.880344229401089e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.2019768443424255e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.4420529623748735e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.627992919064127e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.359369318583049e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.000156742797116749
mask_decoder.transformer.layers.1.norm2.bias grad: 9.29052330320701e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 9.851840150076896e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.887810064246878e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.464942710706964e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015246684779413044
mask_decoder.transformer.norm_final_attn.weight grad: 3.6637193261412904e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.721889465348795e-06
Text_Embedding_Affine.0.weight grad: -2.1357381141395848e-11
Text_Embedding_Affine.0.bias grad: -4.011310728024853e-10
Text_Embedding_Affine.2.weight grad: 3.852361138423355e-11
Text_Embedding_Affine.2.bias grad: 1.924963726196438e-07
Epoch 18 finished with average loss: -58.9607
Epoch 19/39
----------
Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.3]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-61.3]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-58.9]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-58.9]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-59.7]Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-59.7]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8310390841893252e-14
Max value: 0.9998594522476196
Mean value: 0.09142199903726578

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8310390841893252e-14
Max value: 0.9998594522476196
Mean value: 0.09142199903726578

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09368610382080078

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13227836787700653

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07980632781982422

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09368610382080078

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.668495178222656
Max value: 91.10293579101562
Mean value: 61.31121826171875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8310390841893252e-14
Max value: 0.9998594522476196
Mean value: 0.09142199903726578

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8310390841893252e-14
Max value: 0.9998594522476196
Mean value: 0.09142199903726578

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8310390841893252e-14
Max value: 0.9998594522476196
Mean value: 0.09142199903726578

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13227836787700653

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.668495178222656
Max value: 91.10293579101562
Mean value: 61.31121826171875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.31254577636719
Max value: -61.31254577636719
Mean value: -61.31254577636719
sam_encoder.pos_embed grad: -1.0374473502494652e-09
sam_encoder.blocks.0.norm1.weight grad: -4.380398604553193e-05
sam_encoder.blocks.0.norm1.bias grad: -9.801329724723473e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.289827757020248e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.887701147206826e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.723162419395521e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.844215482080472e-07
sam_encoder.blocks.0.norm2.weight grad: 2.7011803467758e-05
sam_encoder.blocks.0.norm2.bias grad: 1.529300061520189e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.795780452899635e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.935144382514409e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.426338015648071e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.913656195843942e-07
sam_encoder.blocks.1.norm1.weight grad: 8.797889677225612e-06
sam_encoder.blocks.1.norm1.bias grad: 1.185410928883357e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.363986464450136e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.743817049122299e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.0106091394845862e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.945786258758744e-06
sam_encoder.blocks.1.norm2.weight grad: 1.9597260688897222e-05
sam_encoder.blocks.1.norm2.bias grad: -1.218764009536244e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.7091228882200085e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7984627902478678e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.0576506781490025e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.634985882352339e-07
sam_encoder.blocks.2.norm1.weight grad: -8.987396540760528e-06
sam_encoder.blocks.2.norm1.bias grad: 8.388489732169546e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.718628123460803e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.0933565540181007e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.279650162672624e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.9405143727199174e-06
sam_encoder.blocks.2.norm2.weight grad: 8.385590035686619e-07
sam_encoder.blocks.2.norm2.bias grad: 5.69369785807794e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.062667135760421e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.319713853983558e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.377370719841565e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.88798635906096e-08
sam_encoder.blocks.3.norm1.weight grad: -6.951008799660485e-06
sam_encoder.blocks.3.norm1.bias grad: -8.313703801832162e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.3106652829719678e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8535783397055638e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.307992417627247e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.0840889192186296e-06
sam_encoder.blocks.3.norm2.weight grad: 6.227311587281292e-06
sam_encoder.blocks.3.norm2.bias grad: 2.608687736938009e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.347795301233418e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.8600273910560645e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.174496098130476e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0126401548404829e-06
sam_encoder.blocks.4.norm1.weight grad: -3.814233423327096e-06
sam_encoder.blocks.4.norm1.bias grad: -6.0744878283003345e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.3840577796363505e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.059060062099888e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.043809788825456e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.3759769735297596e-07
sam_encoder.blocks.4.norm2.weight grad: 9.843351108429488e-06
sam_encoder.blocks.4.norm2.bias grad: -8.921105290937703e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.319162715342827e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.7204902153243893e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.449346650086227e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.0157064025406726e-06
sam_encoder.blocks.5.norm1.weight grad: -4.08148798669572e-06
sam_encoder.blocks.5.norm1.bias grad: -2.1746814127254765e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.649638867704198e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.2178796825755853e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.457382255575794e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.826221532359341e-07
sam_encoder.blocks.5.norm2.weight grad: 7.610909506183816e-06
sam_encoder.blocks.5.norm2.bias grad: -1.6909380065044388e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.36428376310505e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.6474422156752553e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.318646238563815e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.139003628253704e-07
sam_encoder.blocks.6.norm1.weight grad: -9.67440428212285e-07
sam_encoder.blocks.6.norm1.bias grad: 1.3548342394642532e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.0697516472646384e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.265794354476384e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.1083803858346073e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.324265650117013e-07
sam_encoder.blocks.6.norm2.weight grad: 2.0661805137933698e-06
sam_encoder.blocks.6.norm2.bias grad: 1.445583620807156e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.6658059394103475e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.2114714991184883e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.0172940367046976e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.267582258104085e-07
sam_encoder.blocks.7.norm1.weight grad: 2.2816229829913937e-06
sam_encoder.blocks.7.norm1.bias grad: 1.05077185708069e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.663156581344083e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.437789135001367e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4521681350743165e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.3832776580311474e-07
sam_encoder.blocks.7.norm2.weight grad: 9.029325156006962e-06
sam_encoder.blocks.7.norm2.bias grad: -1.3099182751830085e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.090844064805424e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.1581855637341505e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6877856978680938e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.624477689674222e-09
sam_encoder.blocks.8.norm1.weight grad: -1.6887215679162182e-06
sam_encoder.blocks.8.norm1.bias grad: 1.082144535757834e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.4304308706414304e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.488020529905043e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.4699044186272658e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.7181699831780861e-06
sam_encoder.blocks.8.norm2.weight grad: 6.03924809183809e-06
sam_encoder.blocks.8.norm2.bias grad: -5.487704015649797e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.1420178099069744e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.550960855136509e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.3176686403967324e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.328095831671817e-07
sam_encoder.blocks.9.norm1.weight grad: -2.4401610971835908e-06
sam_encoder.blocks.9.norm1.bias grad: 9.82211190603266e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.6422843600594206e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.2887675160964136e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.644191898885765e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0717182874486753e-07
sam_encoder.blocks.9.norm2.weight grad: -9.892593055838006e-08
sam_encoder.blocks.9.norm2.bias grad: -6.016950919729425e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.164506771710876e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.1136667644204863e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8655384792509722e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.480273774897796e-07
sam_encoder.blocks.10.norm1.weight grad: 3.53287578036543e-06
sam_encoder.blocks.10.norm1.bias grad: -9.563212870489224e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.6866613299935125e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0841861239896389e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1574312566153822e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.081260496808682e-07
sam_encoder.blocks.10.norm2.weight grad: 4.4604334448195004e-07
sam_encoder.blocks.10.norm2.bias grad: -5.835005936205562e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.167717063159216e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.955134838586673e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.032413138091215e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.74841351408395e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0208554158452898e-05
sam_encoder.blocks.11.norm1.bias grad: -5.815194867864193e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.5943662624049466e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.2810456812294433e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.33379556802538e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.2951762446155044e-07
sam_encoder.blocks.11.norm2.weight grad: -2.9245220503071323e-06
sam_encoder.blocks.11.norm2.bias grad: 7.242567221510399e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.692283374017279e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.803983296777005e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.773811618477339e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.88447028601513e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.485464160097763e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1581022590689827e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1328265827614814e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.6346085582626984e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.085337372496724e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.283992893761024e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005565042607486248
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00022090086713433266
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011938489478779957
mask_decoder.transformer.layers.0.norm3.bias grad: -1.6688652976881713e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.490883581340313e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.5427270884392783e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.3600768549367785e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 8.862116374075413e-09
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00012572313426062465
mask_decoder.transformer.layers.1.norm2.bias grad: 3.301932156318799e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.5474550309590995e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.3624630810227245e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 1.693305603112094e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014754608855582774
mask_decoder.transformer.norm_final_attn.weight grad: 5.385777058108943e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1902588084922172e-05
Text_Embedding_Affine.0.weight grad: 5.099063532520987e-13
Text_Embedding_Affine.0.bias grad: 2.1630509883241444e-10
Text_Embedding_Affine.2.weight grad: -2.8994612266686204e-11
Text_Embedding_Affine.2.bias grad: 2.9653183446498588e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.09834783867952e-14
Max value: 0.9982530474662781
Mean value: 0.08327776193618774

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.09834783867952e-14
Max value: 0.9982530474662781
Mean value: 0.08327776193618774

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07653665542602539

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11889560520648956

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07303047180175781

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07653665542602539

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.63443374633789
Max value: 62.79747009277344
Mean value: 56.489585876464844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.319061229076317e-14
Max value: 0.9981768131256104
Mean value: 0.08412966132164001

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.319061229076317e-14
Max value: 0.9981768131256104
Mean value: 0.08412966132164001

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.319061229076317e-14
Max value: 0.9981768131256104
Mean value: 0.08412966132164001

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11897306144237518

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9528158903121948
Max value: 1.4732322692871094
Mean value: 0.9999488592147827

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.63443374633789
Max value: 62.79747009277344
Mean value: 56.489585876464844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.48897171020508
Max value: -56.48897171020508
Mean value: -56.48897171020508
sam_encoder.pos_embed grad: -8.20501355747183e-09
sam_encoder.blocks.0.norm1.weight grad: -1.7989659681916237e-05
sam_encoder.blocks.0.norm1.bias grad: 5.862562829861417e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.327348965991405e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3144767763151322e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.0933041266980581e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.042769544161274e-07
sam_encoder.blocks.0.norm2.weight grad: 1.1364529200363904e-05
sam_encoder.blocks.0.norm2.bias grad: 6.0142709116917104e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.163713361369446e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.9133298085071146e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.766210698406212e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.7070103695004946e-06
sam_encoder.blocks.1.norm1.weight grad: 2.186624624300748e-05
sam_encoder.blocks.1.norm1.bias grad: 1.2272223102627322e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.273017798870569e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.757541892606241e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.923553893197095e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.9788424999187555e-08
sam_encoder.blocks.1.norm2.weight grad: 4.070316208526492e-05
sam_encoder.blocks.1.norm2.bias grad: -3.2626771826471668e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.355899924732512e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.5602457753848284e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.98931388190249e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.766899787180591e-07
sam_encoder.blocks.2.norm1.weight grad: -4.639411599782761e-06
sam_encoder.blocks.2.norm1.bias grad: 7.589975211885758e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.2193232780409744e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.328695008051e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.245453965268098e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.239620466250926e-06
sam_encoder.blocks.2.norm2.weight grad: -2.656174729054328e-05
sam_encoder.blocks.2.norm2.bias grad: 1.8364047718932852e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.5921892554615624e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.2517358451732434e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.339501745358575e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.025291339828982e-06
sam_encoder.blocks.3.norm1.weight grad: -1.951674676092807e-06
sam_encoder.blocks.3.norm1.bias grad: -4.1939105699384527e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.355416424710711e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.927083854359807e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.2120082121546147e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.6899374461208936e-07
sam_encoder.blocks.3.norm2.weight grad: -6.669723006780259e-06
sam_encoder.blocks.3.norm2.bias grad: -4.901604370388668e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.969246442167787e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.8718375233438564e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.8210133703178144e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.625214155064896e-07
sam_encoder.blocks.4.norm1.weight grad: 2.8778581508959178e-06
sam_encoder.blocks.4.norm1.bias grad: -1.1309930414427072e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.268734306198894e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.322125151811633e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.906698964328825e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.093259925255552e-06
sam_encoder.blocks.4.norm2.weight grad: -9.213437806465663e-06
sam_encoder.blocks.4.norm2.bias grad: -1.0058236512122676e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.291284080361947e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.366534994915128e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.132666617806535e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.862619213483413e-07
sam_encoder.blocks.5.norm1.weight grad: 7.129406640160596e-06
sam_encoder.blocks.5.norm1.bias grad: -1.5185636584647e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.182189736136934e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.7178990674437955e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.900651664589532e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 5.033582056057639e-06
sam_encoder.blocks.5.norm2.weight grad: 6.549858426296851e-06
sam_encoder.blocks.5.norm2.bias grad: -4.575752427626867e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.622932808866608e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.2280129340069834e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.109363094859873e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.225238055572845e-07
sam_encoder.blocks.6.norm1.weight grad: 1.24627877085004e-05
sam_encoder.blocks.6.norm1.bias grad: -3.7925044580333633e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.0928975825663656e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.956766133545898e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.7376131583878305e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.3011011762719136e-06
sam_encoder.blocks.6.norm2.weight grad: -9.334995411336422e-06
sam_encoder.blocks.6.norm2.bias grad: 4.0988933847074804e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.53578148962697e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.075454853591509e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.196579205497983e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.482931338614435e-06
sam_encoder.blocks.7.norm1.weight grad: 1.0853706044144928e-05
sam_encoder.blocks.7.norm1.bias grad: -2.7190521905140486e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.4708818829094525e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.087403572659241e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.2533311039296677e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 9.833581771090394e-07
sam_encoder.blocks.7.norm2.weight grad: -2.2642120711680036e-06
sam_encoder.blocks.7.norm2.bias grad: -1.1097363312728703e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.6648212951840833e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.797018510136695e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.1820965255537885e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.976178047400026e-07
sam_encoder.blocks.8.norm1.weight grad: 3.823427960014669e-06
sam_encoder.blocks.8.norm1.bias grad: -4.361603714642115e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.821200597390998e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.4567311811551917e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5330767837440362e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.5835520318651106e-06
sam_encoder.blocks.8.norm2.weight grad: -2.2789567992731463e-06
sam_encoder.blocks.8.norm2.bias grad: -1.346515546174487e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.906430035589437e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.133425229227214e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0035334980784683e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.46853106142953e-07
sam_encoder.blocks.9.norm1.weight grad: 2.5604254005884286e-06
sam_encoder.blocks.9.norm1.bias grad: 5.395029347710079e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.629335540405009e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.460951903543901e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.1298836852802197e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.177906369775883e-06
sam_encoder.blocks.9.norm2.weight grad: 1.2100643971280078e-06
sam_encoder.blocks.9.norm2.bias grad: 7.289327186299488e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.4639202845501131e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.932710109846084e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.5045806018606527e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.396036506979726e-07
sam_encoder.blocks.10.norm1.weight grad: 4.020926098746713e-06
sam_encoder.blocks.10.norm1.bias grad: 3.2800930966914166e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.022170631084009e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2436529459591839e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5358546079369262e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.580305686540669e-07
sam_encoder.blocks.10.norm2.weight grad: 6.161717010400025e-06
sam_encoder.blocks.10.norm2.bias grad: -6.888461712151184e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.99302280129632e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.194062517446582e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.8650716526735778e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.777062206860137e-07
sam_encoder.blocks.11.norm1.weight grad: -7.320816621358972e-06
sam_encoder.blocks.11.norm1.bias grad: 1.1983420336036943e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.158900426569744e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.4348033801070414e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.715345661068568e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.455733690316265e-07
sam_encoder.blocks.11.norm2.weight grad: -3.296327804491739e-06
sam_encoder.blocks.11.norm2.bias grad: -1.59596356752445e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.2688594728824683e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.1662710853197495e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7051734175765887e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.1799172625615029e-06
sam_encoder.neck.conv1.trainable_scale grad: -7.501726031478029e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.341734398214612e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.708079697797075e-07
sam_encoder.neck.conv2.trainable_shift grad: -8.778006304055452e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.000191960803931579
mask_decoder.transformer.layers.0.norm1.bias grad: -1.0816380381584167e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.001566116465255618
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0007659499533474445
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00013339922588784248
mask_decoder.transformer.layers.0.norm3.bias grad: -9.999056783271953e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.950600487063639e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.4026527423993684e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.036189314618241e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.852154350170167e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0002564226451795548
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00020769753609783947
mask_decoder.transformer.layers.1.norm3.weight grad: -2.6191171855316497e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.3811098041478544e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.481524592847563e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.322878809645772e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.4043229132075794e-06
mask_decoder.transformer.norm_final_attn.bias grad: -6.4371733969892375e-06
Text_Embedding_Affine.0.weight grad: -4.9217964773196066e-12
Text_Embedding_Affine.0.bias grad: 3.812708759820538e-10
Text_Embedding_Affine.2.weight grad: 1.1112115394507072e-10
Text_Embedding_Affine.2.bias grad: 5.918124952586368e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.4806603209141511e-12
Max value: 0.9996472597122192
Mean value: 0.0828983336687088

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.4806603209141511e-12
Max value: 0.9996472597122192
Mean value: 0.0828983336687088

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07812023162841797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11759448051452637

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.076141357421875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07812023162841797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.86378479003906
Max value: 68.56755828857422
Mean value: 61.289485931396484

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.92883380878917e-12
Max value: 0.9994495511054993
Mean value: 0.08464577049016953

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.92883380878917e-12
Max value: 0.9994495511054993
Mean value: 0.08464577049016953

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.92883380878917e-12
Max value: 0.9994495511054993
Mean value: 0.08464577049016953

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11684759706258774

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.936055600643158
Max value: 2.4534106254577637
Mean value: 1.0010590553283691

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.86378479003906
Max value: 68.56755828857422
Mean value: 61.289485931396484

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.31883239746094
Max value: -61.31883239746094
Mean value: -61.31883239746094
sam_encoder.pos_embed grad: 1.957159767584926e-09
sam_encoder.blocks.0.norm1.weight grad: -5.087716999696568e-06
sam_encoder.blocks.0.norm1.bias grad: -2.7068625058745965e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.2690581873757765e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.3763174138148315e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.399517249315977e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.870983735192567e-06
sam_encoder.blocks.0.norm2.weight grad: 3.0857729143463075e-05
sam_encoder.blocks.0.norm2.bias grad: -1.881790376501158e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4826679944235366e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.689993147621863e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4998762708273716e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.3547078197007068e-05
sam_encoder.blocks.1.norm1.weight grad: 4.546923446469009e-05
sam_encoder.blocks.1.norm1.bias grad: 4.002808054792695e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.442463028273778e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1110223567811772e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.2605918527697213e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.546067313844105e-06
sam_encoder.blocks.1.norm2.weight grad: 4.020201686216751e-06
sam_encoder.blocks.1.norm2.bias grad: 3.1755487270856975e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.873919457779266e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.6126253967740922e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0920557290082797e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.300158012592874e-07
sam_encoder.blocks.2.norm1.weight grad: -2.1579870008281432e-05
sam_encoder.blocks.2.norm1.bias grad: -2.686538209673017e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.546879138913937e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.219922175252577e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.159763077244861e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.121574425473227e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1084538527939003e-05
sam_encoder.blocks.2.norm2.bias grad: 1.1032674365196726e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.947141289652791e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.866874511819333e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0568433935986832e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3645702665598947e-06
sam_encoder.blocks.3.norm1.weight grad: -4.800233909918461e-06
sam_encoder.blocks.3.norm1.bias grad: -2.1532893867970415e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0148128239961807e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.3829625206417404e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.4251421589506208e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.044263732794207e-06
sam_encoder.blocks.3.norm2.weight grad: -1.355094718746841e-05
sam_encoder.blocks.3.norm2.bias grad: 1.9505319869494997e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0371511962148361e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.3906090973468963e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.498469934333116e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.183313315777923e-06
sam_encoder.blocks.4.norm1.weight grad: 2.169131676055258e-06
sam_encoder.blocks.4.norm1.bias grad: -4.150918812229065e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.426515414796995e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.337726416750229e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.2890363854676252e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.964527422795072e-06
sam_encoder.blocks.4.norm2.weight grad: -2.152012712031137e-06
sam_encoder.blocks.4.norm2.bias grad: 2.2720694687450305e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.8421840145019814e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.426947495834611e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.8147160264779814e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.1398924470995553e-06
sam_encoder.blocks.5.norm1.weight grad: -1.6429941751994193e-05
sam_encoder.blocks.5.norm1.bias grad: 2.251575779155246e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.51409016730031e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.350337441863303e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.078808044345351e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.588636329572182e-06
sam_encoder.blocks.5.norm2.weight grad: -1.0813002518261783e-05
sam_encoder.blocks.5.norm2.bias grad: 7.109340913302731e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1587429980863817e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.693653070513392e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.175906049866171e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.600147344215657e-07
sam_encoder.blocks.6.norm1.weight grad: -1.444438311182239e-07
sam_encoder.blocks.6.norm1.bias grad: -4.4035532482666895e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.1828402572718915e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.8771873985533603e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.0108194601343712e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.282955382630462e-07
sam_encoder.blocks.6.norm2.weight grad: 1.713789242785424e-05
sam_encoder.blocks.6.norm2.bias grad: 1.266589060833212e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.415569936914835e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.453042836554232e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.5439162527618464e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.4495458344754297e-06
sam_encoder.blocks.7.norm1.weight grad: -9.388721622372032e-08
sam_encoder.blocks.7.norm1.bias grad: 1.4855977497063577e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.2126785122745787e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.199158638584777e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.623966524761272e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7778064602680388e-06
sam_encoder.blocks.7.norm2.weight grad: 4.22872653871309e-06
sam_encoder.blocks.7.norm2.bias grad: 3.188393748132512e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.1516769973241026e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.179230010478932e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.711511665955186e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.059386012362665e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0157407814403996e-05
sam_encoder.blocks.8.norm1.bias grad: 4.8433648771606386e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.161555337603204e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.7280356082192156e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.613989853576641e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.156883965653833e-06
sam_encoder.blocks.8.norm2.weight grad: 2.8281201593927108e-06
sam_encoder.blocks.8.norm2.bias grad: 2.793144631141331e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.5755556148633332e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.5126279246687773e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.290208034442912e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.747360667854082e-07
sam_encoder.blocks.9.norm1.weight grad: -5.093344839224301e-07
sam_encoder.blocks.9.norm1.bias grad: 1.960744839379913e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.0182328626106028e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1156190566907753e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.274531531540561e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0232697604806162e-06
sam_encoder.blocks.9.norm2.weight grad: 1.504161843968177e-07
sam_encoder.blocks.9.norm2.bias grad: 7.702337825321592e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.1511746151882107e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.0757073596323607e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.654580211787106e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.1741942052576633e-07
sam_encoder.blocks.10.norm1.weight grad: -4.133619313506642e-06
sam_encoder.blocks.10.norm1.bias grad: -1.9290725958853727e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.959185283340048e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.458123493757739e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.431760534222121e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.82182758282579e-07
sam_encoder.blocks.10.norm2.weight grad: -1.360817623208277e-05
sam_encoder.blocks.10.norm2.bias grad: -4.22525363319437e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.3589219533023424e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.450313437904697e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.903931545006344e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.146740260082879e-06
sam_encoder.blocks.11.norm1.weight grad: 3.419564563955646e-06
sam_encoder.blocks.11.norm1.bias grad: -1.5989746771083446e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.5641123809473356e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.4377080503891193e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.957327640411677e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.158059376393794e-06
sam_encoder.blocks.11.norm2.weight grad: -9.780565960681997e-06
sam_encoder.blocks.11.norm2.bias grad: -2.7987994144496042e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.725342710618861e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.6812350572290597e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6251324268523604e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.782247285424091e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.6528839448001236e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.814009010558948e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.6105772121809423e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.5352590202819556e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018434725643601269
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2050149962306023e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002060291590169072
mask_decoder.transformer.layers.0.norm2.bias grad: 0.000995872775092721
mask_decoder.transformer.layers.0.norm3.weight grad: -3.159366315230727e-07
mask_decoder.transformer.layers.0.norm3.bias grad: 3.2561205443926156e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.86622108030133e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.282600563485175e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.519852518569678e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.873124559409916e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0003764070861507207
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00017950014444068074
mask_decoder.transformer.layers.1.norm3.weight grad: 5.143041107658064e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 6.119435420259833e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.994915485032834e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -1.809959940146655e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0996901437465567e-05
mask_decoder.transformer.norm_final_attn.bias grad: 3.77057745026832e-06
Text_Embedding_Affine.0.weight grad: -8.51739789808903e-11
Text_Embedding_Affine.0.bias grad: -2.963504552866425e-09
Text_Embedding_Affine.2.weight grad: -7.074889285529906e-11
Text_Embedding_Affine.2.bias grad: 1.2370313925202936e-05
Epoch 19 finished with average loss: -59.7068
Epoch 20/39
----------
Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/3 [00:01<?, ?it/s, loss=-59.2]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-59.2]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-58.1]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-58.1]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-61.7]Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.20it/s, loss=-61.7]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.221810732462446e-18
Max value: 0.9999610185623169
Mean value: 0.0944744348526001

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.221810732462446e-18
Max value: 0.9999610185623169
Mean value: 0.0944744348526001

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08673810958862305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13322106003761292

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08469772338867188

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08673810958862305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.13349151611328
Max value: 75.10250091552734
Mean value: 59.18658447265625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.221810732462446e-18
Max value: 0.9999610185623169
Mean value: 0.0944744348526001

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.221810732462446e-18
Max value: 0.9999610185623169
Mean value: 0.0944744348526001

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.221810732462446e-18
Max value: 0.9999610185623169
Mean value: 0.0944744348526001

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13322106003761292

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.13349151611328
Max value: 75.10250091552734
Mean value: 59.18658447265625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.18775939941406
Max value: -59.18775939941406
Mean value: -59.18775939941406
sam_encoder.pos_embed grad: 1.6444801076431759e-09
sam_encoder.blocks.0.norm1.weight grad: 1.2982738553546369e-05
sam_encoder.blocks.0.norm1.bias grad: -2.6231744413962588e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.91554703280417e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.494950249205431e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.207379323721398e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.4625147741753608e-06
sam_encoder.blocks.0.norm2.weight grad: -3.597993418225087e-05
sam_encoder.blocks.0.norm2.bias grad: 1.6468620742671192e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.970735168782994e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.869965313351713e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2189004337415099e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.774823305022437e-06
sam_encoder.blocks.1.norm1.weight grad: -7.031195764284348e-06
sam_encoder.blocks.1.norm1.bias grad: 3.7481822801055387e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.0466152313456405e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.8957547354148119e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.848611018180236e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.1943218320739106e-07
sam_encoder.blocks.1.norm2.weight grad: -1.0985691005771514e-05
sam_encoder.blocks.1.norm2.bias grad: 3.838536940747872e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.5301893553405534e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.475721774113481e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.9591302589105908e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.907661044242559e-06
sam_encoder.blocks.2.norm1.weight grad: -9.312050679000095e-06
sam_encoder.blocks.2.norm1.bias grad: -3.624048474648589e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.78815263704746e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.746911817070213e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.4678505522169871e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0206479146290803e-06
sam_encoder.blocks.2.norm2.weight grad: 1.7032480172929354e-05
sam_encoder.blocks.2.norm2.bias grad: 1.4389158877747832e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.2478027201723307e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.693520168075338e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.3329160708508425e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.112103404921072e-06
sam_encoder.blocks.3.norm1.weight grad: -5.3974449656379875e-06
sam_encoder.blocks.3.norm1.bias grad: 4.753377197630471e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.4789900382747874e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.630193591812713e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.5421403531945543e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.9033464013773482e-06
sam_encoder.blocks.3.norm2.weight grad: -5.230868737271521e-06
sam_encoder.blocks.3.norm2.bias grad: -2.4713481252547354e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.721295671421103e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.994988103135256e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.752193712600274e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.339338713383768e-07
sam_encoder.blocks.4.norm1.weight grad: -1.1212052413611673e-05
sam_encoder.blocks.4.norm1.bias grad: -4.246402113494696e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.756013812671881e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.786973254842451e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.0705220979143633e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.6531859020906268e-06
sam_encoder.blocks.4.norm2.weight grad: 2.6356447051512077e-05
sam_encoder.blocks.4.norm2.bias grad: 1.8376431398792192e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.637637979001738e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.158917247172212e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.299412699358072e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.031985331996111e-06
sam_encoder.blocks.5.norm1.weight grad: 1.8407254174235277e-06
sam_encoder.blocks.5.norm1.bias grad: 1.7452952079111128e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.7275590329954866e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.727710231440142e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.393662938033231e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.735805868629541e-07
sam_encoder.blocks.5.norm2.weight grad: 2.4077937268884853e-05
sam_encoder.blocks.5.norm2.bias grad: 8.34832462714985e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.90821752868942e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.2565802737517515e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.6530084394617006e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.617192517907824e-07
sam_encoder.blocks.6.norm1.weight grad: 8.480964424961712e-06
sam_encoder.blocks.6.norm1.bias grad: -7.780092232678726e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.710233381250873e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.9472075766534545e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.813265033793868e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.9102503756585065e-06
sam_encoder.blocks.6.norm2.weight grad: 7.82969163992675e-06
sam_encoder.blocks.6.norm2.bias grad: 2.781128387141507e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.574283138936153e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.9839808373944834e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.9912704374291934e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.617919901444111e-07
sam_encoder.blocks.7.norm1.weight grad: -3.998385636805324e-06
sam_encoder.blocks.7.norm1.bias grad: -4.838852873945143e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.334109694857034e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.304061925111455e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.7006649361283053e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.8658519113378134e-06
sam_encoder.blocks.7.norm2.weight grad: -3.47754337326478e-07
sam_encoder.blocks.7.norm2.bias grad: -1.1724714568117633e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.2028792702476494e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.4202307738742093e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.9361643189295137e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1488750573107609e-07
sam_encoder.blocks.8.norm1.weight grad: -5.094252628623508e-06
sam_encoder.blocks.8.norm1.bias grad: 1.0605331226543058e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.7261029370274628e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.264360419867444e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.6445387650019256e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.563115685916273e-06
sam_encoder.blocks.8.norm2.weight grad: 8.536228961020242e-06
sam_encoder.blocks.8.norm2.bias grad: 3.006904080393724e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.51457481176476e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.2984489735099487e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.986273673537653e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.3391913853411097e-06
sam_encoder.blocks.9.norm1.weight grad: 1.0091821422975045e-06
sam_encoder.blocks.9.norm1.bias grad: 6.727598247380229e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.15615692317806e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.2008616440416517e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.190083705500001e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9657090888358653e-06
sam_encoder.blocks.9.norm2.weight grad: 7.202824690466514e-06
sam_encoder.blocks.9.norm2.bias grad: 3.984923750977032e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8604596334625967e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.922273552030674e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.6111303011712153e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.4695463050884428e-06
sam_encoder.blocks.10.norm1.weight grad: -3.80406049771409e-06
sam_encoder.blocks.10.norm1.bias grad: 7.254188858496491e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.635413127587526e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.080984806227207e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.51038148032967e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.6276497894505155e-07
sam_encoder.blocks.10.norm2.weight grad: 3.898631803167518e-06
sam_encoder.blocks.10.norm2.bias grad: 3.807163466262864e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.3490105175151257e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.5976662477187347e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.770069957274245e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.60344631139742e-07
sam_encoder.blocks.11.norm1.weight grad: -2.8998792913625948e-05
sam_encoder.blocks.11.norm1.bias grad: 1.9638828234747052e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.003595106245484e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.118167329485004e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.5750382519618142e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.295682730225963e-07
sam_encoder.blocks.11.norm2.weight grad: -1.5239829735946842e-06
sam_encoder.blocks.11.norm2.bias grad: -1.1765266663132934e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.5747331190141267e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.4757010546873062e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.903226671463926e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.459810487693176e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.3832832337357104e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.253307659178972e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.4503639249596745e-06
sam_encoder.neck.conv2.trainable_shift grad: -6.20175342191942e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.117789886659011e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.462285581510514e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005615346599370241
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004839396569877863
mask_decoder.transformer.layers.0.norm3.weight grad: 1.0775958799058571e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.0836771252797917e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.000143339391797781
mask_decoder.transformer.layers.0.norm4.bias grad: 1.8415083104628138e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.4822054911055602e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.460503310430795e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.3716962207108736e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -5.7695920986589044e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.64118555909954e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.318154995213263e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.817057924810797e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002532382495701313
mask_decoder.transformer.norm_final_attn.weight grad: 4.486748821364017e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.0448541615915019e-05
Text_Embedding_Affine.0.weight grad: -2.925120562435879e-11
Text_Embedding_Affine.0.bias grad: -8.316560218268876e-10
Text_Embedding_Affine.2.weight grad: -2.5244806245439122e-11
Text_Embedding_Affine.2.bias grad: -4.370523674879223e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.5547869087005054e-15
Max value: 0.9992832541465759
Mean value: 0.08814265578985214

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.5547869087005054e-15
Max value: 0.9992832541465759
Mean value: 0.08814265578985214

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08508729934692383

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1211463063955307

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07749557495117188

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08508729934692383

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.80610275268555
Max value: 67.49890899658203
Mean value: 57.00325012207031

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1132600612575368e-14
Max value: 0.9991968274116516
Mean value: 0.0879003256559372

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1132600612575368e-14
Max value: 0.9991968274116516
Mean value: 0.0879003256559372

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1132600612575368e-14
Max value: 0.9991968274116516
Mean value: 0.0879003256559372

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12109662592411041

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9643788933753967
Max value: 1.304105281829834
Mean value: 1.0000593662261963

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.80610275268555
Max value: 67.49890899658203
Mean value: 57.00325012207031

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.00893020629883
Max value: -57.00893020629883
Mean value: -57.00893020629883
sam_encoder.pos_embed grad: 2.783175911957869e-09
sam_encoder.blocks.0.norm1.weight grad: 5.596637129201554e-05
sam_encoder.blocks.0.norm1.bias grad: 5.106377648189664e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.339206604228821e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.8448089867415547e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.7819735148805194e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.967817065131385e-06
sam_encoder.blocks.0.norm2.weight grad: 6.296028732322156e-05
sam_encoder.blocks.0.norm2.bias grad: -7.497576007153839e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.4361353755230084e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.043105819728225e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.123479346977547e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.252561772475019e-06
sam_encoder.blocks.1.norm1.weight grad: 2.9284192351042293e-05
sam_encoder.blocks.1.norm1.bias grad: 2.228827179351356e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.82943539484404e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.4118853616528213e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.658202204969712e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.05834725825116e-06
sam_encoder.blocks.1.norm2.weight grad: 1.5281700598279713e-06
sam_encoder.blocks.1.norm2.bias grad: 1.6671759794917307e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.551772003149381e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.7322638257155631e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.1229570847935975e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.214433834524243e-06
sam_encoder.blocks.2.norm1.weight grad: -7.137758075259626e-06
sam_encoder.blocks.2.norm1.bias grad: 8.735116352909245e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.086511009722017e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.5475714008061914e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.7909370601264527e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.402818270435091e-07
sam_encoder.blocks.2.norm2.weight grad: -7.892834219092038e-06
sam_encoder.blocks.2.norm2.bias grad: -1.5956913557602093e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.855844053963665e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.2024346435500775e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0162310900341254e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7938366454472998e-06
sam_encoder.blocks.3.norm1.weight grad: -1.578651790623553e-05
sam_encoder.blocks.3.norm1.bias grad: 1.1685452591336798e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1836846169899218e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.591060820122948e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.037597475165967e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.577263098326512e-06
sam_encoder.blocks.3.norm2.weight grad: 2.445064410494524e-06
sam_encoder.blocks.3.norm2.bias grad: 1.2066066119587049e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.7921332730329596e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.539100705689634e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.597921128559392e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8080218069371767e-06
sam_encoder.blocks.4.norm1.weight grad: -7.100239599822089e-06
sam_encoder.blocks.4.norm1.bias grad: 5.522546189240529e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.679173682437977e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.643374146937276e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.7967638490954414e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.170234205957968e-06
sam_encoder.blocks.4.norm2.weight grad: -1.3797467545373365e-05
sam_encoder.blocks.4.norm2.bias grad: 9.11983079276979e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.509728463133797e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.356705514714122e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.0786214918189216e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.8944391513286973e-06
sam_encoder.blocks.5.norm1.weight grad: -1.0441739277666784e-06
sam_encoder.blocks.5.norm1.bias grad: -3.2857924452400766e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.2574414490227355e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.195363084771088e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0978435049935342e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.2025865291652735e-06
sam_encoder.blocks.5.norm2.weight grad: -1.0019288311013952e-05
sam_encoder.blocks.5.norm2.bias grad: -5.34344871994108e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0081997970701195e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.7472352687473176e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.556366325734416e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.7616480363358278e-07
sam_encoder.blocks.6.norm1.weight grad: -3.1792114896234125e-07
sam_encoder.blocks.6.norm1.bias grad: 1.942702965607168e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.3529369198295171e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.102527774804912e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.71038003222202e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.462505209332448e-07
sam_encoder.blocks.6.norm2.weight grad: 1.06301304185763e-05
sam_encoder.blocks.6.norm2.bias grad: 7.81202925281832e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.520758233818924e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.2811109374742955e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.320944299252005e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.5821632334555034e-06
sam_encoder.blocks.7.norm1.weight grad: 5.4361680668080226e-06
sam_encoder.blocks.7.norm1.bias grad: -1.008279014058644e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.96080213249661e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.703049161340459e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.98811856334214e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.5950438359577674e-07
sam_encoder.blocks.7.norm2.weight grad: 2.1422069949039724e-06
sam_encoder.blocks.7.norm2.bias grad: 1.837596641962591e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.172933015273884e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.4219467554285075e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.4753433081059484e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.8434572502410447e-07
sam_encoder.blocks.8.norm1.weight grad: 6.776664577046176e-06
sam_encoder.blocks.8.norm1.bias grad: 3.178650104018743e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.446520274039358e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.6859165700443555e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.8948990145872813e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.246379037591396e-06
sam_encoder.blocks.8.norm2.weight grad: -1.3376464949033107e-06
sam_encoder.blocks.8.norm2.bias grad: -2.0654756553994957e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.6471786895854166e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.3394547952193534e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.458724909753073e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.31448825111147e-07
sam_encoder.blocks.9.norm1.weight grad: -2.91219635073503e-06
sam_encoder.blocks.9.norm1.bias grad: 2.3850529373703466e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.943491836049361e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.987102902807237e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.2080827218596824e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4116061493041343e-06
sam_encoder.blocks.9.norm2.weight grad: 5.227152541920077e-07
sam_encoder.blocks.9.norm2.bias grad: -1.8288537830812857e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.281420279359736e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.9625590514115174e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.883312506834045e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.484060476286686e-06
sam_encoder.blocks.10.norm1.weight grad: -2.8284966901992448e-06
sam_encoder.blocks.10.norm1.bias grad: 9.668036682342063e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -8.454566682303266e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.875870788760949e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2477343602768087e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1813731362053659e-06
sam_encoder.blocks.10.norm2.weight grad: -9.863480045169126e-06
sam_encoder.blocks.10.norm2.bias grad: -3.515058779157698e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.648359663406154e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.420645498408703e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.566462727481849e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.5474838238892517e-08
sam_encoder.blocks.11.norm1.weight grad: -1.4081619156058878e-05
sam_encoder.blocks.11.norm1.bias grad: 1.5626078493369278e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.061463192148949e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.7304283157245663e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.7920111733692465e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.3427950307232095e-06
sam_encoder.blocks.11.norm2.weight grad: -1.1477316547825467e-05
sam_encoder.blocks.11.norm2.bias grad: -4.12641065850039e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.839169835373468e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.883167780964868e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.4171196122988476e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.0451054183467932e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.4259248928283341e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.343972821312491e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.23800418805331e-08
sam_encoder.neck.conv2.trainable_shift grad: 7.246467248478439e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014920177636668086
mask_decoder.transformer.layers.0.norm1.bias grad: -2.4001492420211434e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0038937069475650787
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0009315249044448137
mask_decoder.transformer.layers.0.norm3.weight grad: -5.2407700422918424e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.912574149784632e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -2.48141022893833e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.410195626609493e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.840681064408273e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.304647856974043e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00015892166993580759
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00018449794151820242
mask_decoder.transformer.layers.1.norm3.weight grad: 4.0700979297980666e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.558802462881431e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.059118378383573e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.898618059698492e-05
mask_decoder.transformer.norm_final_attn.weight grad: 6.595785634999629e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.9070830603595823e-06
Text_Embedding_Affine.0.weight grad: 1.818087173866001e-11
Text_Embedding_Affine.0.bias grad: 7.935825885319048e-10
Text_Embedding_Affine.2.weight grad: 5.029227034825112e-11
Text_Embedding_Affine.2.bias grad: 1.4578434274881147e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.704193020425973e-13
Max value: 0.9984790682792664
Mean value: 0.07641236484050751

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.704193020425973e-13
Max value: 0.9984790682792664
Mean value: 0.07641236484050751

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07519912719726562

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09780415892601013

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07101249694824219

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07519912719726562

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 53.874549865722656
Max value: 87.42779541015625
Mean value: 68.90536499023438

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.788144877734905e-13
Max value: 0.9983604550361633
Mean value: 0.07559461891651154

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.788144877734905e-13
Max value: 0.9983604550361633
Mean value: 0.07559461891651154

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.788144877734905e-13
Max value: 0.9983604550361633
Mean value: 0.07559461891651154

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.0975661426782608

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8897933959960938
Max value: 1.3451107740402222
Mean value: 1.0002589225769043

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 53.874549865722656
Max value: 87.42779541015625
Mean value: 68.90536499023438

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.9251708984375
Max value: -68.9251708984375
Mean value: -68.9251708984375
sam_encoder.pos_embed grad: -1.1287031032036765e-10
sam_encoder.blocks.0.norm1.weight grad: 2.267227682750672e-05
sam_encoder.blocks.0.norm1.bias grad: 3.192716758348979e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.962469574820716e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.640747068966448e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.748469215584919e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.1199103887047386e-06
sam_encoder.blocks.0.norm2.weight grad: 8.233478729380295e-05
sam_encoder.blocks.0.norm2.bias grad: 1.1068052117479965e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.0652061721193604e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.043431999889435e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.394746323057916e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0318783097318374e-05
sam_encoder.blocks.1.norm1.weight grad: 6.813642357883509e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4423195352719631e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.1428908086090814e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.771004912778153e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.0204756108578295e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.0422730712161865e-06
sam_encoder.blocks.1.norm2.weight grad: -3.243167157052085e-07
sam_encoder.blocks.1.norm2.bias grad: -3.489485607133247e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.944320375623647e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2988356274945545e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.748441718518734e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.9011495169252157e-06
sam_encoder.blocks.2.norm1.weight grad: -2.4749471776885912e-05
sam_encoder.blocks.2.norm1.bias grad: -2.2351885036187014e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.881689968286082e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.445846570888534e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.3529419447877444e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.675115855614422e-06
sam_encoder.blocks.2.norm2.weight grad: -1.4670516065962147e-05
sam_encoder.blocks.2.norm2.bias grad: -6.636386387981474e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.2932674508192576e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.278377451148117e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2517351933638565e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.4644442621356575e-06
sam_encoder.blocks.3.norm1.weight grad: -2.814169420162216e-06
sam_encoder.blocks.3.norm1.bias grad: -7.2530847319285385e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.389626274634793e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.0310336620023008e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.0830807443417143e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.1262392237986205e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1799786079791375e-05
sam_encoder.blocks.3.norm2.bias grad: -4.408244421938434e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.733956176205538e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.441649252839852e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.0293363124656025e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.315797686009319e-07
sam_encoder.blocks.4.norm1.weight grad: 3.821699920081301e-06
sam_encoder.blocks.4.norm1.bias grad: -1.1914860806427896e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.4169442863476434e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.572896952799056e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.81233972904738e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.851626049960032e-06
sam_encoder.blocks.4.norm2.weight grad: 1.3173619208828313e-06
sam_encoder.blocks.4.norm2.bias grad: -5.629469796986086e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.579577085271012e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.802693863188324e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.8904000828333665e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.189811022570211e-07
sam_encoder.blocks.5.norm1.weight grad: 7.016225481493166e-06
sam_encoder.blocks.5.norm1.bias grad: -1.5482321032322943e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.961236406117678e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.8693912099697627e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.457165919622639e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.338805188628612e-06
sam_encoder.blocks.5.norm2.weight grad: 8.872200851328671e-06
sam_encoder.blocks.5.norm2.bias grad: 3.572840341803385e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.1730345451942412e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.5254051883603097e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.5415083655389026e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.587600474475039e-07
sam_encoder.blocks.6.norm1.weight grad: 8.741729828898315e-08
sam_encoder.blocks.6.norm1.bias grad: -4.810871814697748e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.777576810331084e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.3701429654465755e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.5916569964247174e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.3583012332674116e-06
sam_encoder.blocks.6.norm2.weight grad: 5.327342933014734e-06
sam_encoder.blocks.6.norm2.bias grad: -9.836797971729538e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.606601002407842e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.2556994306578417e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7879389702102344e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.702018365307595e-07
sam_encoder.blocks.7.norm1.weight grad: -3.879667929140851e-07
sam_encoder.blocks.7.norm1.bias grad: -1.4139117183731287e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.725754140759818e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.5750057015302446e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.0993102225475013e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1436543445597636e-07
sam_encoder.blocks.7.norm2.weight grad: -4.109597284696065e-07
sam_encoder.blocks.7.norm2.bias grad: -2.282914920215262e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.5647972304577706e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5963225905579748e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.4992990788064162e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.906464816187508e-07
sam_encoder.blocks.8.norm1.weight grad: 7.633871973666828e-06
sam_encoder.blocks.8.norm1.bias grad: 9.426944416190963e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.3004685570194852e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.018838692194549e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.7682791053630353e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.966871761600487e-07
sam_encoder.blocks.8.norm2.weight grad: -3.2349302614420594e-07
sam_encoder.blocks.8.norm2.bias grad: 3.4659046832530294e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.453955630699056e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.2486561900004745e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0964431567117572e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.8272025904007023e-07
sam_encoder.blocks.9.norm1.weight grad: 2.432740757285501e-06
sam_encoder.blocks.9.norm1.bias grad: -7.706476026214659e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.5817136045370717e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.754757014779898e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.889645310868218e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.677909828387783e-07
sam_encoder.blocks.9.norm2.weight grad: -8.901963042262651e-07
sam_encoder.blocks.9.norm2.bias grad: 2.4911828404583503e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.639490159912384e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.8191756225860445e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1915273034901475e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.116370640374953e-08
sam_encoder.blocks.10.norm1.weight grad: -1.914552512971568e-06
sam_encoder.blocks.10.norm1.bias grad: -1.138755237661826e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.108369926645537e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.0200585620623315e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3992892036185367e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.739801736126537e-07
sam_encoder.blocks.10.norm2.weight grad: -3.731004426299478e-06
sam_encoder.blocks.10.norm2.bias grad: -3.0332863332205307e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.070742640280514e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.6020376278902404e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.556771671104798e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.985564151458675e-08
sam_encoder.blocks.11.norm1.weight grad: -4.934039225190645e-06
sam_encoder.blocks.11.norm1.bias grad: 6.817042219608993e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.5848817030200735e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.270448819923331e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.11538496286812e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.825870286775171e-07
sam_encoder.blocks.11.norm2.weight grad: -5.359438546292949e-07
sam_encoder.blocks.11.norm2.bias grad: 1.5529197980868048e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.410433345787169e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.0523989380526473e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.451377329431125e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.251709087720883e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.2430245988070965e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.4006443709367886e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.9958915800089017e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.7103806132799946e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 8.719084144104272e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.7730199033394456e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005155641585588455
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00018270022701472044
mask_decoder.transformer.layers.0.norm3.weight grad: -1.2301999959163368e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.209606464020908e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011306046508252621
mask_decoder.transformer.layers.0.norm4.bias grad: 1.3182783732190728e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.9439561078324914e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.2803736758069135e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -8.766510291025043e-06
mask_decoder.transformer.layers.1.norm2.bias grad: -3.745611684280448e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.124291419633664e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.9656610422534868e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.30950419488363e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00021579116582870483
mask_decoder.transformer.norm_final_attn.weight grad: 2.2652989173366223e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2592335224326234e-05
Text_Embedding_Affine.0.weight grad: -1.5372519229783776e-11
Text_Embedding_Affine.0.bias grad: -8.820629782135825e-10
Text_Embedding_Affine.2.weight grad: -2.9264354828306693e-11
Text_Embedding_Affine.2.bias grad: -2.8914872018503956e-05
Epoch 20 finished with average loss: -61.7073
Epoch 21/39
----------
Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.6]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.17it/s, loss=-56.6]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.17it/s, loss=-58.6]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-58.6]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-59.8]Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-59.8]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0083291623538826e-12
Max value: 0.9920037388801575
Mean value: 0.08191356062889099

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0083291623538826e-12
Max value: 0.9920037388801575
Mean value: 0.08191356062889099

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07188272476196289

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11101852357387543

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06821393966674805

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07188272476196289

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.418785095214844
Max value: 72.14683532714844
Mean value: 56.60303497314453

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0083291623538826e-12
Max value: 0.9920037388801575
Mean value: 0.08191356062889099

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0083291623538826e-12
Max value: 0.9920037388801575
Mean value: 0.08191356062889099

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0083291623538826e-12
Max value: 0.9920037388801575
Mean value: 0.08191356062889099

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11101852357387543

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.418785095214844
Max value: 72.14683532714844
Mean value: 56.60303497314453

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.60432815551758
Max value: -56.60432815551758
Mean value: -56.60432815551758
sam_encoder.pos_embed grad: 2.737750470771516e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00021761655807495117
sam_encoder.blocks.0.norm1.bias grad: 3.644894604803994e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.879608680610545e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.36237780074589e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.919817446439993e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.944636202708352e-06
sam_encoder.blocks.0.norm2.weight grad: 8.49108437250834e-06
sam_encoder.blocks.0.norm2.bias grad: -0.0001955039333552122
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.726051570789423e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.4738404843228636e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.3794454389426392e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.666866046434734e-05
sam_encoder.blocks.1.norm1.weight grad: 2.3191727450466715e-05
sam_encoder.blocks.1.norm1.bias grad: 1.6571573723922484e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.193612661154475e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.984511749877129e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1597956472542137e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.934565135452431e-06
sam_encoder.blocks.1.norm2.weight grad: -3.722949622897431e-05
sam_encoder.blocks.1.norm2.bias grad: 7.656835805391893e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.183592368965037e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.951756075868616e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.828560147667304e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.165370460716076e-06
sam_encoder.blocks.2.norm1.weight grad: -2.2405394702218473e-05
sam_encoder.blocks.2.norm1.bias grad: 1.6519756172783673e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.6464524378534406e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.9357719288091175e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2420525308698416e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.07566801388748e-06
sam_encoder.blocks.2.norm2.weight grad: -2.9708851343457354e-06
sam_encoder.blocks.2.norm2.bias grad: -3.46003143931739e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.7793186038470594e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.3540336567530176e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.674197119427845e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2364856729618623e-06
sam_encoder.blocks.3.norm1.weight grad: -1.56575370056089e-05
sam_encoder.blocks.3.norm1.bias grad: 2.6070903913932852e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.774292286427226e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.024113761464832e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.012280315801036e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -8.629443982499652e-06
sam_encoder.blocks.3.norm2.weight grad: -1.6675612641847692e-05
sam_encoder.blocks.3.norm2.bias grad: -1.630312908673659e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.4990570889494848e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.9629359232785646e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.451961447353824e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5154085986068822e-06
sam_encoder.blocks.4.norm1.weight grad: 7.211567208287306e-06
sam_encoder.blocks.4.norm1.bias grad: -5.731531928176992e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.653603471320821e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.0633118563418975e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.9799821176275145e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.1033480404876173e-05
sam_encoder.blocks.4.norm2.weight grad: -1.0539866707404144e-05
sam_encoder.blocks.4.norm2.bias grad: 2.6846819309866987e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3475786545313895e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.4438108994218055e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.2426130524545442e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.275513907079585e-06
sam_encoder.blocks.5.norm1.weight grad: -1.4927934898878448e-05
sam_encoder.blocks.5.norm1.bias grad: -1.1582047591218725e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.1407132610183908e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.320537987543503e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.070353391696699e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.511199444503291e-06
sam_encoder.blocks.5.norm2.weight grad: -7.008205102465581e-06
sam_encoder.blocks.5.norm2.bias grad: -7.519229257013649e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0491026841918938e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.6240973056701478e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.8757058241099e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.896466224290634e-08
sam_encoder.blocks.6.norm1.weight grad: 3.5915145417675376e-06
sam_encoder.blocks.6.norm1.bias grad: -9.941452844941523e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.999423254048452e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.1969271983834915e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.635395619814517e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.38443090236251e-06
sam_encoder.blocks.6.norm2.weight grad: 2.886796664824942e-06
sam_encoder.blocks.6.norm2.bias grad: 7.321153816519654e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.0367306231273687e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.268072295119055e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1061274562962353e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.449803448849707e-06
sam_encoder.blocks.7.norm1.weight grad: -2.405787199677434e-06
sam_encoder.blocks.7.norm1.bias grad: 2.29075749302865e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.387083552297554e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.2991606581636006e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.3164884649086162e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.1859077605768107e-06
sam_encoder.blocks.7.norm2.weight grad: 3.740355850823107e-06
sam_encoder.blocks.7.norm2.bias grad: 2.9630980407091556e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.405376451657503e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.3888137573303538e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.665075946126308e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.3322642189450562e-06
sam_encoder.blocks.8.norm1.weight grad: 6.374635631800629e-06
sam_encoder.blocks.8.norm1.bias grad: -1.1675149380607763e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.862970515911002e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.0886188799049705e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.4385033106664196e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.626951977115823e-06
sam_encoder.blocks.8.norm2.weight grad: -7.101052688085474e-07
sam_encoder.blocks.8.norm2.bias grad: 1.1133810176033876e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.146928858972387e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.8949250463483622e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.9796989363385364e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.901235446501232e-07
sam_encoder.blocks.9.norm1.weight grad: -1.542219706607284e-06
sam_encoder.blocks.9.norm1.bias grad: 5.787048280581075e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.956092430395074e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.131984946478042e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.2261923529877095e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.6984844819489808e-07
sam_encoder.blocks.9.norm2.weight grad: -4.359080776339397e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6448391306767007e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.152201538294321e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.4752516765147448e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.111731191689614e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.394291626245831e-07
sam_encoder.blocks.10.norm1.weight grad: 3.990831373812398e-06
sam_encoder.blocks.10.norm1.bias grad: -1.91686467587715e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1195924116691458e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.7112616152180635e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.1218687013279123e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.49710887803667e-07
sam_encoder.blocks.10.norm2.weight grad: -1.4336367712530773e-05
sam_encoder.blocks.10.norm2.bias grad: -3.008710336871445e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.471204531204421e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.467238563345745e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5896657714620233e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.6236311845859746e-07
sam_encoder.blocks.11.norm1.weight grad: -4.5510358177125454e-05
sam_encoder.blocks.11.norm1.bias grad: 1.023971890390385e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.3779321054462343e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.4517932451526576e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.280918127122277e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.1977918385782687e-07
sam_encoder.blocks.11.norm2.weight grad: -3.921215466107242e-06
sam_encoder.blocks.11.norm2.bias grad: -3.801700586336665e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.3654320102650672e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.380599087497103e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.6880234145210125e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.8764577204328816e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.4604765965486877e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.7519610992167145e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.4195939002092928e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.778084646910429e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018641576752997935
mask_decoder.transformer.layers.0.norm1.bias grad: 1.6340782167389989e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0031923307105898857
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0008252074476331472
mask_decoder.transformer.layers.0.norm3.weight grad: -5.467950541060418e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 8.247401274275035e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011377109331078827
mask_decoder.transformer.layers.0.norm4.bias grad: 6.826803655712865e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.817372635239735e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.797654360620072e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0004198419628664851
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001673454826232046
mask_decoder.transformer.layers.1.norm3.weight grad: 2.5045233996934257e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.6873712562955916e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.438474206835963e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 5.667576988344081e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.966527634067461e-07
mask_decoder.transformer.norm_final_attn.bias grad: -8.06514344731113e-06
Text_Embedding_Affine.0.weight grad: 2.8469917395801403e-11
Text_Embedding_Affine.0.bias grad: 8.185823685558091e-10
Text_Embedding_Affine.2.weight grad: 7.457902351237777e-11
Text_Embedding_Affine.2.bias grad: -1.153741504822392e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.15162797532103e-14
Max value: 0.9990076422691345
Mean value: 0.10121838748455048

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.15162797532103e-14
Max value: 0.9990076422691345
Mean value: 0.10121838748455048

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09348487854003906

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13472628593444824

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0906524658203125

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09348487854003906

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.09269714355469
Max value: 85.76699829101562
Mean value: 60.634246826171875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.6336305843934447e-14
Max value: 0.9990102052688599
Mean value: 0.09969615936279297

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6336305843934447e-14
Max value: 0.9990102052688599
Mean value: 0.09969615936279297

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6336305843934447e-14
Max value: 0.9990102052688599
Mean value: 0.09969615936279297

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1341882050037384

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7475353479385376
Max value: 1.0668725967407227
Mean value: 1.0005731582641602

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.09269714355469
Max value: 85.76699829101562
Mean value: 60.634246826171875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.67353057861328
Max value: -60.67353057861328
Mean value: -60.67353057861328
sam_encoder.pos_embed grad: 2.7116136003257907e-09
sam_encoder.blocks.0.norm1.weight grad: 3.056794230360538e-05
sam_encoder.blocks.0.norm1.bias grad: -2.3886332201072946e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.772737495135516e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.556194875884103e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.158773430797737e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.502708404492296e-07
sam_encoder.blocks.0.norm2.weight grad: 6.305878741841298e-06
sam_encoder.blocks.0.norm2.bias grad: -3.3175787393702194e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1240115782129578e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.1507657947950065e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.1993887710559648e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.46273725174251e-06
sam_encoder.blocks.1.norm1.weight grad: 2.542462240739951e-08
sam_encoder.blocks.1.norm1.bias grad: 8.598182830610313e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.15897510619834e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.8018616831104737e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.0833353927591816e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.8338879474176792e-06
sam_encoder.blocks.1.norm2.weight grad: -1.2182390491943806e-05
sam_encoder.blocks.1.norm2.bias grad: 3.4756094464682974e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.787278941075783e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.765770548445289e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.4660774468211457e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6926885564316763e-06
sam_encoder.blocks.2.norm1.weight grad: -7.617168648721417e-06
sam_encoder.blocks.2.norm1.bias grad: 3.6713518056785688e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.2290727075596806e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.6209562545554945e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.6351787053281441e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0236967682430986e-06
sam_encoder.blocks.2.norm2.weight grad: 6.765468242520001e-06
sam_encoder.blocks.2.norm2.bias grad: -5.71879854760482e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.3554453062170069e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.8928975578091922e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.570256224833429e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.1461022495495854e-06
sam_encoder.blocks.3.norm1.weight grad: 2.205845703429077e-06
sam_encoder.blocks.3.norm1.bias grad: 6.174136615300085e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0298178665379965e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.921695679309778e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.2619178707827814e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.822984242811799e-06
sam_encoder.blocks.3.norm2.weight grad: -1.4376465514942538e-05
sam_encoder.blocks.3.norm2.bias grad: 1.9862150111293886e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0792020475491881e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.9523753255489282e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.088754394615535e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.786495075379207e-07
sam_encoder.blocks.4.norm1.weight grad: 2.0950283214915544e-06
sam_encoder.blocks.4.norm1.bias grad: -3.7511867958528455e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0863993793464033e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.633128001951263e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.2169809855986387e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.6853799681703094e-06
sam_encoder.blocks.4.norm2.weight grad: -1.0812467365894918e-07
sam_encoder.blocks.4.norm2.bias grad: 6.720678356941789e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.6937177608488128e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.990259748818062e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.4411265258095227e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.932436917850282e-07
sam_encoder.blocks.5.norm1.weight grad: 5.672026190950419e-07
sam_encoder.blocks.5.norm1.bias grad: -4.622403139364906e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.4829672586056404e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.980665729206521e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5108761292358395e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.899902326220399e-08
sam_encoder.blocks.5.norm2.weight grad: -2.59507100963674e-06
sam_encoder.blocks.5.norm2.bias grad: 2.475007022439968e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.192023309064098e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6799789364085882e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -4.707065670572774e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.4812857784818334e-07
sam_encoder.blocks.6.norm1.weight grad: 2.186051460739691e-06
sam_encoder.blocks.6.norm1.bias grad: -1.6276175074381172e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.6635316342217266e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3411895452009048e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.8561242970681633e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.177946829666325e-07
sam_encoder.blocks.6.norm2.weight grad: 3.99976852349937e-06
sam_encoder.blocks.6.norm2.bias grad: 4.084006377524929e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.40319137548795e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.477092995282874e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1722484032361535e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.344461204818799e-08
sam_encoder.blocks.7.norm1.weight grad: 2.260777819174109e-06
sam_encoder.blocks.7.norm1.bias grad: -1.2464367671327636e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.357094654660614e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.014114089543e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.975527983537177e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.4103125067777e-07
sam_encoder.blocks.7.norm2.weight grad: -2.9252537387947086e-06
sam_encoder.blocks.7.norm2.bias grad: 3.8229876508921734e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.1867106170248007e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.08136782728252e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6410005798661587e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.3775921199085133e-07
sam_encoder.blocks.8.norm1.weight grad: 6.194267825776478e-06
sam_encoder.blocks.8.norm1.bias grad: 5.222922823122644e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.091351562849013e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.0846950974373613e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.8245102612345363e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.683864401362371e-07
sam_encoder.blocks.8.norm2.weight grad: -1.1223669389437418e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5585878827550914e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.334672560915351e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.512007869081572e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.379971076356014e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.2784845416244934e-07
sam_encoder.blocks.9.norm1.weight grad: -1.0564589274508762e-06
sam_encoder.blocks.9.norm1.bias grad: -4.134552682444337e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0142670134882792e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.15417195099144e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.233134505848284e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.69724068857613e-07
sam_encoder.blocks.9.norm2.weight grad: -1.1695518509213798e-07
sam_encoder.blocks.9.norm2.bias grad: 1.7212930742971366e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.4282973097579088e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.519931154500227e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1224299214518396e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.0644936310200137e-06
sam_encoder.blocks.10.norm1.weight grad: -3.0870205591781996e-06
sam_encoder.blocks.10.norm1.bias grad: -3.6649288404078106e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.1181774627621053e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.28331849334063e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.2327859622018877e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.800250058498932e-07
sam_encoder.blocks.10.norm2.weight grad: -2.453939032420749e-06
sam_encoder.blocks.10.norm2.bias grad: 1.100498479900125e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.975222741952166e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.818776334213908e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.72479483607458e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.613394134546979e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3203520211391151e-05
sam_encoder.blocks.11.norm1.bias grad: 1.7549791664350778e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.4157392530810284e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.580400733786519e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.0193140244373353e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.898291076140595e-07
sam_encoder.blocks.11.norm2.weight grad: -4.617189915734343e-06
sam_encoder.blocks.11.norm2.bias grad: -1.7789534467738122e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.2882453524507582e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.30466126697138e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.004815524349397e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.7372728911577724e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.592113201506436e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.0420808393973857e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.3054068404017016e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.7296571968472563e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 8.543495641788468e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.413280187989585e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0057470002211630344
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002332263975404203
mask_decoder.transformer.layers.0.norm3.weight grad: 5.404300463851541e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.3854223652742803e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011900588287971914
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0616098734317347e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.8443326300475746e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.3890543161542155e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00010093458695337176
mask_decoder.transformer.layers.1.norm2.bias grad: -1.991235330933705e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.091192749910988e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -9.971290637622587e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 2.791011138469912e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00019175640773028135
mask_decoder.transformer.norm_final_attn.weight grad: -1.441514086764073e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.4158494195726234e-05
Text_Embedding_Affine.0.weight grad: -1.2363482633503953e-11
Text_Embedding_Affine.0.bias grad: -6.905768734633e-10
Text_Embedding_Affine.2.weight grad: 6.380133921179976e-11
Text_Embedding_Affine.2.bias grad: -4.125748455408029e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.952292486342213e-12
Max value: 0.9980778694152832
Mean value: 0.08238691836595535

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.952292486342213e-12
Max value: 0.9980778694152832
Mean value: 0.08238691836595535

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0880289077758789

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.752108573913574
Max value: -1.1920928244535389e-07
Mean value: -0.11079040169715881

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07792377471923828

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0880289077758789

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 57.01100540161133
Max value: 73.20830535888672
Mean value: 62.132667541503906

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.529604752880894e-13
Max value: 0.9983709454536438
Mean value: 0.07964655756950378

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.529604752880894e-13
Max value: 0.9983709454536438
Mean value: 0.07964655756950378

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.529604752880894e-13
Max value: 0.9983709454536438
Mean value: 0.07964655756950378

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11146416515111923

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.34361398220062256
Max value: 1.0872832536697388
Mean value: 0.9996126890182495

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 57.01100540161133
Max value: 73.20830535888672
Mean value: 62.132667541503906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.11442947387695
Max value: -62.11442947387695
Mean value: -62.11442947387695
sam_encoder.pos_embed grad: -2.2100721253082156e-10
sam_encoder.blocks.0.norm1.weight grad: 7.385146454907954e-05
sam_encoder.blocks.0.norm1.bias grad: -1.6429927200078964e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.525471457687672e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.90812794851081e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.530302506580483e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.119723143958254e-06
sam_encoder.blocks.0.norm2.weight grad: 1.363953515465255e-06
sam_encoder.blocks.0.norm2.bias grad: -0.00010738706623669714
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.1068858990911394e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.065237812435953e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.4573607738129795e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.253363608266227e-06
sam_encoder.blocks.1.norm1.weight grad: 1.2727343346341513e-05
sam_encoder.blocks.1.norm1.bias grad: 8.266042641480453e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.521641130850185e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5602421374060214e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.980448233662173e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.818825800612103e-06
sam_encoder.blocks.1.norm2.weight grad: -1.5529874872299843e-05
sam_encoder.blocks.1.norm2.bias grad: 8.46126931719482e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.78278354118811e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.458393381260976e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0508034140220843e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.9639423953776713e-06
sam_encoder.blocks.2.norm1.weight grad: -1.0471044333826285e-05
sam_encoder.blocks.2.norm1.bias grad: 5.2234099712222815e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.600355391128687e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.3682991923124064e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.0952320483047515e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.667727810352517e-07
sam_encoder.blocks.2.norm2.weight grad: -5.805175078421598e-06
sam_encoder.blocks.2.norm2.bias grad: -9.71091321844142e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.58091733182664e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.985801472732419e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2031432561343536e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5180073660303606e-06
sam_encoder.blocks.3.norm1.weight grad: -3.5635437143355375e-06
sam_encoder.blocks.3.norm1.bias grad: 1.0345847840653732e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.155667844926938e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.5092868984065717e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.437428171717329e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.272369319049176e-06
sam_encoder.blocks.3.norm2.weight grad: -2.3002761736279353e-05
sam_encoder.blocks.3.norm2.bias grad: 6.880509317852557e-08
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.6936644897214137e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.367575224430766e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1110016203019768e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.5502011996868532e-06
sam_encoder.blocks.4.norm1.weight grad: 6.499963092210237e-07
sam_encoder.blocks.4.norm1.bias grad: -6.575453880941495e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.851357061852468e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.8485877717466792e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.2577464733331e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.610663945139095e-07
sam_encoder.blocks.4.norm2.weight grad: 3.5213902265240904e-06
sam_encoder.blocks.4.norm2.bias grad: -4.907912625640165e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.7937693428393686e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.4966401446799864e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.981341135135153e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.714897947153077e-07
sam_encoder.blocks.5.norm1.weight grad: -1.5404646092065377e-06
sam_encoder.blocks.5.norm1.bias grad: -5.652036179526476e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.484704054950271e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.6787762433523312e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.283159450504172e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.974560271075461e-07
sam_encoder.blocks.5.norm2.weight grad: -3.992214260506444e-06
sam_encoder.blocks.5.norm2.bias grad: -4.582498149829917e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.486626378115034e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.1248920347716194e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.661049504444236e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.448012860957533e-07
sam_encoder.blocks.6.norm1.weight grad: -1.9588305804063566e-06
sam_encoder.blocks.6.norm1.bias grad: -4.192558662907686e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.451447683910374e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.2041739410051377e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.1198142974299117e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.0976225079703e-08
sam_encoder.blocks.6.norm2.weight grad: -4.922683729091659e-06
sam_encoder.blocks.6.norm2.bias grad: 2.41045086113445e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.569073204649612e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.26301233144477e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.551942419719126e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.129429847424035e-06
sam_encoder.blocks.7.norm1.weight grad: 6.6908905864693224e-06
sam_encoder.blocks.7.norm1.bias grad: -7.680648650421062e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.5156377887469716e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.048859404472751e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.749047318204248e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.0266174942662474e-06
sam_encoder.blocks.7.norm2.weight grad: -3.757545982807642e-06
sam_encoder.blocks.7.norm2.bias grad: -8.047298933888669e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.563130798691418e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.8377421585901175e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5563950910291169e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.161802280577831e-08
sam_encoder.blocks.8.norm1.weight grad: 7.655342415091582e-06
sam_encoder.blocks.8.norm1.bias grad: -2.0444799702090677e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.89879925630521e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.0568633064831374e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.1284666925348574e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.380581463512499e-06
sam_encoder.blocks.8.norm2.weight grad: -1.0847736575669842e-06
sam_encoder.blocks.8.norm2.bias grad: 2.1440450836962555e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.4399776015779935e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.433837607895839e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.2588764093379723e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.7483512237959076e-07
sam_encoder.blocks.9.norm1.weight grad: 5.419627541414229e-06
sam_encoder.blocks.9.norm1.bias grad: -1.4955949723116646e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.831884557963349e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.8549737862704205e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.6413181924690434e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6100011634989642e-06
sam_encoder.blocks.9.norm2.weight grad: 2.88194019049115e-06
sam_encoder.blocks.9.norm2.bias grad: 2.2657930003333604e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.054779078112915e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.5332832365165814e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.0350814793346217e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.3056151146884076e-06
sam_encoder.blocks.10.norm1.weight grad: 3.680251211335417e-06
sam_encoder.blocks.10.norm1.bias grad: -4.4187535763740016e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.335666284940089e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.712237628406001e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.969570106070023e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.116983068845002e-07
sam_encoder.blocks.10.norm2.weight grad: -2.5675651613710215e-06
sam_encoder.blocks.10.norm2.bias grad: 1.2325640454946551e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.0887745197105687e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.986842107726261e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.949866827999358e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.53476827083432e-07
sam_encoder.blocks.11.norm1.weight grad: -4.718582204077393e-06
sam_encoder.blocks.11.norm1.bias grad: 8.052285238591139e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.663130195898702e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.498239705862943e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.264582796371542e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.38644558850865e-08
sam_encoder.blocks.11.norm2.weight grad: 6.254300387809053e-06
sam_encoder.blocks.11.norm2.bias grad: 1.5702156588304206e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.639259370582295e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.6920278628495e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.9199027267168276e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.3852835536454222e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.6066860553110018e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.752428215695545e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.753731678240001e-06
sam_encoder.neck.conv2.trainable_shift grad: 1.3102800949127413e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00021429343905765563
mask_decoder.transformer.layers.0.norm1.bias grad: 6.9255620473995805e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005032846238464117
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0014101117849349976
mask_decoder.transformer.layers.0.norm3.weight grad: 2.17293381865602e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.337944897590205e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013464211951941252
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2227398656250443e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.8881415346404538e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.3433982530841604e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 6.910914089530706e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.550187830114737e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.0633018215885386e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.0936080545652658e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.5123421690077521e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017925811698660254
mask_decoder.transformer.norm_final_attn.weight grad: 1.1297158835077425e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.0875690350076184e-05
Text_Embedding_Affine.0.weight grad: 3.617335597727589e-11
Text_Embedding_Affine.0.bias grad: 9.001517309314977e-10
Text_Embedding_Affine.2.weight grad: -8.117898020465475e-11
Text_Embedding_Affine.2.bias grad: -9.436728578293696e-05
Epoch 21 finished with average loss: -59.7974
Epoch 22/39
----------
Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-59]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-60]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-60]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-60.9]Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-60.9]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.635369341311369e-12
Max value: 0.9980279803276062
Mean value: 0.08524961769580841

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.635369341311369e-12
Max value: 0.9980279803276062
Mean value: 0.08524961769580841

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08544635772705078

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11811717599630356

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07606697082519531

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08544635772705078

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.35945510864258
Max value: 76.16382598876953
Mean value: 59.012306213378906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.635369341311369e-12
Max value: 0.9980279803276062
Mean value: 0.08524961769580841

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.635369341311369e-12
Max value: 0.9980279803276062
Mean value: 0.08524961769580841

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.635369341311369e-12
Max value: 0.9980279803276062
Mean value: 0.08524961769580841

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11811717599630356

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.35945510864258
Max value: 76.16382598876953
Mean value: 59.012306213378906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.01341247558594
Max value: -59.01341247558594
Mean value: -59.01341247558594
sam_encoder.pos_embed grad: -7.154123404795598e-10
sam_encoder.blocks.0.norm1.weight grad: 1.9728893676074222e-05
sam_encoder.blocks.0.norm1.bias grad: -3.468013892415911e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.149376763962209e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2793502719432581e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.0115499208041001e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.241921374159574e-07
sam_encoder.blocks.0.norm2.weight grad: 9.579277502780315e-06
sam_encoder.blocks.0.norm2.bias grad: 2.2886350052431226e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.0257075700792484e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.5261268799804384e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.9512717699399218e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.3529810530599207e-05
sam_encoder.blocks.1.norm1.weight grad: 2.5125929823843762e-05
sam_encoder.blocks.1.norm1.bias grad: 4.722579433291685e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.6450917377806036e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.6744943422963843e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.460505003109574e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.438160547375446e-06
sam_encoder.blocks.1.norm2.weight grad: 7.412754257529741e-06
sam_encoder.blocks.1.norm2.bias grad: 3.955146894440986e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.546314342704136e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.8451358982929378e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.81752089803922e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.131770659412723e-06
sam_encoder.blocks.2.norm1.weight grad: -6.876801762700779e-06
sam_encoder.blocks.2.norm1.bias grad: -5.607239927485352e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.5711473174160346e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.030695185339937e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.730536824761657e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.559842753020348e-06
sam_encoder.blocks.2.norm2.weight grad: 1.3961915101390332e-05
sam_encoder.blocks.2.norm2.bias grad: -7.455011655110866e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.9372022254392505e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.05654419005441e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2943650290253572e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.325466190697625e-06
sam_encoder.blocks.3.norm1.weight grad: -1.9188502847100608e-05
sam_encoder.blocks.3.norm1.bias grad: -6.980213584029116e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.171911546611227e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.415013220044784e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.341630746144801e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.928557362087304e-06
sam_encoder.blocks.3.norm2.weight grad: 4.113663180760341e-06
sam_encoder.blocks.3.norm2.bias grad: 2.3906820842967136e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.666476914077066e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.903786819137167e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.5129155548929702e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.95136567526788e-06
sam_encoder.blocks.4.norm1.weight grad: 3.737911811185768e-06
sam_encoder.blocks.4.norm1.bias grad: -2.0352348656160757e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.793128937308211e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.7632153180311434e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.5817660659631656e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.320846306247404e-06
sam_encoder.blocks.4.norm2.weight grad: -1.3606952052214183e-05
sam_encoder.blocks.4.norm2.bias grad: 6.654627213720232e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.413722839060938e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.393406925373711e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.669749276014045e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.110435619011696e-06
sam_encoder.blocks.5.norm1.weight grad: -1.4075870922169997e-06
sam_encoder.blocks.5.norm1.bias grad: -3.218680649297312e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5461231441804557e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.635352759876696e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.611551619542297e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.94114704754611e-06
sam_encoder.blocks.5.norm2.weight grad: -1.2130143659305759e-05
sam_encoder.blocks.5.norm2.bias grad: 4.3577560404628457e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.755370799917728e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.975439656438539e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2762802725774236e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.012234846115462e-07
sam_encoder.blocks.6.norm1.weight grad: -2.4378914531553164e-06
sam_encoder.blocks.6.norm1.bias grad: -1.1922237717953976e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.102308023197111e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.9953754417656455e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.043904487436521e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.687446228970657e-06
sam_encoder.blocks.6.norm2.weight grad: 1.297596782023902e-06
sam_encoder.blocks.6.norm2.bias grad: 4.611582426150562e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.5949642551713623e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.8976452338392846e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.198209358539316e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.2376957556625712e-06
sam_encoder.blocks.7.norm1.weight grad: -3.988805474364199e-06
sam_encoder.blocks.7.norm1.bias grad: 3.454205852904124e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.102144314150792e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.190266953533865e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.445887498150114e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.68299935568939e-06
sam_encoder.blocks.7.norm2.weight grad: 1.2330542631389108e-07
sam_encoder.blocks.7.norm2.bias grad: 4.971185717295157e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.5004200122348266e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.609558802963875e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.554239017626969e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.6096022338606417e-06
sam_encoder.blocks.8.norm1.weight grad: -7.679802365601063e-06
sam_encoder.blocks.8.norm1.bias grad: -8.797857731224212e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -9.204355592373759e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.378826815809589e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.541139221852063e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.5767025110544637e-06
sam_encoder.blocks.8.norm2.weight grad: -9.526567737339064e-06
sam_encoder.blocks.8.norm2.bias grad: -3.7996621813363163e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.470204193145037e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.069764145242516e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.313249069629819e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.650155566807371e-07
sam_encoder.blocks.9.norm1.weight grad: -7.514701337640872e-06
sam_encoder.blocks.9.norm1.bias grad: 1.6728612308725133e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.235444627440302e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.525706349842949e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.346041810596944e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.857606548583135e-06
sam_encoder.blocks.9.norm2.weight grad: -7.5083275987708475e-06
sam_encoder.blocks.9.norm2.bias grad: -3.70922134607099e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.587202056427486e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.289150188516942e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.90389025901095e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.945156888425117e-07
sam_encoder.blocks.10.norm1.weight grad: -4.14569376516738e-06
sam_encoder.blocks.10.norm1.bias grad: 8.441332965958281e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.3596886623854516e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.482967134819773e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.0768169431685237e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.3757021406490821e-06
sam_encoder.blocks.10.norm2.weight grad: -6.626883077842649e-06
sam_encoder.blocks.10.norm2.bias grad: -3.1063289043231634e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.505589580119704e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.6965344090967847e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.8292312233825214e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.29125690163346e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2608193173946347e-06
sam_encoder.blocks.11.norm1.bias grad: 9.471623343415558e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.4860484043310862e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.3676577143305622e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.0055135817310656e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.6546817249718515e-08
sam_encoder.blocks.11.norm2.weight grad: -4.277729203749914e-06
sam_encoder.blocks.11.norm2.bias grad: -2.919444739291066e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.1575280041142832e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.811037340208713e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.8463946364354342e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.4688706642118632e-06
sam_encoder.neck.conv1.trainable_scale grad: 4.7984940465539694e-08
sam_encoder.neck.conv1.trainable_shift grad: -4.387159424368292e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.903381629148498e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.067753601091681e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012806597806047648
mask_decoder.transformer.layers.0.norm1.bias grad: -3.377797838766128e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005519252270460129
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0010132781462743878
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00010011693666456267
mask_decoder.transformer.layers.0.norm3.bias grad: -5.981922004139051e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00017290259711444378
mask_decoder.transformer.layers.0.norm4.bias grad: -1.5469091522390954e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.11342955683358e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 7.241814728331519e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -8.020823588594794e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.0852352210786194e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.028097439208068e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.1380672731320374e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.9763800082728267e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002543673326727003
mask_decoder.transformer.norm_final_attn.weight grad: 4.833949788007885e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.5373256246675737e-05
Text_Embedding_Affine.0.weight grad: 3.23642349898956e-12
Text_Embedding_Affine.0.bias grad: 7.792030909392622e-12
Text_Embedding_Affine.2.weight grad: 1.023372914188414e-10
Text_Embedding_Affine.2.bias grad: 6.809721526224166e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.806659851017448e-17
Max value: 0.999649167060852
Mean value: 0.06973621994256973

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.806659851017448e-17
Max value: 0.999649167060852
Mean value: 0.06973621994256973

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07713985443115234

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11436545848846436

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06488561630249023

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07713985443115234

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.82833480834961
Max value: 86.22828674316406
Mean value: 60.93193054199219

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.729345231945905e-17
Max value: 0.9996046423912048
Mean value: 0.06945779174566269

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.729345231945905e-17
Max value: 0.9996046423912048
Mean value: 0.06945779174566269

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.729345231945905e-17
Max value: 0.9996046423912048
Mean value: 0.06945779174566269

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11405982077121735

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7811617255210876
Max value: 1.8320025205612183
Mean value: 1.0003538131713867

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.82833480834961
Max value: 86.22828674316406
Mean value: 60.93193054199219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.953861236572266
Max value: -60.953861236572266
Mean value: -60.953861236572266
sam_encoder.pos_embed grad: -3.4022988870674453e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00019153475295752287
sam_encoder.blocks.0.norm1.bias grad: 5.304371734382585e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.3336671802098863e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.295357606068137e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.95495647151256e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1177892247360433e-06
sam_encoder.blocks.0.norm2.weight grad: -3.499662489048205e-05
sam_encoder.blocks.0.norm2.bias grad: -2.1024292436777614e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.75020885662525e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.2338360647845548e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.738312782137655e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.783856173977256e-06
sam_encoder.blocks.1.norm1.weight grad: 1.6506706742802635e-05
sam_encoder.blocks.1.norm1.bias grad: -2.10076132134418e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2802396440747543e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.9299553716555238e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.985927716916194e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.017972292378545e-06
sam_encoder.blocks.1.norm2.weight grad: 1.828257882152684e-05
sam_encoder.blocks.1.norm2.bias grad: 8.513805369148031e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.1838475984404795e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.3117203201982193e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.004387043707538e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.0418954136403045e-06
sam_encoder.blocks.2.norm1.weight grad: 1.2046764823026024e-05
sam_encoder.blocks.2.norm1.bias grad: 1.5671151913920767e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.316203452006448e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.499487041201064e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.006791980122216e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3083790690870956e-06
sam_encoder.blocks.2.norm2.weight grad: -1.5757213986944407e-05
sam_encoder.blocks.2.norm2.bias grad: 6.250576461752644e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.569284540892113e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.979548066330608e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0522604497964494e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.169468749954831e-06
sam_encoder.blocks.3.norm1.weight grad: 7.477885446860455e-06
sam_encoder.blocks.3.norm1.bias grad: -9.448583114135545e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.5401717468630522e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.0031416195488418e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.6473542220628588e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.7745105651556514e-06
sam_encoder.blocks.3.norm2.weight grad: -1.8238217307953164e-05
sam_encoder.blocks.3.norm2.bias grad: 5.867788331670454e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1276165423623752e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.218816229695221e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.27158455143217e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0276805539888301e-07
sam_encoder.blocks.4.norm1.weight grad: 6.5635731516522355e-06
sam_encoder.blocks.4.norm1.bias grad: -1.7346546883345582e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.296336672065081e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2465660574889625e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.048284386546584e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8595428628032096e-06
sam_encoder.blocks.4.norm2.weight grad: -5.373733802116476e-05
sam_encoder.blocks.4.norm2.bias grad: -3.06574183923658e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.17786107189022e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.2507753126556054e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.228699021448847e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.56585872193682e-06
sam_encoder.blocks.5.norm1.weight grad: -2.374618998146616e-05
sam_encoder.blocks.5.norm1.bias grad: -1.649728619668167e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.8242259102407843e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.742083420860581e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.006304945709417e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.5328445190098137e-06
sam_encoder.blocks.5.norm2.weight grad: -2.9361712222453207e-05
sam_encoder.blocks.5.norm2.bias grad: -2.3375547243631445e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.4935280887584668e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.2632508413807955e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.723969373619184e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.6710757790860953e-06
sam_encoder.blocks.6.norm1.weight grad: 4.501147486735135e-06
sam_encoder.blocks.6.norm1.bias grad: -2.190122131651151e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.087598649173742e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.634111640669289e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.0174842322594486e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.8956928897750913e-06
sam_encoder.blocks.6.norm2.weight grad: -6.233754447748652e-06
sam_encoder.blocks.6.norm2.bias grad: 3.2276470847136807e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.537934950756608e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.0716989840584574e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.501998833144171e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.010609467921313e-07
sam_encoder.blocks.7.norm1.weight grad: 7.534908036177512e-06
sam_encoder.blocks.7.norm1.bias grad: -1.2619534572877456e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.3277139007404912e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.31143552204594e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.8282662495039403e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0584856227069395e-06
sam_encoder.blocks.7.norm2.weight grad: -3.7956901905999985e-06
sam_encoder.blocks.7.norm2.bias grad: 3.7875895486649824e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.60894728146377e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.567629391909577e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.409384253747703e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.418293759859807e-07
sam_encoder.blocks.8.norm1.weight grad: 5.456699000205845e-06
sam_encoder.blocks.8.norm1.bias grad: -3.287673735030694e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.702277121599764e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.6638828621325956e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.0485591701581143e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.6568783318434726e-07
sam_encoder.blocks.8.norm2.weight grad: -6.4955747802741826e-06
sam_encoder.blocks.8.norm2.bias grad: -2.4342139113286976e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.502334715856705e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.3776930195017485e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.240426735828805e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.082785729522584e-06
sam_encoder.blocks.9.norm1.weight grad: -4.744699253933504e-06
sam_encoder.blocks.9.norm1.bias grad: 9.608452273823787e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.886920462216949e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.427693971185363e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0706716011554818e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.701170731394086e-06
sam_encoder.blocks.9.norm2.weight grad: 3.654588454082841e-07
sam_encoder.blocks.9.norm2.bias grad: -2.320465682714712e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.6189068093081e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.625112074383651e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.954277417506091e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.039774464421498e-07
sam_encoder.blocks.10.norm1.weight grad: 1.3452577150019351e-06
sam_encoder.blocks.10.norm1.bias grad: 1.68647557075019e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 9.671155112300767e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.768969799646584e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.324234290223103e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.7159147773782024e-06
sam_encoder.blocks.10.norm2.weight grad: -5.04670470036217e-06
sam_encoder.blocks.10.norm2.bias grad: -3.829883098660503e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.2139088287076447e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.7664694951236015e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.6331342673511244e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.808949706282874e-07
sam_encoder.blocks.11.norm1.weight grad: 3.810228008660488e-07
sam_encoder.blocks.11.norm1.bias grad: 3.8016430607967777e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 9.977302397601306e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.615678209229372e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.178150452891714e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.936759244676068e-07
sam_encoder.blocks.11.norm2.weight grad: 4.747705020236026e-07
sam_encoder.blocks.11.norm2.bias grad: -4.563255970424507e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.7057436707546003e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.110311344149522e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.7504229390397086e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.868685839985119e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.1814627214334905e-06
sam_encoder.neck.conv1.trainable_shift grad: -4.837773303734139e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.863198122009635e-06
sam_encoder.neck.conv2.trainable_shift grad: -7.387774530798197e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011060669203288853
mask_decoder.transformer.layers.0.norm1.bias grad: -3.839872078970075e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004183539655059576
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00046021537855267525
mask_decoder.transformer.layers.0.norm3.weight grad: -4.375993739813566e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.603962613851763e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.959726745961234e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.00557564717019e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.2803618523757905e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.4798961274209432e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002563422603998333
mask_decoder.transformer.layers.1.norm2.bias grad: 9.624965605325997e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.564700818969868e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.842589699663222e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.7354453777661547e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.000216084168641828
mask_decoder.transformer.norm_final_attn.weight grad: 7.4590902841009665e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.085700872266898e-06
Text_Embedding_Affine.0.weight grad: -3.466157916243162e-11
Text_Embedding_Affine.0.bias grad: -5.384210854941784e-10
Text_Embedding_Affine.2.weight grad: -1.986179831714452e-10
Text_Embedding_Affine.2.bias grad: 5.5097385484259576e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0841138750605772e-11
Max value: 0.9982481002807617
Mean value: 0.08929819613695145

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0841138750605772e-11
Max value: 0.9982481002807617
Mean value: 0.08929819613695145

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0943746566772461

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.52199649810791
Max value: -1.1920928244535389e-07
Mean value: -0.1235651820898056

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08032417297363281

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0943746566772461

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 48.277198791503906
Max value: 72.66581726074219
Mean value: 62.715553283691406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.368925368367858e-11
Max value: 0.9978653788566589
Mean value: 0.08928348124027252

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.368925368367858e-11
Max value: 0.9978653788566589
Mean value: 0.08928348124027252

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.368925368367858e-11
Max value: 0.9978653788566589
Mean value: 0.08928348124027252

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.205900192260742
Max value: -1.1920928244535389e-07
Mean value: -0.12335428595542908

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9448833465576172
Max value: 1.414837121963501
Mean value: 1.0002459287643433

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 48.277198791503906
Max value: 72.66581726074219
Mean value: 62.715553283691406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.73361587524414
Max value: -62.73361587524414
Mean value: -62.73361587524414
sam_encoder.pos_embed grad: 5.5939995691201005e-11
sam_encoder.blocks.0.norm1.weight grad: -3.557221498340368e-05
sam_encoder.blocks.0.norm1.bias grad: 1.4999404811533168e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.3903521650936455e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.446654540719464e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.0161521661066217e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.6683528656358249e-06
sam_encoder.blocks.0.norm2.weight grad: 2.2599935618927702e-05
sam_encoder.blocks.0.norm2.bias grad: -2.2355559394782176e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.213509328110376e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.440134039716213e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.471477950573899e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.5752380022604484e-06
sam_encoder.blocks.1.norm1.weight grad: 6.209870662132744e-06
sam_encoder.blocks.1.norm1.bias grad: 7.218928658403456e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.887378229843307e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.3081418021320133e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.8941557300422573e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.207387694852514e-07
sam_encoder.blocks.1.norm2.weight grad: 9.250406947103329e-06
sam_encoder.blocks.1.norm2.bias grad: -1.6508613498444902e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.026154222927289e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.202428721735487e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.6143244465638418e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.2749912293184025e-07
sam_encoder.blocks.2.norm1.weight grad: -6.933755116733664e-07
sam_encoder.blocks.2.norm1.bias grad: 7.040347327347263e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.5850739600864472e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.9587712901957275e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.1521974506176775e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.167079512422788e-06
sam_encoder.blocks.2.norm2.weight grad: -5.249681180430343e-06
sam_encoder.blocks.2.norm2.bias grad: -5.458955911308294e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.6536470159044256e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.346973817817343e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.514663593610749e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.62767819853616e-07
sam_encoder.blocks.3.norm1.weight grad: -2.744183348113438e-06
sam_encoder.blocks.3.norm1.bias grad: 2.4298606149386615e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.309121777623659e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.8900035431433935e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.456018935641623e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.4227704165678006e-08
sam_encoder.blocks.3.norm2.weight grad: 8.871469617588446e-06
sam_encoder.blocks.3.norm2.bias grad: 6.119622412370518e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.924949386506341e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.925011696992442e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.1573854357702658e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.128290527205536e-07
sam_encoder.blocks.4.norm1.weight grad: 2.7260766728431918e-06
sam_encoder.blocks.4.norm1.bias grad: 3.461687811068259e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.7457808780818596e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.61416913519497e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2655325463128975e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.679129000985995e-07
sam_encoder.blocks.4.norm2.weight grad: -1.9753597371163778e-05
sam_encoder.blocks.4.norm2.bias grad: -6.682793809886789e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3372150533541571e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.9418440539739095e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.792129963490879e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.956449957826408e-07
sam_encoder.blocks.5.norm1.weight grad: -2.793109615595313e-06
sam_encoder.blocks.5.norm1.bias grad: -1.4601122302337899e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.824487182806479e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.0431168650247855e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.930443987585022e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.2308798836311325e-07
sam_encoder.blocks.5.norm2.weight grad: -1.15690045277006e-05
sam_encoder.blocks.5.norm2.bias grad: -4.93221568831359e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.925905043113744e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9063033960264875e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.7625576965183427e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.66530622134087e-07
sam_encoder.blocks.6.norm1.weight grad: 4.838310587729211e-07
sam_encoder.blocks.6.norm1.bias grad: 1.4344514056574553e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.472521363320993e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.259988473786507e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.8752515984488127e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.868837942874961e-08
sam_encoder.blocks.6.norm2.weight grad: 8.499227419633826e-07
sam_encoder.blocks.6.norm2.bias grad: 1.23431323117984e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.795371862404863e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.5337060921847296e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.745546781734447e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.7754546749747533e-07
sam_encoder.blocks.7.norm1.weight grad: 2.263475607833243e-06
sam_encoder.blocks.7.norm1.bias grad: 9.592482683729031e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.5057479458846501e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.335073289345019e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.757901817560196e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.4921155297997757e-06
sam_encoder.blocks.7.norm2.weight grad: 7.555265142400458e-07
sam_encoder.blocks.7.norm2.bias grad: 7.283301783900242e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.4363893064437434e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.77094392483923e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.08219762751105e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.099221311866131e-07
sam_encoder.blocks.8.norm1.weight grad: 1.5326038464991143e-06
sam_encoder.blocks.8.norm1.bias grad: -8.62194937667482e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.221141469111899e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.5721498054263066e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.457573368199519e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.583300329206395e-07
sam_encoder.blocks.8.norm2.weight grad: -2.4019363991101272e-06
sam_encoder.blocks.8.norm2.bias grad: -2.070104528684169e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.2850681514464668e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0399625125501188e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.319664518945501e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.593283501388214e-07
sam_encoder.blocks.9.norm1.weight grad: -1.7017398477037204e-06
sam_encoder.blocks.9.norm1.bias grad: 1.7586613410003338e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.1951672149734804e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.476095393281867e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7818263131630374e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0942583230644232e-06
sam_encoder.blocks.9.norm2.weight grad: -1.4725840173923643e-06
sam_encoder.blocks.9.norm2.bias grad: -2.0405821032909444e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.4556808853049006e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.4855412422984955e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.3361280909739435e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.8142994779045694e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4465958884102292e-06
sam_encoder.blocks.10.norm1.bias grad: 4.1212217638531e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0568624020379502e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.526156539621297e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0002017916121986e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.768452643271303e-07
sam_encoder.blocks.10.norm2.weight grad: -2.4802307052596007e-06
sam_encoder.blocks.10.norm2.bias grad: -2.7773307920142543e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.113472075710888e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.325765416979266e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.1321261581542785e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.533921469374036e-07
sam_encoder.blocks.11.norm1.weight grad: 1.3228259376774076e-07
sam_encoder.blocks.11.norm1.bias grad: 5.438655534817372e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.2116258574224048e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.374930178599243e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.60892100718047e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.5487273685721448e-07
sam_encoder.blocks.11.norm2.weight grad: -4.0600048123451415e-06
sam_encoder.blocks.11.norm2.bias grad: -1.7627960460231407e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 9.163038612314267e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.282621593025397e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4631614249083214e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.875546887386008e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.724177754018456e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.638665889913682e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.356156856985763e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.554464117565658e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016836250142659992
mask_decoder.transformer.layers.0.norm1.bias grad: -2.4624641810078174e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005209894850850105
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0009358611423522234
mask_decoder.transformer.layers.0.norm3.weight grad: -2.0173873053863645e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.619914110051468e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.83667341643013e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.198200480866944e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.705440369434655e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.637446964916307e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -1.1146591532451566e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.686280226451345e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.138889900990762e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.745058347703889e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.9899751350749284e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016072439029812813
mask_decoder.transformer.norm_final_attn.weight grad: 5.0657286010391545e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.100600366044091e-05
Text_Embedding_Affine.0.weight grad: -7.426685134925837e-12
Text_Embedding_Affine.0.bias grad: -1.4495037115036524e-11
Text_Embedding_Affine.2.weight grad: 9.491789298987641e-11
Text_Embedding_Affine.2.bias grad: 5.364883327274583e-05
Epoch 22 finished with average loss: -60.9003
Epoch 23/39
----------
Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-59]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-58.4]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-58.4]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-61.9]Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-61.9]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.149202090508424e-13
Max value: 0.9972313046455383
Mean value: 0.08999019861221313

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.149202090508424e-13
Max value: 0.9972313046455383
Mean value: 0.08999019861221313

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08818674087524414

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12372265756130219

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07959938049316406

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08818674087524414

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.386512756347656
Max value: 72.76563262939453
Mean value: 59.04108810424805

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.149202090508424e-13
Max value: 0.9972313046455383
Mean value: 0.08999019861221313

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.149202090508424e-13
Max value: 0.9972313046455383
Mean value: 0.08999019861221313

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.149202090508424e-13
Max value: 0.9972313046455383
Mean value: 0.08999019861221313

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12372265756130219

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.386512756347656
Max value: 72.76563262939453
Mean value: 59.04108810424805

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.042320251464844
Max value: -59.042320251464844
Mean value: -59.042320251464844
sam_encoder.pos_embed grad: 2.210453597939477e-09
sam_encoder.blocks.0.norm1.weight grad: -5.1340404752409086e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0970611583616119e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.182466571161058e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8814034774550237e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.139066353061935e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.299035983810427e-08
sam_encoder.blocks.0.norm2.weight grad: 4.2271334677934647e-05
sam_encoder.blocks.0.norm2.bias grad: 3.7038353184470907e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.8248780179419555e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.6120837800554e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.65884009929141e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.068870111950673e-06
sam_encoder.blocks.1.norm1.weight grad: 3.788125866321934e-07
sam_encoder.blocks.1.norm1.bias grad: -8.762375500737107e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.1698007180457353e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.39206031235517e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.418302629957907e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.140724407378002e-06
sam_encoder.blocks.1.norm2.weight grad: 1.7736707377480343e-05
sam_encoder.blocks.1.norm2.bias grad: 2.5092094801948406e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.6771832583326614e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.90372654996463e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.172539658815367e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2325007219260442e-06
sam_encoder.blocks.2.norm1.weight grad: -4.495506345847389e-06
sam_encoder.blocks.2.norm1.bias grad: 1.1338992180753849e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.820075552444905e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.9192110559961293e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.0565879165369552e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.970275535422843e-06
sam_encoder.blocks.2.norm2.weight grad: -1.5103362784429919e-05
sam_encoder.blocks.2.norm2.bias grad: -6.787660822737962e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.430693353351671e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.934929969138466e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.3098158382927068e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.285811206093058e-06
sam_encoder.blocks.3.norm1.weight grad: 6.537329682032578e-06
sam_encoder.blocks.3.norm1.bias grad: -5.768629307567608e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.2454129318939522e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.017550049364218e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.3848573366412893e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.7566636617848417e-07
sam_encoder.blocks.3.norm2.weight grad: -9.347128070658073e-06
sam_encoder.blocks.3.norm2.bias grad: -4.586893282976234e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.865543698746478e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.613957576613757e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.418542398023419e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3808129324388574e-06
sam_encoder.blocks.4.norm1.weight grad: 1.692147270659916e-05
sam_encoder.blocks.4.norm1.bias grad: -2.135564500349574e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 8.3048489614157e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.4258421288104728e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.8813371955038747e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.136562898158445e-06
sam_encoder.blocks.4.norm2.weight grad: -2.057506571873091e-05
sam_encoder.blocks.4.norm2.bias grad: -4.958520094078267e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.4254772395361215e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.613047960650874e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1477694645000156e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.214229652963695e-07
sam_encoder.blocks.5.norm1.weight grad: 8.307386451633647e-06
sam_encoder.blocks.5.norm1.bias grad: -9.578776371199638e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.782873919699341e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.8399446162220556e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.4963914054533234e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.0245732887124177e-06
sam_encoder.blocks.5.norm2.weight grad: 3.1691211006545927e-06
sam_encoder.blocks.5.norm2.bias grad: -5.483398126671091e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.3101512195135001e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.270517474149528e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1668402041541412e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.3819037166013e-08
sam_encoder.blocks.6.norm1.weight grad: 1.3734199910686584e-06
sam_encoder.blocks.6.norm1.bias grad: -3.1469951409235364e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.1413843569462188e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3578990092355525e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.1922653584406362e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.751305717334617e-06
sam_encoder.blocks.6.norm2.weight grad: 8.457855074084364e-06
sam_encoder.blocks.6.norm2.bias grad: -6.982107834119233e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.897847480198834e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.2466047110137879e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.607996389604523e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1899301171069965e-06
sam_encoder.blocks.7.norm1.weight grad: -6.470055723184487e-06
sam_encoder.blocks.7.norm1.bias grad: -9.887742180580972e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.856027771893423e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.455085794077604e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.8205753298825584e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.23641370414407e-06
sam_encoder.blocks.7.norm2.weight grad: 1.7532008769194363e-06
sam_encoder.blocks.7.norm2.bias grad: -1.158050054073101e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.5677937830769224e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.666757942890399e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.949283377049142e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.0962813803416793e-06
sam_encoder.blocks.8.norm1.weight grad: 6.5782169258454815e-06
sam_encoder.blocks.8.norm1.bias grad: -1.8929844145532115e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.251316441805102e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.9213267680461286e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.8407035895506851e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 7.910588095683124e-08
sam_encoder.blocks.8.norm2.weight grad: -3.4486856748117134e-06
sam_encoder.blocks.8.norm2.bias grad: 5.841459369548829e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.6760527564183576e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.1429073058243375e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.1870609998586588e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.0922513499499473e-07
sam_encoder.blocks.9.norm1.weight grad: -3.2391251352237305e-06
sam_encoder.blocks.9.norm1.bias grad: -1.0985115750372643e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.296573256899137e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.693897843324521e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1901466905328562e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.7093962507460674e-07
sam_encoder.blocks.9.norm2.weight grad: -4.9977661547018215e-06
sam_encoder.blocks.9.norm2.bias grad: 1.9721560420293827e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.646439149131766e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.6901641376753105e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.2708050007859129e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.084427243673417e-07
sam_encoder.blocks.10.norm1.weight grad: -2.1176979316805955e-06
sam_encoder.blocks.10.norm1.bias grad: -6.504326393041993e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.4927984466339694e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.166431608609855e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.177549044470652e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.642292535412707e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0453207323735114e-05
sam_encoder.blocks.10.norm2.bias grad: -1.5182283732428914e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.685445335577242e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.4992723410832696e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.7229072000191081e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.832542223695782e-07
sam_encoder.blocks.11.norm1.weight grad: 3.052200554520823e-07
sam_encoder.blocks.11.norm1.bias grad: 2.3767552193021402e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.248800905770622e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0909134289249778e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.907595088203379e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.845182223154552e-07
sam_encoder.blocks.11.norm2.weight grad: -1.311078631260898e-05
sam_encoder.blocks.11.norm2.bias grad: 8.026690920814872e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.607881242511212e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.9745705230889143e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.091272563120583e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2025761861877982e-06
sam_encoder.neck.conv1.trainable_scale grad: -4.321918822824955e-09
sam_encoder.neck.conv1.trainable_shift grad: -9.913513167703059e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.0714393283706158e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.4481471225735731e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017674373521003872
mask_decoder.transformer.layers.0.norm1.bias grad: -5.581314326263964e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003135520266368985
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00152006174903363
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00013448232493828982
mask_decoder.transformer.layers.0.norm3.bias grad: -3.0548508220817894e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -1.7866215785034e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.178575858939439e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.9151253329473548e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.9261806301074103e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.8481481169583276e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -4.0102662751451135e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.858798214016133e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -1.4971796190366149e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.532530147116631e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.235435022157617e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.969163001078414e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.6751423572713975e-06
Text_Embedding_Affine.0.weight grad: 2.5594316596655453e-11
Text_Embedding_Affine.0.bias grad: 6.153308973466665e-10
Text_Embedding_Affine.2.weight grad: -1.0874089823031952e-11
Text_Embedding_Affine.2.bias grad: 4.8125577450264245e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.959788156288589e-14
Max value: 0.9978081583976746
Mean value: 0.06396696716547012

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.959788156288589e-14
Max value: 0.9978081583976746
Mean value: 0.06396696716547012

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07068014144897461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1059039831161499

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05894899368286133

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07068014144897461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.4149169921875
Max value: 91.43668365478516
Mean value: 57.84867858886719

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.6660997628352723e-13
Max value: 0.997616171836853
Mean value: 0.06350678205490112

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6660997628352723e-13
Max value: 0.997616171836853
Mean value: 0.06350678205490112

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.6660997628352723e-13
Max value: 0.997616171836853
Mean value: 0.06350678205490112

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1059790775179863

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8771027326583862
Max value: 1.963346004486084
Mean value: 0.9999730587005615

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.4149169921875
Max value: 91.43668365478516
Mean value: 57.84867858886719

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.84355926513672
Max value: -57.84355926513672
Mean value: -57.84355926513672
sam_encoder.pos_embed grad: 4.952234178290382e-09
sam_encoder.blocks.0.norm1.weight grad: -1.0669813491404057e-05
sam_encoder.blocks.0.norm1.bias grad: 1.3833972616339452e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.4323365576274227e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.999195203301497e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.180908581474796e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.68984022620134e-06
sam_encoder.blocks.0.norm2.weight grad: 3.444412868702784e-05
sam_encoder.blocks.0.norm2.bias grad: -9.128648525802419e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.918475264683366e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.9491124476189725e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.6683286958141252e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.3905121199495625e-06
sam_encoder.blocks.1.norm1.weight grad: -3.945794560422655e-06
sam_encoder.blocks.1.norm1.bias grad: 3.05180401483085e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.8394935977994464e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -6.724790637235856e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.5245731447066646e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.292705049621873e-06
sam_encoder.blocks.1.norm2.weight grad: 2.8178248612675816e-05
sam_encoder.blocks.1.norm2.bias grad: -1.1811974218289834e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.178704203804955e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.938769052387215e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.0501525543513708e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.1787928946869215e-06
sam_encoder.blocks.2.norm1.weight grad: -4.3589221604634076e-05
sam_encoder.blocks.2.norm1.bias grad: 2.2092344806878828e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.9372313292697072e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.857422133383807e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4846158592263237e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.028492523706518e-06
sam_encoder.blocks.2.norm2.weight grad: 1.5752484614495188e-05
sam_encoder.blocks.2.norm2.bias grad: -1.9869079551426694e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.445486749522388e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.2980142350425012e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1713974345184397e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6417164943050011e-06
sam_encoder.blocks.3.norm1.weight grad: -1.900449930758441e-08
sam_encoder.blocks.3.norm1.bias grad: 1.1288057976344135e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.958356268820353e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.820452886633575e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.016519819240784e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.326655809767544e-06
sam_encoder.blocks.3.norm2.weight grad: 4.272130240678962e-07
sam_encoder.blocks.3.norm2.bias grad: -2.5866884243441746e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.664320274765487e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.83781263937999e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.4808150556054898e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.1741214456815214e-07
sam_encoder.blocks.4.norm1.weight grad: 1.5731578969280235e-05
sam_encoder.blocks.4.norm1.bias grad: -8.518481990904547e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.978882422321476e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 5.166099867892626e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.294049747637473e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.520329068531282e-06
sam_encoder.blocks.4.norm2.weight grad: -1.8197813915321603e-05
sam_encoder.blocks.4.norm2.bias grad: 1.5523150068474934e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6172734831343405e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.638988229999086e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.9499983611458447e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.18905263599845e-08
sam_encoder.blocks.5.norm1.weight grad: -2.9332413760130294e-06
sam_encoder.blocks.5.norm1.bias grad: -1.8399357941234484e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.0573619963215606e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.365911541346577e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5648755581642035e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.5345315179947647e-07
sam_encoder.blocks.5.norm2.weight grad: -3.1063937058206648e-06
sam_encoder.blocks.5.norm2.bias grad: 5.336529284249991e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.573416622908553e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.592536010430194e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.186194357520435e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.655060241835599e-07
sam_encoder.blocks.6.norm1.weight grad: -3.621769792516716e-06
sam_encoder.blocks.6.norm1.bias grad: -8.199761396099348e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.863778718165122e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.076322059314407e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.602774429760757e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.814693966181949e-06
sam_encoder.blocks.6.norm2.weight grad: 1.9420345779508352e-05
sam_encoder.blocks.6.norm2.bias grad: 1.3845309695170727e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.919032891048118e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.004187192345853e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.930780505674193e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.951363057945855e-06
sam_encoder.blocks.7.norm1.weight grad: -8.085889930953272e-06
sam_encoder.blocks.7.norm1.bias grad: -2.0921834220644087e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.0801030485890806e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.0919931102980627e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.903611963731237e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.03987666888861e-06
sam_encoder.blocks.7.norm2.weight grad: 1.3769067663815804e-05
sam_encoder.blocks.7.norm2.bias grad: 3.0910532586858608e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.824239896261133e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.251326916142716e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.325229388588923e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.5457907213422004e-06
sam_encoder.blocks.8.norm1.weight grad: 9.196609425998759e-06
sam_encoder.blocks.8.norm1.bias grad: 3.1419821766576206e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.1480653483886272e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.945991582237184e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.600784450303763e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.3652543101634365e-06
sam_encoder.blocks.8.norm2.weight grad: -2.1445709990075557e-06
sam_encoder.blocks.8.norm2.bias grad: 1.6930841866269475e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.984171598858666e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.1826120903133415e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.326568234906517e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.517304988548858e-08
sam_encoder.blocks.9.norm1.weight grad: -1.1077117051172536e-05
sam_encoder.blocks.9.norm1.bias grad: -3.175485829842728e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.256202247343026e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.416772753756959e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.148293555772398e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.126631781924516e-06
sam_encoder.blocks.9.norm2.weight grad: -6.433912403736031e-06
sam_encoder.blocks.9.norm2.bias grad: 2.618593498482369e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.049062671489082e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.789709017430141e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.829299208111479e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.818319550598972e-07
sam_encoder.blocks.10.norm1.weight grad: -1.472927033319138e-05
sam_encoder.blocks.10.norm1.bias grad: 4.855762085753668e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -9.20252023206558e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.3699428766121855e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.6322371670394205e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.174563633161597e-06
sam_encoder.blocks.10.norm2.weight grad: -1.977857027668506e-05
sam_encoder.blocks.10.norm2.bias grad: -4.526026259554783e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.143686838797294e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.85968394059455e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.354351408939692e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.101359316635353e-06
sam_encoder.blocks.11.norm1.weight grad: -1.5459931091754697e-05
sam_encoder.blocks.11.norm1.bias grad: 3.292623659945093e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.6252763493394013e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.1698634706554e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.744392531894846e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.849128789734095e-07
sam_encoder.blocks.11.norm2.weight grad: -1.752508251229301e-05
sam_encoder.blocks.11.norm2.bias grad: 3.7437379774019064e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.806762601423543e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.5434566143521806e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.988151307676162e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.180671915790299e-06
sam_encoder.neck.conv1.trainable_scale grad: -8.249189704656601e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2428885383997113e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.237375156255439e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.5172349776548799e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.7625239454209805e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -5.987545591779053e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0016186132561415434
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0016662697307765484
mask_decoder.transformer.layers.0.norm3.weight grad: 9.39446545089595e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 2.4799941456876695e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -6.025882612448186e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.188938303035684e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.872206879255828e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.2535854188608937e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.015451850136742e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 8.315750164911151e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.711118602543138e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.2753118426189758e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.0456256101606414e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 5.946692544966936e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.216363661020296e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.20116100233281e-06
Text_Embedding_Affine.0.weight grad: 6.926864637435415e-11
Text_Embedding_Affine.0.bias grad: 1.5103585049303092e-09
Text_Embedding_Affine.2.weight grad: 1.1373765818056825e-10
Text_Embedding_Affine.2.bias grad: 4.38748138549272e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.337395807791052e-16
Max value: 0.9998307228088379
Mean value: 0.09250512719154358

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.337395807791052e-16
Max value: 0.9998307228088379
Mean value: 0.09250512719154358

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10077571868896484

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13340461254119873

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08333110809326172

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10077571868896484

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 55.745933532714844
Max value: 77.99532318115234
Mean value: 68.739990234375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.0348813570460053e-15
Max value: 0.9998098015785217
Mean value: 0.0923568606376648

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.0348813570460053e-15
Max value: 0.9998098015785217
Mean value: 0.0923568606376648

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.0348813570460053e-15
Max value: 0.9998098015785217
Mean value: 0.0923568606376648

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13289205729961395

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8619861006736755
Max value: 3.9061849117279053
Mean value: 1.000872254371643

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 55.745933532714844
Max value: 77.99532318115234
Mean value: 68.739990234375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.7499771118164
Max value: -68.7499771118164
Mean value: -68.7499771118164
sam_encoder.pos_embed grad: -3.452286234661983e-09
sam_encoder.blocks.0.norm1.weight grad: 1.1628507309069391e-05
sam_encoder.blocks.0.norm1.bias grad: 1.721130684018135e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.4433819615078392e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.151558752913843e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.8081942622957285e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.655742884551728e-07
sam_encoder.blocks.0.norm2.weight grad: 3.7569102460111026e-06
sam_encoder.blocks.0.norm2.bias grad: 1.743118991726078e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.92644641478546e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.3659323485626373e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.15623870442505e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.2903424148098566e-06
sam_encoder.blocks.1.norm1.weight grad: 3.302579671071726e-06
sam_encoder.blocks.1.norm1.bias grad: -7.727498086751439e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.075002602301538e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.6268307945210836e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.096513632452115e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.7974324439128395e-06
sam_encoder.blocks.1.norm2.weight grad: 6.487851351266727e-06
sam_encoder.blocks.1.norm2.bias grad: 2.385573452556855e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.5433787413930986e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.101606639826059e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.811423645558534e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.392183091615152e-07
sam_encoder.blocks.2.norm1.weight grad: 1.073932071449235e-05
sam_encoder.blocks.2.norm1.bias grad: -6.557487722602673e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.731986443104688e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.17559773116227e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.9884074592700927e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.6663260566929239e-06
sam_encoder.blocks.2.norm2.weight grad: -5.583484380622394e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2791360859409906e-08
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.959009296115255e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.986927827601903e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.370268814251176e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.716881735726929e-07
sam_encoder.blocks.3.norm1.weight grad: -6.920366104168352e-06
sam_encoder.blocks.3.norm1.bias grad: -5.412182417785516e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.6030534172605257e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.598205123329535e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.3917624528403394e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.981974264708697e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0967438356601633e-05
sam_encoder.blocks.3.norm2.bias grad: 1.0708538411563495e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.876990250428207e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.5196011392836226e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.1954324438411277e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.824177146176226e-07
sam_encoder.blocks.4.norm1.weight grad: -2.9324473871383816e-07
sam_encoder.blocks.4.norm1.bias grad: -7.568814908154309e-09
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.126814140661736e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.222398951649666e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.3665079450220219e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.6364342627639417e-06
sam_encoder.blocks.4.norm2.weight grad: -8.422140126640443e-06
sam_encoder.blocks.4.norm2.bias grad: -1.3551153642765712e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.176535978534957e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.5876374820654746e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.398847176569689e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.337117272574687e-07
sam_encoder.blocks.5.norm1.weight grad: 1.6459639482491184e-06
sam_encoder.blocks.5.norm1.bias grad: -8.483206102027907e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5278872069757199e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.393302550757653e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.7812311625675648e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.890571290161461e-07
sam_encoder.blocks.5.norm2.weight grad: -2.0502925508480985e-06
sam_encoder.blocks.5.norm2.bias grad: -9.150182449957356e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.498850547766779e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.145819960082008e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.713598968919541e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.908457190642366e-07
sam_encoder.blocks.6.norm1.weight grad: 3.4373073276583455e-07
sam_encoder.blocks.6.norm1.bias grad: 2.8423764888430014e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.237012826204591e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.384157581531326e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.2742112548712612e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.719594208310809e-08
sam_encoder.blocks.6.norm2.weight grad: -9.737946129462216e-07
sam_encoder.blocks.6.norm2.bias grad: -2.5012759579112753e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.799837137805298e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.3935787513428295e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.304035539666074e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0412994555508703e-07
sam_encoder.blocks.7.norm1.weight grad: 3.8085797768872e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1255556273681577e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.5523636395519134e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.399767256771156e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.8752004962152569e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1520326097524958e-06
sam_encoder.blocks.7.norm2.weight grad: 3.0900635010766564e-06
sam_encoder.blocks.7.norm2.bias grad: 1.7830909371241432e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.3215432065626374e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.0048345302493544e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.01132114752545e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.309334245699574e-07
sam_encoder.blocks.8.norm1.weight grad: 2.9762377380393445e-06
sam_encoder.blocks.8.norm1.bias grad: -1.8783455288939876e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.596369980296004e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.259773251329534e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.8847298406399204e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.1023452088920749e-06
sam_encoder.blocks.8.norm2.weight grad: 1.9902420262951637e-06
sam_encoder.blocks.8.norm2.bias grad: -1.1271256425970932e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.4473290523019386e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.3269008150018635e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.480617915054609e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.4475732491046074e-07
sam_encoder.blocks.9.norm1.weight grad: 2.1010575323998637e-07
sam_encoder.blocks.9.norm1.bias grad: 6.270036578825966e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.3119355319067836e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.181943940144265e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.883382871412323e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9455356436992588e-07
sam_encoder.blocks.9.norm2.weight grad: 3.223880412406288e-06
sam_encoder.blocks.9.norm2.bias grad: -3.395718408683024e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.672418077054317e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.4679560536023928e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.2403313576214714e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.65187270037859e-07
sam_encoder.blocks.10.norm1.weight grad: 3.6809046832786407e-06
sam_encoder.blocks.10.norm1.bias grad: 5.2610920420193e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.3302209228859283e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0381417041571694e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2708737813227344e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.918641588526953e-07
sam_encoder.blocks.10.norm2.weight grad: 4.443022135092178e-06
sam_encoder.blocks.10.norm2.bias grad: -1.953526407305617e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.082207967963768e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2818094319300144e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.9373344645478028e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.5522600683179917e-07
sam_encoder.blocks.11.norm1.weight grad: 1.8985419956152327e-05
sam_encoder.blocks.11.norm1.bias grad: -1.1599680505014476e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0622479749144986e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.735194801876787e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.7666732219367987e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.78765479986032e-07
sam_encoder.blocks.11.norm2.weight grad: 6.575720817636466e-06
sam_encoder.blocks.11.norm2.bias grad: 6.309733180387411e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.052019903610926e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.54395886765269e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.8359557429903361e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0937829131307808e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4786928659304976e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2186626918264665e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.6216943044564687e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.7759997717803344e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.7862522983923554e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 9.052328096004203e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00547774787992239
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00043330283369868994
mask_decoder.transformer.layers.0.norm3.weight grad: -1.5028793313831557e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.6010617148131132e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011200968583580106
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0430032489239238e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.880533429561183e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.9210638129152358e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001434472796972841
mask_decoder.transformer.layers.1.norm2.bias grad: 1.4075409126235172e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.527292574290186e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.521771355328383e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.239602953428403e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00020089754252694547
mask_decoder.transformer.norm_final_attn.weight grad: 5.020974185754312e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.352448614663444e-06
Text_Embedding_Affine.0.weight grad: 1.4220328040104313e-11
Text_Embedding_Affine.0.bias grad: 3.2984764919419263e-10
Text_Embedding_Affine.2.weight grad: 1.7097243759645053e-11
Text_Embedding_Affine.2.bias grad: 1.3110056897858158e-05
Epoch 23 finished with average loss: -61.8786
Epoch 24/39
----------
Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.5]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-55.5]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-59.9]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-59.9]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-57.8]Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-57.8]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3795283410620099e-14
Max value: 0.998279333114624
Mean value: 0.08244344592094421

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3795283410620099e-14
Max value: 0.998279333114624
Mean value: 0.08244344592094421

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08804798126220703

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12769365310668945

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07315635681152344

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08804798126220703

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.689796447753906
Max value: 88.35617065429688
Mean value: 55.45347595214844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3795283410620099e-14
Max value: 0.998279333114624
Mean value: 0.08244344592094421

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3795283410620099e-14
Max value: 0.998279333114624
Mean value: 0.08244344592094421

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3795283410620099e-14
Max value: 0.998279333114624
Mean value: 0.08244344592094421

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12769365310668945

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.689796447753906
Max value: 88.35617065429688
Mean value: 55.45347595214844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.454627990722656
Max value: -55.454627990722656
Mean value: -55.454627990722656
sam_encoder.pos_embed grad: -2.7523330281553626e-09
sam_encoder.blocks.0.norm1.weight grad: 1.4966028174967505e-05
sam_encoder.blocks.0.norm1.bias grad: -1.4145807654131204e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.058486855588853e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.697890184004791e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.227137186622713e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.8497913717728807e-06
sam_encoder.blocks.0.norm2.weight grad: -2.4145908810169203e-06
sam_encoder.blocks.0.norm2.bias grad: -1.3829352383254445e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.543131116311997e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.4670666789461393e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.916965048731072e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.968794433400035e-06
sam_encoder.blocks.1.norm1.weight grad: -8.480399628751911e-06
sam_encoder.blocks.1.norm1.bias grad: -1.678825356066227e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.6560702483257046e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.428844360721996e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 6.356781796057476e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.147718189211446e-06
sam_encoder.blocks.1.norm2.weight grad: 2.1504565665964037e-06
sam_encoder.blocks.1.norm2.bias grad: 9.009925634018146e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.674942713085329e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4828162875346607e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.0885628297692165e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.162801463067581e-09
sam_encoder.blocks.2.norm1.weight grad: 1.1287940651527606e-05
sam_encoder.blocks.2.norm1.bias grad: -5.5131504268501885e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 8.007646101759747e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.7180271925099078e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.5733752434243797e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.2238172075740295e-06
sam_encoder.blocks.2.norm2.weight grad: 9.938833500200417e-06
sam_encoder.blocks.2.norm2.bias grad: 1.1230874861212214e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.197201400937047e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.8424246945869527e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.6723697626730427e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.1897827789653093e-06
sam_encoder.blocks.3.norm1.weight grad: 7.325306796701625e-06
sam_encoder.blocks.3.norm1.bias grad: -2.2093051939009456e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.505577973963227e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.78884771837329e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.5740905610073241e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.472751591791166e-07
sam_encoder.blocks.3.norm2.weight grad: -1.4186238331603818e-05
sam_encoder.blocks.3.norm2.bias grad: -1.8363254639552906e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.6163208783837035e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.478823590645334e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.074458054972638e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.557500106893713e-07
sam_encoder.blocks.4.norm1.weight grad: 1.0679945262381807e-05
sam_encoder.blocks.4.norm1.bias grad: -2.4267772005259758e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.523840069239668e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.7596930774743669e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.054923863350268e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.0514572750253137e-06
sam_encoder.blocks.4.norm2.weight grad: -7.271608410519548e-06
sam_encoder.blocks.4.norm2.bias grad: -1.2868615158367902e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.327106919139624e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.1957733881426975e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1394716895883903e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.598372349093552e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4887078577885404e-05
sam_encoder.blocks.5.norm1.bias grad: -6.957248842809349e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.39423228171654e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.14553505834192e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.248565917601809e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.943942144564062e-07
sam_encoder.blocks.5.norm2.weight grad: 4.596809048962314e-06
sam_encoder.blocks.5.norm2.bias grad: -7.499036200897535e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.3047090305917663e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.6768035493441857e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7668080545263365e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.3371899260382634e-07
sam_encoder.blocks.6.norm1.weight grad: 7.273588835232658e-06
sam_encoder.blocks.6.norm1.bias grad: 1.1215155382160447e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.4714868130977266e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.988656433444703e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.7804770777729573e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.170386323996354e-06
sam_encoder.blocks.6.norm2.weight grad: -6.352660420816392e-06
sam_encoder.blocks.6.norm2.bias grad: -2.633336407598108e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.097845132695511e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.4089414435147773e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.364792635489721e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.52802192587842e-06
sam_encoder.blocks.7.norm1.weight grad: 5.307530045683961e-06
sam_encoder.blocks.7.norm1.bias grad: -1.0211582548436127e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.1181019696523435e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.114605877068243e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.8008659026236273e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.8537469916045666e-06
sam_encoder.blocks.7.norm2.weight grad: 9.287088573728397e-07
sam_encoder.blocks.7.norm2.bias grad: -1.4698988479722175e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.021061047547846e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.1358372375980252e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.184947889982141e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.32669740082747e-07
sam_encoder.blocks.8.norm1.weight grad: 9.033241440192796e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0092708180309273e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0780217053252272e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.2887886593234725e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.356081942409219e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.432502909272444e-07
sam_encoder.blocks.8.norm2.weight grad: 1.7583492990524974e-06
sam_encoder.blocks.8.norm2.bias grad: 2.2895351321494672e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.3451420954879723e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.3510011740436312e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.377831123112628e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.433536180518786e-08
sam_encoder.blocks.9.norm1.weight grad: 1.791398972272873e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0256314908474451e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.555347684094158e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.4704059948562644e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.563944517281925e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.39493009657599e-07
sam_encoder.blocks.9.norm2.weight grad: -1.3291241884871852e-07
sam_encoder.blocks.9.norm2.bias grad: 2.5302892936451826e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.497401727756369e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.5967667366112437e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.387449502653908e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.136767526892072e-07
sam_encoder.blocks.10.norm1.weight grad: 2.210726961493492e-06
sam_encoder.blocks.10.norm1.bias grad: 5.297009693094878e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.593988359782088e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.9025515030079987e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.045817547648767e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.278542948237373e-08
sam_encoder.blocks.10.norm2.weight grad: 4.556246040010592e-06
sam_encoder.blocks.10.norm2.bias grad: 2.8531994757940993e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.915564760376583e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.330290827667341e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.894948923109041e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.473768389194447e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0874455256271176e-05
sam_encoder.blocks.11.norm1.bias grad: 8.798906492302194e-09
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.5043785828747787e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.70541817018966e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.178853363460803e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.5254914842444123e-07
sam_encoder.blocks.11.norm2.weight grad: 9.516475984128192e-06
sam_encoder.blocks.11.norm2.bias grad: 3.7030063140264247e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.5454064598307014e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.729993869048485e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.9783075206069043e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.1048384749301476e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.660324414842762e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.435158603475429e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.525490006315522e-06
sam_encoder.neck.conv2.trainable_shift grad: 5.6849507927836385e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00014062266563996673
mask_decoder.transformer.layers.0.norm1.bias grad: 1.677122781984508e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004488803446292877
mask_decoder.transformer.layers.0.norm2.bias grad: -0.001245617982931435
mask_decoder.transformer.layers.0.norm3.weight grad: -5.078259709989652e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.055095632793382e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.003224840853363e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.717602678283583e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -5.979352135909721e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.7814261304447427e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -6.032744568074122e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0001316486013820395
mask_decoder.transformer.layers.1.norm3.weight grad: -6.447884516092017e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.540810863953084e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.5056849558022805e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 9.345151192974299e-05
mask_decoder.transformer.norm_final_attn.weight grad: -2.932452161985566e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.104781222238671e-05
Text_Embedding_Affine.0.weight grad: 1.9625329139572045e-11
Text_Embedding_Affine.0.bias grad: 7.436247173586708e-10
Text_Embedding_Affine.2.weight grad: -3.90897730850881e-11
Text_Embedding_Affine.2.bias grad: -5.3192939958535135e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.257912353603077e-16
Max value: 0.9996781349182129
Mean value: 0.08656373620033264

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.257912353603077e-16
Max value: 0.9996781349182129
Mean value: 0.08656373620033264

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08692216873168945

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1167876273393631

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07871532440185547

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08692216873168945

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.69380569458008
Max value: 76.09517669677734
Mean value: 64.38152313232422

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.4199691068990366e-15
Max value: 0.9996092915534973
Mean value: 0.08712883293628693

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4199691068990366e-15
Max value: 0.9996092915534973
Mean value: 0.08712883293628693

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4199691068990366e-15
Max value: 0.9996092915534973
Mean value: 0.08712883293628693

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11647439002990723

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9363051056861877
Max value: 1.8203930854797363
Mean value: 1.0003650188446045

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.69380569458008
Max value: 76.09517669677734
Mean value: 64.38152313232422

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.40459442138672
Max value: -64.40459442138672
Mean value: -64.40459442138672
sam_encoder.pos_embed grad: -3.3486002859461905e-09
sam_encoder.blocks.0.norm1.weight grad: 8.787362162365753e-07
sam_encoder.blocks.0.norm1.bias grad: -1.793463343346957e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.780451723083388e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.556373376843112e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.856560397252906e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.716723876503238e-07
sam_encoder.blocks.0.norm2.weight grad: 1.435565991414478e-05
sam_encoder.blocks.0.norm2.bias grad: 3.495803684927523e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.739252967236098e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.544069841154851e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.3877312994736712e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.245303898642305e-06
sam_encoder.blocks.1.norm1.weight grad: 7.479491614503786e-06
sam_encoder.blocks.1.norm1.bias grad: 9.566530025040265e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.017699898715364e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.282537702238187e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.189825055320398e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.260013484890806e-07
sam_encoder.blocks.1.norm2.weight grad: 1.3933000445831567e-05
sam_encoder.blocks.1.norm2.bias grad: -3.6477838420978514e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.762932687503053e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.12163502308249e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.825807190580235e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.319362111957162e-07
sam_encoder.blocks.2.norm1.weight grad: 7.630575055372901e-06
sam_encoder.blocks.2.norm1.bias grad: -9.787834187591216e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.3850581075967057e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.973270956223132e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.205916752653138e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 7.817799883014231e-07
sam_encoder.blocks.2.norm2.weight grad: -1.0929623385891318e-05
sam_encoder.blocks.2.norm2.bias grad: -1.1510923286550678e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.734072601626394e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.5330327844130807e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2833229448006023e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6153517208294943e-06
sam_encoder.blocks.3.norm1.weight grad: 1.146536078522331e-06
sam_encoder.blocks.3.norm1.bias grad: 6.428484766729525e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.29656707171489e-08
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.813425036331864e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.488891257395153e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.755747234710725e-06
sam_encoder.blocks.3.norm2.weight grad: 6.710507477691863e-06
sam_encoder.blocks.3.norm2.bias grad: -6.312997129498399e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.509197762876283e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.337253934252658e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.107907317229547e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.872554094006773e-07
sam_encoder.blocks.4.norm1.weight grad: 6.8862937041558325e-06
sam_encoder.blocks.4.norm1.bias grad: 3.749595123281324e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.5012633411970455e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.3568266865604528e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4986889027568395e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.5885478887867066e-06
sam_encoder.blocks.4.norm2.weight grad: -1.9653794879559427e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3427492376649752e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.320145747740753e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.313673227647087e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.028766632771294e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.778183655522298e-07
sam_encoder.blocks.5.norm1.weight grad: 3.846460458589718e-06
sam_encoder.blocks.5.norm1.bias grad: -4.130567049287492e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.3528186829935294e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.2843871028708236e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.8600808289193083e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.263492890757334e-06
sam_encoder.blocks.5.norm2.weight grad: -1.2425218301359564e-05
sam_encoder.blocks.5.norm2.bias grad: -6.231459337868728e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.165495506138541e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.437061766613624e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4509871562040644e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.4971254219963157e-07
sam_encoder.blocks.6.norm1.weight grad: 7.87866156315431e-07
sam_encoder.blocks.6.norm1.bias grad: 3.0697071906615747e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2181975534986123e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.278637450421229e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.789368959900457e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.456445582145534e-07
sam_encoder.blocks.6.norm2.weight grad: -3.2153475331142545e-06
sam_encoder.blocks.6.norm2.bias grad: 3.9579703070558026e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.98632085105055e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.4549941624864005e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.702369610891765e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.657323640662071e-07
sam_encoder.blocks.7.norm1.weight grad: 4.386921318655368e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3735364063904854e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.193211796315154e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.912383140734164e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.375712031403964e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.512537946586235e-07
sam_encoder.blocks.7.norm2.weight grad: -1.1252366221015109e-06
sam_encoder.blocks.7.norm2.bias grad: 1.0731243946793256e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.840600915187679e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.63920228969073e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.266758317797212e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0562648640188854e-06
sam_encoder.blocks.8.norm1.weight grad: 5.71967575524468e-06
sam_encoder.blocks.8.norm1.bias grad: 4.0003065748805966e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.6170738439977868e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.6617912024230463e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.306255285271618e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.703045750735328e-08
sam_encoder.blocks.8.norm2.weight grad: 5.734892738473718e-07
sam_encoder.blocks.8.norm2.bias grad: -8.493080940752407e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.981701403674379e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.8193793493992416e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.506094791802752e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.328869600087273e-08
sam_encoder.blocks.9.norm1.weight grad: 7.024777914921287e-07
sam_encoder.blocks.9.norm1.bias grad: 6.670455832136213e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.8629046628102515e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.373318975263828e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.738053563523863e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.119802430428535e-08
sam_encoder.blocks.9.norm2.weight grad: 3.4794511520885862e-06
sam_encoder.blocks.9.norm2.bias grad: -3.2824573281686753e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.4790485895209713e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2909383713122224e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.800301086215768e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.1865051874337951e-07
sam_encoder.blocks.10.norm1.weight grad: 3.5210937312513124e-06
sam_encoder.blocks.10.norm1.bias grad: 1.2015441370749613e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.2601989257964306e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.062593355527497e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.982428537114174e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.747793980186543e-07
sam_encoder.blocks.10.norm2.weight grad: 5.705360308638774e-07
sam_encoder.blocks.10.norm2.bias grad: -1.4778011063754093e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.9433582565397955e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.868434532705578e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.390946734631143e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.566374395333696e-07
sam_encoder.blocks.11.norm1.weight grad: 1.4707346963405143e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6201827293116366e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.991401515828329e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1471472589619225e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.5790893687371863e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.017627462526434e-07
sam_encoder.blocks.11.norm2.weight grad: 7.490541520382976e-06
sam_encoder.blocks.11.norm2.bias grad: -1.8376553612142743e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.429548764368519e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0203500551142497e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.889543785997375e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.818584050601203e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.498965715058148e-08
sam_encoder.neck.conv1.trainable_shift grad: -6.065933121135458e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.705201040953398e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.900288331555203e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 1.8136439393856563e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.9980219551362097e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00596988620236516
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00038497813511639833
mask_decoder.transformer.layers.0.norm3.weight grad: -6.177710019983351e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -2.7712572773452848e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001286639308091253
mask_decoder.transformer.layers.0.norm4.bias grad: -8.090459232334979e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.367278648307547e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.026498805207666e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -9.671827865531668e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.4506246922537684e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.663300958578475e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.80662300408585e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.207887731259689e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.000226002826821059
mask_decoder.transformer.norm_final_attn.weight grad: 2.610686351545155e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.611543646315113e-06
Text_Embedding_Affine.0.weight grad: -5.5000413945460735e-12
Text_Embedding_Affine.0.bias grad: -5.542856451601352e-11
Text_Embedding_Affine.2.weight grad: -3.6242626955118595e-11
Text_Embedding_Affine.2.bias grad: 8.965893357526511e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.232268222405071e-14
Max value: 0.9965841770172119
Mean value: 0.06563639640808105

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.232268222405071e-14
Max value: 0.9965841770172119
Mean value: 0.06563639640808105

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06984519958496094

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11180299520492554

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05233192443847656

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06984519958496094

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 46.72631072998047
Max value: 56.891597747802734
Mean value: 53.48749923706055

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0891741203606156e-13
Max value: 0.9960487484931946
Mean value: 0.06594201922416687

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0891741203606156e-13
Max value: 0.9960487484931946
Mean value: 0.06594201922416687

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0891741203606156e-13
Max value: 0.9960487484931946
Mean value: 0.06594201922416687

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1114458441734314

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8643313050270081
Max value: 1.6915256977081299
Mean value: 1.0004509687423706

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 46.72631072998047
Max value: 56.891597747802734
Mean value: 53.48749923706055

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.50876235961914
Max value: -53.50876235961914
Mean value: -53.50876235961914
sam_encoder.pos_embed grad: -6.239857963663553e-09
sam_encoder.blocks.0.norm1.weight grad: 6.34681637166068e-05
sam_encoder.blocks.0.norm1.bias grad: 1.603711280040443e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.169859948888188e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.300800580698706e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.792663382133469e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.532603960185952e-06
sam_encoder.blocks.0.norm2.weight grad: -1.5599023299728287e-06
sam_encoder.blocks.0.norm2.bias grad: 4.3295451177982613e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2888895071228035e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.4898517949623056e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.5261637599905953e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.60752880826476e-06
sam_encoder.blocks.1.norm1.weight grad: 1.7865033441921696e-05
sam_encoder.blocks.1.norm1.bias grad: 9.439176210435107e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.654973839838931e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.8632060800882755e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.4598558563156985e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.574192310727085e-06
sam_encoder.blocks.1.norm2.weight grad: 2.1678721168427728e-05
sam_encoder.blocks.1.norm2.bias grad: 2.3140305529523175e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.0046426218177658e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.124077233631397e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.073510015383363e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.1507559583587863e-07
sam_encoder.blocks.2.norm1.weight grad: -1.1609634384512901e-05
sam_encoder.blocks.2.norm1.bias grad: 1.1663603061151662e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.66341815708438e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.068830326606985e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.416755918005947e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.900549695070367e-06
sam_encoder.blocks.2.norm2.weight grad: -1.7616239347262308e-05
sam_encoder.blocks.2.norm2.bias grad: 3.4877944017353e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.2739641533698887e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.7866633445228217e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.289207259309478e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2140465059928829e-06
sam_encoder.blocks.3.norm1.weight grad: -3.6465007724473253e-07
sam_encoder.blocks.3.norm1.bias grad: 1.0630224096530583e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.977496367544518e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.684833072587935e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.179489216468937e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -8.405777407460846e-07
sam_encoder.blocks.3.norm2.weight grad: -6.9814122980460525e-06
sam_encoder.blocks.3.norm2.bias grad: -1.317484384344425e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.093602446024306e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.898256636603037e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.3755845834093634e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.067811462642567e-07
sam_encoder.blocks.4.norm1.weight grad: -1.1390404779376695e-06
sam_encoder.blocks.4.norm1.bias grad: -8.07773722044658e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.541452537727309e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.7667210840954795e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.507872295609559e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.0686043171735946e-06
sam_encoder.blocks.4.norm2.weight grad: -5.0644748625927605e-06
sam_encoder.blocks.4.norm2.bias grad: -9.95924665403436e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.3787356440152507e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.281193246744806e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.554011189204175e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.681423604324664e-07
sam_encoder.blocks.5.norm1.weight grad: 1.8898732378147542e-05
sam_encoder.blocks.5.norm1.bias grad: -1.0067917173728347e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4826534425083082e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.011868208588567e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.4031014618230984e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.841689249384217e-06
sam_encoder.blocks.5.norm2.weight grad: 4.2699480218288954e-06
sam_encoder.blocks.5.norm2.bias grad: 3.6432593333302066e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.2038610697782133e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.3585495745901426e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.08367873710813e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.1274470302378177e-07
sam_encoder.blocks.6.norm1.weight grad: 1.5103718396858312e-05
sam_encoder.blocks.6.norm1.bias grad: -5.655454060615739e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2371335287753027e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.673029136232799e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.4195734315289883e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.5231231575162383e-06
sam_encoder.blocks.6.norm2.weight grad: -4.160128810326569e-07
sam_encoder.blocks.6.norm2.bias grad: 4.9031082198780496e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3618753200717038e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.407270459225401e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4732707995790406e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.978404995384153e-08
sam_encoder.blocks.7.norm1.weight grad: 4.981237907486502e-06
sam_encoder.blocks.7.norm1.bias grad: -3.5437187761999667e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.354343562023132e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.785749408460106e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.790733201953117e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.29377347852278e-07
sam_encoder.blocks.7.norm2.weight grad: 2.0449860471671855e-07
sam_encoder.blocks.7.norm2.bias grad: 2.876575706522999e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.6376411622331943e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.1022278790260316e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.5267344224412227e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.762454737938242e-07
sam_encoder.blocks.8.norm1.weight grad: 1.8137379811378196e-06
sam_encoder.blocks.8.norm1.bias grad: -2.8605650186364073e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.3526256376935635e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.6980879991024267e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.269775452783506e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.8952310887907515e-07
sam_encoder.blocks.8.norm2.weight grad: 1.303042949984956e-06
sam_encoder.blocks.8.norm2.bias grad: 3.156825130190555e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.500497420347529e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.235879593281425e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.99468793388769e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.692180487429141e-07
sam_encoder.blocks.9.norm1.weight grad: 2.4583362119301455e-06
sam_encoder.blocks.9.norm1.bias grad: 1.250936406904657e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.4987530221333145e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.958211997698527e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.0232808967411984e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.297233987126674e-07
sam_encoder.blocks.9.norm2.weight grad: 4.344099124864442e-06
sam_encoder.blocks.9.norm2.bias grad: 2.729287643887801e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8092912341671763e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.7529671367810806e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3091064374748385e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.466212986808387e-07
sam_encoder.blocks.10.norm1.weight grad: -1.750144491552419e-07
sam_encoder.blocks.10.norm1.bias grad: 2.8861268219770864e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -8.697903552956632e-08
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.1900754632042663e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.03376901658703e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.4117522084688972e-07
sam_encoder.blocks.10.norm2.weight grad: 7.720905159658287e-06
sam_encoder.blocks.10.norm2.bias grad: 2.5239439764845883e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.674243660294451e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.592953367435257e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.537572747016384e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.528890258370666e-07
sam_encoder.blocks.11.norm1.weight grad: -8.136876203934662e-06
sam_encoder.blocks.11.norm1.bias grad: 8.758603939895693e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.9306858121126425e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.123733212210936e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.5753562365716789e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.2432722087396542e-06
sam_encoder.blocks.11.norm2.weight grad: 1.6469042520839139e-06
sam_encoder.blocks.11.norm2.bias grad: 1.3596389862868818e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.2578331027034437e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.7810067965438066e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.3285210204448958e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.680520871464978e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.94092091685161e-08
sam_encoder.neck.conv1.trainable_shift grad: 2.20207693928387e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.591261025168933e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.92297406506259e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -8.090665505733341e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -6.06317917117849e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003359447466209531
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00043149746488779783
mask_decoder.transformer.layers.0.norm3.weight grad: -2.5148758140858263e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -7.418415771098807e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -4.260741843609139e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.0276573751471005e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.609789928304963e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.3674747353652492e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00023003804381005466
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00020398464403115213
mask_decoder.transformer.layers.1.norm3.weight grad: -7.382652984233573e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -7.278662815224379e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.4429100196575746e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 9.08668152987957e-06
mask_decoder.transformer.norm_final_attn.weight grad: -6.256969413698243e-07
mask_decoder.transformer.norm_final_attn.bias grad: -9.868756023934111e-06
Text_Embedding_Affine.0.weight grad: 9.924371220659811e-12
Text_Embedding_Affine.0.bias grad: 4.542677900509773e-10
Text_Embedding_Affine.2.weight grad: -6.3323708256179945e-12
Text_Embedding_Affine.2.bias grad: 1.227411485160701e-05
Epoch 24 finished with average loss: -57.7893
Epoch 25/39
----------
Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.7]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-55.7]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-61]  Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-61]Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-62.1]Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-62.1]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.4071022912696147e-12
Max value: 0.9961949586868286
Mean value: 0.07270512729883194

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.4071022912696147e-12
Max value: 0.9961949586868286
Mean value: 0.07270512729883194

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07487916946411133

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10831909626722336

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06131744384765625

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07487916946411133

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.70450973510742
Max value: 63.258541107177734
Mean value: 55.704776763916016

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.4071022912696147e-12
Max value: 0.9961949586868286
Mean value: 0.07270512729883194

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.4071022912696147e-12
Max value: 0.9961949586868286
Mean value: 0.07270512729883194

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.4071022912696147e-12
Max value: 0.9961949586868286
Mean value: 0.07270512729883194

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10831909626722336

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.70450973510742
Max value: 63.258541107177734
Mean value: 55.704776763916016

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.70588684082031
Max value: -55.70588684082031
Mean value: -55.70588684082031
sam_encoder.pos_embed grad: -1.7922765493949555e-09
sam_encoder.blocks.0.norm1.weight grad: 1.3584374755737372e-05
sam_encoder.blocks.0.norm1.bias grad: 4.8647983931005e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.088987801267649e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.941506959876278e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.382819037753507e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.410846207112627e-07
sam_encoder.blocks.0.norm2.weight grad: 6.518434020108543e-06
sam_encoder.blocks.0.norm2.bias grad: 6.796783418394625e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.8105112758348696e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.553789949568454e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.5724934200989082e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.710903795057675e-06
sam_encoder.blocks.1.norm1.weight grad: -2.676889835129259e-06
sam_encoder.blocks.1.norm1.bias grad: 2.485027380316751e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.4247932489961386e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.454559186546248e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.0860911718045827e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.5217725578841055e-06
sam_encoder.blocks.1.norm2.weight grad: 2.605474401207175e-05
sam_encoder.blocks.1.norm2.bias grad: 5.369893187889829e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.276875749084866e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6607126553935814e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.9989315559505485e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3610032283395412e-06
sam_encoder.blocks.2.norm1.weight grad: 6.890310828566726e-07
sam_encoder.blocks.2.norm1.bias grad: -6.666226681772969e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.9399978984656627e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.1149829737842083e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.515673026617151e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.9516753582138335e-06
sam_encoder.blocks.2.norm2.weight grad: 1.3128948012308683e-05
sam_encoder.blocks.2.norm2.bias grad: -1.0321552508685272e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.106463504489511e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.6200864883539907e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.9331077965034638e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5256895267157233e-06
sam_encoder.blocks.3.norm1.weight grad: 1.1864385669468902e-05
sam_encoder.blocks.3.norm1.bias grad: -1.554669665893016e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.2379574551887345e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.5497182630497264e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.244358938696678e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.6538608583214227e-06
sam_encoder.blocks.3.norm2.weight grad: 6.6164557210868225e-06
sam_encoder.blocks.3.norm2.bias grad: -6.369249376803054e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.8688718884950504e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.6584126569796354e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.0444644971130401e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.439898475538939e-07
sam_encoder.blocks.4.norm1.weight grad: 1.2346155926934443e-05
sam_encoder.blocks.4.norm1.bias grad: -2.8516396923805587e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.138398511102423e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.430378339748131e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.708841061074054e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.319279352988815e-06
sam_encoder.blocks.4.norm2.weight grad: -1.1799338608398102e-05
sam_encoder.blocks.4.norm2.bias grad: -1.9928731489926577e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.366050678887405e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.1154056614468573e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.2579540680235368e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.11912457265862e-07
sam_encoder.blocks.5.norm1.weight grad: 5.82875281907036e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2433134543243796e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.887875547865406e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.0004692967413575e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.02535146754235e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.7049904929299373e-06
sam_encoder.blocks.5.norm2.weight grad: -7.96813219494652e-06
sam_encoder.blocks.5.norm2.bias grad: -2.7576613774726866e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.4481298623868497e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2417599464242812e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.349953428572917e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.181882892837166e-07
sam_encoder.blocks.6.norm1.weight grad: -4.448206709639635e-06
sam_encoder.blocks.6.norm1.bias grad: 4.225894372211769e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.7069437389145605e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.102493226630031e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.2608010112890042e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.759182724636048e-08
sam_encoder.blocks.6.norm2.weight grad: -4.681721293309238e-06
sam_encoder.blocks.6.norm2.bias grad: 2.3802806481398875e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.794998403667705e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.6128709578188136e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.980063626040646e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.886581213118916e-07
sam_encoder.blocks.7.norm1.weight grad: 5.066373887530062e-06
sam_encoder.blocks.7.norm1.bias grad: 9.981347375287442e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.599345296199317e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0452690730744507e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.650092245763517e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.6214809167868225e-07
sam_encoder.blocks.7.norm2.weight grad: -3.5370953810343053e-06
sam_encoder.blocks.7.norm2.bias grad: 2.1981711029184225e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.005476292448293e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.654609367411467e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1105624935225933e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.7734542956968653e-07
sam_encoder.blocks.8.norm1.weight grad: 2.717271399887977e-06
sam_encoder.blocks.8.norm1.bias grad: -3.331151674501598e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.7326764236713643e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.863160316086578e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.79607762019441e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.4219667718862183e-06
sam_encoder.blocks.8.norm2.weight grad: -3.4087912581526325e-07
sam_encoder.blocks.8.norm2.bias grad: -1.7863492303149542e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.1220172382309102e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.457544259319548e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.4025700895435875e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0739874767295987e-07
sam_encoder.blocks.9.norm1.weight grad: -3.7823454022145597e-06
sam_encoder.blocks.9.norm1.bias grad: -2.6057381319333217e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.028574155905517e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1252226386204711e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.81237624019559e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1304613281026832e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4116940292296931e-06
sam_encoder.blocks.9.norm2.bias grad: -2.387557742622448e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.201507868448971e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.7120195252573467e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.800064617593307e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.396226245262369e-07
sam_encoder.blocks.10.norm1.weight grad: -9.145228432316799e-07
sam_encoder.blocks.10.norm1.bias grad: 4.399859676595952e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.352183739480097e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.973142146511236e-09
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.106034564050788e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.842561741545069e-07
sam_encoder.blocks.10.norm2.weight grad: 4.4458174670580775e-06
sam_encoder.blocks.10.norm2.bias grad: -5.568728624893993e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.0047053820017027e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.5050039766938426e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.8838563846657053e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.3702764312693034e-07
sam_encoder.blocks.11.norm1.weight grad: 2.4995722924359143e-05
sam_encoder.blocks.11.norm1.bias grad: 1.157408860308351e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.599070169002516e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.158484448955278e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.317223222940811e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.8042086341883987e-07
sam_encoder.blocks.11.norm2.weight grad: -5.504300020220398e-07
sam_encoder.blocks.11.norm2.bias grad: -1.521172976026719e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.628991637720901e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.4447933810733957e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.643690410446652e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.314523375294812e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4570114217349328e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.4781808204133995e-05
sam_encoder.neck.conv2.trainable_scale grad: 5.920837793382816e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.9755436116829515e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00021611683769151568
mask_decoder.transformer.layers.0.norm1.bias grad: 1.5297409845516086e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003656126093119383
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0016169734299182892
mask_decoder.transformer.layers.0.norm3.weight grad: 4.373378396849148e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.686599903739989e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001197159435832873
mask_decoder.transformer.layers.0.norm4.bias grad: -1.9510100173647515e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.856649982481031e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 4.789868853549706e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00014128940529190004
mask_decoder.transformer.layers.1.norm2.bias grad: -4.9089823733083904e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.033644705079496e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -1.1780693967011757e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.4557433031732216e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016139302169904113
mask_decoder.transformer.norm_final_attn.weight grad: -1.1468632692412939e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.1258225590136135e-06
Text_Embedding_Affine.0.weight grad: 3.91730675675106e-11
Text_Embedding_Affine.0.bias grad: 1.0923639770510363e-09
Text_Embedding_Affine.2.weight grad: 4.374198052381484e-12
Text_Embedding_Affine.2.bias grad: -2.8801609005313367e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.2540527929403031e-13
Max value: 0.9990662932395935
Mean value: 0.08122198283672333

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2540527929403031e-13
Max value: 0.9990662932395935
Mean value: 0.08122198283672333

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08979511260986328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11585041135549545

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07416725158691406

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08979511260986328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 34.888240814208984
Max value: 87.95929718017578
Mean value: 66.30482482910156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.527310992521097e-13
Max value: 0.9992066025733948
Mean value: 0.08208468556404114

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.527310992521097e-13
Max value: 0.9992066025733948
Mean value: 0.08208468556404114

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.527310992521097e-13
Max value: 0.9992066025733948
Mean value: 0.08208468556404114

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11566515266895294

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6802772283554077
Max value: 1.090961217880249
Mean value: 1.0002233982086182

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 34.888240814208984
Max value: 87.95929718017578
Mean value: 66.30482482910156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.32219696044922
Max value: -66.32219696044922
Mean value: -66.32219696044922
sam_encoder.pos_embed grad: -1.2258523085506567e-08
sam_encoder.blocks.0.norm1.weight grad: 0.00016001897165551782
sam_encoder.blocks.0.norm1.bias grad: -4.435536084201885e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.299273187934887e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.0131197686623636e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.2500704466874595e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.8204856334923534e-06
sam_encoder.blocks.0.norm2.weight grad: -5.217060606810264e-05
sam_encoder.blocks.0.norm2.bias grad: 4.429783530213172e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.765012014715467e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.9127370402857196e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.291323764642584e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.7295434392726747e-06
sam_encoder.blocks.1.norm1.weight grad: 8.879578672349453e-06
sam_encoder.blocks.1.norm1.bias grad: -7.335540431085974e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.642233635531738e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0021460639109137e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 6.9167144829407334e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.80702294933144e-06
sam_encoder.blocks.1.norm2.weight grad: -1.1571351024031173e-05
sam_encoder.blocks.1.norm2.bias grad: 9.366268386656884e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.071012990105373e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.545336090202909e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.2643212105322164e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.584264380966488e-07
sam_encoder.blocks.2.norm1.weight grad: 4.608045401255367e-06
sam_encoder.blocks.2.norm1.bias grad: -7.70201313571306e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.706099727831315e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.232511514601356e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.7906467039429117e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.1336953725258354e-06
sam_encoder.blocks.2.norm2.weight grad: -5.016184331907425e-06
sam_encoder.blocks.2.norm2.bias grad: 5.369130121835042e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.2365669590508332e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.941015158190567e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.981230980163673e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.66114874042978e-07
sam_encoder.blocks.3.norm1.weight grad: 5.157309715286829e-06
sam_encoder.blocks.3.norm1.bias grad: -9.68263248068979e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.379550202633254e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.0673015771753853e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.1170955026027514e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.621801501045411e-07
sam_encoder.blocks.3.norm2.weight grad: -1.3117037269694265e-05
sam_encoder.blocks.3.norm2.bias grad: -1.3256611055112444e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.653122106101364e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.1118453231756575e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.3719613838911755e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.6987072513074963e-06
sam_encoder.blocks.4.norm1.weight grad: 7.664794793527108e-06
sam_encoder.blocks.4.norm1.bias grad: -5.453146059153369e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0111052688444033e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.2397195443300006e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.5349466998013668e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.0278291685826844e-06
sam_encoder.blocks.4.norm2.weight grad: -1.2085814887541346e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0148989531444386e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.1702892354369396e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6407539078500122e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.229728008591337e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.755191973046749e-07
sam_encoder.blocks.5.norm1.weight grad: 1.6595797205809504e-05
sam_encoder.blocks.5.norm1.bias grad: 3.7110585253685713e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.719757715880405e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.2952284527709708e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.6418011809000745e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.9239860193920322e-07
sam_encoder.blocks.5.norm2.weight grad: 5.216259069129592e-06
sam_encoder.blocks.5.norm2.bias grad: -7.630658728885464e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.575764940753288e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.155457074579317e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.424128072358144e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.985718481340882e-07
sam_encoder.blocks.6.norm1.weight grad: 7.914018169685733e-06
sam_encoder.blocks.6.norm1.bias grad: 3.934168489649892e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.531091457873117e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.715901700867107e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6921203496167436e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.5993605302355718e-06
sam_encoder.blocks.6.norm2.weight grad: -2.718871428442071e-06
sam_encoder.blocks.6.norm2.bias grad: -4.748454102809774e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.842595106107183e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.81963694357546e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.2283414889679989e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.519450721498288e-07
sam_encoder.blocks.7.norm1.weight grad: 1.3111175576341338e-05
sam_encoder.blocks.7.norm1.bias grad: -3.528595868829143e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.867328117252328e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.8233357625140343e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.528140379989054e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.440598670247709e-06
sam_encoder.blocks.7.norm2.weight grad: -1.6284775483654812e-06
sam_encoder.blocks.7.norm2.bias grad: -5.609990694210865e-09
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.5767162696865853e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.334618435881566e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.100150252066669e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.54346649753279e-07
sam_encoder.blocks.8.norm1.weight grad: 8.984346095530782e-06
sam_encoder.blocks.8.norm1.bias grad: -1.7866790358311846e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.02260944712907e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.7793419121735496e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.0580874863517238e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.0917236724926624e-06
sam_encoder.blocks.8.norm2.weight grad: 6.842456969025079e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5482210073969327e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.205338311498053e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.6637297853303608e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.9211728360678535e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.259881173609756e-06
sam_encoder.blocks.9.norm1.weight grad: 7.082285719661741e-06
sam_encoder.blocks.9.norm1.bias grad: 1.3171196542316466e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.675635409512324e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.473315933253616e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.4449900618274114e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.931064500444336e-06
sam_encoder.blocks.9.norm2.weight grad: 1.3321116057340987e-05
sam_encoder.blocks.9.norm2.bias grad: 3.985278908658074e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.485803052986739e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.045620582677657e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.6194099973508855e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.3868815358364373e-06
sam_encoder.blocks.10.norm1.weight grad: 5.348778358893469e-06
sam_encoder.blocks.10.norm1.bias grad: 2.4582250262028538e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.1993228074279614e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0130136161023984e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.575694489972193e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.703386599023361e-07
sam_encoder.blocks.10.norm2.weight grad: 2.0759804101544432e-05
sam_encoder.blocks.10.norm2.bias grad: 6.3098814280238e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.377952665090561e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.607438313541934e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.04223408420512e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.2014143067062832e-06
sam_encoder.blocks.11.norm1.weight grad: 1.3258412764116656e-05
sam_encoder.blocks.11.norm1.bias grad: -4.3405407268437557e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.08495588999358e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.329639189862064e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.255919414688833e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.231708541941771e-07
sam_encoder.blocks.11.norm2.weight grad: 2.4700979338376783e-05
sam_encoder.blocks.11.norm2.bias grad: 4.66294204670703e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.009334755508462e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.534361778496532e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.842145815724507e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.7988995750783943e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.38305983657483e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.618696064222604e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.57642113865586e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.0829385650577024e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00024195901642087847
mask_decoder.transformer.layers.0.norm1.bias grad: 3.164983354508877e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0025629308074712753
mask_decoder.transformer.layers.0.norm2.bias grad: -0.002198501257225871
mask_decoder.transformer.layers.0.norm3.weight grad: 7.191102486103773e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.516807479783893e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -3.74072405975312e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.2772410375182517e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -4.76899222121574e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.594163667410612e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00015786918811500072
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00010319369903299958
mask_decoder.transformer.layers.1.norm3.weight grad: -8.345088281203061e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.321353430394083e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.139164467342198e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -3.914442640962079e-05
mask_decoder.transformer.norm_final_attn.weight grad: -3.0649266591353808e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2098616934963502e-05
Text_Embedding_Affine.0.weight grad: 1.4658311023318937e-11
Text_Embedding_Affine.0.bias grad: 7.321281358940723e-10
Text_Embedding_Affine.2.weight grad: -5.922391743684585e-11
Text_Embedding_Affine.2.bias grad: -7.910672866273671e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.068828810661028e-14
Max value: 0.9992507100105286
Mean value: 0.09530274569988251

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.068828810661028e-14
Max value: 0.9992507100105286
Mean value: 0.09530274569988251

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08871936798095703

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1317419707775116

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09186553955078125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08871936798095703

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 55.07999801635742
Max value: 77.66919708251953
Mean value: 64.3746566772461

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.73894295001687e-14
Max value: 0.9993886947631836
Mean value: 0.09708990156650543

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.73894295001687e-14
Max value: 0.9993886947631836
Mean value: 0.09708990156650543

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.73894295001687e-14
Max value: 0.9993886947631836
Mean value: 0.09708990156650543

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13220664858818054

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6935138702392578
Max value: 1.5514544248580933
Mean value: 0.9996802806854248

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 55.07999801635742
Max value: 77.66919708251953
Mean value: 64.3746566772461

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.35240173339844
Max value: -64.35240173339844
Mean value: -64.35240173339844
sam_encoder.pos_embed grad: -3.8114755795959354e-09
sam_encoder.blocks.0.norm1.weight grad: -2.5558849301887676e-05
sam_encoder.blocks.0.norm1.bias grad: 1.0264100637868978e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0132347227909122e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.902514198576682e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.029034244013019e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.325490176095627e-07
sam_encoder.blocks.0.norm2.weight grad: 1.9501236238284037e-05
sam_encoder.blocks.0.norm2.bias grad: 1.4801876204728615e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.810261998500209e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.941171149155707e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5229997188725974e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.39259587842389e-06
sam_encoder.blocks.1.norm1.weight grad: 4.889486717729596e-06
sam_encoder.blocks.1.norm1.bias grad: -6.205599675013218e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.192444066575263e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.033558646668098e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.4648378459678497e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.787308161117835e-07
sam_encoder.blocks.1.norm2.weight grad: 1.9918184989364818e-05
sam_encoder.blocks.1.norm2.bias grad: -4.404400897328742e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.524112566490658e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.0287254756112816e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.053252612517099e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.1998350752692204e-07
sam_encoder.blocks.2.norm1.weight grad: -1.0481233402970247e-05
sam_encoder.blocks.2.norm1.bias grad: -4.609404186339816e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.3719830905029085e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7289567040279508e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.9577047320781276e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.090564743819414e-06
sam_encoder.blocks.2.norm2.weight grad: -9.731211321195588e-06
sam_encoder.blocks.2.norm2.bias grad: -1.3192837286624126e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.704785513036768e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.075607881124597e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.1316133168293163e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.679406350125646e-07
sam_encoder.blocks.3.norm1.weight grad: -5.534539923246484e-06
sam_encoder.blocks.3.norm1.bias grad: -3.645344349934021e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.005358838796383e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.235481590811105e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.886197520041605e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.5736317209302797e-06
sam_encoder.blocks.3.norm2.weight grad: 7.538529644079972e-06
sam_encoder.blocks.3.norm2.bias grad: -4.91215769216069e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.131918442202732e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.768030753941275e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.1555177198706588e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.365570576846949e-07
sam_encoder.blocks.4.norm1.weight grad: 3.528525212459499e-06
sam_encoder.blocks.4.norm1.bias grad: -4.544204330159118e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.4762554201297462e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.849900167551823e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.400230641796952e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.238723936898168e-06
sam_encoder.blocks.4.norm2.weight grad: -2.6499576051719487e-05
sam_encoder.blocks.4.norm2.bias grad: -2.1783029296784662e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8744169210549444e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.23049333828385e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.998337873184937e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4150793958833674e-06
sam_encoder.blocks.5.norm1.weight grad: 9.65320214163512e-06
sam_encoder.blocks.5.norm1.bias grad: -1.1463564078439958e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.6147255236282945e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.373385647544637e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.559458830044605e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.155786205548793e-06
sam_encoder.blocks.5.norm2.weight grad: -8.790735591901466e-06
sam_encoder.blocks.5.norm2.bias grad: -1.2063595931977034e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.671220047683164e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.3627951034322905e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.391860562056536e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.5015572191477986e-07
sam_encoder.blocks.6.norm1.weight grad: -9.2416712504928e-07
sam_encoder.blocks.6.norm1.bias grad: 1.5447408259205986e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.5527593859587796e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.4154930378681456e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.812542980265789e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.474483598140068e-07
sam_encoder.blocks.6.norm2.weight grad: -1.6401681932620704e-06
sam_encoder.blocks.6.norm2.bias grad: -5.593095693257055e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.7452828160458012e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.086588655307423e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.24972949228686e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.278898906775794e-07
sam_encoder.blocks.7.norm1.weight grad: 5.7612478485680185e-06
sam_encoder.blocks.7.norm1.bias grad: 3.247199344968976e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.6508367884380277e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.786174718494294e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.372117801831337e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.654078674728225e-07
sam_encoder.blocks.7.norm2.weight grad: 2.426957962597953e-06
sam_encoder.blocks.7.norm2.bias grad: 4.4504668039735407e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.837763415504014e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.2407663234625943e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.606758636782615e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.742597070617194e-07
sam_encoder.blocks.8.norm1.weight grad: 5.648480055242544e-06
sam_encoder.blocks.8.norm1.bias grad: -5.564929779211525e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.2801526685943827e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.549687794977217e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.3148233430656546e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.91552496998338e-07
sam_encoder.blocks.8.norm2.weight grad: -6.174803957037511e-07
sam_encoder.blocks.8.norm2.bias grad: -1.2362487495920504e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.656531243403151e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.8487164033540466e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.514397863251361e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.192789558350341e-07
sam_encoder.blocks.9.norm1.weight grad: -1.4528831115967478e-07
sam_encoder.blocks.9.norm1.bias grad: 3.366358214407228e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.660472257000947e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.12216376541619e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.477240906908264e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2470407000364503e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4093395748204784e-06
sam_encoder.blocks.9.norm2.bias grad: -1.0381543233961565e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.938945160873118e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.4352640391734894e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.7780623074468167e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.8004208136044326e-07
sam_encoder.blocks.10.norm1.weight grad: 4.369794169178931e-06
sam_encoder.blocks.10.norm1.bias grad: 1.305998011957854e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.815592551996815e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0436690445203567e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.321157924394356e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.891682010566001e-07
sam_encoder.blocks.10.norm2.weight grad: 2.386693722655764e-06
sam_encoder.blocks.10.norm2.bias grad: -2.2828089640825056e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.4574522942421027e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2968415603609174e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.3220601974571764e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.4045408148795104e-08
sam_encoder.blocks.11.norm1.weight grad: 1.6838379451655783e-05
sam_encoder.blocks.11.norm1.bias grad: 1.0862407862077816e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.8427109555195784e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.449472493841313e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.1753180590167176e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.1394748753446038e-06
sam_encoder.blocks.11.norm2.weight grad: 6.485542144218925e-06
sam_encoder.blocks.11.norm2.bias grad: 1.1839505305033526e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.5887909436714835e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0191342880716547e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.15603971962264e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.6728571949897741e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.8423968362621963e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.7911628674482927e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.9491533243563026e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.083284744003322e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -1.9967814296251163e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.30496482597664e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005874676164239645
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001226728199981153
mask_decoder.transformer.layers.0.norm3.weight grad: 3.828827175311744e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.258802437107079e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013997640053275973
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0851155821001157e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.4281835067085922e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.2509143390343525e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -9.782776760403067e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.478258339688182e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 7.646426820429042e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.8083119357470423e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.3360880732070655e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00021369644673541188
mask_decoder.transformer.norm_final_attn.weight grad: 5.87936483498197e-07
mask_decoder.transformer.norm_final_attn.bias grad: 8.981850442069117e-06
Text_Embedding_Affine.0.weight grad: -5.2434285212343834e-12
Text_Embedding_Affine.0.bias grad: -1.9019986974289083e-10
Text_Embedding_Affine.2.weight grad: 3.9746109181670874e-11
Text_Embedding_Affine.2.bias grad: 3.7097874155733734e-05
Epoch 25 finished with average loss: -62.1268
Epoch 26/39
----------
Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/3 [00:01<?, ?it/s, loss=-62.8]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-62.8]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-60.8]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-60.8]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-62.5]Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-62.5]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.9703291909433105e-11
Max value: 0.9975113868713379
Mean value: 0.08566921949386597

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.9703291909433105e-11
Max value: 0.9975113868713379
Mean value: 0.08566921949386597

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08463811874389648

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11253303289413452

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07806110382080078

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08463811874389648

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.031951904296875
Max value: 75.51318359375
Mean value: 62.84550476074219

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.9703291909433105e-11
Max value: 0.9975113868713379
Mean value: 0.08566921949386597

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.9703291909433105e-11
Max value: 0.9975113868713379
Mean value: 0.08566921949386597

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.9703291909433105e-11
Max value: 0.9975113868713379
Mean value: 0.08566921949386597

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11253303289413452

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.031951904296875
Max value: 75.51318359375
Mean value: 62.84550476074219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.846641540527344
Max value: -62.846641540527344
Mean value: -62.846641540527344
sam_encoder.pos_embed grad: 1.6107820632882408e-09
sam_encoder.blocks.0.norm1.weight grad: -5.264359788270667e-05
sam_encoder.blocks.0.norm1.bias grad: 1.8240632925881073e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.8288404817212722e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.5204867054308124e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.5207764237129595e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.112121463454969e-07
sam_encoder.blocks.0.norm2.weight grad: 3.721987013705075e-05
sam_encoder.blocks.0.norm2.bias grad: -7.70528095017653e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6519594282726757e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.405866093293298e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.5237894735473674e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.6581083173150546e-06
sam_encoder.blocks.1.norm1.weight grad: 1.2509673979366198e-05
sam_encoder.blocks.1.norm1.bias grad: 7.9423698480241e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.081636582966894e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.320344603707781e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.449945441185264e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.1133655561934575e-06
sam_encoder.blocks.1.norm2.weight grad: 1.4943560927349608e-05
sam_encoder.blocks.1.norm2.bias grad: -3.1612969451089157e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.189333700807765e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5120649550226517e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.762652340810746e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.42597807807033e-07
sam_encoder.blocks.2.norm1.weight grad: -2.824626790243201e-07
sam_encoder.blocks.2.norm1.bias grad: -1.2441753369785147e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.120228145940928e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.736604128334875e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.3745718610589392e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.8273237856192281e-06
sam_encoder.blocks.2.norm2.weight grad: -1.464759225200396e-05
sam_encoder.blocks.2.norm2.bias grad: -9.423754818271846e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.184345799440052e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.2258228657155996e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.6412518511497183e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.556903382355813e-06
sam_encoder.blocks.3.norm1.weight grad: -4.293057827453595e-06
sam_encoder.blocks.3.norm1.bias grad: -4.749271738546668e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.9770430981225218e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.3285695621998457e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.541413538092456e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.738023449135653e-07
sam_encoder.blocks.3.norm2.weight grad: 1.4384173482540064e-05
sam_encoder.blocks.3.norm2.bias grad: 4.3980016926070675e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1729667676263489e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.915843990398571e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.155259155893873e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.70100599664147e-07
sam_encoder.blocks.4.norm1.weight grad: 3.7014206100138836e-06
sam_encoder.blocks.4.norm1.bias grad: 8.145834726747125e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.515908701956505e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1114751714558224e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.372975912607217e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.083774906073813e-07
sam_encoder.blocks.4.norm2.weight grad: -6.872766789456364e-06
sam_encoder.blocks.4.norm2.bias grad: -1.135105549110449e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.2002148954197764e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.2236152947007213e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.7437909605177992e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.365057743096258e-07
sam_encoder.blocks.5.norm1.weight grad: 3.184789420629386e-06
sam_encoder.blocks.5.norm1.bias grad: -5.08417360833846e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.306216396798845e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.0745114852616098e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.3476605431606004e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.063316514977487e-06
sam_encoder.blocks.5.norm2.weight grad: -3.2697921596991364e-06
sam_encoder.blocks.5.norm2.bias grad: -1.3748651781497756e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.5633380573708564e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2497069974415353e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1192979602346895e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.298187039035838e-07
sam_encoder.blocks.6.norm1.weight grad: 2.323058879483142e-06
sam_encoder.blocks.6.norm1.bias grad: 2.381599870204809e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.8415850010787835e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3715811064685113e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3783271697320743e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0091016520163976e-06
sam_encoder.blocks.6.norm2.weight grad: 4.09948370361235e-06
sam_encoder.blocks.6.norm2.bias grad: 5.962905902379134e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.290812855993863e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.1544850622158265e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.983205038413871e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.146124077422428e-06
sam_encoder.blocks.7.norm1.weight grad: 5.6340190894843545e-06
sam_encoder.blocks.7.norm1.bias grad: 6.504440079879714e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.5658243834623136e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.1699167973565636e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.6032161056500627e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0066963795907213e-06
sam_encoder.blocks.7.norm2.weight grad: 4.951945811626501e-06
sam_encoder.blocks.7.norm2.bias grad: -9.018070841193548e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.3761893973860424e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.998004096203658e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.2640924157713016e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.749765309952636e-07
sam_encoder.blocks.8.norm1.weight grad: 2.623191903694533e-06
sam_encoder.blocks.8.norm1.bias grad: 6.32993646831892e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.5118780488119228e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.5103760233614594e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.486774625751423e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.239317092924466e-07
sam_encoder.blocks.8.norm2.weight grad: 1.040075972014165e-06
sam_encoder.blocks.8.norm2.bias grad: -8.338837460541981e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.44995929835568e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0734190425409906e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.494805570080644e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.511596252612435e-07
sam_encoder.blocks.9.norm1.weight grad: -3.0118669656076236e-06
sam_encoder.blocks.9.norm1.bias grad: 6.437082333832223e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.360977077842108e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.4325894426292507e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.686176104471087e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0087815098813735e-06
sam_encoder.blocks.9.norm2.weight grad: 1.7358960349156405e-06
sam_encoder.blocks.9.norm2.bias grad: -1.1664799330901587e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.1426183138828492e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.0063218642007996e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.0442310838243429e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.7444419831444975e-07
sam_encoder.blocks.10.norm1.weight grad: -1.3312665032572113e-06
sam_encoder.blocks.10.norm1.bias grad: 5.628713779515238e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.7591079881640326e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3998879921928165e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.254082680039573e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.264761959253519e-07
sam_encoder.blocks.10.norm2.weight grad: -5.178022547625005e-06
sam_encoder.blocks.10.norm2.bias grad: -2.04014372684469e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.468832690283307e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.9824290120595833e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6568385490245419e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.422942546014383e-07
sam_encoder.blocks.11.norm1.weight grad: 3.912077318091178e-06
sam_encoder.blocks.11.norm1.bias grad: -8.366593533537525e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.7186289369419683e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.618832072836085e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.535433491691947e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.622739192607696e-07
sam_encoder.blocks.11.norm2.weight grad: -6.411563845176715e-06
sam_encoder.blocks.11.norm2.bias grad: -2.219216867160867e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.657470647842274e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.6436741816505673e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.17480635708489e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.947389473069052e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.2101972970413044e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.3600012355018407e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.2682706912746653e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.719707769458182e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00023648474598303437
mask_decoder.transformer.layers.0.norm1.bias grad: -2.403146936558187e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0037415619008243084
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0013142426032572985
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011411138984840363
mask_decoder.transformer.layers.0.norm3.bias grad: 3.4963988582603633e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.355629087309353e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2875343600171618e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.1526062230113894e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.3447261153487489e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00012047279597027227
mask_decoder.transformer.layers.1.norm2.bias grad: 8.510354382451624e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.765130193438381e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.9452956116292626e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.4809261958580464e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -5.27107113157399e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.384344149206299e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.936871381592937e-06
Text_Embedding_Affine.0.weight grad: -2.8458697204358785e-11
Text_Embedding_Affine.0.bias grad: -1.040396213625172e-09
Text_Embedding_Affine.2.weight grad: -9.692675828620878e-11
Text_Embedding_Affine.2.bias grad: 6.0966351156821474e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5335900138777753e-13
Max value: 0.998613715171814
Mean value: 0.0734151303768158

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5335900138777753e-13
Max value: 0.998613715171814
Mean value: 0.0734151303768158

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06916522979736328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10256418585777283

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06495857238769531

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06916522979736328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.179420471191406
Max value: 88.1851577758789
Mean value: 58.839412689208984

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.2344821305753104e-13
Max value: 0.9986404776573181
Mean value: 0.07411257922649384

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2344821305753104e-13
Max value: 0.9986404776573181
Mean value: 0.07411257922649384

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2344821305753104e-13
Max value: 0.9986404776573181
Mean value: 0.07411257922649384

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10255448520183563

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8431475758552551
Max value: 1.2857739925384521
Mean value: 1.0000234842300415

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.179420471191406
Max value: 88.1851577758789
Mean value: 58.839412689208984

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.84315490722656
Max value: -58.84315490722656
Mean value: -58.84315490722656
sam_encoder.pos_embed grad: -4.3881973610382374e-09
sam_encoder.blocks.0.norm1.weight grad: 3.744475543498993e-05
sam_encoder.blocks.0.norm1.bias grad: 2.89233066723682e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.591677331220126e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1022665376003715e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.877136108116247e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.0222904570109677e-06
sam_encoder.blocks.0.norm2.weight grad: 5.5304186389548704e-05
sam_encoder.blocks.0.norm2.bias grad: -1.774450902303215e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.8892935006297193e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.5952474465593696e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.468712343921652e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.039694876060821e-06
sam_encoder.blocks.1.norm1.weight grad: -1.93921300706279e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3089453204884194e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.844633728382178e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.8339686650724616e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.668742677604314e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.3869512157689314e-06
sam_encoder.blocks.1.norm2.weight grad: -6.2845065258443356e-06
sam_encoder.blocks.1.norm2.bias grad: 1.044580812958884e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.7256520499795442e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.8839983201578434e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.5284327673725784e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.2849933429824887e-06
sam_encoder.blocks.2.norm1.weight grad: -1.8624232325237244e-05
sam_encoder.blocks.2.norm1.bias grad: -3.6114965951128397e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3105198377161287e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.010427801404148e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.70720998843899e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.56207772003836e-06
sam_encoder.blocks.2.norm2.weight grad: 8.152770533342846e-06
sam_encoder.blocks.2.norm2.bias grad: -9.292321010434534e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.6843387129483745e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.5133489341678796e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.5340016084956e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.698002721350349e-07
sam_encoder.blocks.3.norm1.weight grad: -1.0799207302625291e-05
sam_encoder.blocks.3.norm1.bias grad: 9.692988669485203e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.9769229260855354e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2373259323794628e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.100345111306524e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.253274710208643e-06
sam_encoder.blocks.3.norm2.weight grad: 2.4551627575419843e-06
sam_encoder.blocks.3.norm2.bias grad: -3.426933744776761e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.4732285080754082e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.581128685756994e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.97517339681508e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.211209205910563e-07
sam_encoder.blocks.4.norm1.weight grad: 4.492337211559061e-06
sam_encoder.blocks.4.norm1.bias grad: -1.0345183909521438e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.171387793874601e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.3611281701741973e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.3905712371051777e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.7635650237934897e-06
sam_encoder.blocks.4.norm2.weight grad: 1.1846890629385598e-05
sam_encoder.blocks.4.norm2.bias grad: -1.864345676949597e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.827756694998243e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.4273125493200496e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.60313400355517e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.396119485747477e-07
sam_encoder.blocks.5.norm1.weight grad: 1.3213836609793361e-05
sam_encoder.blocks.5.norm1.bias grad: -1.542532118037343e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.3104981007927563e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.777545993623789e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.4112273422360886e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.128383347459021e-07
sam_encoder.blocks.5.norm2.weight grad: 1.1318457836750895e-05
sam_encoder.blocks.5.norm2.bias grad: 3.4254135243827477e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.576215577704716e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.766686055925675e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.4481686270737555e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.0528972325118957e-06
sam_encoder.blocks.6.norm1.weight grad: 9.865342462944682e-07
sam_encoder.blocks.6.norm1.bias grad: -5.178811079531442e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.954309709617519e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.929523705257452e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.377094230927469e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.5012058156571584e-06
sam_encoder.blocks.6.norm2.weight grad: 4.0400987018074375e-06
sam_encoder.blocks.6.norm2.bias grad: 1.8159174715037807e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.1969449360549334e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.4620411548094125e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.188417627417948e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0436823433556128e-07
sam_encoder.blocks.7.norm1.weight grad: -3.8778312045906205e-06
sam_encoder.blocks.7.norm1.bias grad: 3.0890751077095047e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.223790716016083e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0940719903373974e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.190041853595176e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.3328211707630544e-06
sam_encoder.blocks.7.norm2.weight grad: 4.677996003010776e-06
sam_encoder.blocks.7.norm2.bias grad: 1.0534254215599503e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0693158856156515e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.880034450456151e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.5072406490144203e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.170653475441213e-07
sam_encoder.blocks.8.norm1.weight grad: -1.3977334845094447e-07
sam_encoder.blocks.8.norm1.bias grad: 8.322534768012702e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.4525816115783527e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.6653909824526636e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.5201885616988875e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.036460500676185e-06
sam_encoder.blocks.8.norm2.weight grad: 4.347458343545441e-06
sam_encoder.blocks.8.norm2.bias grad: 2.4183768800867256e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.442476218471711e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.822792890190613e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.889163609637762e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.506916628903127e-07
sam_encoder.blocks.9.norm1.weight grad: 1.6497046999575105e-06
sam_encoder.blocks.9.norm1.bias grad: 1.409624019288458e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.3664431125780538e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1639023966836248e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.617539606348146e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.111081453738734e-07
sam_encoder.blocks.9.norm2.weight grad: 4.01021816287539e-06
sam_encoder.blocks.9.norm2.bias grad: 4.08695632359013e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.717693281643733e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.5637715478078462e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.7121416223963024e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.251883408163849e-07
sam_encoder.blocks.10.norm1.weight grad: -6.482002845586976e-06
sam_encoder.blocks.10.norm1.bias grad: -1.7456386558478698e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.145178991166176e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.402347493240086e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.596242666186299e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.5581081242999062e-06
sam_encoder.blocks.10.norm2.weight grad: -4.143169860526541e-07
sam_encoder.blocks.10.norm2.bias grad: 1.2948257790412754e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.777559289934288e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.266470222726639e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.984453986864537e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.773372973611913e-08
sam_encoder.blocks.11.norm1.weight grad: -8.151259862643201e-06
sam_encoder.blocks.11.norm1.bias grad: -2.7789565137936734e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.9203632695716806e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2743670367854065e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4653101061412599e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.88504416707292e-07
sam_encoder.blocks.11.norm2.weight grad: 5.3173003777828853e-08
sam_encoder.blocks.11.norm2.bias grad: -9.250275070371572e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.672423064126633e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.564067854877067e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.3370589019577892e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.198724460977246e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4913657651050016e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.424626291031018e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.5738532965769991e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.7474543710704893e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00017985302838496864
mask_decoder.transformer.layers.0.norm1.bias grad: 3.831402864307165e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004380672238767147
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0014331629499793053
mask_decoder.transformer.layers.0.norm3.weight grad: 1.2448956113075837e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.0376024874858558e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -7.494145393138751e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.69533141667489e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.635118991951458e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.860961209691595e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -3.757070589927025e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -4.038737097289413e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.23168598394841e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.8150756154209375e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.9341161280171946e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013243526336736977
mask_decoder.transformer.norm_final_attn.weight grad: -1.3833232515025884e-06
mask_decoder.transformer.norm_final_attn.bias grad: -6.911686341481982e-06
Text_Embedding_Affine.0.weight grad: -4.7982329914875166e-12
Text_Embedding_Affine.0.bias grad: -5.097582911339771e-10
Text_Embedding_Affine.2.weight grad: -5.833292182622074e-11
Text_Embedding_Affine.2.bias grad: -6.872570520499721e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.830979548007484e-11
Max value: 0.997873067855835
Mean value: 0.11721721291542053

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.830979548007484e-11
Max value: 0.997873067855835
Mean value: 0.11721721291542053

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11130714416503906

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1521316021680832

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11334419250488281

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11130714416503906

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 62.41006088256836
Max value: 71.28536224365234
Mean value: 65.96978759765625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.5713437495623594e-11
Max value: 0.9981533885002136
Mean value: 0.11848343908786774

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.5713437495623594e-11
Max value: 0.9981533885002136
Mean value: 0.11848343908786774

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.5713437495623594e-11
Max value: 0.9981533885002136
Mean value: 0.11848343908786774

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15268471837043762

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5590425729751587
Max value: 1.128217101097107
Mean value: 0.9995546340942383

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 62.41006088256836
Max value: 71.28536224365234
Mean value: 65.96978759765625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.94135284423828
Max value: -65.94135284423828
Mean value: -65.94135284423828
sam_encoder.pos_embed grad: 3.3889277495369186e-10
sam_encoder.blocks.0.norm1.weight grad: -9.341651457361877e-05
sam_encoder.blocks.0.norm1.bias grad: -3.764817301998846e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.974174084461993e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.479935463066795e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.6941772628342733e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.9416270333749708e-06
sam_encoder.blocks.0.norm2.weight grad: -5.010726454202086e-06
sam_encoder.blocks.0.norm2.bias grad: -2.1068013666081242e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6300484276143834e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.3299805686983746e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.633472806541249e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.44121893553529e-06
sam_encoder.blocks.1.norm1.weight grad: 1.7158577975351363e-05
sam_encoder.blocks.1.norm1.bias grad: 4.022145003546029e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.033741662278771e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1885371122843935e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.497935611245339e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2515650951172574e-06
sam_encoder.blocks.1.norm2.weight grad: -2.245556788693648e-05
sam_encoder.blocks.1.norm2.bias grad: -1.3174691048334353e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.566864042019006e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6806550320325186e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0422161469468847e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.6690647700888803e-06
sam_encoder.blocks.2.norm1.weight grad: 1.0017092790803872e-05
sam_encoder.blocks.2.norm1.bias grad: -1.0753574315458536e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.398677439596213e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4980136242570552e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 6.645458597631659e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.9594674490217585e-06
sam_encoder.blocks.2.norm2.weight grad: 4.632656782632694e-06
sam_encoder.blocks.2.norm2.bias grad: -2.1962710889056325e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.472761823606561e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.213996819795284e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1778210136981215e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5814366634003818e-06
sam_encoder.blocks.3.norm1.weight grad: 1.6945537936408073e-05
sam_encoder.blocks.3.norm1.bias grad: 8.407361747231334e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.577689651341643e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.1221414669980732e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.2136015357100405e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.1617395304929232e-06
sam_encoder.blocks.3.norm2.weight grad: -1.4968382856750395e-05
sam_encoder.blocks.3.norm2.bias grad: 1.6992866221698932e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.245283763448242e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.840961653622799e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.2611045349331107e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.0370661079359706e-06
sam_encoder.blocks.4.norm1.weight grad: -7.488318715331843e-06
sam_encoder.blocks.4.norm1.bias grad: 9.01929524843581e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.874527687410591e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.0382357181224506e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.286976268806029e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.6742004592961166e-06
sam_encoder.blocks.4.norm2.weight grad: 5.528341716853902e-06
sam_encoder.blocks.4.norm2.bias grad: -8.568622433813289e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.4971968741738237e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.1032684597012121e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.686016371939331e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.459201484976802e-06
sam_encoder.blocks.5.norm1.weight grad: 4.985203304386232e-06
sam_encoder.blocks.5.norm1.bias grad: -1.0966263062073267e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.390983566641808e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.1194996406848077e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.8704732762416825e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.099552486673929e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1664386647680658e-06
sam_encoder.blocks.5.norm2.bias grad: -1.5497578260692535e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.5692795588838635e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.370908186501765e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.8514318728412036e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6864954659467912e-06
sam_encoder.blocks.6.norm1.weight grad: 9.9795181540685e-07
sam_encoder.blocks.6.norm1.bias grad: -3.175917299813591e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.3546136819495587e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.4066848709480837e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.618905000417726e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.917966983455699e-06
sam_encoder.blocks.6.norm2.weight grad: -2.918409109042841e-06
sam_encoder.blocks.6.norm2.bias grad: 1.6656792922731256e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.7359423004090786e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5185036090770154e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.619660304821082e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.3291790992298047e-06
sam_encoder.blocks.7.norm1.weight grad: 4.491598701861221e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1095297622887301e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.076154035217769e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3652738743985537e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.850225418020273e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7213869796250947e-07
sam_encoder.blocks.7.norm2.weight grad: -6.491824933618773e-06
sam_encoder.blocks.7.norm2.bias grad: -2.004769612540258e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.627397280884907e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.964489678764949e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.2936987988941837e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0456517429702217e-06
sam_encoder.blocks.8.norm1.weight grad: 1.6848825907800347e-05
sam_encoder.blocks.8.norm1.bias grad: -1.1355289188941242e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.613834683666937e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.5217302613309585e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.465275535243563e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.489178024869034e-07
sam_encoder.blocks.8.norm2.weight grad: -3.3174633244925644e-06
sam_encoder.blocks.8.norm2.bias grad: 2.017339284066111e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.01328565608128e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.887718321493594e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.301916538272053e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1983829040218552e-07
sam_encoder.blocks.9.norm1.weight grad: 1.9521489775797818e-06
sam_encoder.blocks.9.norm1.bias grad: 9.28788381315826e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.715891120416927e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.4140634618797776e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.932991828354716e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.156342816306278e-06
sam_encoder.blocks.9.norm2.weight grad: 1.7546083199704299e-06
sam_encoder.blocks.9.norm2.bias grad: 2.5466641773164156e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.0733434047979244e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.55818007291964e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.645678579137893e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.406077659448783e-07
sam_encoder.blocks.10.norm1.weight grad: -9.423839628652786e-07
sam_encoder.blocks.10.norm1.bias grad: -1.4302099771157373e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.0010234038636554e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.819054985702678e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.544111670336861e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.821589871222386e-07
sam_encoder.blocks.10.norm2.weight grad: -2.2569515749637503e-06
sam_encoder.blocks.10.norm2.bias grad: -1.3779533674096456e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.3390102822086192e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.151268290617736e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.1125985938397207e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.6396981550315104e-07
sam_encoder.blocks.11.norm1.weight grad: 1.4105108675721567e-05
sam_encoder.blocks.11.norm1.bias grad: -1.3292456060298719e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.66284881340107e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.2104162578907562e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.9322887965245172e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.8175873012514785e-07
sam_encoder.blocks.11.norm2.weight grad: 4.339242877904326e-06
sam_encoder.blocks.11.norm2.bias grad: -1.7081399619200965e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4718538068336784e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.633477222019792e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.531907163458527e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.726201485842466e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.017263225046918e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.0210176191758364e-06
sam_encoder.neck.conv2.trainable_scale grad: 4.1685088945087045e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.1734274418558925e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00011199693835806102
mask_decoder.transformer.layers.0.norm1.bias grad: 6.261579983402044e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.001384266186505556
mask_decoder.transformer.layers.0.norm2.bias grad: -0.001422649365849793
mask_decoder.transformer.layers.0.norm3.weight grad: 7.560272933915257e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.469337050570175e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -7.634051871718839e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.859833668684587e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.104693395376671e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.5192315408494323e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00010456430027261376
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00016381609020754695
mask_decoder.transformer.layers.1.norm3.weight grad: -2.0994601072743535e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.3283627999480814e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.805677109397948e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 8.768478437559679e-06
mask_decoder.transformer.norm_final_attn.weight grad: 1.9039922563024447e-06
mask_decoder.transformer.norm_final_attn.bias grad: -3.6114333852310665e-06
Text_Embedding_Affine.0.weight grad: -1.0274307446489495e-11
Text_Embedding_Affine.0.bias grad: -9.44212374953679e-10
Text_Embedding_Affine.2.weight grad: -1.0089674234992074e-10
Text_Embedding_Affine.2.bias grad: -8.018326479941607e-05
Epoch 26 finished with average loss: -62.5437
Epoch 27/39
----------
Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.2]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.00it/s, loss=-57.2]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.00it/s, loss=-61.4]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-61.4]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-61.4]Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.20it/s, loss=-61.4]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.9475668587784e-13
Max value: 0.9992507100105286
Mean value: 0.09720952808856964

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.9475668587784e-13
Max value: 0.9992507100105286
Mean value: 0.09720952808856964

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08556413650512695

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13180693984031677

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08305931091308594

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08556413650512695

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 25.607696533203125
Max value: 80.85139465332031
Mean value: 57.19152069091797

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.9475668587784e-13
Max value: 0.9992507100105286
Mean value: 0.09720952808856964

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.9475668587784e-13
Max value: 0.9992507100105286
Mean value: 0.09720952808856964

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.9475668587784e-13
Max value: 0.9992507100105286
Mean value: 0.09720952808856964

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13180693984031677

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 25.607696533203125
Max value: 80.85139465332031
Mean value: 57.19152069091797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.19294357299805
Max value: -57.19294357299805
Mean value: -57.19294357299805
sam_encoder.pos_embed grad: 9.498281272612985e-09
sam_encoder.blocks.0.norm1.weight grad: -5.7773675507633016e-05
sam_encoder.blocks.0.norm1.bias grad: 3.2447060220874846e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -8.046925358939916e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.76818842795501e-09
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.8683498385362327e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.0644620235543698e-08
sam_encoder.blocks.0.norm2.weight grad: 1.6543708625249565e-05
sam_encoder.blocks.0.norm2.bias grad: 1.1843260836030822e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.771325150912162e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.768262442667037e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8126102077076212e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.5450972316320986e-06
sam_encoder.blocks.1.norm1.weight grad: -5.592209163296502e-06
sam_encoder.blocks.1.norm1.bias grad: -5.684259576810291e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.3195974538102746e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0737721822806634e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.152170276938705e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.029364395639277e-06
sam_encoder.blocks.1.norm2.weight grad: -1.8995253412867896e-05
sam_encoder.blocks.1.norm2.bias grad: -9.543038686388172e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.763624474435346e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.78509002480132e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 7.859608558646869e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.1391276732174447e-06
sam_encoder.blocks.2.norm1.weight grad: 1.2553579836094286e-05
sam_encoder.blocks.2.norm1.bias grad: -1.340884955425281e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.550341251771897e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.4399723795577302e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.5374342840223107e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.1967076716246083e-06
sam_encoder.blocks.2.norm2.weight grad: 6.9143670771154575e-06
sam_encoder.blocks.2.norm2.bias grad: 6.0898964875377715e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.552461177809164e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.57693522801128e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0595098132171188e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.84057919595216e-07
sam_encoder.blocks.3.norm1.weight grad: -9.76007322606165e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0002309863921255e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.9399401480768574e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.296093139710138e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.8987159339521895e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.972090437149745e-07
sam_encoder.blocks.3.norm2.weight grad: 1.814265033317497e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0855674190679565e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3819166255757409e-08
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 8.775909918767866e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.132094990287442e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5180687569227302e-06
sam_encoder.blocks.4.norm1.weight grad: -1.4992553587944712e-05
sam_encoder.blocks.4.norm1.bias grad: 5.298501264405786e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.2808703104383312e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.732647772063501e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.1324365232212585e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.728854889890499e-07
sam_encoder.blocks.4.norm2.weight grad: 4.673861894843867e-06
sam_encoder.blocks.4.norm2.bias grad: 6.485078301921021e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.426825398695655e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.9033067246709834e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.0542196378082735e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.480740128405159e-07
sam_encoder.blocks.5.norm1.weight grad: -1.1157082553836517e-05
sam_encoder.blocks.5.norm1.bias grad: 1.8711316442932002e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.050563009310281e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.9512674498400884e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.8070848000206752e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.6146047983056633e-06
sam_encoder.blocks.5.norm2.weight grad: 1.777529860191862e-06
sam_encoder.blocks.5.norm2.bias grad: 5.410634003055748e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.4604299849452218e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.494246124726487e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.4929014418594306e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.855012321058894e-07
sam_encoder.blocks.6.norm1.weight grad: 3.1356780709757004e-06
sam_encoder.blocks.6.norm1.bias grad: 1.6957808384177042e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.9036973501206376e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.605419108993374e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2376649465295486e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.4518336683977395e-06
sam_encoder.blocks.6.norm2.weight grad: 2.8481333629315486e-06
sam_encoder.blocks.6.norm2.bias grad: 1.963004478966468e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.0605775615840685e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.8194172045914456e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.972645122805261e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.2381137821648736e-06
sam_encoder.blocks.7.norm1.weight grad: -1.2088794392184354e-06
sam_encoder.blocks.7.norm1.bias grad: -8.637240966891113e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.3750948255619733e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.2245642362104263e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.467306441962137e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.5699841924288194e-06
sam_encoder.blocks.7.norm2.weight grad: 1.2523968280220288e-06
sam_encoder.blocks.7.norm2.bias grad: -2.596058948256541e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.303403215999424e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.1394271243480034e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.8346453291305806e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.192218064716144e-06
sam_encoder.blocks.8.norm1.weight grad: 3.7293229979695752e-06
sam_encoder.blocks.8.norm1.bias grad: 2.4973505787784234e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.218590897333343e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.8307701995800016e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.203458618372679e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.2396956208249321e-06
sam_encoder.blocks.8.norm2.weight grad: -3.483390855762991e-06
sam_encoder.blocks.8.norm2.bias grad: 7.452370027749566e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.765948920568917e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0069278434675653e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.3409464776923414e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1333953580106026e-06
sam_encoder.blocks.9.norm1.weight grad: -9.09289883566089e-06
sam_encoder.blocks.9.norm1.bias grad: -3.1281464885069e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.200897016446106e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.2607491726157605e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.246777285108692e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.9696693673031405e-06
sam_encoder.blocks.9.norm2.weight grad: 5.464123020715306e-08
sam_encoder.blocks.9.norm2.bias grad: -1.2396440070006065e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.779635908860655e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.884756764222402e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5767966488056118e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.802475631204288e-08
sam_encoder.blocks.10.norm1.weight grad: -4.615796115103876e-06
sam_encoder.blocks.10.norm1.bias grad: -8.848489301271911e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.1107130123709794e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.160138804669259e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5740283743070904e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.02970841453498e-06
sam_encoder.blocks.10.norm2.weight grad: -8.172228262992576e-06
sam_encoder.blocks.10.norm2.bias grad: -3.821649897872703e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.389227110048523e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.264762199250981e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.1012523322715424e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.421911856094084e-07
sam_encoder.blocks.11.norm1.weight grad: -1.500218604633119e-05
sam_encoder.blocks.11.norm1.bias grad: -1.1189545148226898e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.128799107798841e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.4027993984200293e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.292561243346427e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.9158721897838404e-06
sam_encoder.blocks.11.norm2.weight grad: -8.725661245989613e-06
sam_encoder.blocks.11.norm2.bias grad: 1.6638407487334916e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.80269591207616e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.415821427348419e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.780666474995087e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2090864629499265e-06
sam_encoder.neck.conv1.trainable_scale grad: -3.867307896143757e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.4341396308736876e-05
sam_encoder.neck.conv2.trainable_scale grad: 9.304894774686545e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.13483352935873e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00027451757341623306
mask_decoder.transformer.layers.0.norm1.bias grad: -4.237866960465908e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0023150460328906775
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0015381010016426444
mask_decoder.transformer.layers.0.norm3.weight grad: 3.0308074201457202e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 3.67200918844901e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.446841093245894e-07
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2885832802567165e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 5.9007550589740276e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.981294190045446e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001344097836408764
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010103802924277261
mask_decoder.transformer.layers.1.norm3.weight grad: 4.950986476615071e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.897142884554341e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.94282095739618e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 6.909608782734722e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.903126738208812e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.492497631261358e-05
Text_Embedding_Affine.0.weight grad: -9.027836637975906e-12
Text_Embedding_Affine.0.bias grad: -5.38349198553334e-10
Text_Embedding_Affine.2.weight grad: 2.4397309172918824e-10
Text_Embedding_Affine.2.bias grad: 4.1997976950369775e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.811763459125178e-13
Max value: 0.9985036849975586
Mean value: 0.0892631784081459

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.811763459125178e-13
Max value: 0.9985036849975586
Mean value: 0.0892631784081459

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08729267120361328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11656579375267029

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08303070068359375

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08729267120361328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.4905891418457
Max value: 88.47862243652344
Mean value: 65.64064025878906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.2915325778409545e-13
Max value: 0.9984694123268127
Mean value: 0.08919321745634079

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2915325778409545e-13
Max value: 0.9984694123268127
Mean value: 0.08919321745634079

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2915325778409545e-13
Max value: 0.9984694123268127
Mean value: 0.08919321745634079

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1164456382393837

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7741659283638
Max value: 1.074926495552063
Mean value: 1.000128984451294

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.4905891418457
Max value: 88.47862243652344
Mean value: 65.64064025878906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.65069580078125
Max value: -65.65069580078125
Mean value: -65.65069580078125
sam_encoder.pos_embed grad: -5.891570786786815e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00010003657371271402
sam_encoder.blocks.0.norm1.bias grad: -6.85372797306627e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.964106326748151e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2414982109021366e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.824126204359345e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.4654720454673225e-07
sam_encoder.blocks.0.norm2.weight grad: 2.7237911126576364e-05
sam_encoder.blocks.0.norm2.bias grad: -1.9123977835988626e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.350299862679094e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.975066869723378e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.658553618559381e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.827798304380849e-06
sam_encoder.blocks.1.norm1.weight grad: 3.520429163472727e-05
sam_encoder.blocks.1.norm1.bias grad: 7.391405961243436e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.386650733882561e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.6406998990278225e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.60348408826394e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.1434198313509114e-05
sam_encoder.blocks.1.norm2.weight grad: -3.6778583307750523e-06
sam_encoder.blocks.1.norm2.bias grad: -1.5559551684418693e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.7313906230119755e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.93516228819135e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.055468500358984e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.775460406061029e-06
sam_encoder.blocks.2.norm1.weight grad: -2.044723805738613e-05
sam_encoder.blocks.2.norm1.bias grad: 9.76067349256482e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.6329904610756785e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.7949200759612722e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.953179869626183e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.501271622662898e-06
sam_encoder.blocks.2.norm2.weight grad: -5.51149933016859e-05
sam_encoder.blocks.2.norm2.bias grad: -5.170101644580427e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.558299067663029e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.893066478776745e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.6914149202639237e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.691421731375158e-06
sam_encoder.blocks.3.norm1.weight grad: -3.55450356437359e-06
sam_encoder.blocks.3.norm1.bias grad: 5.119572506373515e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.32142359286081e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5378273019450717e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.038650776143186e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.131168447609525e-06
sam_encoder.blocks.3.norm2.weight grad: -5.3455427405424416e-05
sam_encoder.blocks.3.norm2.bias grad: 1.736695230647456e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.916024070349522e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.3025782209297176e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.142320797953289e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.998375516152009e-06
sam_encoder.blocks.4.norm1.weight grad: -2.2751298729417613e-06
sam_encoder.blocks.4.norm1.bias grad: 8.578324923291802e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.4301174309803173e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.194413799676113e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.7464029724578722e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2004430800516275e-06
sam_encoder.blocks.4.norm2.weight grad: -3.186279718647711e-05
sam_encoder.blocks.4.norm2.bias grad: -1.9974377210019156e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.8277141609578393e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.0905321687459946e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.9852089937776327e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.9198464542569127e-06
sam_encoder.blocks.5.norm1.weight grad: -5.569454515352845e-06
sam_encoder.blocks.5.norm1.bias grad: -2.341576328035444e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.615172878809972e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.5608223950257525e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.573917976813391e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.553941269274219e-06
sam_encoder.blocks.5.norm2.weight grad: -2.5853418264887296e-05
sam_encoder.blocks.5.norm2.bias grad: -2.2747990442439914e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.690413773758337e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.620293333980953e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8579496554593788e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.2497010832012165e-07
sam_encoder.blocks.6.norm1.weight grad: 4.782374162459746e-06
sam_encoder.blocks.6.norm1.bias grad: -5.888401574338786e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.177069735713303e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.102299499209039e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.5121072414767696e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.180848347663414e-06
sam_encoder.blocks.6.norm2.weight grad: -1.3107310223858804e-05
sam_encoder.blocks.6.norm2.bias grad: 6.887016752443742e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3101827789796516e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.984437277424149e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.0902114127020468e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.5514994800014392e-07
sam_encoder.blocks.7.norm1.weight grad: 3.096855834883172e-06
sam_encoder.blocks.7.norm1.bias grad: -2.5204967641911935e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.132830326852854e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.7556546936248196e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.224643367298995e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.091340765124187e-08
sam_encoder.blocks.7.norm2.weight grad: -1.4444694897974841e-05
sam_encoder.blocks.7.norm2.bias grad: 1.8540072233008686e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.1841902960441075e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.08505058355513e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.7005444280803204e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.4886849157846882e-06
sam_encoder.blocks.8.norm1.weight grad: 4.503992386162281e-06
sam_encoder.blocks.8.norm1.bias grad: -1.739001959322195e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.311404937761836e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.3651873561902903e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.724092476735223e-09
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.5638454392028507e-06
sam_encoder.blocks.8.norm2.weight grad: -1.6483667423017323e-05
sam_encoder.blocks.8.norm2.bias grad: -2.3758525458106305e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.8268741769134067e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0534027751418762e-05
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.826928034162847e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.2373760657501407e-06
sam_encoder.blocks.9.norm1.weight grad: 2.7584214876696933e-06
sam_encoder.blocks.9.norm1.bias grad: -6.146341888779716e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.1311089969676686e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.240221637199284e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.044327728384815e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.8971704207615403e-07
sam_encoder.blocks.9.norm2.weight grad: 9.227880468642979e-07
sam_encoder.blocks.9.norm2.bias grad: -4.645823992177611e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.440436103119282e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.6083274658740265e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.127993411704665e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.858471230472787e-07
sam_encoder.blocks.10.norm1.weight grad: 2.2666533823212376e-06
sam_encoder.blocks.10.norm1.bias grad: 5.844703991897404e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 9.10291134914587e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.8128599776900955e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.200976612381055e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.641876204113942e-07
sam_encoder.blocks.10.norm2.weight grad: -1.074492229236057e-05
sam_encoder.blocks.10.norm2.bias grad: -1.0443527571624145e-05
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.662231160386e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.4718984807113884e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2271143532416318e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.645391602613017e-08
sam_encoder.blocks.11.norm1.weight grad: -3.1115851015783846e-05
sam_encoder.blocks.11.norm1.bias grad: 1.3096062048134627e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 9.748240699991584e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0933474641205976e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.9523707780754194e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.982002211472718e-07
sam_encoder.blocks.11.norm2.weight grad: -8.85133158590179e-06
sam_encoder.blocks.11.norm2.bias grad: -1.0555681001278572e-05
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.908255159032706e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.320537532796152e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0006733646150678e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0773154457410783e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.409230314195156e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.287175266246777e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.6638153940439224e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.822687772801146e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -7.261479913722724e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 6.703092367388308e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00020716292783617973
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003994899452663958
mask_decoder.transformer.layers.0.norm3.weight grad: 3.651044244179502e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.891983503010124e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011723159695975482
mask_decoder.transformer.layers.0.norm4.bias grad: 3.840815224975813e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 8.643803084851243e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0915322238579392e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002711064589675516
mask_decoder.transformer.layers.1.norm2.bias grad: -3.679035580717027e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.201457780553028e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.6553719837684184e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.946939199930057e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 6.944878987269476e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.8588530110719148e-06
mask_decoder.transformer.norm_final_attn.bias grad: -2.2502386855194345e-05
Text_Embedding_Affine.0.weight grad: 1.2604556287598712e-11
Text_Embedding_Affine.0.bias grad: 7.342150221134602e-10
Text_Embedding_Affine.2.weight grad: -3.664496484034885e-11
Text_Embedding_Affine.2.bias grad: -1.3490469427779317e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7257495345951446e-12
Max value: 0.997938334941864
Mean value: 0.07297927141189575

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7257495345951446e-12
Max value: 0.997938334941864
Mean value: 0.07297927141189575

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07291030883789062

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.667893409729004
Max value: -1.1920928244535389e-07
Mean value: -0.10262230038642883

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0672464370727539

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07291030883789062

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 57.685245513916016
Max value: 68.72842407226562
Mean value: 61.419898986816406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.2492695600100374e-12
Max value: 0.9978517293930054
Mean value: 0.07213646918535233

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.2492695600100374e-12
Max value: 0.9978517293930054
Mean value: 0.07213646918535233

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.2492695600100374e-12
Max value: 0.9978517293930054
Mean value: 0.07213646918535233

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.470139503479004
Max value: -1.1920928244535389e-07
Mean value: -0.10258370637893677

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.501884400844574
Max value: 1.456714391708374
Mean value: 1.000120759010315

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 57.685245513916016
Max value: 68.72842407226562
Mean value: 61.419898986816406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.428077697753906
Max value: -61.428077697753906
Mean value: -61.428077697753906
sam_encoder.pos_embed grad: -8.51997583595221e-09
sam_encoder.blocks.0.norm1.weight grad: -3.4098913602065295e-05
sam_encoder.blocks.0.norm1.bias grad: 6.632453732891008e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.320960776269203e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.803422773922648e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.5955650926334783e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.829085471807048e-06
sam_encoder.blocks.0.norm2.weight grad: 4.11342698498629e-05
sam_encoder.blocks.0.norm2.bias grad: 0.0001225403684657067
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.2400072339223698e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.754004981397884e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8988430383615196e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.092623602351523e-07
sam_encoder.blocks.1.norm1.weight grad: -2.1587298761005513e-05
sam_encoder.blocks.1.norm1.bias grad: 1.8848861145670526e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.7397645681048743e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.439147573975788e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.727117018570425e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.109132078156108e-06
sam_encoder.blocks.1.norm2.weight grad: 1.4527761777571868e-05
sam_encoder.blocks.1.norm2.bias grad: -9.208255505654961e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.0255127310520038e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.055909019167302e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.207127181463875e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.0233643479296006e-06
sam_encoder.blocks.2.norm1.weight grad: -2.0090139514650218e-05
sam_encoder.blocks.2.norm1.bias grad: -1.6889525795704685e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2584081559907645e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.065404032691731e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.06285061116796e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.1430268942785915e-06
sam_encoder.blocks.2.norm2.weight grad: -1.205987973662559e-05
sam_encoder.blocks.2.norm2.bias grad: 2.199258960899897e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.981427865568548e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.099546458746772e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.921382929343963e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0848278861885774e-06
sam_encoder.blocks.3.norm1.weight grad: 4.063750566274393e-06
sam_encoder.blocks.3.norm1.bias grad: -2.0636658518924378e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.474866621720139e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.4105515876726713e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.730035470856819e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.7760825130608282e-06
sam_encoder.blocks.3.norm2.weight grad: 1.9964743842137977e-05
sam_encoder.blocks.3.norm2.bias grad: 2.4454202502965927e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.3094696441839915e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2130413981358288e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1795636964961886e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.825398951245006e-06
sam_encoder.blocks.4.norm1.weight grad: -1.113418966269819e-05
sam_encoder.blocks.4.norm1.bias grad: -6.3007882999954745e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.29645068733953e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.2759127205063123e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.38930986901687e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.9897238416888285e-06
sam_encoder.blocks.4.norm2.weight grad: 2.8454189305193722e-05
sam_encoder.blocks.4.norm2.bias grad: -3.5975851915281964e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.6458034224342555e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.91845946473768e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.476017112319823e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.309341536805732e-06
sam_encoder.blocks.5.norm1.weight grad: 7.988506695255637e-06
sam_encoder.blocks.5.norm1.bias grad: -7.996646672836505e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.170396262750728e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.195754500979092e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.2221803343854845e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.7220403947248997e-07
sam_encoder.blocks.5.norm2.weight grad: 2.335033059353009e-05
sam_encoder.blocks.5.norm2.bias grad: 4.041062766191317e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.0066223694593646e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.5192769044224406e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.544013336271746e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6991050415526843e-06
sam_encoder.blocks.6.norm1.weight grad: 4.598758096108213e-06
sam_encoder.blocks.6.norm1.bias grad: -4.5138753534956777e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.947172667220002e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.7350655475165695e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.1747946448158473e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.632133257269743e-06
sam_encoder.blocks.6.norm2.weight grad: 1.2991848052479327e-05
sam_encoder.blocks.6.norm2.bias grad: 2.624611397550325e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.315446964639705e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.419895392653416e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.934389383175585e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.3125815807343315e-08
sam_encoder.blocks.7.norm1.weight grad: 3.468248451099498e-06
sam_encoder.blocks.7.norm1.bias grad: 5.28632597251999e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.804279458563542e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.822383617574815e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.931847802756238e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.770491043222137e-06
sam_encoder.blocks.7.norm2.weight grad: 9.774272257345729e-06
sam_encoder.blocks.7.norm2.bias grad: -2.759252993200789e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.41685290550231e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.535513191214704e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.440849246137077e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.4243848909245571e-06
sam_encoder.blocks.8.norm1.weight grad: 6.334213139780331e-06
sam_encoder.blocks.8.norm1.bias grad: 6.397516472134157e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.334249287145212e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.063388365058927e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.2843740882526617e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.6395165352587355e-06
sam_encoder.blocks.8.norm2.weight grad: 9.502637112746015e-06
sam_encoder.blocks.8.norm2.bias grad: 2.3451782453776104e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 8.045989488891792e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.47716229245998e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.3784411951055517e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.2360181617386843e-07
sam_encoder.blocks.9.norm1.weight grad: 6.720613328070613e-07
sam_encoder.blocks.9.norm1.bias grad: 1.2561398534671753e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.6237452150089666e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.982130121788941e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.516781129699666e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9477190562611213e-06
sam_encoder.blocks.9.norm2.weight grad: 1.2336973668425344e-05
sam_encoder.blocks.9.norm2.bias grad: 1.5709896388216293e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.043433924991405e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.5118434880132554e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.395412709825905e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.6969482291860913e-07
sam_encoder.blocks.10.norm1.weight grad: -5.611916549241869e-06
sam_encoder.blocks.10.norm1.bias grad: 7.097082743712235e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.6967376217944548e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1443172525105183e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6898193280212581e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.638593958996353e-07
sam_encoder.blocks.10.norm2.weight grad: 1.2761603102262598e-05
sam_encoder.blocks.10.norm2.bias grad: -7.622438715770841e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.660744813620113e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.4598284653620794e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.011738034634618e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.0746969059691764e-07
sam_encoder.blocks.11.norm1.weight grad: 2.8909489628858864e-05
sam_encoder.blocks.11.norm1.bias grad: -3.3773617360566277e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.920651114545763e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.4962761269998737e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.3202423449220078e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.101063369598705e-07
sam_encoder.blocks.11.norm2.weight grad: 1.1435974556661677e-05
sam_encoder.blocks.11.norm2.bias grad: -2.4690079953870736e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.017495929379947e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.8287710190634243e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.707334715523757e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.5502132555411663e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.2500574889127165e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.8122561818454415e-05
sam_encoder.neck.conv2.trainable_scale grad: 4.1958373913075775e-06
sam_encoder.neck.conv2.trainable_shift grad: 7.31081745470874e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00014632637612521648
mask_decoder.transformer.layers.0.norm1.bias grad: 4.38469578512013e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -3.969878889620304e-05
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0013002585619688034
mask_decoder.transformer.layers.0.norm3.weight grad: 3.937858855351806e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.481863364460878e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -6.707290594931692e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.772863111516926e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.4747227143961936e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.082256054971367e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.020581789314747e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00012697494821622968
mask_decoder.transformer.layers.1.norm3.weight grad: -3.867197665385902e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.9654105926747434e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.049466123338789e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.590795702417381e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.942786396597512e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.86208455185988e-06
Text_Embedding_Affine.0.weight grad: -3.214343721746893e-11
Text_Embedding_Affine.0.bias grad: -8.881806401461745e-10
Text_Embedding_Affine.2.weight grad: 2.332296022977687e-10
Text_Embedding_Affine.2.bias grad: -6.803616997785866e-05
Epoch 27 finished with average loss: -61.4239
Epoch 28/39
----------
Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.4]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-60.4]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-63.7]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-63.7]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-61.8]Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.26it/s, loss=-61.8]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.612262158106843e-13
Max value: 0.9979240894317627
Mean value: 0.07894720137119293

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.612262158106843e-13
Max value: 0.9979240894317627
Mean value: 0.07894720137119293

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07769966125488281

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11050060391426086

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06827545166015625

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07769966125488281

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.832542419433594
Max value: 80.36491394042969
Mean value: 60.39530944824219

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.612262158106843e-13
Max value: 0.9979240894317627
Mean value: 0.07894720137119293

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.612262158106843e-13
Max value: 0.9979240894317627
Mean value: 0.07894720137119293

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.612262158106843e-13
Max value: 0.9979240894317627
Mean value: 0.07894720137119293

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11050060391426086

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.832542419433594
Max value: 80.36491394042969
Mean value: 60.39530944824219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.396446228027344
Max value: -60.396446228027344
Mean value: -60.396446228027344
sam_encoder.pos_embed grad: -6.826803566895023e-10
sam_encoder.blocks.0.norm1.weight grad: -1.1767727983169607e-06
sam_encoder.blocks.0.norm1.bias grad: 1.0183702215726953e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.478323484770954e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.0321109584765509e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.548480435711099e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.647742788525647e-08
sam_encoder.blocks.0.norm2.weight grad: -7.975183393682528e-07
sam_encoder.blocks.0.norm2.bias grad: -8.483330930175725e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 8.147551852744073e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.605544068501331e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8187456589657813e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.755599780357443e-06
sam_encoder.blocks.1.norm1.weight grad: 2.4966002456494607e-06
sam_encoder.blocks.1.norm1.bias grad: 1.2357156720099738e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3228191164671443e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.753787253430346e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.5140525394817814e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.605820216354914e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0037512765848078e-05
sam_encoder.blocks.1.norm2.bias grad: -3.839856503873307e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.223063332479796e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3591287029157684e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.427953177175368e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.081310519017279e-07
sam_encoder.blocks.2.norm1.weight grad: -7.493355042242911e-06
sam_encoder.blocks.2.norm1.bias grad: -6.151893103378825e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.477684797166148e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.969369330065092e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1309075489407405e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.4293438488930406e-07
sam_encoder.blocks.2.norm2.weight grad: -1.5230234566843137e-06
sam_encoder.blocks.2.norm2.bias grad: -3.856303919747006e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.474701533283223e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.64046524434525e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.017532652753289e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3003231060793041e-06
sam_encoder.blocks.3.norm1.weight grad: -3.062754785787547e-06
sam_encoder.blocks.3.norm1.bias grad: -5.688432338502025e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.8203646706970176e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.702252857034182e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.908298846193702e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.035630910148029e-08
sam_encoder.blocks.3.norm2.weight grad: 7.40873201721115e-06
sam_encoder.blocks.3.norm2.bias grad: -2.707832891246653e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.737210696883267e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.9713907022378407e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.3482558642863296e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7391452900028526e-07
sam_encoder.blocks.4.norm1.weight grad: -1.2398007811498246e-06
sam_encoder.blocks.4.norm1.bias grad: -1.7809179553296417e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.036708908941364e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.278593562252354e-09
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.8432989179473225e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.355603545671329e-07
sam_encoder.blocks.4.norm2.weight grad: -1.5989342500688508e-05
sam_encoder.blocks.4.norm2.bias grad: -6.083997504902072e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0674069017113652e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.085507953277556e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.317533531164372e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.728865062337718e-07
sam_encoder.blocks.5.norm1.weight grad: -1.4636466403317172e-06
sam_encoder.blocks.5.norm1.bias grad: -4.7873427320155315e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.2529417290352285e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.507500043857362e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.674231325272558e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.0048654530692147e-06
sam_encoder.blocks.5.norm2.weight grad: -1.2887048796983436e-06
sam_encoder.blocks.5.norm2.bias grad: -4.732185971079161e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.988552867260296e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.624617405279423e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.157655444534612e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.501061650647898e-08
sam_encoder.blocks.6.norm1.weight grad: -4.344407443568343e-06
sam_encoder.blocks.6.norm1.bias grad: -3.2331354304915294e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.9038201344301342e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.6084003934556677e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.863445267095813e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.73053455354966e-07
sam_encoder.blocks.6.norm2.weight grad: 7.34190962248249e-06
sam_encoder.blocks.6.norm2.bias grad: 3.355581384312245e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.031414735232829e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0957055565086193e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.8772307157632895e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.107241693418473e-07
sam_encoder.blocks.7.norm1.weight grad: 3.943381216231501e-06
sam_encoder.blocks.7.norm1.bias grad: 7.848213385841518e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.7347282411938068e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0027212056229473e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.417658594022214e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.5451068691163528e-07
sam_encoder.blocks.7.norm2.weight grad: -1.4529349527947488e-06
sam_encoder.blocks.7.norm2.bias grad: 5.506474280991824e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.8043290310743032e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.617646148588392e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.665370619884925e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.996368711043033e-07
sam_encoder.blocks.8.norm1.weight grad: 5.498367499967571e-06
sam_encoder.blocks.8.norm1.bias grad: -3.2713933251216076e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.76906131755095e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.7541242414154112e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.117970876104664e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.05358810742473e-06
sam_encoder.blocks.8.norm2.weight grad: 1.7444447166781174e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2907674999951269e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.070585767593002e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.242513917532051e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.250572149227082e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.301734577438765e-07
sam_encoder.blocks.9.norm1.weight grad: -4.265720576768217e-07
sam_encoder.blocks.9.norm1.bias grad: 2.4261009912152076e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.887285846663872e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.876129307580413e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.7645336924942967e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.070757313456852e-07
sam_encoder.blocks.9.norm2.weight grad: 1.4069435110286577e-06
sam_encoder.blocks.9.norm2.bias grad: -6.112686037340609e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0199055395787582e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.620770586276194e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.2485256206673512e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.512408000005962e-07
sam_encoder.blocks.10.norm1.weight grad: -5.838546712766401e-07
sam_encoder.blocks.10.norm1.bias grad: 4.402333502184774e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.2015233841775625e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.69648364034947e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.823630206374219e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.3909765306816553e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0660002089935006e-06
sam_encoder.blocks.10.norm2.bias grad: -2.0576330825861078e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.425713768796413e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.90643214384545e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.573626822297229e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.5612481497082626e-07
sam_encoder.blocks.11.norm1.weight grad: 9.02681586012477e-06
sam_encoder.blocks.11.norm1.bias grad: 5.546420993596257e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.751511136826593e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.269120831348118e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.502183502263506e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.791629469811596e-07
sam_encoder.blocks.11.norm2.weight grad: -3.8885144704181585e-07
sam_encoder.blocks.11.norm2.bias grad: -2.2434778657043353e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.222042894572951e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.294307759915682e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.218615916011913e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.343366175722622e-08
sam_encoder.neck.conv1.trainable_scale grad: -4.882213033852167e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.012568974256283e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.4645457819569856e-07
sam_encoder.neck.conv2.trainable_shift grad: -5.322767719917465e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -6.492641841759905e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.5971745597198606e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0056276824325323105
mask_decoder.transformer.layers.0.norm2.bias grad: 8.858012733981013e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -6.55321273370646e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.9357630662852898e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.248569065472111e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.345082394749625e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.522215360542759e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.628644430544227e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.25517142098397e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00012375014193821698
mask_decoder.transformer.layers.1.norm3.weight grad: 4.412793350638822e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.9348083848599344e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.784838554565795e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010017371096182615
mask_decoder.transformer.norm_final_attn.weight grad: 5.619202056550421e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4902010661899112e-05
Text_Embedding_Affine.0.weight grad: 9.338315710982759e-13
Text_Embedding_Affine.0.bias grad: 5.364088062620453e-10
Text_Embedding_Affine.2.weight grad: -1.0430243474468526e-11
Text_Embedding_Affine.2.bias grad: 1.4842949894955382e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.646355658357974e-13
Max value: 0.999276340007782
Mean value: 0.10486063361167908

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.646355658357974e-13
Max value: 0.999276340007782
Mean value: 0.10486063361167908

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09644269943237305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12071509659290314

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09893321990966797

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09644269943237305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 53.34328079223633
Max value: 86.86451721191406
Mean value: 67.06974792480469

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.027338479044071e-12
Max value: 0.999437153339386
Mean value: 0.10364040732383728

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.027338479044071e-12
Max value: 0.999437153339386
Mean value: 0.10364040732383728

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.027338479044071e-12
Max value: 0.999437153339386
Mean value: 0.10364040732383728

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12031720578670502

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6278098225593567
Max value: 1.2931820154190063
Mean value: 1.0004630088806152

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 53.34328079223633
Max value: 86.86451721191406
Mean value: 67.06974792480469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.10103607177734
Max value: -67.10103607177734
Mean value: -67.10103607177734
sam_encoder.pos_embed grad: -1.103465763208078e-08
sam_encoder.blocks.0.norm1.weight grad: 3.126711453660391e-05
sam_encoder.blocks.0.norm1.bias grad: -7.983518298715353e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.196448116999818e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.863349248462328e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.8078957282341435e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8152604752685875e-06
sam_encoder.blocks.0.norm2.weight grad: -3.587332685128786e-05
sam_encoder.blocks.0.norm2.bias grad: -7.160312816267833e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.085912223672494e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.1972164202234126e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.156544360332191e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.550679922336712e-06
sam_encoder.blocks.1.norm1.weight grad: -8.564398740418255e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4980239939177409e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.645319935050793e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.303126272337977e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.8302389435120858e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2457075172278564e-05
sam_encoder.blocks.1.norm2.weight grad: -3.7049114325782284e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0561869203229435e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.6328575586376246e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.9918678023932443e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.152425051666796e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.107330252940301e-06
sam_encoder.blocks.2.norm1.weight grad: -4.744552279589698e-05
sam_encoder.blocks.2.norm1.bias grad: -1.4408127753995359e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.8309061235631816e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.446879524446558e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.989967111323494e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.5620221296994714e-06
sam_encoder.blocks.2.norm2.weight grad: 8.193394023692235e-06
sam_encoder.blocks.2.norm2.bias grad: 2.9680642910534516e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.950683063498218e-08
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.3907020931801526e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.387420343235135e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.285603030344646e-07
sam_encoder.blocks.3.norm1.weight grad: 5.7513425417710096e-06
sam_encoder.blocks.3.norm1.bias grad: -3.4888903428509366e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.220969119865913e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.0298150502640055e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.4082556276662217e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.040073352167383e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1119786904600915e-05
sam_encoder.blocks.3.norm2.bias grad: -3.451548036537133e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.284619641723111e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.4839837250474375e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.7649197161517804e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.1531048989563715e-06
sam_encoder.blocks.4.norm1.weight grad: -5.538331606658176e-07
sam_encoder.blocks.4.norm1.bias grad: -1.179152422992047e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 9.741170288180001e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.870110620278865e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.982569069194142e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.7628571309132894e-08
sam_encoder.blocks.4.norm2.weight grad: 2.9889415600337088e-05
sam_encoder.blocks.4.norm2.bias grad: 2.228723133157473e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.8141483451472595e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 8.69366976985475e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.651978310401319e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.658712330434355e-06
sam_encoder.blocks.5.norm1.weight grad: 1.2618751497939229e-05
sam_encoder.blocks.5.norm1.bias grad: 6.012472113070544e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.677890607737936e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.69508824305376e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.693913979281206e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.089368071116041e-06
sam_encoder.blocks.5.norm2.weight grad: 2.362086161156185e-05
sam_encoder.blocks.5.norm2.bias grad: 1.322111529589165e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.155458322609775e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.566668510757154e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.746722647221759e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.2952220863080584e-07
sam_encoder.blocks.6.norm1.weight grad: -1.2600670515894308e-06
sam_encoder.blocks.6.norm1.bias grad: -4.3925547288381495e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.1066290375747485e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.3200157102110097e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3613616829388775e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.4500418501484091e-06
sam_encoder.blocks.6.norm2.weight grad: 3.8356388358806726e-06
sam_encoder.blocks.6.norm2.bias grad: 5.628103735944023e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.0486555765965022e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.092701715308067e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.5860332420488703e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1111630726645672e-07
sam_encoder.blocks.7.norm1.weight grad: -7.164658654801315e-06
sam_encoder.blocks.7.norm1.bias grad: 2.275192400702508e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.6636863519088365e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.4422050703142304e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.038863370529725e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.264054612373002e-06
sam_encoder.blocks.7.norm2.weight grad: 1.0565951924945693e-05
sam_encoder.blocks.7.norm2.bias grad: 6.471201686508721e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.7596634026849642e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.118222017903463e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.052348231198266e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.6629135188850341e-06
sam_encoder.blocks.8.norm1.weight grad: 4.1884595702867955e-06
sam_encoder.blocks.8.norm1.bias grad: 3.687908701976994e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.130707333795726e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.239122063154355e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.341232513776049e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.840915724140359e-06
sam_encoder.blocks.8.norm2.weight grad: 2.0434134057722986e-05
sam_encoder.blocks.8.norm2.bias grad: 8.860993148118723e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.1283878848189488e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.436896678176709e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.256500223069452e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.2677439776307438e-06
sam_encoder.blocks.9.norm1.weight grad: 4.355191322247265e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0924293292191578e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.8695721994154155e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.14651912151021e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.6669758312891645e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.5493030736688524e-06
sam_encoder.blocks.9.norm2.weight grad: 1.2890416655864101e-05
sam_encoder.blocks.9.norm2.bias grad: 9.319116543338168e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.798815775255207e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.226665052759927e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.643242169142468e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.709426214802079e-06
sam_encoder.blocks.10.norm1.weight grad: -2.352474893996259e-06
sam_encoder.blocks.10.norm1.bias grad: -6.717702376590751e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.3135880863046623e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.2808787270587345e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.819761675709742e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.6164825638043112e-06
sam_encoder.blocks.10.norm2.weight grad: 2.0530616893665865e-05
sam_encoder.blocks.10.norm2.bias grad: 8.464462553092744e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.0676696547307074e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.7202571547823027e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.212789463053923e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.571459392835095e-06
sam_encoder.blocks.11.norm1.weight grad: -1.7157351976493374e-05
sam_encoder.blocks.11.norm1.bias grad: -7.042635843390599e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.8806777006830089e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.8400476164970314e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8113603061920003e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0425926575408084e-06
sam_encoder.blocks.11.norm2.weight grad: 2.777938061626628e-05
sam_encoder.blocks.11.norm2.bias grad: -2.24711220653262e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.086678275896702e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.23750622960506e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.156497991265496e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.337181397000677e-06
sam_encoder.neck.conv1.trainable_scale grad: 9.092036634683609e-07
sam_encoder.neck.conv1.trainable_shift grad: 0.000107826832390856
sam_encoder.neck.conv2.trainable_scale grad: 1.552962203277275e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.00017476109496783465
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00018344158888794482
mask_decoder.transformer.layers.0.norm1.bias grad: 7.74308864492923e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004568976350128651
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0012484396575018764
mask_decoder.transformer.layers.0.norm3.weight grad: 2.2375976186594926e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.3024603908415884e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010681703861337155
mask_decoder.transformer.layers.0.norm4.bias grad: 1.659401459619403e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.2853710106574e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -7.764749625494005e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001147038274211809
mask_decoder.transformer.layers.1.norm2.bias grad: 6.263382965698838e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -7.080135401338339e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.371075192466378e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -1.3594348274637014e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00015945310587994754
mask_decoder.transformer.norm_final_attn.weight grad: 1.0039609605883015e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.567596336826682e-05
Text_Embedding_Affine.0.weight grad: 8.096658760115005e-11
Text_Embedding_Affine.0.bias grad: 3.5585030477847113e-09
Text_Embedding_Affine.2.weight grad: -7.501756160710471e-11
Text_Embedding_Affine.2.bias grad: -8.888499723980203e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.152976740371932e-13
Max value: 0.9970884919166565
Mean value: 0.06907788664102554

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.152976740371932e-13
Max value: 0.9970884919166565
Mean value: 0.06907788664102554

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0708770751953125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11135043203830719

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.061878204345703125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0708770751953125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.243412017822266
Max value: 60.231285095214844
Mean value: 57.90614700317383

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.937198126398495e-14
Max value: 0.9973688125610352
Mean value: 0.06812348961830139

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.937198126398495e-14
Max value: 0.9973688125610352
Mean value: 0.06812348961830139

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.937198126398495e-14
Max value: 0.9973688125610352
Mean value: 0.06812348961830139

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11223528534173965

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.3843841552734375
Max value: 1.228107213973999
Mean value: 0.999335765838623

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.243412017822266
Max value: 60.231285095214844
Mean value: 57.90614700317383

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.86933135986328
Max value: -57.86933135986328
Mean value: -57.86933135986328
sam_encoder.pos_embed grad: -6.107280015044125e-09
sam_encoder.blocks.0.norm1.weight grad: -3.975050276494585e-05
sam_encoder.blocks.0.norm1.bias grad: -6.999896868364885e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.334575981421949e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.28787416240084e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.823690692821401e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.3432658053934574e-06
sam_encoder.blocks.0.norm2.weight grad: 6.460056283685844e-06
sam_encoder.blocks.0.norm2.bias grad: 2.6635265385266393e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.589975105773192e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -9.479328468842141e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.0776307792402804e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.4138304221851286e-06
sam_encoder.blocks.1.norm1.weight grad: -3.145322580166976e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3383871191763319e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.728655651182635e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.032955879054498e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.7875225795432925e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.6549081414705142e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0285410098731518e-05
sam_encoder.blocks.1.norm2.bias grad: 5.6787066569086164e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.95332358241285e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.4512547131271276e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.1566328188055195e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.970604312708019e-07
sam_encoder.blocks.2.norm1.weight grad: -2.657353979884647e-05
sam_encoder.blocks.2.norm1.bias grad: -2.269051719849813e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.5808012904017232e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.415780838622595e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.3334719015983865e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.9107142179564107e-06
sam_encoder.blocks.2.norm2.weight grad: -7.550288501079194e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0294066669302993e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.3487123043159954e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.2487978438002756e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.094627911399584e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.4496316086697334e-07
sam_encoder.blocks.3.norm1.weight grad: 1.06809166027233e-05
sam_encoder.blocks.3.norm1.bias grad: -2.907569864873949e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.5676330804126337e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.9446250664477702e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.994753337290604e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.6544233833192266e-07
sam_encoder.blocks.3.norm2.weight grad: -1.6236423107329756e-05
sam_encoder.blocks.3.norm2.bias grad: 8.255485226982273e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.2351056284387596e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.75133253732929e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.852126155834412e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.0453384169959463e-07
sam_encoder.blocks.4.norm1.weight grad: -1.6552211263842764e-06
sam_encoder.blocks.4.norm1.bias grad: -1.110463108489057e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0904435612246743e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.026270279515302e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0040058668892016e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.43322267831536e-07
sam_encoder.blocks.4.norm2.weight grad: 3.0112329113762826e-05
sam_encoder.blocks.4.norm2.bias grad: 2.1127212676219642e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.843889731389936e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.5348355090245605e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.33282752460218e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.5251227927801665e-06
sam_encoder.blocks.5.norm1.weight grad: 1.3041726560913958e-06
sam_encoder.blocks.5.norm1.bias grad: -2.427852450637147e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.378695277613588e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.734250407840591e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.323775884695351e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.3480764664564049e-06
sam_encoder.blocks.5.norm2.weight grad: 2.5739578632055782e-05
sam_encoder.blocks.5.norm2.bias grad: 1.0843914424185641e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.202885510399938e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.8006197680952027e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.975861550818081e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.333817618222383e-07
sam_encoder.blocks.6.norm1.weight grad: 3.4252389014000073e-07
sam_encoder.blocks.6.norm1.bias grad: -1.7003710581775522e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.2993266358971596e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.7159092041983968e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.201674244086462e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.0160880467301467e-06
sam_encoder.blocks.6.norm2.weight grad: 1.3918595868744887e-05
sam_encoder.blocks.6.norm2.bias grad: 3.1044025945448084e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.890859029022977e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.5073427423194516e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.189964223158313e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.707171742917126e-07
sam_encoder.blocks.7.norm1.weight grad: -4.175013145868434e-06
sam_encoder.blocks.7.norm1.bias grad: -7.036305191832071e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.942690108895476e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.062918386196543e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.023327164759394e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.0348346626851708e-06
sam_encoder.blocks.7.norm2.weight grad: 2.4088915324682603e-06
sam_encoder.blocks.7.norm2.bias grad: -1.7275110621994827e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.062865632979083e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.394865401191055e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.0187292193440953e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.744485633840668e-07
sam_encoder.blocks.8.norm1.weight grad: -7.358548373304075e-06
sam_encoder.blocks.8.norm1.bias grad: 8.872105894397464e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.5441803447611164e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.432586032024119e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.5819808822925552e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5923042155918665e-06
sam_encoder.blocks.8.norm2.weight grad: 7.79564470576588e-06
sam_encoder.blocks.8.norm2.bias grad: 3.456715376159991e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.282297029727488e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.269088210799964e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.1723758461812395e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.36854383123864e-07
sam_encoder.blocks.9.norm1.weight grad: 4.641552550310735e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0773771919048158e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.236289441905683e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.289918807553477e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.6214560218941187e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.1225744148978265e-06
sam_encoder.blocks.9.norm2.weight grad: 9.289941772294696e-06
sam_encoder.blocks.9.norm2.bias grad: 3.4335407690377906e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.548018867149949e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.1566564757667948e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.5519701435096067e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.525566848518793e-07
sam_encoder.blocks.10.norm1.weight grad: -1.9650592548714485e-06
sam_encoder.blocks.10.norm1.bias grad: 9.595401024853345e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -8.000885713954631e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.3763173828683648e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.384157581531326e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.167689837686339e-07
sam_encoder.blocks.10.norm2.weight grad: 7.11863094693399e-06
sam_encoder.blocks.10.norm2.bias grad: 3.5737634789256845e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.243086782982573e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2239768238941906e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.288063117499405e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.451134264447319e-07
sam_encoder.blocks.11.norm1.weight grad: -1.2687526577792596e-05
sam_encoder.blocks.11.norm1.bias grad: 2.278678401523848e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.2628175884165103e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.150380957275047e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.51675338253699e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.688480430559139e-07
sam_encoder.blocks.11.norm2.weight grad: 6.6887473622045945e-06
sam_encoder.blocks.11.norm2.bias grad: -3.0106397730378376e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.5984779767895816e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.6744124877732247e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.684027317125583e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.341142804762057e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.2757518561556935e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.954295243602246e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.884105586213991e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.5996265321737155e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.793200297281146e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.5949196899309754e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005193260498344898
mask_decoder.transformer.layers.0.norm2.bias grad: -0.000750519975554198
mask_decoder.transformer.layers.0.norm3.weight grad: 5.18387314514257e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.2978732886258513e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00014924249262548983
mask_decoder.transformer.layers.0.norm4.bias grad: 1.630561746424064e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -4.2311789002269506e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.9410999811952934e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00012660378706641495
mask_decoder.transformer.layers.1.norm2.bias grad: -9.729748126119375e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -0.00011694335989886895
mask_decoder.transformer.layers.1.norm3.bias grad: -4.923548476654105e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.5450736100319773e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002246368967462331
mask_decoder.transformer.norm_final_attn.weight grad: 6.055445282981964e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.3301492799655534e-05
Text_Embedding_Affine.0.weight grad: 1.2994948866973388e-11
Text_Embedding_Affine.0.bias grad: 2.2668866783703834e-10
Text_Embedding_Affine.2.weight grad: 2.358028529381162e-11
Text_Embedding_Affine.2.bias grad: -4.393776544020511e-05
Epoch 28 finished with average loss: -61.7889
Epoch 29/39
----------
Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.6]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.14it/s, loss=-60.6]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.14it/s, loss=-61.4]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-61.4]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-61.8]Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.37it/s, loss=-61.8]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.45944989520028e-14
Max value: 0.9956223368644714
Mean value: 0.07712022960186005

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.45944989520028e-14
Max value: 0.9956223368644714
Mean value: 0.07712022960186005

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07851457595825195

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11488019675016403

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06945371627807617

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07851457595825195

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 53.701961517333984
Max value: 69.61480712890625
Mean value: 60.596885681152344

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.45944989520028e-14
Max value: 0.9956223368644714
Mean value: 0.07712022960186005

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.45944989520028e-14
Max value: 0.9956223368644714
Mean value: 0.07712022960186005

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.45944989520028e-14
Max value: 0.9956223368644714
Mean value: 0.07712022960186005

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11488019675016403

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 53.701961517333984
Max value: 69.61480712890625
Mean value: 60.596885681152344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.5979118347168
Max value: -60.5979118347168
Mean value: -60.5979118347168
sam_encoder.pos_embed grad: 1.7625514381336416e-09
sam_encoder.blocks.0.norm1.weight grad: -2.2764525056118146e-05
sam_encoder.blocks.0.norm1.bias grad: -5.814974429085851e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.91424781709793e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.757100289358277e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.516825134080136e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.46403076795832e-07
sam_encoder.blocks.0.norm2.weight grad: 1.0512910193938296e-05
sam_encoder.blocks.0.norm2.bias grad: 2.2740428903489374e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.9969858082477e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.2030242234905018e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.83966186948237e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.641667495277943e-07
sam_encoder.blocks.1.norm1.weight grad: 1.176423393189907e-05
sam_encoder.blocks.1.norm1.bias grad: 2.614420282043284e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.852792699239217e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.5692201031924924e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.779269152597408e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.072365744737908e-07
sam_encoder.blocks.1.norm2.weight grad: 6.807621957705123e-06
sam_encoder.blocks.1.norm2.bias grad: -3.364567874086788e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.905887180939317e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.413676262833178e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.4313341024680994e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.211605060954753e-07
sam_encoder.blocks.2.norm1.weight grad: 1.2733885341731366e-05
sam_encoder.blocks.2.norm1.bias grad: -5.082512871013023e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.222324711619876e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.3955575468571624e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.4122628044788144e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.597308710188372e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0029994882643223e-05
sam_encoder.blocks.2.norm2.bias grad: 2.536238525863155e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.2885367292910814e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.338291551495786e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1595784599194303e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.139903588409652e-06
sam_encoder.blocks.3.norm1.weight grad: -8.209904990508221e-06
sam_encoder.blocks.3.norm1.bias grad: -5.3808266784471925e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.767501766560599e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.425628160082852e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2629475349967834e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.731197572662495e-07
sam_encoder.blocks.3.norm2.weight grad: 6.280524303292623e-06
sam_encoder.blocks.3.norm2.bias grad: 4.344992248661583e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.983993221685523e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.8709582718656748e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.7213351384270936e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.435189685456862e-07
sam_encoder.blocks.4.norm1.weight grad: 8.062527001584385e-08
sam_encoder.blocks.4.norm1.bias grad: 2.6284951673005708e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.913468718674267e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.633567757788114e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.996976261078089e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5155868027250108e-07
sam_encoder.blocks.4.norm2.weight grad: -8.034827260416932e-06
sam_encoder.blocks.4.norm2.bias grad: -3.4940846944664372e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.895911843050271e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6733397387724835e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.016279942537949e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.611762728425674e-07
sam_encoder.blocks.5.norm1.weight grad: 1.2913145610582433e-06
sam_encoder.blocks.5.norm1.bias grad: 7.270526793945464e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.670191959936346e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.855470135429641e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.6157515498634893e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.233801635360578e-07
sam_encoder.blocks.5.norm2.weight grad: -5.4367533266486134e-06
sam_encoder.blocks.5.norm2.bias grad: -1.0527987797104288e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.6220806123310467e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5909504327282775e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.514435426652199e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.589017805756157e-07
sam_encoder.blocks.6.norm1.weight grad: 6.551536898768973e-06
sam_encoder.blocks.6.norm1.bias grad: 2.1759851165370492e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.422071469889488e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3900853446102701e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.8671660200197948e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.3365455515668145e-06
sam_encoder.blocks.6.norm2.weight grad: 1.958498387466534e-06
sam_encoder.blocks.6.norm2.bias grad: 1.4824795471213292e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.2470421754405834e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.3014281421419582e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.853001650597434e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.99069540687924e-07
sam_encoder.blocks.7.norm1.weight grad: 2.1065866349090356e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4819465832260903e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.057397750832024e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.441582298866706e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.1577891427805298e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.5670520876228693e-07
sam_encoder.blocks.7.norm2.weight grad: -5.449876425700495e-07
sam_encoder.blocks.7.norm2.bias grad: 6.026245955581544e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.3612861948786303e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.281152203271631e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.230801889410941e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.186309728813285e-07
sam_encoder.blocks.8.norm1.weight grad: 2.0378690805955557e-06
sam_encoder.blocks.8.norm1.bias grad: 6.642990229011048e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.910031859457376e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.647229729926039e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.89296803354955e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.881671150589682e-07
sam_encoder.blocks.8.norm2.weight grad: -1.7560304286234896e-06
sam_encoder.blocks.8.norm2.bias grad: -1.1879114936164115e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.930984746602917e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.6727746532960737e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.1808629924180423e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.384923275007168e-07
sam_encoder.blocks.9.norm1.weight grad: -7.921158839963027e-07
sam_encoder.blocks.9.norm1.bias grad: 1.001742020889651e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.250449698403827e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.713578848874022e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.756224983448192e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.91211778808065e-07
sam_encoder.blocks.9.norm2.weight grad: -1.7839272459241329e-06
sam_encoder.blocks.9.norm2.bias grad: -1.3168214536563028e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.466648219012768e-08
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.120980298059294e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.476784738471906e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.921377071947063e-07
sam_encoder.blocks.10.norm1.weight grad: 5.195078074393678e-07
sam_encoder.blocks.10.norm1.bias grad: 6.334018394227314e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.323253565667983e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.4222290423713275e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.086052740603918e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.305735395362717e-07
sam_encoder.blocks.10.norm2.weight grad: -3.131196990580065e-06
sam_encoder.blocks.10.norm2.bias grad: -3.149678377667442e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.621670430220547e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.897891585642355e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.566496393934358e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.984777769503125e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1134778105770238e-05
sam_encoder.blocks.11.norm1.bias grad: 2.71717397026805e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.2356372280919459e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.152686929297488e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.387102863911423e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.2921288689303765e-07
sam_encoder.blocks.11.norm2.weight grad: -2.2712199552188395e-06
sam_encoder.blocks.11.norm2.bias grad: -8.25366612389189e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 9.958289410860743e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.462831040858873e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5560763131361455e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.839604793640319e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.1873635230585933e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1495261787786148e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.5727982827229425e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.6187561413971707e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001581722463015467
mask_decoder.transformer.layers.0.norm1.bias grad: -2.4513174139428884e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005361377261579037
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0008850081358104944
mask_decoder.transformer.layers.0.norm3.weight grad: -2.8971298888791353e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.161949330708012e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011667444778140634
mask_decoder.transformer.layers.0.norm4.bias grad: -3.329781065986026e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.650482540251687e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.591629476635717e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -5.053736822446808e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.393578951247036e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.2651648982428014e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.145282971672714e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.0273284210124984e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015071325469762087
mask_decoder.transformer.norm_final_attn.weight grad: 6.641807885898743e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1263135093031451e-05
Text_Embedding_Affine.0.weight grad: 3.44682372921401e-11
Text_Embedding_Affine.0.bias grad: 1.1330920646202003e-09
Text_Embedding_Affine.2.weight grad: -7.416521563552436e-11
Text_Embedding_Affine.2.bias grad: 4.940542930853553e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7390798723036544e-15
Max value: 0.9998862743377686
Mean value: 0.0820477083325386

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7390798723036544e-15
Max value: 0.9998862743377686
Mean value: 0.0820477083325386

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07976007461547852

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11498923599720001

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0765070915222168

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07976007461547852

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 30.0352783203125
Max value: 85.4942855834961
Mean value: 62.156211853027344

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.479871912203571e-15
Max value: 0.9998843669891357
Mean value: 0.08197945356369019

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.479871912203571e-15
Max value: 0.9998843669891357
Mean value: 0.08197945356369019

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.479871912203571e-15
Max value: 0.9998843669891357
Mean value: 0.08197945356369019

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1147863119840622

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8257285356521606
Max value: 1.2921810150146484
Mean value: 1.0002155303955078

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 30.0352783203125
Max value: 85.4942855834961
Mean value: 62.156211853027344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.16823196411133
Max value: -62.16823196411133
Mean value: -62.16823196411133
sam_encoder.pos_embed grad: -2.884951721959794e-10
sam_encoder.blocks.0.norm1.weight grad: -1.6248519386863336e-05
sam_encoder.blocks.0.norm1.bias grad: -1.1672465916490182e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.1993686257483205e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2291289408494777e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.3187281991995405e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5112348137336085e-06
sam_encoder.blocks.0.norm2.weight grad: 2.1493708118214272e-05
sam_encoder.blocks.0.norm2.bias grad: 2.238843808299862e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.855783688777592e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.0391247491934337e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.3263522760098567e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.965842764358968e-07
sam_encoder.blocks.1.norm1.weight grad: 8.403969331993721e-06
sam_encoder.blocks.1.norm1.bias grad: -3.045592620765092e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.6600844194035744e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1265177590757958e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.0373317966004834e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.985260240644493e-07
sam_encoder.blocks.1.norm2.weight grad: 8.907312803785317e-06
sam_encoder.blocks.1.norm2.bias grad: 1.4339186691358918e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.8254730750632007e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.499279503354046e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.2770562938821968e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.434558664139331e-07
sam_encoder.blocks.2.norm1.weight grad: 5.944041731709149e-06
sam_encoder.blocks.2.norm1.bias grad: -3.6594165067072026e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.7619672639266355e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.680762231146218e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.8844484657165594e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.85994461188966e-07
sam_encoder.blocks.2.norm2.weight grad: -1.0471156201674603e-05
sam_encoder.blocks.2.norm2.bias grad: 4.625301244232105e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.400507689046208e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.3529814825451467e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.012282938172575e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3757464785157936e-06
sam_encoder.blocks.3.norm1.weight grad: -9.035273251356557e-06
sam_encoder.blocks.3.norm1.bias grad: -6.05178047408117e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.668727913463954e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.872362637797778e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.4176498552842531e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.032555231489823e-07
sam_encoder.blocks.3.norm2.weight grad: 6.4690880208218005e-06
sam_encoder.blocks.3.norm2.bias grad: 8.479264579364099e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.17804028277169e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.6048745692387456e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.867792656819802e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.0117778401763644e-06
sam_encoder.blocks.4.norm1.weight grad: 5.154067366675008e-06
sam_encoder.blocks.4.norm1.bias grad: 3.584993010008475e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.669721071579261e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.958779946193317e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.8711272054570145e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.3666706634203365e-08
sam_encoder.blocks.4.norm2.weight grad: -1.2446102118701674e-05
sam_encoder.blocks.4.norm2.bias grad: -6.199205017765053e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.79351773619419e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.666805241664406e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.444459710204683e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.7523466289712815e-07
sam_encoder.blocks.5.norm1.weight grad: 8.232882464653812e-06
sam_encoder.blocks.5.norm1.bias grad: -2.5673098207334988e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.500979568751063e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.5059464405785548e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.356333864867338e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.372506729552697e-07
sam_encoder.blocks.5.norm2.weight grad: -6.059878614905756e-06
sam_encoder.blocks.5.norm2.bias grad: -3.6082492442801595e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.509401494738995e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5449768397957087e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.8752728198355726e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.302293288877991e-07
sam_encoder.blocks.6.norm1.weight grad: 7.13727786205709e-06
sam_encoder.blocks.6.norm1.bias grad: 1.1468650882306974e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.1120982789143454e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3516749959308072e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9355320546310395e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.37893164264824e-06
sam_encoder.blocks.6.norm2.weight grad: 2.019588919210946e-06
sam_encoder.blocks.6.norm2.bias grad: 2.0268689695512876e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.480650098528713e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.532559488434345e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.24427331735933e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.717519069188711e-07
sam_encoder.blocks.7.norm1.weight grad: 8.722296342966729e-07
sam_encoder.blocks.7.norm1.bias grad: 1.4130373529042117e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4916266763975727e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.24204732907674e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.058699000277556e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.7621034582334687e-07
sam_encoder.blocks.7.norm2.weight grad: -8.381488214581623e-07
sam_encoder.blocks.7.norm2.bias grad: 1.6956948911683867e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.909026477482257e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.646744511977886e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.562518243910745e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.074246587355447e-07
sam_encoder.blocks.8.norm1.weight grad: 1.9848698684654664e-07
sam_encoder.blocks.8.norm1.bias grad: -1.0734402167145163e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.891415639780462e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.928356578508101e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.430219237543497e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.5839168554521166e-07
sam_encoder.blocks.8.norm2.weight grad: -1.2037719443469541e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2637817690119846e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.101460480247624e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.956102313575684e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.4172130136103078e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.085932860358298e-07
sam_encoder.blocks.9.norm1.weight grad: -1.0584180927253328e-06
sam_encoder.blocks.9.norm1.bias grad: 6.395336527020845e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.652219326497288e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.7505799948812637e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.7814727470977232e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.047364197707793e-07
sam_encoder.blocks.9.norm2.weight grad: 6.261527119022503e-07
sam_encoder.blocks.9.norm2.bias grad: -1.1061118811994675e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0719807050918462e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.539641503877647e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.7027056742335844e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.4902478773801704e-07
sam_encoder.blocks.10.norm1.weight grad: 1.1442643881309777e-06
sam_encoder.blocks.10.norm1.bias grad: 4.808345579476736e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.027478219839395e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.175831686050515e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.424299385798804e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.2406146977546086e-08
sam_encoder.blocks.10.norm2.weight grad: -1.21678155551308e-07
sam_encoder.blocks.10.norm2.bias grad: -2.218803956566262e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.532417379887193e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.038444600951152e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6843960111145861e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.441803973051719e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1564638043637387e-05
sam_encoder.blocks.11.norm1.bias grad: 3.4928598324768245e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.7112830492988e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.472222829259408e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.1338009926475934e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.643317316142202e-07
sam_encoder.blocks.11.norm2.weight grad: 1.2012726529064821e-06
sam_encoder.blocks.11.norm2.bias grad: -8.102097126538865e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.6734633138403296e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.198420017724857e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2946646847922239e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.689475190389203e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.111163096036762e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.5648405426181853e-06
sam_encoder.neck.conv2.trainable_scale grad: -3.191926225554198e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.331392796710134e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001660461421124637
mask_decoder.transformer.layers.0.norm1.bias grad: -2.801403752528131e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005217783153057098
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0008654526900500059
mask_decoder.transformer.layers.0.norm3.weight grad: -5.884714119019918e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.2004111340502277e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011625303886830807
mask_decoder.transformer.layers.0.norm4.bias grad: -6.337912054732442e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.879740688716993e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.850550562376156e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -5.958167457720265e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.821287777507678e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.3771713788155466e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.855061575246509e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.403538721613586e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014738489699084312
mask_decoder.transformer.norm_final_attn.weight grad: 6.7701153056987096e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4340943380375393e-05
Text_Embedding_Affine.0.weight grad: 8.270501471174807e-12
Text_Embedding_Affine.0.bias grad: 3.754107857911748e-10
Text_Embedding_Affine.2.weight grad: 1.1239846726962543e-11
Text_Embedding_Affine.2.bias grad: 4.7284698666771874e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.5438406936473257e-09
Max value: 0.9980596899986267
Mean value: 0.10185211151838303

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.5438406936473257e-09
Max value: 0.9980596899986267
Mean value: 0.10185211151838303

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10307693481445312

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.794195175170898
Max value: -1.1920928244535389e-07
Mean value: -0.12631326913833618

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09474658966064453

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10307693481445312

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 44.59547805786133
Max value: 77.502197265625
Mean value: 62.49458694458008

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.1273723610780735e-09
Max value: 0.9975860118865967
Mean value: 0.1017574667930603

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.1273723610780735e-09
Max value: 0.9975860118865967
Mean value: 0.1017574667930603

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.1273723610780735e-09
Max value: 0.9975860118865967
Mean value: 0.1017574667930603

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.732850074768066
Max value: -1.1920928244535389e-07
Mean value: -0.1264377385377884

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9201145768165588
Max value: 1.605002760887146
Mean value: 0.9999396204948425

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 44.59547805786133
Max value: 77.502197265625
Mean value: 62.49458694458008

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.489105224609375
Max value: -62.489105224609375
Mean value: -62.489105224609375
sam_encoder.pos_embed grad: 4.2418307755198725e-10
sam_encoder.blocks.0.norm1.weight grad: -8.348090341314673e-05
sam_encoder.blocks.0.norm1.bias grad: -8.331732715305407e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.722781214804854e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.28783289155399e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.788548828102648e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.1445339396232157e-06
sam_encoder.blocks.0.norm2.weight grad: 3.806313907261938e-05
sam_encoder.blocks.0.norm2.bias grad: -2.481817500665784e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.982555638998747e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.1186496521986555e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4013785403221846e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.68008090845251e-06
sam_encoder.blocks.1.norm1.weight grad: 5.662281182594597e-06
sam_encoder.blocks.1.norm1.bias grad: -1.0693767762859352e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.3533427767906687e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.4194750974638737e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 9.496397979091853e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.175480520032579e-06
sam_encoder.blocks.1.norm2.weight grad: 1.3206788196384878e-07
sam_encoder.blocks.1.norm2.bias grad: 7.962580639286898e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.9476649388016085e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.06363800620602e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.735343620472122e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.158137466627522e-07
sam_encoder.blocks.2.norm1.weight grad: 1.5106612408999354e-05
sam_encoder.blocks.2.norm1.bias grad: -5.594888989435276e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.2241092008480337e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.1359088603057899e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.538465989549877e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.473734187129594e-06
sam_encoder.blocks.2.norm2.weight grad: -2.228871835541213e-06
sam_encoder.blocks.2.norm2.bias grad: 2.016335929511115e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.435767214592488e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4107794186202227e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.1419717793614836e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.122897164255846e-07
sam_encoder.blocks.3.norm1.weight grad: -2.43724698520964e-05
sam_encoder.blocks.3.norm1.bias grad: -2.4850548925314797e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.061684977496043e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.2035669644537847e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.674794227976236e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.9305196019558934e-06
sam_encoder.blocks.3.norm2.weight grad: 1.038371010508854e-05
sam_encoder.blocks.3.norm2.bias grad: 7.475471193174599e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.463453923468478e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.2846069188963156e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.2710655684932135e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1691076906572562e-06
sam_encoder.blocks.4.norm1.weight grad: -2.2010244720149785e-06
sam_encoder.blocks.4.norm1.bias grad: -3.89094793717959e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.798786570361699e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.057175715388439e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.5543791909731226e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.336370006465586e-07
sam_encoder.blocks.4.norm2.weight grad: 1.2961673746758606e-05
sam_encoder.blocks.4.norm2.bias grad: -3.2945158636721317e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 8.01464011601638e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.709850832616212e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.777716756303562e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.939808498718776e-06
sam_encoder.blocks.5.norm1.weight grad: -5.099196187074995e-06
sam_encoder.blocks.5.norm1.bias grad: 4.124070528632728e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.885103978973348e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.839957460309961e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.0560103166644694e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.6953502419455617e-07
sam_encoder.blocks.5.norm2.weight grad: 3.901393938576803e-06
sam_encoder.blocks.5.norm2.bias grad: -7.4347781264805235e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.770708639829536e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.762520001757366e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.363552883049124e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.0905723374653462e-07
sam_encoder.blocks.6.norm1.weight grad: 2.767060095720808e-06
sam_encoder.blocks.6.norm1.bias grad: 3.5309892609802773e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2583157058543293e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0965175079036271e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.768935243897431e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.819502237296547e-07
sam_encoder.blocks.6.norm2.weight grad: -1.5155460175719782e-07
sam_encoder.blocks.6.norm2.bias grad: -7.741670629002328e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.8582932170829736e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.3122543047502404e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1026285164916771e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.648683665844146e-07
sam_encoder.blocks.7.norm1.weight grad: -3.022442569999839e-06
sam_encoder.blocks.7.norm1.bias grad: -2.476020881658769e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.034735871347948e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0271651262883097e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.698572814097133e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 9.640173175284872e-07
sam_encoder.blocks.7.norm2.weight grad: 6.530235623358749e-06
sam_encoder.blocks.7.norm2.bias grad: 1.1914570450244355e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.629956609074725e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.3814629912521923e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.7107890926126856e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.9203425810919725e-07
sam_encoder.blocks.8.norm1.weight grad: -4.662907485908363e-06
sam_encoder.blocks.8.norm1.bias grad: 1.1274806865912979e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.392359187477268e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.0455781875862158e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.6102253539429512e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.294219924209756e-07
sam_encoder.blocks.8.norm2.weight grad: 2.910488092311425e-06
sam_encoder.blocks.8.norm2.bias grad: 1.3279206996230641e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.3081238396116532e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.451337407677784e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0115097381913074e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.8771584109344985e-07
sam_encoder.blocks.9.norm1.weight grad: -2.3424383925885195e-06
sam_encoder.blocks.9.norm1.bias grad: 8.248215976891515e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.512450237190933e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.69656544812824e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.926810414142892e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0186062127104378e-06
sam_encoder.blocks.9.norm2.weight grad: 9.627365216147155e-08
sam_encoder.blocks.9.norm2.bias grad: -6.228333404578734e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.429806210737297e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.554616168661596e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.452534080381156e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.459758772805799e-07
sam_encoder.blocks.10.norm1.weight grad: 8.807202220850741e-07
sam_encoder.blocks.10.norm1.bias grad: -5.130470412950672e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.059412397808046e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.339882929751184e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.044090810064517e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.0916728494266863e-07
sam_encoder.blocks.10.norm2.weight grad: -6.500826543742733e-07
sam_encoder.blocks.10.norm2.bias grad: -1.2663467714446597e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.3877889766008593e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.0737855973275146e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.8389272327112849e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.626438965260604e-07
sam_encoder.blocks.11.norm1.weight grad: -9.833485819399357e-06
sam_encoder.blocks.11.norm1.bias grad: -1.0930656344498857e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.6788885608984856e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.625237342130276e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.2620830602827482e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.858827413860126e-07
sam_encoder.blocks.11.norm2.weight grad: -1.5563080069114221e-06
sam_encoder.blocks.11.norm2.bias grad: -1.931547330968897e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.863358474769484e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.147516155077028e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.9199119378754403e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.32140177256224e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.130832505528815e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.1995010936516337e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.4341504690237343e-08
sam_encoder.neck.conv2.trainable_shift grad: -8.950219125836156e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019363808678463101
mask_decoder.transformer.layers.0.norm1.bias grad: -4.738976713269949e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0037922346964478493
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0007949041901156306
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00013429464888758957
mask_decoder.transformer.layers.0.norm3.bias grad: 2.216020948253572e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.098738569766283e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.6960060495184734e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.615270103793591e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0283623598515987e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.3893014915520325e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011173592793056741
mask_decoder.transformer.layers.1.norm3.weight grad: 3.775150253204629e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.631205592886545e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.882942160591483e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010579921945463866
mask_decoder.transformer.norm_final_attn.weight grad: 7.512427146139089e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.949135008151643e-06
Text_Embedding_Affine.0.weight grad: 1.7565768284377725e-11
Text_Embedding_Affine.0.bias grad: 3.286236838206946e-10
Text_Embedding_Affine.2.weight grad: -1.9794187122723628e-11
Text_Embedding_Affine.2.bias grad: 2.72134602710139e-05
Epoch 29 finished with average loss: -61.7517
Epoch 30/39
----------
Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s, loss=-65.3]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.17it/s, loss=-65.3]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.17it/s, loss=-60.1]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-60.1]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-60.7]Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.41it/s, loss=-60.7]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.174121102211274e-11
Max value: 0.9981991648674011
Mean value: 0.08633193373680115

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.174121102211274e-11
Max value: 0.9981991648674011
Mean value: 0.08633193373680115

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08782672882080078

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.926196098327637
Max value: -1.1920928244535389e-07
Mean value: -0.1143093854188919

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0798029899597168

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08782672882080078

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.835205078125
Max value: 90.35198974609375
Mean value: 65.34268188476562

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.174121102211274e-11
Max value: 0.9981991648674011
Mean value: 0.08633193373680115

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.174121102211274e-11
Max value: 0.9981991648674011
Mean value: 0.08633193373680115

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.174121102211274e-11
Max value: 0.9981991648674011
Mean value: 0.08633193373680115

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.926196098327637
Max value: -1.1920928244535389e-07
Mean value: -0.1143093854188919

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.835205078125
Max value: 90.35198974609375
Mean value: 65.34268188476562

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.34380340576172
Max value: -65.34380340576172
Mean value: -65.34380340576172
sam_encoder.pos_embed grad: -2.171134383388562e-10
sam_encoder.blocks.0.norm1.weight grad: -1.693162994342856e-05
sam_encoder.blocks.0.norm1.bias grad: 6.794268756493693e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.079434231447522e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0256371751893312e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.8107373023212858e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.213635187014006e-06
sam_encoder.blocks.0.norm2.weight grad: 1.5488574717892334e-05
sam_encoder.blocks.0.norm2.bias grad: 1.2793534551747143e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.333862994419178e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.254272658319678e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.815503987425473e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.197543037458672e-06
sam_encoder.blocks.1.norm1.weight grad: -7.641221600351855e-06
sam_encoder.blocks.1.norm1.bias grad: -2.0119003238505684e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.822454684472177e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.918539510370465e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 6.400654456228949e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.2900616133701988e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0114305041497573e-05
sam_encoder.blocks.1.norm2.bias grad: 1.044131386152003e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.909143065859098e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.787921501607343e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.747511285240762e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.62029732564406e-06
sam_encoder.blocks.2.norm1.weight grad: -4.159696800343227e-06
sam_encoder.blocks.2.norm1.bias grad: -2.726652382989414e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.792533453226497e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4272402495407732e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.9614651591837173e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.4773111110553145e-06
sam_encoder.blocks.2.norm2.weight grad: -8.174785762093961e-06
sam_encoder.blocks.2.norm2.bias grad: -2.361347924306756e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.0075614176894305e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.0405046850792132e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 6.221463991096243e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.1820028450747486e-06
sam_encoder.blocks.3.norm1.weight grad: -1.5844125300645828e-07
sam_encoder.blocks.3.norm1.bias grad: -4.5363572098722216e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.1873350962996483e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.2773560911227833e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.428947254884406e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.933092997016502e-07
sam_encoder.blocks.3.norm2.weight grad: -2.910701368818991e-07
sam_encoder.blocks.3.norm2.bias grad: -1.191611204376386e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.416100172325969e-08
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.0591766037323396e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.065135261858813e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5440164133906364e-06
sam_encoder.blocks.4.norm1.weight grad: 1.5930832887534052e-05
sam_encoder.blocks.4.norm1.bias grad: 2.858016046047851e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.381321782100713e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.149652345906361e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.5682915091019822e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.859371642851329e-07
sam_encoder.blocks.4.norm2.weight grad: -7.4948565043087e-07
sam_encoder.blocks.4.norm2.bias grad: -2.1366765849961666e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.4471038412011694e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.0664783733082004e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1110490706632845e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.9639115101408606e-08
sam_encoder.blocks.5.norm1.weight grad: 1.432717817806406e-05
sam_encoder.blocks.5.norm1.bias grad: -9.784542953639175e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.844694432104006e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.701979949255474e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.2297215309663443e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.2508531856146874e-06
sam_encoder.blocks.5.norm2.weight grad: 1.2777195479429793e-05
sam_encoder.blocks.5.norm2.bias grad: -4.493837877816986e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.2369869131798623e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.41169072221237e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.0375079000368714e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.941528004565043e-07
sam_encoder.blocks.6.norm1.weight grad: 1.1250117495364975e-05
sam_encoder.blocks.6.norm1.bias grad: -1.298596089327475e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.86197631189134e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.394508323457558e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.7787613160180626e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.327633054250327e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1367024853825569e-05
sam_encoder.blocks.6.norm2.bias grad: 1.5669287449782132e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.4781280596216675e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.5377394194947556e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.682096452299447e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.7864947444177233e-07
sam_encoder.blocks.7.norm1.weight grad: 8.455431270704139e-07
sam_encoder.blocks.7.norm1.bias grad: -1.6011117622838356e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.028320977842668e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.0007506640904467e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.4210642973466747e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.5418052018721937e-07
sam_encoder.blocks.7.norm2.weight grad: 5.7844986258714925e-06
sam_encoder.blocks.7.norm2.bias grad: -2.8786762413801625e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.590014552581124e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.207630816679739e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.7101805244456045e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1099132279923651e-08
sam_encoder.blocks.8.norm1.weight grad: 5.358735506888479e-06
sam_encoder.blocks.8.norm1.bias grad: -2.72283887170488e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.557976692216471e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.5112863138710964e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.5012323046903475e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.2941923159814905e-06
sam_encoder.blocks.8.norm2.weight grad: 3.154448677378241e-06
sam_encoder.blocks.8.norm2.bias grad: 8.791706562760737e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.942599952708406e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.4488493838580325e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.2523126972373575e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.938599088040064e-07
sam_encoder.blocks.9.norm1.weight grad: -1.152274649030005e-06
sam_encoder.blocks.9.norm1.bias grad: -1.7203915092522948e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.5161838834719674e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.980515194181635e-09
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.901185093331151e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.532739813432272e-07
sam_encoder.blocks.9.norm2.weight grad: 2.010901425819611e-06
sam_encoder.blocks.9.norm2.bias grad: 1.5074741668286151e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.5572626921311894e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.03560113934509e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.925608886376722e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.3335938692525815e-07
sam_encoder.blocks.10.norm1.weight grad: -2.4945240966189886e-06
sam_encoder.blocks.10.norm1.bias grad: 5.837674734721077e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.0853268577193376e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.529239964133012e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.7802419683430344e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.101078587837037e-08
sam_encoder.blocks.10.norm2.weight grad: 1.0372798442404019e-06
sam_encoder.blocks.10.norm2.bias grad: 6.319014005384815e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.567343007191084e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -7.404987627523951e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.056103315022483e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.284629243211384e-08
sam_encoder.blocks.11.norm1.weight grad: -8.2981796367676e-07
sam_encoder.blocks.11.norm1.bias grad: 5.490778676175978e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.65602499339002e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.4736393078892434e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.455875561390712e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.8078906666451076e-07
sam_encoder.blocks.11.norm2.weight grad: -5.956363565928768e-06
sam_encoder.blocks.11.norm2.bias grad: 3.6154874578642193e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.9174566407164093e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.6808746750029968e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6226584875767003e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0312662652722793e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.1454980014823377e-08
sam_encoder.neck.conv1.trainable_shift grad: -4.702071237261407e-06
sam_encoder.neck.conv2.trainable_scale grad: -3.064797056140378e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.967018033610657e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00020924794080201536
mask_decoder.transformer.layers.0.norm1.bias grad: -5.202062311582267e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0022037066519260406
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0014858576469123363
mask_decoder.transformer.layers.0.norm3.weight grad: 3.259781078668311e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.878714414895512e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -4.575391358230263e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 1.225705273100175e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.508374356897548e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.6850062820594758e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00016177943325601518
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00014537600509356707
mask_decoder.transformer.layers.1.norm3.weight grad: -6.857073458377272e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.845308234915137e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.5511475794482976e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -1.4897633263899479e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.025969934038585e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.051453864420182e-06
Text_Embedding_Affine.0.weight grad: 1.4006431431345945e-11
Text_Embedding_Affine.0.bias grad: 4.051872726229533e-10
Text_Embedding_Affine.2.weight grad: -3.183584992849653e-11
Text_Embedding_Affine.2.bias grad: 6.134401337476447e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.388566077319234e-14
Max value: 0.9973164200782776
Mean value: 0.0788918286561966

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.388566077319234e-14
Max value: 0.9973164200782776
Mean value: 0.0788918286561966

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07791423797607422

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11411789059638977

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06891775131225586

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07791423797607422

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.12223434448242
Max value: 64.71553039550781
Mean value: 54.87357711791992

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.785886705445855e-13
Max value: 0.9971116781234741
Mean value: 0.07964059710502625

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.785886705445855e-13
Max value: 0.9971116781234741
Mean value: 0.07964059710502625

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.785886705445855e-13
Max value: 0.9971116781234741
Mean value: 0.07964059710502625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1141439825296402

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9554227590560913
Max value: 1.6099343299865723
Mean value: 1.0000054836273193

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.12223434448242
Max value: 64.71553039550781
Mean value: 54.87357711791992

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.87520980834961
Max value: -54.87520980834961
Mean value: -54.87520980834961
sam_encoder.pos_embed grad: -1.1129136723297961e-08
sam_encoder.blocks.0.norm1.weight grad: -0.00012103916378691792
sam_encoder.blocks.0.norm1.bias grad: -4.75442866445519e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.1063917301944457e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.7650976335280575e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.2972568331169896e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.1012051547586452e-06
sam_encoder.blocks.0.norm2.weight grad: 7.37488953745924e-05
sam_encoder.blocks.0.norm2.bias grad: 4.64765980723314e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.0038835171144456e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.333603333681822e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.5978608391596936e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.4116262668248964e-06
sam_encoder.blocks.1.norm1.weight grad: -7.982685019669589e-06
sam_encoder.blocks.1.norm1.bias grad: -9.488237992627546e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.237879001171677e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.3898811580002075e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.0186525157869255e-08
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.651254706303007e-06
sam_encoder.blocks.1.norm2.weight grad: 2.0211322407703847e-05
sam_encoder.blocks.1.norm2.bias grad: 9.434343155589886e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.192623585666297e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.9718279367662035e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.51108424688573e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.6171662739216117e-06
sam_encoder.blocks.2.norm1.weight grad: -3.291735538368812e-06
sam_encoder.blocks.2.norm1.bias grad: 1.9776023236772744e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.757121238682885e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2474999948608456e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.6260286201941199e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.2168063626158983e-06
sam_encoder.blocks.2.norm2.weight grad: -9.704427611723077e-06
sam_encoder.blocks.2.norm2.bias grad: 2.9606459065689705e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.8973563429608475e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.6692421165062115e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 8.85972440300975e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.2507787182112224e-06
sam_encoder.blocks.3.norm1.weight grad: -5.362075171433389e-06
sam_encoder.blocks.3.norm1.bias grad: 3.6100391298532486e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 6.940146704437211e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.968716555391438e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.469807547342498e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.7317073520171107e-07
sam_encoder.blocks.3.norm2.weight grad: 4.095365056855371e-06
sam_encoder.blocks.3.norm2.bias grad: 6.251329068618361e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.5111916076857597e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2988194814388407e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.7822279662359506e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.038130209162773e-07
sam_encoder.blocks.4.norm1.weight grad: 1.3355509508983232e-05
sam_encoder.blocks.4.norm1.bias grad: -1.298608367505949e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.834300858012284e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.8391642697679345e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.330022751579236e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.3581418392714113e-06
sam_encoder.blocks.4.norm2.weight grad: 3.1371411751024425e-05
sam_encoder.blocks.4.norm2.bias grad: -2.177474380005151e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.5742003597551957e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.6571747184789274e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.1090486623288598e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.835088475374505e-06
sam_encoder.blocks.5.norm1.weight grad: 9.207313269143924e-06
sam_encoder.blocks.5.norm1.bias grad: 3.809594488757284e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.412516086129472e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.558999873755965e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.4629595170845278e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.6413157482020324e-06
sam_encoder.blocks.5.norm2.weight grad: 2.3849241188145243e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0225447113043629e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.93421781458892e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.3808023545134347e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.241847818775568e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.253497316611174e-06
sam_encoder.blocks.6.norm1.weight grad: 4.158842784818262e-06
sam_encoder.blocks.6.norm1.bias grad: 5.020200660510454e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.441625944513362e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.7284478366927942e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.882565083467853e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.5316855953860795e-06
sam_encoder.blocks.6.norm2.weight grad: 3.556544243110693e-06
sam_encoder.blocks.6.norm2.bias grad: -6.979716545174597e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.300213956616062e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.533707844231685e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.588341653288808e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.6323548354412196e-06
sam_encoder.blocks.7.norm1.weight grad: 5.684875759470742e-06
sam_encoder.blocks.7.norm1.bias grad: -4.1970029087678995e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.748029591108207e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.870594652738873e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.3393130252079573e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.0960329645022284e-06
sam_encoder.blocks.7.norm2.weight grad: 9.51958918449236e-06
sam_encoder.blocks.7.norm2.bias grad: -4.767046448250767e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0585650670691393e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.097886630916037e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.212309919348627e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.830312824808061e-07
sam_encoder.blocks.8.norm1.weight grad: -6.750537068000995e-06
sam_encoder.blocks.8.norm1.bias grad: -1.2744699233735446e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.2836800326331286e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.628190148039721e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.8278182096764795e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.1965353223786224e-06
sam_encoder.blocks.8.norm2.weight grad: 8.84714609128423e-06
sam_encoder.blocks.8.norm2.bias grad: 3.015875790879363e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 8.119755875668488e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.298347448639106e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.5635114323231392e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.1575410730511067e-07
sam_encoder.blocks.9.norm1.weight grad: 2.3141151359595824e-06
sam_encoder.blocks.9.norm1.bias grad: 1.5276766589522595e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.621515578648541e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.2157254332123557e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.100071924360236e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.463334567437414e-06
sam_encoder.blocks.9.norm2.weight grad: 5.24217966813012e-06
sam_encoder.blocks.9.norm2.bias grad: 1.1690781320794486e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.5565020678186556e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.7916277101903688e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.177141029984341e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.882018629359663e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2785620810973342e-06
sam_encoder.blocks.10.norm1.bias grad: 2.824774583132239e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.69363623476238e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.079024465563634e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.187560757098254e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.0164104575524107e-07
sam_encoder.blocks.10.norm2.weight grad: 1.09461325337179e-05
sam_encoder.blocks.10.norm2.bias grad: 3.348669224578771e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.975022420694586e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.135668637492927e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.235787400830304e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.07297829194431e-07
sam_encoder.blocks.11.norm1.weight grad: -5.321589924278669e-06
sam_encoder.blocks.11.norm1.bias grad: 9.211770475303638e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -9.347766535938717e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.8324916456767824e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.3529559055314166e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.568029675690923e-07
sam_encoder.blocks.11.norm2.weight grad: 4.425484803505242e-06
sam_encoder.blocks.11.norm2.bias grad: 1.5742753021186218e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.548996002995409e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.261137847715872e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.727139970687858e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.0260085875634104e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.1448555596871302e-06
sam_encoder.neck.conv1.trainable_shift grad: 5.450354365166277e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.6119502106448635e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.2047136957990006e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 5.351088475435972e-06
mask_decoder.transformer.layers.0.norm1.bias grad: -2.0160950953140855e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0030513466335833073
mask_decoder.transformer.layers.0.norm2.bias grad: 9.54512506723404e-06
mask_decoder.transformer.layers.0.norm3.weight grad: -1.5115118003450334e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -7.61726259952411e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 2.9495093258447014e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.6556989066884853e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.3388689189450815e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.4736397133674473e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00030561385210603476
mask_decoder.transformer.layers.1.norm2.bias grad: -0.000187115409062244
mask_decoder.transformer.layers.1.norm3.weight grad: -0.00010703768202802166
mask_decoder.transformer.layers.1.norm3.bias grad: -8.647686627227813e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.7605790819507092e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.8408136131474748e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.7327155294187833e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.6584077608713415e-06
Text_Embedding_Affine.0.weight grad: 1.9877459053740942e-11
Text_Embedding_Affine.0.bias grad: 5.276106218587984e-10
Text_Embedding_Affine.2.weight grad: 3.2820426931756685e-11
Text_Embedding_Affine.2.bias grad: -1.4261750038713217e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.88200406920603e-13
Max value: 0.9977561831474304
Mean value: 0.08997185528278351

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.88200406920603e-13
Max value: 0.9977561831474304
Mean value: 0.08997185528278351

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08809089660644531

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1307864487171173

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08185482025146484

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08809089660644531

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 59.078224182128906
Max value: 65.87638092041016
Mean value: 61.81676483154297

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6074526652403174e-12
Max value: 0.9972289204597473
Mean value: 0.09025949239730835

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6074526652403174e-12
Max value: 0.9972289204597473
Mean value: 0.09025949239730835

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6074526652403174e-12
Max value: 0.9972289204597473
Mean value: 0.09025949239730835

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13027197122573853

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9530016183853149
Max value: 1.932431697845459
Mean value: 1.000594973564148

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 59.078224182128906
Max value: 65.87638092041016
Mean value: 61.81676483154297

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.85051727294922
Max value: -61.85051727294922
Mean value: -61.85051727294922
sam_encoder.pos_embed grad: 8.199132039976575e-09
sam_encoder.blocks.0.norm1.weight grad: 8.321215136675164e-05
sam_encoder.blocks.0.norm1.bias grad: 1.769032678566873e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.286587111186236e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.232677675488958e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.610760227777064e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.679328417798388e-06
sam_encoder.blocks.0.norm2.weight grad: 2.41263369389344e-05
sam_encoder.blocks.0.norm2.bias grad: -5.35490908077918e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.18841596506536e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.092578365089139e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.008119140053168e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.8244050857611e-06
sam_encoder.blocks.1.norm1.weight grad: 3.6015833302371902e-06
sam_encoder.blocks.1.norm1.bias grad: 5.005401908420026e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.401359233772382e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.153012458933517e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.2596967028221115e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2806816812371835e-05
sam_encoder.blocks.1.norm2.weight grad: 1.9990380678791553e-05
sam_encoder.blocks.1.norm2.bias grad: -1.59374758368358e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.2140171747887507e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.2334706955007277e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.2474170186324045e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.4823941506329e-06
sam_encoder.blocks.2.norm1.weight grad: -7.007682870607823e-05
sam_encoder.blocks.2.norm1.bias grad: 1.995717866520863e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.7083576646400616e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.121856808429584e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.7644186047837138e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3665422557096463e-05
sam_encoder.blocks.2.norm2.weight grad: -2.0818686607526615e-05
sam_encoder.blocks.2.norm2.bias grad: -1.2798764146282338e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.2467196029319894e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4894575315338443e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.810463254514616e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.063342541689053e-06
sam_encoder.blocks.3.norm1.weight grad: 2.5165847546304576e-05
sam_encoder.blocks.3.norm1.bias grad: 7.98688233771827e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.0968719784141285e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.926516006278689e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.089233127364423e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.0618397179059684e-06
sam_encoder.blocks.3.norm2.weight grad: -1.6259522453765385e-05
sam_encoder.blocks.3.norm2.bias grad: 9.034025424625725e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3761359696218278e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.989750325672503e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.475791800156003e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8750010895018931e-06
sam_encoder.blocks.4.norm1.weight grad: -7.584563263662858e-06
sam_encoder.blocks.4.norm1.bias grad: -2.6059615265694447e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.840588973020203e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.3776341297198087e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2872797015006654e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.1225685057070223e-06
sam_encoder.blocks.4.norm2.weight grad: -3.006151018780656e-05
sam_encoder.blocks.4.norm2.bias grad: -1.7396108887623996e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.9473503673216328e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.37093193695182e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.696996373037109e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.79636388617655e-07
sam_encoder.blocks.5.norm1.weight grad: -1.3553684766520746e-05
sam_encoder.blocks.5.norm1.bias grad: -2.0876479538856074e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.0325697076041251e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.3986430025834125e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.571969839162193e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.95310212802724e-06
sam_encoder.blocks.5.norm2.weight grad: -1.6993635654216632e-05
sam_encoder.blocks.5.norm2.bias grad: -6.1417531469487585e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.3930992281530052e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.2027104427688755e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.817614469880937e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.845347565511474e-07
sam_encoder.blocks.6.norm1.weight grad: -2.280968601553468e-06
sam_encoder.blocks.6.norm1.bias grad: -3.2139439554157434e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.497316568740644e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.699165275378618e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.563500063639367e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.9807360988343135e-06
sam_encoder.blocks.6.norm2.weight grad: 1.1894097951881122e-05
sam_encoder.blocks.6.norm2.bias grad: 1.5933546819724143e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.154990224629728e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.78296077644336e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.44580110120296e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.243276012199203e-07
sam_encoder.blocks.7.norm1.weight grad: 8.164493920048699e-06
sam_encoder.blocks.7.norm1.bias grad: -1.1830777566501638e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.019429302890785e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.4662849707747228e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.5446477138757473e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.840182216663379e-06
sam_encoder.blocks.7.norm2.weight grad: -1.0545826626184862e-05
sam_encoder.blocks.7.norm2.bias grad: -3.6724550227518193e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.745728685724316e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.631949195754714e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.5687121453520376e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.115786549936274e-08
sam_encoder.blocks.8.norm1.weight grad: 2.316250538569875e-05
sam_encoder.blocks.8.norm1.bias grad: -2.5316998630842136e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.877855720522348e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.160375050967559e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -8.97994766546617e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.688566382857971e-06
sam_encoder.blocks.8.norm2.weight grad: -4.370671831566142e-06
sam_encoder.blocks.8.norm2.bias grad: 1.883991672002594e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.868198968528304e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.2858411032066215e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.584018941182876e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2051355042785872e-06
sam_encoder.blocks.9.norm1.weight grad: -1.0720807495090412e-06
sam_encoder.blocks.9.norm1.bias grad: -1.2472348771552788e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.4849114222670323e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.062159981302102e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.708036847958283e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2783566489815712e-06
sam_encoder.blocks.9.norm2.weight grad: -8.603724381828215e-06
sam_encoder.blocks.9.norm2.bias grad: -2.9432553105834813e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.96550011727959e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.832061338471249e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.668311367415299e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.315819973679027e-07
sam_encoder.blocks.10.norm1.weight grad: -3.6517303669825196e-06
sam_encoder.blocks.10.norm1.bias grad: 8.497262342643808e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.872615371212305e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.451953140640398e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4230126907932572e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.0816357821095153e-07
sam_encoder.blocks.10.norm2.weight grad: -1.8488388377591036e-05
sam_encoder.blocks.10.norm2.bias grad: -7.009201908658724e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.787542694539297e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.197680937068071e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.0051642170292325e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.1230521269899327e-06
sam_encoder.blocks.11.norm1.weight grad: 3.0455918022198603e-05
sam_encoder.blocks.11.norm1.bias grad: 4.6425984692177735e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.3101171134621836e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.962716052934411e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2950888503837632e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.2981870628768775e-08
sam_encoder.blocks.11.norm2.weight grad: -1.0110395123774651e-05
sam_encoder.blocks.11.norm2.bias grad: -4.081191946170293e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.9456098167866e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.1105095129314577e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7240004126506392e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.970574304432375e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.058529157191515e-08
sam_encoder.neck.conv1.trainable_shift grad: -9.229552233591676e-08
sam_encoder.neck.conv2.trainable_scale grad: 1.9231265468988568e-06
sam_encoder.neck.conv2.trainable_shift grad: -9.125826181843877e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00016870058607310057
mask_decoder.transformer.layers.0.norm1.bias grad: -5.341436917660758e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0032982933335006237
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0009986991062760353
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00026206759503111243
mask_decoder.transformer.layers.0.norm3.bias grad: -3.122103225905448e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -1.2874450476374477e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.009860044287052e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.7264532036497258e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.840370820602402e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00017082272097468376
mask_decoder.transformer.layers.1.norm2.bias grad: 3.948588710045442e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.752219734247774e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.12366607633885e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.8430833228630945e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.21127993427217e-06
mask_decoder.transformer.norm_final_attn.weight grad: 9.432560545974411e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3851748690285604e-06
Text_Embedding_Affine.0.weight grad: 3.268873366435443e-11
Text_Embedding_Affine.0.bias grad: -3.7620306869712294e-10
Text_Embedding_Affine.2.weight grad: -4.115163071416461e-12
Text_Embedding_Affine.2.bias grad: -4.234250445733778e-05
Epoch 30 finished with average loss: -60.6898
Epoch 31/39
----------
Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-56]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-54.5]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-54.5]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-59.2]Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-59.2]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.120630482136068e-12
Max value: 0.9992341995239258
Mean value: 0.06904233247041702

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.120630482136068e-12
Max value: 0.9992341995239258
Mean value: 0.06904233247041702

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07316160202026367

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10292865335941315

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05995988845825195

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07316160202026367

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 17.88201904296875
Max value: 87.26741027832031
Mean value: 55.9870719909668

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.120630482136068e-12
Max value: 0.9992341995239258
Mean value: 0.06904233247041702

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.120630482136068e-12
Max value: 0.9992341995239258
Mean value: 0.06904233247041702

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.120630482136068e-12
Max value: 0.9992341995239258
Mean value: 0.06904233247041702

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10292865335941315

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 17.88201904296875
Max value: 87.26741027832031
Mean value: 55.9870719909668

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.987979888916016
Max value: -55.987979888916016
Mean value: -55.987979888916016
sam_encoder.pos_embed grad: 5.460974783488837e-09
sam_encoder.blocks.0.norm1.weight grad: 1.6675932783982717e-05
sam_encoder.blocks.0.norm1.bias grad: -1.911696745082736e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.375758519221563e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.989400099158047e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.515464974654606e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.779175348332501e-07
sam_encoder.blocks.0.norm2.weight grad: -8.102495485218242e-06
sam_encoder.blocks.0.norm2.bias grad: 7.886691491876263e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.729985332436627e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.974210241925903e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.020392099046148e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.162910489772912e-06
sam_encoder.blocks.1.norm1.weight grad: 2.2550868379767053e-05
sam_encoder.blocks.1.norm1.bias grad: 3.4794261409842875e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.981215498555684e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.1943449723949016e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.5887523829860584e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.8687142616945494e-07
sam_encoder.blocks.1.norm2.weight grad: 4.039855411974713e-06
sam_encoder.blocks.1.norm2.bias grad: -5.196363417780958e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.003800727214184e-08
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.3780583546795242e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.4896610284486087e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.970276101332274e-07
sam_encoder.blocks.2.norm1.weight grad: 2.937252247647848e-06
sam_encoder.blocks.2.norm1.bias grad: -1.258350494026672e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.156648067990318e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.070358722354285e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.3949429558124393e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 6.938201835282598e-08
sam_encoder.blocks.2.norm2.weight grad: -9.745616807776969e-06
sam_encoder.blocks.2.norm2.bias grad: 8.342400178662501e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.320359832694521e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4718679040015559e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.3986042378965067e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.1277824089338537e-06
sam_encoder.blocks.3.norm1.weight grad: -1.0829130587808322e-05
sam_encoder.blocks.3.norm1.bias grad: -3.5741011288337177e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.367661858850624e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.094956701308547e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.9247925138188293e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.079874320770614e-06
sam_encoder.blocks.3.norm2.weight grad: 5.528072506422177e-07
sam_encoder.blocks.3.norm2.bias grad: 9.052781933860388e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.898709681176115e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.311400575967127e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.6334324755007401e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.587017307741917e-07
sam_encoder.blocks.4.norm1.weight grad: -1.5374116628663614e-05
sam_encoder.blocks.4.norm1.bias grad: 2.753333205873787e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0728191227826755e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.8207990655791946e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.939069301850395e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.347962658357574e-06
sam_encoder.blocks.4.norm2.weight grad: 8.866571079124697e-06
sam_encoder.blocks.4.norm2.bias grad: 1.1526116395543795e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.534917247336125e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.59653552348027e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.0637080524466e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0730827852967195e-06
sam_encoder.blocks.5.norm1.weight grad: -4.652026291296352e-06
sam_encoder.blocks.5.norm1.bias grad: -2.5117446966760326e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.2856893363277777e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.6497622254973976e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.299957370472839e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.0299391962907976e-06
sam_encoder.blocks.5.norm2.weight grad: 2.1218136225797934e-06
sam_encoder.blocks.5.norm2.bias grad: 7.163507689256221e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.7938727978616953e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.321478960875538e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.068177415523678e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.7771488930738997e-07
sam_encoder.blocks.6.norm1.weight grad: 1.2375741789583117e-05
sam_encoder.blocks.6.norm1.bias grad: -4.109553174203029e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.584431270719506e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.1693225537310354e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.1642500744055724e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.2541420296183787e-06
sam_encoder.blocks.6.norm2.weight grad: 9.872027476376388e-06
sam_encoder.blocks.6.norm2.bias grad: 4.10261827710201e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.879021723056212e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.808343990385765e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.472131027137948e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.490649866464082e-07
sam_encoder.blocks.7.norm1.weight grad: -4.256735337548889e-06
sam_encoder.blocks.7.norm1.bias grad: 2.3547968339698855e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.806727937037067e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.279654663401743e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.687715649102756e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.6507706277479883e-06
sam_encoder.blocks.7.norm2.weight grad: -3.2964321690087672e-06
sam_encoder.blocks.7.norm2.bias grad: -4.0866972028652526e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.051720912277233e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7352108443446923e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6184210380743025e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.6503206501947716e-07
sam_encoder.blocks.8.norm1.weight grad: -4.382293809612747e-06
sam_encoder.blocks.8.norm1.bias grad: 1.0502029681447311e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.070982868142892e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.952161483131931e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.851476665455266e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.6395364355048514e-06
sam_encoder.blocks.8.norm2.weight grad: -5.308927939040586e-06
sam_encoder.blocks.8.norm2.bias grad: -1.5022867501102155e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.46493777417345e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.060604285565205e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.9250398963777116e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.208507900533732e-07
sam_encoder.blocks.9.norm1.weight grad: -3.951554845116334e-06
sam_encoder.blocks.9.norm1.bias grad: 1.572372980263026e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.0229844014684204e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.130894689704292e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.93767605703033e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.224014891311526e-07
sam_encoder.blocks.9.norm2.weight grad: -3.7099869132362073e-06
sam_encoder.blocks.9.norm2.bias grad: -1.8170694602304138e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.236714408354601e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.1687660617099027e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8970631288084405e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.61679075367283e-09
sam_encoder.blocks.10.norm1.weight grad: -3.700713477883255e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1685655181281618e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.2950061975279823e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.94449772961525e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.499138519051485e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.414261750047444e-07
sam_encoder.blocks.10.norm2.weight grad: -7.213964181573829e-06
sam_encoder.blocks.10.norm2.bias grad: -4.222525603836402e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.426555622354499e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.4222972569987178e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.6275317850377178e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.574799608140893e-07
sam_encoder.blocks.11.norm1.weight grad: -8.813018212094903e-06
sam_encoder.blocks.11.norm1.bias grad: 1.0080884749186225e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.924697355410899e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.1105105386377545e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.080183076548565e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.5599318809763645e-07
sam_encoder.blocks.11.norm2.weight grad: -9.799115105124656e-06
sam_encoder.blocks.11.norm2.bias grad: -2.39524842982064e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.652366674738005e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.9972069367213408e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.6638513190846425e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0485816801519832e-06
sam_encoder.neck.conv1.trainable_scale grad: 3.712793841259554e-07
sam_encoder.neck.conv1.trainable_shift grad: 6.715864401485305e-06
sam_encoder.neck.conv2.trainable_scale grad: 4.0033137338468805e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.565200576209463e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00030643277568742633
mask_decoder.transformer.layers.0.norm1.bias grad: -4.427958629094064e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0025210408493876457
mask_decoder.transformer.layers.0.norm2.bias grad: 0.001619019079953432
mask_decoder.transformer.layers.0.norm3.weight grad: -9.806323942029849e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.0856860171770677e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.642167161568068e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.215116289036814e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.731406337057706e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.24772985954769e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -1.376577711198479e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.242412326973863e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.2348567906883545e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.8824823200702667e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.6289177185390145e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 1.1412903404561803e-06
mask_decoder.transformer.norm_final_attn.weight grad: 8.955174052971415e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.3927801774116233e-05
Text_Embedding_Affine.0.weight grad: -1.3882532276521253e-11
Text_Embedding_Affine.0.bias grad: -4.985895030173992e-10
Text_Embedding_Affine.2.weight grad: 9.190352645571664e-11
Text_Embedding_Affine.2.bias grad: 6.784201832488179e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.70299256067974e-12
Max value: 0.9952980875968933
Mean value: 0.08204576373100281

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.70299256067974e-12
Max value: 0.9952980875968933
Mean value: 0.08204576373100281

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08237838745117188

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.678298950195312
Max value: -1.1920928244535389e-07
Mean value: -0.12490297853946686

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06812858581542969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08237838745117188

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.406063079833984
Max value: 74.79014587402344
Mean value: 53.00566482543945

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.24415319797067e-12
Max value: 0.9942606687545776
Mean value: 0.08361805230379105

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.24415319797067e-12
Max value: 0.9942606687545776
Mean value: 0.08361805230379105

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.24415319797067e-12
Max value: 0.9942606687545776
Mean value: 0.08361805230379105

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.308120727539062
Max value: -1.1920928244535389e-07
Mean value: -0.12496443092823029

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9638887047767639
Max value: 1.6996238231658936
Mean value: 1.000037670135498

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.406063079833984
Max value: 74.79014587402344
Mean value: 53.00566482543945

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.00568389892578
Max value: -53.00568389892578
Mean value: -53.00568389892578
sam_encoder.pos_embed grad: 6.087135240306907e-10
sam_encoder.blocks.0.norm1.weight grad: -1.8598015230963938e-05
sam_encoder.blocks.0.norm1.bias grad: -1.2128299204050563e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.276060735719511e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.006195801295689e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -9.176384082820732e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.331564238986175e-07
sam_encoder.blocks.0.norm2.weight grad: -7.388218364212662e-06
sam_encoder.blocks.0.norm2.bias grad: 4.729405191028491e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.8815135263139382e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.7144354842457687e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.2660958260730695e-08
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.4386940847543883e-06
sam_encoder.blocks.1.norm1.weight grad: 4.482916210690746e-06
sam_encoder.blocks.1.norm1.bias grad: 4.8935280574369244e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.4873583015505574e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.8792308626179874e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.929689213095116e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.2335765947900654e-07
sam_encoder.blocks.1.norm2.weight grad: 2.64091431745328e-05
sam_encoder.blocks.1.norm2.bias grad: -1.284694008063525e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.792467956984183e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.2089282083470607e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.145780505699804e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.039310953085078e-07
sam_encoder.blocks.2.norm1.weight grad: 6.0629527069977485e-06
sam_encoder.blocks.2.norm1.bias grad: -9.332061381428503e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.512929313525092e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.004496632769587e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.9132024792488664e-08
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.5213627193588763e-06
sam_encoder.blocks.2.norm2.weight grad: 9.087541002372745e-06
sam_encoder.blocks.2.norm2.bias grad: -1.9271337805548683e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.403194336395245e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.1908032244464266e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.585952415756765e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7894360553327715e-06
sam_encoder.blocks.3.norm1.weight grad: -6.898218998685479e-06
sam_encoder.blocks.3.norm1.bias grad: -5.253159088169923e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.249313744570827e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4453432868322125e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.981773369967414e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.4586725001208833e-06
sam_encoder.blocks.3.norm2.weight grad: 1.2380798580124974e-05
sam_encoder.blocks.3.norm2.bias grad: -5.304751539370045e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.95396078703925e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.5943717193731572e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.084661213710206e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.913639829988824e-07
sam_encoder.blocks.4.norm1.weight grad: 1.008598610496847e-05
sam_encoder.blocks.4.norm1.bias grad: -4.694081212619494e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.304203907347983e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.8547065110396943e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.083233877987368e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.2396893655241e-06
sam_encoder.blocks.4.norm2.weight grad: -1.2367435374471825e-05
sam_encoder.blocks.4.norm2.bias grad: -9.953423614206258e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.953846877877368e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.8907606974826194e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.0154843721466023e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.27250494492182e-07
sam_encoder.blocks.5.norm1.weight grad: -3.277207724750042e-06
sam_encoder.blocks.5.norm1.bias grad: -7.5865318649448454e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.492144737218041e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.690138671823661e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5124545572907664e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.3200588000472635e-07
sam_encoder.blocks.5.norm2.weight grad: -9.525330824544653e-06
sam_encoder.blocks.5.norm2.bias grad: -5.882112873223377e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.631106094166171e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.4781937807128998e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.18413070646784e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0573064628260909e-06
sam_encoder.blocks.6.norm1.weight grad: -2.6532575247983914e-06
sam_encoder.blocks.6.norm1.bias grad: 3.0848917731418624e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.000777153123636e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.3845755094953347e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.6463403653688147e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.2488966376622557e-06
sam_encoder.blocks.6.norm2.weight grad: 1.1633604657390606e-07
sam_encoder.blocks.6.norm2.bias grad: 1.5106382988960831e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.967516353346582e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.321635399013758e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.4119808611212648e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0572736073299893e-06
sam_encoder.blocks.7.norm1.weight grad: -2.645604126882972e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3475317928168806e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.521832695696503e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.198747766778979e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.5786422409291845e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.6433084460441023e-06
sam_encoder.blocks.7.norm2.weight grad: 2.038902948697796e-06
sam_encoder.blocks.7.norm2.bias grad: 1.0864666819543345e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9172880456608254e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.2362974644020142e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.960715038279886e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.969271003574249e-07
sam_encoder.blocks.8.norm1.weight grad: -1.4570914572686888e-06
sam_encoder.blocks.8.norm1.bias grad: -3.760160325327888e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.2484953155508265e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.7210386431543157e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.813521278876578e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3385470083449036e-06
sam_encoder.blocks.8.norm2.weight grad: -1.3799078715237556e-06
sam_encoder.blocks.8.norm2.bias grad: -1.944823679878027e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.49298272037413e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.176024041655182e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.79595371416508e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.342469708262797e-07
sam_encoder.blocks.9.norm1.weight grad: -6.899728646203585e-07
sam_encoder.blocks.9.norm1.bias grad: 3.898113334344089e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.350850156877641e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.365934730936715e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.6468703140380967e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.515678367373766e-07
sam_encoder.blocks.9.norm2.weight grad: -2.4913788365665823e-08
sam_encoder.blocks.9.norm2.bias grad: -9.073745559362578e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.714545068258303e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.845239232054155e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.641213197624893e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.749187377863564e-07
sam_encoder.blocks.10.norm1.weight grad: -7.717084145042463e-07
sam_encoder.blocks.10.norm1.bias grad: 6.592828754037328e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.988280804558599e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.115669014481682e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.359526878441102e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.037095837044035e-07
sam_encoder.blocks.10.norm2.weight grad: -7.370330195044517e-07
sam_encoder.blocks.10.norm2.bias grad: -1.6377020983782131e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.770046757585078e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.04914100424503e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.4099244936005562e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.842995159990096e-07
sam_encoder.blocks.11.norm1.weight grad: 3.827437012660084e-06
sam_encoder.blocks.11.norm1.bias grad: 2.462714292050805e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0383528206148185e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.119413112377515e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.137833007509471e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.890058337674418e-07
sam_encoder.blocks.11.norm2.weight grad: -9.702520031851236e-08
sam_encoder.blocks.11.norm2.bias grad: -1.2974339824722847e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 9.527552151666896e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -9.474346995830274e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.301361387770157e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.545692379702814e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.8083119357470423e-07
sam_encoder.neck.conv1.trainable_shift grad: -7.3316414272994734e-06
sam_encoder.neck.conv2.trainable_scale grad: -9.331652108812705e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.887135972036049e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012563695781864226
mask_decoder.transformer.layers.0.norm1.bias grad: -4.071476723765954e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0054480042308568954
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003831903450191021
mask_decoder.transformer.layers.0.norm3.weight grad: 5.315754606272094e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -5.3563620895147324e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013040215708315372
mask_decoder.transformer.layers.0.norm4.bias grad: -9.553056770528201e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.202907075523399e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.1116466086823493e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -8.919525134842843e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.8244685381650925e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 2.7938471248489805e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.945478627225384e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -2.1535532141570002e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00021282471425365657
mask_decoder.transformer.norm_final_attn.weight grad: 6.337539616652066e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.6369600416510366e-05
Text_Embedding_Affine.0.weight grad: 5.536415943752093e-12
Text_Embedding_Affine.0.bias grad: -3.237926593513407e-10
Text_Embedding_Affine.2.weight grad: -7.937039220307085e-11
Text_Embedding_Affine.2.bias grad: 4.97802029713057e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6112960752056047e-11
Max value: 0.9983086585998535
Mean value: 0.11719464510679245

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6112960752056047e-11
Max value: 0.9983086585998535
Mean value: 0.11719464510679245

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10701274871826172

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.360519409179688
Max value: -1.1920928244535389e-07
Mean value: -0.14148780703544617

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11180686950683594

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10701274871826172

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 59.56350326538086
Max value: 77.05409240722656
Mean value: 68.57449340820312

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.155157881801657e-11
Max value: 0.9977688789367676
Mean value: 0.1172228530049324

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.155157881801657e-11
Max value: 0.9977688789367676
Mean value: 0.1172228530049324

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.155157881801657e-11
Max value: 0.9977688789367676
Mean value: 0.1172228530049324

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.809277534484863
Max value: -1.1920928244535389e-07
Mean value: -0.14119979739189148

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9278634786605835
Max value: 2.545055866241455
Mean value: 1.0004754066467285

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 59.56350326538086
Max value: 77.05409240722656
Mean value: 68.57449340820312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.58515930175781
Max value: -68.58515930175781
Mean value: -68.58515930175781
sam_encoder.pos_embed grad: -1.22492460619128e-10
sam_encoder.blocks.0.norm1.weight grad: 1.0099278370034881e-05
sam_encoder.blocks.0.norm1.bias grad: -3.812944487435743e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.0400697141885757e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.709560741389396e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.25909547629999e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.888202627422288e-06
sam_encoder.blocks.0.norm2.weight grad: -1.8948903743876144e-05
sam_encoder.blocks.0.norm2.bias grad: -1.1917763004021253e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 8.221779353334568e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.986557890631957e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.311330561293289e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.76876437762985e-06
sam_encoder.blocks.1.norm1.weight grad: 7.824301974324044e-06
sam_encoder.blocks.1.norm1.bias grad: 2.799504727590829e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.361731614859309e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.177851001761155e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.891980435990263e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.585031092574354e-06
sam_encoder.blocks.1.norm2.weight grad: -3.270797378718271e-06
sam_encoder.blocks.1.norm2.bias grad: -4.05979881179519e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.5472811532599735e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.4811328103169217e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3763514289166778e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.366666649322724e-06
sam_encoder.blocks.2.norm1.weight grad: 7.043781806714833e-07
sam_encoder.blocks.2.norm1.bias grad: 4.444472779141506e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.450874712347286e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8074955505653634e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4550978448824026e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.6368655906262575e-06
sam_encoder.blocks.2.norm2.weight grad: -2.1372177798184566e-05
sam_encoder.blocks.2.norm2.bias grad: -7.009826276771491e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.4355950042954646e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.2684106372471433e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.08278252609307e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.995716729652486e-06
sam_encoder.blocks.3.norm1.weight grad: -4.727102350443602e-06
sam_encoder.blocks.3.norm1.bias grad: 2.2898179850017186e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.258073997538304e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1967129012191435e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.305321454012301e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.1572577679762617e-06
sam_encoder.blocks.3.norm2.weight grad: -1.5825562513782643e-05
sam_encoder.blocks.3.norm2.bias grad: -9.971494364435785e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0550697879807558e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.840053523163078e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.216096507050679e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2885386695415946e-06
sam_encoder.blocks.4.norm1.weight grad: 6.560620022355579e-06
sam_encoder.blocks.4.norm1.bias grad: 2.8373228815326e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.7296323449045303e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1543833124960656e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.207621249312069e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.1268309612642042e-06
sam_encoder.blocks.4.norm2.weight grad: -1.1644197911664378e-05
sam_encoder.blocks.4.norm2.bias grad: -2.748713541222969e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.706372914777603e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.0282386685721576e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.2850798561412375e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.5151333627727581e-06
sam_encoder.blocks.5.norm1.weight grad: 1.0070316420751624e-05
sam_encoder.blocks.5.norm1.bias grad: 2.1227856450423133e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.087826245173346e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.0404434078736813e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.015669454318413e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.9014636336578405e-06
sam_encoder.blocks.5.norm2.weight grad: -1.2266208614164498e-05
sam_encoder.blocks.5.norm2.bias grad: 1.2588507161126472e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.87233909452334e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.1845584089751355e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.8842777080863016e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.0196221700862225e-07
sam_encoder.blocks.6.norm1.weight grad: 1.4693614502903074e-06
sam_encoder.blocks.6.norm1.bias grad: -3.336822828714503e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.882151082099881e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.212733536704036e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.735430252367223e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.797897190655931e-07
sam_encoder.blocks.6.norm2.weight grad: -1.5999612514860928e-06
sam_encoder.blocks.6.norm2.bias grad: 1.6979545307549415e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.7465961213456467e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.940594074767432e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.5365195597260026e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.14090057588146e-08
sam_encoder.blocks.7.norm1.weight grad: -1.9939666344725993e-06
sam_encoder.blocks.7.norm1.bias grad: 1.8066975826513954e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.288827206735732e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.542176945207757e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.5984498986654216e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.4280944924394134e-06
sam_encoder.blocks.7.norm2.weight grad: -7.075723260641098e-06
sam_encoder.blocks.7.norm2.bias grad: -5.18464275955921e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.910254458285635e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.421298515604576e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.9514363884809427e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.2669634581216087e-07
sam_encoder.blocks.8.norm1.weight grad: 1.3798307918477803e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0516608739408184e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.591444626887096e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.8075970110185153e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.563326006566058e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.0638442492781905e-06
sam_encoder.blocks.8.norm2.weight grad: -5.256146323517896e-06
sam_encoder.blocks.8.norm2.bias grad: 1.3355065675568767e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.4511959863011725e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.1284279177489225e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.3208926904771943e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.306966042757267e-07
sam_encoder.blocks.9.norm1.weight grad: 2.426968194413348e-06
sam_encoder.blocks.9.norm1.bias grad: -7.023489843049902e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.1074165488244034e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.780520844680723e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.3089842809677066e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.835973979628761e-07
sam_encoder.blocks.9.norm2.weight grad: -1.4340530469780788e-06
sam_encoder.blocks.9.norm2.bias grad: 1.1255573184598688e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.40253552874492e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.8393665186522412e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.2605495903226256e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.859129265038064e-07
sam_encoder.blocks.10.norm1.weight grad: -3.8336071384037496e-07
sam_encoder.blocks.10.norm1.bias grad: 4.212741657738661e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.877013687590079e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.040132701746188e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1090606903962907e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.020946893338987e-07
sam_encoder.blocks.10.norm2.weight grad: -5.0539124458737206e-06
sam_encoder.blocks.10.norm2.bias grad: -1.1383003766241018e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.5753647605597507e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.6879388340385049e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.899718592492718e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.2843851133511635e-07
sam_encoder.blocks.11.norm1.weight grad: -1.1322295904392377e-05
sam_encoder.blocks.11.norm1.bias grad: 6.092263333812298e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.681416041625198e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.388868314388674e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.082028226548573e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.6566154903994175e-07
sam_encoder.blocks.11.norm2.weight grad: 5.518066927834298e-07
sam_encoder.blocks.11.norm2.bias grad: 2.1992352685629157e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.5077946500241524e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.1129151289424044e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.443527121926309e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.916659683360194e-08
sam_encoder.neck.conv1.trainable_scale grad: 8.155411705956794e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.890570719202515e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.5154309949139133e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.7695807400741614e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 4.642440762836486e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -5.063357093604282e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005340665578842163
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001998348452616483
mask_decoder.transformer.layers.0.norm3.weight grad: 7.78665198595263e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.8486032786313444e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.693210838828236e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0349587682867423e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -4.975215415470302e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.568821623252006e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -1.574127236381173e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0001109714139602147
mask_decoder.transformer.layers.1.norm3.weight grad: -4.317010461818427e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.9738799639744684e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.437399896531133e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 9.572581620886922e-05
mask_decoder.transformer.norm_final_attn.weight grad: -2.9228917810542043e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.648449142521713e-05
Text_Embedding_Affine.0.weight grad: -1.2809186003548412e-11
Text_Embedding_Affine.0.bias grad: -5.723760354570118e-10
Text_Embedding_Affine.2.weight grad: 9.130552217073706e-12
Text_Embedding_Affine.2.bias grad: -1.575406531628687e-05
Epoch 31 finished with average loss: -59.1929
Epoch 32/39
----------
Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s, loss=-66.2]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-66.2]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-62.7]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-62.7]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-60.4]Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-60.4]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.899690462384365e-12
Max value: 0.9990142583847046
Mean value: 0.09991656988859177

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.899690462384365e-12
Max value: 0.9990142583847046
Mean value: 0.09991656988859177

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0988311767578125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.649889945983887
Max value: -1.1920928244535389e-07
Mean value: -0.12469522655010223

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09114742279052734

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0988311767578125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.84574508666992
Max value: 90.8823013305664
Mean value: 66.21798706054688

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.899690462384365e-12
Max value: 0.9990142583847046
Mean value: 0.09991656988859177

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.899690462384365e-12
Max value: 0.9990142583847046
Mean value: 0.09991656988859177

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.899690462384365e-12
Max value: 0.9990142583847046
Mean value: 0.09991656988859177

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.649889945983887
Max value: -1.1920928244535389e-07
Mean value: -0.12469522655010223

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.84574508666992
Max value: 90.8823013305664
Mean value: 66.21798706054688

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.21929168701172
Max value: -66.21929168701172
Mean value: -66.21929168701172
sam_encoder.pos_embed grad: 1.3084198169366346e-09
sam_encoder.blocks.0.norm1.weight grad: 2.228638913948089e-05
sam_encoder.blocks.0.norm1.bias grad: -1.2585891454364173e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.7671758289216086e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.642718127139233e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.594898541654402e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.3353187000575417e-07
sam_encoder.blocks.0.norm2.weight grad: 4.645460649044253e-06
sam_encoder.blocks.0.norm2.bias grad: -1.803184386517387e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.163959708123002e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.149306510546012e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4900894711900037e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.197573151846882e-06
sam_encoder.blocks.1.norm1.weight grad: 6.850206318631535e-06
sam_encoder.blocks.1.norm1.bias grad: 1.2853207408625167e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.056946742522996e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.2008402993378695e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.931360076123383e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.646592404038529e-06
sam_encoder.blocks.1.norm2.weight grad: -8.431396054220386e-06
sam_encoder.blocks.1.norm2.bias grad: -1.8850046217266936e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.287568794505205e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.1954909950873116e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.391462648025481e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.961260060554196e-07
sam_encoder.blocks.2.norm1.weight grad: -1.5111631000763737e-05
sam_encoder.blocks.2.norm1.bias grad: 4.323408575146459e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0182974619965535e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.9050361263216473e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.594948677549837e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.6918618257477647e-06
sam_encoder.blocks.2.norm2.weight grad: -2.679433634966699e-07
sam_encoder.blocks.2.norm2.bias grad: -5.127460553921992e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.4965121408749837e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.810455713297415e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.238116162014194e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.211395202626591e-07
sam_encoder.blocks.3.norm1.weight grad: -1.2042858088534558e-06
sam_encoder.blocks.3.norm1.bias grad: 4.962548246112419e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.4926545190974139e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.9635043574671727e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.5758455447212327e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.0179849090927746e-06
sam_encoder.blocks.3.norm2.weight grad: -4.164915935689351e-06
sam_encoder.blocks.3.norm2.bias grad: -1.2601043408722035e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.5321921788854524e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.6169985883607296e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.486622401600471e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0423373169032857e-06
sam_encoder.blocks.4.norm1.weight grad: -3.483555474304012e-06
sam_encoder.blocks.4.norm1.bias grad: -4.070514478371479e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.6520784760796232e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5136547517613508e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.945903815998463e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.4826072149153333e-06
sam_encoder.blocks.4.norm2.weight grad: 1.1436495697125793e-05
sam_encoder.blocks.4.norm2.bias grad: 1.2584178875840735e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.92664673604304e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.097812739521032e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.6581786610458948e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.0078586494018964e-07
sam_encoder.blocks.5.norm1.weight grad: 1.3945743830845458e-06
sam_encoder.blocks.5.norm1.bias grad: 2.325473587916349e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.423141606617719e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.6405881473910995e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7287014770772657e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2124964996473864e-06
sam_encoder.blocks.5.norm2.weight grad: 6.0108191064500716e-06
sam_encoder.blocks.5.norm2.bias grad: 7.233811629703268e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.447346751452642e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.327305612785494e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.737991841670009e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.750801056412456e-07
sam_encoder.blocks.6.norm1.weight grad: 2.244664756290149e-06
sam_encoder.blocks.6.norm1.bias grad: -1.6480225895065814e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.70041334463167e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.3094069092621794e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.942894970052294e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.499557230199571e-07
sam_encoder.blocks.6.norm2.weight grad: 5.048951152275549e-06
sam_encoder.blocks.6.norm2.bias grad: 3.0592691473430023e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.429376536383643e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0888549013543525e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.826668143527058e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.6379583200887282e-07
sam_encoder.blocks.7.norm1.weight grad: -2.4672610834386433e-06
sam_encoder.blocks.7.norm1.bias grad: -9.056195438006398e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.661163519718684e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -9.924997357302345e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.000490783553687e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.927261063718106e-08
sam_encoder.blocks.7.norm2.weight grad: -6.214257837200421e-07
sam_encoder.blocks.7.norm2.bias grad: -1.0451368552821805e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.8531197838456137e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.392097245428886e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.5905288819340058e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.678524187009316e-07
sam_encoder.blocks.8.norm1.weight grad: -3.8094453884696122e-06
sam_encoder.blocks.8.norm1.bias grad: 1.1372371773177292e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.5082321169757051e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.358514236306291e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.3568586584588047e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.7935120695256046e-06
sam_encoder.blocks.8.norm2.weight grad: 1.8551199900684878e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5221582998492522e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.4095698475102836e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.250913659438083e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0377766557212453e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.7122642854446894e-07
sam_encoder.blocks.9.norm1.weight grad: -1.8566365156402753e-07
sam_encoder.blocks.9.norm1.bias grad: 1.6582902162554092e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.0257506839225243e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.8058641393945436e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0198635891356389e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.5894795524218353e-07
sam_encoder.blocks.9.norm2.weight grad: -5.318221951711166e-07
sam_encoder.blocks.9.norm2.bias grad: 1.2337209227553103e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.5802256712049711e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.876931936654728e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.570921987578913e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.6638623985018057e-07
sam_encoder.blocks.10.norm1.weight grad: -3.2520201784791425e-06
sam_encoder.blocks.10.norm1.bias grad: 2.1301957531250082e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.1279947759467177e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.275904631067533e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.182346295536263e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.682180130861525e-07
sam_encoder.blocks.10.norm2.weight grad: -2.0156016944383737e-06
sam_encoder.blocks.10.norm2.bias grad: 6.119380486779846e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.6698820672900183e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.2955451893503778e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.229369660104567e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.478058434007835e-07
sam_encoder.blocks.11.norm1.weight grad: -1.996171340579167e-05
sam_encoder.blocks.11.norm1.bias grad: 5.24224901710113e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.2495054256287403e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -9.85521523944044e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.227494405815378e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.79856179633498e-07
sam_encoder.blocks.11.norm2.weight grad: -1.9899828203051584e-06
sam_encoder.blocks.11.norm2.bias grad: 9.014217425828974e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.75159846094175e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.2234174796030857e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.218843668330919e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.990426809101336e-08
sam_encoder.neck.conv1.trainable_scale grad: 4.419071046868339e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.884179982880596e-05
sam_encoder.neck.conv2.trainable_scale grad: 9.720661182655022e-07
sam_encoder.neck.conv2.trainable_shift grad: -5.11492726218421e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -4.9177078835782595e-06
mask_decoder.transformer.layers.0.norm1.bias grad: -6.269401637837291e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005619311239570379
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003607840626500547
mask_decoder.transformer.layers.0.norm3.weight grad: -1.907922705868259e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.3396231224760413e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012749937013722956
mask_decoder.transformer.layers.0.norm4.bias grad: 1.3751835467701312e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.1046638468978927e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.46222953137476e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 1.753292053763289e-06
mask_decoder.transformer.layers.1.norm2.bias grad: -5.982677248539403e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.669906724710017e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.2012285373639315e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.018599843722768e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001759387960191816
mask_decoder.transformer.norm_final_attn.weight grad: -1.1132029840155155e-06
mask_decoder.transformer.norm_final_attn.bias grad: -7.778044164297171e-06
Text_Embedding_Affine.0.weight grad: -1.5491449269211532e-12
Text_Embedding_Affine.0.bias grad: -5.786622570003175e-11
Text_Embedding_Affine.2.weight grad: -6.613928155152493e-12
Text_Embedding_Affine.2.bias grad: -8.664153938298114e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.4277730867328096e-11
Max value: 0.9991052746772766
Mean value: 0.07433480024337769

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4277730867328096e-11
Max value: 0.9991052746772766
Mean value: 0.07433480024337769

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06883096694946289

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10282423347234726

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06542396545410156

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06883096694946289

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 34.85176467895508
Max value: 74.26355743408203
Mean value: 59.160003662109375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.421663911067462e-11
Max value: 0.9990513920783997
Mean value: 0.07364542782306671

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.421663911067462e-11
Max value: 0.9990513920783997
Mean value: 0.07364542782306671

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.421663911067462e-11
Max value: 0.9990513920783997
Mean value: 0.07364542782306671

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10271520167589188

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6788339614868164
Max value: 1.3367524147033691
Mean value: 1.00014328956604

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 34.85176467895508
Max value: 74.26355743408203
Mean value: 59.160003662109375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.1682014465332
Max value: -59.1682014465332
Mean value: -59.1682014465332
sam_encoder.pos_embed grad: -1.7854973055619894e-09
sam_encoder.blocks.0.norm1.weight grad: -1.583716039021965e-05
sam_encoder.blocks.0.norm1.bias grad: -2.970798777823802e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.3027678278376698e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.954525216291586e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.527168130152859e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.0588227016560268e-06
sam_encoder.blocks.0.norm2.weight grad: 1.5379629985545762e-05
sam_encoder.blocks.0.norm2.bias grad: 4.032082415506011e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.510341568675358e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.7436650523450226e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2351650184427854e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.227916183983325e-06
sam_encoder.blocks.1.norm1.weight grad: -3.325896614114754e-06
sam_encoder.blocks.1.norm1.bias grad: -1.55200291374058e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.6860512914718129e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.7454387208081243e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 6.045418103894917e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.6855419693893055e-07
sam_encoder.blocks.1.norm2.weight grad: -2.150855834770482e-06
sam_encoder.blocks.1.norm2.bias grad: 3.4629781566763995e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.263122499040037e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.345059838011366e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.476748927118024e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.052325726253912e-06
sam_encoder.blocks.2.norm1.weight grad: -7.74329873820534e-06
sam_encoder.blocks.2.norm1.bias grad: -4.026051556138555e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.397229870141018e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7587087768333731e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2051083331243717e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.334340140601853e-06
sam_encoder.blocks.2.norm2.weight grad: 1.1582598745008e-05
sam_encoder.blocks.2.norm2.bias grad: 1.5347293356171576e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.32253420210327e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.446086227791966e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.3477032325681648e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.385288101118931e-06
sam_encoder.blocks.3.norm1.weight grad: -8.175933317033923e-07
sam_encoder.blocks.3.norm1.bias grad: 1.255811184819322e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.3500306269852445e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.4386577618097363e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.779648179464857e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.402858171990374e-06
sam_encoder.blocks.3.norm2.weight grad: -1.271700966753997e-06
sam_encoder.blocks.3.norm2.bias grad: -3.9690239646006376e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.141299541515764e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7874040167953353e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.7486840420133376e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5814862308616284e-07
sam_encoder.blocks.4.norm1.weight grad: 3.376433369339793e-06
sam_encoder.blocks.4.norm1.bias grad: -1.243432734554517e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 8.844131116347853e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4227780411601998e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.5879044212852023e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.4725583241670392e-06
sam_encoder.blocks.4.norm2.weight grad: 6.8558856582967564e-06
sam_encoder.blocks.4.norm2.bias grad: 6.806914370827144e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.842963906208752e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 7.175843848017394e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.043594006157946e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.3374481113714864e-06
sam_encoder.blocks.5.norm1.weight grad: 1.0677875252440572e-05
sam_encoder.blocks.5.norm1.bias grad: -8.803253876976669e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.1090311090811156e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.356457222660538e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.1574122709134826e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.043050800348283e-07
sam_encoder.blocks.5.norm2.weight grad: 1.1880939382535871e-05
sam_encoder.blocks.5.norm2.bias grad: 2.789893869703519e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.574267566364142e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.235594254467287e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.9930689632019494e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.079824738160823e-07
sam_encoder.blocks.6.norm1.weight grad: 4.46626654593274e-06
sam_encoder.blocks.6.norm1.bias grad: -2.4859689347067615e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.500428076426033e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.9775386590481503e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.0006318689192994e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0512540029594675e-06
sam_encoder.blocks.6.norm2.weight grad: 5.037488335801754e-06
sam_encoder.blocks.6.norm2.bias grad: 1.760154873409192e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.309434421476908e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.3822655091644265e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.7959267779588117e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.0079569057761546e-08
sam_encoder.blocks.7.norm1.weight grad: -1.0268602181895403e-06
sam_encoder.blocks.7.norm1.bias grad: 6.082580057409359e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.675629376535653e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.678315915247367e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.69672340084071e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.617881591504556e-07
sam_encoder.blocks.7.norm2.weight grad: -1.7774398202163866e-06
sam_encoder.blocks.7.norm2.bias grad: -1.5284358596545644e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.0071229300810955e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.0862390809052158e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.0045711102720816e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.943213636783184e-07
sam_encoder.blocks.8.norm1.weight grad: -4.345933120930567e-06
sam_encoder.blocks.8.norm1.bias grad: 8.602690968473325e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.2103295123088174e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.726028279833372e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.9696402634726837e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.8554513872004463e-06
sam_encoder.blocks.8.norm2.weight grad: 2.970471541630104e-06
sam_encoder.blocks.8.norm2.bias grad: 2.155990387109341e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.064918251358904e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.510392260381195e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.4730146819251786e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.698991571989609e-07
sam_encoder.blocks.9.norm1.weight grad: 2.227553522970993e-06
sam_encoder.blocks.9.norm1.bias grad: 1.9789851535279013e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.0164304740101215e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.0059948130656267e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.2575503066946112e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.696628591067565e-07
sam_encoder.blocks.9.norm2.weight grad: -2.1557040952302486e-07
sam_encoder.blocks.9.norm2.bias grad: 1.7202273738803342e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.3479364042723319e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.783484647916339e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.825334940505854e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.326655809767544e-07
sam_encoder.blocks.10.norm1.weight grad: -4.279035010767984e-07
sam_encoder.blocks.10.norm1.bias grad: 1.1173909797435044e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.3205235518398695e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.078253136365674e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.678073643546668e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.1672041700403497e-07
sam_encoder.blocks.10.norm2.weight grad: 1.4854407481834642e-06
sam_encoder.blocks.10.norm2.bias grad: 1.1883083743668976e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.090130119038804e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.216811788637642e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.2182441600525635e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.674755018641008e-07
sam_encoder.blocks.11.norm1.weight grad: -1.7837895939010195e-05
sam_encoder.blocks.11.norm1.bias grad: 1.4979318621044513e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.4608416449846118e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.085089575615712e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.5028493862700998e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.119468144381244e-07
sam_encoder.blocks.11.norm2.weight grad: 2.4888618099794257e-06
sam_encoder.blocks.11.norm2.bias grad: 2.8378494789649267e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.2405262118118117e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.8655855405522743e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.288368676772734e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.310060611103836e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.3018252502661198e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.8603368264157325e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8057462511933409e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.211208190303296e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 5.2959607273805887e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.340147719020024e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004836864769458771
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00012127455556765199
mask_decoder.transformer.layers.0.norm3.weight grad: -2.1188217942835763e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.776390364393592e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -9.682749805506319e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.2230332079925574e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -4.794463166035712e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.5605186237953603e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.909395208116621e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00010695836681406945
mask_decoder.transformer.layers.1.norm3.weight grad: -8.587536285631359e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.104801286710426e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.5824814909137785e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001760129234753549
mask_decoder.transformer.norm_final_attn.weight grad: -2.12918871511647e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3444503565551713e-05
Text_Embedding_Affine.0.weight grad: -3.35673806459158e-12
Text_Embedding_Affine.0.bias grad: -6.144441067057471e-10
Text_Embedding_Affine.2.weight grad: 5.197413679991492e-13
Text_Embedding_Affine.2.bias grad: -1.1168358469149098e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.7866906698870153e-11
Max value: 0.9981207251548767
Mean value: 0.08393131196498871

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.7866906698870153e-11
Max value: 0.9981207251548767
Mean value: 0.08393131196498871

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08343982696533203

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.866868019104004
Max value: -1.1920928244535389e-07
Mean value: -0.12318505346775055

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07210445404052734

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08343982696533203

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 50.131446838378906
Max value: 64.34468078613281
Mean value: 55.791168212890625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.2102702520722097e-11
Max value: 0.9986530542373657
Mean value: 0.0834553986787796

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.2102702520722097e-11
Max value: 0.9986530542373657
Mean value: 0.0834553986787796

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.2102702520722097e-11
Max value: 0.9986530542373657
Mean value: 0.0834553986787796

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.339069366455078
Max value: -1.1920928244535389e-07
Mean value: -0.1237323135137558

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5303088426589966
Max value: 1.3414521217346191
Mean value: 0.9995919466018677

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 50.131446838378906
Max value: 64.34468078613281
Mean value: 55.791168212890625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.764896392822266
Max value: -55.764896392822266
Mean value: -55.764896392822266
sam_encoder.pos_embed grad: 8.344137825133657e-09
sam_encoder.blocks.0.norm1.weight grad: 8.24376693344675e-05
sam_encoder.blocks.0.norm1.bias grad: 2.5367267880938016e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.657285328197759e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.3986872318128007e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.884549980488373e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.2804717875478673e-07
sam_encoder.blocks.0.norm2.weight grad: -2.5713539798744023e-05
sam_encoder.blocks.0.norm2.bias grad: -2.5298289983766153e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.4678351451257186e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.523256848187884e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.159343810286373e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.897699571098201e-06
sam_encoder.blocks.1.norm1.weight grad: 5.088561010779813e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3220786058809608e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.1062536436365917e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.1361024664656725e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.5570284378773067e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.32560478252708e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0189002750848886e-05
sam_encoder.blocks.1.norm2.bias grad: -2.2622507458436303e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.0847534112108406e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.196852263608889e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0572992323432118e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.709781711018877e-06
sam_encoder.blocks.2.norm1.weight grad: -5.699120720237261e-06
sam_encoder.blocks.2.norm1.bias grad: 7.0452770160045475e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.839818863430992e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.963379418157274e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.2546292914048536e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.9195057322795037e-06
sam_encoder.blocks.2.norm2.weight grad: -1.3353203939914238e-05
sam_encoder.blocks.2.norm2.bias grad: -1.114452606998384e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -8.273656931123696e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.7328563899354776e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.525301720714197e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.7050054995925166e-06
sam_encoder.blocks.3.norm1.weight grad: 2.304494728377904e-06
sam_encoder.blocks.3.norm1.bias grad: 7.198535513452953e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.485375600575935e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2221483984831139e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.362500021670712e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.045618313990417e-06
sam_encoder.blocks.3.norm2.weight grad: -1.3999371731188148e-05
sam_encoder.blocks.3.norm2.bias grad: -9.672790838521905e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1692794032569509e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.500349293972249e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.4302921701746527e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.220605895468907e-06
sam_encoder.blocks.4.norm1.weight grad: -8.477278242935427e-06
sam_encoder.blocks.4.norm1.bias grad: 5.557002623390872e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.5510166677995585e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.1078639040060807e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.1704256596422056e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.6217558115604334e-06
sam_encoder.blocks.4.norm2.weight grad: -9.257615602109581e-06
sam_encoder.blocks.4.norm2.bias grad: 7.93259732745355e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.481449650484137e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.044410104597773e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.4772908697486855e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.8592659216665197e-06
sam_encoder.blocks.5.norm1.weight grad: 2.3842317204980645e-06
sam_encoder.blocks.5.norm1.bias grad: -2.413236416032305e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.4510408113419544e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.270289402555136e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.799208224743779e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.184348886657972e-06
sam_encoder.blocks.5.norm2.weight grad: -4.027744125778554e-06
sam_encoder.blocks.5.norm2.bias grad: 2.49864160650759e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.3632538816164015e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.0997886192853912e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.412913186679361e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.3481937344295147e-07
sam_encoder.blocks.6.norm1.weight grad: -7.393632586172316e-07
sam_encoder.blocks.6.norm1.bias grad: -4.368481313576922e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.3281889955105726e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.516454055192298e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.277610964389169e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.3117490880176774e-06
sam_encoder.blocks.6.norm2.weight grad: 4.427143721841276e-06
sam_encoder.blocks.6.norm2.bias grad: 5.100744601804763e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.2555941541213542e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.5836897066255915e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.227500423643505e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.468253559432924e-07
sam_encoder.blocks.7.norm1.weight grad: -5.904622867092257e-06
sam_encoder.blocks.7.norm1.bias grad: -2.960217102554452e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.076886282040505e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.7844125750343665e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.880986241711071e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.6877215734421043e-06
sam_encoder.blocks.7.norm2.weight grad: -2.352863020860241e-06
sam_encoder.blocks.7.norm2.bias grad: 6.829636731708888e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0728356301115127e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.3157099374438985e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.77957280256669e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.687568377903517e-07
sam_encoder.blocks.8.norm1.weight grad: 1.098616621675319e-06
sam_encoder.blocks.8.norm1.bias grad: 1.4850968454993563e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.77041145486146e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.626784619991668e-09
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.248268512834329e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.4353788578300737e-06
sam_encoder.blocks.8.norm2.weight grad: -6.7213150032330304e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0086279189636116e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.90684282744769e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.216213255858747e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.056057721551042e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.742545449218596e-07
sam_encoder.blocks.9.norm1.weight grad: -3.6620449463953264e-06
sam_encoder.blocks.9.norm1.bias grad: -7.64077526582696e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.3542238523077685e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.7797317468648544e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.12388443085365e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.54978373151971e-07
sam_encoder.blocks.9.norm2.weight grad: -4.358960723038763e-06
sam_encoder.blocks.9.norm2.bias grad: 5.983274036225339e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.866341103275772e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.166473223041976e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.444304633783759e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.338364512548651e-07
sam_encoder.blocks.10.norm1.weight grad: -5.762477940152166e-06
sam_encoder.blocks.10.norm1.bias grad: 1.3893952655053e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.540750069281785e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.8542841644375585e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3937495850768755e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.918405001168139e-07
sam_encoder.blocks.10.norm2.weight grad: -1.046738907461986e-05
sam_encoder.blocks.10.norm2.bias grad: -1.941431719387765e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.475376721937209e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.1315510113927303e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.142021564097377e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.3615060190375061e-08
sam_encoder.blocks.11.norm1.weight grad: -2.0028737708344124e-05
sam_encoder.blocks.11.norm1.bias grad: 2.4552371087338543e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.94179585580423e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.594853694721678e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.053167910773482e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.0543162665708223e-07
sam_encoder.blocks.11.norm2.weight grad: -5.348733793653082e-06
sam_encoder.blocks.11.norm2.bias grad: 1.5051857360504073e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.173998943064362e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4070832321522175e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.244198074346059e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.23097758231961e-08
sam_encoder.neck.conv1.trainable_scale grad: 7.325679689529352e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.833515049540438e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.0528642633289564e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.7381820725859143e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -9.778035018825904e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.936274202307686e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005321160424500704
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003659530484583229
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00013395922724157572
mask_decoder.transformer.layers.0.norm3.bias grad: -1.625345612410456e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.881603283341974e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.022414476727135e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.6879768736544065e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.1316086531442124e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.8509450455894694e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -7.5180687417741865e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -1.8230466594104655e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.498217094806023e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -3.0312890885397792e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 7.607832958456129e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.292107183166081e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.44002716903924e-06
Text_Embedding_Affine.0.weight grad: 1.508472166622532e-12
Text_Embedding_Affine.0.bias grad: 1.546375250072174e-10
Text_Embedding_Affine.2.weight grad: 2.325925910207083e-13
Text_Embedding_Affine.2.bias grad: 6.564936484210193e-06
Epoch 32 finished with average loss: -60.3841
Epoch 33/39
----------
Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.1]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.00it/s, loss=-64.1]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.00it/s, loss=-61.6]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-61.6]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-59.5]Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-59.5]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1500719437386193e-14
Max value: 0.9988530874252319
Mean value: 0.08743084967136383

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1500719437386193e-14
Max value: 0.9988530874252319
Mean value: 0.08743084967136383

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08823394775390625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12159377336502075

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07931661605834961

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08823394775390625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.60968017578125
Max value: 85.17091369628906
Mean value: 64.11866760253906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1500719437386193e-14
Max value: 0.9988530874252319
Mean value: 0.08743084967136383

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1500719437386193e-14
Max value: 0.9988530874252319
Mean value: 0.08743084967136383

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1500719437386193e-14
Max value: 0.9988530874252319
Mean value: 0.08743084967136383

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12159377336502075

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.60968017578125
Max value: 85.17091369628906
Mean value: 64.11866760253906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.11983489990234
Max value: -64.11983489990234
Mean value: -64.11983489990234
sam_encoder.pos_embed grad: 2.235317708709772e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00011931778135476634
sam_encoder.blocks.0.norm1.bias grad: 6.880969158373773e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.139355208579218e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.374942919748719e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.4755146771203727e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.853932983271079e-06
sam_encoder.blocks.0.norm2.weight grad: -3.8998980016913265e-05
sam_encoder.blocks.0.norm2.bias grad: -0.00014314275176730007
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.6763583668507636e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.285872925422154e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2057809726684354e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.4044692306924844e-06
sam_encoder.blocks.1.norm1.weight grad: -1.853515414040885e-06
sam_encoder.blocks.1.norm1.bias grad: 3.0485098250210285e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.235380275640637e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.884763373207534e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.633924491936341e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.691689693776425e-06
sam_encoder.blocks.1.norm2.weight grad: -1.5512111986026866e-06
sam_encoder.blocks.1.norm2.bias grad: 3.788543381233467e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.124149176552237e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.194629117497243e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.2902646378497593e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.2118423405336216e-06
sam_encoder.blocks.2.norm1.weight grad: -6.765439138689544e-06
sam_encoder.blocks.2.norm1.bias grad: -4.172126409685006e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.7728071876917966e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.995613711704209e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.6420810879935743e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.161170158387904e-07
sam_encoder.blocks.2.norm2.weight grad: -4.926684482597921e-07
sam_encoder.blocks.2.norm2.bias grad: -1.25144460980664e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.520511316106422e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.5639789125998504e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.08220910988166e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7712188764562597e-06
sam_encoder.blocks.3.norm1.weight grad: 5.2919886002200656e-06
sam_encoder.blocks.3.norm1.bias grad: 8.414050171268173e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0875337466131896e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.1248068808054086e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.399752576020546e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.391538823256269e-06
sam_encoder.blocks.3.norm2.weight grad: -2.0801577193196863e-05
sam_encoder.blocks.3.norm2.bias grad: -1.4844801626168191e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0760722943814471e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.0900758954667253e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.976829470455414e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.410352863080334e-06
sam_encoder.blocks.4.norm1.weight grad: -1.6317699191858992e-05
sam_encoder.blocks.4.norm1.bias grad: 1.8429421970722615e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.199086212494876e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.039745140791638e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.4714430512394756e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.237042164982995e-06
sam_encoder.blocks.4.norm2.weight grad: -2.1343355911085382e-05
sam_encoder.blocks.4.norm2.bias grad: -5.2163004511385225e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.080550287559163e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.5627210814272985e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.795267043140484e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.674990244282526e-06
sam_encoder.blocks.5.norm1.weight grad: -2.328914706595242e-05
sam_encoder.blocks.5.norm1.bias grad: 6.750537977495696e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3529797545052134e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.0746141924755648e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.509008593027829e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.970386726199649e-06
sam_encoder.blocks.5.norm2.weight grad: -2.1610050680465065e-05
sam_encoder.blocks.5.norm2.bias grad: -1.890903149615042e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0967234629788436e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.2367013318435056e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -7.522271516791079e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.38835593033582e-07
sam_encoder.blocks.6.norm1.weight grad: -7.680624548811466e-06
sam_encoder.blocks.6.norm1.bias grad: -2.4795513127173763e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.002335456083529e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.0539687284326646e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.0833272174058948e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.3525612959929276e-06
sam_encoder.blocks.6.norm2.weight grad: -3.837863005173858e-06
sam_encoder.blocks.6.norm2.bias grad: -9.253066082237638e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.497395588667132e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.2810913833382074e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.039747753064148e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.413500451188156e-07
sam_encoder.blocks.7.norm1.weight grad: 9.608467735233717e-06
sam_encoder.blocks.7.norm1.bias grad: -8.412816896452568e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.540774054679787e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.186993469877052e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.6809951830509817e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.428145067933656e-07
sam_encoder.blocks.7.norm2.weight grad: 2.6171528588747606e-07
sam_encoder.blocks.7.norm2.bias grad: 2.848986241588136e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.921756160707446e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.608928171976004e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.3922723357827635e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2423986390786013e-06
sam_encoder.blocks.8.norm1.weight grad: 1.0561087947280612e-05
sam_encoder.blocks.8.norm1.bias grad: -2.186828169215005e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.813666575704701e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.5188870747806504e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.872260438380181e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.1947890925512183e-06
sam_encoder.blocks.8.norm2.weight grad: -4.907226866635028e-06
sam_encoder.blocks.8.norm2.bias grad: -1.673315068728698e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.33791114523774e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.81552308681421e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.5357839907374e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.5024527278437745e-07
sam_encoder.blocks.9.norm1.weight grad: -5.58764611469087e-07
sam_encoder.blocks.9.norm1.bias grad: -8.023811801649572e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.414422712286978e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.578668146379641e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.4102899348908977e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.0894034946650208e-07
sam_encoder.blocks.9.norm2.weight grad: -2.503959194655181e-06
sam_encoder.blocks.9.norm2.bias grad: -1.0154063829759252e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.1272569483699044e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.49656921166752e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.330795550482435e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.25035523548911e-09
sam_encoder.blocks.10.norm1.weight grad: 2.6069751584145706e-06
sam_encoder.blocks.10.norm1.bias grad: 6.326929451461183e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.314133654290345e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.0740771705950465e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.0147156116509e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.3086913668303168e-06
sam_encoder.blocks.10.norm2.weight grad: -8.717987839190755e-06
sam_encoder.blocks.10.norm2.bias grad: -2.6367501959612127e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.7980566958140116e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.9417569749057293e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.317890945846557e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.8488275322379195e-07
sam_encoder.blocks.11.norm1.weight grad: -6.351612228172598e-06
sam_encoder.blocks.11.norm1.bias grad: 2.456497441016836e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.499474925978575e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1351487501087831e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.0443103519719443e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.651142487295147e-07
sam_encoder.blocks.11.norm2.weight grad: -1.2701987088803435e-06
sam_encoder.blocks.11.norm2.bias grad: -1.8985596170750796e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.397278760530753e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3888978855902678e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.871676643844694e-09
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.9616712165770878e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.867197276325896e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.2476571757579222e-05
sam_encoder.neck.conv2.trainable_scale grad: 6.762129487469792e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.3034970834269188e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00023653316020499915
mask_decoder.transformer.layers.0.norm1.bias grad: 5.887493898626417e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0010096237529069185
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0012111988617107272
mask_decoder.transformer.layers.0.norm3.weight grad: 7.93007857282646e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.1540261008776724e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 1.2080206943210214e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.92225285092718e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.147321593947709e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.294639100204222e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00033513735979795456
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00021366163855418563
mask_decoder.transformer.layers.1.norm3.weight grad: 0.00011024434206774458
mask_decoder.transformer.layers.1.norm3.bias grad: 8.639823499834165e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.436308078467846e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -2.2237893062992953e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.0004631551273633e-07
mask_decoder.transformer.norm_final_attn.bias grad: 8.911412123779883e-07
Text_Embedding_Affine.0.weight grad: 1.0947840724251368e-11
Text_Embedding_Affine.0.bias grad: -8.244905869148056e-10
Text_Embedding_Affine.2.weight grad: 5.3407330641297435e-11
Text_Embedding_Affine.2.bias grad: -8.39668937260285e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.600236761677143e-12
Max value: 0.9988975524902344
Mean value: 0.08092010021209717

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.600236761677143e-12
Max value: 0.9988975524902344
Mean value: 0.08092010021209717

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08063316345214844

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11762524396181107

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0700526237487793

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08063316345214844

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.548423767089844
Max value: 79.85066986083984
Mean value: 59.09056091308594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.100675431874032e-12
Max value: 0.9989847540855408
Mean value: 0.07985332608222961

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.100675431874032e-12
Max value: 0.9989847540855408
Mean value: 0.07985332608222961

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.100675431874032e-12
Max value: 0.9989847540855408
Mean value: 0.07985332608222961

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11760328710079193

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7139776945114136
Max value: 1.069777488708496
Mean value: 1.000064730644226

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.548423767089844
Max value: 79.85066986083984
Mean value: 59.09056091308594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.09477615356445
Max value: -59.09477615356445
Mean value: -59.09477615356445
sam_encoder.pos_embed grad: -4.5081751665065894e-09
sam_encoder.blocks.0.norm1.weight grad: 6.791084888391197e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0361351996834856e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.5271001529981731e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.014823166973656e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.5120371244847775e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.5397775971214287e-06
sam_encoder.blocks.0.norm2.weight grad: 5.271376721793786e-05
sam_encoder.blocks.0.norm2.bias grad: 4.966984488419257e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.7457281501265243e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.150501460273517e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2024267562082969e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.1682430340442806e-05
sam_encoder.blocks.1.norm1.weight grad: 5.6498531193938106e-05
sam_encoder.blocks.1.norm1.bias grad: 4.994940172764473e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.4900501759693725e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0907488103839569e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.531040187634062e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.9737456113944063e-06
sam_encoder.blocks.1.norm2.weight grad: 1.3486576335708378e-06
sam_encoder.blocks.1.norm2.bias grad: -3.7554054870270193e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.47676949686138e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.888244913876406e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.911981578625273e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.8783330233418383e-06
sam_encoder.blocks.2.norm1.weight grad: -4.770926898345351e-05
sam_encoder.blocks.2.norm1.bias grad: 9.885937288345303e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.0223474823287688e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.076155947695952e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5162911950028501e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.09912398835877e-06
sam_encoder.blocks.2.norm2.weight grad: -4.122521204408258e-05
sam_encoder.blocks.2.norm2.bias grad: -9.315392048847571e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.6090430765179917e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.002618415048346e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.168379619950429e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.262485622850363e-06
sam_encoder.blocks.3.norm1.weight grad: -2.608407157822512e-05
sam_encoder.blocks.3.norm1.bias grad: 1.6237977433775086e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.89292789704632e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.490329375694273e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.485167897248175e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.917773028661031e-06
sam_encoder.blocks.3.norm2.weight grad: 2.1716721676057205e-05
sam_encoder.blocks.3.norm2.bias grad: 2.9596496460726485e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2341302863205783e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 7.409307727357373e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.228066351672169e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.649057594477199e-06
sam_encoder.blocks.4.norm1.weight grad: -4.04894399252953e-06
sam_encoder.blocks.4.norm1.bias grad: -2.9665807232959196e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.891874131222721e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.194697794446256e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.794522399402922e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.027351678814739e-06
sam_encoder.blocks.4.norm2.weight grad: 7.098760306689655e-06
sam_encoder.blocks.4.norm2.bias grad: 1.226239328389056e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.0035565739817685e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.330354163859738e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.723250069422647e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.2110289137344807e-06
sam_encoder.blocks.5.norm1.weight grad: 6.578306965820957e-06
sam_encoder.blocks.5.norm1.bias grad: -1.1895859643118456e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.510168112872634e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 8.636072379886173e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.267367945791193e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.847246254437778e-07
sam_encoder.blocks.5.norm2.weight grad: -1.177611920866184e-06
sam_encoder.blocks.5.norm2.bias grad: 1.2680206964432728e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.1947151809581555e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.685189883777639e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.901780871728988e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0100345662067411e-06
sam_encoder.blocks.6.norm1.weight grad: 1.3217819287092425e-05
sam_encoder.blocks.6.norm1.bias grad: -5.368284291762393e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2208111002109945e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.506679255835479e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.986272299196571e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.571699719235767e-06
sam_encoder.blocks.6.norm2.weight grad: 1.0956307960441336e-05
sam_encoder.blocks.6.norm2.bias grad: -1.3324863630259642e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.505168130388483e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.696047886274755e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.5890465167321963e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.8628756492944376e-07
sam_encoder.blocks.7.norm1.weight grad: -4.523614734353032e-06
sam_encoder.blocks.7.norm1.bias grad: 1.974866336240666e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.201868695323355e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.4694815787570406e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.90707669389667e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 9.121316679738811e-07
sam_encoder.blocks.7.norm2.weight grad: -1.3796828852719045e-06
sam_encoder.blocks.7.norm2.bias grad: -6.61660851619672e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.8804937553795753e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7670762417765218e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.994905910076341e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.875168310216395e-07
sam_encoder.blocks.8.norm1.weight grad: -3.624153066539293e-07
sam_encoder.blocks.8.norm1.bias grad: 1.2226312264829176e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.047228119612555e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.916848759719869e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.737150440334517e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.348474540918687e-07
sam_encoder.blocks.8.norm2.weight grad: 5.714747203455772e-06
sam_encoder.blocks.8.norm2.bias grad: 1.1927452305826591e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.205138106452068e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.7575043734250357e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.9919447658576246e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.697181677533081e-07
sam_encoder.blocks.9.norm1.weight grad: 4.519743924902286e-06
sam_encoder.blocks.9.norm1.bias grad: 3.0018268262210768e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.1742239368904848e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.576375436547096e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.5587269786010438e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.949497605683973e-08
sam_encoder.blocks.9.norm2.weight grad: 1.132659690483706e-06
sam_encoder.blocks.9.norm2.bias grad: 9.555196811561473e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.5275010052137077e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.7124164247993576e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8463427977621905e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.973048473606468e-07
sam_encoder.blocks.10.norm1.weight grad: 1.7081433725252282e-06
sam_encoder.blocks.10.norm1.bias grad: 1.615142764421762e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.207467322383309e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.8970424987592196e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.0079530688453815e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.2544214200715942e-07
sam_encoder.blocks.10.norm2.weight grad: 7.241851562866941e-06
sam_encoder.blocks.10.norm2.bias grad: -1.0999656296917237e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.7712816265411675e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.3102156799504883e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.261110456762253e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 9.327233669864654e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3788956493954174e-05
sam_encoder.blocks.11.norm1.bias grad: 1.1318282986394479e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.416196927399142e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.009155989275314e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.009882448168355e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.6373294329241617e-06
sam_encoder.blocks.11.norm2.weight grad: 4.054604687553365e-06
sam_encoder.blocks.11.norm2.bias grad: 1.6202151300603873e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.91741593577899e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.012774418995832e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.0210012482712045e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.720681989871082e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.3445987860905007e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.6433827113360167e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0192474039504305e-06
sam_encoder.neck.conv2.trainable_shift grad: 3.5367676900932565e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002490759361535311
mask_decoder.transformer.layers.0.norm1.bias grad: -6.441725417971611e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0016183367697522044
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0014287088997662067
mask_decoder.transformer.layers.0.norm3.weight grad: 0.000135596637846902
mask_decoder.transformer.layers.0.norm3.bias grad: 4.7442335926461965e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -4.7588342567905784e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.8443548469804227e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.7580628739087842e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.7238780856132507e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.541745875030756e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0001516562479082495
mask_decoder.transformer.layers.1.norm3.weight grad: -5.9432357375044376e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.365334825706668e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.097133958362974e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.358287019887939e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0539421055000275e-05
mask_decoder.transformer.norm_final_attn.bias grad: -1.1613307833613362e-05
Text_Embedding_Affine.0.weight grad: -3.497167139210333e-11
Text_Embedding_Affine.0.bias grad: -1.191388876442545e-09
Text_Embedding_Affine.2.weight grad: -8.27891227794808e-12
Text_Embedding_Affine.2.bias grad: 5.591609078692272e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.852892059898807e-10
Max value: 0.9982947707176208
Mean value: 0.08689092099666595

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.852892059898807e-10
Max value: 0.9982947707176208
Mean value: 0.08689092099666595

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0811452865600586

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.898591041564941
Max value: -1.1920928244535389e-07
Mean value: -0.11693806946277618

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07044124603271484

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0811452865600586

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 36.574554443359375
Max value: 77.38899993896484
Mean value: 55.326690673828125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.659830966589283e-10
Max value: 0.9987241625785828
Mean value: 0.08441554009914398

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.659830966589283e-10
Max value: 0.9987241625785828
Mean value: 0.08441554009914398

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.659830966589283e-10
Max value: 0.9987241625785828
Mean value: 0.08441554009914398

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.240533828735352
Max value: -1.1920928244535389e-07
Mean value: -0.11591652780771255

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6062397956848145
Max value: 1.1956512928009033
Mean value: 1.0011579990386963

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 36.574554443359375
Max value: 77.38899993896484
Mean value: 55.326690673828125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.36745071411133
Max value: -55.36745071411133
Mean value: -55.36745071411133
sam_encoder.pos_embed grad: -3.6141425407976158e-09
sam_encoder.blocks.0.norm1.weight grad: -6.811904313508421e-05
sam_encoder.blocks.0.norm1.bias grad: -3.46569977409672e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.591936653421726e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.856750474071305e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.4972855499072466e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.5671341720444616e-06
sam_encoder.blocks.0.norm2.weight grad: -2.9000437280046754e-05
sam_encoder.blocks.0.norm2.bias grad: -4.598378291120753e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.3325119653018191e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.40024735123734e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4887082215864211e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.486569428583607e-06
sam_encoder.blocks.1.norm1.weight grad: -1.5389177860924974e-05
sam_encoder.blocks.1.norm1.bias grad: 5.2227169362595305e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.390929684130242e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.0663691227819072e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.166827243854641e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2092926908735535e-06
sam_encoder.blocks.1.norm2.weight grad: 1.548415093566291e-05
sam_encoder.blocks.1.norm2.bias grad: -1.155749305326026e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.905870158225298e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.0636815507896245e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.73299302131636e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.357154234137852e-07
sam_encoder.blocks.2.norm1.weight grad: -4.194788198219612e-05
sam_encoder.blocks.2.norm1.bias grad: 1.818613054638263e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.469512401148677e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.408722012769431e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.828780093812384e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.993176844436675e-06
sam_encoder.blocks.2.norm2.weight grad: -3.3763780038498226e-07
sam_encoder.blocks.2.norm2.bias grad: 2.3278797016246244e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.848399832255382e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.457183316233568e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.036582716551493e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.3158462479623267e-06
sam_encoder.blocks.3.norm1.weight grad: -8.367339432879817e-06
sam_encoder.blocks.3.norm1.bias grad: 3.2281975563819287e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.005406935903011e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.2278200049186125e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.9407747206278145e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8552968867879827e-06
sam_encoder.blocks.3.norm2.weight grad: -9.060871889232658e-06
sam_encoder.blocks.3.norm2.bias grad: -3.31776891471236e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.005709226679755e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.9893926384593215e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.944738753285492e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.842126039264258e-06
sam_encoder.blocks.4.norm1.weight grad: -4.054282271681586e-06
sam_encoder.blocks.4.norm1.bias grad: 5.321711427086484e-08
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.5282864701002836e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.0704751477751415e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.3053075892676134e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.5901322260324378e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5079207262024283e-05
sam_encoder.blocks.4.norm2.bias grad: -8.357415936188772e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6693844372639433e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.465100796049228e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.700714609702118e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.2639667349722004e-06
sam_encoder.blocks.5.norm1.weight grad: -1.918530870170798e-05
sam_encoder.blocks.5.norm1.bias grad: 9.938434232026339e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.3695373127120547e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.022270331915934e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.1156470211280975e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.7719457900966518e-06
sam_encoder.blocks.5.norm2.weight grad: 8.338417501363438e-06
sam_encoder.blocks.5.norm2.bias grad: -1.399213942931965e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.634256017903681e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.5561294048893615e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.2319934436818585e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.284748330173898e-07
sam_encoder.blocks.6.norm1.weight grad: -9.449929052607331e-07
sam_encoder.blocks.6.norm1.bias grad: 3.9164224290288985e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.597662389940524e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4182332961354405e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.380198455080972e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.97993538476294e-07
sam_encoder.blocks.6.norm2.weight grad: 8.307206371682696e-06
sam_encoder.blocks.6.norm2.bias grad: 3.5384764487389475e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.707822427008068e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.635476451156137e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.6163571672223043e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.204180635904777e-07
sam_encoder.blocks.7.norm1.weight grad: -8.171107765519992e-06
sam_encoder.blocks.7.norm1.bias grad: 5.032137551097549e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.0805920182028785e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.9693609323876444e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.364450182312794e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.1230941911198897e-06
sam_encoder.blocks.7.norm2.weight grad: 1.1193578757229261e-05
sam_encoder.blocks.7.norm2.bias grad: -9.332537587170009e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.1782945875893347e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.213495230942499e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.8331597857468296e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.4195347830536775e-07
sam_encoder.blocks.8.norm1.weight grad: 9.284030966227874e-06
sam_encoder.blocks.8.norm1.bias grad: 3.4009349292318802e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2730207345157396e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.0424056351184845e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3337061091078795e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.487830897734966e-06
sam_encoder.blocks.8.norm2.weight grad: 2.7428686735220253e-06
sam_encoder.blocks.8.norm2.bias grad: 2.2607760001847055e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.1867415347951464e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.033019642221916e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.3302354179577378e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.1770517832919722e-07
sam_encoder.blocks.9.norm1.weight grad: 4.7610078013349266e-07
sam_encoder.blocks.9.norm1.bias grad: -1.7821018900576746e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.5934696193653508e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1520397720232722e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.5331588087974524e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.0972738639102317e-06
sam_encoder.blocks.9.norm2.weight grad: 3.9009537431411445e-06
sam_encoder.blocks.9.norm2.bias grad: 8.816783747533918e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.190135546698002e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.446332928229822e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6237208910752088e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.9560715713851096e-07
sam_encoder.blocks.10.norm1.weight grad: 1.0844586313396576e-06
sam_encoder.blocks.10.norm1.bias grad: -7.086802611411258e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0422977538837586e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.416045840116567e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.001616839057533e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.516362312439014e-08
sam_encoder.blocks.10.norm2.weight grad: -3.7284808058757335e-06
sam_encoder.blocks.10.norm2.bias grad: -5.425904873845866e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.8698875667032553e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.9928263554902514e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.455796205453225e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.764934947663278e-08
sam_encoder.blocks.11.norm1.weight grad: -1.5329005691455677e-05
sam_encoder.blocks.11.norm1.bias grad: 2.576531869635801e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.998365289386129e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.0681456785732735e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.6123757973218744e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.711827834100404e-07
sam_encoder.blocks.11.norm2.weight grad: 3.353284228069242e-07
sam_encoder.blocks.11.norm2.bias grad: -2.5925032787199598e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.575592134235194e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.430524758296087e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.6163601180305704e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.5042103029827558e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.733844202244654e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.924460179405287e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0505649445112795e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.7277307051699609e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001528298744233325
mask_decoder.transformer.layers.0.norm1.bias grad: -5.4864431149326265e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00571930268779397
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0008542307768948376
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00016871304251253605
mask_decoder.transformer.layers.0.norm3.bias grad: -4.284230817575008e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 2.41603993345052e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 8.071598131209612e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.8471094992710277e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.9060405470081605e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00012529367813840508
mask_decoder.transformer.layers.1.norm2.bias grad: 1.8132377590518445e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -3.46860324498266e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.953389750677161e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 3.16734985972289e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00012159426114521921
mask_decoder.transformer.norm_final_attn.weight grad: -2.7227565624343697e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.6120069378521293e-06
Text_Embedding_Affine.0.weight grad: 5.013704295481203e-12
Text_Embedding_Affine.0.bias grad: -8.359512526645574e-10
Text_Embedding_Affine.2.weight grad: -3.62921845353803e-11
Text_Embedding_Affine.2.bias grad: 4.0437742427457124e-05
Epoch 33 finished with average loss: -59.5274
Epoch 34/39
----------
Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s, loss=-67.9]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-67.9]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-60.7]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-60.7]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-59.6]Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-59.6]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.980818378044668e-14
Max value: 0.9998865127563477
Mean value: 0.08421966433525085

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.980818378044668e-14
Max value: 0.9998865127563477
Mean value: 0.08421966433525085

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08977556228637695

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11019043624401093

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07818794250488281

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08977556228637695

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 49.32627868652344
Max value: 89.5591049194336
Mean value: 67.85446166992188

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.980818378044668e-14
Max value: 0.9998865127563477
Mean value: 0.08421966433525085

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.980818378044668e-14
Max value: 0.9998865127563477
Mean value: 0.08421966433525085

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.980818378044668e-14
Max value: 0.9998865127563477
Mean value: 0.08421966433525085

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11019043624401093

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 49.32627868652344
Max value: 89.5591049194336
Mean value: 67.85446166992188

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.85549926757812
Max value: -67.85549926757812
Mean value: -67.85549926757812
sam_encoder.pos_embed grad: 7.20651982533127e-10
sam_encoder.blocks.0.norm1.weight grad: 7.950053986860439e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0240854862786364e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.039684871619102e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.398630709256395e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.1678016562655102e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.736839708310072e-08
sam_encoder.blocks.0.norm2.weight grad: -3.196724355802871e-05
sam_encoder.blocks.0.norm2.bias grad: -1.977868305402808e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.521148417145014e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.58595979277743e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.764073987142183e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.0112975346032727e-08
sam_encoder.blocks.1.norm1.weight grad: 9.100974239117932e-06
sam_encoder.blocks.1.norm1.bias grad: 2.7658901672111824e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.983731850596087e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2908725466331816e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.2730116547318175e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.0008668545633554e-06
sam_encoder.blocks.1.norm2.weight grad: 6.394679076038301e-06
sam_encoder.blocks.1.norm2.bias grad: -2.4163073248928413e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.3720334663958056e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.614215521949518e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.4893128536641598e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.571427785369451e-06
sam_encoder.blocks.2.norm1.weight grad: 1.5527386494795792e-05
sam_encoder.blocks.2.norm1.bias grad: -2.7281439543003216e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.392330305970972e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.346736894447531e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.25474774299073e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.1173046813346446e-06
sam_encoder.blocks.2.norm2.weight grad: -9.674174179963302e-06
sam_encoder.blocks.2.norm2.bias grad: -1.433492229807598e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.171533979999367e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.8472005081093812e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.285250598622952e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.7056225917476695e-06
sam_encoder.blocks.3.norm1.weight grad: -1.7450824998377357e-06
sam_encoder.blocks.3.norm1.bias grad: 1.3114429009419837e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.91786488762591e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.605571568092273e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.447113951755455e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.217981207446428e-06
sam_encoder.blocks.3.norm2.weight grad: -3.3361629903083667e-07
sam_encoder.blocks.3.norm2.bias grad: -2.3010056793282274e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.922264325723518e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.0561767516701366e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.023767360195052e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.7429358649678761e-06
sam_encoder.blocks.4.norm1.weight grad: 2.3073098418535665e-06
sam_encoder.blocks.4.norm1.bias grad: 5.8872792578767985e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.136052899004426e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.1375311664305627e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.213654508726904e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.6979224660171894e-06
sam_encoder.blocks.4.norm2.weight grad: -2.2555410396307707e-05
sam_encoder.blocks.4.norm2.bias grad: -1.1108420949312858e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5187530152616091e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.544398962025298e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.822488558100304e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.729860625549918e-06
sam_encoder.blocks.5.norm1.weight grad: 6.811096682213247e-06
sam_encoder.blocks.5.norm1.bias grad: -3.0469509511021897e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.2162721405911725e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 8.917472769098822e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.5942593734052934e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.500284153938992e-06
sam_encoder.blocks.5.norm2.weight grad: -1.2424325177562423e-05
sam_encoder.blocks.5.norm2.bias grad: 5.326070890987467e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.4790320872562e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.470399860816542e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.6247880694209016e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.729524445996503e-07
sam_encoder.blocks.6.norm1.weight grad: 3.469539478828665e-06
sam_encoder.blocks.6.norm1.bias grad: -9.1155141035415e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.7105130609706976e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.095813998603262e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.613814657110197e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.347481070813956e-07
sam_encoder.blocks.6.norm2.weight grad: 2.7128808142151684e-06
sam_encoder.blocks.6.norm2.bias grad: 2.9673992685275152e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.015017651681774e-08
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.86741737909324e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.0819842088949372e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.184728368272772e-07
sam_encoder.blocks.7.norm1.weight grad: 1.575196364456133e-07
sam_encoder.blocks.7.norm1.bias grad: 1.7976162780541927e-09
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.9870383312081685e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.341806167460163e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.160793984439806e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.1927752439078176e-06
sam_encoder.blocks.7.norm2.weight grad: -1.224730567628285e-06
sam_encoder.blocks.7.norm2.bias grad: 1.40515055591095e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.5849836927372962e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.3628141459776089e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.983262502060825e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.4126572978057084e-07
sam_encoder.blocks.8.norm1.weight grad: 3.865539383696159e-06
sam_encoder.blocks.8.norm1.bias grad: -1.8827904568752274e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.364169742781087e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.0436914383026306e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -8.676003631080675e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.35638412454864e-07
sam_encoder.blocks.8.norm2.weight grad: -2.4901287360989954e-06
sam_encoder.blocks.8.norm2.bias grad: 1.263158424080757e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.491172265057685e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0911420506308787e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.3483415841619717e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1053684545458964e-07
sam_encoder.blocks.9.norm1.weight grad: -8.046817470130918e-07
sam_encoder.blocks.9.norm1.bias grad: -8.886113391781691e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.290438475138217e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.099960627470864e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.4098187263207365e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.476154332332953e-07
sam_encoder.blocks.9.norm2.weight grad: 1.3433218555292115e-06
sam_encoder.blocks.9.norm2.bias grad: 1.746649331835215e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.405892788852725e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.0103899050761811e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3522164863388753e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.774338198236364e-07
sam_encoder.blocks.10.norm1.weight grad: -3.3633714338066056e-06
sam_encoder.blocks.10.norm1.bias grad: 4.3738782551372424e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.0727831017429708e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.5037501270853681e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.013616378666484e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0153921436995006e-07
sam_encoder.blocks.10.norm2.weight grad: -3.412055320950458e-06
sam_encoder.blocks.10.norm2.bias grad: -8.984338819573168e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.191551402574987e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1113215805380605e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.157519116342883e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.327005396793538e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0521259810047923e-06
sam_encoder.blocks.11.norm1.bias grad: -6.257675408960495e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.396747034566943e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6235511566264904e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3314378293216578e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.520828037537285e-07
sam_encoder.blocks.11.norm2.weight grad: 9.714138968774932e-07
sam_encoder.blocks.11.norm2.bias grad: -1.6036408112540812e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.492228526942199e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.171237908527473e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.4470588212134317e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.696391897596186e-08
sam_encoder.neck.conv1.trainable_scale grad: 9.238137863576412e-07
sam_encoder.neck.conv1.trainable_shift grad: 7.32583794160746e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.3263161235954612e-06
sam_encoder.neck.conv2.trainable_shift grad: 1.245646762981778e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 3.6547840863931924e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.4955730875954032e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005084389820694923
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00011046661529690027
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00010075038153445348
mask_decoder.transformer.layers.0.norm3.bias grad: 6.731599569320679e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -6.129423854872584e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.7293448258424178e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.6359150069765747e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.680570443975739e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 7.554530748166144e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.184885129798204e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 9.61053137871204e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 8.444650120509323e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -2.9009865102125332e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 8.210512169171125e-05
mask_decoder.transformer.norm_final_attn.weight grad: -1.2711868748738198e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.4625580661231652e-05
Text_Embedding_Affine.0.weight grad: -3.4647180957581014e-11
Text_Embedding_Affine.0.bias grad: -1.07604070098688e-09
Text_Embedding_Affine.2.weight grad: -1.6216160358961673e-11
Text_Embedding_Affine.2.bias grad: -2.355889228056185e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.302595333991135e-11
Max value: 0.9991669654846191
Mean value: 0.07542077451944351

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.302595333991135e-11
Max value: 0.9991669654846191
Mean value: 0.07542077451944351

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08244180679321289

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.877350807189941
Max value: -1.1920928244535389e-07
Mean value: -0.12469768524169922

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06580972671508789

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08244180679321289

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.21874237060547
Max value: 69.55038452148438
Mean value: 53.46937561035156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.825591398167518e-11
Max value: 0.9991965889930725
Mean value: 0.07462437450885773

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.825591398167518e-11
Max value: 0.9991965889930725
Mean value: 0.07462437450885773

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.825591398167518e-11
Max value: 0.9991965889930725
Mean value: 0.07462437450885773

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12501481175422668

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.779842734336853
Max value: 1.225563406944275
Mean value: 0.9997246861457825

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.21874237060547
Max value: 69.55038452148438
Mean value: 53.46937561035156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.4590950012207
Max value: -53.4590950012207
Mean value: -53.4590950012207
sam_encoder.pos_embed grad: -4.2111034659342295e-09
sam_encoder.blocks.0.norm1.weight grad: 2.348866473766975e-06
sam_encoder.blocks.0.norm1.bias grad: 1.8444025045027956e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0301525839604437e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.5652219076400797e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.9577739130436385e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0911981007666327e-06
sam_encoder.blocks.0.norm2.weight grad: 2.8605052193597658e-06
sam_encoder.blocks.0.norm2.bias grad: 1.2711292583844624e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4670271752947883e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.655027057902771e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.1883623301400803e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.455506758764386e-06
sam_encoder.blocks.1.norm1.weight grad: -7.5058919719595e-06
sam_encoder.blocks.1.norm1.bias grad: -8.269670615845826e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.505881851306185e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.4598643904027995e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 9.034862159751356e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.7034272938617505e-06
sam_encoder.blocks.1.norm2.weight grad: 7.4853332989732735e-06
sam_encoder.blocks.1.norm2.bias grad: 4.957755663781427e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1591781003517099e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.306492888237699e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 7.992615792318247e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.146944429019641e-07
sam_encoder.blocks.2.norm1.weight grad: 1.8704053218243644e-05
sam_encoder.blocks.2.norm1.bias grad: -2.865277110686293e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 8.874341801856644e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.573229266999988e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.2111493055708706e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.433900592928694e-06
sam_encoder.blocks.2.norm2.weight grad: 6.606655006180517e-06
sam_encoder.blocks.2.norm2.bias grad: -4.122238806303358e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.000175406166818e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.956334234724636e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.7111141207569744e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 7.449709187312692e-07
sam_encoder.blocks.3.norm1.weight grad: -4.1708440221555065e-06
sam_encoder.blocks.3.norm1.bias grad: -4.003685717179906e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.5439567278008326e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.0065137341116497e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.5035063206123596e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.096311618515756e-06
sam_encoder.blocks.3.norm2.weight grad: 2.0259435586922336e-06
sam_encoder.blocks.3.norm2.bias grad: 6.47214528726181e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.368195166331134e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.627259381275508e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.917434756000148e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.0048869348320295e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0445737643749453e-06
sam_encoder.blocks.4.norm1.bias grad: 3.0065907594689634e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.993857025212492e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.064079123760166e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4106481103226542e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.324812140221184e-07
sam_encoder.blocks.4.norm2.weight grad: -1.7839774955064058e-05
sam_encoder.blocks.4.norm2.bias grad: -2.14002557186177e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -9.803758075577207e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.434806214703713e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.7511435380110925e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.668612400062557e-07
sam_encoder.blocks.5.norm1.weight grad: -1.8547402191870788e-07
sam_encoder.blocks.5.norm1.bias grad: 3.492998530418845e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.03106913229567e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.164970283047296e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.9661866847163765e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.853368634234357e-07
sam_encoder.blocks.5.norm2.weight grad: -1.0057544386654627e-05
sam_encoder.blocks.5.norm2.bias grad: -1.1277797966613434e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.5222637961851433e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.8631020566317602e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.41752592400735e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.3967014562440454e-07
sam_encoder.blocks.6.norm1.weight grad: -5.696737730431778e-07
sam_encoder.blocks.6.norm1.bias grad: 4.847616764891427e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.0574069619906368e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.671963319604401e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.761922802274057e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.6556800725738867e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0382418622612022e-06
sam_encoder.blocks.6.norm2.bias grad: -3.679232577269431e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.070251750614261e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.306771165194732e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.022956083346799e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.1169055720047254e-08
sam_encoder.blocks.7.norm1.weight grad: 5.56339364266023e-06
sam_encoder.blocks.7.norm1.bias grad: 3.6250716561880836e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.070456270710565e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.8064738469547592e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5919675888653728e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.930886668333187e-07
sam_encoder.blocks.7.norm2.weight grad: 3.530852552557917e-07
sam_encoder.blocks.7.norm2.bias grad: -1.1757996389860637e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.78336404133006e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.590554898546543e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.9793698053690605e-09
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.09996448019956e-07
sam_encoder.blocks.8.norm1.weight grad: 1.435461854271125e-06
sam_encoder.blocks.8.norm1.bias grad: 2.6017255549959373e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.037180699218879e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.7763606763310236e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.489545636308321e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.828600938504678e-07
sam_encoder.blocks.8.norm2.weight grad: 5.481959419739724e-07
sam_encoder.blocks.8.norm2.bias grad: -1.4331652664623107e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.7607289919396862e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.633758514202782e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.1035497209377354e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.357520921871583e-08
sam_encoder.blocks.9.norm1.weight grad: 7.144848268580972e-07
sam_encoder.blocks.9.norm1.bias grad: 1.0423768799228128e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.0142595025827177e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.6122107733026496e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.241961283289129e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.073401206980634e-07
sam_encoder.blocks.9.norm2.weight grad: 3.3086623716371832e-06
sam_encoder.blocks.9.norm2.bias grad: -2.243186827399768e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.3299438655376434e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.6494963119839667e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.581801355627249e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.598959405110463e-10
sam_encoder.blocks.10.norm1.weight grad: 6.839640263933688e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1779509350162698e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.195678229734767e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3915082490711939e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.8045666365651414e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.212097686220659e-06
sam_encoder.blocks.10.norm2.weight grad: 5.654899268847657e-06
sam_encoder.blocks.10.norm2.bias grad: -2.4144792405422777e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.904102752334438e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.861110831669066e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.3733815649175085e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.30912621141033e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2670278920268174e-05
sam_encoder.blocks.11.norm1.bias grad: 1.662945010139083e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.9835329112538602e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.4322834829272324e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2789807897206629e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.9247055383384577e-07
sam_encoder.blocks.11.norm2.weight grad: 5.621624040941242e-06
sam_encoder.blocks.11.norm2.bias grad: -1.653267986512219e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.849087301612599e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0214438361799694e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.49932236076711e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.35414931385003e-08
sam_encoder.neck.conv1.trainable_scale grad: 7.844982974347658e-08
sam_encoder.neck.conv1.trainable_shift grad: 1.4873142390570138e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.0313669918105006e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.5500726223981474e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -6.52236703899689e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -9.891027730191126e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005505962297320366
mask_decoder.transformer.layers.0.norm2.bias grad: -6.155567825771868e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -1.4228020518203266e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.666773070814088e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001085407639038749
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0888558790611569e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.403807932045311e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.6488684195792302e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.4881718016113155e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.53931900463067e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.3873918659519404e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.20243343594484e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.2220777433831245e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018952647224068642
mask_decoder.transformer.norm_final_attn.weight grad: 1.7354760757370968e-06
mask_decoder.transformer.norm_final_attn.bias grad: 4.328215254645329e-06
Text_Embedding_Affine.0.weight grad: -2.36776553225182e-11
Text_Embedding_Affine.0.bias grad: -6.606806768338913e-10
Text_Embedding_Affine.2.weight grad: -1.9270024811945952e-11
Text_Embedding_Affine.2.bias grad: 1.603900636837352e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.336485644376495e-10
Max value: 0.9975153207778931
Mean value: 0.07258786261081696

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.336485644376495e-10
Max value: 0.9975153207778931
Mean value: 0.07258786261081696

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0747671127319336

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.405808448791504
Max value: -1.1920928244535389e-07
Mean value: -0.10968757420778275

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06071662902832031

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0747671127319336

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 50.6570930480957
Max value: 62.49417495727539
Mean value: 57.63897705078125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.285783424176401e-10
Max value: 0.9977836012840271
Mean value: 0.0713471919298172

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.285783424176401e-10
Max value: 0.9977836012840271
Mean value: 0.0713471919298172

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.285783424176401e-10
Max value: 0.9977836012840271
Mean value: 0.0713471919298172

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.442777633666992
Max value: -1.1920928244535389e-07
Mean value: -0.10981649160385132

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8527090549468994
Max value: 1.1576734781265259
Mean value: 0.9999213814735413

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 50.6570930480957
Max value: 62.49417495727539
Mean value: 57.63897705078125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.63405990600586
Max value: -57.63405990600586
Mean value: -57.63405990600586
sam_encoder.pos_embed grad: -2.223479400598194e-09
sam_encoder.blocks.0.norm1.weight grad: -2.9624394301208667e-05
sam_encoder.blocks.0.norm1.bias grad: -3.3940938010346144e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.60223133006366e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.938111715091509e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.455252448882675e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.2202497146063251e-06
sam_encoder.blocks.0.norm2.weight grad: -1.4777454452996608e-05
sam_encoder.blocks.0.norm2.bias grad: 3.157924220431596e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.58147359394934e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.5697654564282857e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5167649962677388e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.168919309042394e-06
sam_encoder.blocks.1.norm1.weight grad: 7.733138772891834e-06
sam_encoder.blocks.1.norm1.bias grad: 5.81959102419205e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.800369086093269e-08
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.157639376169755e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.962788928722148e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.1109084425697802e-06
sam_encoder.blocks.1.norm2.weight grad: 2.2350117433234118e-05
sam_encoder.blocks.1.norm2.bias grad: -2.09431300390861e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.601088327646721e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8797197753883665e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.426927605687524e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.1298069324539028e-07
sam_encoder.blocks.2.norm1.weight grad: 6.256495453271782e-06
sam_encoder.blocks.2.norm1.bias grad: 7.177690122261993e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.325932993902825e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.1395609905994206e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.233709213011025e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.1862134670082014e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0739050594565924e-05
sam_encoder.blocks.2.norm2.bias grad: 6.820960152253974e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.394972842826974e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.614759978314396e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.717311988613801e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6586150195507798e-06
sam_encoder.blocks.3.norm1.weight grad: -5.680771209881641e-06
sam_encoder.blocks.3.norm1.bias grad: -5.88389957556501e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.6866702518855163e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.201386450906284e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.8821808630018495e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.486897523747757e-06
sam_encoder.blocks.3.norm2.weight grad: 7.272585207829252e-06
sam_encoder.blocks.3.norm2.bias grad: -2.0852537545579253e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.375916877412237e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.2753264349594247e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.018566419792478e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.978281704064557e-09
sam_encoder.blocks.4.norm1.weight grad: -2.984776756420615e-06
sam_encoder.blocks.4.norm1.bias grad: -4.940802227793029e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.841150141350226e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0441367521707434e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.6734572909626877e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.9514461655489868e-06
sam_encoder.blocks.4.norm2.weight grad: -5.676549335476011e-06
sam_encoder.blocks.4.norm2.bias grad: -5.5053924370440654e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8055977761832764e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.475311688016518e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.0108162718534004e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.944096983512281e-07
sam_encoder.blocks.5.norm1.weight grad: -1.3797171050100587e-06
sam_encoder.blocks.5.norm1.bias grad: -8.004687401808042e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.008148951266776e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.1791071301558986e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.6177888179954607e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.342419626686024e-07
sam_encoder.blocks.5.norm2.weight grad: 4.570165401673876e-06
sam_encoder.blocks.5.norm2.bias grad: -1.0946730526484316e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.433591245993739e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.4339620975079015e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3299603551786277e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.9462410111591453e-07
sam_encoder.blocks.6.norm1.weight grad: -5.3033800213597715e-06
sam_encoder.blocks.6.norm1.bias grad: 1.6393653368140804e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.440837983565871e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.0681573005276732e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.058279622156988e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.594488026057661e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0112571544595994e-06
sam_encoder.blocks.6.norm2.bias grad: -4.773459068019292e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.406119025659791e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5713720813437249e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.0202221523722983e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.438091754214838e-07
sam_encoder.blocks.7.norm1.weight grad: 2.672807340786676e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0456717518536607e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.0330053303041495e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.4498549489871948e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.0545948043727549e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.473405800174078e-07
sam_encoder.blocks.7.norm2.weight grad: 4.640564554847515e-07
sam_encoder.blocks.7.norm2.bias grad: -1.5152944570218096e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.110440378710337e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.801237309948192e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.818359340992174e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2427710771589773e-06
sam_encoder.blocks.8.norm1.weight grad: 6.4004407249740325e-06
sam_encoder.blocks.8.norm1.bias grad: 3.3187015446856094e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.4086124287568964e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.333364576174063e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.0502633358555613e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.363642223230272e-07
sam_encoder.blocks.8.norm2.weight grad: 3.5889941045752494e-06
sam_encoder.blocks.8.norm2.bias grad: -7.546655069745611e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.654871534308768e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.6330668586306274e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.329334168076457e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.779980547984451e-07
sam_encoder.blocks.9.norm1.weight grad: 1.702272129477933e-06
sam_encoder.blocks.9.norm1.bias grad: 4.377845357339538e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.8160060335503658e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4353990991367027e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.108036470526713e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0723231014253543e-07
sam_encoder.blocks.9.norm2.weight grad: 6.03319494985044e-06
sam_encoder.blocks.9.norm2.bias grad: 1.8638908727552916e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.902556156594073e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.8864196792710572e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.143439807397954e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.212919009205507e-07
sam_encoder.blocks.10.norm1.weight grad: 2.8940637548657833e-06
sam_encoder.blocks.10.norm1.bias grad: 2.0324923752923496e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.7254600354353897e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.272509507543873e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.545903599748272e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.5533927328069694e-07
sam_encoder.blocks.10.norm2.weight grad: 6.915794074302539e-06
sam_encoder.blocks.10.norm2.bias grad: -3.3721957493071386e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.7660854559362633e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.2474973775388207e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.897047011174436e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.371823590394342e-07
sam_encoder.blocks.11.norm1.weight grad: 1.6572224922128953e-05
sam_encoder.blocks.11.norm1.bias grad: 2.1812077193317236e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.767230166180525e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.931152837642003e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.3322741071751807e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.69761686064885e-07
sam_encoder.blocks.11.norm2.weight grad: 8.641507520223968e-06
sam_encoder.blocks.11.norm2.bias grad: 2.2169585633946554e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.5024644350633025e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.6153426258824766e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.2207378097837136e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.2540710631346883e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.3335815058089793e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.833773346035741e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.3668205762514845e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.056024434044957e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 2.986962499562651e-06
mask_decoder.transformer.layers.0.norm1.bias grad: -2.908709575422108e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005507999565452337
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005673312116414309
mask_decoder.transformer.layers.0.norm3.weight grad: 2.4739907530602068e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.226283635944128e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001712753582978621
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1911878573300783e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.1448154661338776e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.274809725757223e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00016896965098567307
mask_decoder.transformer.layers.1.norm2.bias grad: -1.0137548088096082e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.5276500309701078e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.673930561693851e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -4.502612864598632e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00021959919831715524
mask_decoder.transformer.norm_final_attn.weight grad: 2.5884833121381234e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.8215385352959856e-05
Text_Embedding_Affine.0.weight grad: 2.7531943738723363e-11
Text_Embedding_Affine.0.bias grad: 5.585533147112187e-10
Text_Embedding_Affine.2.weight grad: -4.359361482908497e-11
Text_Embedding_Affine.2.bias grad: 3.028544597327709e-06
Epoch 34 finished with average loss: -59.6496
Epoch 35/39
----------
Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.7]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.18it/s, loss=-60.7]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.18it/s, loss=-61.5]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-61.5]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-60.5]Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.42it/s, loss=-60.5]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.848423308141282e-12
Max value: 0.9986922144889832
Mean value: 0.07722336053848267

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.848423308141282e-12
Max value: 0.9986922144889832
Mean value: 0.07722336053848267

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08605003356933594

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1331179141998291

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06906270980834961

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08605003356933594

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.083757400512695
Max value: 90.18242645263672
Mean value: 60.659584045410156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.848423308141282e-12
Max value: 0.9986922144889832
Mean value: 0.07722336053848267

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.848423308141282e-12
Max value: 0.9986922144889832
Mean value: 0.07722336053848267

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.848423308141282e-12
Max value: 0.9986922144889832
Mean value: 0.07722336053848267

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1331179141998291

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.083757400512695
Max value: 90.18242645263672
Mean value: 60.659584045410156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.6606330871582
Max value: -60.6606330871582
Mean value: -60.6606330871582
sam_encoder.pos_embed grad: -7.223400100286881e-09
sam_encoder.blocks.0.norm1.weight grad: 4.9600741476751864e-05
sam_encoder.blocks.0.norm1.bias grad: 4.358751903055236e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.803745135475765e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.030976015201304e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.77333150128834e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.7369821964384755e-06
sam_encoder.blocks.0.norm2.weight grad: -6.4336250034102704e-06
sam_encoder.blocks.0.norm2.bias grad: 8.77146958373487e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.003820893354714e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.63525042909896e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.2974440071266145e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.806286713370355e-06
sam_encoder.blocks.1.norm1.weight grad: -7.78494359110482e-06
sam_encoder.blocks.1.norm1.bias grad: -2.639567128426279e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.051927928434452e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.476119102037046e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.516385160968639e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.7824689823319204e-06
sam_encoder.blocks.1.norm2.weight grad: 2.4174820282496512e-05
sam_encoder.blocks.1.norm2.bias grad: 6.618712177441921e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.721318403724581e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.2843507799261715e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.037589289713651e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.077076821180526e-07
sam_encoder.blocks.2.norm1.weight grad: -3.989413016824983e-06
sam_encoder.blocks.2.norm1.bias grad: -9.211400538333692e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.530908602693671e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.321396656654542e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.0213435618643416e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.761479666129162e-06
sam_encoder.blocks.2.norm2.weight grad: -4.886848728347104e-06
sam_encoder.blocks.2.norm2.bias grad: 7.93004801380448e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.926842954475433e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.981631380156614e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.9178773413841554e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.350898967051762e-06
sam_encoder.blocks.3.norm1.weight grad: 2.6411362341605127e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0324949471396394e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.043821147410199e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.307639862119686e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.4769623198371846e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.319218533055391e-06
sam_encoder.blocks.3.norm2.weight grad: 7.748025382170454e-06
sam_encoder.blocks.3.norm2.bias grad: -1.2534108009276679e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.9082245873723878e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.168365078134229e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.515034793759696e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.547334242488432e-07
sam_encoder.blocks.4.norm1.weight grad: 1.0719140846049413e-05
sam_encoder.blocks.4.norm1.bias grad: -3.743448132809135e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.185605798236793e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.0086372387595475e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.475790774449706e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.515383236343041e-06
sam_encoder.blocks.4.norm2.weight grad: -1.0604925591906067e-05
sam_encoder.blocks.4.norm2.bias grad: -2.1383002604125068e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.718428499472793e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6846282733240514e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.066168119403301e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.928285299385607e-07
sam_encoder.blocks.5.norm1.weight grad: 1.36712387757143e-05
sam_encoder.blocks.5.norm1.bias grad: -8.81799769558711e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.595643859938718e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.407371761772083e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 7.566882686660392e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.7536914330994477e-06
sam_encoder.blocks.5.norm2.weight grad: -1.7735515029926319e-06
sam_encoder.blocks.5.norm2.bias grad: -1.613967810953909e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.604273039556574e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.013199254084611e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8086360569213866e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.598168968390382e-07
sam_encoder.blocks.6.norm1.weight grad: 4.969856490788516e-06
sam_encoder.blocks.6.norm1.bias grad: 3.3906751468748553e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.9808644537988584e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.6817157794976083e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.9356482400544337e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.478402620909037e-06
sam_encoder.blocks.6.norm2.weight grad: -8.721142876311205e-06
sam_encoder.blocks.6.norm2.bias grad: -2.594316356407944e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.0758934523619246e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.379094894422451e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.326202886455576e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.3437656889436767e-06
sam_encoder.blocks.7.norm1.weight grad: 7.856959200580604e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3117785329086473e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.533271749096457e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.380012236040784e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.1400746845756657e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.211753892173874e-06
sam_encoder.blocks.7.norm2.weight grad: -2.8184635993966367e-06
sam_encoder.blocks.7.norm2.bias grad: -9.404333241036511e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.7751774521457264e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.0877200793402153e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1768981948989676e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.4666591141576646e-06
sam_encoder.blocks.8.norm1.weight grad: 2.1388491404650267e-06
sam_encoder.blocks.8.norm1.bias grad: -9.432833394384943e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2086633205399266e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.7002141703414964e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.835513654048555e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.16726539292722e-06
sam_encoder.blocks.8.norm2.weight grad: 2.371649316046387e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4507454579870682e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.9630032258864958e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.0291522560000885e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.296980809063825e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.7549773423961597e-07
sam_encoder.blocks.9.norm1.weight grad: -5.143613748259668e-07
sam_encoder.blocks.9.norm1.bias grad: 2.053523076028796e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.3886743722177926e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.8604313229152467e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.315935709404584e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.167094852571608e-07
sam_encoder.blocks.9.norm2.weight grad: 7.350291525654029e-06
sam_encoder.blocks.9.norm2.bias grad: -1.460251041862648e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.12170106251142e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.6219541925675003e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.2436551060091006e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.430916646924743e-07
sam_encoder.blocks.10.norm1.weight grad: -2.4557164124416886e-07
sam_encoder.blocks.10.norm1.bias grad: 2.3056027202983387e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.5939416420660564e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2281908823297272e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.742498790870741e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.5933405822797795e-07
sam_encoder.blocks.10.norm2.weight grad: 1.4198049029801041e-05
sam_encoder.blocks.10.norm2.bias grad: 1.3782871519651962e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.921417480043601e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.491559138841694e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.9670092115120497e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.319527645042399e-07
sam_encoder.blocks.11.norm1.weight grad: 3.601613570936024e-05
sam_encoder.blocks.11.norm1.bias grad: 4.388651575482072e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.102862582542002e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.767911271599587e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.8118863610870903e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.209720820355869e-07
sam_encoder.blocks.11.norm2.weight grad: 1.5075453120516613e-05
sam_encoder.blocks.11.norm2.bias grad: 3.083463013808796e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.775487807113677e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.141383331239922e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.117651014074909e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.898994229231903e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.3407183107337914e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.73198295669863e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.302682332810946e-06
sam_encoder.neck.conv2.trainable_shift grad: 1.941397385962773e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00026678797439672053
mask_decoder.transformer.layers.0.norm1.bias grad: 2.7444912120699883e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0022951371502131224
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0017691822722554207
mask_decoder.transformer.layers.0.norm3.weight grad: 3.5171186027582735e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.927514136303216e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010275750537402928
mask_decoder.transformer.layers.0.norm4.bias grad: -1.6535148461116478e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.954334948095493e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.265997631591745e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00022108264965936542
mask_decoder.transformer.layers.1.norm2.bias grad: -5.254422649159096e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.236413820355665e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.331122570671141e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.819983875378966e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00012788339518010616
mask_decoder.transformer.norm_final_attn.weight grad: -1.2820410120184533e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.980706762580667e-06
Text_Embedding_Affine.0.weight grad: 2.0642869358322713e-11
Text_Embedding_Affine.0.bias grad: 5.987429996245908e-10
Text_Embedding_Affine.2.weight grad: -1.0066962541355196e-10
Text_Embedding_Affine.2.bias grad: -4.232265200698748e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.150990216642228e-11
Max value: 0.9984844326972961
Mean value: 0.08544909954071045

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.150990216642228e-11
Max value: 0.9984844326972961
Mean value: 0.08544909954071045

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.090972900390625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.73902702331543
Max value: -1.1920928244535389e-07
Mean value: -0.11999232321977615

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0772237777709961

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.090972900390625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.03466796875
Max value: 80.07789611816406
Mean value: 62.28413772583008

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.207007907128471e-11
Max value: 0.9984666109085083
Mean value: 0.08614873886108398

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.207007907128471e-11
Max value: 0.9984666109085083
Mean value: 0.08614873886108398

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.207007907128471e-11
Max value: 0.9984666109085083
Mean value: 0.08614873886108398

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.629244804382324
Max value: -1.1920928244535389e-07
Mean value: -0.11983440071344376

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9674442410469055
Max value: 1.116034984588623
Mean value: 1.0001671314239502

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.03466796875
Max value: 80.07789611816406
Mean value: 62.28413772583008

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.295745849609375
Max value: -62.295745849609375
Mean value: -62.295745849609375
sam_encoder.pos_embed grad: 1.39194211712379e-10
sam_encoder.blocks.0.norm1.weight grad: -2.861051143554505e-05
sam_encoder.blocks.0.norm1.bias grad: -5.42981069884263e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.965252861031331e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.770234909301507e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.7602667412575101e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5564872910545091e-06
sam_encoder.blocks.0.norm2.weight grad: -7.884806109359488e-06
sam_encoder.blocks.0.norm2.bias grad: 1.5540976164629683e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.00014613053645e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.416548911947757e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.3789123083115555e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.234483185427962e-06
sam_encoder.blocks.1.norm1.weight grad: -7.91018010204425e-06
sam_encoder.blocks.1.norm1.bias grad: -6.770982054149499e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.1302455479599303e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.147479219478555e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.291751640854272e-08
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.643589239909488e-07
sam_encoder.blocks.1.norm2.weight grad: 1.6247278836090118e-05
sam_encoder.blocks.1.norm2.bias grad: -2.428489779049414e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.867990694241598e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.642458983042161e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.643474989687093e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.793672931351466e-07
sam_encoder.blocks.2.norm1.weight grad: 1.916816472657956e-06
sam_encoder.blocks.2.norm1.bias grad: -4.580157110467553e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.990200189538882e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.405532768534613e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.2947640470883925e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.914500439350377e-07
sam_encoder.blocks.2.norm2.weight grad: 6.537119588756468e-06
sam_encoder.blocks.2.norm2.bias grad: 5.830426744068973e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.1739699554455e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.205065912785358e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.778232323587872e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.116566512697318e-07
sam_encoder.blocks.3.norm1.weight grad: -4.184469617030118e-06
sam_encoder.blocks.3.norm1.bias grad: -3.5522384678188246e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.7320926417596638e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1288192354186322e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.28577731479163e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1378358522051712e-06
sam_encoder.blocks.3.norm2.weight grad: 1.3700339877686929e-05
sam_encoder.blocks.3.norm2.bias grad: 3.276006736996351e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.0793175533763133e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.6792250739381416e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.762951608787262e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.28169528277067e-07
sam_encoder.blocks.4.norm1.weight grad: -2.8461233796406304e-06
sam_encoder.blocks.4.norm1.bias grad: -3.97571966459509e-08
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.610823114286177e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.216404694394441e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.7665908558228693e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3537031691157608e-06
sam_encoder.blocks.4.norm2.weight grad: 4.472030923352577e-08
sam_encoder.blocks.4.norm2.bias grad: -5.866348146810196e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.6677025743993e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.6380550366411626e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.011240894717048e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.8696687220653985e-07
sam_encoder.blocks.5.norm1.weight grad: 1.7895840187520662e-07
sam_encoder.blocks.5.norm1.bias grad: -3.0447640710917767e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.6967367173492676e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.0503193692557034e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.8995774553332012e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.5774351065119845e-07
sam_encoder.blocks.5.norm2.weight grad: 1.3610432461064192e-06
sam_encoder.blocks.5.norm2.bias grad: -2.285374193888856e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.50694426742848e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.5982731156327645e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1534335726537392e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.279938430798211e-07
sam_encoder.blocks.6.norm1.weight grad: 2.2268500288191717e-06
sam_encoder.blocks.6.norm1.bias grad: 1.9230519683333114e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.431397079926683e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.554399311018642e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.762755558360368e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.883217681912356e-07
sam_encoder.blocks.6.norm2.weight grad: -2.788530764519237e-06
sam_encoder.blocks.6.norm2.bias grad: -1.3764741879640496e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4121210369921755e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.198198837457312e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.183700401787064e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.280724622025446e-07
sam_encoder.blocks.7.norm1.weight grad: 1.2154641808592714e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3379674328461988e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.2754906038026093e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.818927775180782e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5325776985264383e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.778754600920365e-07
sam_encoder.blocks.7.norm2.weight grad: 1.4736755247213296e-06
sam_encoder.blocks.7.norm2.bias grad: 3.1395956057167496e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.7886685554913129e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.4657133331566e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4547424598276848e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.8129990065936e-07
sam_encoder.blocks.8.norm1.weight grad: 1.293901732424274e-06
sam_encoder.blocks.8.norm1.bias grad: -1.3173023489798652e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.109456419129856e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.417106218099434e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.422129682599916e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.1021382988474215e-06
sam_encoder.blocks.8.norm2.weight grad: 2.5005751922435593e-06
sam_encoder.blocks.8.norm2.bias grad: -5.608585524896625e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.6924120649928227e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.035826582869049e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.5195136029433343e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.1885857393044716e-07
sam_encoder.blocks.9.norm1.weight grad: -1.936295120685827e-06
sam_encoder.blocks.9.norm1.bias grad: 5.673477971868124e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.456206859984377e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.7812495773105184e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.9443118048911856e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.729741481743986e-07
sam_encoder.blocks.9.norm2.weight grad: -8.471655377206844e-08
sam_encoder.blocks.9.norm2.bias grad: -1.0863159332075156e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.3526963584808982e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.1292781891825143e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.064921199642413e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.649765739690338e-07
sam_encoder.blocks.10.norm1.weight grad: -3.279587303950393e-07
sam_encoder.blocks.10.norm1.bias grad: -7.314118875001441e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.650337584484078e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.4912388830198324e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.53492747915152e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.703572973445262e-08
sam_encoder.blocks.10.norm2.weight grad: 1.0342995437895297e-06
sam_encoder.blocks.10.norm2.bias grad: -1.941894424817292e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.0707745989057003e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2845765695601585e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.868817882197618e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.0016317137105943e-07
sam_encoder.blocks.11.norm1.weight grad: 1.4172590454109013e-05
sam_encoder.blocks.11.norm1.bias grad: -2.6204628511550254e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.5458928121224744e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.4591183723241556e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8264145182911307e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.466650575021049e-07
sam_encoder.blocks.11.norm2.weight grad: -4.5666383812204e-06
sam_encoder.blocks.11.norm2.bias grad: -2.091288934025215e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4419970284507144e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.911280247048126e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7318233176411013e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.5055823016373324e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.679250196204521e-07
sam_encoder.neck.conv1.trainable_shift grad: -7.613938578288071e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.7899659471586347e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.0290419595548883e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -3.319834286230616e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 7.224298315122724e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00520697608590126
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003420043794903904
mask_decoder.transformer.layers.0.norm3.weight grad: -9.01513485587202e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.510549191152677e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00014466969878412783
mask_decoder.transformer.layers.0.norm4.bias grad: -1.7728469174471684e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.388962406665087e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 8.127808541757986e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001532602618681267
mask_decoder.transformer.layers.1.norm2.bias grad: 4.462344804778695e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.202962009003386e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.018598727067001e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.144384678918868e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018177951278630644
mask_decoder.transformer.norm_final_attn.weight grad: 5.55942278879229e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.542416248412337e-05
Text_Embedding_Affine.0.weight grad: 1.0261026403557416e-11
Text_Embedding_Affine.0.bias grad: 1.0831206070927024e-10
Text_Embedding_Affine.2.weight grad: -2.1185983523075436e-11
Text_Embedding_Affine.2.bias grad: 1.3098484487272799e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0141865125490312e-09
Max value: 0.9935755133628845
Mean value: 0.06275772303342819

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0141865125490312e-09
Max value: 0.9935755133628845
Mean value: 0.06275772303342819

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06571483612060547

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.971565246582031
Max value: -1.1920928244535389e-07
Mean value: -0.09347569197416306

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.053783416748046875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06571483612060547

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.578060150146484
Max value: 72.83631896972656
Mean value: 58.55766296386719

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1980298975089454e-09
Max value: 0.9935675263404846
Mean value: 0.06471218168735504

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1980298975089454e-09
Max value: 0.9935675263404846
Mean value: 0.06471218168735504

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1980298975089454e-09
Max value: 0.9935675263404846
Mean value: 0.06471218168735504

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.872488975524902
Max value: -1.1920928244535389e-07
Mean value: -0.09332730621099472

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9242779016494751
Max value: 1.2928193807601929
Mean value: 1.0002202987670898

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.578060150146484
Max value: 72.83631896972656
Mean value: 58.55766296386719

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.56804275512695
Max value: -58.56804275512695
Mean value: -58.56804275512695
sam_encoder.pos_embed grad: -5.765073307628654e-09
sam_encoder.blocks.0.norm1.weight grad: -2.2306017854134552e-05
sam_encoder.blocks.0.norm1.bias grad: -1.7110967746702954e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.083852453120926e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.361915438901633e-10
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.89262163227977e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.429570925727603e-07
sam_encoder.blocks.0.norm2.weight grad: -8.633143806946464e-06
sam_encoder.blocks.0.norm2.bias grad: 7.526146418967983e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.897110779391369e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.141215761890635e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.707286153570749e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.214683824306121e-06
sam_encoder.blocks.1.norm1.weight grad: -4.312608780310256e-06
sam_encoder.blocks.1.norm1.bias grad: -4.051305040775333e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.3772419644483307e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.271980848599924e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.360450253036106e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.2796268694946775e-06
sam_encoder.blocks.1.norm2.weight grad: 1.6370544472010806e-05
sam_encoder.blocks.1.norm2.bias grad: -4.090790753252804e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.0573919098533224e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.7972328098258004e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0733128874562681e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.197593974211486e-06
sam_encoder.blocks.2.norm1.weight grad: -9.775152648217045e-06
sam_encoder.blocks.2.norm1.bias grad: -1.1035935131076258e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.92224808112951e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2908615190099226e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.4741786950908136e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.5147026008198736e-06
sam_encoder.blocks.2.norm2.weight grad: -6.541644097524113e-07
sam_encoder.blocks.2.norm2.bias grad: 6.156385552458232e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.1541026146442164e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.525588851971406e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.896616362908389e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.121764512390655e-06
sam_encoder.blocks.3.norm1.weight grad: 1.724665708024986e-06
sam_encoder.blocks.3.norm1.bias grad: -5.56177747057518e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4952678384361207e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.3746933897637064e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.55957671572105e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1789156815211754e-06
sam_encoder.blocks.3.norm2.weight grad: 1.5023242667666636e-05
sam_encoder.blocks.3.norm2.bias grad: -1.10934633994475e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1528121831361204e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.2706684578442946e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.125662599108182e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3029368801653618e-06
sam_encoder.blocks.4.norm1.weight grad: 1.0919163287326228e-05
sam_encoder.blocks.4.norm1.bias grad: -2.108739863615483e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.204250101087382e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.6586849369559786e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.66631377851445e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.5630513391661225e-06
sam_encoder.blocks.4.norm2.weight grad: -2.1885402020416223e-05
sam_encoder.blocks.4.norm2.bias grad: -1.5022031220723875e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3596286407846492e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.148240234120749e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.305682068661554e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.090103523893049e-06
sam_encoder.blocks.5.norm1.weight grad: 3.5827802093990613e-06
sam_encoder.blocks.5.norm1.bias grad: -6.298055723163998e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.588975563521672e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.821022230316885e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.4610848211304983e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.1511468730750494e-06
sam_encoder.blocks.5.norm2.weight grad: -5.614396059172577e-07
sam_encoder.blocks.5.norm2.bias grad: -7.227657988551073e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.3362972595132305e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 7.181149044299673e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.226993711308751e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.2468020688393153e-07
sam_encoder.blocks.6.norm1.weight grad: 2.0140923879807815e-06
sam_encoder.blocks.6.norm1.bias grad: 1.4810200354986591e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.7153287217297475e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.910912896453738e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.87295186657866e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.928923307394143e-07
sam_encoder.blocks.6.norm2.weight grad: -3.0576989047403913e-06
sam_encoder.blocks.6.norm2.bias grad: -2.11667929761461e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.112135118499282e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.3273433978611138e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.203264663578011e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.720923693137593e-07
sam_encoder.blocks.7.norm1.weight grad: 2.1517707864404656e-06
sam_encoder.blocks.7.norm1.bias grad: 3.422036911615578e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.6417450297012692e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.106522849018802e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2432150242602802e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.841822030561161e-07
sam_encoder.blocks.7.norm2.weight grad: 3.334110715513816e-06
sam_encoder.blocks.7.norm2.bias grad: 1.0930643838946708e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.928493020386668e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.288069478912803e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.634571493828844e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2285964885450085e-06
sam_encoder.blocks.8.norm1.weight grad: 5.806378794659395e-06
sam_encoder.blocks.8.norm1.bias grad: -2.1718342395615764e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.056311238149647e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.8435064248478739e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.183971446356736e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.8175522857054602e-06
sam_encoder.blocks.8.norm2.weight grad: 3.507543397063273e-06
sam_encoder.blocks.8.norm2.bias grad: -2.802982521643571e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.741520347626647e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.11210863199085e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.3033384220761945e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.085722456968142e-07
sam_encoder.blocks.9.norm1.weight grad: -1.0167203745581332e-09
sam_encoder.blocks.9.norm1.bias grad: 1.7383551664806873e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.30167221515876e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.91316075870418e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.747238501247921e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.7010553316795267e-07
sam_encoder.blocks.9.norm2.weight grad: 4.273811555322027e-06
sam_encoder.blocks.9.norm2.bias grad: 1.3029042520429357e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.7293160655972315e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.3202796910481993e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.90539116274158e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.862509518308798e-07
sam_encoder.blocks.10.norm1.weight grad: 2.2526605789607856e-06
sam_encoder.blocks.10.norm1.bias grad: 7.23313291928207e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.6339995454472955e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.013246105685539e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.511093258472101e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.8865721074234898e-07
sam_encoder.blocks.10.norm2.weight grad: 7.51616744310013e-06
sam_encoder.blocks.10.norm2.bias grad: 8.951334962148394e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.2746860344777815e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.272749497933546e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.3142123407305917e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.849977587260355e-09
sam_encoder.blocks.11.norm1.weight grad: 1.8595299479784444e-05
sam_encoder.blocks.11.norm1.bias grad: 1.8544690192356938e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.436584620430949e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1612985417741584e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.010293883358827e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.746862588144722e-07
sam_encoder.blocks.11.norm2.weight grad: 9.806137313717045e-06
sam_encoder.blocks.11.norm2.bias grad: 4.9106045452163016e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.128206794324797e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.5526418337685755e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.360445586826245e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.605300094022823e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.62537321052514e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.4418998034670949e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.049317456316203e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.227071622153744e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 6.357049278449267e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2934469850733876e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005535766016691923
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0006231698207557201
mask_decoder.transformer.layers.0.norm3.weight grad: -1.5215757230180316e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.674103936646134e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001520123623777181
mask_decoder.transformer.layers.0.norm4.bias grad: -1.713303936412558e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.08006198995281e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.927387868112419e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.6995472833514214e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.251071656355634e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.442577846930362e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.4796236175461672e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.89410049340222e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002237984153907746
mask_decoder.transformer.norm_final_attn.weight grad: -4.332852086008643e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.1424195690779015e-05
Text_Embedding_Affine.0.weight grad: 7.456570083608227e-12
Text_Embedding_Affine.0.bias grad: 5.202237529644549e-10
Text_Embedding_Affine.2.weight grad: -1.9277163199049596e-11
Text_Embedding_Affine.2.bias grad: -1.9970204448327422e-05
Epoch 35 finished with average loss: -60.5081
Epoch 36/39
----------
Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.16it/s, loss=-64]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.16it/s, loss=-61.1]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.74it/s, loss=-61.1]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.74it/s, loss=-63.9]Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.39it/s, loss=-63.9]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.755493958688572e-13
Max value: 0.9989410042762756
Mean value: 0.08145637810230255

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.755493958688572e-13
Max value: 0.9989410042762756
Mean value: 0.08145637810230255

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08403158187866211

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.68217658996582
Max value: -1.1920928244535389e-07
Mean value: -0.11027209460735321

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07378053665161133

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08403158187866211

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.888641357421875
Max value: 90.98991394042969
Mean value: 63.96611022949219

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.755493958688572e-13
Max value: 0.9989410042762756
Mean value: 0.08145637810230255

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.755493958688572e-13
Max value: 0.9989410042762756
Mean value: 0.08145637810230255

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.755493958688572e-13
Max value: 0.9989410042762756
Mean value: 0.08145637810230255

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.68217658996582
Max value: -1.1920928244535389e-07
Mean value: -0.11027209460735321

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.888641357421875
Max value: 90.98991394042969
Mean value: 63.96611022949219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.96719741821289
Max value: -63.96719741821289
Mean value: -63.96719741821289
sam_encoder.pos_embed grad: -9.114191179548925e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00014656988787464797
sam_encoder.blocks.0.norm1.bias grad: 2.5389628717675805e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1918581549252849e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.760738872595539e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.143779718404403e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.652767250310717e-07
sam_encoder.blocks.0.norm2.weight grad: -3.170599666191265e-05
sam_encoder.blocks.0.norm2.bias grad: -7.1635891799815e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.052174391399603e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.6993023968534544e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.2741260181646794e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.838954972299689e-06
sam_encoder.blocks.1.norm1.weight grad: -1.0540643415879458e-05
sam_encoder.blocks.1.norm1.bias grad: 4.503387572185602e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.2393159017374273e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.33089645007567e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.0634947759390343e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.711556928465143e-07
sam_encoder.blocks.1.norm2.weight grad: -1.0810958883666899e-05
sam_encoder.blocks.1.norm2.bias grad: 8.35190530779073e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.6237408999586478e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.0462698440960594e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.756655238859821e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.7919537640409544e-06
sam_encoder.blocks.2.norm1.weight grad: -8.423519830103032e-06
sam_encoder.blocks.2.norm1.bias grad: -6.247471901588142e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2129820561312954e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.394540613044228e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.2633846558383084e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.5626191043338622e-06
sam_encoder.blocks.2.norm2.weight grad: 8.310436896863393e-06
sam_encoder.blocks.2.norm2.bias grad: -1.6705541838746285e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.7187531941308407e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.346508906242889e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7668197617458645e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.598746959847631e-07
sam_encoder.blocks.3.norm1.weight grad: -4.99697634381846e-08
sam_encoder.blocks.3.norm1.bias grad: -1.4036659194971435e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.2573759628794505e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.460999995601014e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0711478353186976e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.303722340002423e-06
sam_encoder.blocks.3.norm2.weight grad: -4.719383923657006e-06
sam_encoder.blocks.3.norm2.bias grad: -5.057306225353386e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.0883645649737446e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.474953816999914e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.6611303383106133e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.8957967401765927e-07
sam_encoder.blocks.4.norm1.weight grad: 8.809038263279945e-06
sam_encoder.blocks.4.norm1.bias grad: -1.2673495803028345e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0214192798230215e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.294418426477932e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4905890566296875e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.0081586171727395e-06
sam_encoder.blocks.4.norm2.weight grad: -1.6763300664024428e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0817870133905672e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.115690974984318e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.219019047013717e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.7024805149267195e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.926507249867427e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4248273146222346e-05
sam_encoder.blocks.5.norm1.bias grad: 8.325996532221325e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.14475993643282e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.5769959393073805e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 7.704669769736938e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.6962540030363016e-06
sam_encoder.blocks.5.norm2.weight grad: -8.583630915381946e-06
sam_encoder.blocks.5.norm2.bias grad: -1.2721813618554734e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.4144156820257194e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.241397623947705e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.91897229848837e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.672751169389812e-07
sam_encoder.blocks.6.norm1.weight grad: 7.918568371678703e-06
sam_encoder.blocks.6.norm1.bias grad: 6.143501195765566e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.217948455538135e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.3177963157650083e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.4289711291203275e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.4200486475601792e-06
sam_encoder.blocks.6.norm2.weight grad: -5.990359113638988e-06
sam_encoder.blocks.6.norm2.bias grad: -4.426970463100588e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.486424354079645e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.414497885183664e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1945660389756085e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0259530824896501e-07
sam_encoder.blocks.7.norm1.weight grad: 1.3976725313114002e-05
sam_encoder.blocks.7.norm1.bias grad: 8.637198334326968e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.276723176299129e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.9773416372336214e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.429678938322468e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.399401743488852e-06
sam_encoder.blocks.7.norm2.weight grad: -2.4174408963517635e-07
sam_encoder.blocks.7.norm2.bias grad: 1.6433249356850865e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.610643827618333e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1873653420479968e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.542693380291894e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.603825219528517e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0486557584954426e-05
sam_encoder.blocks.8.norm1.bias grad: -1.998672132685897e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.451159374089912e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.132086360186804e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.300467480788939e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.8741649202856934e-06
sam_encoder.blocks.8.norm2.weight grad: 6.974360985623207e-06
sam_encoder.blocks.8.norm2.bias grad: 7.866278792789672e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.549327059066854e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.9719265057792654e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.161734639434144e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.186140689758759e-07
sam_encoder.blocks.9.norm1.weight grad: 5.528534074983327e-06
sam_encoder.blocks.9.norm1.bias grad: 5.51096832168696e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.8772553832823178e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.2009295460302383e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.1641191122180317e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.243773678856087e-06
sam_encoder.blocks.9.norm2.weight grad: 7.409041245409753e-06
sam_encoder.blocks.9.norm2.bias grad: 8.11549398349598e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.0085791372112e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.25234213960357e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.589538896951126e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.174038844619645e-07
sam_encoder.blocks.10.norm1.weight grad: 4.467223334359005e-06
sam_encoder.blocks.10.norm1.bias grad: 7.732455173936614e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.248121290904237e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.149410971076577e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.18912549093875e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.277260915041552e-07
sam_encoder.blocks.10.norm2.weight grad: 1.248330227099359e-05
sam_encoder.blocks.10.norm2.bias grad: 3.315894900879357e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.680887054244522e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.769949333014665e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.9262777186668245e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.515152340900386e-07
sam_encoder.blocks.11.norm1.weight grad: 9.362532182422001e-06
sam_encoder.blocks.11.norm1.bias grad: 5.281985977489967e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.159509565695771e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0154817573493347e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.5879954844422173e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.610781954601407e-07
sam_encoder.blocks.11.norm2.weight grad: 1.7500844478490762e-05
sam_encoder.blocks.11.norm2.bias grad: -7.060036750772269e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.63542936713202e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.092564611506532e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.525509898987366e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.583103198754543e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.6484882507938892e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.6381649149698205e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0848710846621543e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.930044476874173e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0002549830242060125
mask_decoder.transformer.layers.0.norm1.bias grad: 6.4519408624619246e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0018310402520000935
mask_decoder.transformer.layers.0.norm2.bias grad: -0.002082530641928315
mask_decoder.transformer.layers.0.norm3.weight grad: 3.772502168430947e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.2846803656429984e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 1.187792258861009e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.505558197502978e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.6424701041542e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 2.1610112526104786e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.495075573795475e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 8.337887993548065e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.98212205254822e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -4.6093191485852e-08
mask_decoder.transformer.layers.1.norm4.weight grad: -3.8488760765176266e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -6.952213880140334e-05
mask_decoder.transformer.norm_final_attn.weight grad: -5.092229002912063e-06
mask_decoder.transformer.norm_final_attn.bias grad: -5.299847998685436e-06
Text_Embedding_Affine.0.weight grad: -5.275854753072906e-11
Text_Embedding_Affine.0.bias grad: -1.488554168815881e-09
Text_Embedding_Affine.2.weight grad: 3.9077973496004503e-11
Text_Embedding_Affine.2.bias grad: -6.016305269440636e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.02949869252145e-11
Max value: 0.9957239627838135
Mean value: 0.06877566874027252

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.02949869252145e-11
Max value: 0.9957239627838135
Mean value: 0.06877566874027252

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07036685943603516

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11072725057601929

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.060224056243896484

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07036685943603516

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.51519012451172
Max value: 70.4896469116211
Mean value: 58.16327667236328

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.14078240982019e-11
Max value: 0.996313750743866
Mean value: 0.07024049758911133

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.14078240982019e-11
Max value: 0.996313750743866
Mean value: 0.07024049758911133

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.14078240982019e-11
Max value: 0.996313750743866
Mean value: 0.07024049758911133

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11029371619224548

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8499667644500732
Max value: 1.4340413808822632
Mean value: 1.0005199909210205

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.51519012451172
Max value: 70.4896469116211
Mean value: 58.16327667236328

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.191715240478516
Max value: -58.191715240478516
Mean value: -58.191715240478516
sam_encoder.pos_embed grad: -9.31555099725756e-09
sam_encoder.blocks.0.norm1.weight grad: 3.076743087149225e-05
sam_encoder.blocks.0.norm1.bias grad: -3.9609814848518e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.69706344322185e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0366019154162132e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.092963990842691e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.2293611436907668e-06
sam_encoder.blocks.0.norm2.weight grad: -4.221824201522395e-05
sam_encoder.blocks.0.norm2.bias grad: 5.540348865906708e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.3709773156733718e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.654645181290107e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.928661266807467e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.094121307687601e-05
sam_encoder.blocks.1.norm1.weight grad: -1.5970686945365742e-05
sam_encoder.blocks.1.norm1.bias grad: -3.4909842270280933e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.2024200259475037e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.5022466161317425e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.554547093808651e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.2578968784946483e-06
sam_encoder.blocks.1.norm2.weight grad: 2.67595669356524e-06
sam_encoder.blocks.1.norm2.bias grad: 2.1443338482640684e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.8608416212373413e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.70644602298853e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.2746057109325193e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.108787387238408e-06
sam_encoder.blocks.2.norm1.weight grad: -8.475740287394729e-06
sam_encoder.blocks.2.norm1.bias grad: -2.3135877199820243e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.6442176022101194e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.984030384657672e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.448376777574595e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.7382715213898337e-06
sam_encoder.blocks.2.norm2.weight grad: 1.3845286730429507e-06
sam_encoder.blocks.2.norm2.bias grad: 7.012713012954919e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.984616225556238e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.952229227863427e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.7551238822052255e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.2767067119057174e-06
sam_encoder.blocks.3.norm1.weight grad: 7.1171684794535395e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0493708032299764e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 6.767025752196787e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.1677083193717408e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.3152482501463965e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.519067478118814e-07
sam_encoder.blocks.3.norm2.weight grad: 3.1037445296533406e-05
sam_encoder.blocks.3.norm2.bias grad: -6.688165740342811e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.0105624571442604e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.657848876377102e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.592122296453454e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.312199052947108e-06
sam_encoder.blocks.4.norm1.weight grad: 1.2914621038362384e-05
sam_encoder.blocks.4.norm1.bias grad: -6.8843955887132324e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.097511919098906e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0788859299282194e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.1655904422223102e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.055553290527314e-06
sam_encoder.blocks.4.norm2.weight grad: -7.489448989872471e-07
sam_encoder.blocks.4.norm2.bias grad: -9.843975931289606e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.436652832533582e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.4946030524320975e-10
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.227882633742411e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.5336968267074553e-06
sam_encoder.blocks.5.norm1.weight grad: 8.628764589957427e-06
sam_encoder.blocks.5.norm1.bias grad: -1.3377551795201725e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.218092726659961e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.991431185568217e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.1229480959591456e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.243934770580381e-06
sam_encoder.blocks.5.norm2.weight grad: 8.027204785321373e-06
sam_encoder.blocks.5.norm2.bias grad: -9.143977877101861e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.226098099024966e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.5156051631493028e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.064313768343709e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.7650861511574476e-07
sam_encoder.blocks.6.norm1.weight grad: 8.42462122818688e-06
sam_encoder.blocks.6.norm1.bias grad: 5.4898273447179236e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.913959855912253e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.32047305721062e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9747767510125414e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.6349239306000527e-06
sam_encoder.blocks.6.norm2.weight grad: -2.2909566723683383e-06
sam_encoder.blocks.6.norm2.bias grad: -5.143946509633679e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0167090067625395e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.137145938580943e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.0475331439229194e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.9557155610527843e-06
sam_encoder.blocks.7.norm1.weight grad: 1.6339524790964788e-06
sam_encoder.blocks.7.norm1.bias grad: 1.6832241271913517e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.5869021581238485e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.160675300430739e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.724517460388597e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.803680561351939e-06
sam_encoder.blocks.7.norm2.weight grad: 5.755181973654544e-06
sam_encoder.blocks.7.norm2.bias grad: -7.283989589268458e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.166348960803589e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.621162255105446e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.160556828646804e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.8306620859220857e-06
sam_encoder.blocks.8.norm1.weight grad: 1.945765461641713e-06
sam_encoder.blocks.8.norm1.bias grad: -2.947471102743293e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.8240192477824166e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.804533990769414e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.327464921516366e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.988040589320008e-06
sam_encoder.blocks.8.norm2.weight grad: 8.561280083085876e-06
sam_encoder.blocks.8.norm2.bias grad: 2.720536940614693e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.212873242679052e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.3793488657684065e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.2731486498960294e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.635603439353872e-07
sam_encoder.blocks.9.norm1.weight grad: 3.0444632557191653e-06
sam_encoder.blocks.9.norm1.bias grad: 1.2252510259713745e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.567181243444793e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1787901712523308e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.296717982768314e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9792680632235715e-06
sam_encoder.blocks.9.norm2.weight grad: 8.103210348053835e-06
sam_encoder.blocks.9.norm2.bias grad: 1.9602202883106656e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.934995558869559e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.968515900647617e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.799315706487505e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.345362978914636e-07
sam_encoder.blocks.10.norm1.weight grad: 6.0141719586681575e-06
sam_encoder.blocks.10.norm1.bias grad: 2.9305701332305034e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.573198000594857e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5534385511273285e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6655039871693589e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.020127673560637e-07
sam_encoder.blocks.10.norm2.weight grad: 1.7159993149107322e-05
sam_encoder.blocks.10.norm2.bias grad: 3.2434086278954055e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 8.989300113171339e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.8456723814306315e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.2097397049947176e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.091267212264938e-07
sam_encoder.blocks.11.norm1.weight grad: 2.0869139916612767e-05
sam_encoder.blocks.11.norm1.bias grad: -6.777235057597863e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.445251539029414e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0298065262759337e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.321975782455411e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2950729342264822e-06
sam_encoder.blocks.11.norm2.weight grad: 1.9587510905694216e-05
sam_encoder.blocks.11.norm2.bias grad: 6.770582672288583e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.723083738004789e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.4151044019381516e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.470845844181895e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.622910965845222e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.9246093617985025e-06
sam_encoder.neck.conv1.trainable_shift grad: 4.2604264308465645e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.775585016934201e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.708014264702797e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.363187564304098e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.870547516271472e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004382782150059938
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0012547348160296679
mask_decoder.transformer.layers.0.norm3.weight grad: 3.104968345724046e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.545524618355557e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.335072536487132e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.939703209558502e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.1896872820216231e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.877586095768493e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00019601330859586596
mask_decoder.transformer.layers.1.norm2.bias grad: -1.9558618078008294e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.3807865444687195e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -4.849251126870513e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -8.925030124373734e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014270248357206583
mask_decoder.transformer.norm_final_attn.weight grad: 9.884699920803541e-07
mask_decoder.transformer.norm_final_attn.bias grad: 3.3183600862685125e-06
Text_Embedding_Affine.0.weight grad: 2.872975295165059e-13
Text_Embedding_Affine.0.bias grad: -9.973536579943598e-11
Text_Embedding_Affine.2.weight grad: 6.85642237430173e-11
Text_Embedding_Affine.2.bias grad: -2.6553741918178275e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.3731650805890467e-10
Max value: 0.9963866472244263
Mean value: 0.10948577523231506

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.3731650805890467e-10
Max value: 0.9963866472244263
Mean value: 0.10948577523231506

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11010932922363281

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1355191469192505

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10107707977294922

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11010932922363281

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.33063888549805
Max value: 78.42167663574219
Mean value: 69.5228271484375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.8675606333905534e-10
Max value: 0.9966917037963867
Mean value: 0.11283453553915024

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.8675606333905534e-10
Max value: 0.9966917037963867
Mean value: 0.11283453553915024

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.8675606333905534e-10
Max value: 0.9966917037963867
Mean value: 0.11283453553915024

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13549837470054626

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7101341485977173
Max value: 1.4180614948272705
Mean value: 1.0001927614212036

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.33063888549805
Max value: 78.42167663574219
Mean value: 69.5228271484375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.53650665283203
Max value: -69.53650665283203
Mean value: -69.53650665283203
sam_encoder.pos_embed grad: -3.2986782194655007e-09
sam_encoder.blocks.0.norm1.weight grad: 3.603670120355673e-05
sam_encoder.blocks.0.norm1.bias grad: 1.0507801562198438e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.7460397430113517e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.288112561174785e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.8434558316803304e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.816285349486861e-07
sam_encoder.blocks.0.norm2.weight grad: 1.5341795005952008e-05
sam_encoder.blocks.0.norm2.bias grad: 5.150924607733032e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.268267159408424e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.30737589643104e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.6055028027039953e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.789203452062793e-09
sam_encoder.blocks.1.norm1.weight grad: -4.909667836727749e-07
sam_encoder.blocks.1.norm1.bias grad: 3.285520278950571e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.3318865462206304e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2271887044335017e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.8809422474296298e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.044454489208874e-07
sam_encoder.blocks.1.norm2.weight grad: 4.715214345196728e-06
sam_encoder.blocks.1.norm2.bias grad: -5.97463713347679e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.064033641450806e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.557117457196e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.813332687561342e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.55139491148293e-07
sam_encoder.blocks.2.norm1.weight grad: -8.762508514337242e-06
sam_encoder.blocks.2.norm1.bias grad: 2.488660811650334e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.699002147390274e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8329074009670876e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.1672961995354854e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.9768876882153563e-06
sam_encoder.blocks.2.norm2.weight grad: -2.4007833872019546e-06
sam_encoder.blocks.2.norm2.bias grad: 5.530440461143371e-08
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.6430898313046782e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.396264886163408e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 7.738913154753391e-08
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.4909498702309065e-07
sam_encoder.blocks.3.norm1.weight grad: -5.1942110985692125e-06
sam_encoder.blocks.3.norm1.bias grad: -1.7946906609722646e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.5672798074083403e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.023662528306886e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.367439092016866e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.25165830822516e-07
sam_encoder.blocks.3.norm2.weight grad: 4.546582204056904e-06
sam_encoder.blocks.3.norm2.bias grad: -2.2518042896990664e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.298792075336678e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.6895577320829034e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.4309971447801217e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.09976201151585e-07
sam_encoder.blocks.4.norm1.weight grad: -4.079545760760084e-06
sam_encoder.blocks.4.norm1.bias grad: -1.5601069662807276e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.3729380725635565e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.398301598484977e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.879620180669008e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.397009997272107e-07
sam_encoder.blocks.4.norm2.weight grad: -4.445778358785901e-06
sam_encoder.blocks.4.norm2.bias grad: -5.390938440541504e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.820441295625642e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.040092668830766e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.731175178880221e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.766590215396718e-08
sam_encoder.blocks.5.norm1.weight grad: -5.128719749336597e-06
sam_encoder.blocks.5.norm1.bias grad: 1.3626162171931355e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.001280664553633e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.6054550491826376e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.4549929971963138e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2897887700091815e-06
sam_encoder.blocks.5.norm2.weight grad: -6.849840019640396e-07
sam_encoder.blocks.5.norm2.bias grad: -5.160472028364893e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.317493454029318e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.1545823781489162e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.850938802926976e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.037093279090186e-07
sam_encoder.blocks.6.norm1.weight grad: -3.7617060115735512e-06
sam_encoder.blocks.6.norm1.bias grad: 1.7952243069885299e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.9583829928014893e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.2124428394599818e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.844270738933119e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.261437756118539e-07
sam_encoder.blocks.6.norm2.weight grad: -1.8670452845981345e-06
sam_encoder.blocks.6.norm2.bias grad: -1.0392809599579778e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3902524642617209e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.344867968100516e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.996132017571654e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.335919416258548e-07
sam_encoder.blocks.7.norm1.weight grad: 5.303502916831349e-07
sam_encoder.blocks.7.norm1.bias grad: 1.2443156265362632e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.832435926502512e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.1605097682831911e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3701321677217493e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.645117759442655e-07
sam_encoder.blocks.7.norm2.weight grad: 3.4831525681511266e-06
sam_encoder.blocks.7.norm2.bias grad: 1.0575765827525174e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.929113295773277e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.51864763010235e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.318502698832162e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.862559990215232e-07
sam_encoder.blocks.8.norm1.weight grad: 6.00571411268902e-07
sam_encoder.blocks.8.norm1.bias grad: -4.280067003037402e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.6246647192019736e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.607192742398183e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.0213760788246873e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.336046544040073e-08
sam_encoder.blocks.8.norm2.weight grad: 2.222964894826873e-06
sam_encoder.blocks.8.norm2.bias grad: -1.1995941804343602e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.440436674078228e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2789630545739783e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.105880849347159e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.249262358120177e-09
sam_encoder.blocks.9.norm1.weight grad: 2.460464827436226e-07
sam_encoder.blocks.9.norm1.bias grad: 5.175907062948681e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.869897610315093e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.729693164837954e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.2606279748724774e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.5926984764955705e-07
sam_encoder.blocks.9.norm2.weight grad: 3.396887905182666e-06
sam_encoder.blocks.9.norm2.bias grad: -3.6734064678967115e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.864443558792118e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.6157682694029063e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.72309534921078e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.3895079809553863e-07
sam_encoder.blocks.10.norm1.weight grad: 3.585028935049195e-06
sam_encoder.blocks.10.norm1.bias grad: 2.520666839700425e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.7801015676232055e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0195290087722242e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.042500437317358e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.8101359223219333e-07
sam_encoder.blocks.10.norm2.weight grad: 4.839229404751677e-06
sam_encoder.blocks.10.norm2.bias grad: -4.3791919779323507e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.857894742192002e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.5202789427348762e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.326435399879756e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.8448357625165954e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2455248906917404e-05
sam_encoder.blocks.11.norm1.bias grad: -1.6562444216106087e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.6861536045762477e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.23219206216163e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.7060154959835927e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.806164497495047e-07
sam_encoder.blocks.11.norm2.weight grad: 4.111737325729337e-06
sam_encoder.blocks.11.norm2.bias grad: -7.437831186507537e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.8467029551393352e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.717923722339037e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.902124939893838e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.224062877256074e-09
sam_encoder.neck.conv1.trainable_scale grad: 5.611764208879322e-08
sam_encoder.neck.conv1.trainable_shift grad: -5.063842763775028e-06
sam_encoder.neck.conv2.trainable_scale grad: -9.421091817785054e-08
sam_encoder.neck.conv2.trainable_shift grad: 2.914221113314852e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 5.3967032727086917e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -9.200448403134942e-09
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0054545169696211815
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005498933023773134
mask_decoder.transformer.layers.0.norm3.weight grad: -4.6285051212180406e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.1634401744231582e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.784970512147993e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.462140951654874e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.320695734350011e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.1003703548340127e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.5308756701415405e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.935847027809359e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.942432158510201e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.9722639737883583e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.4472192308166996e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00012572502600960433
mask_decoder.transformer.norm_final_attn.weight grad: 3.6489529975369805e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.570371624547988e-06
Text_Embedding_Affine.0.weight grad: -2.151850312520631e-12
Text_Embedding_Affine.0.bias grad: 1.506735014533689e-11
Text_Embedding_Affine.2.weight grad: -9.30904658913434e-14
Text_Embedding_Affine.2.bias grad: -5.500633051269688e-06
Epoch 36 finished with average loss: -63.8985
Epoch 37/39
----------
Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.6]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-64.6]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-62.6]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-62.6]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-62.2]Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-62.2]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8050860285667714e-12
Max value: 0.9982183575630188
Mean value: 0.08850906789302826

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8050860285667714e-12
Max value: 0.9982183575630188
Mean value: 0.08850906789302826

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08728551864624023

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.812421798706055
Max value: -1.1920928244535389e-07
Mean value: -0.11702459305524826

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08141565322875977

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08728551864624023

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 53.3297233581543
Max value: 89.70027160644531
Mean value: 64.63752746582031

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8050860285667714e-12
Max value: 0.9982183575630188
Mean value: 0.08850906789302826

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8050860285667714e-12
Max value: 0.9982183575630188
Mean value: 0.08850906789302826

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8050860285667714e-12
Max value: 0.9982183575630188
Mean value: 0.08850906789302826

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.812421798706055
Max value: -1.1920928244535389e-07
Mean value: -0.11702459305524826

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 53.3297233581543
Max value: 89.70027160644531
Mean value: 64.63752746582031

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.63863372802734
Max value: -64.63863372802734
Mean value: -64.63863372802734
sam_encoder.pos_embed grad: -1.1290488544091204e-09
sam_encoder.blocks.0.norm1.weight grad: 3.7468365917447954e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0250585546600632e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.2880203687236644e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.389034984342288e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.302756911376491e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.2527366379799787e-06
sam_encoder.blocks.0.norm2.weight grad: 1.2221893484820612e-05
sam_encoder.blocks.0.norm2.bias grad: -1.55756115418626e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9333663203724427e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.2372178161967895e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.017676004266832e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.800540753218229e-06
sam_encoder.blocks.1.norm1.weight grad: -3.781293344218284e-06
sam_encoder.blocks.1.norm1.bias grad: 1.7247866708203219e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.7506958960875636e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.3931102103015292e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.209841335978126e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.8306222955288831e-06
sam_encoder.blocks.1.norm2.weight grad: -3.2324390986104845e-07
sam_encoder.blocks.1.norm2.bias grad: 4.65707307739649e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.800829633997637e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2691945983078767e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.766790764027974e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.10810661278083e-07
sam_encoder.blocks.2.norm1.weight grad: -1.2981672625755891e-05
sam_encoder.blocks.2.norm1.bias grad: 1.5906814496702282e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.882110705599189e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8977073068526806e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.884296347678173e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.4993464674262214e-06
sam_encoder.blocks.2.norm2.weight grad: -7.320335043914383e-06
sam_encoder.blocks.2.norm2.bias grad: -8.648009384160105e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.181721917324467e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.922137577523245e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.4031282919168007e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.172128799633356e-07
sam_encoder.blocks.3.norm1.weight grad: 1.066376171365846e-06
sam_encoder.blocks.3.norm1.bias grad: 5.377221441449365e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.6108578999337624e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.0483073487630463e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.0726588445540983e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.0868294566535042e-06
sam_encoder.blocks.3.norm2.weight grad: -1.2407188478391618e-05
sam_encoder.blocks.3.norm2.bias grad: -4.2076808313140646e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0400663995824289e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.9543057280534413e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.253207069064956e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1356876257195836e-06
sam_encoder.blocks.4.norm1.weight grad: -9.82189931164612e-07
sam_encoder.blocks.4.norm1.bias grad: -1.7472556237407844e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.921447048720438e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.493757721022121e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.598268338260823e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.069065428462636e-07
sam_encoder.blocks.4.norm2.weight grad: 6.613555342482869e-06
sam_encoder.blocks.4.norm2.bias grad: 1.3425468523564632e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.0176094039925374e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.5133441517464234e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.437664185592439e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.979156074114144e-07
sam_encoder.blocks.5.norm1.weight grad: 3.7101860925758956e-06
sam_encoder.blocks.5.norm1.bias grad: -1.8210561165687977e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.1371033653849736e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.894360922160558e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.220643071064842e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.3435077335088863e-06
sam_encoder.blocks.5.norm2.weight grad: 4.537047061603516e-06
sam_encoder.blocks.5.norm2.bias grad: -9.406597882843926e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.729233976126125e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.277461644302093e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.352025133717689e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.239895438715394e-08
sam_encoder.blocks.6.norm1.weight grad: -6.438201012315403e-07
sam_encoder.blocks.6.norm1.bias grad: -2.5382846615684684e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.194039896290633e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.6892544181246194e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2453381259547314e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1681807876584571e-07
sam_encoder.blocks.6.norm2.weight grad: 3.38460881721403e-06
sam_encoder.blocks.6.norm2.bias grad: 1.267420657313778e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.5307706980347575e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.990328043661066e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.565247071601334e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.2217338369046047e-07
sam_encoder.blocks.7.norm1.weight grad: 2.2974533919750684e-07
sam_encoder.blocks.7.norm1.bias grad: -1.5244636415445711e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.127616304889671e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.3794532328101923e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.573233584575064e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.8898466553073376e-07
sam_encoder.blocks.7.norm2.weight grad: 9.791285719984444e-07
sam_encoder.blocks.7.norm2.bias grad: -1.2327606100370758e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.356746793135244e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.4432165462707758e-09
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.9245325094962027e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.404472176451236e-07
sam_encoder.blocks.8.norm1.weight grad: 1.070082589649246e-06
sam_encoder.blocks.8.norm1.bias grad: -8.764671832750537e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0330442137274076e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.435282102756901e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.4809775166213512e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.040824145093211e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0079601224788348e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5047202168716467e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.0723251762101427e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.5481614329692093e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.727921461584629e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.829453104093773e-08
sam_encoder.blocks.9.norm1.weight grad: 1.0251550293105538e-06
sam_encoder.blocks.9.norm1.bias grad: -6.314530764939263e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.2445883018917812e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.1726864335723803e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.394800695057711e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.115631497825234e-07
sam_encoder.blocks.9.norm2.weight grad: 2.4968262550828513e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6089707060018554e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.2743341193963715e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.786902299107169e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.2500001957960194e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.728175432930584e-07
sam_encoder.blocks.10.norm1.weight grad: -2.398306378381676e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1864183306897758e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.58252203164011e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.616987207053171e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.0121805189555744e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.4075751525742817e-07
sam_encoder.blocks.10.norm2.weight grad: 7.996258659659361e-07
sam_encoder.blocks.10.norm2.bias grad: 1.2136382565586246e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.1389401777250896e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.896445453070555e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.690030537967687e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.664768482598447e-07
sam_encoder.blocks.11.norm1.weight grad: -7.808378541085403e-06
sam_encoder.blocks.11.norm1.bias grad: 8.37102675177448e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.176234374928754e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -9.210181701746478e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.2526618320407579e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.5961600158552756e-07
sam_encoder.blocks.11.norm2.weight grad: 5.809479262097739e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2276294683033484e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.3628213082483853e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.133243565884186e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.1804085008625407e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.073519784877135e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.451179170748219e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.4331921192933805e-05
sam_encoder.neck.conv2.trainable_scale grad: 9.46989530348219e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.785074558341876e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00011592030205065385
mask_decoder.transformer.layers.0.norm1.bias grad: 1.843800419010222e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005263269878923893
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00034032465191558003
mask_decoder.transformer.layers.0.norm3.weight grad: -7.362792530329898e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -2.4357137590413913e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.731982572702691e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.262144547188655e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.5162640415364876e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.1930178516195156e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.816414416884072e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -7.220052793854848e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.613462781184353e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.753276880364865e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.242940874770284e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00011181937588844448
mask_decoder.transformer.norm_final_attn.weight grad: -3.661893970274832e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.887105650501326e-06
Text_Embedding_Affine.0.weight grad: 1.6086715293184284e-11
Text_Embedding_Affine.0.bias grad: 5.708057915221332e-10
Text_Embedding_Affine.2.weight grad: 5.5743736016022893e-11
Text_Embedding_Affine.2.bias grad: -2.5905490474542603e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2095980684093122e-12
Max value: 0.9980484247207642
Mean value: 0.08749198913574219

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2095980684093122e-12
Max value: 0.9980484247207642
Mean value: 0.08749198913574219

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08614444732666016

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11567696928977966

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0784921646118164

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08614444732666016

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.69614791870117
Max value: 83.51726531982422
Mean value: 60.53021240234375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9747814494763816e-12
Max value: 0.9978474378585815
Mean value: 0.08864012360572815

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9747814494763816e-12
Max value: 0.9978474378585815
Mean value: 0.08864012360572815

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9747814494763816e-12
Max value: 0.9978474378585815
Mean value: 0.08864012360572815

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11575192213058472

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9148540496826172
Max value: 1.36296546459198
Mean value: 0.9999615550041199

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.69614791870117
Max value: 83.51726531982422
Mean value: 60.53021240234375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.52943420410156
Max value: -60.52943420410156
Mean value: -60.52943420410156
sam_encoder.pos_embed grad: 1.919885361800766e-09
sam_encoder.blocks.0.norm1.weight grad: -5.634440094581805e-05
sam_encoder.blocks.0.norm1.bias grad: 1.7583066437509842e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.2664578409603564e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.390746420947835e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.4081083413184388e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.044189942462253e-07
sam_encoder.blocks.0.norm2.weight grad: -2.2182844077178743e-06
sam_encoder.blocks.0.norm2.bias grad: 3.8491340092150494e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.0540041330386885e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -9.602548516340903e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.956373580469517e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.3991954972425447e-07
sam_encoder.blocks.1.norm1.weight grad: 1.3850104551238474e-05
sam_encoder.blocks.1.norm1.bias grad: 6.952827789064031e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.2907836359518114e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.014807705563726e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.066277935839025e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.4237494926637737e-06
sam_encoder.blocks.1.norm2.weight grad: 1.889787927211728e-05
sam_encoder.blocks.1.norm2.bias grad: 2.8667732294707093e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.2392909967456944e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3454663303491543e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.2988375601707958e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.4265200408990495e-06
sam_encoder.blocks.2.norm1.weight grad: 1.6642818081891164e-05
sam_encoder.blocks.2.norm1.bias grad: 3.078409235968138e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.07957748696208e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.0134602891630493e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.900391675415449e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.319606099059456e-06
sam_encoder.blocks.2.norm2.weight grad: -8.80877450981643e-06
sam_encoder.blocks.2.norm2.bias grad: 8.654685188957956e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.875965143786743e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.8003487386740744e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.603067912332335e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8020026573140058e-06
sam_encoder.blocks.3.norm1.weight grad: -1.3927068721386604e-05
sam_encoder.blocks.3.norm1.bias grad: -1.2198015610920265e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.932186806807294e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.461690193442337e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.9612581304027117e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.2057375897711609e-06
sam_encoder.blocks.3.norm2.weight grad: 1.4755945798583525e-08
sam_encoder.blocks.3.norm2.bias grad: 1.0671625204849988e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.8206018239652622e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.845238330133725e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.9767230696743354e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.981006895832252e-07
sam_encoder.blocks.4.norm1.weight grad: -1.9785467884503305e-05
sam_encoder.blocks.4.norm1.bias grad: -5.868672587894253e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.130847795138834e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.511225713737076e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.0681226209926535e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.011182798218215e-06
sam_encoder.blocks.4.norm2.weight grad: 2.465523493810906e-06
sam_encoder.blocks.4.norm2.bias grad: 3.077390374528477e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.7805406261904864e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 9.476484024162346e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.2727416560665006e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.421582944924012e-07
sam_encoder.blocks.5.norm1.weight grad: -5.761991815234069e-06
sam_encoder.blocks.5.norm1.bias grad: 2.599830395411118e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.7775317218138298e-08
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.074571969184035e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.9641313403772074e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.139343556948006e-06
sam_encoder.blocks.5.norm2.weight grad: -2.3800996586942347e-06
sam_encoder.blocks.5.norm2.bias grad: 6.779040404580883e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.800383301997499e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1060776614613133e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.227989845479897e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0034692650151555e-06
sam_encoder.blocks.6.norm1.weight grad: -1.6839744603203144e-06
sam_encoder.blocks.6.norm1.bias grad: 2.997459887410514e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.25410440179985e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.073646770550113e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.63842866338382e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.57605141896056e-07
sam_encoder.blocks.6.norm2.weight grad: 4.90793581775506e-06
sam_encoder.blocks.6.norm2.bias grad: 3.999279670097167e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.698238859011326e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.4257364000513917e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.6725222091481555e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.3855295694374945e-07
sam_encoder.blocks.7.norm1.weight grad: 3.890477728418773e-06
sam_encoder.blocks.7.norm1.bias grad: 2.0382312868605368e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.327086571720429e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.5229908260371303e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5606792658218183e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2280288501642644e-06
sam_encoder.blocks.7.norm2.weight grad: 2.213687366747763e-07
sam_encoder.blocks.7.norm2.bias grad: -4.1950761442421935e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.225792609868222e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.6494027477165218e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0829726306837983e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.319379852153361e-07
sam_encoder.blocks.8.norm1.weight grad: -2.0715237951662857e-06
sam_encoder.blocks.8.norm1.bias grad: 2.006356226047501e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.023629571747733e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.711438244456076e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.3181142217463275e-08
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3857791145710507e-06
sam_encoder.blocks.8.norm2.weight grad: 8.175760513040586e-07
sam_encoder.blocks.8.norm2.bias grad: -9.746739806359983e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.238395609310828e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2196055649837945e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.905816351514659e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.545623374317074e-07
sam_encoder.blocks.9.norm1.weight grad: -7.699967454755097e-07
sam_encoder.blocks.9.norm1.bias grad: 7.654134037693439e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.829115761775029e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.659308494112338e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.416016849972948e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.7276364587814896e-06
sam_encoder.blocks.9.norm2.weight grad: 3.3156770768982824e-06
sam_encoder.blocks.9.norm2.bias grad: -7.17319494469848e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.872946308547398e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.158054030587664e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.8575885835380177e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.7504672200630012e-07
sam_encoder.blocks.10.norm1.weight grad: 3.4037427667499287e-06
sam_encoder.blocks.10.norm1.bias grad: 9.438796269023442e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.034281235159142e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.367968575839768e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.852413770910061e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.171849058020598e-08
sam_encoder.blocks.10.norm2.weight grad: 1.7949907942238497e-06
sam_encoder.blocks.10.norm2.bias grad: -3.736281087185489e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.970078074009507e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.371966373488249e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3887454315408831e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.6763071875611786e-07
sam_encoder.blocks.11.norm1.weight grad: 1.3436270819511265e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6264882560790284e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.457325308569125e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.316919526876518e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.4007397314562695e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.707637905696174e-07
sam_encoder.blocks.11.norm2.weight grad: -6.585899882338708e-06
sam_encoder.blocks.11.norm2.bias grad: -3.447133622103138e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4279446531872964e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.791645657562185e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.8286201541050104e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.365734854327457e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0852236300706863e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.0486589821521193e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.524584488128312e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.621080734068528e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015992802218534052
mask_decoder.transformer.layers.0.norm1.bias grad: -3.641471266746521e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00401954585686326
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00011958193499594927
mask_decoder.transformer.layers.0.norm3.weight grad: 4.953429015586153e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 8.927701856009662e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 9.683870302978903e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.14711654331768e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.517711931839585e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.543429673096398e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -9.24704218050465e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.334639819106087e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.12530537485145e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.5941597414202988e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.933860277058557e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013488919648807496
mask_decoder.transformer.norm_final_attn.weight grad: 5.659425823978381e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0458751603437122e-05
Text_Embedding_Affine.0.weight grad: 4.033378839252144e-11
Text_Embedding_Affine.0.bias grad: 1.3416361355211848e-09
Text_Embedding_Affine.2.weight grad: 2.2864198381822298e-11
Text_Embedding_Affine.2.bias grad: 3.2481762900715694e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.350295281622788e-12
Max value: 0.998467743396759
Mean value: 0.07172922790050507

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.350295281622788e-12
Max value: 0.998467743396759
Mean value: 0.07172922790050507

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07268524169921875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.827746391296387
Max value: -1.1920928244535389e-07
Mean value: -0.10421088337898254

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06601905822753906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07268524169921875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 54.4962158203125
Max value: 66.93451690673828
Mean value: 61.305702209472656

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.397076874637865e-12
Max value: 0.9984446167945862
Mean value: 0.07342661917209625

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.397076874637865e-12
Max value: 0.9984446167945862
Mean value: 0.07342661917209625

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.397076874637865e-12
Max value: 0.9984446167945862
Mean value: 0.07342661917209625

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.686440467834473
Max value: -1.1920928244535389e-07
Mean value: -0.10428935289382935

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8665196895599365
Max value: 1.2689305543899536
Mean value: 0.9999973773956299

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 54.4962158203125
Max value: 66.93451690673828
Mean value: 61.305702209472656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.30517578125
Max value: -61.30517578125
Mean value: -61.30517578125
sam_encoder.pos_embed grad: -1.0081037116194125e-09
sam_encoder.blocks.0.norm1.weight grad: -2.1950377231405582e-06
sam_encoder.blocks.0.norm1.bias grad: 1.593379602127243e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.4969843959988793e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.187811211726512e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.990257012759685e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.589471759823937e-07
sam_encoder.blocks.0.norm2.weight grad: 1.3490857782016974e-05
sam_encoder.blocks.0.norm2.bias grad: -3.888446372002363e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4184444808051921e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.965094492741628e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4204015315044671e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.050627921969863e-06
sam_encoder.blocks.1.norm1.weight grad: -1.4818414456385653e-05
sam_encoder.blocks.1.norm1.bias grad: -1.2138532838434912e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.7932666095439345e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.0095391189679503e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.9095895115460735e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.5240918855852215e-06
sam_encoder.blocks.1.norm2.weight grad: 3.0072278605075553e-06
sam_encoder.blocks.1.norm2.bias grad: 4.308733878133353e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.016327430164893e-08
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.974401749928802e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.0163308767660055e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.498883067251882e-07
sam_encoder.blocks.2.norm1.weight grad: -2.119565397151746e-05
sam_encoder.blocks.2.norm1.bias grad: 7.162345355027355e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0942401786451228e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.799779506152845e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.948522357357433e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.902997832483379e-06
sam_encoder.blocks.2.norm2.weight grad: -6.833922725490993e-06
sam_encoder.blocks.2.norm2.bias grad: 7.183208708738675e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.00903570355149e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.9036626497381803e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.833333383023273e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.390822887969989e-07
sam_encoder.blocks.3.norm1.weight grad: -4.293295205570757e-06
sam_encoder.blocks.3.norm1.bias grad: 2.8802019187423866e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.281612862338079e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6171309198398376e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.880385181924794e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.4026304547296604e-06
sam_encoder.blocks.3.norm2.weight grad: -2.6525563953327946e-05
sam_encoder.blocks.3.norm2.bias grad: -1.0694653610698879e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.1068908608867787e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.14699399395613e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.0357329049147666e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.4537195031371084e-07
sam_encoder.blocks.4.norm1.weight grad: 2.9437023840728216e-06
sam_encoder.blocks.4.norm1.bias grad: -1.2121683994337218e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.5240419770634617e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.5133604140137322e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.7431236756237922e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5580576473439578e-06
sam_encoder.blocks.4.norm2.weight grad: -3.3619352279856685e-07
sam_encoder.blocks.4.norm2.bias grad: -4.98995268571889e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8066921256831847e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.28214196593035e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.643671672965866e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.6955027604126371e-06
sam_encoder.blocks.5.norm1.weight grad: -3.350927499923273e-06
sam_encoder.blocks.5.norm1.bias grad: 4.789832019014284e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.321283075929387e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.80496520746965e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.508591023797635e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.457182166741404e-07
sam_encoder.blocks.5.norm2.weight grad: 1.060153590515256e-05
sam_encoder.blocks.5.norm2.bias grad: -4.976490345143247e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.6360339688835666e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.692214462120319e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.0190759641991463e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.298472108781425e-07
sam_encoder.blocks.6.norm1.weight grad: 3.9415532171460654e-08
sam_encoder.blocks.6.norm1.bias grad: -9.57426891545765e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.6552356757747475e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.138892341463361e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.32345756154973e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.3440151980812516e-08
sam_encoder.blocks.6.norm2.weight grad: 6.432639111153549e-06
sam_encoder.blocks.6.norm2.bias grad: 1.866811089712428e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.9846006580337416e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.583932415400341e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.3180788300815038e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.778627721359953e-07
sam_encoder.blocks.7.norm1.weight grad: 2.4256685264845146e-06
sam_encoder.blocks.7.norm1.bias grad: -2.6688703655963764e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.8953799099108437e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -9.987128350985586e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.171794560330454e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.8843339805462165e-07
sam_encoder.blocks.7.norm2.weight grad: 3.16909927278175e-06
sam_encoder.blocks.7.norm2.bias grad: 1.2131825997130363e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.1188992579700425e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.0415656599179783e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.3285649553581607e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.758873840022716e-07
sam_encoder.blocks.8.norm1.weight grad: 2.2736003302270547e-06
sam_encoder.blocks.8.norm1.bias grad: 2.3572320060338825e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.751365395350149e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.988649149912817e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.590817532814981e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.525442539536016e-07
sam_encoder.blocks.8.norm2.weight grad: 3.819859557552263e-07
sam_encoder.blocks.8.norm2.bias grad: 1.7746249341143994e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.061628022915102e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.274957975918369e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.332411668248824e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.541544621541107e-07
sam_encoder.blocks.9.norm1.weight grad: 3.270649131081882e-06
sam_encoder.blocks.9.norm1.bias grad: -1.2662696917686844e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.7548549041966908e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.992635578877525e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.340988309399108e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.514797175645072e-07
sam_encoder.blocks.9.norm2.weight grad: 1.5351668025687104e-06
sam_encoder.blocks.9.norm2.bias grad: 1.4928477867215406e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.780244087347455e-08
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.195757921683253e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.08288548467317e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.148738241838146e-07
sam_encoder.blocks.10.norm1.weight grad: -9.401892384630628e-07
sam_encoder.blocks.10.norm1.bias grad: -7.953566409923951e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.275876671679725e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.5730144531953556e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.205856723478064e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.244857951922313e-08
sam_encoder.blocks.10.norm2.weight grad: -3.51664493791759e-06
sam_encoder.blocks.10.norm2.bias grad: -1.27867406263249e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.0482966647250578e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8175821878685383e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.734674116160022e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.824492342933809e-08
sam_encoder.blocks.11.norm1.weight grad: -9.868621418718249e-06
sam_encoder.blocks.11.norm1.bias grad: -9.810969459067564e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.5195884606764594e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.0808489605551586e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4576852436221088e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.4401545911368885e-07
sam_encoder.blocks.11.norm2.weight grad: -1.526573441879009e-06
sam_encoder.blocks.11.norm2.bias grad: 1.6190992369047308e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.6075649682534277e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.177707400136569e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.994253686163574e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.4466544346068986e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.1014763003913686e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.7798701921710745e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.3912581380282063e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.526878688513534e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -8.928932402341161e-06
mask_decoder.transformer.layers.0.norm1.bias grad: -1.8838836695067585e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005784986540675163
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00024302213569171727
mask_decoder.transformer.layers.0.norm3.weight grad: -2.237802982563153e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.415516064502299e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010111850133398548
mask_decoder.transformer.layers.0.norm4.bias grad: 1.229546523973113e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.655586260720156e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.600881998660043e-08
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00015439421986229718
mask_decoder.transformer.layers.1.norm2.bias grad: -6.067671347409487e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.994494156562723e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.16260993713513e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.338835762813687e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017174198001157492
mask_decoder.transformer.norm_final_attn.weight grad: -8.015151706786128e-07
mask_decoder.transformer.norm_final_attn.bias grad: -7.745036782580428e-06
Text_Embedding_Affine.0.weight grad: 1.3889024479130097e-11
Text_Embedding_Affine.0.bias grad: 8.597386691455711e-11
Text_Embedding_Affine.2.weight grad: -6.451616324509857e-11
Text_Embedding_Affine.2.bias grad: -4.616004844137933e-06
Epoch 37 finished with average loss: -62.1577
Epoch 38/39
----------
Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.14it/s, loss=-62]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.14it/s, loss=-62.3]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-62.3]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-60.9]Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.38it/s, loss=-60.9]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.717189611673888e-10
Max value: 0.9987590312957764
Mean value: 0.10538704693317413

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.717189611673888e-10
Max value: 0.9987590312957764
Mean value: 0.10538704693317413

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09886598587036133

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.736007690429688
Max value: -1.1920928244535389e-07
Mean value: -0.12850482761859894

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09740829467773438

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09886598587036133

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.11834144592285
Max value: 79.9278793334961
Mean value: 62.03971481323242

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.717189611673888e-10
Max value: 0.9987590312957764
Mean value: 0.10538704693317413

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.717189611673888e-10
Max value: 0.9987590312957764
Mean value: 0.10538704693317413

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.717189611673888e-10
Max value: 0.9987590312957764
Mean value: 0.10538704693317413

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.736007690429688
Max value: -1.1920928244535389e-07
Mean value: -0.12850482761859894

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.11834144592285
Max value: 79.9278793334961
Mean value: 62.03971481323242

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.04102325439453
Max value: -62.04102325439453
Mean value: -62.04102325439453
sam_encoder.pos_embed grad: 1.563894125311549e-09
sam_encoder.blocks.0.norm1.weight grad: 1.5769940091558965e-06
sam_encoder.blocks.0.norm1.bias grad: 4.020065716758836e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.683340873474663e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.42427097671316e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.156724233122077e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.7947650121641345e-06
sam_encoder.blocks.0.norm2.weight grad: 3.5200057027395815e-05
sam_encoder.blocks.0.norm2.bias grad: 9.978230082197115e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.611049917002674e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.4631509606697364e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.854730726336129e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.5191300210281042e-06
sam_encoder.blocks.1.norm1.weight grad: 1.2667287592194043e-05
sam_encoder.blocks.1.norm1.bias grad: 3.135399310849607e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.391701627857401e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.199707164952997e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.677154710312607e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.5690507098042872e-06
sam_encoder.blocks.1.norm2.weight grad: 5.797136964247329e-06
sam_encoder.blocks.1.norm2.bias grad: -1.575852365931496e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.040834594183252e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.3479910282730998e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.4369145446835319e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.771774122971692e-07
sam_encoder.blocks.2.norm1.weight grad: 2.80031304100703e-06
sam_encoder.blocks.2.norm1.bias grad: -6.5566359808144625e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 9.977500212698942e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.140673036725275e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.458316885167733e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.551371262095927e-07
sam_encoder.blocks.2.norm2.weight grad: -7.433783139276784e-06
sam_encoder.blocks.2.norm2.bias grad: -1.5018298427094123e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.5543708943587262e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4868155631120317e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7413984753366094e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4855598919893964e-06
sam_encoder.blocks.3.norm1.weight grad: -7.429542165482417e-06
sam_encoder.blocks.3.norm1.bias grad: -6.384428161254618e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.706092113337945e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.809795536355523e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.574129212007392e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.1338420335960109e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0921608009084594e-05
sam_encoder.blocks.3.norm2.bias grad: 5.568524557020282e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.810632268956397e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.4166618004528573e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.382119080517441e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.2060196392412763e-07
sam_encoder.blocks.4.norm1.weight grad: -1.312151880483725e-07
sam_encoder.blocks.4.norm1.bias grad: -2.713470621529268e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.2406351288518636e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.611575713577622e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.571287372025836e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.3601082571312872e-07
sam_encoder.blocks.4.norm2.weight grad: -9.805102308746427e-06
sam_encoder.blocks.4.norm2.bias grad: -6.336452770483447e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.719527613720857e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.4411166325298836e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.3954495986799884e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.263116923335474e-07
sam_encoder.blocks.5.norm1.weight grad: 2.2697231543133967e-06
sam_encoder.blocks.5.norm1.bias grad: -8.871407771948725e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.0810734920596587e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.346840789068665e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.539832722613937e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.3436140850208176e-07
sam_encoder.blocks.5.norm2.weight grad: -6.637911610596348e-06
sam_encoder.blocks.5.norm2.bias grad: -4.364343112683855e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.1837444112170488e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.3237531675258651e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.7145152848315774e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.1171636060680612e-07
sam_encoder.blocks.6.norm1.weight grad: 1.1572658422664972e-06
sam_encoder.blocks.6.norm1.bias grad: -1.553322363179177e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2510614624261507e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5906738326521008e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.271108764442033e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.484218152356334e-08
sam_encoder.blocks.6.norm2.weight grad: 1.8887667465605773e-06
sam_encoder.blocks.6.norm2.bias grad: 1.342682935501216e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.2181711781522608e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.724007567347144e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.214099468910717e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.537836773010895e-08
sam_encoder.blocks.7.norm1.weight grad: -2.051183855655836e-06
sam_encoder.blocks.7.norm1.bias grad: 1.7932629816641565e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.2382656677800696e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.373791747028008e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.963528800137283e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.1114552762592211e-06
sam_encoder.blocks.7.norm2.weight grad: 3.815895524894586e-06
sam_encoder.blocks.7.norm2.bias grad: 1.8119934566129814e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2181757231010124e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.7413096265481727e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0879421097342856e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.2093927277164767e-07
sam_encoder.blocks.8.norm1.weight grad: 4.7555539595123264e-07
sam_encoder.blocks.8.norm1.bias grad: -7.673840514144104e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.942661568449694e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.467657840403263e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.1824077356977796e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.408058427747164e-07
sam_encoder.blocks.8.norm2.weight grad: -1.6879459963092813e-06
sam_encoder.blocks.8.norm2.bias grad: -6.750944407940551e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.2920758081236272e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.451696208387148e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.108282034096192e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.874789283348946e-07
sam_encoder.blocks.9.norm1.weight grad: -2.9574052859970834e-06
sam_encoder.blocks.9.norm1.bias grad: 8.7879186594364e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.588133156677941e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.3938346177819767e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.810804850625573e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.004855903374846e-06
sam_encoder.blocks.9.norm2.weight grad: -3.829238266916946e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2819723451684695e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.3998229607968824e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.461604369978886e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1898530374310212e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.117648124221887e-07
sam_encoder.blocks.10.norm1.weight grad: -8.582718180605298e-08
sam_encoder.blocks.10.norm1.bias grad: -2.785347419376194e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1009130673755863e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.860051040443068e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.040752964509011e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.808682767063146e-08
sam_encoder.blocks.10.norm2.weight grad: -5.193511242396198e-06
sam_encoder.blocks.10.norm2.bias grad: -2.876055077649653e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.8727872657109401e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.5893544969003415e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.9001208784175105e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.183973250197596e-07
sam_encoder.blocks.11.norm1.weight grad: 6.913341167091858e-06
sam_encoder.blocks.11.norm1.bias grad: -5.55889187126013e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.5577099311012716e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.3361495727367583e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3402213880908675e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.459552656044252e-07
sam_encoder.blocks.11.norm2.weight grad: -4.153543159191031e-06
sam_encoder.blocks.11.norm2.bias grad: -1.8493794868845725e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.1470002543064766e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.192378590531007e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5927223557810066e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.912066510267323e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.540465746074915e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2473881724872626e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.375829227385111e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.207101821724791e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018673608428798616
mask_decoder.transformer.layers.0.norm1.bias grad: -1.0697549441829324e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004817754030227661
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0008564426098018885
mask_decoder.transformer.layers.0.norm3.weight grad: -4.859089676756412e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.2398358851205558e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.969825623556972e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.649609531450551e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.232233161223121e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.0044332157121971e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 4.807100776815787e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010973693133564666
mask_decoder.transformer.layers.1.norm3.weight grad: 6.011126970406622e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.2006122132297605e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.803422365919687e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014459721569437534
mask_decoder.transformer.norm_final_attn.weight grad: 8.127920409606304e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.6302947187796235e-05
Text_Embedding_Affine.0.weight grad: 5.800779995235317e-12
Text_Embedding_Affine.0.bias grad: 4.4423900669166017e-10
Text_Embedding_Affine.2.weight grad: 7.830973716704825e-12
Text_Embedding_Affine.2.bias grad: 4.745111073134467e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.213922609631494e-12
Max value: 0.9990921020507812
Mean value: 0.07866142690181732

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.213922609631494e-12
Max value: 0.9990921020507812
Mean value: 0.07866142690181732

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07613611221313477

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.586627006530762
Max value: -1.1920928244535389e-07
Mean value: -0.10457412898540497

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07158517837524414

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07613611221313477

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 56.04442596435547
Max value: 87.04637145996094
Mean value: 62.50562286376953

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.559348984108704e-12
Max value: 0.9990992546081543
Mean value: 0.07905012369155884

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.559348984108704e-12
Max value: 0.9990992546081543
Mean value: 0.07905012369155884

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.559348984108704e-12
Max value: 0.9990992546081543
Mean value: 0.07905012369155884

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.556808471679688
Max value: -1.1920928244535389e-07
Mean value: -0.10458555817604065

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9633581042289734
Max value: 1.1427996158599854
Mean value: 0.9999938011169434

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 56.04442596435547
Max value: 87.04637145996094
Mean value: 62.50562286376953

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.506126403808594
Max value: -62.506126403808594
Mean value: -62.506126403808594
sam_encoder.pos_embed grad: 2.672090548827555e-09
sam_encoder.blocks.0.norm1.weight grad: 8.646386413602158e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0924753951258026e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.2719381124479696e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.578942593980173e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.6797348507679999e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.610796840002877e-07
sam_encoder.blocks.0.norm2.weight grad: -5.07879231008701e-05
sam_encoder.blocks.0.norm2.bias grad: -1.8006623577093706e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.7460176877648337e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.3593344192486256e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.0612810001475736e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.090846338542178e-06
sam_encoder.blocks.1.norm1.weight grad: -8.480736141791567e-06
sam_encoder.blocks.1.norm1.bias grad: 5.629997303913115e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.226145498862024e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.7472224246594124e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.384808330039959e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.9322670747642405e-06
sam_encoder.blocks.1.norm2.weight grad: -6.06497451371979e-06
sam_encoder.blocks.1.norm2.bias grad: -7.547949280706234e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.848463509508292e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.2670126276789233e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.3303669927991e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.380218226491706e-07
sam_encoder.blocks.2.norm1.weight grad: -1.2637417057703715e-05
sam_encoder.blocks.2.norm1.bias grad: 1.7764471067494014e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0402228326711338e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.0416459847183432e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5857240214245394e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.7487363379586895e-07
sam_encoder.blocks.2.norm2.weight grad: 2.8073050089005847e-06
sam_encoder.blocks.2.norm2.bias grad: 5.036206403019605e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.1229756182729034e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.1847779407835333e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.09931146047893e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5193689932857524e-06
sam_encoder.blocks.3.norm1.weight grad: 8.4624389273813e-06
sam_encoder.blocks.3.norm1.bias grad: 1.865445824478229e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.616016667569056e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 9.38574430620065e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.53400918634361e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.072435886992025e-07
sam_encoder.blocks.3.norm2.weight grad: -1.205343141919002e-05
sam_encoder.blocks.3.norm2.bias grad: -1.7503858543932438e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.253154530597385e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.9578493417357095e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.044042270834325e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.947473826177884e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0216748705715872e-05
sam_encoder.blocks.4.norm1.bias grad: -1.8849548268917715e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.77020546188578e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.6131848497025203e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.162881284879404e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.3214042812469415e-06
sam_encoder.blocks.4.norm2.weight grad: 1.772615360096097e-05
sam_encoder.blocks.4.norm2.bias grad: 1.34713263832964e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.2645202332350891e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.1110046115354635e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.6924643659876892e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.296778908814304e-07
sam_encoder.blocks.5.norm1.weight grad: -5.866346327820793e-06
sam_encoder.blocks.5.norm1.bias grad: 2.3079762456745812e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.4638036393298535e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.538701988276443e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.190345187751518e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.923710422299337e-07
sam_encoder.blocks.5.norm2.weight grad: 7.4881090768030845e-06
sam_encoder.blocks.5.norm2.bias grad: 1.189136810353375e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.309654064447386e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 8.392712516069878e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.405795387654507e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.370876816508826e-07
sam_encoder.blocks.6.norm1.weight grad: -6.72408486934728e-06
sam_encoder.blocks.6.norm1.bias grad: -2.9710677154071163e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.949389338231413e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.64512607625511e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2878006145911058e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.4244847079680767e-07
sam_encoder.blocks.6.norm2.weight grad: 7.018766609689919e-06
sam_encoder.blocks.6.norm2.bias grad: 3.6188982903695432e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.678835011873161e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.8918904061138164e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.61752340597377e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.2384940002193616e-07
sam_encoder.blocks.7.norm1.weight grad: -6.9799061748199165e-06
sam_encoder.blocks.7.norm1.bias grad: 6.791862574573315e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.494130164152011e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.06335641653277e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.9563133264455246e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.882611103264935e-08
sam_encoder.blocks.7.norm2.weight grad: 2.135760041710455e-06
sam_encoder.blocks.7.norm2.bias grad: 5.653024572893628e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.4934252021703287e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.791031973487407e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.1395711630466394e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.301287847534695e-07
sam_encoder.blocks.8.norm1.weight grad: -3.379580846285535e-07
sam_encoder.blocks.8.norm1.bias grad: 1.1340696346451296e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.7591136156624998e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.6255220316452323e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -8.979664016806055e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3074544540359057e-06
sam_encoder.blocks.8.norm2.weight grad: 2.4576092982897535e-06
sam_encoder.blocks.8.norm2.bias grad: 3.4345491712883813e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.789050530642271e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.939429913974891e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.510475370509084e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.276061412791023e-07
sam_encoder.blocks.9.norm1.weight grad: -8.694613597981515e-07
sam_encoder.blocks.9.norm1.bias grad: -3.0088017410889734e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.404148512549e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.5139436123427e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.675036228083627e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9516983229550533e-07
sam_encoder.blocks.9.norm2.weight grad: 1.923656753888281e-07
sam_encoder.blocks.9.norm2.bias grad: 2.539276465540752e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.939579644589685e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.28127429788583e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.7858766909739643e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.0835129532770225e-07
sam_encoder.blocks.10.norm1.weight grad: -2.4749315343797207e-06
sam_encoder.blocks.10.norm1.bias grad: -1.2400907962728525e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.2316074844420655e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.960037464727066e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.096538065023196e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.8160684450995177e-07
sam_encoder.blocks.10.norm2.weight grad: -5.937144123890903e-06
sam_encoder.blocks.10.norm2.bias grad: -3.1814101930649485e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.992170150013408e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.031552751053823e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.946070349542424e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.1979226378098247e-07
sam_encoder.blocks.11.norm1.weight grad: -1.4352906873682514e-05
sam_encoder.blocks.11.norm1.bias grad: 2.4863084036041982e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.5245595932356082e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.862761546879483e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1268218713667011e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.623270986163334e-08
sam_encoder.blocks.11.norm2.weight grad: -2.992144345626002e-06
sam_encoder.blocks.11.norm2.bias grad: -2.1979044504405465e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.8462704904086422e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -9.85041651802021e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.699867753923172e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.760913784844888e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.4897675504907966e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.297078001196496e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.067928891046904e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.1615050829714164e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -5.796369805466384e-06
mask_decoder.transformer.layers.0.norm1.bias grad: 1.6750673239585012e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0063523282296955585
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003410622593946755
mask_decoder.transformer.layers.0.norm3.weight grad: 9.183968359138817e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 4.1484221583232284e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001450716081308201
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0785459380713291e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -7.635857400600798e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -1.661794613028178e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00015824132424313575
mask_decoder.transformer.layers.1.norm2.bias grad: 1.1129448466817848e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.902539174305275e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.7710009312140755e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 5.023487756261602e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00019722030265256763
mask_decoder.transformer.norm_final_attn.weight grad: 2.326582034584135e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.938708692250657e-06
Text_Embedding_Affine.0.weight grad: 1.4143230857299738e-12
Text_Embedding_Affine.0.bias grad: 2.923664088605449e-10
Text_Embedding_Affine.2.weight grad: -1.0134422814833677e-11
Text_Embedding_Affine.2.bias grad: -3.466541602392681e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.6663442847786314e-10
Max value: 0.996539831161499
Mean value: 0.07956486195325851

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.6663442847786314e-10
Max value: 0.996539831161499
Mean value: 0.07956486195325851

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06945991516113281

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10836161673069

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06829071044921875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06945991516113281

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 39.19939422607422
Max value: 73.19226837158203
Mean value: 58.15584182739258

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.573589397147913e-10
Max value: 0.9962688684463501
Mean value: 0.08052891492843628

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.573589397147913e-10
Max value: 0.9962688684463501
Mean value: 0.08052891492843628

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.573589397147913e-10
Max value: 0.9962688684463501
Mean value: 0.08052891492843628

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10856760293245316

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9764357209205627
Max value: 1.451278805732727
Mean value: 0.9998166561126709

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 39.19939422607422
Max value: 73.19226837158203
Mean value: 58.15584182739258

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.14828872680664
Max value: -58.14828872680664
Mean value: -58.14828872680664
sam_encoder.pos_embed grad: 6.232296456687436e-09
sam_encoder.blocks.0.norm1.weight grad: 3.160744017804973e-05
sam_encoder.blocks.0.norm1.bias grad: 2.3555428924737498e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.463537273593829e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.579119945447019e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.452644695149502e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.940292349900119e-06
sam_encoder.blocks.0.norm2.weight grad: 9.153594874078408e-06
sam_encoder.blocks.0.norm2.bias grad: -1.2079747648385819e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.187324520898983e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.591475206121686e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.41762187317363e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.270566816761857e-06
sam_encoder.blocks.1.norm1.weight grad: 7.2579073275846895e-06
sam_encoder.blocks.1.norm1.bias grad: -1.2304884876357391e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.2016921522881603e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.5407121054522577e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.127517175016692e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.7450565792387351e-06
sam_encoder.blocks.1.norm2.weight grad: -1.7307111193076707e-05
sam_encoder.blocks.1.norm2.bias grad: 5.775303293376055e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.70561496715527e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2489608707255684e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.2728033804451115e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.41750979310018e-06
sam_encoder.blocks.2.norm1.weight grad: 2.185275889132754e-06
sam_encoder.blocks.2.norm1.bias grad: -6.9189372879918665e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.072207735182019e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0059184205601923e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.125057782606746e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.1548034965235274e-06
sam_encoder.blocks.2.norm2.weight grad: -5.781621439382434e-07
sam_encoder.blocks.2.norm2.bias grad: 3.590532173802785e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.613865449229706e-08
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.1162767538385197e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.682728447529371e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.1900018509768415e-06
sam_encoder.blocks.3.norm1.weight grad: -1.7202064555021934e-05
sam_encoder.blocks.3.norm1.bias grad: -3.2400484997197054e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.627564627910033e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6295728073600912e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.261914909875486e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.5121842099906644e-06
sam_encoder.blocks.3.norm2.weight grad: -7.265390195243526e-06
sam_encoder.blocks.3.norm2.bias grad: -1.1859924597956706e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.0308137765096035e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.056302587850951e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.192319243476959e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5528464700764744e-06
sam_encoder.blocks.4.norm1.weight grad: -1.516648171673296e-05
sam_encoder.blocks.4.norm1.bias grad: 4.34616003985866e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.2626705938600935e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.391824404592626e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.478394773992477e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.530898427721695e-06
sam_encoder.blocks.4.norm2.weight grad: 3.508088042281088e-08
sam_encoder.blocks.4.norm2.bias grad: 6.873276106489357e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.007813807518687e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.1987011677992996e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.446412170480471e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.599291176215047e-07
sam_encoder.blocks.5.norm1.weight grad: -2.497431978554232e-06
sam_encoder.blocks.5.norm1.bias grad: 4.259956767782569e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.103216148607316e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.283172382381963e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.8341969507673639e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.7196853150380775e-06
sam_encoder.blocks.5.norm2.weight grad: -2.804910536724492e-06
sam_encoder.blocks.5.norm2.bias grad: 4.1653342996994525e-09
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.039145435148384e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6782527154646232e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.716836663945287e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.2286178591457428e-07
sam_encoder.blocks.6.norm1.weight grad: 5.623365950668813e-07
sam_encoder.blocks.6.norm1.bias grad: -2.7528792543307645e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.8700682176131522e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.515920282865409e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6086985965557687e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.7547790182325116e-07
sam_encoder.blocks.6.norm2.weight grad: 8.77787169883959e-06
sam_encoder.blocks.6.norm2.bias grad: 4.310770691517973e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.7663304434972815e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.35158779307676e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.100640131175169e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1129264976261766e-06
sam_encoder.blocks.7.norm1.weight grad: 2.5062668100872543e-06
sam_encoder.blocks.7.norm1.bias grad: -1.0078982768391143e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.2118902052170597e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.18730336252338e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.258320238179294e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7014776858559344e-06
sam_encoder.blocks.7.norm2.weight grad: -3.059064965782454e-07
sam_encoder.blocks.7.norm2.bias grad: -1.0124465177341335e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.530583114752517e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.420591714435432e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.142530643657665e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.00183052356806e-07
sam_encoder.blocks.8.norm1.weight grad: 4.808195626537781e-06
sam_encoder.blocks.8.norm1.bias grad: 2.0459096958802547e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.848541837214725e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.6121557564474642e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.460971700202208e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.790146029634343e-06
sam_encoder.blocks.8.norm2.weight grad: -1.9527587937773205e-06
sam_encoder.blocks.8.norm2.bias grad: 6.785028006106586e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.3019804302748526e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3339351880858885e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.6852845874382183e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.273210146900965e-07
sam_encoder.blocks.9.norm1.weight grad: -1.359192538075149e-06
sam_encoder.blocks.9.norm1.bias grad: 6.023767582519213e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.2775847153534414e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.811660687664698e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.443840969590383e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.143743588727375e-06
sam_encoder.blocks.9.norm2.weight grad: -1.7771908460417762e-06
sam_encoder.blocks.9.norm2.bias grad: -4.611989368186187e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.860212023530039e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.5383669733637362e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.5941522469329357e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.9011137908364617e-07
sam_encoder.blocks.10.norm1.weight grad: -3.766532017834834e-06
sam_encoder.blocks.10.norm1.bias grad: 3.920517883670982e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.249990757263731e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.380769264069386e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.546650534895889e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.1278368106104608e-07
sam_encoder.blocks.10.norm2.weight grad: -6.10724009675323e-06
sam_encoder.blocks.10.norm2.bias grad: -2.820440840878291e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.392358732729917e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.477353973517893e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3670527323483839e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.0964895952602092e-07
sam_encoder.blocks.11.norm1.weight grad: -1.6254967704298906e-05
sam_encoder.blocks.11.norm1.bias grad: 2.2830485590930039e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.10542066522612e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.033571545074665e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.9317949409014545e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.0492086630620179e-06
sam_encoder.blocks.11.norm2.weight grad: -3.7256547784636496e-06
sam_encoder.blocks.11.norm2.bias grad: -3.0361343306140043e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.8874186480388744e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.696861886557599e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.586523800753639e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.754258154411218e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.2592848836211488e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.0487541405600496e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.743028618278913e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.5102640645636711e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0003381456481292844
mask_decoder.transformer.layers.0.norm1.bias grad: -4.179775714874268e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00027115404373034835
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0017520172987133265
mask_decoder.transformer.layers.0.norm3.weight grad: 4.129172884859145e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.969954948639497e-07
mask_decoder.transformer.layers.0.norm4.weight grad: -3.356541128596291e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 4.468362021725625e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.649131783982739e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.832932169549167e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 5.415788837126456e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.1759824701584876e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.8256956536788493e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.2611024178331718e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.0736781152663752e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -1.9608660295489244e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.927485734806396e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.081687504571164e-06
Text_Embedding_Affine.0.weight grad: 2.9746094476479357e-11
Text_Embedding_Affine.0.bias grad: 1.0726997068388755e-09
Text_Embedding_Affine.2.weight grad: 8.108658189343032e-11
Text_Embedding_Affine.2.bias grad: 8.094304939731956e-05
Epoch 38 finished with average loss: -60.8985
Epoch 39/39
----------
Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s, loss=-54.8]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-54.8]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-57.6]Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-57.6]Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-62.5]Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-62.5]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.224967597998841e-11
Max value: 0.9998370409011841
Mean value: 0.0886855274438858

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.224967597998841e-11
Max value: 0.9998370409011841
Mean value: 0.0886855274438858

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08409929275512695

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1281546950340271

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0777897834777832

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08409929275512695

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.20899963378906
Max value: 75.52752685546875
Mean value: 54.81482696533203

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.224967597998841e-11
Max value: 0.9998370409011841
Mean value: 0.0886855274438858

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.224967597998841e-11
Max value: 0.9998370409011841
Mean value: 0.0886855274438858

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.224967597998841e-11
Max value: 0.9998370409011841
Mean value: 0.0886855274438858

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1281546950340271

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.20899963378906
Max value: 75.52752685546875
Mean value: 54.81482696533203

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.81604766845703
Max value: -54.81604766845703
Mean value: -54.81604766845703
sam_encoder.pos_embed grad: 4.310016343822554e-09
sam_encoder.blocks.0.norm1.weight grad: -4.8733429139247164e-05
sam_encoder.blocks.0.norm1.bias grad: -1.8780185200739652e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.6798728615394793e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.3458539999410277e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.8680269679171033e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.377681423444301e-08
sam_encoder.blocks.0.norm2.weight grad: 1.0195009053859394e-05
sam_encoder.blocks.0.norm2.bias grad: -4.709434506366961e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4701066902489401e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.676402345969109e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.0644241228874307e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.309923835739028e-06
sam_encoder.blocks.1.norm1.weight grad: -3.0326209525810555e-06
sam_encoder.blocks.1.norm1.bias grad: -3.6163450545245723e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2389798484946368e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.797064054988368e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.3603825499994855e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.215242933649279e-07
sam_encoder.blocks.1.norm2.weight grad: -1.9247956515755504e-05
sam_encoder.blocks.1.norm2.bias grad: -6.091243903938448e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.6768000174779445e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.4126469523034757e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.458030161913484e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.319155671808403e-06
sam_encoder.blocks.2.norm1.weight grad: -1.8114455087925307e-05
sam_encoder.blocks.2.norm1.bias grad: -1.1344576478222734e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.554810847272165e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.5170011213049293e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.1134610506123863e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.089721308744629e-06
sam_encoder.blocks.2.norm2.weight grad: 1.1471796597106731e-06
sam_encoder.blocks.2.norm2.bias grad: 5.676121872966178e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.8400430690235225e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.6913691069930792e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.5273983485240024e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.1115511142634205e-06
sam_encoder.blocks.3.norm1.weight grad: 1.002907993097324e-06
sam_encoder.blocks.3.norm1.bias grad: 5.592137313215062e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.810370799328666e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.238840685706236e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0957221547869267e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.735399903031066e-06
sam_encoder.blocks.3.norm2.weight grad: -1.5931882444419898e-05
sam_encoder.blocks.3.norm2.bias grad: 2.065522949123988e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.2597802196978591e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.533055289357435e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.494859124155482e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.876621334115043e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0434398063807748e-05
sam_encoder.blocks.4.norm1.bias grad: 1.3671849501406541e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.409467798424885e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.0050409804971423e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.9174354899150785e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.657048975786893e-06
sam_encoder.blocks.4.norm2.weight grad: 2.4187886083382182e-05
sam_encoder.blocks.4.norm2.bias grad: 1.886824429675471e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.2992971278436016e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.181252163311001e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.312300582867465e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.832062465240597e-07
sam_encoder.blocks.5.norm1.weight grad: -6.2930103013059124e-06
sam_encoder.blocks.5.norm1.bias grad: 4.621282641892321e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5380708191514714e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2011772696496337e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5861143058136804e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.897724700938852e-06
sam_encoder.blocks.5.norm2.weight grad: 1.8989936506841332e-05
sam_encoder.blocks.5.norm2.bias grad: 9.355773727293126e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.377512363542337e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.800006313918857e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4782895050302614e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.1202778296137694e-06
sam_encoder.blocks.6.norm1.weight grad: -1.1265372990010292e-07
sam_encoder.blocks.6.norm1.bias grad: -4.211693521938287e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.0700094864878338e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.6840385796967894e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.0643737741465884e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.7272715758263075e-07
sam_encoder.blocks.6.norm2.weight grad: 1.0136351193068549e-05
sam_encoder.blocks.6.norm2.bias grad: 4.478426490095444e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.92641333444044e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.0676342248625588e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.314130693383049e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.1966996516530344e-07
sam_encoder.blocks.7.norm1.weight grad: -4.2069523260579444e-06
sam_encoder.blocks.7.norm1.bias grad: -8.29028977022972e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.0702982510556467e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.8124421785614686e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.0100804956891807e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.0940343498950824e-08
sam_encoder.blocks.7.norm2.weight grad: 3.10647078549664e-06
sam_encoder.blocks.7.norm2.bias grad: -1.0313254961147322e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.323830301520502e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.2139382710738573e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.28411646882887e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.4600331016699784e-07
sam_encoder.blocks.8.norm1.weight grad: -1.2633010726403882e-07
sam_encoder.blocks.8.norm1.bias grad: 3.099914238191559e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.683858272372163e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.797763146299985e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.8252192148793256e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3921278423367767e-06
sam_encoder.blocks.8.norm2.weight grad: 2.5964573069359176e-06
sam_encoder.blocks.8.norm2.bias grad: 1.7783509065338876e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.79345668888709e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.610255690655322e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.4172139723741566e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.893009647981671e-07
sam_encoder.blocks.9.norm1.weight grad: -6.990825909269915e-07
sam_encoder.blocks.9.norm1.bias grad: -1.2098456636522315e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.075500778024434e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.20144431245717e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.2686664869506785e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.8594529289403e-08
sam_encoder.blocks.9.norm2.weight grad: 2.569148591646808e-07
sam_encoder.blocks.9.norm2.bias grad: 2.285218670294853e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.6120254713314353e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.2785876530615496e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.670283467092304e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.15593796990288e-07
sam_encoder.blocks.10.norm1.weight grad: -4.2774895518959966e-06
sam_encoder.blocks.10.norm1.bias grad: -5.503585498445318e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.6651932785171084e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.882795666271704e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4590750652132556e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.9883056501821557e-07
sam_encoder.blocks.10.norm2.weight grad: -5.487364887812873e-06
sam_encoder.blocks.10.norm2.bias grad: -1.0476385341462446e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.2476145861437544e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.726103048189543e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.934817176646902e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 9.68586491012502e-08
sam_encoder.blocks.11.norm1.weight grad: -2.160590338462498e-05
sam_encoder.blocks.11.norm1.bias grad: 4.0736921391726355e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.834572569554439e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2153650459367782e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.8385620680637658e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.185929800674785e-07
sam_encoder.blocks.11.norm2.weight grad: -4.584342605085112e-06
sam_encoder.blocks.11.norm2.bias grad: -5.884368192710099e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.482576630631229e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.2015589163638651e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.045656112339202e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.964120824344718e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.912217264063656e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.9276323655503802e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.643329809070565e-07
sam_encoder.neck.conv2.trainable_shift grad: 8.808232450974174e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -6.778242095606402e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 8.321985660586506e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.006002763286232948
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005180969019420445
mask_decoder.transformer.layers.0.norm3.weight grad: -1.1230509699089453e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.935290103778243e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00015054811956360936
mask_decoder.transformer.layers.0.norm4.bias grad: 1.6770962247392163e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.840441266016569e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.74117814519559e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00016943964874371886
mask_decoder.transformer.layers.1.norm2.bias grad: -8.57226041262038e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -5.664461787091568e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.9235117078060284e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 6.918473809491843e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00024953216779977083
mask_decoder.transformer.norm_final_attn.weight grad: 1.5681575860071462e-06
mask_decoder.transformer.norm_final_attn.bias grad: -6.303146619757172e-06
Text_Embedding_Affine.0.weight grad: 6.2930272971828405e-12
Text_Embedding_Affine.0.bias grad: 7.021792869377208e-11
Text_Embedding_Affine.2.weight grad: -3.583961252773271e-11
Text_Embedding_Affine.2.bias grad: -6.937792932149023e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.575263758970776e-13
Max value: 0.997774064540863
Mean value: 0.08448905497789383

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.575263758970776e-13
Max value: 0.997774064540863
Mean value: 0.08448905497789383

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07578420639038086

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11432866752147675

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0804281234741211

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07578420639038086

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 50.61185836791992
Max value: 67.68832397460938
Mean value: 60.46257019042969

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.720738432603514e-13
Max value: 0.9976274371147156
Mean value: 0.08367499709129333

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.720738432603514e-13
Max value: 0.9976274371147156
Mean value: 0.08367499709129333

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.720738432603514e-13
Max value: 0.9976274371147156
Mean value: 0.08367499709129333

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11404432356357574

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8431934118270874
Max value: 1.1432933807373047
Mean value: 1.0003001689910889

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 50.61185836791992
Max value: 67.68832397460938
Mean value: 60.46257019042969

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.48212814331055
Max value: -60.48212814331055
Mean value: -60.48212814331055
sam_encoder.pos_embed grad: 2.864532167023981e-09
sam_encoder.blocks.0.norm1.weight grad: 9.598582983016968e-05
sam_encoder.blocks.0.norm1.bias grad: 4.709667700808495e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.172425413642486e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2866200904682046e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.7640984879108146e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.07792275736574e-06
sam_encoder.blocks.0.norm2.weight grad: 7.000003824941814e-05
sam_encoder.blocks.0.norm2.bias grad: -8.437148062512279e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.436812428641133e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.3256380043458194e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4036641914572101e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.361930819461122e-05
sam_encoder.blocks.1.norm1.weight grad: 1.4518196621793322e-05
sam_encoder.blocks.1.norm1.bias grad: 2.823796785378363e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.539372482919134e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1065465514548123e-05
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.0306617190944962e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.19890410132939e-05
sam_encoder.blocks.1.norm2.weight grad: -1.828987296903506e-05
sam_encoder.blocks.1.norm2.bias grad: -4.906809044769034e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.399843762963428e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.093657240555331e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.1910833311267197e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.2933113541512284e-06
sam_encoder.blocks.2.norm1.weight grad: -5.0270096835447475e-05
sam_encoder.blocks.2.norm1.bias grad: 4.2937590478686616e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.1610747100785375e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0110898074344732e-05
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.759534466662444e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0432794397274847e-06
sam_encoder.blocks.2.norm2.weight grad: 1.1466267096693628e-05
sam_encoder.blocks.2.norm2.bias grad: 2.6773512217914686e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.631488536688266e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.973027216692572e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.5542147593805566e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.339507775810489e-06
sam_encoder.blocks.3.norm1.weight grad: -2.5591614758013748e-05
sam_encoder.blocks.3.norm1.bias grad: 2.027486880251672e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1313662980683148e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.4565913412952796e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3846913589077303e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.1277500056603458e-06
sam_encoder.blocks.3.norm2.weight grad: -3.960794128943235e-05
sam_encoder.blocks.3.norm2.bias grad: 1.5230448298098054e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.7993224901147187e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.650762093660887e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.3513581001898274e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.647808160982095e-06
sam_encoder.blocks.4.norm1.weight grad: -6.792714702896774e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1381249350961298e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.120648761978373e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.445751306368038e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.1172697668371256e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.4305274817161262e-05
sam_encoder.blocks.4.norm2.weight grad: 8.595309918746352e-05
sam_encoder.blocks.4.norm2.bias grad: 2.279218278999906e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.731736746383831e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.299882544321008e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.771837503383722e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.0601853470434435e-06
sam_encoder.blocks.5.norm1.weight grad: -5.070904080639593e-05
sam_encoder.blocks.5.norm1.bias grad: 2.4202188797062263e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.715788261615671e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.2200488527014386e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.549878086545505e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.248192327504512e-06
sam_encoder.blocks.5.norm2.weight grad: 2.7130290618515573e-05
sam_encoder.blocks.5.norm2.bias grad: -1.008812068903353e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.494633559370413e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.818453701067483e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.809395880376542e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.2440699467551894e-06
sam_encoder.blocks.6.norm1.weight grad: -2.0239873265381902e-05
sam_encoder.blocks.6.norm1.bias grad: -3.7040153983980417e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.0945412213914096e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.3507623154728208e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.3463688851043116e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.5213831779401517e-06
sam_encoder.blocks.6.norm2.weight grad: 1.0233375178358983e-05
sam_encoder.blocks.6.norm2.bias grad: 3.0799944852333283e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.999627890356351e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.430441554679419e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -6.781640877306927e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.7679647044133162e-06
sam_encoder.blocks.7.norm1.weight grad: -4.478230948734563e-06
sam_encoder.blocks.7.norm1.bias grad: -1.308070181949006e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.072881205909653e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.6840976867533755e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.0514069092314458e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.3922308426117525e-06
sam_encoder.blocks.7.norm2.weight grad: 2.373060124227777e-05
sam_encoder.blocks.7.norm2.bias grad: -5.904897761865868e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.1861443454108667e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.618265277007595e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.446146370653878e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.264524010646255e-09
sam_encoder.blocks.8.norm1.weight grad: -3.284738340880722e-05
sam_encoder.blocks.8.norm1.bias grad: 5.846490239491686e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.193056181771681e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.155445170297753e-05
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.0444988220115192e-05
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.352512279292569e-06
sam_encoder.blocks.8.norm2.weight grad: 1.5872892618062906e-05
sam_encoder.blocks.8.norm2.bias grad: -9.361538104712963e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.61642581387423e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.350115887064021e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.858941444283118e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.865249371097889e-07
sam_encoder.blocks.9.norm1.weight grad: -1.3523442248697393e-05
sam_encoder.blocks.9.norm1.bias grad: 3.88439229936921e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.4957031453377567e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.5682128327607643e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.952319507836364e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.874369197859778e-07
sam_encoder.blocks.9.norm2.weight grad: 3.7558202166110277e-06
sam_encoder.blocks.9.norm2.bias grad: -1.68919700627157e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.68047097051749e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.761530902896993e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.165666460196007e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.0253871702589095e-07
sam_encoder.blocks.10.norm1.weight grad: -7.993046892806888e-06
sam_encoder.blocks.10.norm1.bias grad: -6.030784334143391e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.194755431148224e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.831387615122367e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.658215524003026e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.619957619273919e-07
sam_encoder.blocks.10.norm2.weight grad: -5.204753961152164e-06
sam_encoder.blocks.10.norm2.bias grad: -4.106616870558355e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.602445061318576e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.126163392153103e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.405183476474122e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.347046787093859e-08
sam_encoder.blocks.11.norm1.weight grad: -5.0119524530600756e-05
sam_encoder.blocks.11.norm1.bias grad: 1.4830609416094376e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.6929689081734978e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.006418748758733e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.768082246504491e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.390498593740631e-06
sam_encoder.blocks.11.norm2.weight grad: -8.01610713097034e-06
sam_encoder.blocks.11.norm2.bias grad: -3.0947080631449353e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.2193938800919568e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.928014853547211e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.1386330243112752e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.093846825981018e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.4192119124345481e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.4880499293212779e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.535671228542924e-09
sam_encoder.neck.conv2.trainable_shift grad: -3.741362888831645e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001592173066455871
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6720150597393513e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0008533888612873852
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0009189640404656529
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00019279183470644057
mask_decoder.transformer.layers.0.norm3.bias grad: 3.119666507700458e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.873430488165468e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2008547855657525e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 8.407888526562601e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.1719788744812831e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00046962840133346617
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00018521393940318376
mask_decoder.transformer.layers.1.norm3.weight grad: 1.4459310477832332e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.879109423607588e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00019225830328650773
mask_decoder.transformer.layers.1.norm4.bias grad: 9.170015982817858e-05
mask_decoder.transformer.norm_final_attn.weight grad: -7.367790431089816e-07
mask_decoder.transformer.norm_final_attn.bias grad: 3.830563400697429e-06
Text_Embedding_Affine.0.weight grad: 1.3646682742174399e-11
Text_Embedding_Affine.0.bias grad: -3.71603914306462e-10
Text_Embedding_Affine.2.weight grad: 5.806319314238806e-11
Text_Embedding_Affine.2.bias grad: -6.867602496640757e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7439397148599767e-11
Max value: 0.9983892440795898
Mean value: 0.09622786939144135

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7439397148599767e-11
Max value: 0.9983892440795898
Mean value: 0.09622786939144135

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0985565185546875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.937736511230469
Max value: -1.1920928244535389e-07
Mean value: -0.11334817111492157

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09049797058105469

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0985565185546875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.24144744873047
Max value: 91.31233215332031
Mean value: 72.17325592041016

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.79795674076977e-11
Max value: 0.9979909658432007
Mean value: 0.09448754787445068

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.79795674076977e-11
Max value: 0.9979909658432007
Mean value: 0.09448754787445068

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.79795674076977e-11
Max value: 0.9979909658432007
Mean value: 0.09448754787445068

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.35634708404541
Max value: -1.1920928244535389e-07
Mean value: -0.11335808038711548

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8480401635169983
Max value: 1.7885217666625977
Mean value: 1.0000872611999512

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.24144744873047
Max value: 91.31233215332031
Mean value: 72.17325592041016

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -72.17937469482422
Max value: -72.17937469482422
Mean value: -72.17937469482422
sam_encoder.pos_embed grad: 8.151783248422362e-09
sam_encoder.blocks.0.norm1.weight grad: -8.153024828061461e-05
sam_encoder.blocks.0.norm1.bias grad: -9.864972525974736e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.179985914262943e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.514995559176896e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.19778280047467e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.485298066152609e-06
sam_encoder.blocks.0.norm2.weight grad: 3.452708915574476e-05
sam_encoder.blocks.0.norm2.bias grad: -4.394787538331002e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.147080158465542e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.048767995205708e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.923813670146046e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.293430265533971e-06
sam_encoder.blocks.1.norm1.weight grad: 1.4368974916578736e-05
sam_encoder.blocks.1.norm1.bias grad: 5.7918605307349935e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.456461970723467e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.2887517186754849e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.343434850146878e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.374862214717723e-07
sam_encoder.blocks.1.norm2.weight grad: -1.488335237809224e-05
sam_encoder.blocks.1.norm2.bias grad: -2.7978212528978474e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.800466275715735e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.2942649593460374e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.459574706241256e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.188126243003353e-07
sam_encoder.blocks.2.norm1.weight grad: 1.6775138647062704e-06
sam_encoder.blocks.2.norm1.bias grad: -5.771150426880922e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.948282260855194e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.7113426287760376e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.0631932784453966e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.2476640399181633e-07
sam_encoder.blocks.2.norm2.weight grad: 4.963570063409861e-06
sam_encoder.blocks.2.norm2.bias grad: 2.6826928660739213e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.8567550291190855e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.0848093552340288e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.977844921289943e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.6066807972947572e-07
sam_encoder.blocks.3.norm1.weight grad: -1.128375697589945e-05
sam_encoder.blocks.3.norm1.bias grad: 5.303246780385962e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.910959432891104e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.827433137208573e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.0685118872497696e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.528757133608451e-06
sam_encoder.blocks.3.norm2.weight grad: -1.0382885193394031e-05
sam_encoder.blocks.3.norm2.bias grad: 8.57381473906571e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.616717200813582e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.1607115766310017e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.427201358543243e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.226306368262158e-07
sam_encoder.blocks.4.norm1.weight grad: -1.6384739865316078e-05
sam_encoder.blocks.4.norm1.bias grad: 9.326095096184872e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.705163963895757e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.2917652131582145e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.6139049370831344e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.550792260080925e-06
sam_encoder.blocks.4.norm2.weight grad: 1.583336961630266e-05
sam_encoder.blocks.4.norm2.bias grad: 1.2524998965091072e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.200928848760668e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.9979987630213145e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.5580797025904758e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.663781171781011e-07
sam_encoder.blocks.5.norm1.weight grad: -1.6822370525915176e-05
sam_encoder.blocks.5.norm1.bias grad: -1.203328110932489e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.639849511382636e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.933374384563649e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.554767994908616e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.681018137693172e-06
sam_encoder.blocks.5.norm2.weight grad: 7.057237780827563e-06
sam_encoder.blocks.5.norm2.bias grad: 1.6430158211733215e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.954170205768605e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.8467241008911515e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.3162970137491357e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.672446594777284e-07
sam_encoder.blocks.6.norm1.weight grad: -4.120463927392848e-06
sam_encoder.blocks.6.norm1.bias grad: -4.102750608581118e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.313062380693736e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.9704798382445006e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.5431997957857675e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.019934749521781e-07
sam_encoder.blocks.6.norm2.weight grad: 1.0519486750126816e-05
sam_encoder.blocks.6.norm2.bias grad: 4.118806373298867e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.904969606897794e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.6062090202904074e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.811120437712816e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.2687729622484767e-06
sam_encoder.blocks.7.norm1.weight grad: -6.360630322888028e-06
sam_encoder.blocks.7.norm1.bias grad: 2.1072273170830158e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.036211182916304e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.1194443914064323e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -6.326298489511828e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.2950296119670384e-07
sam_encoder.blocks.7.norm2.weight grad: 2.2645158423983958e-06
sam_encoder.blocks.7.norm2.bias grad: -4.483237603380985e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9094227354798932e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.977527628900134e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.050717173711746e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.6397776764497394e-07
sam_encoder.blocks.8.norm1.weight grad: -5.204552053328371e-06
sam_encoder.blocks.8.norm1.bias grad: 1.5281392506949487e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.387362423585728e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.3245611398815527e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.220043254259508e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.617879767465638e-06
sam_encoder.blocks.8.norm2.weight grad: -3.6255976283428026e-06
sam_encoder.blocks.8.norm2.bias grad: -3.095017291343538e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.877223545918241e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.444191750328173e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.817582756302727e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.155772958507441e-07
sam_encoder.blocks.9.norm1.weight grad: -5.046929345553508e-06
sam_encoder.blocks.9.norm1.bias grad: 5.630255941468931e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.378157543920679e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.085369603970321e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.978289780410705e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.168726933239668e-07
sam_encoder.blocks.9.norm2.weight grad: -3.098456318184617e-06
sam_encoder.blocks.9.norm2.bias grad: -7.011385037003492e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.8401449273806065e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.6074867517090752e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.544634452623541e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.9997818867523165e-07
sam_encoder.blocks.10.norm1.weight grad: -3.8817320273665246e-06
sam_encoder.blocks.10.norm1.bias grad: -8.107140274660196e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.7127416640505544e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.595743519075768e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.691504156857263e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.1350040191900916e-07
sam_encoder.blocks.10.norm2.weight grad: -1.1336667739669792e-05
sam_encoder.blocks.10.norm2.bias grad: -4.826104941457743e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.716515028732829e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.651360541174654e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.0074304504523752e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.649559279343521e-07
sam_encoder.blocks.11.norm1.weight grad: -2.2193791664903983e-05
sam_encoder.blocks.11.norm1.bias grad: 3.198574631824158e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.348229256516788e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.529851811545086e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.4594144178990973e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.1461079338914715e-06
sam_encoder.blocks.11.norm2.weight grad: -1.5211115169222467e-05
sam_encoder.blocks.11.norm2.bias grad: -4.122365680814255e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.122599981812527e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.6675714909506496e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.1614996512653306e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.880033657173044e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.348550308146514e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.546471584239043e-06
sam_encoder.neck.conv2.trainable_scale grad: 4.862340574618429e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.7943191778613254e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00025074294535443187
mask_decoder.transformer.layers.0.norm1.bias grad: 2.2991589503362775e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0019324414897710085
mask_decoder.transformer.layers.0.norm2.bias grad: 0.000686334038618952
mask_decoder.transformer.layers.0.norm3.weight grad: -4.800083115696907e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.478832124732435e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -2.561006840551272e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2193553629913367e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.73145155410748e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.479081664816476e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00022290660126600415
mask_decoder.transformer.layers.1.norm2.bias grad: 8.714220894034952e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.561292603786569e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.970041820546612e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.455608723219484e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 6.080493039917201e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.292242177441949e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.2929946024087258e-05
Text_Embedding_Affine.0.weight grad: -5.7449245013940775e-12
Text_Embedding_Affine.0.bias grad: 5.604623709576373e-11
Text_Embedding_Affine.2.weight grad: 3.246494739705952e-10
Text_Embedding_Affine.2.bias grad: 3.088192534050904e-05
Epoch 39 finished with average loss: -62.4925
Final Validation
Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, Loss=0.693, Dice=0.681]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.76it/s, Loss=0.693, Dice=0.681]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.76it/s, Loss=0.692, Dice=0.697]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                         
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.5209635187425765e-32
Max value: 0.9999988079071045
Mean value: 0.07833763211965561

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5209635187425765e-32
Max value: 0.9999988079071045
Mean value: 0.07833763211965561

Debugging images:
Shape: torch.Size([8, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 0.7981443405151367

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06797647476196289

Debugging predicted segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07536029815673828

Debugging Raw model output:
Shape: torch.Size([2, 512, 512])
Contains NaN: False
Min value: 6.968855957649338e-32
Max value: 0.9999750852584839
Mean value: 0.06740636378526688

Debugging Processed model output:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 6.968855957649338e-32
Max value: 0.9999750852584839
Mean value: 0.06740636378526688

Debugging images:
Shape: torch.Size([2, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 1.0704917907714844

Debugging Ground truth:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05922889709472656

Debugging predicted segs:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06654167175292969
Validation completed for Epoch 1:
Average Loss: 0.6920, Average Dice: 0.6965
