Sun Oct 13 21:46:45 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        On  | 00000000:41:00.0 Off |                  Off |
|  0%   37C    P8              11W / 450W |     54MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   1770066      G   /usr/lib/xorg/Xorg                           44MiB |
+---------------------------------------------------------------------------------------+
wandb: Currently logged in as: abdelrahman-elsayed (dinesh_saggurthi). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/abdelrahman.elsayed/wandb/run-20241013_214659-itgfztvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DIAS_modelnone
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dinesh_saggurthi/SVD_exps
wandb: üöÄ View run at https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/itgfztvi
{'data_transforms': {'a_min': 0, 'a_max': 255, 'img_size': 512, 'use_random_crop': False, 'use_rotation': True, 'rotation_angle': 10, 'use_saturation': False, 'saturation': 2, 'use_brightness': True, 'brightness': 2, 'use_horizontal_flip': True, 'use_random_scale': True}, 'data': {'name': 'ArcadeDataset', 'root_path': '/home/abdelrahman.elsayed/DIAS', 'data_split_csv': '/home/abdelrahman.elsayed/DIAS/data_split.csv', 'fold_num': 0, 'label_list': [0, 1], 'label_names': ['Background', 'Vein'], 'volume_channel': 3, 'negative_to_positive_ratio': -1}}
{'sam': {'img_size': 512, 'num_classes': 2, 'sam_type': 'base'}, 'img_type': 'image', 'arch': 'Prompt Adapted SAM', 'use_fdn': False, 'decoder_training': 'none', 'mlp_transform': False, 'prompts': {'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}, 'training': {'optimizer': 'adamw', 'lr': '1e-4', 'batch_size': 8, 'num_epochs': 200, 'schedule_step': 200, 'schedule_step_factor': 0.2, 'weight_decay': '1e-2', 'loss': 'focal+dice', 'reg_multiplier': 0}}
HERE
Train dataset size: 20
Val dataset size: 10
Train dataset size: 20
Val dataset size: 10
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Total parameters: 242,767,409
Trainable parameters: 1,034,496
Frozen parameters: 241,732,913

Parameters by module:
*************************************************************************************************************
  sam_encoder:
    Total: 87,293,696
    Trainable: 898,048
    Frozen: 86,395,648
*******************************************************************************************
*************************************************************************************************************
  clip_model:
    Total: 151,277,313
    Trainable: 0
    Frozen: 151,277,313
*******************************************************************************************
*************************************************************************************************************
  prompt_encoder:
    Total: 6,220
    Trainable: 0
    Frozen: 6,220
*******************************************************************************************
*************************************************************************************************************
  mask_decoder:
    Total: 4,058,340
    Trainable: 4,608
    Frozen: 4,053,732
*******************************************************************************************
*************************************************************************************************************
  Text_Embedding_Affine:
    Total: 131,840
    Trainable: 131,840
    Frozen: 0
*******************************************************************************************
./svdtuning/DIAS
Training parameters: 
----------
number of trainable parameters:  1034496
batch size:  5
num epochs:  200
Epoch 0/199
----------
train Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 0:   0%|          | 0/4 [00:02<?, ?it/s, loss=0.974, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.90s/it, loss=0.974, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:03<00:08,  2.90s/it, loss=0.941, dice=tensor(0.0240, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.29s/it, loss=0.941, dice=tensor(0.0240, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.29s/it, loss=0.946, dice=tensor(0.0161, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.29it/s, loss=0.946, dice=tensor(0.0161, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.29it/s, loss=0.887, dice=tensor(0.0126, device='cuda:0')]train Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.88it/s, loss=0.887, dice=tensor(0.0126, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                              train Loss: 0.9370 Dice: 0.0025
val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.92, dice=tensor(0.0138, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.92, dice=tensor(0.0138, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.909, dice=tensor(0.0097, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.9147 Dice: 0.0019
Epoch 1/199
----------
train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.938, dice=tensor(0.0099, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.938, dice=tensor(0.0099, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.888, dice=tensor(0.0070, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.888, dice=tensor(0.0070, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.931, dice=tensor(0.0064, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.931, dice=tensor(0.0064, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.892, dice=tensor(0.0579, device='cuda:0')]train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.892, dice=tensor(0.0579, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.9122 Dice: 0.0116
val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.921, dice=tensor(0.2072, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.921, dice=tensor(0.2072, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.924, dice=tensor(0.1250, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.9224 Dice: 0.0250
Epoch 2/199
----------
train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.896, dice=tensor(0.1800, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.896, dice=tensor(0.1800, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.912, dice=tensor(0.1923, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.912, dice=tensor(0.1923, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.905, dice=tensor(0.1905, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.905, dice=tensor(0.1905, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.876, dice=tensor(0.1863, device='cuda:0')]train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.876, dice=tensor(0.1863, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                              train Loss: 0.8973 Dice: 0.0373
val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.918, dice=tensor(0.2309, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.918, dice=tensor(0.2309, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.928, dice=tensor(0.1855, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.9233 Dice: 0.0371
Epoch 3/199
----------
train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.893, dice=tensor(0.0789, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.893, dice=tensor(0.0789, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.906, dice=tensor(0.1973, device='cuda:0')]train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.906, dice=tensor(0.1973, device='cuda:0')]train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.902, dice=tensor(0.1882, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.902, dice=tensor(0.1882, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.895, dice=tensor(0.2327, device='cuda:0')]train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.895, dice=tensor(0.2327, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                              train Loss: 0.8990 Dice: 0.0465
val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.925, dice=tensor(0.2048, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.925, dice=tensor(0.2048, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.911, dice=tensor(0.2107, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9178 Dice: 0.0421
Epoch 4/199
----------
train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.91, dice=tensor(0.1301, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.91, dice=tensor(0.1301, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.895, dice=tensor(0.2109, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.895, dice=tensor(0.2109, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.922, dice=tensor(0.2502, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.922, dice=tensor(0.2502, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.855, dice=tensor(0.3109, device='cuda:0')]train Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.855, dice=tensor(0.3109, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                              train Loss: 0.8956 Dice: 0.0622
val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.903, dice=tensor(0.0962, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.903, dice=tensor(0.0962, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.923, dice=tensor(0.2249, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.9129 Dice: 0.0450
Epoch 5/199
----------
train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.888, dice=tensor(0.3143, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.888, dice=tensor(0.3143, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.905, dice=tensor(0.3494, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.905, dice=tensor(0.3494, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.884, dice=tensor(0.2755, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.884, dice=tensor(0.2755, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.882, dice=tensor(0.2408, device='cuda:0')]train Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.882, dice=tensor(0.2408, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                              train Loss: 0.8901 Dice: 0.0482
val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.904, dice=tensor(0.1623, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.904, dice=tensor(0.1623, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.914, dice=tensor(0.2183, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.9091 Dice: 0.0437
Epoch 6/199
----------
train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.924, dice=tensor(0.1159, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.924, dice=tensor(0.1159, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.892, dice=tensor(0.0765, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.892, dice=tensor(0.0765, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.861, dice=tensor(0.1385, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.861, dice=tensor(0.1385, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.897, dice=tensor(0.2126, device='cuda:0')]train Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.897, dice=tensor(0.2126, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                              train Loss: 0.8935 Dice: 0.0425
val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.891, dice=tensor(0.0644, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.891, dice=tensor(0.0644, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.917, dice=tensor(0.1826, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9044 Dice: 0.0365
Epoch 7/199
----------
train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.888, dice=tensor(0.0040, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.888, dice=tensor(0.0040, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.9, dice=tensor(0.0885, device='cuda:0')]  train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.9, dice=tensor(0.0885, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.911, dice=tensor(0.1075, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.911, dice=tensor(0.1075, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.857, dice=tensor(0.1531, device='cuda:0')]train Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.857, dice=tensor(0.1531, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                              train Loss: 0.8887 Dice: 0.0306
val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.906, dice=tensor(0.0600, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.906, dice=tensor(0.0600, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.898, dice=tensor(0.1572, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9021 Dice: 0.0314
Epoch 8/199
----------
train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.865, dice=tensor(0.3020, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.865, dice=tensor(0.3020, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.879, dice=tensor(0.2208, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.879, dice=tensor(0.2208, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.887, dice=tensor(0.2099, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.887, dice=tensor(0.2099, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.886, dice=tensor(0.1680, device='cuda:0')]train Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.886, dice=tensor(0.1680, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                              train Loss: 0.8793 Dice: 0.0336
val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.876, dice=tensor(0.1266, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.876, dice=tensor(0.1266, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.916, dice=tensor(0.1491, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.8960 Dice: 0.0298
Epoch 9/199
----------
train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.856, dice=tensor(0.3810, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.856, dice=tensor(0.3810, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.888, dice=tensor(0.2627, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.888, dice=tensor(0.2627, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.875, dice=tensor(0.2134, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.875, dice=tensor(0.2134, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.859, dice=tensor(0.2162, device='cuda:0')]train Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.859, dice=tensor(0.2162, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                              train Loss: 0.8695 Dice: 0.0432
val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.904, dice=tensor(0.1763, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.904, dice=tensor(0.1763, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.892, dice=tensor(0.1567, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.8978 Dice: 0.0313
Epoch 10/199
----------
train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.864, dice=tensor(0.1765, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.864, dice=tensor(0.1765, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.896, dice=tensor(0.1016, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.896, dice=tensor(0.1016, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.832, dice=tensor(0.1276, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.832, dice=tensor(0.1276, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.859, dice=tensor(0.2132, device='cuda:0')]train Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.859, dice=tensor(0.2132, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.8628 Dice: 0.0426
val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.91, dice=tensor(0.1971, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.91, dice=tensor(0.1971, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.881, dice=tensor(0.1410, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.8958 Dice: 0.0282
Epoch 11/199
----------
train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.886, dice=tensor(0.0016, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.886, dice=tensor(0.0016, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.85, dice=tensor(0.3077, device='cuda:0')] train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.85, dice=tensor(0.3077, device='cuda:0')]train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.857, dice=tensor(0.2205, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.857, dice=tensor(0.2205, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.83, dice=tensor(0.3387, device='cuda:0')] train Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.83, dice=tensor(0.3387, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                              train Loss: 0.8556 Dice: 0.0677
val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.881, dice=tensor(0.2659, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.881, dice=tensor(0.2659, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.901, dice=tensor(0.1538, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.8907 Dice: 0.0308
Epoch 12/199
----------
train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.903, dice=tensor(0.0054, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.903, dice=tensor(0.0054, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.845, dice=tensor(0.0329, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.845, dice=tensor(0.0329, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.78, dice=tensor(0.1690, device='cuda:0')] train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.78, dice=tensor(0.1690, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.825, dice=tensor(0.2620, device='cuda:0')]train Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.825, dice=tensor(0.2620, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.8384 Dice: 0.0524
val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.91, dice=tensor(0.0565, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.91, dice=tensor(0.0565, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.867, dice=tensor(0.0855, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.8885 Dice: 0.0171
Epoch 13/199
----------
train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.82, dice=tensor(0.6171, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.82, dice=tensor(0.6171, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.752, dice=tensor(0.9774, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.752, dice=tensor(0.9774, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.845, dice=tensor(0.8696, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.845, dice=tensor(0.8696, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.829, dice=tensor(0.6911, device='cuda:0')]train Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.829, dice=tensor(0.6911, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.8117 Dice: 0.1382
val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.903, dice=tensor(0.0015, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.903, dice=tensor(0.0015, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.932, dice=tensor(0.0009, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.9175 Dice: 0.0002
Epoch 14/199
----------
train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.789, dice=tensor(1.2053, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.789, dice=tensor(1.2053, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.76, dice=tensor(1.1877, device='cuda:0')] train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.76, dice=tensor(1.1877, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.737, dice=tensor(1.4236, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.737, dice=tensor(1.4236, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.767, dice=tensor(1.3089, device='cuda:0')]train Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.767, dice=tensor(1.3089, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.7631 Dice: 0.2618
val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.01, dice=tensor(0.0003, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.03it/s, loss=1.01, dice=tensor(0.0003, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.03it/s, loss=0.999, dice=tensor(0.0003, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 1.0051 Dice: 0.0001
Epoch 15/199
----------
train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.704, dice=tensor(1.7644, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.704, dice=tensor(1.7644, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.739, dice=tensor(1.5085, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.739, dice=tensor(1.5085, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.756, dice=tensor(1.7045, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.756, dice=tensor(1.7045, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.721, dice=tensor(1.7318, device='cuda:0')]train Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.721, dice=tensor(1.7318, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.7302 Dice: 0.3464
val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.978, dice=tensor(0.0004, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.978, dice=tensor(0.0004, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.999, dice=tensor(0.0003, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.9887 Dice: 0.0001
Epoch 16/199
----------
train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.603, dice=tensor(1.8039, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.45it/s, loss=0.603, dice=tensor(1.8039, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.45it/s, loss=0.823, dice=tensor(1.3525, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.64it/s, loss=0.823, dice=tensor(1.3525, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.64it/s, loss=0.676, dice=tensor(1.7305, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.676, dice=tensor(1.7305, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.691, dice=tensor(1.8542, device='cuda:0')]train Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.29it/s, loss=0.691, dice=tensor(1.8542, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.6984 Dice: 0.3708
val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.861, dice=tensor(0.6052, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.861, dice=tensor(0.6052, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.872, dice=tensor(0.7939, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.8665 Dice: 0.1588
Epoch 17/199
----------
train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.609, dice=tensor(2.9677, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.609, dice=tensor(2.9677, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.591, dice=tensor(2.4224, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.591, dice=tensor(2.4224, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.74, dice=tensor(2.1469, device='cuda:0')] train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.74, dice=tensor(2.1469, device='cuda:0')]train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.472, dice=tensor(2.2476, device='cuda:0')]train Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.472, dice=tensor(2.2476, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.6030 Dice: 0.4495
val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.691, dice=tensor(1.9869, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.691, dice=tensor(1.9869, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.776, dice=tensor(2.0333, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.7336 Dice: 0.4067
Epoch 18/199
----------
train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.531, dice=tensor(2.8637, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.531, dice=tensor(2.8637, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.49, dice=tensor(2.7263, device='cuda:0')] train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.49, dice=tensor(2.7263, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.663, dice=tensor(2.3438, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.663, dice=tensor(2.3438, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.575, dice=tensor(2.4935, device='cuda:0')]train Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.575, dice=tensor(2.4935, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.5646 Dice: 0.4987
val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.63, dice=tensor(2.2299, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.63, dice=tensor(2.2299, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.64, dice=tensor(2.2128, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.6351 Dice: 0.4426
Epoch 19/199
----------
train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.441, dice=tensor(2.7879, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.441, dice=tensor(2.7879, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.461, dice=tensor(2.9002, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.461, dice=tensor(2.9002, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.534, dice=tensor(2.8395, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.534, dice=tensor(2.8395, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.495, dice=tensor(2.7216, device='cuda:0')]train Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.495, dice=tensor(2.7216, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.4828 Dice: 0.5443
val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.539, dice=tensor(2.8236, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.539, dice=tensor(2.8236, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.686, dice=tensor(2.0123, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.6126 Dice: 0.4025
Epoch 20/199
----------
train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.455, dice=tensor(2.9426, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.455, dice=tensor(2.9426, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.41, dice=tensor(2.9438, device='cuda:0')] train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.41, dice=tensor(2.9438, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.42, dice=tensor(3.0129, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.42, dice=tensor(3.0129, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.489, dice=tensor(2.9202, device='cuda:0')]train Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.489, dice=tensor(2.9202, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.4434 Dice: 0.5840
val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.784, dice=tensor(0.8454, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.784, dice=tensor(0.8454, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.833, dice=tensor(0.8770, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.8085 Dice: 0.1754
Epoch 21/199
----------
train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.412, dice=tensor(3.0666, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.412, dice=tensor(3.0666, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.487, dice=tensor(2.7647, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.487, dice=tensor(2.7647, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.386, dice=tensor(2.9238, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.386, dice=tensor(2.9238, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.444, dice=tensor(2.9845, device='cuda:0')]train Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.444, dice=tensor(2.9845, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.4321 Dice: 0.5969
val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.761, dice=tensor(1.0997, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.94it/s, loss=0.761, dice=tensor(1.0997, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.94it/s, loss=0.869, dice=tensor(0.8989, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.8150 Dice: 0.1798
Epoch 22/199
----------
train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.451, dice=tensor(3.1001, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.451, dice=tensor(3.1001, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.502, dice=tensor(3.0326, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.502, dice=tensor(3.0326, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.395, dice=tensor(3.0062, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.395, dice=tensor(3.0062, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.362, dice=tensor(3.0595, device='cuda:0')]train Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.362, dice=tensor(3.0595, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.4274 Dice: 0.6119
val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.839, dice=tensor(0.8698, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.839, dice=tensor(0.8698, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.627, dice=tensor(1.2285, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.7330 Dice: 0.2457
Epoch 23/199
----------
train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.418, dice=tensor(2.7841, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.418, dice=tensor(2.7841, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.408, dice=tensor(2.9753, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.408, dice=tensor(2.9753, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.342, dice=tensor(3.1144, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.342, dice=tensor(3.1144, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.385, dice=tensor(3.0890, device='cuda:0')]train Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.385, dice=tensor(3.0890, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3882 Dice: 0.6178
val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.723, dice=tensor(1.4109, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.723, dice=tensor(1.4109, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.68, dice=tensor(1.4161, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                            val Loss: 0.7016 Dice: 0.2832
Epoch 24/199
----------
train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2522, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.358, dice=tensor(3.2522, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.423, dice=tensor(3.1350, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.423, dice=tensor(3.1350, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.391, dice=tensor(3.0946, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.391, dice=tensor(3.0946, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.417, dice=tensor(3.0429, device='cuda:0')]train Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.417, dice=tensor(3.0429, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3973 Dice: 0.6086
val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.758, dice=tensor(1.2268, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.758, dice=tensor(1.2268, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.681, dice=tensor(1.3624, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.7196 Dice: 0.2725
Epoch 25/199
----------
train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.401, dice=tensor(3.0821, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.401, dice=tensor(3.0821, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.386, dice=tensor(3.0876, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.386, dice=tensor(3.0876, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.399, dice=tensor(3.0786, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.399, dice=tensor(3.0786, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.359, dice=tensor(3.0663, device='cuda:0')]train Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.359, dice=tensor(3.0663, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3863 Dice: 0.6133
val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.877, dice=tensor(0.7029, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.877, dice=tensor(0.7029, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.715, dice=tensor(1.0068, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.7960 Dice: 0.2014
Epoch 26/199
----------
train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.4051, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.336, dice=tensor(3.4051, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.419, dice=tensor(3.1519, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.419, dice=tensor(3.1519, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.365, dice=tensor(3.1676, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.365, dice=tensor(3.1676, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.36, dice=tensor(3.1862, device='cuda:0')] train Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.36, dice=tensor(3.1862, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                              train Loss: 0.3699 Dice: 0.6372
val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.883, dice=tensor(0.6858, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.883, dice=tensor(0.6858, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.761, dice=tensor(0.8661, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.8222 Dice: 0.1732
Epoch 27/199
----------
train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2327, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.356, dice=tensor(3.2327, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.37, dice=tensor(3.2310, device='cuda:0')] train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.37, dice=tensor(3.2310, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.406, dice=tensor(3.1849, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.406, dice=tensor(3.1849, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.344, dice=tensor(3.2210, device='cuda:0')]train Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.344, dice=tensor(3.2210, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3694 Dice: 0.6442
val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.767, dice=tensor(1.1082, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.767, dice=tensor(1.1082, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.907, dice=tensor(0.8469, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.8368 Dice: 0.1694
Epoch 28/199
----------
train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.1486, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.362, dice=tensor(3.1486, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.418, dice=tensor(3.0666, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.418, dice=tensor(3.0666, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.359, dice=tensor(3.1239, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.359, dice=tensor(3.1239, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.339, dice=tensor(3.1798, device='cuda:0')]train Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.339, dice=tensor(3.1798, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3694 Dice: 0.6360
val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.843, dice=tensor(0.8358, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.843, dice=tensor(0.8358, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.774, dice=tensor(0.9611, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.8084 Dice: 0.1922
Epoch 29/199
----------
train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.2058, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.38, dice=tensor(3.2058, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.321, dice=tensor(3.3187, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.321, dice=tensor(3.3187, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.389, dice=tensor(3.2539, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.389, dice=tensor(3.2539, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.351, dice=tensor(3.2351, device='cuda:0')]train Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.351, dice=tensor(3.2351, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3603 Dice: 0.6470
val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.858, dice=tensor(0.7710, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.858, dice=tensor(0.7710, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.724, dice=tensor(1.0213, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.7912 Dice: 0.2043
Epoch 30/199
----------
train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.382, dice=tensor(3.0366, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.382, dice=tensor(3.0366, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.408, dice=tensor(3.0009, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.408, dice=tensor(3.0009, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.349, dice=tensor(3.0615, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.349, dice=tensor(3.0615, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.321, dice=tensor(3.1494, device='cuda:0')]train Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.321, dice=tensor(3.1494, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3647 Dice: 0.6299
val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.722, dice=tensor(1.3771, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.722, dice=tensor(1.3771, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.751, dice=tensor(1.3179, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.7361 Dice: 0.2636
Epoch 31/199
----------
train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4070, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.327, dice=tensor(3.4070, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.396, dice=tensor(3.2316, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.396, dice=tensor(3.2316, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.386, dice=tensor(3.2209, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.386, dice=tensor(3.2209, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.36, dice=tensor(3.2314, device='cuda:0')] train Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.36, dice=tensor(3.2314, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                              train Loss: 0.3672 Dice: 0.6463
val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.658, dice=tensor(1.5854, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.658, dice=tensor(1.5854, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.722, dice=tensor(1.3882, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.6899 Dice: 0.2776
Epoch 32/199
----------
train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.403, dice=tensor(3.0612, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.403, dice=tensor(3.0612, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.387, dice=tensor(3.0141, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.387, dice=tensor(3.0141, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.326, dice=tensor(3.1582, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.326, dice=tensor(3.1582, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.348, dice=tensor(3.1809, device='cuda:0')]train Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.348, dice=tensor(3.1809, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3657 Dice: 0.6362
val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.676, dice=tensor(1.5206, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.676, dice=tensor(1.5206, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.478, dice=tensor(2.0198, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.5766 Dice: 0.4040
Epoch 33/199
----------
train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2498, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.36, dice=tensor(3.2498, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.336, dice=tensor(3.2479, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.336, dice=tensor(3.2479, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.383, dice=tensor(3.2065, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.383, dice=tensor(3.2065, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.385, dice=tensor(3.1931, device='cuda:0')]train Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.385, dice=tensor(3.1931, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3663 Dice: 0.6386
val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.503, dice=tensor(2.3055, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.503, dice=tensor(2.3055, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.628, dice=tensor(2.0616, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.5657 Dice: 0.4123
Epoch 34/199
----------
train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.388, dice=tensor(3.1247, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.388, dice=tensor(3.1247, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.435, dice=tensor(3.0066, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.435, dice=tensor(3.0066, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.312, dice=tensor(3.1712, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.312, dice=tensor(3.1712, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.345, dice=tensor(3.1932, device='cuda:0')]train Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.345, dice=tensor(3.1932, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3700 Dice: 0.6386
val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.642, dice=tensor(1.7098, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.642, dice=tensor(1.7098, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.587, dice=tensor(1.8695, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.6148 Dice: 0.3739
Epoch 35/199
----------
train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2148, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.362, dice=tensor(3.2148, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.338, dice=tensor(3.2762, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.338, dice=tensor(3.2762, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.375, dice=tensor(3.2452, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.375, dice=tensor(3.2452, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.364, dice=tensor(3.2358, device='cuda:0')]train Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.364, dice=tensor(3.2358, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3596 Dice: 0.6472
val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.597, dice=tensor(2.0490, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.597, dice=tensor(2.0490, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.771, dice=tensor(1.5825, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.6841 Dice: 0.3165
Epoch 36/199
----------
train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.1837, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.36, dice=tensor(3.1837, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.399, dice=tensor(3.1319, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.399, dice=tensor(3.1319, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.361, dice=tensor(3.1832, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.361, dice=tensor(3.1832, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.3, dice=tensor(3.2565, device='cuda:0')]  train Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.3, dice=tensor(3.2565, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                             train Loss: 0.3549 Dice: 0.6513
val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.691, dice=tensor(1.5551, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.691, dice=tensor(1.5551, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.728, dice=tensor(1.4422, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.7098 Dice: 0.2884
Epoch 37/199
----------
train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2269, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.345, dice=tensor(3.2269, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.344, dice=tensor(3.2724, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.344, dice=tensor(3.2724, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.371, dice=tensor(3.2315, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.371, dice=tensor(3.2315, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.348, dice=tensor(3.2576, device='cuda:0')]train Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.348, dice=tensor(3.2576, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3518 Dice: 0.6515
val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.676, dice=tensor(1.6475, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.676, dice=tensor(1.6475, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.66, dice=tensor(1.6611, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.6683 Dice: 0.3322
Epoch 38/199
----------
train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1353, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.38, dice=tensor(3.1353, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.343, dice=tensor(3.2337, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.343, dice=tensor(3.2337, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.318, dice=tensor(3.2882, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.318, dice=tensor(3.2882, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.385, dice=tensor(3.2440, device='cuda:0')]train Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.385, dice=tensor(3.2440, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3563 Dice: 0.6488
val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.652, dice=tensor(1.7430, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.652, dice=tensor(1.7430, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.584, dice=tensor(1.9028, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.6181 Dice: 0.3806
Epoch 39/199
----------
train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2817, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.351, dice=tensor(3.2817, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.356, dice=tensor(3.2400, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.356, dice=tensor(3.2400, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.334, dice=tensor(3.2856, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.334, dice=tensor(3.2856, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.347, dice=tensor(3.2811, device='cuda:0')]train Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.347, dice=tensor(3.2811, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3469 Dice: 0.6562
val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.538, dice=tensor(2.3263, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.538, dice=tensor(2.3263, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.614, dice=tensor(2.1131, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.5763 Dice: 0.4226
Epoch 40/199
----------
train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.292, dice=tensor(3.5132, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.96it/s, loss=0.292, dice=tensor(3.5132, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.96it/s, loss=0.374, dice=tensor(3.3574, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.26it/s, loss=0.374, dice=tensor(3.3574, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.26it/s, loss=0.398, dice=tensor(3.2280, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.15it/s, loss=0.398, dice=tensor(3.2280, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.15it/s, loss=0.357, dice=tensor(3.2039, device='cuda:0')]train Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.76it/s, loss=0.357, dice=tensor(3.2039, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3551 Dice: 0.6408
val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.528, dice=tensor(2.4489, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.528, dice=tensor(2.4489, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.593, dice=tensor(2.2312, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.5604 Dice: 0.4462
Epoch 41/199
----------
train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.408, dice=tensor(3.0114, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.408, dice=tensor(3.0114, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.324, dice=tensor(3.1601, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.324, dice=tensor(3.1601, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.313, dice=tensor(3.2649, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.313, dice=tensor(3.2649, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.379, dice=tensor(3.2393, device='cuda:0')]train Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.379, dice=tensor(3.2393, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3556 Dice: 0.6479
val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.671, dice=tensor(1.5781, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.671, dice=tensor(1.5781, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.746, dice=tensor(1.4370, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.7087 Dice: 0.2874
Epoch 42/199
----------
train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1282, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.377, dice=tensor(3.1282, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.325, dice=tensor(3.2277, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.325, dice=tensor(3.2277, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.359, dice=tensor(3.2277, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.359, dice=tensor(3.2277, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.349, dice=tensor(3.2437, device='cuda:0')]train Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.349, dice=tensor(3.2437, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3525 Dice: 0.6487
val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.724, dice=tensor(1.3712, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.724, dice=tensor(1.3712, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.747, dice=tensor(1.3538, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.7354 Dice: 0.2708
Epoch 43/199
----------
train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2132, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.36, dice=tensor(3.2132, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.278, dice=tensor(3.4422, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.278, dice=tensor(3.4422, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.415, dice=tensor(3.2950, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.415, dice=tensor(3.2950, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.36, dice=tensor(3.2775, device='cuda:0')] train Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.36, dice=tensor(3.2775, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                              train Loss: 0.3534 Dice: 0.6555
val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.734, dice=tensor(1.3670, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.734, dice=tensor(1.3670, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.669, dice=tensor(1.5455, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.7016 Dice: 0.3091
Epoch 44/199
----------
train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1183, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.378, dice=tensor(3.1183, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.332, dice=tensor(3.2255, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.332, dice=tensor(3.2255, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.361, dice=tensor(3.2240, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.361, dice=tensor(3.2240, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.31, dice=tensor(3.2923, device='cuda:0')] train Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.31, dice=tensor(3.2923, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                              train Loss: 0.3453 Dice: 0.6585
val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.599, dice=tensor(2.1169, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.599, dice=tensor(2.1169, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.693, dice=tensor(1.8552, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.6464 Dice: 0.3710
Epoch 45/199
----------
train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2465, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.35, dice=tensor(3.2465, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.375, dice=tensor(3.1941, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.375, dice=tensor(3.1941, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.367, dice=tensor(3.1932, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.367, dice=tensor(3.1932, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.318, dice=tensor(3.2266, device='cuda:0')]train Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.318, dice=tensor(3.2266, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3527 Dice: 0.6453
val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.557, dice=tensor(2.2773, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.557, dice=tensor(2.2773, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.664, dice=tensor(2.0013, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.6106 Dice: 0.4003
Epoch 46/199
----------
train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.0936, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.374, dice=tensor(3.0936, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.366, dice=tensor(3.1407, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.366, dice=tensor(3.1407, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.325, dice=tensor(3.1674, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.325, dice=tensor(3.1674, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.348, dice=tensor(3.2046, device='cuda:0')]train Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.348, dice=tensor(3.2046, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3530 Dice: 0.6409
val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.603, dice=tensor(2.0475, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.603, dice=tensor(2.0475, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.603, dice=tensor(2.0546, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.6033 Dice: 0.4109
Epoch 47/199
----------
train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.274, dice=tensor(3.6902, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.274, dice=tensor(3.6902, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.402, dice=tensor(3.3895, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.402, dice=tensor(3.3895, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.352, dice=tensor(3.3490, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.352, dice=tensor(3.3490, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.394, dice=tensor(3.2779, device='cuda:0')]train Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.394, dice=tensor(3.2779, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3558 Dice: 0.6556
val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.567, dice=tensor(2.1967, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.567, dice=tensor(2.1967, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.567, dice=tensor(2.2244, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.5670 Dice: 0.4449
Epoch 48/199
----------
train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.0992, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.384, dice=tensor(3.0992, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.316, dice=tensor(3.2605, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.316, dice=tensor(3.2605, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.383, dice=tensor(3.2297, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.383, dice=tensor(3.2297, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.331, dice=tensor(3.2733, device='cuda:0')]train Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.331, dice=tensor(3.2733, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3535 Dice: 0.6547
val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.511, dice=tensor(2.4760, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.511, dice=tensor(2.4760, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.44, dice=tensor(2.6762, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.4756 Dice: 0.5352
Epoch 49/199
----------
train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2281, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.343, dice=tensor(3.2281, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.314, dice=tensor(3.3067, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.314, dice=tensor(3.3067, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.343, dice=tensor(3.2871, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.343, dice=tensor(3.2871, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.374, dice=tensor(3.2541, device='cuda:0')]train Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.374, dice=tensor(3.2541, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3434 Dice: 0.6508
val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.433, dice=tensor(2.8734, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.433, dice=tensor(2.8734, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.447, dice=tensor(2.8232, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4401 Dice: 0.5646
Epoch 50/199
----------
train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.5115, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.307, dice=tensor(3.5115, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.351, dice=tensor(3.3697, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.351, dice=tensor(3.3697, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.334, dice=tensor(3.3585, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.334, dice=tensor(3.3585, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.385, dice=tensor(3.3014, device='cuda:0')]train Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.385, dice=tensor(3.3014, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3441 Dice: 0.6603
val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.1159, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.384, dice=tensor(3.1159, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.425, dice=tensor(3.0303, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4046 Dice: 0.6061
Epoch 51/199
----------
train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2702, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.88it/s, loss=0.338, dice=tensor(3.2702, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.88it/s, loss=0.337, dice=tensor(3.2666, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.17it/s, loss=0.337, dice=tensor(3.2666, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.17it/s, loss=0.309, dice=tensor(3.3431, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.07it/s, loss=0.309, dice=tensor(3.3431, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.07it/s, loss=0.434, dice=tensor(3.2361, device='cuda:0')]train Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.70it/s, loss=0.434, dice=tensor(3.2361, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3546 Dice: 0.6472
val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.392, dice=tensor(3.1321, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.392, dice=tensor(3.1321, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.466, dice=tensor(2.8984, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4293 Dice: 0.5797
Epoch 52/199
----------
train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4470, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.308, dice=tensor(3.4470, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.342, dice=tensor(3.3867, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.342, dice=tensor(3.3867, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.4, dice=tensor(3.2859, device='cuda:0')]  train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.4, dice=tensor(3.2859, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.332, dice=tensor(3.3043, device='cuda:0')]train Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.332, dice=tensor(3.3043, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3455 Dice: 0.6609
val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.452, dice=tensor(2.8207, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.452, dice=tensor(2.8207, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.496, dice=tensor(2.6761, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4739 Dice: 0.5352
Epoch 53/199
----------
train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3288, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.338, dice=tensor(3.3288, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.302, dice=tensor(3.4304, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.302, dice=tensor(3.4304, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.348, dice=tensor(3.3281, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.348, dice=tensor(3.3281, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.38, dice=tensor(3.2854, device='cuda:0')] train Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.38, dice=tensor(3.2854, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.3419 Dice: 0.6571
val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.418, dice=tensor(2.9608, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.418, dice=tensor(2.9608, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.494, dice=tensor(2.7475, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4560 Dice: 0.5495
Epoch 54/199
----------
train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1167, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.377, dice=tensor(3.1167, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.349, dice=tensor(3.2272, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.349, dice=tensor(3.2272, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.29, dice=tensor(3.3311, device='cuda:0')] train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.29, dice=tensor(3.3311, device='cuda:0')]train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.382, dice=tensor(3.2449, device='cuda:0')]train Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.382, dice=tensor(3.2449, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3498 Dice: 0.6490
val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.451, dice=tensor(2.7605, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.451, dice=tensor(2.7605, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.457, dice=tensor(2.7753, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4537 Dice: 0.5551
Epoch 55/199
----------
train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.2641, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.355, dice=tensor(3.2641, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.355, dice=tensor(3.2289, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.355, dice=tensor(3.2289, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.311, dice=tensor(3.2984, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.311, dice=tensor(3.2984, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.333, dice=tensor(3.3240, device='cuda:0')]train Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.333, dice=tensor(3.3240, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3385 Dice: 0.6648
val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.387, dice=tensor(3.1474, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.387, dice=tensor(3.1474, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.478, dice=tensor(2.9109, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.4325 Dice: 0.5822
Epoch 56/199
----------
train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.347, dice=tensor(3.2559, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.347, dice=tensor(3.2559, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.339, dice=tensor(3.2938, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.339, dice=tensor(3.2938, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.365, dice=tensor(3.2375, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.365, dice=tensor(3.2375, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.327, dice=tensor(3.2843, device='cuda:0')]train Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.327, dice=tensor(3.2843, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3442 Dice: 0.6569
val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.423, dice=tensor(2.8438, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.423, dice=tensor(2.8438, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.446, dice=tensor(2.8662, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.4342 Dice: 0.5732
Epoch 57/199
----------
train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.5105, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.303, dice=tensor(3.5105, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.375, dice=tensor(3.3324, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.375, dice=tensor(3.3324, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.331, dice=tensor(3.3552, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.331, dice=tensor(3.3552, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.372, dice=tensor(3.2995, device='cuda:0')]train Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.372, dice=tensor(3.2995, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3451 Dice: 0.6599
val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.471, dice=tensor(2.7344, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.471, dice=tensor(2.7344, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.557, dice=tensor(2.4674, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.5141 Dice: 0.4935
Epoch 58/199
----------
train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3641, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.333, dice=tensor(3.3641, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.331, dice=tensor(3.3458, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.331, dice=tensor(3.3458, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.362, dice=tensor(3.3029, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.362, dice=tensor(3.3029, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.35, dice=tensor(3.2802, device='cuda:0')] train Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.35, dice=tensor(3.2802, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                              train Loss: 0.3439 Dice: 0.6560
val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.494, dice=tensor(2.5645, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.494, dice=tensor(2.5645, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.579, dice=tensor(2.3016, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.5363 Dice: 0.4603
Epoch 59/199
----------
train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3585, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.324, dice=tensor(3.3585, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.353, dice=tensor(3.2758, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.65it/s, loss=0.353, dice=tensor(3.2758, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.65it/s, loss=0.332, dice=tensor(3.2983, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.332, dice=tensor(3.2983, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.383, dice=tensor(3.2361, device='cuda:0')]train Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.383, dice=tensor(3.2361, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3482 Dice: 0.6472
val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.442, dice=tensor(2.9142, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.442, dice=tensor(2.9142, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.427, dice=tensor(2.9563, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4347 Dice: 0.5913
Epoch 60/199
----------
train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4219, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.315, dice=tensor(3.4219, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.357, dice=tensor(3.3425, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.357, dice=tensor(3.3425, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.327, dice=tensor(3.3291, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.327, dice=tensor(3.3291, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.387, dice=tensor(3.2750, device='cuda:0')]train Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.387, dice=tensor(3.2750, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3464 Dice: 0.6550
val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.438, dice=tensor(2.9015, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.438, dice=tensor(2.9015, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.372, dice=tensor(3.0335, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4053 Dice: 0.6067
Epoch 61/199
----------
train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2216, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.87it/s, loss=0.362, dice=tensor(3.2216, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.87it/s, loss=0.327, dice=tensor(3.2996, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.16it/s, loss=0.327, dice=tensor(3.2996, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.16it/s, loss=0.357, dice=tensor(3.2497, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.06it/s, loss=0.357, dice=tensor(3.2497, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.06it/s, loss=0.311, dice=tensor(3.3107, device='cuda:0')]train Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.68it/s, loss=0.311, dice=tensor(3.3107, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3392 Dice: 0.6621
val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.43, dice=tensor(2.9188, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.43, dice=tensor(2.9188, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.403, dice=tensor(2.9423, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4169 Dice: 0.5885
Epoch 62/199
----------
train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.4476, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.296, dice=tensor(3.4476, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.369, dice=tensor(3.3232, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.369, dice=tensor(3.3232, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.332, dice=tensor(3.3383, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.332, dice=tensor(3.3383, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.368, dice=tensor(3.2984, device='cuda:0')]train Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.368, dice=tensor(3.2984, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3410 Dice: 0.6597
val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.425, dice=tensor(2.9387, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.425, dice=tensor(2.9387, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.438, dice=tensor(2.8672, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4316 Dice: 0.5734
Epoch 63/199
----------
train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.279, dice=tensor(3.6194, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.279, dice=tensor(3.6194, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.44, dice=tensor(3.2212, device='cuda:0')] train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.44, dice=tensor(3.2212, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.333, dice=tensor(3.2792, device='cuda:0')]train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.333, dice=tensor(3.2792, device='cuda:0')]train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.334, dice=tensor(3.2770, device='cuda:0')]train Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.334, dice=tensor(3.2770, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3468 Dice: 0.6554
val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.543, dice=tensor(2.3331, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.543, dice=tensor(2.3331, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.30it/s, loss=0.454, dice=tensor(2.5853, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4984 Dice: 0.5171
Epoch 64/199
----------
train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.1090, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.384, dice=tensor(3.1090, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.364, dice=tensor(3.1779, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.364, dice=tensor(3.1779, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.29, dice=tensor(3.3060, device='cuda:0')] train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.29, dice=tensor(3.3060, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.34, dice=tensor(3.2833, device='cuda:0')]train Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.34, dice=tensor(3.2833, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                              train Loss: 0.3447 Dice: 0.6567
val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.448, dice=tensor(2.7841, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.448, dice=tensor(2.7841, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.498, dice=tensor(2.6589, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.4727 Dice: 0.5318
Epoch 65/199
----------
train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2268, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.36, dice=tensor(3.2268, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.298, dice=tensor(3.3702, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.298, dice=tensor(3.3702, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.315, dice=tensor(3.3932, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.315, dice=tensor(3.3932, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.353, dice=tensor(3.3684, device='cuda:0')]train Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.353, dice=tensor(3.3684, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3313 Dice: 0.6737
val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.464, dice=tensor(2.7147, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.464, dice=tensor(2.7147, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.395, dice=tensor(2.9132, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4293 Dice: 0.5826
Epoch 66/199
----------
train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4053, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.323, dice=tensor(3.4053, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.298, dice=tensor(3.4425, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.298, dice=tensor(3.4425, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.341, dice=tensor(3.4077, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.341, dice=tensor(3.4077, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.359, dice=tensor(3.3580, device='cuda:0')]train Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.359, dice=tensor(3.3580, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3302 Dice: 0.6716
val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.386, dice=tensor(3.1644, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.386, dice=tensor(3.1644, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.388, dice=tensor(3.0955, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3866 Dice: 0.6191
Epoch 67/199
----------
train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4331, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.321, dice=tensor(3.4331, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.352, dice=tensor(3.3444, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.352, dice=tensor(3.3444, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.337, dice=tensor(3.3167, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.02it/s, loss=0.337, dice=tensor(3.3167, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.02it/s, loss=0.346, dice=tensor(3.2979, device='cuda:0')]train Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.346, dice=tensor(3.2979, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3389 Dice: 0.6596
val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.436, dice=tensor(2.8636, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.436, dice=tensor(2.8636, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.32, dice=tensor(3.1621, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.3781 Dice: 0.6324
Epoch 68/199
----------
train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.3345, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.33, dice=tensor(3.3345, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.316, dice=tensor(3.3755, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.316, dice=tensor(3.3755, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.303, dice=tensor(3.4306, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.303, dice=tensor(3.4306, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.409, dice=tensor(3.3183, device='cuda:0')]train Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.409, dice=tensor(3.3183, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3392 Dice: 0.6637
val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.386, dice=tensor(3.0846, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.386, dice=tensor(3.0846, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.37, dice=tensor(3.1486, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.3777 Dice: 0.6297
Epoch 69/199
----------
train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.396, dice=tensor(3.0673, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.396, dice=tensor(3.0673, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.33, dice=tensor(3.1963, device='cuda:0')] train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.33, dice=tensor(3.1963, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.287, dice=tensor(3.3325, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.287, dice=tensor(3.3325, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.347, dice=tensor(3.3266, device='cuda:0')]train Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.347, dice=tensor(3.3266, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3400 Dice: 0.6653
val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.392, dice=tensor(3.0324, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.392, dice=tensor(3.0324, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.365, dice=tensor(3.1470, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3785 Dice: 0.6294
Epoch 70/199
----------
train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.299, dice=tensor(3.3963, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.299, dice=tensor(3.3963, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.39, dice=tensor(3.2071, device='cuda:0')] train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.39, dice=tensor(3.2071, device='cuda:0')]train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.34, dice=tensor(3.2504, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.34, dice=tensor(3.2504, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.331, dice=tensor(3.2878, device='cuda:0')]train Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.331, dice=tensor(3.2878, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3400 Dice: 0.6576
val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.433, dice=tensor(2.8791, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.433, dice=tensor(2.8791, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.325, dice=tensor(3.1521, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3788 Dice: 0.6304
Epoch 71/199
----------
train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3471, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.329, dice=tensor(3.3471, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.295, dice=tensor(3.4405, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.295, dice=tensor(3.4405, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.338, dice=tensor(3.4039, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.338, dice=tensor(3.4039, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.367, dice=tensor(3.3543, device='cuda:0')]train Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.367, dice=tensor(3.3543, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3322 Dice: 0.6709
val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.404, dice=tensor(3.0020, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.404, dice=tensor(3.0020, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.354, dice=tensor(3.1506, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3788 Dice: 0.6301
Epoch 72/199
----------
train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2252, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.345, dice=tensor(3.2252, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.356, dice=tensor(3.2222, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.356, dice=tensor(3.2222, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.344, dice=tensor(3.2647, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.344, dice=tensor(3.2647, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.296, dice=tensor(3.3166, device='cuda:0')]train Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.296, dice=tensor(3.3166, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3354 Dice: 0.6633
val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.403, dice=tensor(2.9946, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.403, dice=tensor(2.9946, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.347, dice=tensor(3.1602, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3753 Dice: 0.6320
Epoch 73/199
----------
train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3195, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.338, dice=tensor(3.3195, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.321, dice=tensor(3.3652, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.321, dice=tensor(3.3652, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.351, dice=tensor(3.3319, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.351, dice=tensor(3.3319, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.319, dice=tensor(3.3489, device='cuda:0')]train Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.319, dice=tensor(3.3489, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3323 Dice: 0.6698
val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2914, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.359, dice=tensor(3.2914, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.388, dice=tensor(3.1660, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3732 Dice: 0.6332
Epoch 74/199
----------
train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.2538, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.335, dice=tensor(3.2538, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.39, dice=tensor(3.1921, device='cuda:0')] train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.39, dice=tensor(3.1921, device='cuda:0')]train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.318, dice=tensor(3.2649, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.318, dice=tensor(3.2649, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.315, dice=tensor(3.3156, device='cuda:0')]train Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.315, dice=tensor(3.3156, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3396 Dice: 0.6631
val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.4021, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.333, dice=tensor(3.4021, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.421, dice=tensor(3.1642, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3770 Dice: 0.6328
Epoch 75/199
----------
train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2539, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.357, dice=tensor(3.2539, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.321, dice=tensor(3.3156, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.321, dice=tensor(3.3156, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.317, dice=tensor(3.3405, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.317, dice=tensor(3.3405, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.329, dice=tensor(3.3559, device='cuda:0')]train Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.329, dice=tensor(3.3559, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3309 Dice: 0.6712
val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.43, dice=tensor(2.8843, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.43, dice=tensor(2.8843, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.321, dice=tensor(3.1653, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3756 Dice: 0.6331
Epoch 76/199
----------
train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3039, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.348, dice=tensor(3.3039, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.309, dice=tensor(3.3206, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.309, dice=tensor(3.3206, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.31, dice=tensor(3.3622, device='cuda:0')] train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.31, dice=tensor(3.3622, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.362, dice=tensor(3.3406, device='cuda:0')]train Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.362, dice=tensor(3.3406, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3324 Dice: 0.6681
val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.432, dice=tensor(2.8823, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.432, dice=tensor(2.8823, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.32, dice=tensor(3.1717, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                            val Loss: 0.3761 Dice: 0.6343
Epoch 77/199
----------
train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2414, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.86it/s, loss=0.357, dice=tensor(3.2414, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.86it/s, loss=0.318, dice=tensor(3.3380, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.15it/s, loss=0.318, dice=tensor(3.3380, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.15it/s, loss=0.357, dice=tensor(3.2572, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.06it/s, loss=0.357, dice=tensor(3.2572, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.06it/s, loss=0.322, dice=tensor(3.3023, device='cuda:0')]train Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.69it/s, loss=0.322, dice=tensor(3.3023, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3388 Dice: 0.6605
val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.0619, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.389, dice=tensor(3.0619, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.367, dice=tensor(3.1531, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3778 Dice: 0.6306
Epoch 78/199
----------
train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.2004, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.361, dice=tensor(3.2004, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.386, dice=tensor(3.1649, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.386, dice=tensor(3.1649, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.317, dice=tensor(3.2342, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.317, dice=tensor(3.2342, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.311, dice=tensor(3.2830, device='cuda:0')]train Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.311, dice=tensor(3.2830, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3436 Dice: 0.6566
val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.393, dice=tensor(3.1356, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.393, dice=tensor(3.1356, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.365, dice=tensor(3.1389, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3791 Dice: 0.6278
Epoch 79/199
----------
train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4430, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.32, dice=tensor(3.4430, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.38, dice=tensor(3.2871, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.38, dice=tensor(3.2871, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.296, dice=tensor(3.3746, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.296, dice=tensor(3.3746, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.328, dice=tensor(3.3706, device='cuda:0')]train Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.328, dice=tensor(3.3706, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3309 Dice: 0.6741
val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.414, dice=tensor(2.9691, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.414, dice=tensor(2.9691, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.351, dice=tensor(3.1379, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3827 Dice: 0.6276
Epoch 80/199
----------
train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4378, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.312, dice=tensor(3.4378, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.325, dice=tensor(3.4204, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.325, dice=tensor(3.4204, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.338, dice=tensor(3.3753, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.338, dice=tensor(3.3753, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.337, dice=tensor(3.3541, device='cuda:0')]train Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.337, dice=tensor(3.3541, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3278 Dice: 0.6708
val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.399, dice=tensor(2.9977, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.399, dice=tensor(2.9977, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.361, dice=tensor(3.1350, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3802 Dice: 0.6270
Epoch 81/199
----------
train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.2867, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.335, dice=tensor(3.2867, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.342, dice=tensor(3.3225, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.342, dice=tensor(3.3225, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.349, dice=tensor(3.3133, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.349, dice=tensor(3.3133, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.292, dice=tensor(3.3680, device='cuda:0')]train Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.292, dice=tensor(3.3680, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3293 Dice: 0.6736
val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.425, dice=tensor(2.9229, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.425, dice=tensor(2.9229, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.339, dice=tensor(3.1427, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3822 Dice: 0.6285
Epoch 82/199
----------
train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3380, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.339, dice=tensor(3.3380, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.349, dice=tensor(3.2995, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.349, dice=tensor(3.2995, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.312, dice=tensor(3.3526, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.312, dice=tensor(3.3526, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.323, dice=tensor(3.3568, device='cuda:0')]train Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.323, dice=tensor(3.3568, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3306 Dice: 0.6714
val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.427, dice=tensor(2.8906, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.427, dice=tensor(2.8906, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.332, dice=tensor(3.1446, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3796 Dice: 0.6289
Epoch 83/199
----------
train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.288, dice=tensor(3.5961, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.288, dice=tensor(3.5961, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.308, dice=tensor(3.4990, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.308, dice=tensor(3.4990, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.332, dice=tensor(3.4391, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.332, dice=tensor(3.4391, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.384, dice=tensor(3.3673, device='cuda:0')]train Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.384, dice=tensor(3.3673, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3281 Dice: 0.6735
val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.3006, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.353, dice=tensor(3.3006, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.408, dice=tensor(3.1489, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3804 Dice: 0.6298
Epoch 84/199
----------
train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.289, dice=tensor(3.5852, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.289, dice=tensor(3.5852, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.325, dice=tensor(3.4491, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.325, dice=tensor(3.4491, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.358, dice=tensor(3.3813, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.358, dice=tensor(3.3813, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.363, dice=tensor(3.3235, device='cuda:0')]train Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.363, dice=tensor(3.3235, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3337 Dice: 0.6647
val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.1857, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.355, dice=tensor(3.1857, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.394, dice=tensor(3.1605, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3746 Dice: 0.6321
Epoch 85/199
----------
train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.5128, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.304, dice=tensor(3.5128, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.361, dice=tensor(3.3605, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.361, dice=tensor(3.3605, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.304, dice=tensor(3.3987, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.62it/s, loss=0.304, dice=tensor(3.3987, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.62it/s, loss=0.355, dice=tensor(3.3586, device='cuda:0')]train Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.31it/s, loss=0.355, dice=tensor(3.3586, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3311 Dice: 0.6717
val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4585, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.316, dice=tensor(3.4585, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.428, dice=tensor(3.1707, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3722 Dice: 0.6341
Epoch 86/199
----------
train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4378, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.323, dice=tensor(3.4378, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.328, dice=tensor(3.3989, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.328, dice=tensor(3.3989, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.334, dice=tensor(3.3703, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.334, dice=tensor(3.3703, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.316, dice=tensor(3.3793, device='cuda:0')]train Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.316, dice=tensor(3.3793, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3252 Dice: 0.6759
val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.406, dice=tensor(2.9893, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.406, dice=tensor(2.9893, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.335, dice=tensor(3.1796, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3706 Dice: 0.6359
Epoch 87/199
----------
train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3866, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.337, dice=tensor(3.3866, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.303, dice=tensor(3.4617, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.303, dice=tensor(3.4617, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.36, dice=tensor(3.3573, device='cuda:0')] train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.36, dice=tensor(3.3573, device='cuda:0')]train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.337, dice=tensor(3.3304, device='cuda:0')]train Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.337, dice=tensor(3.3304, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3342 Dice: 0.6661
val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.1206, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.371, dice=tensor(3.1206, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.37, dice=tensor(3.1794, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.3704 Dice: 0.6359
Epoch 88/199
----------
train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.286, dice=tensor(3.6226, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.286, dice=tensor(3.6226, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.308, dice=tensor(3.5347, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.308, dice=tensor(3.5347, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.361, dice=tensor(3.4345, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.361, dice=tensor(3.4345, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.361, dice=tensor(3.3960, device='cuda:0')]train Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.361, dice=tensor(3.3960, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3288 Dice: 0.6792
val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.1136, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.381, dice=tensor(3.1136, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.362, dice=tensor(3.1781, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3712 Dice: 0.6356
Epoch 89/199
----------
train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.283, dice=tensor(3.6057, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.283, dice=tensor(3.6057, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.316, dice=tensor(3.5239, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.316, dice=tensor(3.5239, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.354, dice=tensor(3.4455, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.354, dice=tensor(3.4455, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.368, dice=tensor(3.3889, device='cuda:0')]train Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.368, dice=tensor(3.3889, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3302 Dice: 0.6778
val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1977, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.377, dice=tensor(3.1977, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.357, dice=tensor(3.1896, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3670 Dice: 0.6379
Epoch 90/199
----------
train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3372, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.339, dice=tensor(3.3372, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.281, dice=tensor(3.4618, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.281, dice=tensor(3.4618, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.365, dice=tensor(3.3650, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.365, dice=tensor(3.3650, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.342, dice=tensor(3.3578, device='cuda:0')]train Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.342, dice=tensor(3.3578, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3317 Dice: 0.6716
val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.1579, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.34it/s, loss=0.367, dice=tensor(3.1579, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.34it/s, loss=0.365, dice=tensor(3.1973, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3660 Dice: 0.6395
Epoch 91/199
----------
train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2019, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.36, dice=tensor(3.2019, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.335, dice=tensor(3.2600, device='cuda:0')]train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.335, dice=tensor(3.2600, device='cuda:0')]train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.68it/s, loss=0.291, dice=tensor(3.3542, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.61it/s, loss=0.291, dice=tensor(3.3542, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.337, dice=tensor(3.3608, device='cuda:0')]train Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.337, dice=tensor(3.3608, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3307 Dice: 0.6722
val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.1327, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.375, dice=tensor(3.1327, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.358, dice=tensor(3.1994, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3666 Dice: 0.6399
Epoch 92/199
----------
train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.3949, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.313, dice=tensor(3.3949, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.335, dice=tensor(3.3952, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.335, dice=tensor(3.3952, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.298, dice=tensor(3.4228, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.298, dice=tensor(3.4228, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.341, dice=tensor(3.4034, device='cuda:0')]train Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.341, dice=tensor(3.4034, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3221 Dice: 0.6807
val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.403, dice=tensor(3.0222, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.403, dice=tensor(3.0222, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.335, dice=tensor(3.2029, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3691 Dice: 0.6406
Epoch 93/199
----------
train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5527, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.29, dice=tensor(3.5527, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.365, dice=tensor(3.3848, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.365, dice=tensor(3.3848, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.366, dice=tensor(3.3494, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.366, dice=tensor(3.3494, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.316, dice=tensor(3.3658, device='cuda:0')]train Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.316, dice=tensor(3.3658, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3341 Dice: 0.6732
val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2507, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.343, dice=tensor(3.2507, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.387, dice=tensor(3.2016, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3648 Dice: 0.6403
Epoch 94/199
----------
train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.5258, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.291, dice=tensor(3.5258, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.345, dice=tensor(3.3315, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.345, dice=tensor(3.3315, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.338, dice=tensor(3.3274, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.338, dice=tensor(3.3274, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.359, dice=tensor(3.3106, device='cuda:0')]train Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.359, dice=tensor(3.3106, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3332 Dice: 0.6621
val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.383, dice=tensor(3.1790, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.383, dice=tensor(3.1790, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.348, dice=tensor(3.2005, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3659 Dice: 0.6401
Epoch 95/199
----------
train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4101, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.318, dice=tensor(3.4101, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.321, dice=tensor(3.3778, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.321, dice=tensor(3.3778, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.374, dice=tensor(3.2975, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.374, dice=tensor(3.2975, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.311, dice=tensor(3.3351, device='cuda:0')]train Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.311, dice=tensor(3.3351, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3312 Dice: 0.6670
val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.412, dice=tensor(2.9607, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.412, dice=tensor(2.9607, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.322, dice=tensor(3.1993, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3665 Dice: 0.6399
Epoch 96/199
----------
train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4564, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.318, dice=tensor(3.4564, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.314, dice=tensor(3.4271, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.19it/s, loss=0.314, dice=tensor(3.4271, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.19it/s, loss=0.336, dice=tensor(3.4055, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.10it/s, loss=0.336, dice=tensor(3.4055, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.10it/s, loss=0.33, dice=tensor(3.3822, device='cuda:0')] train Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.72it/s, loss=0.33, dice=tensor(3.3822, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                              train Loss: 0.3244 Dice: 0.6764
val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4207, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.326, dice=tensor(3.4207, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.41, dice=tensor(3.1994, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.3676 Dice: 0.6399
Epoch 97/199
----------
train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.0529, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.364, dice=tensor(3.0529, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.341, dice=tensor(3.1601, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.341, dice=tensor(3.1601, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.31, dice=tensor(3.2651, device='cuda:0')] train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.31, dice=tensor(3.2651, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.331, dice=tensor(3.2986, device='cuda:0')]train Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.331, dice=tensor(3.2986, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3362 Dice: 0.6597
val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.373, dice=tensor(3.1443, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.373, dice=tensor(3.1443, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.358, dice=tensor(3.2023, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3651 Dice: 0.6405
Epoch 98/199
----------
train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.31, dice=tensor(3.4881, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.31, dice=tensor(3.4881, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.326, dice=tensor(3.4419, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.326, dice=tensor(3.4419, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.334, dice=tensor(3.3823, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.334, dice=tensor(3.3823, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.341, dice=tensor(3.3605, device='cuda:0')]train Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.341, dice=tensor(3.3605, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3277 Dice: 0.6721
val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.0429, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.394, dice=tensor(3.0429, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.335, dice=tensor(3.2070, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3643 Dice: 0.6414
Epoch 99/199
----------
train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.1217, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.333, dice=tensor(3.1217, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.331, dice=tensor(3.2510, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.331, dice=tensor(3.2510, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.316, dice=tensor(3.3053, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.316, dice=tensor(3.3053, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.326, dice=tensor(3.3352, device='cuda:0')]train Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.326, dice=tensor(3.3352, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3267 Dice: 0.6670
val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.373, dice=tensor(3.1398, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.373, dice=tensor(3.1398, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.355, dice=tensor(3.2112, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3636 Dice: 0.6422
Epoch 100/199
----------
train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3814, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.96it/s, loss=0.334, dice=tensor(3.3814, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.96it/s, loss=0.316, dice=tensor(3.3126, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.27it/s, loss=0.316, dice=tensor(3.3126, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.27it/s, loss=0.355, dice=tensor(3.2932, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.16it/s, loss=0.355, dice=tensor(3.2932, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.16it/s, loss=0.319, dice=tensor(3.3250, device='cuda:0')]train Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.77it/s, loss=0.319, dice=tensor(3.3250, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3310 Dice: 0.6650
val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3824, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.334, dice=tensor(3.3824, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.392, dice=tensor(3.2151, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3631 Dice: 0.6430
Epoch 101/199
----------
train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3102, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.34, dice=tensor(3.3102, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.353, dice=tensor(3.2336, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.353, dice=tensor(3.2336, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.308, dice=tensor(3.3109, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.308, dice=tensor(3.3109, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.32, dice=tensor(3.3513, device='cuda:0')] train Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.32, dice=tensor(3.3513, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3299 Dice: 0.6703
val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3462, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.07it/s, loss=0.344, dice=tensor(3.3462, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.07it/s, loss=0.382, dice=tensor(3.2147, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3633 Dice: 0.6429
Epoch 102/199
----------
train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1359, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.376, dice=tensor(3.1359, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.323, dice=tensor(3.2743, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.323, dice=tensor(3.2743, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.287, dice=tensor(3.3542, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.287, dice=tensor(3.3542, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.341, dice=tensor(3.3515, device='cuda:0')]train Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.341, dice=tensor(3.3515, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3317 Dice: 0.6703
val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2044, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.353, dice=tensor(3.2044, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.373, dice=tensor(3.2147, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3629 Dice: 0.6429
Epoch 103/199
----------
train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2507, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.354, dice=tensor(3.2507, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.368, dice=tensor(3.2393, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.368, dice=tensor(3.2393, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.278, dice=tensor(3.3617, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.278, dice=tensor(3.3617, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.324, dice=tensor(3.3716, device='cuda:0')]train Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.324, dice=tensor(3.3716, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3310 Dice: 0.6743
val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2672, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.336, dice=tensor(3.2672, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.387, dice=tensor(3.2134, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3614 Dice: 0.6427
Epoch 104/199
----------
train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.1841, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.354, dice=tensor(3.1841, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.308, dice=tensor(3.3299, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.308, dice=tensor(3.3299, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.414, dice=tensor(3.2216, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.414, dice=tensor(3.2216, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.293, dice=tensor(3.2969, device='cuda:0')]train Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.293, dice=tensor(3.2969, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3423 Dice: 0.6594
val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.414, dice=tensor(2.9652, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.414, dice=tensor(2.9652, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.316, dice=tensor(3.2112, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3650 Dice: 0.6422
Epoch 105/199
----------
train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3529, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.341, dice=tensor(3.3529, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.389, dice=tensor(3.2208, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.389, dice=tensor(3.2208, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.266, dice=tensor(3.3940, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.266, dice=tensor(3.3940, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.336, dice=tensor(3.3870, device='cuda:0')]train Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.336, dice=tensor(3.3870, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3331 Dice: 0.6774
val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.383, dice=tensor(3.0945, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.383, dice=tensor(3.0945, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.348, dice=tensor(3.2069, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3657 Dice: 0.6414
Epoch 106/199
----------
train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.296, dice=tensor(3.5099, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.296, dice=tensor(3.5099, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.331, dice=tensor(3.4271, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.331, dice=tensor(3.4271, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.286, dice=tensor(3.4777, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.286, dice=tensor(3.4777, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.386, dice=tensor(3.3969, device='cuda:0')]train Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.386, dice=tensor(3.3969, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3248 Dice: 0.6794
val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3619, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.342, dice=tensor(3.3619, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.396, dice=tensor(3.1953, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3690 Dice: 0.6391
Epoch 107/199
----------
train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4552, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.306, dice=tensor(3.4552, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.31, dice=tensor(3.4341, device='cuda:0')] train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.31, dice=tensor(3.4341, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.363, dice=tensor(3.3764, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.363, dice=tensor(3.3764, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.328, dice=tensor(3.3640, device='cuda:0')]train Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.328, dice=tensor(3.3640, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3267 Dice: 0.6728
val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.42, dice=tensor(2.9283, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.42, dice=tensor(2.9283, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.317, dice=tensor(3.1955, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3688 Dice: 0.6391
Epoch 108/199
----------
train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.1305, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.375, dice=tensor(3.1305, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.277, dice=tensor(3.3665, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.277, dice=tensor(3.3665, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.334, dice=tensor(3.3741, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.334, dice=tensor(3.3741, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.331, dice=tensor(3.3653, device='cuda:0')]train Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.331, dice=tensor(3.3653, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3294 Dice: 0.6731
val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.2603, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.366, dice=tensor(3.2603, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.366, dice=tensor(3.2011, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3659 Dice: 0.6402
Epoch 109/199
----------
train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4408, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.322, dice=tensor(3.4408, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.357, dice=tensor(3.3322, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.357, dice=tensor(3.3322, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.351, dice=tensor(3.2871, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.351, dice=tensor(3.2871, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.288, dice=tensor(3.3453, device='cuda:0')]train Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.288, dice=tensor(3.3453, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3295 Dice: 0.6691
val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.409, dice=tensor(2.9972, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.409, dice=tensor(2.9972, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.322, dice=tensor(3.2189, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3653 Dice: 0.6438
Epoch 110/199
----------
train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2230, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.362, dice=tensor(3.2230, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.287, dice=tensor(3.4060, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.287, dice=tensor(3.4060, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.324, dice=tensor(3.4010, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.324, dice=tensor(3.4010, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.328, dice=tensor(3.3814, device='cuda:0')]train Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.328, dice=tensor(3.3814, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3250 Dice: 0.6763
val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.4, dice=tensor(3.0258, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.4, dice=tensor(3.0258, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.323, dice=tensor(3.2289, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3617 Dice: 0.6458
Epoch 111/199
----------
train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.2371, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.332, dice=tensor(3.2371, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.31, dice=tensor(3.3038, device='cuda:0')] train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.31, dice=tensor(3.3038, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.328, dice=tensor(3.3361, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.328, dice=tensor(3.3361, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.341, dice=tensor(3.3341, device='cuda:0')]train Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.341, dice=tensor(3.3341, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3278 Dice: 0.6668
val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.2798, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.334, dice=tensor(3.2798, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.381, dice=tensor(3.2301, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3574 Dice: 0.6460
Epoch 112/199
----------
train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4370, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.311, dice=tensor(3.4370, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.311, dice=tensor(3.4491, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.311, dice=tensor(3.4491, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.329, dice=tensor(3.3917, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.329, dice=tensor(3.3917, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.36, dice=tensor(3.3545, device='cuda:0')] train Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.36, dice=tensor(3.3545, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3279 Dice: 0.6709
val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4419, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.321, dice=tensor(3.4419, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.404, dice=tensor(3.2250, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3621 Dice: 0.6450
Epoch 113/199
----------
train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3724, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.329, dice=tensor(3.3724, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.306, dice=tensor(3.4126, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.306, dice=tensor(3.4126, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.364, dice=tensor(3.3595, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.364, dice=tensor(3.3595, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.291, dice=tensor(3.4034, device='cuda:0')]train Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.291, dice=tensor(3.4034, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3226 Dice: 0.6807
val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.1775, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.94it/s, loss=0.381, dice=tensor(3.1775, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.94it/s, loss=0.337, dice=tensor(3.2287, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3591 Dice: 0.6457
Epoch 114/199
----------
train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.2950, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.339, dice=tensor(3.2950, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.283, dice=tensor(3.4448, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.283, dice=tensor(3.4448, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.373, dice=tensor(3.3621, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.373, dice=tensor(3.3621, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.306, dice=tensor(3.3982, device='cuda:0')]train Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.306, dice=tensor(3.3982, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3252 Dice: 0.6796
val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.407, dice=tensor(3.0087, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.407, dice=tensor(3.0087, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.321, dice=tensor(3.2281, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3640 Dice: 0.6456
Epoch 115/199
----------
train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.2150, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.346, dice=tensor(3.2150, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.33, dice=tensor(3.2795, device='cuda:0')] train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.33, dice=tensor(3.2795, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.295, dice=tensor(3.3779, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.295, dice=tensor(3.3779, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.346, dice=tensor(3.3546, device='cuda:0')]train Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.346, dice=tensor(3.3546, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3291 Dice: 0.6709
val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.1817, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.359, dice=tensor(3.1817, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.363, dice=tensor(3.2185, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3613 Dice: 0.6437
Epoch 116/199
----------
train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.3759, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.314, dice=tensor(3.3759, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.365, dice=tensor(3.3048, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.365, dice=tensor(3.3048, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.314, dice=tensor(3.3374, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.314, dice=tensor(3.3374, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.309, dice=tensor(3.3704, device='cuda:0')]train Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.309, dice=tensor(3.3704, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3256 Dice: 0.6741
val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4201, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.326, dice=tensor(3.4201, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.4, dice=tensor(3.2194, device='cuda:0')]  /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                            val Loss: 0.3629 Dice: 0.6439
Epoch 117/199
----------
train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3365, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.95it/s, loss=0.322, dice=tensor(3.3365, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.95it/s, loss=0.304, dice=tensor(3.3928, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.25it/s, loss=0.304, dice=tensor(3.3928, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.25it/s, loss=0.307, dice=tensor(3.4341, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.14it/s, loss=0.307, dice=tensor(3.4341, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.14it/s, loss=0.345, dice=tensor(3.4051, device='cuda:0')]train Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.75it/s, loss=0.345, dice=tensor(3.4051, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3196 Dice: 0.6810
val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.4036, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.33, dice=tensor(3.4036, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.398, dice=tensor(3.2243, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3641 Dice: 0.6449
Epoch 118/199
----------
train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.292, dice=tensor(3.5990, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.292, dice=tensor(3.5990, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.31, dice=tensor(3.4939, device='cuda:0')] train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.31, dice=tensor(3.4939, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.356, dice=tensor(3.4312, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.356, dice=tensor(3.4312, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.33, dice=tensor(3.4170, device='cuda:0')] train Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.33, dice=tensor(3.4170, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3222 Dice: 0.6834
val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3829, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.338, dice=tensor(3.3829, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.382, dice=tensor(3.2257, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3598 Dice: 0.6451
Epoch 119/199
----------
train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.4982, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.293, dice=tensor(3.4982, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.305, dice=tensor(3.4925, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.305, dice=tensor(3.4925, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.365, dice=tensor(3.3992, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.365, dice=tensor(3.3992, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.324, dice=tensor(3.4077, device='cuda:0')]train Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.324, dice=tensor(3.4077, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3218 Dice: 0.6815
val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.4027, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.331, dice=tensor(3.4027, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.392, dice=tensor(3.2295, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3614 Dice: 0.6459
Epoch 120/199
----------
train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.1669, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.356, dice=tensor(3.1669, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.328, dice=tensor(3.2704, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.328, dice=tensor(3.2704, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.317, dice=tensor(3.3266, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.317, dice=tensor(3.3266, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.286, dice=tensor(3.3955, device='cuda:0')]train Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.286, dice=tensor(3.3955, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3219 Dice: 0.6791
val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0661, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.39, dice=tensor(3.0661, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.33, dice=tensor(3.2357, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3602 Dice: 0.6471
Epoch 121/199
----------
train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.1963, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.365, dice=tensor(3.1963, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.305, dice=tensor(3.3553, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.305, dice=tensor(3.3553, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.295, dice=tensor(3.4094, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.295, dice=tensor(3.4094, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.334, dice=tensor(3.3708, device='cuda:0')]train Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.334, dice=tensor(3.3708, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3246 Dice: 0.6742
val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1284, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.377, dice=tensor(3.1284, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.344, dice=tensor(3.2332, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3603 Dice: 0.6466
Epoch 122/199
----------
train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.2421, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.364, dice=tensor(3.2421, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.334, dice=tensor(3.2819, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.334, dice=tensor(3.2819, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.31, dice=tensor(3.3428, device='cuda:0')] train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.31, dice=tensor(3.3428, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.27, dice=tensor(3.4233, device='cuda:0')]train Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.27, dice=tensor(3.4233, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3195 Dice: 0.6847
val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.0197, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.398, dice=tensor(3.0197, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.323, dice=tensor(3.2274, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3604 Dice: 0.6455
Epoch 123/199
----------
train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.4245, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.33, dice=tensor(3.4245, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.314, dice=tensor(3.4055, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.314, dice=tensor(3.4055, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.343, dice=tensor(3.3821, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.343, dice=tensor(3.3821, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.284, dice=tensor(3.4369, device='cuda:0')]train Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.284, dice=tensor(3.4369, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3177 Dice: 0.6874
val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0514, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.39, dice=tensor(3.0514, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.333, dice=tensor(3.2255, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3615 Dice: 0.6451
Epoch 124/199
----------
train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4220, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.315, dice=tensor(3.4220, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.338, dice=tensor(3.3462, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.338, dice=tensor(3.3462, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.292, dice=tensor(3.4268, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.292, dice=tensor(3.4268, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.367, dice=tensor(3.3724, device='cuda:0')]train Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.367, dice=tensor(3.3724, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3279 Dice: 0.6745
val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1110, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.378, dice=tensor(3.1110, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.342, dice=tensor(3.2324, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3603 Dice: 0.6465
Epoch 125/199
----------
train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.2356, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.348, dice=tensor(3.2356, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.274, dice=tensor(3.3966, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.274, dice=tensor(3.3966, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.31, dice=tensor(3.4295, device='cuda:0')] train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.31, dice=tensor(3.4295, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.352, dice=tensor(3.3873, device='cuda:0')]train Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.352, dice=tensor(3.3873, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3211 Dice: 0.6775
val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.2237, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.349, dice=tensor(3.2237, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.366, dice=tensor(3.2395, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3576 Dice: 0.6479
Epoch 126/199
----------
train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4524, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.311, dice=tensor(3.4524, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.305, dice=tensor(3.4494, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.305, dice=tensor(3.4494, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.296, dice=tensor(3.4858, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.296, dice=tensor(3.4858, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.39, dice=tensor(3.3824, device='cuda:0')] train Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.39, dice=tensor(3.3824, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3258 Dice: 0.6765
val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2257, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.35, dice=tensor(3.2257, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.362, dice=tensor(3.2442, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3559 Dice: 0.6488
Epoch 127/199
----------
train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.298, dice=tensor(3.5447, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.298, dice=tensor(3.5447, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.346, dice=tensor(3.4028, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.346, dice=tensor(3.4028, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.317, dice=tensor(3.4126, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.317, dice=tensor(3.4126, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.334, dice=tensor(3.3735, device='cuda:0')]train Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.334, dice=tensor(3.3735, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3236 Dice: 0.6747
val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4317, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.323, dice=tensor(3.4317, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.394, dice=tensor(3.2449, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3586 Dice: 0.6490
Epoch 128/199
----------
train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.2262, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.374, dice=tensor(3.2262, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.307, dice=tensor(3.3583, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.307, dice=tensor(3.3583, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.307, dice=tensor(3.3957, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.307, dice=tensor(3.3957, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.314, dice=tensor(3.4087, device='cuda:0')]train Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.314, dice=tensor(3.4087, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3254 Dice: 0.6817
val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.1487, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.374, dice=tensor(3.1487, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.339, dice=tensor(3.2457, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3563 Dice: 0.6491
Epoch 129/199
----------
train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.299, dice=tensor(3.4891, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.299, dice=tensor(3.4891, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.336, dice=tensor(3.3623, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.336, dice=tensor(3.3623, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.35, dice=tensor(3.3346, device='cuda:0')] train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.35, dice=tensor(3.3346, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.325, dice=tensor(3.3546, device='cuda:0')]train Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.325, dice=tensor(3.3546, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3272 Dice: 0.6709
val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2313, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.352, dice=tensor(3.2313, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.357, dice=tensor(3.2490, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3549 Dice: 0.6498
Epoch 130/199
----------
train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4553, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.318, dice=tensor(3.4553, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.326, dice=tensor(3.4165, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.326, dice=tensor(3.4165, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.31, dice=tensor(3.4162, device='cuda:0')] train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.31, dice=tensor(3.4162, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.317, dice=tensor(3.4174, device='cuda:0')]train Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.317, dice=tensor(3.4174, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3178 Dice: 0.6835
val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.2112, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.374, dice=tensor(3.2112, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.334, dice=tensor(3.2518, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3543 Dice: 0.6504
Epoch 131/199
----------
train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.2054, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.371, dice=tensor(3.2054, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.29, dice=tensor(3.3776, device='cuda:0')] train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.29, dice=tensor(3.3776, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.3, dice=tensor(3.4068, device='cuda:0')] train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.3, dice=tensor(3.4068, device='cuda:0')]train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.338, dice=tensor(3.3845, device='cuda:0')]train Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.338, dice=tensor(3.3845, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3248 Dice: 0.6769
val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.3019, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.33, dice=tensor(3.3019, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.377, dice=tensor(3.2530, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3535 Dice: 0.6506
Epoch 132/199
----------
train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4189, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.306, dice=tensor(3.4189, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.332, dice=tensor(3.3823, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.332, dice=tensor(3.3823, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.305, dice=tensor(3.4202, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.305, dice=tensor(3.4202, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.314, dice=tensor(3.4342, device='cuda:0')]train Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.314, dice=tensor(3.4342, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3142 Dice: 0.6868
val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.2382, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.346, dice=tensor(3.2382, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.365, dice=tensor(3.2462, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3556 Dice: 0.6492
Epoch 133/199
----------
train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4659, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.92it/s, loss=0.311, dice=tensor(3.4659, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.92it/s, loss=0.313, dice=tensor(3.4742, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.23it/s, loss=0.313, dice=tensor(3.4742, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.23it/s, loss=0.318, dice=tensor(3.4485, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.12it/s, loss=0.318, dice=tensor(3.4485, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.12it/s, loss=0.313, dice=tensor(3.4384, device='cuda:0')]train Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.75it/s, loss=0.313, dice=tensor(3.4384, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3138 Dice: 0.6877
val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2959, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.358, dice=tensor(3.2959, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.355, dice=tensor(3.2451, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3564 Dice: 0.6490
Epoch 134/199
----------
train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4677, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.306, dice=tensor(3.4677, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.322, dice=tensor(3.4428, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.322, dice=tensor(3.4428, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.334, dice=tensor(3.3910, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.334, dice=tensor(3.3910, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.315, dice=tensor(3.4084, device='cuda:0')]train Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.315, dice=tensor(3.4084, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3191 Dice: 0.6817
val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.3252, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.349, dice=tensor(3.3252, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.364, dice=tensor(3.2469, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3562 Dice: 0.6494
Epoch 135/199
----------
train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.397, dice=tensor(3.0473, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.397, dice=tensor(3.0473, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.3, dice=tensor(3.2699, device='cuda:0')]  train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.3, dice=tensor(3.2699, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.325, dice=tensor(3.3199, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.325, dice=tensor(3.3199, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.278, dice=tensor(3.3945, device='cuda:0')]train Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.278, dice=tensor(3.3945, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3250 Dice: 0.6789
val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.1934, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.357, dice=tensor(3.1934, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.352, dice=tensor(3.2542, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3544 Dice: 0.6508
Epoch 136/199
----------
train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3209, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.345, dice=tensor(3.3209, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.354, dice=tensor(3.2899, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.354, dice=tensor(3.2899, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.255, dice=tensor(3.4457, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.255, dice=tensor(3.4457, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.348, dice=tensor(3.4015, device='cuda:0')]train Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.348, dice=tensor(3.4015, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3255 Dice: 0.6803
val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4464, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.321, dice=tensor(3.4464, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.396, dice=tensor(3.2457, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3586 Dice: 0.6491
Epoch 137/199
----------
train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.5163, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.293, dice=tensor(3.5163, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.301, dice=tensor(3.5315, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.301, dice=tensor(3.5315, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.395, dice=tensor(3.3766, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.395, dice=tensor(3.3766, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.304, dice=tensor(3.4054, device='cuda:0')]train Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.304, dice=tensor(3.4054, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3233 Dice: 0.6811
val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.407, dice=tensor(3.0010, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.407, dice=tensor(3.0010, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.32, dice=tensor(3.2312, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3631 Dice: 0.6462
Epoch 138/199
----------
train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.28, dice=tensor(3.5973, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.28, dice=tensor(3.5973, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.32, dice=tensor(3.5385, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.32, dice=tensor(3.5385, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.327, dice=tensor(3.4674, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.327, dice=tensor(3.4674, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.34, dice=tensor(3.4384, device='cuda:0')] train Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.34, dice=tensor(3.4384, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3167 Dice: 0.6877
val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4755, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.314, dice=tensor(3.4755, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.413, dice=tensor(3.2236, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3634 Dice: 0.6447
Epoch 139/199
----------
train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3192, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.334, dice=tensor(3.3192, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.31, dice=tensor(3.4007, device='cuda:0')] train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.31, dice=tensor(3.4007, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.36, dice=tensor(3.2927, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.36, dice=tensor(3.2927, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.301, dice=tensor(3.3542, device='cuda:0')]train Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.34it/s, loss=0.301, dice=tensor(3.3542, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3261 Dice: 0.6708
val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.2151, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.377, dice=tensor(3.2151, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.34, dice=tensor(3.2396, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3582 Dice: 0.6479
Epoch 140/199
----------
train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4437, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.311, dice=tensor(3.4437, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.345, dice=tensor(3.3510, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.345, dice=tensor(3.3510, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.294, dice=tensor(3.4107, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.294, dice=tensor(3.4107, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.331, dice=tensor(3.4007, device='cuda:0')]train Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.331, dice=tensor(3.4007, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3201 Dice: 0.6801
val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.406, dice=tensor(2.9972, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.406, dice=tensor(2.9972, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.313, dice=tensor(3.2424, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3593 Dice: 0.6485
Epoch 141/199
----------
train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2439, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.359, dice=tensor(3.2439, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.375, dice=tensor(3.1690, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.375, dice=tensor(3.1690, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.309, dice=tensor(3.2706, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.309, dice=tensor(3.2706, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.27, dice=tensor(3.3730, device='cuda:0')] train Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.27, dice=tensor(3.3730, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3284 Dice: 0.6746
val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3982, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.38it/s, loss=0.335, dice=tensor(3.3982, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.38it/s, loss=0.381, dice=tensor(3.2421, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3576 Dice: 0.6484
Epoch 142/199
----------
train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.4446, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.319, dice=tensor(3.4446, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.292, dice=tensor(3.4778, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.292, dice=tensor(3.4778, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.312, dice=tensor(3.4644, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.312, dice=tensor(3.4644, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.352, dice=tensor(3.4229, device='cuda:0')]train Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.352, dice=tensor(3.4229, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3187 Dice: 0.6846
val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.0483, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.389, dice=tensor(3.0483, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.33, dice=tensor(3.2346, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3597 Dice: 0.6469
Epoch 143/199
----------
train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.292, dice=tensor(3.5369, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.292, dice=tensor(3.5369, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.319, dice=tensor(3.4462, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.65it/s, loss=0.319, dice=tensor(3.4462, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.65it/s, loss=0.332, dice=tensor(3.4291, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.332, dice=tensor(3.4291, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.58it/s, loss=0.321, dice=tensor(3.4282, device='cuda:0')]train Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.29it/s, loss=0.321, dice=tensor(3.4282, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3158 Dice: 0.6856
val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2529, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.343, dice=tensor(3.2529, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.374, dice=tensor(3.2377, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3584 Dice: 0.6475
Epoch 144/199
----------
train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2857, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.352, dice=tensor(3.2857, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.296, dice=tensor(3.3881, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.296, dice=tensor(3.3881, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.31, dice=tensor(3.4038, device='cuda:0')] train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.31, dice=tensor(3.4038, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.298, dice=tensor(3.4375, device='cuda:0')]train Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.298, dice=tensor(3.4375, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3141 Dice: 0.6875
val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3381, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.346, dice=tensor(3.3381, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.37, dice=tensor(3.2451, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3577 Dice: 0.6490
Epoch 145/199
----------
train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.4894, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.303, dice=tensor(3.4894, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.332, dice=tensor(3.4399, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.332, dice=tensor(3.4399, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.309, dice=tensor(3.4579, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.309, dice=tensor(3.4579, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.318, dice=tensor(3.4334, device='cuda:0')]train Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.318, dice=tensor(3.4334, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3152 Dice: 0.6867
val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.0257, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.398, dice=tensor(3.0257, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.314, dice=tensor(3.2520, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3558 Dice: 0.6504
Epoch 146/199
----------
train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3270, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.334, dice=tensor(3.3270, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.315, dice=tensor(3.3900, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.315, dice=tensor(3.3900, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.321, dice=tensor(3.3963, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.321, dice=tensor(3.3963, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.299, dice=tensor(3.4104, device='cuda:0')]train Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.299, dice=tensor(3.4104, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3173 Dice: 0.6821
val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.1437, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.375, dice=tensor(3.1437, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.337, dice=tensor(3.2566, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3561 Dice: 0.6513
Epoch 147/199
----------
train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4209, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.32, dice=tensor(3.4209, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.358, dice=tensor(3.3564, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.358, dice=tensor(3.3564, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.308, dice=tensor(3.3946, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.308, dice=tensor(3.3946, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.282, dice=tensor(3.4461, device='cuda:0')]train Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.282, dice=tensor(3.4461, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3170 Dice: 0.6892
val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3554, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.341, dice=tensor(3.3554, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.368, dice=tensor(3.2634, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3545 Dice: 0.6527
Epoch 148/199
----------
train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4228, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.315, dice=tensor(3.4228, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.301, dice=tensor(3.4594, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.301, dice=tensor(3.4594, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.3, dice=tensor(3.4665, device='cuda:0')]  train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.05it/s, loss=0.3, dice=tensor(3.4665, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.05it/s, loss=0.344, dice=tensor(3.4188, device='cuda:0')]train Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.68it/s, loss=0.344, dice=tensor(3.4188, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3149 Dice: 0.6838
val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.1687, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.361, dice=tensor(3.1687, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.343, dice=tensor(3.2678, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3519 Dice: 0.6536
Epoch 149/199
----------
train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.283, dice=tensor(3.5803, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.283, dice=tensor(3.5803, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.314, dice=tensor(3.5079, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.314, dice=tensor(3.5079, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.327, dice=tensor(3.4771, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.327, dice=tensor(3.4771, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.324, dice=tensor(3.4387, device='cuda:0')]train Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.324, dice=tensor(3.4387, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3120 Dice: 0.6877
val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.0252, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.398, dice=tensor(3.0252, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.301, dice=tensor(3.2756, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3495 Dice: 0.6551
Epoch 150/199
----------
train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.289, dice=tensor(3.5762, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.289, dice=tensor(3.5762, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.281, dice=tensor(3.6148, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.281, dice=tensor(3.6148, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.367, dice=tensor(3.4712, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.367, dice=tensor(3.4712, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.355, dice=tensor(3.3957, device='cuda:0')]train Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.355, dice=tensor(3.3957, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3231 Dice: 0.6791
val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.4291, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.325, dice=tensor(3.4291, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.381, dice=tensor(3.2786, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3529 Dice: 0.6557
Epoch 151/199
----------
train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3601, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.335, dice=tensor(3.3601, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.357, dice=tensor(3.3254, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.357, dice=tensor(3.3254, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.272, dice=tensor(3.4302, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.272, dice=tensor(3.4302, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.303, dice=tensor(3.4371, device='cuda:0')]train Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.303, dice=tensor(3.4371, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3168 Dice: 0.6874
val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.2560, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.349, dice=tensor(3.2560, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.35, dice=tensor(3.2778, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3495 Dice: 0.6556
Epoch 152/199
----------
train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.2184, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.366, dice=tensor(3.2184, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.306, dice=tensor(3.3588, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.306, dice=tensor(3.3588, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.287, dice=tensor(3.4454, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.287, dice=tensor(3.4454, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.302, dice=tensor(3.4603, device='cuda:0')]train Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.302, dice=tensor(3.4603, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3152 Dice: 0.6921
val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1358, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.379, dice=tensor(3.1358, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.326, dice=tensor(3.2829, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3521 Dice: 0.6566
Epoch 153/199
----------
train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.3434, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.321, dice=tensor(3.3434, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.341, dice=tensor(3.3380, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.341, dice=tensor(3.3380, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.323, dice=tensor(3.3674, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.323, dice=tensor(3.3674, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.295, dice=tensor(3.4073, device='cuda:0')]train Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.295, dice=tensor(3.4073, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3200 Dice: 0.6815
val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3244, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.351, dice=tensor(3.3244, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.348, dice=tensor(3.2796, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3492 Dice: 0.6559
Epoch 154/199
----------
train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.286, dice=tensor(3.5677, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.286, dice=tensor(3.5677, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.315, dice=tensor(3.5045, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.315, dice=tensor(3.5045, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.314, dice=tensor(3.4872, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.314, dice=tensor(3.4872, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.33, dice=tensor(3.4486, device='cuda:0')] train Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.33, dice=tensor(3.4486, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3112 Dice: 0.6897
val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3619, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.85it/s, loss=0.338, dice=tensor(3.3619, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.85it/s, loss=0.365, dice=tensor(3.2739, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3514 Dice: 0.6548
Epoch 155/199
----------
train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2949, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.343, dice=tensor(3.2949, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.26, dice=tensor(3.4872, device='cuda:0')] train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.26, dice=tensor(3.4872, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.333, dice=tensor(3.4347, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.333, dice=tensor(3.4347, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.323, dice=tensor(3.4325, device='cuda:0')]train Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.323, dice=tensor(3.4325, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3148 Dice: 0.6865
val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.2001, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.356, dice=tensor(3.2001, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.348, dice=tensor(3.2704, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3518 Dice: 0.6541
Epoch 156/199
----------
train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3162, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.337, dice=tensor(3.3162, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.318, dice=tensor(3.3896, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.318, dice=tensor(3.3896, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.315, dice=tensor(3.4009, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.315, dice=tensor(3.4009, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.309, dice=tensor(3.3910, device='cuda:0')]train Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.309, dice=tensor(3.3910, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3200 Dice: 0.6782
val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2486, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.345, dice=tensor(3.2486, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.357, dice=tensor(3.2731, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3512 Dice: 0.6546
Epoch 157/199
----------
train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.3572, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.321, dice=tensor(3.3572, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.304, dice=tensor(3.4317, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.304, dice=tensor(3.4317, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.315, dice=tensor(3.4156, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.315, dice=tensor(3.4156, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.321, dice=tensor(3.4155, device='cuda:0')]train Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.321, dice=tensor(3.4155, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3152 Dice: 0.6831
val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3769, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.337, dice=tensor(3.3769, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.367, dice=tensor(3.2712, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3518 Dice: 0.6542
Epoch 158/199
----------
train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.284, dice=tensor(3.6078, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.284, dice=tensor(3.6078, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.324, dice=tensor(3.5069, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.324, dice=tensor(3.5069, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.295, dice=tensor(3.4982, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.64it/s, loss=0.295, dice=tensor(3.4982, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.64it/s, loss=0.351, dice=tensor(3.4416, device='cuda:0')]train Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.351, dice=tensor(3.4416, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3133 Dice: 0.6883
val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.2446, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.349, dice=tensor(3.2446, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.353, dice=tensor(3.2747, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3508 Dice: 0.6549
Epoch 159/199
----------
train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.2980, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.323, dice=tensor(3.2980, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.303, dice=tensor(3.3744, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.303, dice=tensor(3.3744, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.311, dice=tensor(3.3947, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.311, dice=tensor(3.3947, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.331, dice=tensor(3.3910, device='cuda:0')]train Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.331, dice=tensor(3.3910, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3170 Dice: 0.6782
val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.2653, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.346, dice=tensor(3.2653, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.351, dice=tensor(3.2863, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3481 Dice: 0.6573
Epoch 160/199
----------
train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3957, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.335, dice=tensor(3.3957, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.311, dice=tensor(3.4236, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.311, dice=tensor(3.4236, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.278, dice=tensor(3.4906, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.278, dice=tensor(3.4906, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.335, dice=tensor(3.4433, device='cuda:0')]train Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.335, dice=tensor(3.4433, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3147 Dice: 0.6887
val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3832, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.336, dice=tensor(3.3832, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.362, dice=tensor(3.2884, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3489 Dice: 0.6577
Epoch 161/199
----------
train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2979, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.345, dice=tensor(3.2979, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.345, dice=tensor(3.3128, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.345, dice=tensor(3.3128, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.3, dice=tensor(3.3762, device='cuda:0')]  train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.3, dice=tensor(3.3762, device='cuda:0')]train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.263, dice=tensor(3.4588, device='cuda:0')]train Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.263, dice=tensor(3.4588, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3132 Dice: 0.6918
val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4395, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.23it/s, loss=0.323, dice=tensor(3.4395, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.23it/s, loss=0.379, dice=tensor(3.2889, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3508 Dice: 0.6578
Epoch 162/199
----------
train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4032, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.312, dice=tensor(3.4032, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.328, dice=tensor(3.3559, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.328, dice=tensor(3.3559, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.294, dice=tensor(3.4154, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.294, dice=tensor(3.4154, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.333, dice=tensor(3.4062, device='cuda:0')]train Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.333, dice=tensor(3.4062, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3164 Dice: 0.6812
val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.2073, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.374, dice=tensor(3.2073, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.318, dice=tensor(3.2912, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3459 Dice: 0.6582
Epoch 163/199
----------
train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3436, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.327, dice=tensor(3.3436, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.349, dice=tensor(3.3302, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.349, dice=tensor(3.3302, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.292, dice=tensor(3.4100, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.292, dice=tensor(3.4100, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.3, dice=tensor(3.4245, device='cuda:0')]  train Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.3, dice=tensor(3.4245, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                              train Loss: 0.3170 Dice: 0.6849
val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2502, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.352, dice=tensor(3.2502, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.342, dice=tensor(3.2943, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3471 Dice: 0.6589
Epoch 164/199
----------
train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.287, dice=tensor(3.5924, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.287, dice=tensor(3.5924, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.288, dice=tensor(3.5601, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.288, dice=tensor(3.5601, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.383, dice=tensor(3.4235, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.383, dice=tensor(3.4235, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.306, dice=tensor(3.4414, device='cuda:0')]train Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.306, dice=tensor(3.4414, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3158 Dice: 0.6883
val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1887, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.366, dice=tensor(3.1887, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.332, dice=tensor(3.2937, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3488 Dice: 0.6587
Epoch 165/199
----------
train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.3613, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.313, dice=tensor(3.3613, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.32, dice=tensor(3.3895, device='cuda:0')] train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.32, dice=tensor(3.3895, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.287, dice=tensor(3.4541, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.287, dice=tensor(3.4541, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.338, dice=tensor(3.4287, device='cuda:0')]train Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.338, dice=tensor(3.4287, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3142 Dice: 0.6857
val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3458, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.324, dice=tensor(3.3458, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.368, dice=tensor(3.2924, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3460 Dice: 0.6585
Epoch 166/199
----------
train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3287, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.341, dice=tensor(3.3287, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.316, dice=tensor(3.3807, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.316, dice=tensor(3.3807, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.304, dice=tensor(3.4005, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.304, dice=tensor(3.4005, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.303, dice=tensor(3.4151, device='cuda:0')]train Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.303, dice=tensor(3.4151, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3158 Dice: 0.6830
val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.2385, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.369, dice=tensor(3.2385, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.321, dice=tensor(3.2929, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3451 Dice: 0.6586
Epoch 167/199
----------
train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.268, dice=tensor(3.6875, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.90it/s, loss=0.268, dice=tensor(3.6875, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.90it/s, loss=0.306, dice=tensor(3.5684, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.20it/s, loss=0.306, dice=tensor(3.5684, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.20it/s, loss=0.347, dice=tensor(3.4808, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.09it/s, loss=0.347, dice=tensor(3.4808, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.09it/s, loss=0.332, dice=tensor(3.4518, device='cuda:0')]train Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.71it/s, loss=0.332, dice=tensor(3.4518, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3130 Dice: 0.6904
val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3752, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.336, dice=tensor(3.3752, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.36, dice=tensor(3.2928, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3479 Dice: 0.6586
Epoch 168/199
----------
train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3636, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.329, dice=tensor(3.3636, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.306, dice=tensor(3.3811, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.306, dice=tensor(3.3811, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.306, dice=tensor(3.4256, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.306, dice=tensor(3.4256, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.31, dice=tensor(3.4320, device='cuda:0')] train Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.31, dice=tensor(3.4320, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3126 Dice: 0.6864
val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2109, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.357, dice=tensor(3.2109, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.337, dice=tensor(3.2926, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3469 Dice: 0.6585
Epoch 169/199
----------
train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3664, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.337, dice=tensor(3.3664, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.303, dice=tensor(3.4161, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.303, dice=tensor(3.4161, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.292, dice=tensor(3.4563, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.292, dice=tensor(3.4563, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.317, dice=tensor(3.4567, device='cuda:0')]train Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.317, dice=tensor(3.4567, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3124 Dice: 0.6913
val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3228, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.327, dice=tensor(3.3228, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.39it/s, loss=0.364, dice=tensor(3.2955, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3453 Dice: 0.6591
Epoch 170/199
----------
train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2893, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.353, dice=tensor(3.2893, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.348, dice=tensor(3.2762, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.348, dice=tensor(3.2762, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.296, dice=tensor(3.3472, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.296, dice=tensor(3.3472, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.285, dice=tensor(3.4110, device='cuda:0')]train Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.285, dice=tensor(3.4110, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3206 Dice: 0.6822
val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3313, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.345, dice=tensor(3.3313, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.347, dice=tensor(3.2976, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3459 Dice: 0.6595
Epoch 171/199
----------
train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.5048, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.308, dice=tensor(3.5048, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.28, dice=tensor(3.5632, device='cuda:0')] train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.28, dice=tensor(3.5632, device='cuda:0')]train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.348, dice=tensor(3.4651, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.348, dice=tensor(3.4651, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.31, dice=tensor(3.4646, device='cuda:0')] train Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.31, dice=tensor(3.4646, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3114 Dice: 0.6929
val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.2501, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.349, dice=tensor(3.2501, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.341, dice=tensor(3.3006, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3452 Dice: 0.6601
Epoch 172/199
----------
train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4498, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.313, dice=tensor(3.4498, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.314, dice=tensor(3.4309, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.314, dice=tensor(3.4309, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.294, dice=tensor(3.4442, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.294, dice=tensor(3.4442, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.332, dice=tensor(3.4283, device='cuda:0')]train Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.332, dice=tensor(3.4283, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3135 Dice: 0.6857
val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.372, dice=tensor(3.1621, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.372, dice=tensor(3.1621, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.32, dice=tensor(3.3020, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3461 Dice: 0.6604
Epoch 173/199
----------
train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3042, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.327, dice=tensor(3.3042, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.50it/s, loss=0.34, dice=tensor(3.2777, device='cuda:0')] train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.34, dice=tensor(3.2777, device='cuda:0')]train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.26, dice=tensor(3.4275, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.26, dice=tensor(3.4275, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.343, dice=tensor(3.3995, device='cuda:0')]train Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.343, dice=tensor(3.3995, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3177 Dice: 0.6799
val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1775, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.366, dice=tensor(3.1775, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.325, dice=tensor(3.3027, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3456 Dice: 0.6605
Epoch 174/199
----------
train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.4358, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.327, dice=tensor(3.4358, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.284, dice=tensor(3.5202, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.284, dice=tensor(3.5202, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.293, dice=tensor(3.5173, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.293, dice=tensor(3.5173, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.355, dice=tensor(3.4389, device='cuda:0')]train Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.355, dice=tensor(3.4389, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3148 Dice: 0.6878
val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.3016, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.351, dice=tensor(3.3016, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.34, dice=tensor(3.2984, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3453 Dice: 0.6597
Epoch 175/199
----------
train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3290, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.346, dice=tensor(3.3290, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.273, dice=tensor(3.4967, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.273, dice=tensor(3.4967, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.306, dice=tensor(3.4924, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.306, dice=tensor(3.4924, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.325, dice=tensor(3.4666, device='cuda:0')]train Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.325, dice=tensor(3.4666, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3125 Dice: 0.6933
val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.3537, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.341, dice=tensor(3.3537, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.351, dice=tensor(3.2969, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3460 Dice: 0.6594
Epoch 176/199
----------
train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4727, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.306, dice=tensor(3.4727, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.317, dice=tensor(3.4526, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.317, dice=tensor(3.4526, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.277, dice=tensor(3.5196, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.277, dice=tensor(3.5196, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.356, dice=tensor(3.4509, device='cuda:0')]train Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.356, dice=tensor(3.4509, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3138 Dice: 0.6902
val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3812, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.338, dice=tensor(3.3812, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.352, dice=tensor(3.3002, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3451 Dice: 0.6600
Epoch 177/199
----------
train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.298, dice=tensor(3.4616, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.298, dice=tensor(3.4616, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.353, dice=tensor(3.3686, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.353, dice=tensor(3.3686, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.347, dice=tensor(3.3152, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.347, dice=tensor(3.3152, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.296, dice=tensor(3.3739, device='cuda:0')]train Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.296, dice=tensor(3.3739, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3234 Dice: 0.6748
val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.4624, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.317, dice=tensor(3.4624, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.373, dice=tensor(3.3029, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3449 Dice: 0.6606
Epoch 178/199
----------
train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.2747, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.328, dice=tensor(3.2747, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.29, dice=tensor(3.4232, device='cuda:0')] train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.29, dice=tensor(3.4232, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.32, dice=tensor(3.4087, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.32, dice=tensor(3.4087, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.308, dice=tensor(3.4233, device='cuda:0')]train Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.308, dice=tensor(3.4233, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3117 Dice: 0.6847
val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1982, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.363, dice=tensor(3.1982, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.327, dice=tensor(3.3047, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3452 Dice: 0.6609
Epoch 179/199
----------
train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.4174, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.324, dice=tensor(3.4174, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.316, dice=tensor(3.4265, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.316, dice=tensor(3.4265, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.3, dice=tensor(3.4473, device='cuda:0')]  train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.3, dice=tensor(3.4473, device='cuda:0')]train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.307, dice=tensor(3.4293, device='cuda:0')]train Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.307, dice=tensor(3.4293, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3117 Dice: 0.6859
val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3866, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.336, dice=tensor(3.3866, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.352, dice=tensor(3.3057, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3440 Dice: 0.6611
Epoch 180/199
----------
train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2908, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.351, dice=tensor(3.2908, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.283, dice=tensor(3.4375, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.283, dice=tensor(3.4375, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.322, dice=tensor(3.4182, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.322, dice=tensor(3.4182, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.279, dice=tensor(3.4617, device='cuda:0')]train Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.279, dice=tensor(3.4617, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3088 Dice: 0.6923
val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2497, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.34it/s, loss=0.351, dice=tensor(3.2497, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.34it/s, loss=0.338, dice=tensor(3.3084, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3443 Dice: 0.6617
Epoch 181/199
----------
train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.298, dice=tensor(3.4753, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.298, dice=tensor(3.4753, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.29, dice=tensor(3.5199, device='cuda:0')] train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.29, dice=tensor(3.5199, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.341, dice=tensor(3.4719, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.341, dice=tensor(3.4719, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.319, dice=tensor(3.4549, device='cuda:0')]train Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.319, dice=tensor(3.4549, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3122 Dice: 0.6910
val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1620, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.366, dice=tensor(3.1620, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.319, dice=tensor(3.3101, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3424 Dice: 0.6620
Epoch 182/199
----------
train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.4157, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.33, dice=tensor(3.4157, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.291, dice=tensor(3.5059, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.291, dice=tensor(3.5059, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.295, dice=tensor(3.5253, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.295, dice=tensor(3.5253, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.325, dice=tensor(3.4731, device='cuda:0')]train Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.325, dice=tensor(3.4731, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3102 Dice: 0.6946
val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3343, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.344, dice=tensor(3.3343, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.341, dice=tensor(3.3150, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3427 Dice: 0.6630
Epoch 183/199
----------
train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1712, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.376, dice=tensor(3.1712, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.288, dice=tensor(3.3748, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.288, dice=tensor(3.3748, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.317, dice=tensor(3.4062, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.317, dice=tensor(3.4062, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.294, dice=tensor(3.4336, device='cuda:0')]train Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.294, dice=tensor(3.4336, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3187 Dice: 0.6867
val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3470, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.345, dice=tensor(3.3470, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.34, dice=tensor(3.3151, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3427 Dice: 0.6630
Epoch 184/199
----------
train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.278, dice=tensor(3.6311, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.278, dice=tensor(3.6311, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.332, dice=tensor(3.5160, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.332, dice=tensor(3.5160, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.307, dice=tensor(3.5071, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.307, dice=tensor(3.5071, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.33, dice=tensor(3.4585, device='cuda:0')] train Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.33, dice=tensor(3.4585, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3120 Dice: 0.6917
val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.1795, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.37, dice=tensor(3.1795, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.321, dice=tensor(3.3164, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3458 Dice: 0.6633
Epoch 185/199
----------
train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.3871, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.325, dice=tensor(3.3871, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.281, dice=tensor(3.4881, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.281, dice=tensor(3.4881, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.319, dice=tensor(3.4687, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.319, dice=tensor(3.4687, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.303, dice=tensor(3.4716, device='cuda:0')]train Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.303, dice=tensor(3.4716, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3071 Dice: 0.6943
val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.386, dice=tensor(3.1115, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.386, dice=tensor(3.1115, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.303, dice=tensor(3.3164, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3443 Dice: 0.6633
Epoch 186/199
----------
train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.4542, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.303, dice=tensor(3.4542, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.286, dice=tensor(3.5336, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.286, dice=tensor(3.5336, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.307, dice=tensor(3.5191, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.307, dice=tensor(3.5191, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.342, dice=tensor(3.4571, device='cuda:0')]train Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.342, dice=tensor(3.4571, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3097 Dice: 0.6914
val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.4180, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.33, dice=tensor(3.4180, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.355, dice=tensor(3.3153, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3424 Dice: 0.6631
Epoch 187/199
----------
train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.1778, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.354, dice=tensor(3.1778, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.259, dice=tensor(3.4437, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.259, dice=tensor(3.4437, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.299, dice=tensor(3.4743, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.299, dice=tensor(3.4743, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.349, dice=tensor(3.4260, device='cuda:0')]train Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.349, dice=tensor(3.4260, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3154 Dice: 0.6852
val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3298, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.348, dice=tensor(3.3298, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.336, dice=tensor(3.3162, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3423 Dice: 0.6632
Epoch 188/199
----------
train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.3676, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.312, dice=tensor(3.3676, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.325, dice=tensor(3.4092, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.325, dice=tensor(3.4092, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.287, dice=tensor(3.4695, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.287, dice=tensor(3.4695, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.311, dice=tensor(3.4644, device='cuda:0')]train Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.311, dice=tensor(3.4644, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3087 Dice: 0.6929
val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.4307, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.326, dice=tensor(3.4307, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.358, dice=tensor(3.3168, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3419 Dice: 0.6634
Epoch 189/199
----------
train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4043, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.308, dice=tensor(3.4043, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.34, dice=tensor(3.3620, device='cuda:0')] train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.34, dice=tensor(3.3620, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.07it/s, loss=0.277, dice=tensor(3.4574, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.277, dice=tensor(3.4574, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.335, dice=tensor(3.4394, device='cuda:0')]train Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.335, dice=tensor(3.4394, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3150 Dice: 0.6879
val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.5383, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.303, dice=tensor(3.5383, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.387, dice=tensor(3.3164, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3451 Dice: 0.6633
Epoch 190/199
----------
train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3834, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.333, dice=tensor(3.3834, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.288, dice=tensor(3.4519, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.288, dice=tensor(3.4519, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.333, dice=tensor(3.4160, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.333, dice=tensor(3.4160, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.28, dice=tensor(3.4499, device='cuda:0')] train Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.28, dice=tensor(3.4499, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3086 Dice: 0.6900
val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4476, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.322, dice=tensor(3.4476, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.368, dice=tensor(3.3177, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3453 Dice: 0.6635
Epoch 191/199
----------
train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.255, dice=tensor(3.7631, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.255, dice=tensor(3.7631, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.349, dice=tensor(3.5252, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.349, dice=tensor(3.5252, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.298, dice=tensor(3.5270, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.298, dice=tensor(3.5270, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.34, dice=tensor(3.4847, device='cuda:0')] train Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.34, dice=tensor(3.4847, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3104 Dice: 0.6969
val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4932, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.311, dice=tensor(3.4932, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.38, dice=tensor(3.3170, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3455 Dice: 0.6634
Epoch 192/199
----------
train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4397, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.318, dice=tensor(3.4397, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.314, dice=tensor(3.4406, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.314, dice=tensor(3.4406, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.278, dice=tensor(3.5127, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.278, dice=tensor(3.5127, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.343, dice=tensor(3.4600, device='cuda:0')]train Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.343, dice=tensor(3.4600, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3131 Dice: 0.6920
val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4487, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.322, dice=tensor(3.4487, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.366, dice=tensor(3.3173, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3439 Dice: 0.6635
Epoch 193/199
----------
train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.271, dice=tensor(3.6472, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.271, dice=tensor(3.6472, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.285, dice=tensor(3.6032, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.285, dice=tensor(3.6032, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.354, dice=tensor(3.4999, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.354, dice=tensor(3.4999, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.317, dice=tensor(3.4722, device='cuda:0')]train Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.317, dice=tensor(3.4722, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3069 Dice: 0.6944
val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2555, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.35, dice=tensor(3.2555, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.335, dice=tensor(3.3192, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3423 Dice: 0.6638
Epoch 194/199
----------
train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.269, dice=tensor(3.5954, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.269, dice=tensor(3.5954, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.312, dice=tensor(3.5415, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.312, dice=tensor(3.5415, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.298, dice=tensor(3.5358, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.298, dice=tensor(3.5358, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.349, dice=tensor(3.4688, device='cuda:0')]train Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.349, dice=tensor(3.4688, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3073 Dice: 0.6938
val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2314, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.357, dice=tensor(3.2314, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.329, dice=tensor(3.3178, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3434 Dice: 0.6636
Epoch 195/199
----------
train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3959, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.322, dice=tensor(3.3959, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.338, dice=tensor(3.3632, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.338, dice=tensor(3.3632, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.325, dice=tensor(3.3668, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.325, dice=tensor(3.3668, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.283, dice=tensor(3.4294, device='cuda:0')]train Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.283, dice=tensor(3.4294, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3169 Dice: 0.6859
val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1231, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.38, dice=tensor(3.1231, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.303, dice=tensor(3.3215, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3413 Dice: 0.6643
Epoch 196/199
----------
train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1645, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.377, dice=tensor(3.1645, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.311, dice=tensor(3.3037, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.311, dice=tensor(3.3037, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.317, dice=tensor(3.3384, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.317, dice=tensor(3.3384, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.252, dice=tensor(3.4418, device='cuda:0')]train Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.252, dice=tensor(3.4418, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3143 Dice: 0.6884
val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.2180, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.362, dice=tensor(3.2180, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.325, dice=tensor(3.3257, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3434 Dice: 0.6651
Epoch 197/199
----------
train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.4625, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.317, dice=tensor(3.4625, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.321, dice=tensor(3.4325, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.321, dice=tensor(3.4325, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.316, dice=tensor(3.4368, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.04it/s, loss=0.316, dice=tensor(3.4368, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.04it/s, loss=0.281, dice=tensor(3.4833, device='cuda:0')]train Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.281, dice=tensor(3.4833, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3088 Dice: 0.6967
val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.3756, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.32, dice=tensor(3.3756, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.36, dice=tensor(3.3262, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3400 Dice: 0.6652
Epoch 198/199
----------
train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.3895, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.306, dice=tensor(3.3895, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.314, dice=tensor(3.4301, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.314, dice=tensor(3.4301, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.261, dice=tensor(3.5291, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.261, dice=tensor(3.5291, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.341, dice=tensor(3.4846, device='cuda:0')]train Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.341, dice=tensor(3.4846, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3054 Dice: 0.6969
val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2678, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.363, dice=tensor(3.2678, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.316, dice=tensor(3.3240, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3394 Dice: 0.6648
Epoch 199/199
----------
train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.347, dice=tensor(3.3332, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.347, dice=tensor(3.3332, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.298, dice=tensor(3.4239, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.298, dice=tensor(3.4239, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.298, dice=tensor(3.4371, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.298, dice=tensor(3.4371, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.283, dice=tensor(3.4771, device='cuda:0')]train Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.283, dice=tensor(3.4771, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3066 Dice: 0.6954
val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.2507, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.346, dice=tensor(3.2507, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.337, dice=tensor(3.3212, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.042 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.042 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: train_dice ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   val_dice ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   val_loss ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: best_val_dice 0.6648
wandb: best_val_loss 0.33942
wandb:         epoch 199
wandb:    train_dice 0.69541
wandb:    train_loss 0.30659
wandb:      val_dice 0.66425
wandb:      val_loss 0.34162
wandb: 
wandb: üöÄ View run DIAS_modelnone at: https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/itgfztvi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241013_214659-itgfztvi/logs
val Loss: 0.3416 Dice: 0.6642
Best val loss: 0.339424, best val dice: 0.664805
Model saved at: ./modelsDIAS/final_model.pth
Starting RLHF fine-tuning...
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Epoch 0/39
----------
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/3 [00:02<?, ?it/s, loss=-70.8]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:04,  2.48s/it, loss=-70.8]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:04,  2.48s/it, loss=-68.2]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.23s/it, loss=-68.2]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:03<00:01,  1.23s/it, loss=-67.9]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.30it/s, loss=-67.9]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09104102849960327

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09104102849960327

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08454656600952148

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40969783067703247

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09109258651733398

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08454656600952148

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.42897033691406
Max value: 88.94148254394531
Mean value: 70.81775665283203

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09104102849960327

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09104102849960327

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09104102849960327

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40969783067703247

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.42897033691406
Max value: 88.94148254394531
Mean value: 70.81775665283203

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.81787109375
Max value: -70.81787109375
Mean value: -70.81787109375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09244850277900696

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09244850277900696

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0845937728881836

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.48308178782463074

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0924673080444336

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0845937728881836

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 50.227813720703125
Max value: 80.96839904785156
Mean value: 65.26925659179688

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09162695705890656

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09162695705890656

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09162695705890656

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.46770501136779785

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.13091981410980225
Max value: 16.99999237060547
Mean value: 1.0244507789611816

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 50.227813720703125
Max value: 80.96839904785156
Mean value: 65.26925659179688

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.58565521240234
Max value: -65.58565521240234
Mean value: -65.58565521240234
sam_encoder.pos_embed grad: 3.691089656143731e-09
sam_encoder.blocks.0.norm1.weight grad: -4.428334068506956e-05
sam_encoder.blocks.0.norm1.bias grad: -3.711460976774106e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0650733202055562e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.316380106203724e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.1866251194733195e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5959716392899281e-06
sam_encoder.blocks.0.norm2.weight grad: 1.2935961422044784e-05
sam_encoder.blocks.0.norm2.bias grad: 1.872458597063087e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.344803983258316e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.3797846299421508e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.689624523100065e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.5098360108822817e-06
sam_encoder.blocks.1.norm1.weight grad: -3.5023383588850265e-06
sam_encoder.blocks.1.norm1.bias grad: 8.609837891526695e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.0496971754037077e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.831485729388078e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.31826664073742e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.052176396067807e-07
sam_encoder.blocks.1.norm2.weight grad: 1.0168683729716577e-05
sam_encoder.blocks.1.norm2.bias grad: -7.796285785843793e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.0082650987897068e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.912442030516104e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.719378699111985e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.2678517578024184e-06
sam_encoder.blocks.2.norm1.weight grad: -2.341385425097542e-06
sam_encoder.blocks.2.norm1.bias grad: 3.4133663575630635e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.7921055359693128e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.860086389475327e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.1970348572940566e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.5417549497651635e-06
sam_encoder.blocks.2.norm2.weight grad: 2.3296302060771268e-06
sam_encoder.blocks.2.norm2.bias grad: 3.802308128797449e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.8541365989221958e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.351851086743409e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.027856001201144e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4712189795318409e-06
sam_encoder.blocks.3.norm1.weight grad: -9.738696462591179e-06
sam_encoder.blocks.3.norm1.bias grad: -8.399797479796689e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.8103105503541883e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.728975563419226e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.654114935779944e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.8857106169889448e-06
sam_encoder.blocks.3.norm2.weight grad: 1.5650261047994718e-05
sam_encoder.blocks.3.norm2.bias grad: 8.449400411336683e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1288082532701083e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.16911188949598e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.4769618650898337e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.700421977257065e-07
sam_encoder.blocks.4.norm1.weight grad: -1.7799102352000773e-05
sam_encoder.blocks.4.norm1.bias grad: -1.2293048712308519e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.263845640816726e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.750296516751405e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.6641272345150355e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.185061137221055e-06
sam_encoder.blocks.4.norm2.weight grad: -2.011678589042276e-06
sam_encoder.blocks.4.norm2.bias grad: -1.5868457694523386e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.3215570763568394e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.8595943629406975e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.6792544101917883e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1061836719127314e-07
sam_encoder.blocks.5.norm1.weight grad: -8.669385351822712e-06
sam_encoder.blocks.5.norm1.bias grad: 5.524484549823683e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.7895497371209785e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 8.093287533483817e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.272623760291026e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.8578713227034314e-06
sam_encoder.blocks.5.norm2.weight grad: 1.8664286471903324e-07
sam_encoder.blocks.5.norm2.bias grad: 4.676498974731658e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.2548435961434734e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.354291599564021e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7315549030172406e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.702544285668409e-07
sam_encoder.blocks.6.norm1.weight grad: 3.2791044191071705e-07
sam_encoder.blocks.6.norm1.bias grad: 1.3274951697894721e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.9577464627218433e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.076773383436375e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.261023711180314e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.5758430410860456e-07
sam_encoder.blocks.6.norm2.weight grad: 4.38491679233266e-06
sam_encoder.blocks.6.norm2.bias grad: 2.2441981855081394e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.044275101477979e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.8973108808495454e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.0793565624899202e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.509182301466353e-07
sam_encoder.blocks.7.norm1.weight grad: -3.61085540134809e-06
sam_encoder.blocks.7.norm1.bias grad: 1.8416553757560905e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.3154351563571254e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.053662187672671e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.525223064571037e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.3682981716556242e-06
sam_encoder.blocks.7.norm2.weight grad: -2.7523935841600178e-06
sam_encoder.blocks.7.norm2.bias grad: -5.323739173945796e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.3456518647435587e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.36148031515404e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.69010830733896e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.200965228548739e-07
sam_encoder.blocks.8.norm1.weight grad: -6.346382178890053e-06
sam_encoder.blocks.8.norm1.bias grad: 4.966196684108581e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.484282832592726e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.6889401851803996e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.9915994471375598e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.30968680625665e-06
sam_encoder.blocks.8.norm2.weight grad: 1.7872762327897362e-06
sam_encoder.blocks.8.norm2.bias grad: -2.2315477963275043e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.291536247867043e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.4438537618843839e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.9809865534625715e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.876958759174158e-07
sam_encoder.blocks.9.norm1.weight grad: -6.178601097417413e-07
sam_encoder.blocks.9.norm1.bias grad: -7.311940635190695e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.19086096726096e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.64859850682842e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.528545503035275e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.781463177205296e-07
sam_encoder.blocks.9.norm2.weight grad: 3.065706550842151e-07
sam_encoder.blocks.9.norm2.bias grad: -1.5479239436899661e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.654463504673913e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.2151282880477083e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.491465463412169e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.169886551608215e-07
sam_encoder.blocks.10.norm1.weight grad: 1.8440991880197544e-06
sam_encoder.blocks.10.norm1.bias grad: -1.5311518382077338e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.547057531250175e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.752075129654258e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.733390473025793e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.682122150574287e-07
sam_encoder.blocks.10.norm2.weight grad: -1.9651506590889767e-06
sam_encoder.blocks.10.norm2.bias grad: -3.4727781894616783e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.928040198137751e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.91306251307833e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5144219105422962e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.095671440358274e-07
sam_encoder.blocks.11.norm1.weight grad: -1.1840496881632134e-05
sam_encoder.blocks.11.norm1.bias grad: 1.4385972235686495e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.788672418319038e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.4890877625693975e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.6224109913309803e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.1670234698613058e-06
sam_encoder.blocks.11.norm2.weight grad: -7.126855052774772e-07
sam_encoder.blocks.11.norm2.bias grad: -2.289410758749e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.135557780202362e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.333040865527437e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.094917353038909e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.6330167440514742e-08
sam_encoder.neck.conv1.trainable_scale grad: 9.907125786412507e-08
sam_encoder.neck.conv1.trainable_shift grad: -2.6742025511339307e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.563882485963404e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.1864722182508558e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00020683585898950696
mask_decoder.transformer.layers.0.norm1.bias grad: -1.9664294086396694e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00033443025313317776
mask_decoder.transformer.layers.0.norm2.bias grad: -7.694272790104151e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 8.721157792024314e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.9029488612432033e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010190506145590916
mask_decoder.transformer.layers.0.norm4.bias grad: -1.983145921258256e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.836973913479596e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.378902303869836e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -9.68023159657605e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001432026328984648
mask_decoder.transformer.layers.1.norm3.weight grad: 7.087089761625975e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.0001020828349282965
mask_decoder.transformer.layers.1.norm4.weight grad: 5.44898139196448e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -3.963020571973175e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.374742689426057e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.5583073036395945e-05
Text_Embedding_Affine.0.weight grad: 1.4295176153922284e-11
Text_Embedding_Affine.0.bias grad: 3.9728098588653893e-10
Text_Embedding_Affine.2.weight grad: 6.81458361961873e-11
Text_Embedding_Affine.2.bias grad: -1.1296375305391848e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08593127131462097

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08593127131462097

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08041572570800781

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4438572824001312

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0858306884765625

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08041572570800781

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 57.85997772216797
Max value: 78.67794036865234
Mean value: 67.08740234375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08705208450555801

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08705208450555801

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08705208450555801

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4229094982147217

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.11191906780004501
Max value: 46.83840560913086
Mean value: 1.0503616333007812

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 57.85997772216797
Max value: 78.67794036865234
Mean value: 67.08740234375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.31952667236328
Max value: -67.31952667236328
Mean value: -67.31952667236328
sam_encoder.pos_embed grad: -1.4220736588299587e-08
sam_encoder.blocks.0.norm1.weight grad: 7.115250627975911e-05
sam_encoder.blocks.0.norm1.bias grad: 2.9637223633471876e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.030097549431957e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.128481585510599e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.633381523599382e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.2918123957206262e-06
sam_encoder.blocks.0.norm2.weight grad: 5.465540016302839e-05
sam_encoder.blocks.0.norm2.bias grad: 9.789515388547443e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.215623524331022e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.974917490268126e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.2501386411022395e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.213620054040803e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2820142728742212e-05
sam_encoder.blocks.1.norm1.bias grad: 2.2522617655340582e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.459258881681308e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.7882593965623528e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.559501692507183e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.467692411300959e-06
sam_encoder.blocks.1.norm2.weight grad: 7.891402674431447e-06
sam_encoder.blocks.1.norm2.bias grad: -2.5831611765170237e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.9747342321352335e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4909351193637121e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3301955732458737e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.307860763219651e-06
sam_encoder.blocks.2.norm1.weight grad: 6.756918992323335e-06
sam_encoder.blocks.2.norm1.bias grad: -6.566338925040327e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.2654915028397227e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.57704584782914e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.4807273954793345e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.349074748053681e-06
sam_encoder.blocks.2.norm2.weight grad: -2.1423609268822474e-06
sam_encoder.blocks.2.norm2.bias grad: -1.4260696843848564e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.215895387460478e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.4863948056008667e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.7023735280381516e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.3116385818866547e-06
sam_encoder.blocks.3.norm1.weight grad: 1.0016236046794802e-05
sam_encoder.blocks.3.norm1.bias grad: -1.3507909898180515e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.807758043374633e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1942175888179918e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.4669362776185153e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.594234148200485e-07
sam_encoder.blocks.3.norm2.weight grad: 1.1381692957002087e-06
sam_encoder.blocks.3.norm2.bias grad: -1.0899129847530276e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.8032791306031868e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.0344070915380144e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.800308488484006e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.279218046576716e-08
sam_encoder.blocks.4.norm1.weight grad: 3.2622479920974e-05
sam_encoder.blocks.4.norm1.bias grad: -6.192785804159939e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.7309186659986153e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.96648601963534e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.365819667233154e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.89877049101051e-06
sam_encoder.blocks.4.norm2.weight grad: -6.857011612737551e-05
sam_encoder.blocks.4.norm2.bias grad: -4.3266401917207986e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.5194330596132204e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.558255280542653e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.558128298664087e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.3343430964596337e-06
sam_encoder.blocks.5.norm1.weight grad: 1.8622502466314472e-05
sam_encoder.blocks.5.norm1.bias grad: -1.5710340449004434e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.0190216926275752e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.393894871805969e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.448412932513747e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.2484468799084425e-06
sam_encoder.blocks.5.norm2.weight grad: -3.513965566526167e-05
sam_encoder.blocks.5.norm2.bias grad: -1.802452970878221e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.4906783690094016e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.7270505092456006e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.460443144196688e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.584651709497848e-07
sam_encoder.blocks.6.norm1.weight grad: 4.954507858201396e-06
sam_encoder.blocks.6.norm1.bias grad: 2.5310937417089008e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.1799409043742344e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.609094154759077e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.589878477010643e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.4263834436387697e-07
sam_encoder.blocks.6.norm2.weight grad: -2.1085277694510296e-05
sam_encoder.blocks.6.norm2.bias grad: -2.178305976485717e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.503750081610633e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.685040716547519e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.750474211803521e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.315139229518536e-06
sam_encoder.blocks.7.norm1.weight grad: 3.950521204387769e-06
sam_encoder.blocks.7.norm1.bias grad: 2.4157507141353562e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.948749155024416e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.105556293623522e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.02289412402024e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0187966381636215e-06
sam_encoder.blocks.7.norm2.weight grad: 3.136216946586501e-06
sam_encoder.blocks.7.norm2.bias grad: 5.160035470908042e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.7072173907072283e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.856523774942616e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4596374739994644e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.778342935831461e-07
sam_encoder.blocks.8.norm1.weight grad: 6.601914265047526e-06
sam_encoder.blocks.8.norm1.bias grad: -3.285088268967229e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.183377313893288e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.0417406883789226e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.212826297589345e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.67394580077962e-06
sam_encoder.blocks.8.norm2.weight grad: -2.642635763550061e-06
sam_encoder.blocks.8.norm2.bias grad: 7.233779797388706e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.3412923130526906e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3586385421149316e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.6000070672816946e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0860497923204093e-06
sam_encoder.blocks.9.norm1.weight grad: -9.332745776191587e-07
sam_encoder.blocks.9.norm1.bias grad: 7.595048145958572e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.5439928776904708e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.01888144097029e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.5385221985297903e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.8060572415379283e-07
sam_encoder.blocks.9.norm2.weight grad: 1.973584403458517e-06
sam_encoder.blocks.9.norm2.bias grad: 2.208578052886878e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.3043291719204717e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.047722654831887e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.641536411829293e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.786040446764673e-07
sam_encoder.blocks.10.norm1.weight grad: 7.830700269551016e-06
sam_encoder.blocks.10.norm1.bias grad: 9.30878456983919e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.6917881516274065e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.693261651780631e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.0355009837658145e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2812110981030855e-06
sam_encoder.blocks.10.norm2.weight grad: 3.4560580388642848e-06
sam_encoder.blocks.10.norm2.bias grad: 1.8777367358779884e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.8542014004196972e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.046920819040679e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.992438510318607e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.20753372307081e-07
sam_encoder.blocks.11.norm1.weight grad: 1.590581268828828e-05
sam_encoder.blocks.11.norm1.bias grad: -5.954886361791978e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.074279781387304e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.141075002436992e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.1349087546695955e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.255824693354953e-07
sam_encoder.blocks.11.norm2.weight grad: 8.286725460493471e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2973121101822471e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.468562110560015e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.066877406534331e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.2132121557660867e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.167545798987703e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.82293830323033e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.4627434211433865e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.271140359283891e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.770862945704721e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -3.877533890772611e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.0094375940971076e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004987827967852354
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002398252545390278
mask_decoder.transformer.layers.0.norm3.weight grad: -3.820511119556613e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.5833549191011116e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010135826596524566
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0075553291244432e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 7.598872343805851e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.2712939678749535e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001977360952878371
mask_decoder.transformer.layers.1.norm2.bias grad: 3.723840927705169e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.997736141376663e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -5.055592737335246e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -3.9607970393262804e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015393916692119092
mask_decoder.transformer.norm_final_attn.weight grad: 1.265123955818126e-05
mask_decoder.transformer.norm_final_attn.bias grad: 8.498611350660212e-06
Text_Embedding_Affine.0.weight grad: 2.441109380607598e-12
Text_Embedding_Affine.0.bias grad: 1.019558187875802e-10
Text_Embedding_Affine.2.weight grad: 5.405375799738543e-11
Text_Embedding_Affine.2.bias grad: -6.070472863939358e-06
Epoch 0 finished with average loss: -67.9077
Epoch 1/39
----------
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.6]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-60.6]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-64.3]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-64.3]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-64.2]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.24it/s, loss=-64.2]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671317994594574

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671317994594574

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0871591567993164

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4805147051811218

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08674907684326172

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0871591567993164

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.40692138671875
Max value: 76.48493957519531
Mean value: 60.64955139160156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671317994594574

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671317994594574

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08671317994594574

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4805147051811218

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.40692138671875
Max value: 76.48493957519531
Mean value: 60.64955139160156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.64968490600586
Max value: -60.64968490600586
Mean value: -60.64968490600586
sam_encoder.pos_embed grad: 1.446087605216917e-08
sam_encoder.blocks.0.norm1.weight grad: 6.465617730100348e-07
sam_encoder.blocks.0.norm1.bias grad: -3.5035209293710068e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.432635579287307e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.593798965084716e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.284378173404548e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.709864924734575e-07
sam_encoder.blocks.0.norm2.weight grad: -5.1390830776654184e-05
sam_encoder.blocks.0.norm2.bias grad: -2.6815270757651888e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.919680006627459e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.188063136709388e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.594723451300524e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.99364614370279e-06
sam_encoder.blocks.1.norm1.weight grad: -1.4021478591530467e-06
sam_encoder.blocks.1.norm1.bias grad: -1.4351837307913229e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.3767371948888467e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.1987457898831053e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.6016708741517505e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 7.829918899915356e-07
sam_encoder.blocks.1.norm2.weight grad: -1.909038473968394e-06
sam_encoder.blocks.1.norm2.bias grad: 3.9662003814555646e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.7376939872046933e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.40849327990145e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.661558472842444e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.867900548153557e-06
sam_encoder.blocks.2.norm1.weight grad: -1.0583847142697778e-05
sam_encoder.blocks.2.norm1.bias grad: 3.3442890980950324e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.0368096304300707e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.432122355206957e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.6781842734635575e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.1518203539017122e-06
sam_encoder.blocks.2.norm2.weight grad: 1.879642513813451e-05
sam_encoder.blocks.2.norm2.bias grad: 8.26660016173264e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.4526625818689354e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.8175064623355865e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.7548688542065065e-08
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.335339316545287e-07
sam_encoder.blocks.3.norm1.weight grad: -1.2898017303086817e-05
sam_encoder.blocks.3.norm1.bias grad: 5.9786643760162406e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.6659552077035187e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.750707476996467e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3835258414474083e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.5494879335165024e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0157329597859643e-05
sam_encoder.blocks.3.norm2.bias grad: 5.374440661398694e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.608002655004384e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.3680732990906108e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.885006092081312e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.306133167934604e-07
sam_encoder.blocks.4.norm1.weight grad: -3.52397546521388e-05
sam_encoder.blocks.4.norm1.bias grad: 2.6024585508821474e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.0227120330673642e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.7762877077038866e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0168556400458328e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.982855782349361e-06
sam_encoder.blocks.4.norm2.weight grad: 3.763121640076861e-05
sam_encoder.blocks.4.norm2.bias grad: 2.9135466320440173e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.5462777557549998e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 9.912411769619212e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.278240895582712e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.039533104740258e-07
sam_encoder.blocks.5.norm1.weight grad: -1.9595383491832763e-05
sam_encoder.blocks.5.norm1.bias grad: 1.3708347523788689e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.108800102490932e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.978374701953726e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.666784545610426e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.75757576370961e-06
sam_encoder.blocks.5.norm2.weight grad: 1.7764503354555927e-05
sam_encoder.blocks.5.norm2.bias grad: 1.3133765605743974e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.6118456086551305e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.506110265836469e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.892330374175799e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.279806363338139e-07
sam_encoder.blocks.6.norm1.weight grad: -7.1074314291763585e-06
sam_encoder.blocks.6.norm1.bias grad: -6.0696693253703415e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.064032287307782e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.9623728892147483e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.496111849519366e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.768850772052247e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1690084647852927e-05
sam_encoder.blocks.6.norm2.bias grad: 5.202057764108758e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.468327334616333e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.295122380426619e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.067120815103408e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.9726560367416823e-06
sam_encoder.blocks.7.norm1.weight grad: -5.418667115009157e-06
sam_encoder.blocks.7.norm1.bias grad: -1.2155559261373128e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.627555431899964e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.2483122873163666e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.5010109564173035e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.552975134217377e-09
sam_encoder.blocks.7.norm2.weight grad: -2.935818883997854e-06
sam_encoder.blocks.7.norm2.bias grad: -1.8475336673873244e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.2337920856662095e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.153981039844439e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.8532913372837356e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.7499003130724304e-07
sam_encoder.blocks.8.norm1.weight grad: -3.0474325285467785e-06
sam_encoder.blocks.8.norm1.bias grad: 3.5491466405801475e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.2595130556292133e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.370238050275475e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.5841239878209308e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.887914888560772e-06
sam_encoder.blocks.8.norm2.weight grad: -3.4280092222616076e-06
sam_encoder.blocks.8.norm2.bias grad: -4.777539288625121e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.138587544526672e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.5770259551572963e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.412923193645838e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2727448961413756e-07
sam_encoder.blocks.9.norm1.weight grad: -4.301841727283318e-06
sam_encoder.blocks.9.norm1.bias grad: -1.2676896403718274e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.1120825951802544e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.6100437960631098e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.2012753813905874e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.1727211674260616e-07
sam_encoder.blocks.9.norm2.weight grad: -8.503908247803338e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2172994274806115e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.935966328252107e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.8979907256143633e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.2133257314417278e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.694175122996967e-07
sam_encoder.blocks.10.norm1.weight grad: -8.614901162218302e-06
sam_encoder.blocks.10.norm1.bias grad: -2.4375458451686427e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.290627657610457e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.7314094975517946e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6050647673182539e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.477193892351352e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3527378541766666e-05
sam_encoder.blocks.10.norm2.bias grad: -2.6638979306881083e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.824067324690986e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.7313998291210737e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5164199567152536e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.290403007369605e-07
sam_encoder.blocks.11.norm1.weight grad: -2.0184241293463856e-05
sam_encoder.blocks.11.norm1.bias grad: 1.1756644653360127e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.082477964104328e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2408690963638946e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.6823422583911452e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.179857443086803e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3383362784225028e-05
sam_encoder.blocks.11.norm2.bias grad: -2.6680952487367904e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.282978913281113e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.2674319097859552e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.225867643181118e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.6499333810315875e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.102497304207645e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.881815660453867e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.762922228313982e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.0746036170748994e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.563403439940885e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.2565585570409894e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.006080586928874254
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00031153816962614655
mask_decoder.transformer.layers.0.norm3.weight grad: -1.2014941603410989e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.206716302083805e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -3.536156509653665e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.817524990765378e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.706512011878658e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.539881047094241e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00019093463197350502
mask_decoder.transformer.layers.1.norm2.bias grad: 7.1087451942730695e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 4.405991785461083e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.929361239192076e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00013591282186098397
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001853191206464544
mask_decoder.transformer.norm_final_attn.weight grad: 6.745165592292324e-06
mask_decoder.transformer.norm_final_attn.bias grad: 4.392489699966973e-06
Text_Embedding_Affine.0.weight grad: -1.0620383695744695e-12
Text_Embedding_Affine.0.bias grad: -1.2065624888091264e-10
Text_Embedding_Affine.2.weight grad: -1.0049787391164244e-10
Text_Embedding_Affine.2.bias grad: -4.192302185401786e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08459825813770294

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08459825813770294

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07952260971069336

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.38158372044563293

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08466672897338867

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07952260971069336

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.68006896972656
Max value: 89.68695831298828
Mean value: 67.60200500488281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08443745225667953

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08443745225667953

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08443745225667953

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.37255406379699707

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.5823277235031128
Max value: 4.999995231628418
Mean value: 1.0116667747497559

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.68006896972656
Max value: 89.68695831298828
Mean value: 67.60200500488281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.92940521240234
Max value: -67.92940521240234
Mean value: -67.92940521240234
sam_encoder.pos_embed grad: -4.369448691754485e-10
sam_encoder.blocks.0.norm1.weight grad: -2.3268794393516146e-05
sam_encoder.blocks.0.norm1.bias grad: 4.103903847862966e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.610568794305436e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0703665509481652e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.9595306639530463e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.2658082937377912e-07
sam_encoder.blocks.0.norm2.weight grad: -2.937076715170406e-06
sam_encoder.blocks.0.norm2.bias grad: 5.711748144676676e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.847731477435445e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.263609298504889e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.8832504287711345e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.6934461655182531e-06
sam_encoder.blocks.1.norm1.weight grad: -4.395549694891088e-06
sam_encoder.blocks.1.norm1.bias grad: 5.3980338634573855e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.1076970117283054e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.4866548048739787e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.543548134781304e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.6108299405459547e-06
sam_encoder.blocks.1.norm2.weight grad: 9.810794836084824e-06
sam_encoder.blocks.1.norm2.bias grad: -3.4070212677761447e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.940969574818155e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5897534240139066e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.8551068023953121e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.0169410415983293e-06
sam_encoder.blocks.2.norm1.weight grad: -5.331357442628359e-06
sam_encoder.blocks.2.norm1.bias grad: 2.017818587773945e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.183048976206919e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.373108347024754e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.611346983234398e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.361656359222252e-06
sam_encoder.blocks.2.norm2.weight grad: 1.4737432820766116e-06
sam_encoder.blocks.2.norm2.bias grad: 3.832982656604145e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.5700065887358505e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.685365529941919e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.189463745276953e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.393506843480282e-07
sam_encoder.blocks.3.norm1.weight grad: -1.0616900908644311e-05
sam_encoder.blocks.3.norm1.bias grad: -2.8733309136441676e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.4368504202575423e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.055978355514526e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.170591417576361e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.626842991546255e-08
sam_encoder.blocks.3.norm2.weight grad: 6.960412974876817e-06
sam_encoder.blocks.3.norm2.bias grad: 5.333554781827843e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.540202775795478e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.377320015511941e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.7943831355514703e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.455637175240554e-06
sam_encoder.blocks.4.norm1.weight grad: -1.0700166967581026e-05
sam_encoder.blocks.4.norm1.bias grad: -2.4196519916586112e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.563620900124079e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.907792920974316e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.1704948974511353e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.8722924721714662e-07
sam_encoder.blocks.4.norm2.weight grad: -1.838061848502548e-06
sam_encoder.blocks.4.norm2.bias grad: 3.418650976527715e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.408142793479783e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.3555477096360846e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.919529495353345e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.638726794491959e-08
sam_encoder.blocks.5.norm1.weight grad: -7.093548447301146e-06
sam_encoder.blocks.5.norm1.bias grad: 3.72591921404819e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.790176030335715e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.462201907997951e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7120207758125616e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.6812299438461196e-06
sam_encoder.blocks.5.norm2.weight grad: -2.5820042992563685e-06
sam_encoder.blocks.5.norm2.bias grad: 1.969683125935262e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.103600763803115e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.028952495602425e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.946964958842727e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.823383162351092e-07
sam_encoder.blocks.6.norm1.weight grad: 2.103055976476753e-06
sam_encoder.blocks.6.norm1.bias grad: 4.767069185618311e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.042770456180733e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.836869594437303e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.5796401814659475e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.427640073525254e-07
sam_encoder.blocks.6.norm2.weight grad: 1.3492548305293894e-06
sam_encoder.blocks.6.norm2.bias grad: 1.2660015045184991e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.468075535944081e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.1023630577255972e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.1735848438074754e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.4922436498163734e-08
sam_encoder.blocks.7.norm1.weight grad: -1.736790835593638e-07
sam_encoder.blocks.7.norm1.bias grad: 1.373463874188019e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.595286201147246e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.484986285049672e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.491393378382782e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.31781206391679e-07
sam_encoder.blocks.7.norm2.weight grad: 1.2636315886993543e-06
sam_encoder.blocks.7.norm2.bias grad: -4.767383359194355e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.2130294635426253e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.0915719523582084e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.3501006296555715e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2872395416252402e-07
sam_encoder.blocks.8.norm1.weight grad: -4.786154931935016e-06
sam_encoder.blocks.8.norm1.bias grad: 2.4062364900601096e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.4805349211383145e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.990379132621456e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -8.311657211379497e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.918942396325292e-07
sam_encoder.blocks.8.norm2.weight grad: 4.262341008143267e-06
sam_encoder.blocks.8.norm2.bias grad: -1.246411898137012e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.7020017771283165e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.3064012566464953e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.9662938939291053e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.983784371390357e-07
sam_encoder.blocks.9.norm1.weight grad: -1.0194389687967487e-06
sam_encoder.blocks.9.norm1.bias grad: -6.886752856871681e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.1206219003033766e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.812966143523226e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.710539999701723e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0693300964703667e-06
sam_encoder.blocks.9.norm2.weight grad: 3.649910922831623e-06
sam_encoder.blocks.9.norm2.bias grad: -5.069136932434049e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.9370021366048604e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.543903067613428e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.297195795923471e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.824133543162134e-08
sam_encoder.blocks.10.norm1.weight grad: 1.3006850849706098e-06
sam_encoder.blocks.10.norm1.bias grad: -1.4716322027652495e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.5449212444073055e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.852467428572709e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.272229029491427e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.762962587141374e-07
sam_encoder.blocks.10.norm2.weight grad: 1.4086942883295706e-06
sam_encoder.blocks.10.norm2.bias grad: -2.366226453887066e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.3623437098431168e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.3567845270663383e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.365666073790635e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.0024826830631355e-07
sam_encoder.blocks.11.norm1.weight grad: -3.069199919991661e-06
sam_encoder.blocks.11.norm1.bias grad: 1.1128561254736269e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.0583837542508263e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.998759640604476e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4101028682489414e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.159327305496845e-07
sam_encoder.blocks.11.norm2.weight grad: 8.519870675627317e-07
sam_encoder.blocks.11.norm2.bias grad: -3.078998588534887e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.432317614875501e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.5282692800155928e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.418427698103187e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.1661767018722458e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.434700607205741e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.728184522828087e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.981458682275843e-07
sam_encoder.neck.conv2.trainable_shift grad: -9.346309525426477e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016515082097612321
mask_decoder.transformer.layers.0.norm1.bias grad: -2.1721789380535483e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0015153480926528573
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00011249716044403613
mask_decoder.transformer.layers.0.norm3.weight grad: 4.3169231503270566e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.675620296737179e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.47505619074218e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.5699937395984307e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.072929292917252e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.5372424968518317e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.826710912515409e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.681212107650936e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.549582470441237e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.9942736697848886e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.0590343410731293e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010358129657106474
mask_decoder.transformer.norm_final_attn.weight grad: 1.5972633264027536e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.1182468369952403e-05
Text_Embedding_Affine.0.weight grad: -4.456090010873659e-12
Text_Embedding_Affine.0.bias grad: -1.5439650946635908e-10
Text_Embedding_Affine.2.weight grad: 1.2793335835148412e-10
Text_Embedding_Affine.2.bias grad: -1.4053004633751698e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0941900908946991

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0941900908946991

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0854034423828125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40239018201828003

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09427547454833984

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0854034423828125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 54.35335922241211
Max value: 71.48881530761719
Mean value: 63.567359924316406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09317217022180557

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09317217022180557

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09317217022180557

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.37882301211357117

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.4038383364677429
Max value: 10.999995231628418
Mean value: 1.0413310527801514

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 54.35335922241211
Max value: 71.48881530761719
Mean value: 63.567359924316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.9619026184082
Max value: -63.9619026184082
Mean value: -63.9619026184082
sam_encoder.pos_embed grad: 3.035731666045649e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00027858075918629766
sam_encoder.blocks.0.norm1.bias grad: -8.580838039051741e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.3122458514990285e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.781202609497996e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.135094968660269e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.245615622901823e-06
sam_encoder.blocks.0.norm2.weight grad: -0.0001400192704750225
sam_encoder.blocks.0.norm2.bias grad: 5.181504093343392e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.767542097601108e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.638224784983322e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.6080749850953e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.562796205689665e-05
sam_encoder.blocks.1.norm1.weight grad: -3.633999585872516e-05
sam_encoder.blocks.1.norm1.bias grad: 1.5038879610074218e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.850702062711207e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.564954345667502e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.3779306249925867e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4708401749885525e-06
sam_encoder.blocks.1.norm2.weight grad: -1.818287819332909e-05
sam_encoder.blocks.1.norm2.bias grad: -7.946036930661649e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.5889552742009982e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.736390448873863e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.864249033038504e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3095361737214262e-06
sam_encoder.blocks.2.norm1.weight grad: 1.536166382720694e-05
sam_encoder.blocks.2.norm1.bias grad: 6.001387191645335e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.715754471362743e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.539879233154352e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.7535548977321014e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.8967640395858325e-06
sam_encoder.blocks.2.norm2.weight grad: 3.656710032373667e-05
sam_encoder.blocks.2.norm2.bias grad: -3.3203981729457155e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.431844040984288e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.9655227535840822e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.685250915936194e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.340380655776244e-06
sam_encoder.blocks.3.norm1.weight grad: 2.3786727979313582e-05
sam_encoder.blocks.3.norm1.bias grad: 7.914167326816823e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.5434692386406823e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.125390776403947e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.637580786948092e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.281602976632712e-06
sam_encoder.blocks.3.norm2.weight grad: 8.48330273583997e-06
sam_encoder.blocks.3.norm2.bias grad: 2.031701114901807e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.256339939776808e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.4244629887325573e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1372438166290522e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.039081199560314e-06
sam_encoder.blocks.4.norm1.weight grad: -4.0042550608632155e-06
sam_encoder.blocks.4.norm1.bias grad: -5.6294647947652265e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.8141373604739783e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.130132644306286e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.8907489902630914e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -9.050953622136149e-07
sam_encoder.blocks.4.norm2.weight grad: -2.4497252525179647e-05
sam_encoder.blocks.4.norm2.bias grad: -1.774503652995918e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.3614586098119617e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.672379979339894e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.0343205708049936e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.931151463300921e-07
sam_encoder.blocks.5.norm1.weight grad: -1.7245511116925627e-05
sam_encoder.blocks.5.norm1.bias grad: -2.637537181726657e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.489574949839152e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.8986328313985723e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.463261125740246e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.218833060396719e-06
sam_encoder.blocks.5.norm2.weight grad: -1.658506880630739e-05
sam_encoder.blocks.5.norm2.bias grad: 3.7137210711080115e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.441599675279576e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.1341487556346692e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.847551725921221e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.871120043186238e-06
sam_encoder.blocks.6.norm1.weight grad: -6.91870809532702e-06
sam_encoder.blocks.6.norm1.bias grad: -7.297810043382924e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.118934601952787e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.3742951523454394e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.475318852812052e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.3839638768331497e-06
sam_encoder.blocks.6.norm2.weight grad: -9.203355148201808e-06
sam_encoder.blocks.6.norm2.bias grad: 4.5334618334891275e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.415030500444118e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.260431529066409e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.5433225750457495e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.299134166605654e-06
sam_encoder.blocks.7.norm1.weight grad: -7.992701284820214e-06
sam_encoder.blocks.7.norm1.bias grad: 4.9693162509356625e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -9.823050277191214e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.6092744772322476e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.2982832181005506e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.3774019761476666e-06
sam_encoder.blocks.7.norm2.weight grad: -5.350586320673756e-07
sam_encoder.blocks.7.norm2.bias grad: 2.2149454252939904e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.481316298348247e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.8871927522923215e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.22480683887261e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.9950989553763065e-06
sam_encoder.blocks.8.norm1.weight grad: -6.2538019847124815e-06
sam_encoder.blocks.8.norm1.bias grad: 2.057145820799633e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.0863815987249836e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.969320914620766e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.439879492361797e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.539217793033458e-06
sam_encoder.blocks.8.norm2.weight grad: -9.105011486099102e-06
sam_encoder.blocks.8.norm2.bias grad: -2.7455578219814925e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.0257589565298986e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.850938694289653e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.9554667218812938e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.0370663403591607e-06
sam_encoder.blocks.9.norm1.weight grad: -2.371300524828257e-06
sam_encoder.blocks.9.norm1.bias grad: 5.486757572725764e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.07844356939313e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.7201949706068262e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.594373189727776e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.350293132418301e-06
sam_encoder.blocks.9.norm2.weight grad: -1.2946458809892647e-05
sam_encoder.blocks.9.norm2.bias grad: -5.0670423661358654e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.2366283044684678e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.852262231404893e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.2819407351780683e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.8150961977880797e-06
sam_encoder.blocks.10.norm1.weight grad: -1.2453956514946185e-06
sam_encoder.blocks.10.norm1.bias grad: -5.614430733658082e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.1141856620943145e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.758035234113777e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.589792873346596e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.0489291563972074e-07
sam_encoder.blocks.10.norm2.weight grad: -2.0318937458796427e-05
sam_encoder.blocks.10.norm2.bias grad: -8.76759622769896e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.655655048845802e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.4930677581287455e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.9969214665470645e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.7342697447020328e-06
sam_encoder.blocks.11.norm1.weight grad: -1.3790780030831229e-05
sam_encoder.blocks.11.norm1.bias grad: 3.494116299407324e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.1528279628691962e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.338520617850008e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.335999053888372e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.168930907624599e-06
sam_encoder.blocks.11.norm2.weight grad: -1.795358730305452e-05
sam_encoder.blocks.11.norm2.bias grad: -7.141269634303171e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.101075425453018e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.219481979816919e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.0915086881577736e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.7299006458415533e-06
sam_encoder.neck.conv1.trainable_scale grad: -1.8600985640659928e-06
sam_encoder.neck.conv1.trainable_shift grad: -4.446518141776323e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.5988083507400006e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.762402022606693e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002795760810840875
mask_decoder.transformer.layers.0.norm1.bias grad: 1.0997173376381397e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00139136821962893
mask_decoder.transformer.layers.0.norm2.bias grad: -4.2589614167809486e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00016501342179253697
mask_decoder.transformer.layers.0.norm3.bias grad: 1.6506142856087536e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011096490197815001
mask_decoder.transformer.layers.0.norm4.bias grad: 4.809975507669151e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.438951095333323e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.717614501714706e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00019838716252706945
mask_decoder.transformer.layers.1.norm2.bias grad: 3.5017401387449354e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.834387022536248e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.745395072968677e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00019690347835421562
mask_decoder.transformer.layers.1.norm4.bias grad: -9.61916521191597e-06
mask_decoder.transformer.norm_final_attn.weight grad: 4.032786819152534e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.9898437787778676e-05
Text_Embedding_Affine.0.weight grad: 4.8842605307464204e-12
Text_Embedding_Affine.0.bias grad: 2.5211654985923815e-10
Text_Embedding_Affine.2.weight grad: -9.27374080306187e-11
Text_Embedding_Affine.2.bias grad: -3.827128239208832e-06
Epoch 1 finished with average loss: -64.1803
Epoch 2/39
----------
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, loss=-66.2]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-66.2]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-67]  Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-67]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-68]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-68]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09200803935527802

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09200803935527802

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09028196334838867

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.37234628200531006

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09202718734741211

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09028196334838867

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 58.79166793823242
Max value: 76.65462493896484
Mean value: 66.230712890625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09200803935527802

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09200803935527802

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09200803935527802

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.37234628200531006

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 58.79166793823242
Max value: 76.65462493896484
Mean value: 66.230712890625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.23088073730469
Max value: -66.23088073730469
Mean value: -66.23088073730469
sam_encoder.pos_embed grad: -1.544863970082133e-08
sam_encoder.blocks.0.norm1.weight grad: 6.060907617211342e-05
sam_encoder.blocks.0.norm1.bias grad: 2.7364927518647164e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.736124421673594e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.454543270388967e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.1956150249025086e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.107534212176688e-07
sam_encoder.blocks.0.norm2.weight grad: 3.091912003583275e-05
sam_encoder.blocks.0.norm2.bias grad: 1.945016992976889e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.4390536307473667e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.2422444342519157e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.747433584067039e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.5000815437815618e-05
sam_encoder.blocks.1.norm1.weight grad: -1.842808342189528e-05
sam_encoder.blocks.1.norm1.bias grad: 1.4474142517428845e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.58290295075858e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.8299751799495425e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.281873119296506e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.968770660227165e-06
sam_encoder.blocks.1.norm2.weight grad: -5.046047135692788e-06
sam_encoder.blocks.1.norm2.bias grad: -1.510666947979189e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.246308511326788e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.322408528878441e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.491114562668372e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.249242687772494e-06
sam_encoder.blocks.2.norm1.weight grad: 8.151803740474861e-06
sam_encoder.blocks.2.norm1.bias grad: -4.034194262203528e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.458953192923218e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4528441170114093e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.750411896267906e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.808694029634353e-06
sam_encoder.blocks.2.norm2.weight grad: 1.6289923223666847e-06
sam_encoder.blocks.2.norm2.bias grad: -7.888443178671878e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.0279768452601274e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.7429077817942016e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1674553661578102e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.940897163876798e-06
sam_encoder.blocks.3.norm1.weight grad: -6.36497134109959e-07
sam_encoder.blocks.3.norm1.bias grad: -1.2405420420691371e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.975557774538174e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1142967650812352e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.2656417968391906e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8512807855586288e-06
sam_encoder.blocks.3.norm2.weight grad: -1.5009779872343643e-06
sam_encoder.blocks.3.norm2.bias grad: -2.623410546220839e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.815879143890925e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.682717704123206e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.1572556104511023e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7407695622750907e-06
sam_encoder.blocks.4.norm1.weight grad: 5.884909114683978e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1887321306858212e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.8203123292769305e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.884453902486712e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.3746343029197305e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.1857488061650656e-05
sam_encoder.blocks.4.norm2.weight grad: -6.197581387823448e-05
sam_encoder.blocks.4.norm2.bias grad: -4.426090163178742e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.340412124292925e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6252324712695554e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.3821024822391337e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.963450912029657e-07
sam_encoder.blocks.5.norm1.weight grad: 3.734782148967497e-05
sam_encoder.blocks.5.norm1.bias grad: -1.1844289474538527e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.1256781110423617e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.00500891575939e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.26652285468299e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.79858635016717e-06
sam_encoder.blocks.5.norm2.weight grad: -3.7717731174780056e-05
sam_encoder.blocks.5.norm2.bias grad: -1.7321952327620238e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.8446311514708214e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.869093340355903e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.7599223762517795e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.814434752617672e-07
sam_encoder.blocks.6.norm1.weight grad: 1.4718592865392566e-05
sam_encoder.blocks.6.norm1.bias grad: 1.162149419542402e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.92665980750462e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.943188181030564e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.040068688482279e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.849117421050323e-07
sam_encoder.blocks.6.norm2.weight grad: -1.5046258340589702e-05
sam_encoder.blocks.6.norm2.bias grad: -4.547020580503158e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3327480701263994e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.502026619476965e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.1642426872858778e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.029052100420813e-06
sam_encoder.blocks.7.norm1.weight grad: 1.1390136933187023e-05
sam_encoder.blocks.7.norm1.bias grad: 3.2551949971093563e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.900170319568133e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.7676001081999857e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3834701348969247e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.482495109594311e-07
sam_encoder.blocks.7.norm2.weight grad: 1.5884073718552827e-06
sam_encoder.blocks.7.norm2.bias grad: 5.400090117291256e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.2246997509209905e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.964704759113374e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.939954116409353e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.817829903913662e-07
sam_encoder.blocks.8.norm1.weight grad: 2.0465857232920825e-05
sam_encoder.blocks.8.norm1.bias grad: -5.048447746958118e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.6643156413920224e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.411156507761916e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.227617409924278e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.60397519266553e-06
sam_encoder.blocks.8.norm2.weight grad: 7.95164339706389e-07
sam_encoder.blocks.8.norm2.bias grad: -6.872913900224376e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.0589165450910514e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0580804616088244e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.86561895943305e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.736854523594957e-07
sam_encoder.blocks.9.norm1.weight grad: 2.5433346309000626e-06
sam_encoder.blocks.9.norm1.bias grad: 4.4166296220282675e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.3375015934543626e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.104078108937756e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.309465566620929e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.0013833079701726e-07
sam_encoder.blocks.9.norm2.weight grad: 2.863475629055756e-06
sam_encoder.blocks.9.norm2.bias grad: -4.413474918862903e-09
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.2047204311093083e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.3758254264503194e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.569807737832889e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.686559466586914e-07
sam_encoder.blocks.10.norm1.weight grad: 7.858856406528503e-06
sam_encoder.blocks.10.norm1.bias grad: 4.6444893087027594e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.3256369533773977e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.31716888063238e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.982976755243726e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.007197965918749e-06
sam_encoder.blocks.10.norm2.weight grad: 7.49710443415097e-06
sam_encoder.blocks.10.norm2.bias grad: 1.99555984181643e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.989941433246713e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.7318850495939841e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.820680588745745e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.383450237175566e-08
sam_encoder.blocks.11.norm1.weight grad: 2.549831333453767e-05
sam_encoder.blocks.11.norm1.bias grad: -6.430550456570927e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.389018613437656e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.370300537928415e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.7429596229922026e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.3601046475741896e-06
sam_encoder.blocks.11.norm2.weight grad: 1.7094485883717425e-05
sam_encoder.blocks.11.norm2.bias grad: 2.5149611246888526e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.548948244424537e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.9156141206622124e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.7076406493288232e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.394254690647358e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.5143541531870142e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.1151214494020678e-06
sam_encoder.neck.conv2.trainable_scale grad: -2.8529711926239543e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.1938014469924383e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -5.046818114351481e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.2668169802054763e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005261649843305349
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001806634245440364
mask_decoder.transformer.layers.0.norm3.weight grad: 7.532909512519836e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.9238907851977274e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.906676132231951e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.850256689474918e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 8.952209100243635e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -1.058297129929997e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00014222855679690838
mask_decoder.transformer.layers.1.norm2.bias grad: 1.1701982657541521e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.3063963453751057e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.438532859145198e-07
mask_decoder.transformer.layers.1.norm4.weight grad: 1.3893950381316245e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015725975390523672
mask_decoder.transformer.norm_final_attn.weight grad: 1.4549319530487992e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.0262963769491762e-05
Text_Embedding_Affine.0.weight grad: -3.9606816090720365e-13
Text_Embedding_Affine.0.bias grad: 9.512910598141744e-11
Text_Embedding_Affine.2.weight grad: -1.118814502848453e-11
Text_Embedding_Affine.2.bias grad: 5.7333627410116605e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09041525423526764

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09041525423526764

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08725404739379883

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3873525857925415

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09035921096801758

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08725404739379883

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.9201774597168
Max value: 92.76081085205078
Mean value: 67.43441772460938

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09069058299064636

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09069058299064636

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09069058299064636

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3768046498298645

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6080893278121948
Max value: 4.430046081542969
Mean value: 1.0141714811325073

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.9201774597168
Max value: 92.76081085205078
Mean value: 67.43441772460938

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.76626586914062
Max value: -67.76626586914062
Mean value: -67.76626586914062
sam_encoder.pos_embed grad: -1.6257775126149454e-09
sam_encoder.blocks.0.norm1.weight grad: -1.607626472832635e-05
sam_encoder.blocks.0.norm1.bias grad: 1.1362708391970955e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.407296960882377e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.4610463949793484e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -9.204345587932039e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.730642674781848e-07
sam_encoder.blocks.0.norm2.weight grad: 6.195693913468858e-06
sam_encoder.blocks.0.norm2.bias grad: 1.4173390809446573e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.3502705011633225e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.888255654757813e-08
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.2800539884192403e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.2951336354235536e-07
sam_encoder.blocks.1.norm1.weight grad: -1.549487251395476e-06
sam_encoder.blocks.1.norm1.bias grad: 2.345063649045187e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.4406545005840599e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.701575105376833e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.5801218751221313e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 7.141640594454657e-07
sam_encoder.blocks.1.norm2.weight grad: 3.2624061532260384e-06
sam_encoder.blocks.1.norm2.bias grad: -1.723812601994723e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1576760243769968e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.726580264488803e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.4284539702202892e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.807375996231713e-08
sam_encoder.blocks.2.norm1.weight grad: 4.899134182778653e-07
sam_encoder.blocks.2.norm1.bias grad: -1.0029245913756313e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.77097204970778e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.2729047916291165e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.011910957364307e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0218545867246576e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0292856131854933e-06
sam_encoder.blocks.2.norm2.bias grad: -3.5112550449412083e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.657413678112789e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.3974914142854686e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.5672616200390621e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.132041102726362e-07
sam_encoder.blocks.3.norm1.weight grad: -4.03138938054326e-06
sam_encoder.blocks.3.norm1.bias grad: -3.045421863134834e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.8501872318665846e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.872265494919702e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.417510919869528e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.59438796901668e-07
sam_encoder.blocks.3.norm2.weight grad: 7.650180123164319e-06
sam_encoder.blocks.3.norm2.bias grad: 7.193739293143153e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.069070423109224e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.4311652850883547e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.3422226174952812e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.3885152106449823e-07
sam_encoder.blocks.4.norm1.weight grad: -2.4250800834124675e-06
sam_encoder.blocks.4.norm1.bias grad: 3.166457531733613e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.867676797308377e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.267856977297924e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.290655901215359e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.24112306770985e-07
sam_encoder.blocks.4.norm2.weight grad: -8.616896593593992e-06
sam_encoder.blocks.4.norm2.bias grad: -3.0006212909938768e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.783465894637629e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.5510213415836915e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.9753490455041174e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.1003943351825e-07
sam_encoder.blocks.5.norm1.weight grad: -1.816171788959764e-06
sam_encoder.blocks.5.norm1.bias grad: 1.5956219385770964e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.279562233477918e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.169764966060029e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.5618256788438885e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.268634145570104e-07
sam_encoder.blocks.5.norm2.weight grad: -6.875704912090441e-06
sam_encoder.blocks.5.norm2.bias grad: 1.5742832601972623e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.5756420402321965e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1474066923256032e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.16442606667988e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.198604640099802e-07
sam_encoder.blocks.6.norm1.weight grad: 1.036978801494115e-06
sam_encoder.blocks.6.norm1.bias grad: 5.807773391097726e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.465147019847791e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.0057302069508296e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.575316208705772e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.334201702567043e-08
sam_encoder.blocks.6.norm2.weight grad: 2.443476319058391e-07
sam_encoder.blocks.6.norm2.bias grad: 2.0840927561494027e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.511184089205926e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.577232968789758e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.418320476266672e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.9126022127456963e-07
sam_encoder.blocks.7.norm1.weight grad: 6.437196020669944e-07
sam_encoder.blocks.7.norm1.bias grad: 1.5517928204644704e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.820184914133279e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.508690830742125e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.581259756581858e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.795325250801397e-07
sam_encoder.blocks.7.norm2.weight grad: 1.6862363736436237e-06
sam_encoder.blocks.7.norm2.bias grad: 8.376190407943795e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.3003394744591787e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.1217010609243516e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.424553594617464e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.813405212189537e-07
sam_encoder.blocks.8.norm1.weight grad: 4.721327684364951e-07
sam_encoder.blocks.8.norm1.bias grad: 1.1464730960142333e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.451270676028798e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.5736351239611395e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.5006513599000755e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.149359705887036e-07
sam_encoder.blocks.8.norm2.weight grad: 1.2908644748677034e-06
sam_encoder.blocks.8.norm2.bias grad: -6.403455472536734e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.053183837029792e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.630805273744045e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.025095669632719e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.067503146463423e-07
sam_encoder.blocks.9.norm1.weight grad: -6.612790457438678e-07
sam_encoder.blocks.9.norm1.bias grad: 2.2938650090509327e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.776782821456436e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.2545892736379756e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.4779755019844742e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.48376953904517e-07
sam_encoder.blocks.9.norm2.weight grad: 2.2487233763968106e-06
sam_encoder.blocks.9.norm2.bias grad: -3.2256019721899065e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.9229751160310116e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 7.346677080022346e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.9073794987889414e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.544972576539294e-07
sam_encoder.blocks.10.norm1.weight grad: 1.1745021311071469e-06
sam_encoder.blocks.10.norm1.bias grad: -1.9350045477040112e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.5209700450213859e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.198082473929389e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.6480397486448055e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.657611387097859e-07
sam_encoder.blocks.10.norm2.weight grad: 2.370147029751024e-07
sam_encoder.blocks.10.norm2.bias grad: -1.334043645329075e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.2508835425251164e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.222054528213448e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.188984909589635e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.9315211236280447e-07
sam_encoder.blocks.11.norm1.weight grad: 5.087025328975869e-06
sam_encoder.blocks.11.norm1.bias grad: -7.928804279799806e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.767495955908089e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.598328248699545e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.404181032034103e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.352386647113235e-07
sam_encoder.blocks.11.norm2.weight grad: 1.2238940598763293e-06
sam_encoder.blocks.11.norm2.bias grad: -9.111280405704747e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.13576777241542e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.2243138886324232e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.653554921991599e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.1265063903920236e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.8325879359035753e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.825365850701928e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.789596227463335e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.612470623513218e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001448197290301323
mask_decoder.transformer.layers.0.norm1.bias grad: -6.348600436467677e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0031387479975819588
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00012946073547936976
mask_decoder.transformer.layers.0.norm3.weight grad: 4.579219239531085e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.417706466279924e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.0487404223531485e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.4388260751729831e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.20252758380957e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0065544958924875e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -6.988522363826632e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.209405834553763e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.63668441423215e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.5056167184375226e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.4643826691317372e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010207235027337447
mask_decoder.transformer.norm_final_attn.weight grad: 8.907516530598514e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.841583854111377e-06
Text_Embedding_Affine.0.weight grad: -2.3067875734583687e-13
Text_Embedding_Affine.0.bias grad: -2.0710926029732235e-11
Text_Embedding_Affine.2.weight grad: 1.5402172592882124e-10
Text_Embedding_Affine.2.bias grad: -6.333484634524211e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07400819659233093

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07400819659233093

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0631704330444336

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3145306706428528

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07410621643066406

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0631704330444336

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 64.35064697265625
Max value: 78.20115661621094
Mean value: 69.50978088378906

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07379882037639618

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07379882037639618

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07379882037639618

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2968234419822693

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.669426679611206
Max value: 9.999995231628418
Mean value: 1.0288286209106445

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 64.35064697265625
Max value: 78.20115661621094
Mean value: 69.50978088378906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.89202880859375
Max value: -69.89202880859375
Mean value: -69.89202880859375
sam_encoder.pos_embed grad: 1.7607101554517612e-08
sam_encoder.blocks.0.norm1.weight grad: -3.522569022607058e-05
sam_encoder.blocks.0.norm1.bias grad: -2.2106974938651547e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.718473860521044e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.762794283877156e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.2099013676779578e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.01021280697023e-07
sam_encoder.blocks.0.norm2.weight grad: -5.8583347708918154e-05
sam_encoder.blocks.0.norm2.bias grad: -4.695366806117818e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.732104338880163e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.699126738065388e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.297785547649255e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.839385034458246e-06
sam_encoder.blocks.1.norm1.weight grad: -4.651569724956062e-06
sam_encoder.blocks.1.norm1.bias grad: -6.13921073977508e-08
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.549859558115713e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.104400437019649e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.999010798201198e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.7437721402966417e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0466976164025255e-05
sam_encoder.blocks.1.norm2.bias grad: -4.740484200738138e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.634926031281793e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.136399181537854e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1352403816999868e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.8789758087223163e-06
sam_encoder.blocks.2.norm1.weight grad: -3.745970388990827e-06
sam_encoder.blocks.2.norm1.bias grad: 1.6465559156131349e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.079601017612731e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.578849252036889e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.010697699006414e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.1271898731356487e-06
sam_encoder.blocks.2.norm2.weight grad: 1.29678774101194e-05
sam_encoder.blocks.2.norm2.bias grad: 1.632326893741265e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.968607628252357e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.141572844673647e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.5790626498055644e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6836361282912549e-07
sam_encoder.blocks.3.norm1.weight grad: -9.25986205402296e-06
sam_encoder.blocks.3.norm1.bias grad: 5.940941264270805e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.72529200376448e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.499005849036621e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.1498589174152585e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.138424843513349e-07
sam_encoder.blocks.3.norm2.weight grad: 6.39393965684576e-06
sam_encoder.blocks.3.norm2.bias grad: 5.265143954602536e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.3861931569845183e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.839354457748414e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.045127404126106e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2661546406889101e-06
sam_encoder.blocks.4.norm1.weight grad: -3.7196030461927876e-05
sam_encoder.blocks.4.norm1.bias grad: -4.255597559676971e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.092852082569152e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.726206043415004e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0370386007707566e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.787160145904636e-06
sam_encoder.blocks.4.norm2.weight grad: 3.7621539377141744e-05
sam_encoder.blocks.4.norm2.bias grad: 3.2319032470695674e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.566678449511528e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.027849066304043e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.296603487498942e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.2977565688743198e-07
sam_encoder.blocks.5.norm1.weight grad: -2.5282504793722183e-05
sam_encoder.blocks.5.norm1.bias grad: 1.941670234373305e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5366731531685218e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.74498961516656e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.327034043351887e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.346111942752032e-06
sam_encoder.blocks.5.norm2.weight grad: 1.3789722288493067e-05
sam_encoder.blocks.5.norm2.bias grad: 1.713435813144315e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.349331331672147e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.7627005490794545e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -4.856398838626319e-09
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.617159323875967e-07
sam_encoder.blocks.6.norm1.weight grad: -5.14238263349398e-06
sam_encoder.blocks.6.norm1.bias grad: -4.559414264804218e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.912670197474654e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.387125495166401e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0639424772307393e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.338875202516192e-09
sam_encoder.blocks.6.norm2.weight grad: 8.008511940715834e-06
sam_encoder.blocks.6.norm2.bias grad: 3.9670012483838946e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.493504537909757e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.4183926800324116e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4159279544401215e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.638159574213205e-06
sam_encoder.blocks.7.norm1.weight grad: -7.803844709997065e-06
sam_encoder.blocks.7.norm1.bias grad: 4.5025763029116206e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.821039055968868e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.3082911866367795e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.437779019397567e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.410803846141789e-07
sam_encoder.blocks.7.norm2.weight grad: -4.373034244053997e-06
sam_encoder.blocks.7.norm2.bias grad: -2.8493104764493182e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.839811481360812e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.7951679132675054e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.0755131825135322e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.8104494137769507e-07
sam_encoder.blocks.8.norm1.weight grad: -5.090126705908915e-06
sam_encoder.blocks.8.norm1.bias grad: 5.217580110183917e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.456201168068219e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.6056422964538797e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.202417585474905e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.393739007151453e-06
sam_encoder.blocks.8.norm2.weight grad: -2.273378868267173e-06
sam_encoder.blocks.8.norm2.bias grad: -8.968248721430427e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.7206006077685743e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.694392252233229e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.259976311819628e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.771493872292922e-07
sam_encoder.blocks.9.norm1.weight grad: -4.053583779750625e-06
sam_encoder.blocks.9.norm1.bias grad: -1.3391776292337454e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.1797677618451416e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.2201235222164541e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.977239076557453e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.900724767750944e-07
sam_encoder.blocks.9.norm2.weight grad: -1.0444606232340448e-05
sam_encoder.blocks.9.norm2.bias grad: -2.758841901595588e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.068648756103357e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.5567286431614775e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6577166661591036e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.106989189902379e-07
sam_encoder.blocks.10.norm1.weight grad: -5.938133654126432e-06
sam_encoder.blocks.10.norm1.bias grad: -3.0252401757024927e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.132785766661982e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.3340662690097815e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.160671786237799e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.5277531057763554e-07
sam_encoder.blocks.10.norm2.weight grad: -1.689473538135644e-05
sam_encoder.blocks.10.norm2.bias grad: -4.652594270737609e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.39235178520903e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.643119609681889e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.3803459043847397e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.05591584542708e-06
sam_encoder.blocks.11.norm1.weight grad: -1.496034201409202e-05
sam_encoder.blocks.11.norm1.bias grad: 1.65909602856118e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.1716298331521102e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.4388480091583915e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.100273377436679e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.216528971781372e-06
sam_encoder.blocks.11.norm2.weight grad: -1.7173077139887027e-05
sam_encoder.blocks.11.norm2.bias grad: -4.828614692087285e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -8.757507202972192e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.740037871262757e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6750036593293771e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.108052849005617e-07
sam_encoder.neck.conv1.trainable_scale grad: -7.462258508894593e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.6043675208929926e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.913025233894587e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.734939360176213e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001121237946790643
mask_decoder.transformer.layers.0.norm1.bias grad: 2.462646079948172e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00520108500495553
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00022176798665896058
mask_decoder.transformer.layers.0.norm3.weight grad: -2.3527609300799668e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.570953701157123e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -3.6768309655599296e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -8.138466000673361e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.2906834753230214e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.511210813187063e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002729482657741755
mask_decoder.transformer.layers.1.norm2.bias grad: 7.846193329896778e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 7.713564991718158e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.102289186557755e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00015481853915844113
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017220377048943192
mask_decoder.transformer.norm_final_attn.weight grad: 1.1529444236657582e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.023726539046038e-06
Text_Embedding_Affine.0.weight grad: 1.0067593460283408e-12
Text_Embedding_Affine.0.bias grad: 2.6184922286009993e-11
Text_Embedding_Affine.2.weight grad: 7.478669766802781e-11
Text_Embedding_Affine.2.bias grad: -1.3375364687817637e-05
Epoch 2 finished with average loss: -67.9631
Epoch 3/39
----------
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, loss=-67.4]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-67.4]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-68.2]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-68.2]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-68.2]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-68.2]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08642415702342987

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08642415702342987

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08312797546386719

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3493754267692566

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08637428283691406

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08312797546386719

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 61.0482063293457
Max value: 74.25384521484375
Mean value: 67.40707397460938

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08642415702342987

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08642415702342987

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08642415702342987

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3493754267692566

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 61.0482063293457
Max value: 74.25384521484375
Mean value: 67.40707397460938

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.4072494506836
Max value: -67.4072494506836
Mean value: -67.4072494506836
sam_encoder.pos_embed grad: 1.8420504233063184e-08
sam_encoder.blocks.0.norm1.weight grad: -7.7747659815941e-05
sam_encoder.blocks.0.norm1.bias grad: -2.03696072276216e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.2309296784660546e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.2535797345190076e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.86943053046707e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.211206482475973e-07
sam_encoder.blocks.0.norm2.weight grad: 6.901879714860115e-06
sam_encoder.blocks.0.norm2.bias grad: -6.11001523793675e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.0144263544352725e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.2649605752085336e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.4200669435667805e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.995533916167915e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2897287888335995e-05
sam_encoder.blocks.1.norm1.bias grad: -7.916062713775318e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.845383162115468e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1190250006620772e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.33581340580713e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.7766072915037512e-06
sam_encoder.blocks.1.norm2.weight grad: -1.7769163605407812e-05
sam_encoder.blocks.1.norm2.bias grad: 1.1427018762333319e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.597573130624369e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4106443124717316e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.094398147775792e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.278146535507403e-07
sam_encoder.blocks.2.norm1.weight grad: -8.060626896622125e-06
sam_encoder.blocks.2.norm1.bias grad: 8.705034701961267e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.840652425424196e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.3826495382527355e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.121121197746106e-08
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.547371983993798e-07
sam_encoder.blocks.2.norm2.weight grad: 2.414607661194168e-05
sam_encoder.blocks.2.norm2.bias grad: -2.1546627237967186e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.687170697550755e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.400446636689594e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.413794042397058e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0951278994753011e-07
sam_encoder.blocks.3.norm1.weight grad: 9.32101755779513e-08
sam_encoder.blocks.3.norm1.bias grad: 7.705910320510156e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.989653229538817e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6238489024544833e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.1741883503855206e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.8240683604963124e-06
sam_encoder.blocks.3.norm2.weight grad: 1.642051211092621e-05
sam_encoder.blocks.3.norm2.bias grad: 1.2074068763467949e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.907571671239566e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.206064775440609e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.283309736929368e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.507233148207888e-06
sam_encoder.blocks.4.norm1.weight grad: -3.0020022677490488e-05
sam_encoder.blocks.4.norm1.bias grad: -5.453894118545577e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.556064307806082e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.086957687832182e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.24236883292906e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.684120540332515e-06
sam_encoder.blocks.4.norm2.weight grad: 3.199133789166808e-05
sam_encoder.blocks.4.norm2.bias grad: 2.3269105440704152e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.047186717391014e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 8.166833140421659e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.765134230590775e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.594749102830974e-07
sam_encoder.blocks.5.norm1.weight grad: -3.201868094038218e-05
sam_encoder.blocks.5.norm1.bias grad: -5.286336090648547e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.8909116988652386e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.8363477870007046e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.462894584226888e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.1690410550218076e-06
sam_encoder.blocks.5.norm2.weight grad: 1.2518321454990655e-05
sam_encoder.blocks.5.norm2.bias grad: 9.01564271771349e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.5449170354695525e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.0331141311326064e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3062656307738507e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.7186024479087791e-06
sam_encoder.blocks.6.norm1.weight grad: -1.0477393516339362e-05
sam_encoder.blocks.6.norm1.bias grad: -3.5069074328930583e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.772869826614624e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.4819992202319554e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.6356946161977248e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.16928327745336e-07
sam_encoder.blocks.6.norm2.weight grad: 2.6648302764442633e-07
sam_encoder.blocks.6.norm2.bias grad: 9.203619697473187e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.4347145906867809e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.733773147971078e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.8725602874146716e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.524262173319585e-07
sam_encoder.blocks.7.norm1.weight grad: -8.398343197768554e-06
sam_encoder.blocks.7.norm1.bias grad: 9.224608561453351e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.328391009446932e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.6928423721983563e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.7942581962415716e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.0525992517359555e-07
sam_encoder.blocks.7.norm2.weight grad: -5.099233931105118e-06
sam_encoder.blocks.7.norm2.bias grad: -2.961496193165658e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.1101233111694455e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.6788944751388044e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.0768857237053453e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.006629291732679e-07
sam_encoder.blocks.8.norm1.weight grad: -4.440034444996854e-06
sam_encoder.blocks.8.norm1.bias grad: 4.042860382469371e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.5270815058320295e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.32050273452478e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.958229515570565e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.1858669444773113e-06
sam_encoder.blocks.8.norm2.weight grad: -3.170168838551035e-06
sam_encoder.blocks.8.norm2.bias grad: -9.280572044190194e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.7225275971431984e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.031604938361852e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.868288088910049e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.18996682028228e-07
sam_encoder.blocks.9.norm1.weight grad: -5.221065293881111e-06
sam_encoder.blocks.9.norm1.bias grad: -1.8503303635952761e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.632736024883343e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.0473378299357137e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.4992574506322853e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.828371740790317e-07
sam_encoder.blocks.9.norm2.weight grad: -1.5237363186315633e-05
sam_encoder.blocks.9.norm2.bias grad: -3.8944931475271005e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.0712332368711941e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.6115450206561945e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.5589949927962152e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.08712400157674e-07
sam_encoder.blocks.10.norm1.weight grad: -7.68091376812663e-06
sam_encoder.blocks.10.norm1.bias grad: -4.053130396641791e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.7346114822867094e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.6491271708218846e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4632362308475422e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.079995955587947e-07
sam_encoder.blocks.10.norm2.weight grad: -2.0797975594177842e-05
sam_encoder.blocks.10.norm2.bias grad: -5.923269782215357e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.0629495591274463e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.8116906984650996e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.2354631710186368e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.1765906720029307e-06
sam_encoder.blocks.11.norm1.weight grad: -1.9415765564190224e-05
sam_encoder.blocks.11.norm1.bias grad: 1.1687905043800129e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.3697932028408104e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.3832180318095197e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.690227216196945e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.808023845725984e-07
sam_encoder.blocks.11.norm2.weight grad: -1.7371141439070925e-05
sam_encoder.blocks.11.norm2.bias grad: -5.190209321881412e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.518333172309212e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.109585122729186e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5491616522922413e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.4993146869055636e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0838684829650447e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.594576264731586e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.472699508070946e-07
sam_encoder.neck.conv2.trainable_shift grad: -8.007376891328022e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -6.3793093431741e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.9335205908864737e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004446401260793209
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003307742881588638
mask_decoder.transformer.layers.0.norm3.weight grad: 7.949594873934984e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -6.9321467890404165e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -1.6911722923396155e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -8.480448741465807e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.5957298930734396e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -9.821331332204863e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00028704022406600416
mask_decoder.transformer.layers.1.norm2.bias grad: 7.619798270752653e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 7.09897285560146e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.619534153491259e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0001920370850712061
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002193193940911442
mask_decoder.transformer.norm_final_attn.weight grad: 1.1309905858070124e-05
mask_decoder.transformer.norm_final_attn.bias grad: 9.669984137872234e-06
Text_Embedding_Affine.0.weight grad: -9.986511617654514e-12
Text_Embedding_Affine.0.bias grad: -3.5283098664962154e-10
Text_Embedding_Affine.2.weight grad: -1.2590360698450098e-10
Text_Embedding_Affine.2.bias grad: 1.6525109458598308e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08937852084636688

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08937852084636688

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08304309844970703

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3383713960647583

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08936738967895508

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08304309844970703

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.94931411743164
Max value: 87.71125793457031
Mean value: 68.5493392944336

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08820116519927979

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08820116519927979

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08820116519927979

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.32862505316734314

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.4874226748943329
Max value: 4.999995231628418
Mean value: 1.0127899646759033

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.94931411743164
Max value: 87.71125793457031
Mean value: 68.5493392944336

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.895751953125
Max value: -68.895751953125
Mean value: -68.895751953125
sam_encoder.pos_embed grad: -2.240616581161703e-09
sam_encoder.blocks.0.norm1.weight grad: -2.9378115868894383e-05
sam_encoder.blocks.0.norm1.bias grad: 1.9570607037167065e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.43545139003254e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.3726990744089562e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.6467937484776485e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.377455967296555e-07
sam_encoder.blocks.0.norm2.weight grad: 3.0159342713886872e-05
sam_encoder.blocks.0.norm2.bias grad: 1.3577962818089873e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.548670403892174e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.530838517282973e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.9746192821185105e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.7683812529867282e-06
sam_encoder.blocks.1.norm1.weight grad: -8.480307656100194e-07
sam_encoder.blocks.1.norm1.bias grad: 5.746009264839813e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.356641956197564e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.939385007673991e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.0424469110148493e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.877434633954181e-08
sam_encoder.blocks.1.norm2.weight grad: 7.117198038031347e-06
sam_encoder.blocks.1.norm2.bias grad: -1.1026838819816476e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.728335509047611e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0649209798430093e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.027729674926377e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.11682776757516e-09
sam_encoder.blocks.2.norm1.weight grad: 3.4814954119610775e-07
sam_encoder.blocks.2.norm1.bias grad: -5.23417256204084e-08
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.826818044672109e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.8505959903668554e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.5997685497713974e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.13977409657673e-06
sam_encoder.blocks.2.norm2.weight grad: 4.6858881432854105e-06
sam_encoder.blocks.2.norm2.bias grad: -5.254858479020186e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.5221920623152982e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.6525754037720617e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.189355654991232e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.791117463464616e-07
sam_encoder.blocks.3.norm1.weight grad: -9.961825526261237e-06
sam_encoder.blocks.3.norm1.bias grad: -4.643122331060567e-09
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.692111360782292e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1363231351424474e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.6553210571146337e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.843183525807035e-07
sam_encoder.blocks.3.norm2.weight grad: 1.1922820704057813e-05
sam_encoder.blocks.3.norm2.bias grad: 9.486304406891577e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.996430551633239e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.6700953387480695e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.389220175151422e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.075965869849597e-09
sam_encoder.blocks.4.norm1.weight grad: -4.556955900625326e-06
sam_encoder.blocks.4.norm1.bias grad: -4.310801955398347e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.8670226583926706e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3775122624792857e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.4818618271638115e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.523522521703853e-07
sam_encoder.blocks.4.norm2.weight grad: -1.4520958757202607e-05
sam_encoder.blocks.4.norm2.bias grad: -7.863984137657098e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1544153494469356e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.885984369844664e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.03511876356788e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.184214041444648e-07
sam_encoder.blocks.5.norm1.weight grad: -1.5874375094426796e-06
sam_encoder.blocks.5.norm1.bias grad: -4.3584429931797786e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.030289796399302e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.032316145545337e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.0022993137681624e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.009509204181086e-07
sam_encoder.blocks.5.norm2.weight grad: -7.6245542004471645e-06
sam_encoder.blocks.5.norm2.bias grad: -8.449011374977999e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.1726666495378595e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6699984826118452e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1170812967975507e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.471249445079593e-07
sam_encoder.blocks.6.norm1.weight grad: -8.878048163296626e-08
sam_encoder.blocks.6.norm1.bias grad: 2.2062040443415754e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.324680500962131e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.8386166301716e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.1588659744084e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.872071777597739e-07
sam_encoder.blocks.6.norm2.weight grad: -4.771417749793727e-08
sam_encoder.blocks.6.norm2.bias grad: -8.562226128105976e-08
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.0514571019702998e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.05476850271225e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.118478831420362e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.532879304657399e-07
sam_encoder.blocks.7.norm1.weight grad: 7.85613508469396e-07
sam_encoder.blocks.7.norm1.bias grad: 1.9766416698985267e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.5555156096525025e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0216160717391176e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.26323311633314e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.40709698068531e-07
sam_encoder.blocks.7.norm2.weight grad: 2.5316126084362622e-06
sam_encoder.blocks.7.norm2.bias grad: 4.640156134883e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 8.500119292875752e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.098526222966029e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6048195661255704e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.72589227026765e-07
sam_encoder.blocks.8.norm1.weight grad: 8.805828883851063e-07
sam_encoder.blocks.8.norm1.bias grad: 1.4675360944238491e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.233479878237631e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.2233891172618314e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.775472911613178e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.009683594740636e-07
sam_encoder.blocks.8.norm2.weight grad: 1.4264845731304376e-06
sam_encoder.blocks.8.norm2.bias grad: -1.031840156429098e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.5089881344465539e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.30368924450886e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.142424015502911e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.533663152031295e-07
sam_encoder.blocks.9.norm1.weight grad: -5.397503173298901e-07
sam_encoder.blocks.9.norm1.bias grad: 3.8455490880551224e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.543226287343714e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.280879460973665e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.7642951749839995e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.138104933801515e-07
sam_encoder.blocks.9.norm2.weight grad: 1.952080765477149e-06
sam_encoder.blocks.9.norm2.bias grad: -8.770845738581556e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.949605575646274e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.692041552014416e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6555532056372613e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.0363935366040096e-07
sam_encoder.blocks.10.norm1.weight grad: 2.1909868337388616e-06
sam_encoder.blocks.10.norm1.bias grad: -3.3828581535999547e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.305401267221896e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.962700578900694e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.334574204127421e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.653251034549612e-07
sam_encoder.blocks.10.norm2.weight grad: -1.1143913525302196e-06
sam_encoder.blocks.10.norm2.bias grad: -2.0740108084282838e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.791972507220635e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.03369642249163e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2624333294297685e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.898570296063554e-07
sam_encoder.blocks.11.norm1.weight grad: 7.689825906709302e-06
sam_encoder.blocks.11.norm1.bias grad: 5.499578037415631e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.269305241497932e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.7166083782503847e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.670250924235006e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.78860596836239e-07
sam_encoder.blocks.11.norm2.weight grad: -4.672403974836925e-08
sam_encoder.blocks.11.norm2.bias grad: -1.8391164076092537e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.4082980871753534e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.8314746575451863e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0219972637059982e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.656590538663295e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.2533171179238707e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.0136311175301671e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.600822987616993e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.844315895345062e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001737534475978464
mask_decoder.transformer.layers.0.norm1.bias grad: -7.766466296743602e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00283942767418921
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00018452138465363532
mask_decoder.transformer.layers.0.norm3.weight grad: 2.0300860342103988e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.1033683121204376e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.31644720165059e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.1147570805624127e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 7.53594795241952e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.7243677322985604e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.113123137969524e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00013594591291621327
mask_decoder.transformer.layers.1.norm3.weight grad: 5.18338565598242e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.34270506654866e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.4903479142230935e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011248186638113111
mask_decoder.transformer.norm_final_attn.weight grad: 1.2908891221741214e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.0838504749699496e-05
Text_Embedding_Affine.0.weight grad: -1.3019500842009757e-12
Text_Embedding_Affine.0.bias grad: -3.647842444776117e-11
Text_Embedding_Affine.2.weight grad: 2.076093290337422e-11
Text_Embedding_Affine.2.bias grad: -7.488033588742837e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08927483856678009

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08927483856678009

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08617877960205078

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3400440216064453

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0894155502319336

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08617877960205078

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.00225067138672
Max value: 83.9561767578125
Mean value: 68.08621215820312

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08726119995117188

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08726119995117188

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08726119995117188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3213011622428894

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.15698562562465668
Max value: 82.0
Mean value: 1.0441582202911377

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.00225067138672
Max value: 83.9561767578125
Mean value: 68.08621215820312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.3676528930664
Max value: -68.3676528930664
Mean value: -68.3676528930664
sam_encoder.pos_embed grad: -1.210601219270302e-08
sam_encoder.blocks.0.norm1.weight grad: -2.2764503228245303e-05
sam_encoder.blocks.0.norm1.bias grad: 1.3819389096170198e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0338130727614043e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.570852223968359e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.3376753688353347e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.727067448584421e-07
sam_encoder.blocks.0.norm2.weight grad: 1.9260911358287558e-05
sam_encoder.blocks.0.norm2.bias grad: 2.1847474272362888e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.275737516465597e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.407235221355222e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.075319025607314e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.477503797621466e-06
sam_encoder.blocks.1.norm1.weight grad: -7.558402330687386e-07
sam_encoder.blocks.1.norm1.bias grad: 1.0042683243227657e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.993635229766369e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1165432169946143e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.5500321498839185e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.999242027130094e-07
sam_encoder.blocks.1.norm2.weight grad: 1.4706745787407272e-05
sam_encoder.blocks.1.norm2.bias grad: -5.823707027730052e-08
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.34317939329776e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.9588705981732346e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.71193912846502e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.5513687685597688e-06
sam_encoder.blocks.2.norm1.weight grad: 9.516179488855414e-06
sam_encoder.blocks.2.norm1.bias grad: -5.535716809390578e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.695570052921539e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.142204382631462e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4787518693992752e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.469301534802071e-06
sam_encoder.blocks.2.norm2.weight grad: -3.6280798667576164e-06
sam_encoder.blocks.2.norm2.bias grad: -7.536988050560467e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.6664461074688006e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.4854134608176537e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.823978206833999e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.121219477492559e-07
sam_encoder.blocks.3.norm1.weight grad: 3.5039126942137955e-06
sam_encoder.blocks.3.norm1.bias grad: -6.545457836182322e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.579271136317402e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.804639494679577e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.4029261541945743e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.4028303212398896e-06
sam_encoder.blocks.3.norm2.weight grad: -3.549925622792216e-06
sam_encoder.blocks.3.norm2.bias grad: -7.588641437905608e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.2327853937676991e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.1609388884135114e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.006482974247774e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.21186610613222e-06
sam_encoder.blocks.4.norm1.weight grad: 2.287866300321184e-05
sam_encoder.blocks.4.norm1.bias grad: -3.1185816169454483e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1811445801868103e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.0971648357080994e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.445613846357446e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.976155080134049e-06
sam_encoder.blocks.4.norm2.weight grad: -4.2230494727846235e-05
sam_encoder.blocks.4.norm2.bias grad: -2.4839318939484656e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.723822217376437e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.99792609945871e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.180951110465685e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.191947541836271e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4870913219056092e-05
sam_encoder.blocks.5.norm1.bias grad: -2.9984989851072896e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.989900041138753e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.51760821154312e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.576604507950833e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.565474682749482e-06
sam_encoder.blocks.5.norm2.weight grad: -2.2684427676722407e-05
sam_encoder.blocks.5.norm2.bias grad: -1.2102990694984328e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.108955055125989e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.976201130877598e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.501858417275798e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.392810180637753e-07
sam_encoder.blocks.6.norm1.weight grad: 7.5328280217945576e-06
sam_encoder.blocks.6.norm1.bias grad: 6.148964075691765e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.259385948695126e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.116185780527303e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.338492777198553e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.160476229728374e-07
sam_encoder.blocks.6.norm2.weight grad: -9.903686077450402e-06
sam_encoder.blocks.6.norm2.bias grad: -3.5844584544975078e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.95330436428776e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.94231131192646e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.797571015544236e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.986174068719265e-07
sam_encoder.blocks.7.norm1.weight grad: 5.356693691282999e-06
sam_encoder.blocks.7.norm1.bias grad: 2.0526513253571466e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.0766800591663923e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.8081834696204169e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.676594365562778e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.484705975002726e-07
sam_encoder.blocks.7.norm2.weight grad: 2.06160984816961e-06
sam_encoder.blocks.7.norm2.bias grad: 1.6595572560618166e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.9265006560308393e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.1165701958334466e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.438703634448757e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.453476769114786e-07
sam_encoder.blocks.8.norm1.weight grad: -8.773084800850484e-07
sam_encoder.blocks.8.norm1.bias grad: -1.3115879937686259e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.944241830642568e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.373037422235939e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.8580047910509165e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.7520519577374216e-06
sam_encoder.blocks.8.norm2.weight grad: 7.737883152003633e-07
sam_encoder.blocks.8.norm2.bias grad: -1.243266524397768e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.2865564258390805e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.5175882595030998e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.849189328912871e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.0473736362400814e-07
sam_encoder.blocks.9.norm1.weight grad: 1.460837438571616e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0377439139119815e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.173849437298486e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.590603440301493e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.0774068641694612e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.853472207993036e-08
sam_encoder.blocks.9.norm2.weight grad: 6.481954187620431e-06
sam_encoder.blocks.9.norm2.bias grad: 8.207773589674616e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.726452516479185e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.0257912183296867e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.0463812714078813e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.3264041359993826e-08
sam_encoder.blocks.10.norm1.weight grad: 6.811048933741404e-06
sam_encoder.blocks.10.norm1.bias grad: 1.6141286778292852e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.6934932268195553e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.6208595070565934e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.9716071619768627e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.836170420385315e-07
sam_encoder.blocks.10.norm2.weight grad: 8.788284503680188e-06
sam_encoder.blocks.10.norm2.bias grad: 5.435553021015949e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.58913006898365e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.0607662918337155e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.769211384176742e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.3113276509102434e-07
sam_encoder.blocks.11.norm1.weight grad: 1.4240368727769237e-05
sam_encoder.blocks.11.norm1.bias grad: 7.312944205750682e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.100486871218891e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.615375365166983e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.5723010164947482e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.219078502705088e-07
sam_encoder.blocks.11.norm2.weight grad: 9.660690921009518e-06
sam_encoder.blocks.11.norm2.bias grad: 7.01623775967164e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.4170189943979494e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.3139338079781737e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.319522647871054e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.5069664627276325e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.199493221472949e-07
sam_encoder.neck.conv1.trainable_shift grad: 7.409575118799694e-06
sam_encoder.neck.conv2.trainable_scale grad: -3.4915865398943424e-07
sam_encoder.neck.conv2.trainable_shift grad: -8.008387339941692e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -8.013835758902133e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.996326657012105e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004560881294310093
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00010590726742520928
mask_decoder.transformer.layers.0.norm3.weight grad: 5.977832188364118e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 1.9413600966800004e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.844501280691475e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.8053741415496916e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.219136331405025e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.905493031197693e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00022458350576926023
mask_decoder.transformer.layers.1.norm2.bias grad: 3.4149998100474477e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -1.3448201571009122e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.416892574634403e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -6.919271982042119e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016849514213390648
mask_decoder.transformer.norm_final_attn.weight grad: 7.872789865359664e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.936963927728357e-06
Text_Embedding_Affine.0.weight grad: -1.5862036076980113e-12
Text_Embedding_Affine.0.bias grad: -7.88167586751598e-11
Text_Embedding_Affine.2.weight grad: 3.318163799281848e-11
Text_Embedding_Affine.2.bias grad: -2.546752966736676e-06
Epoch 3 finished with average loss: -68.2236
Epoch 4/39
----------
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.8]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-64.8]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-65.3]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-65.3]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-66.7]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-66.7]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09413766860961914

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09413766860961914

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0925898551940918

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.34792259335517883

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09419059753417969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0925898551940918

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 49.16070556640625
Max value: 79.59201049804688
Mean value: 64.82806396484375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09413766860961914

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09413766860961914

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09413766860961914

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.34792259335517883

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 49.16070556640625
Max value: 79.59201049804688
Mean value: 64.82806396484375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.82828521728516
Max value: -64.82828521728516
Mean value: -64.82828521728516
sam_encoder.pos_embed grad: -1.830953166859217e-08
sam_encoder.blocks.0.norm1.weight grad: 3.814561750914436e-07
sam_encoder.blocks.0.norm1.bias grad: 2.239259993075393e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.7189189520649961e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.264518172978569e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.350638722731674e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.0778849097478087e-07
sam_encoder.blocks.0.norm2.weight grad: 7.99653644207865e-05
sam_encoder.blocks.0.norm2.bias grad: 1.669138146098703e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 8.183884347090498e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.86994895254611e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.059990922338329e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.15231123851845e-06
sam_encoder.blocks.1.norm1.weight grad: -1.0969285995088285e-06
sam_encoder.blocks.1.norm1.bias grad: -7.608273335790727e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.0991542467309046e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.800413636185112e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.979821485700086e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.831857955243322e-06
sam_encoder.blocks.1.norm2.weight grad: 1.9328743292135186e-05
sam_encoder.blocks.1.norm2.bias grad: 2.6847028493648395e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.110802481387509e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4484426174021792e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0145753549295478e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.181744770903606e-06
sam_encoder.blocks.2.norm1.weight grad: -2.290805696247844e-06
sam_encoder.blocks.2.norm1.bias grad: -1.290808904741425e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.8680397033676854e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4820915339441854e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.81854396336712e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.385440206533531e-06
sam_encoder.blocks.2.norm2.weight grad: -8.386308763874695e-06
sam_encoder.blocks.2.norm2.bias grad: -1.0544328688411042e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.996853360556997e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.7909625259781023e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.660088599919618e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3641119949170388e-06
sam_encoder.blocks.3.norm1.weight grad: 1.8590493709780276e-05
sam_encoder.blocks.3.norm1.bias grad: -1.2371589036774822e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.6505849645182025e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2497082479967503e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.8572819701366825e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.6033709471230395e-06
sam_encoder.blocks.3.norm2.weight grad: -1.78708194198407e-06
sam_encoder.blocks.3.norm2.bias grad: -1.2538244845927693e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.803816414598259e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.3183498595026322e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.2861927290214226e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.3269118426251225e-07
sam_encoder.blocks.4.norm1.weight grad: 4.495284520089626e-05
sam_encoder.blocks.4.norm1.bias grad: -7.18131832400104e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.603586108307354e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.576857569802087e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2226551916683093e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.025345207192004e-06
sam_encoder.blocks.4.norm2.weight grad: -7.392563566099852e-05
sam_encoder.blocks.4.norm2.bias grad: -4.611018084688112e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.140603752806783e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.9368446373846382e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.361640326853376e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1876235223317053e-06
sam_encoder.blocks.5.norm1.weight grad: 2.305576163053047e-05
sam_encoder.blocks.5.norm1.bias grad: -1.9950064597651362e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4238218682294246e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.8829717873813934e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 7.396083674393594e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.123777661239728e-06
sam_encoder.blocks.5.norm2.weight grad: -2.8990158170927316e-05
sam_encoder.blocks.5.norm2.bias grad: -2.626430068630725e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.548512025503442e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.71423846243124e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.993491640765569e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.74792715926742e-07
sam_encoder.blocks.6.norm1.weight grad: 5.202815373195335e-06
sam_encoder.blocks.6.norm1.bias grad: 2.203966687375214e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.2917519092734437e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.759483307585469e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9898993741662707e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.06816399795207e-07
sam_encoder.blocks.6.norm2.weight grad: -2.089573536068201e-05
sam_encoder.blocks.6.norm2.bias grad: -6.069197752367472e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.6314827007590793e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.301734058273723e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.9232263639423763e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.2902449952889583e-06
sam_encoder.blocks.7.norm1.weight grad: 2.8836184355895966e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0438843673910014e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.653915877701365e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.37698862090474e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.381655287488684e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7886426348923123e-06
sam_encoder.blocks.7.norm2.weight grad: 3.1463923733099364e-06
sam_encoder.blocks.7.norm2.bias grad: 3.87260888601304e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.9016026676108595e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.464898317266488e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0809860668814508e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.3723598963651966e-08
sam_encoder.blocks.8.norm1.weight grad: 6.0381316870916635e-06
sam_encoder.blocks.8.norm1.bias grad: -6.603367182833608e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.4940893531020265e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.236062528027105e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.7294380490493495e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.157987288839649e-06
sam_encoder.blocks.8.norm2.weight grad: -5.6315475376322865e-06
sam_encoder.blocks.8.norm2.bias grad: -2.4179857405215444e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.647169018629938e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.764306827884866e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.8217298222443787e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.3379188885664917e-06
sam_encoder.blocks.9.norm1.weight grad: -2.168243099731626e-06
sam_encoder.blocks.9.norm1.bias grad: 1.5472903669433435e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.6431144962989492e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1648966165012098e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.942542494110967e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.8299407378872274e-07
sam_encoder.blocks.9.norm2.weight grad: 3.411018042243086e-06
sam_encoder.blocks.9.norm2.bias grad: 8.86345077333317e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 9.081779239750176e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.816671613141807e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.368657174491091e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.535970946217276e-08
sam_encoder.blocks.10.norm1.weight grad: 7.941316653159447e-06
sam_encoder.blocks.10.norm1.bias grad: 3.0335309020301793e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.0424448596022557e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3824887901137117e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.463244300088263e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.062699084286578e-06
sam_encoder.blocks.10.norm2.weight grad: 7.834659299987834e-06
sam_encoder.blocks.10.norm2.bias grad: -2.718495011322375e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.106033313495573e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.6130178437379072e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.1219322004762944e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.9270040613482706e-07
sam_encoder.blocks.11.norm1.weight grad: 2.3426026018569246e-05
sam_encoder.blocks.11.norm1.bias grad: 1.4605575415771455e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.5471248932262824e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.92497747472953e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.899262082995847e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7578670394868823e-06
sam_encoder.blocks.11.norm2.weight grad: 1.0670849405869376e-05
sam_encoder.blocks.11.norm2.bias grad: 8.635652193333954e-09
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.497523256461136e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.107737923841341e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.389239158328564e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.8100169540957722e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.6399069358594716e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.4091245247982442e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.080689101712778e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.5805258954060264e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 1.1890166206285357e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.224172931164503e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00375117314979434
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00012769707245752215
mask_decoder.transformer.layers.0.norm3.weight grad: 9.856077667791396e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.590366633143276e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010594085324555635
mask_decoder.transformer.layers.0.norm4.bias grad: 9.313473128713667e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.258235301473178e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.3757241908460855e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00039432611083611846
mask_decoder.transformer.layers.1.norm2.bias grad: -7.282152364496142e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.086232704343274e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.813240179326385e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.589856351027265e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.000203108080313541
mask_decoder.transformer.norm_final_attn.weight grad: 1.0604495400912128e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.076002445188351e-05
Text_Embedding_Affine.0.weight grad: 5.786405209151635e-12
Text_Embedding_Affine.0.bias grad: 2.5821578208962137e-10
Text_Embedding_Affine.2.weight grad: 3.643888663029671e-11
Text_Embedding_Affine.2.bias grad: 7.3490964496158995e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07194065302610397

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07194065302610397

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07436656951904297

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2845830023288727

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07191753387451172

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07436656951904297

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.00386047363281
Max value: 90.51097869873047
Mean value: 65.55692291259766

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07198092341423035

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07198092341423035

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07198092341423035

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.27647045254707336

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7301212549209595
Max value: 4.673151969909668
Mean value: 1.0108132362365723

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.00386047363281
Max value: 90.51097869873047
Mean value: 65.55692291259766

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.83598327636719
Max value: -65.83598327636719
Mean value: -65.83598327636719
sam_encoder.pos_embed grad: -1.801536475554144e-09
sam_encoder.blocks.0.norm1.weight grad: 4.3605041355476715e-06
sam_encoder.blocks.0.norm1.bias grad: 1.6405174392275512e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.624304215714801e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.365292896745814e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.4777098133199615e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.096294751818277e-08
sam_encoder.blocks.0.norm2.weight grad: 2.2601030650548637e-05
sam_encoder.blocks.0.norm2.bias grad: 1.981827699637506e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.222130544600077e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.249679198484955e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.6352701044961577e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.199391306272446e-07
sam_encoder.blocks.1.norm1.weight grad: -3.338084297865862e-06
sam_encoder.blocks.1.norm1.bias grad: 8.674316632095724e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.4294877221109346e-08
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.3314632358051313e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.3439740693429485e-09
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.878043106757104e-08
sam_encoder.blocks.1.norm2.weight grad: 6.506306817755103e-06
sam_encoder.blocks.1.norm2.bias grad: -5.267649157758569e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.808432666119188e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.044500651114504e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.25238737181644e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2844094499087078e-07
sam_encoder.blocks.2.norm1.weight grad: 2.220028363808524e-06
sam_encoder.blocks.2.norm1.bias grad: -9.292550089412543e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.5466184777324088e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.198078032568446e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4256960412240005e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.693334964642418e-07
sam_encoder.blocks.2.norm2.weight grad: -5.904716431359702e-07
sam_encoder.blocks.2.norm2.bias grad: -6.845662028354127e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.7317539402483817e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.595244268377428e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1570036804187112e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.840166631467582e-07
sam_encoder.blocks.3.norm1.weight grad: -6.761046279279981e-06
sam_encoder.blocks.3.norm1.bias grad: -2.6956740839523263e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.5449494387430605e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.745794915881561e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.602842965250602e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.3586024983378593e-07
sam_encoder.blocks.3.norm2.weight grad: 1.0327307791158091e-05
sam_encoder.blocks.3.norm2.bias grad: 7.38293874746887e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.299547633010661e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.6864963729167357e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.514376415609149e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.824408961212612e-07
sam_encoder.blocks.4.norm1.weight grad: -2.7059068088419735e-06
sam_encoder.blocks.4.norm1.bias grad: -1.3880011806577386e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.7181782823172398e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.029585612552182e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.543268576322589e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3340620625967858e-06
sam_encoder.blocks.4.norm2.weight grad: -8.098740181594621e-06
sam_encoder.blocks.4.norm2.bias grad: -4.612131760950433e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.703101007587975e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.9106623767584097e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.919195018577739e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6243358774991066e-07
sam_encoder.blocks.5.norm1.weight grad: -3.3460871691204375e-06
sam_encoder.blocks.5.norm1.bias grad: -3.720096515280602e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.2148274183564354e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.669016225809173e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.155978755055912e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.9636264997634498e-08
sam_encoder.blocks.5.norm2.weight grad: -5.286770829115994e-06
sam_encoder.blocks.5.norm2.bias grad: 5.8749947129399516e-09
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.8595310393720865e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.408375614024408e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -7.512209663218528e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.31206546586327e-07
sam_encoder.blocks.6.norm1.weight grad: 5.539080660810214e-08
sam_encoder.blocks.6.norm1.bias grad: 2.4833091174514266e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.149716788670048e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.0211806511506438e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.6985593371573486e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.1012621093395865e-07
sam_encoder.blocks.6.norm2.weight grad: -3.4030807682938757e-07
sam_encoder.blocks.6.norm2.bias grad: -2.505410918729467e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.940008910940378e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.5281361243069114e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.3273982441860426e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.566288680507569e-09
sam_encoder.blocks.7.norm1.weight grad: -4.6141289544721076e-07
sam_encoder.blocks.7.norm1.bias grad: 1.6140957086463459e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.045054649599479e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.095980324971606e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.854483096205513e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.383023531952858e-08
sam_encoder.blocks.7.norm2.weight grad: 1.9093981791229453e-06
sam_encoder.blocks.7.norm2.bias grad: 8.075303412624635e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0139692676602863e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.543693137293303e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.831457994849188e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.669647518720012e-07
sam_encoder.blocks.8.norm1.weight grad: -1.6538778027097578e-06
sam_encoder.blocks.8.norm1.bias grad: 1.2584135902216076e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.872861841751728e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.0238586583000142e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9602932727357256e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.98941068624481e-07
sam_encoder.blocks.8.norm2.weight grad: 1.3250328265712596e-06
sam_encoder.blocks.8.norm2.bias grad: -5.823768560730969e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.122636376749142e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.0329945250050514e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.719735784419754e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.484300278472801e-08
sam_encoder.blocks.9.norm1.weight grad: -2.004213456530124e-06
sam_encoder.blocks.9.norm1.bias grad: 2.098344964451826e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.2787284049409209e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.5869298408688337e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.704016174476692e-09
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.823818345466862e-07
sam_encoder.blocks.9.norm2.weight grad: 1.9277367755421437e-06
sam_encoder.blocks.9.norm2.bias grad: -2.8027903908878216e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7455407714805915e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 7.244711923704017e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1145607459184248e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.0887516427592345e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2845902119806851e-06
sam_encoder.blocks.10.norm1.bias grad: -3.507542487568571e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.7105592178268125e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.223154400686326e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.633079235347395e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.74322712054709e-07
sam_encoder.blocks.10.norm2.weight grad: -3.16824753099354e-08
sam_encoder.blocks.10.norm2.bias grad: -1.5672765130148036e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.478206948188017e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.958554159084088e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.211332899714762e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.701356661167665e-07
sam_encoder.blocks.11.norm1.weight grad: 4.38512688560877e-06
sam_encoder.blocks.11.norm1.bias grad: 3.245826860620582e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.3695370110488057e-09
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.6670676334106247e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.9562359909741645e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.808941073657479e-08
sam_encoder.blocks.11.norm2.weight grad: 6.304660473688273e-07
sam_encoder.blocks.11.norm2.bias grad: -7.33003787445341e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.6875117125891848e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.045392193394946e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.941666015336523e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.1878594108338802e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.734909791499376e-08
sam_encoder.neck.conv1.trainable_shift grad: -9.47644093685085e-06
sam_encoder.neck.conv2.trainable_scale grad: -3.6043638829141855e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.9085631720372476e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001502281811553985
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2561540643218905e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0032409033738076687
mask_decoder.transformer.layers.0.norm2.bias grad: 9.144912473857403e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -2.2416003048419952e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.891904245596379e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.781307118013501e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3543958630179986e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.820893031544983e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.3744775060331449e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.7209516449365765e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010872022539842874
mask_decoder.transformer.layers.1.norm3.weight grad: 4.8214555135928094e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.0576669056899846e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.24080515888636e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011625195475062355
mask_decoder.transformer.norm_final_attn.weight grad: 1.0256031600874849e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.97205120761646e-06
Text_Embedding_Affine.0.weight grad: 4.695595908627004e-12
Text_Embedding_Affine.0.bias grad: 1.0728441746099548e-10
Text_Embedding_Affine.2.weight grad: 1.3159973111243062e-10
Text_Embedding_Affine.2.bias grad: -4.932937372359447e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08876385539770126

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08876385539770126

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08482933044433594

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.30522146821022034

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08878803253173828

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08482933044433594

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 62.06590270996094
Max value: 80.00606536865234
Mean value: 69.08124542236328

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08773782849311829

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08773782849311829

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08773782849311829

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.28375792503356934

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6584952473640442
Max value: 10.98505687713623
Mean value: 1.0362001657485962

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 62.06590270996094
Max value: 80.00606536865234
Mean value: 69.08124542236328

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.5186767578125
Max value: -69.5186767578125
Mean value: -69.5186767578125
sam_encoder.pos_embed grad: 1.0700981434297319e-08
sam_encoder.blocks.0.norm1.weight grad: -2.0885088815703057e-05
sam_encoder.blocks.0.norm1.bias grad: 1.4043196188140428e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0495219839867787e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8726132111623883e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.24418748379685e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1433763802415342e-06
sam_encoder.blocks.0.norm2.weight grad: 1.5298333892133087e-05
sam_encoder.blocks.0.norm2.bias grad: -3.710846431204118e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6534489986952394e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.1332067515468225e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.180203288546181e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.148766937665641e-06
sam_encoder.blocks.1.norm1.weight grad: -1.4739154721610248e-05
sam_encoder.blocks.1.norm1.bias grad: -1.1665682677630684e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.1293011993984692e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.960547473980114e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.109609891311266e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.109463240340119e-06
sam_encoder.blocks.1.norm2.weight grad: -7.19862146070227e-06
sam_encoder.blocks.1.norm2.bias grad: -4.981996880815132e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.1153771285753464e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.3047058423107956e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0245165867672767e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.727207957941573e-07
sam_encoder.blocks.2.norm1.weight grad: 1.1163642739120405e-06
sam_encoder.blocks.2.norm1.bias grad: -1.1857573554152623e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.745129222603282e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.4256877395600895e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.2177865654812194e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.8020198240265017e-06
sam_encoder.blocks.2.norm2.weight grad: 5.180796506465413e-06
sam_encoder.blocks.2.norm2.bias grad: -3.4785366551659536e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.927918442059308e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.6864398730831454e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2077614883310162e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.298898946013651e-06
sam_encoder.blocks.3.norm1.weight grad: 4.2573192331474274e-06
sam_encoder.blocks.3.norm1.bias grad: 2.0109225715714274e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.149711238213058e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5892353530944092e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.216024419496534e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.7985310023505008e-06
sam_encoder.blocks.3.norm2.weight grad: 2.737999693636084e-06
sam_encoder.blocks.3.norm2.bias grad: 9.969362508854829e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1058740483349538e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.330610168944986e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1865478882100433e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.517101959005231e-06
sam_encoder.blocks.4.norm1.weight grad: -2.9188629923737608e-05
sam_encoder.blocks.4.norm1.bias grad: -9.158698958344758e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.8088321667164564e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.861863544647349e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.371615306008607e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.652556865243241e-06
sam_encoder.blocks.4.norm2.weight grad: -4.4942858039576095e-06
sam_encoder.blocks.4.norm2.bias grad: 5.993964350636816e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.870571956416825e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.1119794862679555e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.687226464739069e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.167463304038392e-07
sam_encoder.blocks.5.norm1.weight grad: -2.4472377845086157e-05
sam_encoder.blocks.5.norm1.bias grad: -9.233050150214694e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.4345764611789491e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.3482889446313493e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.636159585264977e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.498986294900533e-06
sam_encoder.blocks.5.norm2.weight grad: -7.175332484621322e-06
sam_encoder.blocks.5.norm2.bias grad: 2.3411339498125017e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.44200213678414e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6621183931420092e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.211080408822454e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.462636067932181e-07
sam_encoder.blocks.6.norm1.weight grad: -1.002709541353397e-05
sam_encoder.blocks.6.norm1.bias grad: -2.9493144211301114e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.609358933928888e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.308852117494098e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3626740837935358e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1445119980635354e-06
sam_encoder.blocks.6.norm2.weight grad: -3.2167736208066344e-06
sam_encoder.blocks.6.norm2.bias grad: -7.489992412956781e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.949336703750305e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.431037844668026e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.845037851619054e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.319781616388354e-07
sam_encoder.blocks.7.norm1.weight grad: -5.903076726099243e-06
sam_encoder.blocks.7.norm1.bias grad: 2.41249267673993e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.71340990770841e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.4633585578849306e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.432002687186468e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0115763870999217e-06
sam_encoder.blocks.7.norm2.weight grad: -7.416145990646328e-07
sam_encoder.blocks.7.norm2.bias grad: -2.063149395326036e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.825098585570231e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.269179948503734e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.5789185542635096e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.4348431654507294e-07
sam_encoder.blocks.8.norm1.weight grad: 1.5864101214901893e-06
sam_encoder.blocks.8.norm1.bias grad: 2.4128657969413325e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.7305687833868433e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.94949004962109e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3823464541928843e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.3617237729922635e-06
sam_encoder.blocks.8.norm2.weight grad: -4.903525677946163e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2506446864790632e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.018586307414807e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.754863771770033e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.0171440812409855e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.7181583795463666e-07
sam_encoder.blocks.9.norm1.weight grad: -1.7449597180529963e-06
sam_encoder.blocks.9.norm1.bias grad: -1.7616453078517225e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0183498488913756e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.474133786265156e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.7130681701237336e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.703761184529867e-07
sam_encoder.blocks.9.norm2.weight grad: -1.0020936315413564e-05
sam_encoder.blocks.9.norm2.bias grad: -3.5630282582133077e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.728705895715393e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.364067990536569e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.392356236669002e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.124847358369152e-06
sam_encoder.blocks.10.norm1.weight grad: -3.463751454546582e-06
sam_encoder.blocks.10.norm1.bias grad: -4.07745574193541e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.1767855312427855e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.66905145610508e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.414426714698493e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.619360869488446e-08
sam_encoder.blocks.10.norm2.weight grad: -1.6771606169641018e-05
sam_encoder.blocks.10.norm2.bias grad: -5.509840320883086e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.213388355216011e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.472281827678671e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.49055926562869e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.6567704506087466e-06
sam_encoder.blocks.11.norm1.weight grad: -2.6047414394270163e-06
sam_encoder.blocks.11.norm1.bias grad: 1.3150496442904114e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.9106681154189573e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.4032152623476577e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.401505399684538e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.466085954391019e-07
sam_encoder.blocks.11.norm2.weight grad: -7.69755570217967e-06
sam_encoder.blocks.11.norm2.bias grad: -4.44414126832271e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.320121206546901e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.8582634311314905e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.790061656327453e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.4697580392494274e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.528401404968463e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.015079659642652e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1926931620109826e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.8141766455955803e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019232474733144045
mask_decoder.transformer.layers.0.norm1.bias grad: 5.566595064010471e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0028050814289599657
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002827378048095852
mask_decoder.transformer.layers.0.norm3.weight grad: -4.7977744543459266e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.568070527166128e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -2.248316741315648e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.3019618866965175e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.027848864207044e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.043185516726226e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00025438639568164945
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00017574890807736665
mask_decoder.transformer.layers.1.norm3.weight grad: 9.984594362322241e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00012122312909923494
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00017972866771742702
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013786600902676582
mask_decoder.transformer.norm_final_attn.weight grad: 1.7298363673035055e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.7117796232923865e-05
Text_Embedding_Affine.0.weight grad: -5.642926230453593e-12
Text_Embedding_Affine.0.bias grad: -2.5156798866277086e-10
Text_Embedding_Affine.2.weight grad: -4.57143732590648e-11
Text_Embedding_Affine.2.bias grad: -5.966405296931043e-06
Epoch 4 finished with average loss: -66.7276
Epoch 5/39
----------
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, loss=-69.9]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-69.9]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-69.7]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-69.7]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-68.1]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-68.1]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07723332941532135

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07723332941532135

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07281303405761719

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2437969446182251

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07722902297973633

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07281303405761719

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 62.87350082397461
Max value: 87.546875
Mean value: 69.8578109741211

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07723332941532135

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07723332941532135

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07723332941532135

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2437969446182251

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 62.87350082397461
Max value: 87.546875
Mean value: 69.8578109741211

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.85801696777344
Max value: -69.85801696777344
Mean value: -69.85801696777344
sam_encoder.pos_embed grad: 1.543003946835597e-08
sam_encoder.blocks.0.norm1.weight grad: -5.315321322996169e-05
sam_encoder.blocks.0.norm1.bias grad: -1.7031299648806453e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.756753231864423e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.3024692836770555e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.694648280041292e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4360080058395397e-06
sam_encoder.blocks.0.norm2.weight grad: -2.684492210391909e-05
sam_encoder.blocks.0.norm2.bias grad: -4.8535959649598226e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.8871032807510346e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.356300567247672e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.288550919298359e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.1438910405559e-06
sam_encoder.blocks.1.norm1.weight grad: -2.951496389869135e-05
sam_encoder.blocks.1.norm1.bias grad: -2.581527951406315e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.236256351461634e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.0779750684596365e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.624157898229896e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.0838010666702758e-06
sam_encoder.blocks.1.norm2.weight grad: -1.4891302271280438e-05
sam_encoder.blocks.1.norm2.bias grad: -8.887843137017626e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1276611985522322e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.414497768972069e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.10592440655455e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.746940132667078e-07
sam_encoder.blocks.2.norm1.weight grad: 1.0436842785566114e-05
sam_encoder.blocks.2.norm1.bias grad: -2.454158675391227e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.0274188753101043e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.659787696757121e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.486393441358814e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.6835618907862226e-06
sam_encoder.blocks.2.norm2.weight grad: 9.450624929741025e-06
sam_encoder.blocks.2.norm2.bias grad: 1.3449300240608864e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.3104545359965414e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.408690645301249e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.430556437753694e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.305355226577376e-06
sam_encoder.blocks.3.norm1.weight grad: 9.620041964808479e-06
sam_encoder.blocks.3.norm1.bias grad: -6.925219622644363e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.695151230611373e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.029387525861239e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 9.9321948709985e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.289548544671561e-07
sam_encoder.blocks.3.norm2.weight grad: 3.407813346711919e-05
sam_encoder.blocks.3.norm2.bias grad: 1.3894727089791559e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2509424777817912e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.017329385736957e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.4099895098479465e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1638913974820753e-06
sam_encoder.blocks.4.norm1.weight grad: -2.4673170628375374e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1004539373971056e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.4149830349197146e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.2492905575054465e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -5.961897841189057e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5708377532064333e-06
sam_encoder.blocks.4.norm2.weight grad: 1.4946308510843664e-05
sam_encoder.blocks.4.norm2.bias grad: 1.803216218831949e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.2826711099478416e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.4785367713775486e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.2945116597838933e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.514677460880193e-07
sam_encoder.blocks.5.norm1.weight grad: -4.409843677422032e-05
sam_encoder.blocks.5.norm1.bias grad: -2.112437505275011e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.781072907964699e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.1250353862997144e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.4678984017518815e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.4759779080341104e-06
sam_encoder.blocks.5.norm2.weight grad: 1.676570354902651e-05
sam_encoder.blocks.5.norm2.bias grad: 1.6923711427807575e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.803743533761008e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.9278172658232506e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.6056287626706762e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.2178326162247686e-06
sam_encoder.blocks.6.norm1.weight grad: 1.130093187384773e-05
sam_encoder.blocks.6.norm1.bias grad: -6.747099178028293e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.0351488526794128e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.9067572288331576e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.3250641990889562e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.554996394290356e-06
sam_encoder.blocks.6.norm2.weight grad: -1.211445669468958e-05
sam_encoder.blocks.6.norm2.bias grad: -3.0143323215270357e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.22493054025108e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.882261232021847e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.505172915334697e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.865316433708358e-07
sam_encoder.blocks.7.norm1.weight grad: -2.836843577824766e-06
sam_encoder.blocks.7.norm1.bias grad: 4.286139301257208e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.1465590432635508e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.043211113938014e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3088073274047929e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.922941464727046e-06
sam_encoder.blocks.7.norm2.weight grad: -8.244238415500149e-06
sam_encoder.blocks.7.norm2.bias grad: -4.822358278033789e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.542595656355843e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.904867681598262e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6881780311450711e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0225244295725133e-06
sam_encoder.blocks.8.norm1.weight grad: 2.2270730823947815e-06
sam_encoder.blocks.8.norm1.bias grad: 2.4269822915812256e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.813650881871581e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.864964012085693e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.413272912031971e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.580853657098487e-07
sam_encoder.blocks.8.norm2.weight grad: -9.236456207872834e-06
sam_encoder.blocks.8.norm2.bias grad: -8.616874538347474e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.186154445866123e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.7444420993560925e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.399762252025539e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.408567176345969e-07
sam_encoder.blocks.9.norm1.weight grad: -7.185612957982812e-06
sam_encoder.blocks.9.norm1.bias grad: 9.041215776051104e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.850520887586754e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.9491288842109498e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.149658030248247e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.116804696721374e-06
sam_encoder.blocks.9.norm2.weight grad: -1.8175138393417e-05
sam_encoder.blocks.9.norm2.bias grad: -4.6451059461105615e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.2426526154740714e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.276515589182964e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.7256562589172972e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.0839466919351253e-07
sam_encoder.blocks.10.norm1.weight grad: -6.638838385697454e-06
sam_encoder.blocks.10.norm1.bias grad: -2.6832890398509335e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.264264473225921e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.562913095971453e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.34771994453331e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.6653000756150504e-08
sam_encoder.blocks.10.norm2.weight grad: -1.9472856365609914e-05
sam_encoder.blocks.10.norm2.bias grad: -5.4704260037397034e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.056418022926664e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.409855930338381e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2943501133122481e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.975715341970499e-07
sam_encoder.blocks.11.norm1.weight grad: -1.4477499462373089e-05
sam_encoder.blocks.11.norm1.bias grad: 2.4813919026200892e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -8.361097570741549e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.450659960435587e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.421261453695479e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.5155331968562678e-06
sam_encoder.blocks.11.norm2.weight grad: -2.2079544578446075e-05
sam_encoder.blocks.11.norm2.bias grad: -5.446770956041291e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.0250797458866145e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.771277761188685e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.5265167096222285e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.143813374772435e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.218560884008184e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.71967616956681e-05
sam_encoder.neck.conv2.trainable_scale grad: 4.1030216380022466e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.2618171240319498e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 1.9384808183531277e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 6.572023266926408e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002878829836845398
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00043809314956888556
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00024411958293057978
mask_decoder.transformer.layers.0.norm3.bias grad: -5.576344483415596e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.394245818024501e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.4501641746610403e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.163608562317677e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.910119504434988e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00013039720943197608
mask_decoder.transformer.layers.1.norm2.bias grad: -1.8329395970795304e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 9.186194802168757e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.280397817841731e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0001777978613972664
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013953006418887526
mask_decoder.transformer.norm_final_attn.weight grad: 1.3233926438260823e-05
mask_decoder.transformer.norm_final_attn.bias grad: 9.455936378799379e-06
Text_Embedding_Affine.0.weight grad: 1.0221361951279206e-11
Text_Embedding_Affine.0.bias grad: 4.5988848840217145e-10
Text_Embedding_Affine.2.weight grad: -1.6330013730136983e-11
Text_Embedding_Affine.2.bias grad: -4.2274237785022706e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09282881021499634

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09282881021499634

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09485006332397461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.27868467569351196

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09288787841796875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09485006332397461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.631019592285156
Max value: 84.85589599609375
Mean value: 69.28034210205078

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09154238551855087

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09154238551855087

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09154238551855087

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.27015021443367004

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6706621646881104
Max value: 4.0
Mean value: 1.0108133554458618

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.631019592285156
Max value: 84.85589599609375
Mean value: 69.28034210205078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.63137817382812
Max value: -69.63137817382812
Mean value: -69.63137817382812
sam_encoder.pos_embed grad: -3.054420494308374e-09
sam_encoder.blocks.0.norm1.weight grad: -1.1155198080814444e-05
sam_encoder.blocks.0.norm1.bias grad: 1.1190879376954399e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.7706222479318967e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.3409668870044698e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.492148258985253e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.7072006736925687e-07
sam_encoder.blocks.0.norm2.weight grad: 2.4301316443597898e-05
sam_encoder.blocks.0.norm2.bias grad: 6.1484779507736675e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.166024041296623e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.569587931906426e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.329678616457386e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.7128395484178327e-06
sam_encoder.blocks.1.norm1.weight grad: -1.368599669149262e-06
sam_encoder.blocks.1.norm1.bias grad: 1.0664050932973623e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.5474092833756004e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.423417010457342e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.007867542872191e-08
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.8050842476877733e-07
sam_encoder.blocks.1.norm2.weight grad: 6.954795935598668e-06
sam_encoder.blocks.1.norm2.bias grad: -1.6482617866131477e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.633833214029437e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.550492344103986e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.2033692655677442e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.339730364539719e-07
sam_encoder.blocks.2.norm1.weight grad: 7.232228199427482e-06
sam_encoder.blocks.2.norm1.bias grad: -1.75243076228071e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.194826033199206e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.5719141401859815e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.555263899419515e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.216186877987639e-07
sam_encoder.blocks.2.norm2.weight grad: 2.106220108544221e-06
sam_encoder.blocks.2.norm2.bias grad: -5.351622803573264e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.3695492927799933e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.2851751307607628e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.509064415789908e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0554228992987191e-06
sam_encoder.blocks.3.norm1.weight grad: -2.6648244784155395e-06
sam_encoder.blocks.3.norm1.bias grad: -2.6584129955153912e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.6598236243225983e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.7699647020540397e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.119676880989573e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.539338765927823e-07
sam_encoder.blocks.3.norm2.weight grad: 4.264749804860912e-06
sam_encoder.blocks.3.norm2.bias grad: 6.0205320551176555e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.214273192497785e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.260063969421026e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.072059477446601e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.924696218542522e-07
sam_encoder.blocks.4.norm1.weight grad: 7.390434575427207e-07
sam_encoder.blocks.4.norm1.bias grad: -1.869464313131175e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.6469456909362634e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.4795373693441434e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2248414122950635e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.1410439785540802e-06
sam_encoder.blocks.4.norm2.weight grad: -1.90194677998079e-05
sam_encoder.blocks.4.norm2.bias grad: -8.241373507189564e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3713242879020981e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.502999217947945e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.8315790839551482e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.860071491450071e-07
sam_encoder.blocks.5.norm1.weight grad: -3.9021556403895374e-06
sam_encoder.blocks.5.norm1.bias grad: -3.986658157373313e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.124863613062189e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.6987205242458003e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.1378280002390966e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.118453465982384e-07
sam_encoder.blocks.5.norm2.weight grad: -9.980411050491966e-06
sam_encoder.blocks.5.norm2.bias grad: -2.6430952857481316e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.931847913918318e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2704117580142338e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7782406303012976e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.147555270923476e-07
sam_encoder.blocks.6.norm1.weight grad: 2.794843965148175e-07
sam_encoder.blocks.6.norm1.bias grad: 2.6657041871658294e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.453145715568098e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.54953839279915e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.231093945847533e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.335015166949233e-08
sam_encoder.blocks.6.norm2.weight grad: -2.446891585350386e-06
sam_encoder.blocks.6.norm2.bias grad: -2.508130307887768e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.2856978628406068e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.683468083996559e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.5090633926083683e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0820391338484114e-07
sam_encoder.blocks.7.norm1.weight grad: -7.415153504553018e-07
sam_encoder.blocks.7.norm1.bias grad: 2.6276024982507806e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.398377200232062e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.082686189121887e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.044459963850386e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.528800670617784e-07
sam_encoder.blocks.7.norm2.weight grad: 3.8126172512420453e-06
sam_encoder.blocks.7.norm2.bias grad: 1.6593379541518516e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.6539137277504778e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.84247504270752e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.330678713884481e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.878783504911553e-07
sam_encoder.blocks.8.norm1.weight grad: -4.686737327119772e-07
sam_encoder.blocks.8.norm1.bias grad: 1.0595554158498999e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.213088012264052e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.243823579803575e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.176289515569806e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.9587348510394804e-08
sam_encoder.blocks.8.norm2.weight grad: 1.5231389625114389e-06
sam_encoder.blocks.8.norm2.bias grad: -6.708653188525204e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.2247875247339834e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.87293334572314e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.694589380160323e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.0914299031792325e-07
sam_encoder.blocks.9.norm1.weight grad: -1.565419893267972e-06
sam_encoder.blocks.9.norm1.bias grad: 7.739961205288637e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.2101613720005844e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.513639488365698e-09
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.907042652912423e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2150934480814612e-06
sam_encoder.blocks.9.norm2.weight grad: 3.099016225860396e-07
sam_encoder.blocks.9.norm2.bias grad: -1.0141766324522905e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.731641744612716e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.909356453528744e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.2899623053926916e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.605772119248286e-07
sam_encoder.blocks.10.norm1.weight grad: 2.2082545001467224e-06
sam_encoder.blocks.10.norm1.bias grad: -9.731667205414851e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0705388124042656e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.659268135284947e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.0697875521073e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.618404657070641e-07
sam_encoder.blocks.10.norm2.weight grad: -2.796200533339288e-06
sam_encoder.blocks.10.norm2.bias grad: -2.833214239217341e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.853846118952788e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.0198857580689946e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2761104244418675e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.133030296950892e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0821377145475708e-05
sam_encoder.blocks.11.norm1.bias grad: -6.339762137486105e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.0915654747332155e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.081754241269664e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.895176625221211e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7358824777602422e-07
sam_encoder.blocks.11.norm2.weight grad: 8.162975291270413e-07
sam_encoder.blocks.11.norm2.bias grad: -1.827699975365249e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.8221738830325194e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.952073145934264e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.905122174634016e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.5161000394291477e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.094608812010847e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1489792086649686e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.430673238355666e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.6072588298120536e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016277236863970757
mask_decoder.transformer.layers.0.norm1.bias grad: -4.050525603815913e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0038233965169638395
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00027516833506524563
mask_decoder.transformer.layers.0.norm3.weight grad: -3.5808305256068707e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 7.116189954103902e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.281290941638872e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.081042450503446e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.0213369326666e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.7470174498157576e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.5075143387075514e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001401994377374649
mask_decoder.transformer.layers.1.norm3.weight grad: 6.233465683180839e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.322792953345925e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.594735845690593e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00012032764789182693
mask_decoder.transformer.norm_final_attn.weight grad: 1.120374599850038e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.0314435712643899e-05
Text_Embedding_Affine.0.weight grad: -3.93792247074809e-12
Text_Embedding_Affine.0.bias grad: -1.4244280754915906e-10
Text_Embedding_Affine.2.weight grad: 9.676773271571903e-11
Text_Embedding_Affine.2.bias grad: 3.830811692751013e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08062339574098587

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08062339574098587

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08425140380859375

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.31109094619750977

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0805196762084961

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08425140380859375

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 62.58030319213867
Max value: 69.27923583984375
Mean value: 64.48370361328125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07933910191059113

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07933910191059113

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07933910191059113

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.29240304231643677

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5279983282089233
Max value: 8.999992370605469
Mean value: 1.030355453491211

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 62.58030319213867
Max value: 69.27923583984375
Mean value: 64.48370361328125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.85649871826172
Max value: -64.85649871826172
Mean value: -64.85649871826172
sam_encoder.pos_embed grad: -1.3327566605880747e-08
sam_encoder.blocks.0.norm1.weight grad: 6.359786311804783e-06
sam_encoder.blocks.0.norm1.bias grad: 1.4971730706747621e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.609161128930282e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.345543007071683e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.9554824979859404e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.06526873778057e-07
sam_encoder.blocks.0.norm2.weight grad: -1.364562467642827e-05
sam_encoder.blocks.0.norm2.bias grad: 3.576581730158068e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.324456727365032e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.549052952526836e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.2963708033785224e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.348327694169711e-06
sam_encoder.blocks.1.norm1.weight grad: -1.067121047526598e-06
sam_encoder.blocks.1.norm1.bias grad: 8.992737093649339e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.0109433787874877e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.168513901779079e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.77725404582452e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.214107553299982e-06
sam_encoder.blocks.1.norm2.weight grad: 2.4308250431204215e-05
sam_encoder.blocks.1.norm2.bias grad: -5.597446943284012e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1735251973732375e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.7404374779725913e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.6285840653581545e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.8439271204661054e-07
sam_encoder.blocks.2.norm1.weight grad: 9.336809853266459e-06
sam_encoder.blocks.2.norm1.bias grad: -5.012971087126061e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 9.131320439337287e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.935028649313608e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.071596898327698e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.6095473256427795e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1448904842836782e-05
sam_encoder.blocks.2.norm2.bias grad: -3.924506017938256e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.247423592256382e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.868998308258597e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.610573574202135e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0219991963822395e-06
sam_encoder.blocks.3.norm1.weight grad: 3.000485548909637e-06
sam_encoder.blocks.3.norm1.bias grad: -5.976163265586365e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.161100034456467e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2367559065751266e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.836300663806469e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.969473128672689e-07
sam_encoder.blocks.3.norm2.weight grad: 1.0986527740897145e-06
sam_encoder.blocks.3.norm2.bias grad: -5.3659509831049945e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.03636226009985e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.717657388018324e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.624406862305477e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.02342993261118e-07
sam_encoder.blocks.4.norm1.weight grad: 2.3352846255875193e-05
sam_encoder.blocks.4.norm1.bias grad: -3.8017496990505606e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1286350854788907e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.1426353669085074e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.469623142242199e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.426537765946705e-06
sam_encoder.blocks.4.norm2.weight grad: -5.158732528798282e-05
sam_encoder.blocks.4.norm2.bias grad: -3.6801422538701445e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.343733988003805e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.2821961718145758e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.760460008881637e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6147972675971687e-09
sam_encoder.blocks.5.norm1.weight grad: 6.6412685555405915e-06
sam_encoder.blocks.5.norm1.bias grad: -1.1290070688119158e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.955790574167622e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.4113625133613823e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.2083949008665513e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 5.3846597438678145e-06
sam_encoder.blocks.5.norm2.weight grad: -1.9411687389947474e-05
sam_encoder.blocks.5.norm2.bias grad: -2.269794640596956e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.627484592376277e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.339255615879665e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1215737671932402e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.365134587824286e-07
sam_encoder.blocks.6.norm1.weight grad: 5.742487701354548e-06
sam_encoder.blocks.6.norm1.bias grad: 4.557739430310903e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.62310072685068e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.863178718205745e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.203016038038186e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.360122703583329e-07
sam_encoder.blocks.6.norm2.weight grad: -1.8027660189545713e-05
sam_encoder.blocks.6.norm2.bias grad: -5.080482878838666e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.193281241285149e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.361852345231455e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.5056893971632235e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.6800112234705011e-06
sam_encoder.blocks.7.norm1.weight grad: 7.303510756173637e-06
sam_encoder.blocks.7.norm1.bias grad: -2.529270659579197e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.507032826950308e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.16582384382491e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.176357040501898e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.3651331793626014e-07
sam_encoder.blocks.7.norm2.weight grad: 3.752787506527966e-06
sam_encoder.blocks.7.norm2.bias grad: 3.298748197266832e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.69491885471507e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.165606064063468e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2515657772382838e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.144315420897328e-07
sam_encoder.blocks.8.norm1.weight grad: 2.8635331545956433e-06
sam_encoder.blocks.8.norm1.bias grad: -4.135711606068071e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0733838280430064e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.246579798447783e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.766679012391251e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.3529380491236225e-06
sam_encoder.blocks.8.norm2.weight grad: -7.965717259139637e-07
sam_encoder.blocks.8.norm2.bias grad: -6.970371941861231e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.031192469890811e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.644066843364271e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.3473244280248764e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1748525139410049e-06
sam_encoder.blocks.9.norm1.weight grad: 2.4332575776497833e-07
sam_encoder.blocks.9.norm1.bias grad: 8.13179667602526e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.9869519007897907e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.133284043447929e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.3186515843699453e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.7967561183904763e-07
sam_encoder.blocks.9.norm2.weight grad: 6.079711511119967e-06
sam_encoder.blocks.9.norm2.bias grad: 7.810753004378057e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.626620011549676e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.852576929195493e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.4784420727664838e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.404592304917969e-08
sam_encoder.blocks.10.norm1.weight grad: 8.716930096852593e-06
sam_encoder.blocks.10.norm1.bias grad: 2.614102413645014e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.14993371325545e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.182991465815576e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.943074605354923e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.414972530255909e-06
sam_encoder.blocks.10.norm2.weight grad: 9.116622095461935e-06
sam_encoder.blocks.10.norm2.bias grad: 3.6365753430800396e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.02110151501256e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.2075121250964003e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.822564617119497e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.913712352092261e-08
sam_encoder.blocks.11.norm1.weight grad: 1.436279035260668e-05
sam_encoder.blocks.11.norm1.bias grad: 1.8961045498144813e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.304416284459876e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.127040659161139e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.306315991518204e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.564739235021989e-07
sam_encoder.blocks.11.norm2.weight grad: 1.0163600563828368e-05
sam_encoder.blocks.11.norm2.bias grad: 2.769693310256116e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.29317571313004e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.1777265171986073e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.596343844947114e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0801404926041869e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.296694093383849e-08
sam_encoder.neck.conv1.trainable_shift grad: 3.692339305416681e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.032614692230709e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.656706657144241e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010518896306166425
mask_decoder.transformer.layers.0.norm1.bias grad: -5.197609425522387e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003703838214278221
mask_decoder.transformer.layers.0.norm2.bias grad: 6.95384806022048e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 5.990150384604931e-07
mask_decoder.transformer.layers.0.norm3.bias grad: 2.127121842931956e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001437721075490117
mask_decoder.transformer.layers.0.norm4.bias grad: 2.836670319084078e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.228039713576436e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.807563295296859e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00027769015287049115
mask_decoder.transformer.layers.1.norm2.bias grad: -3.5973138437839225e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.695699317380786e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -1.2210167369630653e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.7845286240335554e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00022995594190433621
mask_decoder.transformer.norm_final_attn.weight grad: 1.325286939390935e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.6414798665209673e-05
Text_Embedding_Affine.0.weight grad: -8.644690865922122e-12
Text_Embedding_Affine.0.bias grad: -3.205505028081035e-10
Text_Embedding_Affine.2.weight grad: 5.524310522919684e-11
Text_Embedding_Affine.2.bias grad: 5.813721145386808e-06
Epoch 5 finished with average loss: -68.1153
Epoch 6/39
----------
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, loss=-68.1]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-68.1]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-65]  Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-65]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-69.4]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-69.4]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636834681034088

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636834681034088

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07439374923706055

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.237137570977211

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07642889022827148

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07439374923706055

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 60.78488540649414
Max value: 82.50499725341797
Mean value: 68.1157455444336

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636834681034088

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636834681034088

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636834681034088

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.237137570977211

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 60.78488540649414
Max value: 82.50499725341797
Mean value: 68.1157455444336

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.1159896850586
Max value: -68.1159896850586
Mean value: -68.1159896850586
sam_encoder.pos_embed grad: -1.8727792649997355e-08
sam_encoder.blocks.0.norm1.weight grad: 0.00011387541599106044
sam_encoder.blocks.0.norm1.bias grad: 1.9072667782893404e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.550666403702053e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.595636025645945e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.5689164431241807e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.6306219094985863e-06
sam_encoder.blocks.0.norm2.weight grad: 4.937655103276484e-05
sam_encoder.blocks.0.norm2.bias grad: 4.442188946995884e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.5393450060801115e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.211348591023125e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.65949437461677e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.0888828556926455e-06
sam_encoder.blocks.1.norm1.weight grad: -7.188878498709528e-06
sam_encoder.blocks.1.norm1.bias grad: 3.378774181328481e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.155132963504002e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.816397229958966e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.193366870211321e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4524682683259016e-06
sam_encoder.blocks.1.norm2.weight grad: 2.2316067770589143e-05
sam_encoder.blocks.1.norm2.bias grad: -2.083608023895067e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.674449317259132e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.707457269934821e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.004375189950224e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.769580755237257e-06
sam_encoder.blocks.2.norm1.weight grad: 1.4796154573559761e-05
sam_encoder.blocks.2.norm1.bias grad: -3.8925586522964295e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.055301699030679e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.643549568252638e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.021806595730595e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.828479177376721e-06
sam_encoder.blocks.2.norm2.weight grad: -1.7346152162645012e-05
sam_encoder.blocks.2.norm2.bias grad: -5.325063739292091e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.1824682587757707e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.693292223440949e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0625899449223652e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8465865423422656e-06
sam_encoder.blocks.3.norm1.weight grad: 1.0236513844574802e-05
sam_encoder.blocks.3.norm1.bias grad: -1.7727074009599164e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.133415015734499e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.866574603416666e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.943626668638899e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.893263394478709e-07
sam_encoder.blocks.3.norm2.weight grad: 1.0304141142114531e-05
sam_encoder.blocks.3.norm2.bias grad: -7.995462510734797e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.051184517564252e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.518165385685279e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.561137630953453e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.70502016771934e-06
sam_encoder.blocks.4.norm1.weight grad: 4.8166006308747455e-05
sam_encoder.blocks.4.norm1.bias grad: -7.1499480327474885e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.3493674234487116e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.70612223277567e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 9.324978236691095e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.641983756911941e-06
sam_encoder.blocks.4.norm2.weight grad: -6.226960249477997e-05
sam_encoder.blocks.4.norm2.bias grad: -3.744038986042142e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.4472471927292645e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6993379176710732e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.783136197758722e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.990891728899442e-07
sam_encoder.blocks.5.norm1.weight grad: 2.658805897226557e-05
sam_encoder.blocks.5.norm1.bias grad: -1.9938835976063274e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4512656889564823e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.228295892971801e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.33491550211329e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.643249212676892e-06
sam_encoder.blocks.5.norm2.weight grad: -2.141290133295115e-05
sam_encoder.blocks.5.norm2.bias grad: -1.5141113181016408e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.019155186251737e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.104624511252041e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.679092964783194e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.623921429607435e-07
sam_encoder.blocks.6.norm1.weight grad: 4.625198016583454e-06
sam_encoder.blocks.6.norm1.bias grad: -3.929250738110568e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.5863429275195813e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.756416829986847e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.56546045927098e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1049157819797983e-06
sam_encoder.blocks.6.norm2.weight grad: -1.9074603187618777e-05
sam_encoder.blocks.6.norm2.bias grad: -6.994052000663942e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4844519682810642e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.769467290723696e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.064385272315121e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.0882272855924384e-07
sam_encoder.blocks.7.norm1.weight grad: -9.889193961498677e-07
sam_encoder.blocks.7.norm1.bias grad: 1.390151169289311e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.244327672291547e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.930411137138435e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.7201973605551757e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.6326898730767425e-06
sam_encoder.blocks.7.norm2.weight grad: 5.731454621127341e-06
sam_encoder.blocks.7.norm2.bias grad: 3.5347384255146608e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.366047844290733e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.178655442250601e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.29092165682232e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.30862302841706e-07
sam_encoder.blocks.8.norm1.weight grad: 5.31444948137505e-06
sam_encoder.blocks.8.norm1.bias grad: -6.611378012166824e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.8608160391740967e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.260119572383701e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.8746169391524745e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.005561095254961e-06
sam_encoder.blocks.8.norm2.weight grad: -4.1666667129902635e-06
sam_encoder.blocks.8.norm2.bias grad: -1.736191507006879e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.9916543503059074e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.927999958046712e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.044510660605738e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.0025818230351433e-06
sam_encoder.blocks.9.norm1.weight grad: -6.597323363166652e-07
sam_encoder.blocks.9.norm1.bias grad: 2.530842039050185e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.4161090550478548e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.6309759227369796e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.857021273594e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.956974054148304e-07
sam_encoder.blocks.9.norm2.weight grad: 4.815469765162561e-06
sam_encoder.blocks.9.norm2.bias grad: 2.7007743028661935e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7939222516361042e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.449626077184803e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5619870907812583e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.803770821126818e-07
sam_encoder.blocks.10.norm1.weight grad: 9.390461855218746e-06
sam_encoder.blocks.10.norm1.bias grad: 3.2117520731844706e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.871769877150655e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.0923484953527804e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.568559011706384e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.5800155779288616e-06
sam_encoder.blocks.10.norm2.weight grad: 1.0389320777903777e-05
sam_encoder.blocks.10.norm2.bias grad: 4.557154170470312e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.876495950156823e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.78079642157536e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.367055670532864e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.759592578309821e-07
sam_encoder.blocks.11.norm1.weight grad: 2.1951707822154276e-05
sam_encoder.blocks.11.norm1.bias grad: 1.057618419508799e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.268308882477868e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.616927402727015e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.8992908482905477e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.400869905410218e-06
sam_encoder.blocks.11.norm2.weight grad: 1.059372880263254e-05
sam_encoder.blocks.11.norm2.bias grad: 2.4137152649927884e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.802571078878827e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.3091483879179577e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.6276262587998644e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.69441374661983e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.9958315533585846e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.539576805953402e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.147821866557933e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.4326660422957502e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -5.1045419240836054e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.565346898743883e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0023971833288669586
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0004997143405489624
mask_decoder.transformer.layers.0.norm3.weight grad: -5.771937139797956e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.7943693567067385e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.490143565926701e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.297084236284718e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -4.701424768427387e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.643072654493153e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00032892386661842465
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00013741609291173518
mask_decoder.transformer.layers.1.norm3.weight grad: -4.069245551363565e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -7.524373359046876e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.2287882782402448e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00017455912893638015
mask_decoder.transformer.norm_final_attn.weight grad: 9.087771104532294e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.648844772716984e-05
Text_Embedding_Affine.0.weight grad: 1.0380251345976088e-12
Text_Embedding_Affine.0.bias grad: 2.0334359196461094e-11
Text_Embedding_Affine.2.weight grad: 1.5525445512531988e-11
Text_Embedding_Affine.2.bias grad: 6.662154191872105e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06976501643657684

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06976501643657684

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0787038803100586

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2745027542114258

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06964445114135742

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0787038803100586

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.62202453613281
Max value: 74.36637878417969
Mean value: 61.620079040527344

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06953023374080658

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06953023374080658

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06953023374080658

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2648601531982422

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7861708998680115
Max value: 4.303250312805176
Mean value: 1.0128955841064453

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.62202453613281
Max value: 74.36637878417969
Mean value: 61.620079040527344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.92427062988281
Max value: -61.92427062988281
Mean value: -61.92427062988281
sam_encoder.pos_embed grad: -2.7515578704395693e-09
sam_encoder.blocks.0.norm1.weight grad: -9.035315088112839e-06
sam_encoder.blocks.0.norm1.bias grad: 7.632894266862422e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.1394997727620648e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.765019288148324e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.2334480743447784e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.924388233324862e-07
sam_encoder.blocks.0.norm2.weight grad: 1.4725103028467856e-05
sam_encoder.blocks.0.norm2.bias grad: 2.6481211534701288e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4586970564778312e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.1764768714783713e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.227775091043441e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.898422846759786e-07
sam_encoder.blocks.1.norm1.weight grad: -2.011516471611685e-06
sam_encoder.blocks.1.norm1.bias grad: 4.586368504533311e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.256328101197141e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.6874667469201086e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.539902296433866e-08
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.157750919224327e-09
sam_encoder.blocks.1.norm2.weight grad: 1.7093969972847844e-06
sam_encoder.blocks.1.norm2.bias grad: -2.1682812985091005e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.6592543867518543e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0273055295328959e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.36229016334255e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.939581685903249e-07
sam_encoder.blocks.2.norm1.weight grad: -4.1643920667411294e-07
sam_encoder.blocks.2.norm1.bias grad: -2.6307707230444066e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.640876909434155e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.847527523248573e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7966571022043354e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.2537686870928155e-06
sam_encoder.blocks.2.norm2.weight grad: -3.805244830346055e-07
sam_encoder.blocks.2.norm2.bias grad: -4.464833182282746e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.755934348097071e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.7153143971881946e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.5514040114794625e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.051099035175866e-07
sam_encoder.blocks.3.norm1.weight grad: -1.8896498659159988e-06
sam_encoder.blocks.3.norm1.bias grad: -2.1865048438485246e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.944536734299618e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.013954798485429e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.631346079506329e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.159715144031907e-08
sam_encoder.blocks.3.norm2.weight grad: 4.64029335489613e-06
sam_encoder.blocks.3.norm2.bias grad: 4.952543804392917e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.5308180486026686e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.3635542472911766e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.5342761798819993e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.0715403315516596e-07
sam_encoder.blocks.4.norm1.weight grad: 1.70518433151301e-06
sam_encoder.blocks.4.norm1.bias grad: -2.609072453196859e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.6103513189591467e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.0359038899186999e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.252328941831365e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.1057411484216573e-06
sam_encoder.blocks.4.norm2.weight grad: -1.3493571714207064e-05
sam_encoder.blocks.4.norm2.bias grad: -4.636389803636121e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -9.605508239474148e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.3182491279148962e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.6863301627599867e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.1527013650011213e-07
sam_encoder.blocks.5.norm1.weight grad: -2.778801444947021e-06
sam_encoder.blocks.5.norm1.bias grad: -3.369265414221445e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.6544344109424856e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.491264793519804e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.3601070842669287e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.360002326895483e-08
sam_encoder.blocks.5.norm2.weight grad: -6.110668891778914e-06
sam_encoder.blocks.5.norm2.bias grad: -1.6717749531380832e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.423945034024655e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.62100967222068e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.0086508694939766e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.995347353542456e-07
sam_encoder.blocks.6.norm1.weight grad: 1.1479672821224085e-06
sam_encoder.blocks.6.norm1.bias grad: 1.2576135759445606e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.3485378025943646e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.649421730893664e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.32056412541715e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.218418302391001e-07
sam_encoder.blocks.6.norm2.weight grad: -2.1206908513704548e-06
sam_encoder.blocks.6.norm2.bias grad: -4.320633593124512e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.524642337055411e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.6469926928693894e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.7968339938743156e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.156999011684093e-08
sam_encoder.blocks.7.norm1.weight grad: 1.3282260624691844e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3027786280872533e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.026829750117031e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.376305456498812e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.0082314929604763e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.55654730508104e-07
sam_encoder.blocks.7.norm2.weight grad: 3.4527433854236733e-06
sam_encoder.blocks.7.norm2.bias grad: 1.1072654615418287e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.0190313989587594e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.9082277554553e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.8612676910834125e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.6875761705014156e-07
sam_encoder.blocks.8.norm1.weight grad: 1.5000466646597488e-06
sam_encoder.blocks.8.norm1.bias grad: 9.72537872456769e-09
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.653346531493298e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.929999022351694e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.505558884673519e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.692295370503416e-07
sam_encoder.blocks.8.norm2.weight grad: 7.825908028280537e-07
sam_encoder.blocks.8.norm2.bias grad: -7.01094904798083e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.039783784217434e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.8975998727910337e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.3087638939832686e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.906072348376256e-08
sam_encoder.blocks.9.norm1.weight grad: -3.8820653003313055e-07
sam_encoder.blocks.9.norm1.bias grad: 1.32472194991351e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.6899753063626122e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.2334477850781695e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.940569174825214e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.951712521185982e-07
sam_encoder.blocks.9.norm2.weight grad: 6.873622169223381e-07
sam_encoder.blocks.9.norm2.bias grad: -7.412786544591654e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 9.188230478685e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.7669535168352013e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.3405162841736455e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.564542107094894e-07
sam_encoder.blocks.10.norm1.weight grad: 2.0827767457376467e-06
sam_encoder.blocks.10.norm1.bias grad: -5.954036623734282e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.8771122540783836e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.217783490887086e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.41865550885268e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.349821433104808e-07
sam_encoder.blocks.10.norm2.weight grad: -8.503926665071049e-07
sam_encoder.blocks.10.norm2.bias grad: -1.8261887362314155e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 8.152732675625884e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.137610171208507e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.861574881142587e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.351263325792388e-07
sam_encoder.blocks.11.norm1.weight grad: 6.687028417218244e-06
sam_encoder.blocks.11.norm1.bias grad: -4.7080774834284966e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.722098871454364e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.256151899222459e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.808010534266941e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.5639899326488376e-07
sam_encoder.blocks.11.norm2.weight grad: 1.2609489203896374e-06
sam_encoder.blocks.11.norm2.bias grad: -1.0297965218342142e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.1945468233752763e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.196390767039702e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.671579058092902e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.50558940706469e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.905594556068536e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1595237083383836e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.012651283526793e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.0081697332207114e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014244050544220954
mask_decoder.transformer.layers.0.norm1.bias grad: -7.054914021864533e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004170597065240145
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002725710510276258
mask_decoder.transformer.layers.0.norm3.weight grad: -1.2220785720273852e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.5967750338604674e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.5010586947901174e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.7606829462456517e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.182908691698685e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.7676065908744931e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.3162105460651219e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00012558206799440086
mask_decoder.transformer.layers.1.norm3.weight grad: 4.903131048195064e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.709781908080913e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.63611455517821e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010942498192889616
mask_decoder.transformer.norm_final_attn.weight grad: 8.905453796614893e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.819525075727142e-06
Text_Embedding_Affine.0.weight grad: 7.536176543920803e-12
Text_Embedding_Affine.0.bias grad: 2.5725360730533e-10
Text_Embedding_Affine.2.weight grad: 2.4153366806611842e-11
Text_Embedding_Affine.2.bias grad: 8.442171747446992e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11224745959043503

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11224745959043503

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1128072738647461

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3259698748588562

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11229515075683594

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1128072738647461

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 66.2968521118164
Max value: 88.1741943359375
Mean value: 77.68095397949219

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11213769763708115

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11213769763708115

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11213769763708115

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3051968216896057

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6122561693191528
Max value: 20.197927474975586
Mean value: 1.0355297327041626

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 66.2968521118164
Max value: 88.1741943359375
Mean value: 77.68095397949219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -78.16241455078125
Max value: -78.16241455078125
Mean value: -78.16241455078125
sam_encoder.pos_embed grad: 8.228872583337932e-10
sam_encoder.blocks.0.norm1.weight grad: -1.7610178474569693e-05
sam_encoder.blocks.0.norm1.bias grad: 4.669958070735447e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.3471419151755981e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0979117348597356e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2772356058121659e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.021758736096672e-07
sam_encoder.blocks.0.norm2.weight grad: 1.6027119045247673e-06
sam_encoder.blocks.0.norm2.bias grad: 3.43437677656766e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.915517532324884e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.42046326345735e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.719591091386974e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.0565686276750057e-07
sam_encoder.blocks.1.norm1.weight grad: -8.631861419416964e-06
sam_encoder.blocks.1.norm1.bias grad: 1.6165286069735885e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.43679551203968e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.503568551532226e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.149466442029734e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.6997910279314965e-06
sam_encoder.blocks.1.norm2.weight grad: -5.462797616928583e-06
sam_encoder.blocks.1.norm2.bias grad: -5.574626811721828e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.789278813812416e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.334465307285427e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.765613195762853e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2845034689235035e-06
sam_encoder.blocks.2.norm1.weight grad: 8.225949386542197e-06
sam_encoder.blocks.2.norm1.bias grad: 3.708940766955493e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.729180323512992e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.2526652426458895e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.4322557123923616e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.0944739844708238e-06
sam_encoder.blocks.2.norm2.weight grad: -2.3259678982867626e-06
sam_encoder.blocks.2.norm2.bias grad: -7.498769264202565e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.012138227451942e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4998306596680777e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.3233102335070726e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.8046331408404512e-06
sam_encoder.blocks.3.norm1.weight grad: -7.5927637226413935e-06
sam_encoder.blocks.3.norm1.bias grad: 2.13065322896e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.6987448766012676e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.012438360703527e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.011855594399094e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.5335049283748958e-06
sam_encoder.blocks.3.norm2.weight grad: 2.7818991839012597e-06
sam_encoder.blocks.3.norm2.bias grad: 8.011550562514458e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.5942035815896816e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.219251531547343e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.71973658780189e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.881030109681888e-07
sam_encoder.blocks.4.norm1.weight grad: -1.1362206350895576e-05
sam_encoder.blocks.4.norm1.bias grad: 1.8185692169936374e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.600472028774675e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.4304372345795855e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.715439225336013e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5503619579249062e-06
sam_encoder.blocks.4.norm2.weight grad: -4.2066158130182885e-06
sam_encoder.blocks.4.norm2.bias grad: -4.810888640349731e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.486405825649854e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.0709148884634487e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.6959775166469626e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4354593069754173e-08
sam_encoder.blocks.5.norm1.weight grad: 1.5512350159951893e-07
sam_encoder.blocks.5.norm1.bias grad: 3.2536540857108776e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.2920691833405726e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.588828339066822e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.126099843735574e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.700937653178698e-07
sam_encoder.blocks.5.norm2.weight grad: 1.0681337698770221e-06
sam_encoder.blocks.5.norm2.bias grad: -1.8037929976344458e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.425396001461195e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.4902675477278535e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2070515822415473e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.6990113610736444e-07
sam_encoder.blocks.6.norm1.weight grad: 9.973366559279384e-07
sam_encoder.blocks.6.norm1.bias grad: -1.2283203432161827e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.517273737292271e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.786291351090767e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2429612752384855e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.644276820428786e-07
sam_encoder.blocks.6.norm2.weight grad: 7.072992048051674e-06
sam_encoder.blocks.6.norm2.bias grad: 9.65295612331829e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.157668056199327e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.6126972468555323e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.160790247922705e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.271671739137673e-07
sam_encoder.blocks.7.norm1.weight grad: -1.0038911568699405e-07
sam_encoder.blocks.7.norm1.bias grad: 1.195059212477645e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.2659854671001085e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.668273388437228e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.3266240368211584e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7750920733305975e-06
sam_encoder.blocks.7.norm2.weight grad: 4.238068868289702e-06
sam_encoder.blocks.7.norm2.bias grad: 9.481967566671301e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.55075247221248e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.5033978090505116e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.7127653109128005e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.1110071227449225e-06
sam_encoder.blocks.8.norm1.weight grad: -7.54786515244632e-06
sam_encoder.blocks.8.norm1.bias grad: 1.6234121176239569e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.087653557391604e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.2711619749316014e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -9.120830100073363e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.92185301684367e-07
sam_encoder.blocks.8.norm2.weight grad: 8.899691010810784e-07
sam_encoder.blocks.8.norm2.bias grad: -1.3629094155476196e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.790638345435582e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.227295301641789e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.448130255241267e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.6413241610280238e-07
sam_encoder.blocks.9.norm1.weight grad: -3.9003011806926224e-06
sam_encoder.blocks.9.norm1.bias grad: 3.7754315940219385e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.884730292862514e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.7067466728803993e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.1995154497744807e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2188266964585637e-06
sam_encoder.blocks.9.norm2.weight grad: 3.9464788414989016e-07
sam_encoder.blocks.9.norm2.bias grad: -8.244919058597588e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.1901458663032827e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.1793562748607656e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.315284389937005e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.855092126694217e-07
sam_encoder.blocks.10.norm1.weight grad: -1.7094174609155743e-06
sam_encoder.blocks.10.norm1.bias grad: -7.520627036683436e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.655683755710015e-08
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.141487235960085e-09
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.560942781812628e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.4609044519129384e-07
sam_encoder.blocks.10.norm2.weight grad: -2.791327005979838e-06
sam_encoder.blocks.10.norm2.bias grad: -2.075664724543458e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.7696479517326225e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1304331337669282e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.1193527572904713e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.240328952524578e-07
sam_encoder.blocks.11.norm1.weight grad: 5.630988653138047e-06
sam_encoder.blocks.11.norm1.bias grad: 1.6601240986346966e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.378035095622181e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.669547924000653e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.618340992441517e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.7151125670552574e-08
sam_encoder.blocks.11.norm2.weight grad: -8.371859621547628e-06
sam_encoder.blocks.11.norm2.bias grad: -2.099066477967426e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.5731169469290762e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.8015515479419264e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.419851853119326e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.094736472230579e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.6390490499325097e-08
sam_encoder.neck.conv1.trainable_shift grad: -3.067518991883844e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.669632395845838e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.8682236006716266e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00020227556524332613
mask_decoder.transformer.layers.0.norm1.bias grad: -1.703854650259018e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0028340660501271486
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002723168581724167
mask_decoder.transformer.layers.0.norm3.weight grad: -2.4551525712013245e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.9752980481134728e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.1356186051853e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.967346856370568e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 8.287281525554135e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.290188033133745e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.678125019883737e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010833103442564607
mask_decoder.transformer.layers.1.norm3.weight grad: 6.169066909933463e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.90294400556013e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.017608782509342e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.496254642726853e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.5315954442485236e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.811456968425773e-05
Text_Embedding_Affine.0.weight grad: -3.8672580762733055e-13
Text_Embedding_Affine.0.bias grad: 1.3958575961758868e-10
Text_Embedding_Affine.2.weight grad: 5.6341063758846843e-11
Text_Embedding_Affine.2.bias grad: 5.3114708862267435e-06
Epoch 6 finished with average loss: -69.4009
Epoch 7/39
----------
Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, loss=-70.4]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.03it/s, loss=-70.4]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.03it/s, loss=-68]  Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s, loss=-68]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s, loss=-66.4]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.16it/s, loss=-66.4]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09754800796508789

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09754800796508789

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09134149551391602

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2551388144493103

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09778165817260742

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09134149551391602

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 59.77372360229492
Max value: 81.5992660522461
Mean value: 70.38002014160156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09754800796508789

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09754800796508789

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09754800796508789

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2551388144493103

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 59.77372360229492
Max value: 81.5992660522461
Mean value: 70.38002014160156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.38031768798828
Max value: -70.38031768798828
Mean value: -70.38031768798828
sam_encoder.pos_embed grad: 1.040358199588809e-08
sam_encoder.blocks.0.norm1.weight grad: 1.325989251199644e-05
sam_encoder.blocks.0.norm1.bias grad: 1.2736287317238748e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.233555955579504e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8854568395454407e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.6325792557836394e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.664107902703108e-07
sam_encoder.blocks.0.norm2.weight grad: 4.060231276525883e-06
sam_encoder.blocks.0.norm2.bias grad: -2.3442575184162706e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.358831832476426e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.718063337350031e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.1154503226862289e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.411140697717201e-06
sam_encoder.blocks.1.norm1.weight grad: -9.090683306567371e-06
sam_encoder.blocks.1.norm1.bias grad: 6.895739261381095e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.192160834762035e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.7468023492692737e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.0553460015216842e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.62688853481086e-06
sam_encoder.blocks.1.norm2.weight grad: -6.654455773968948e-06
sam_encoder.blocks.1.norm2.bias grad: -3.894137989846058e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.3396403270890005e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.013206418880145e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.03175078847562e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.247725536923099e-07
sam_encoder.blocks.2.norm1.weight grad: -1.6317979316227138e-05
sam_encoder.blocks.2.norm1.bias grad: 3.883107183355605e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1345082384650595e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7946243815458729e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.699229172430933e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.863284630118869e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0044486771221273e-05
sam_encoder.blocks.2.norm2.bias grad: 1.9043520751438336e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.746097591938451e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.024715053674299e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.113989573146682e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.822291081538424e-07
sam_encoder.blocks.3.norm1.weight grad: 1.6870201307028765e-06
sam_encoder.blocks.3.norm1.bias grad: -5.983251867291983e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.1271190487605054e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.896476006408193e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.72094075626228e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.5180992249952396e-06
sam_encoder.blocks.3.norm2.weight grad: -1.5626986851202673e-06
sam_encoder.blocks.3.norm2.bias grad: -3.4033189422189025e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.839729626837652e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.6189276215736754e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.609952844068175e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.447643616207642e-07
sam_encoder.blocks.4.norm1.weight grad: -4.272642854630249e-06
sam_encoder.blocks.4.norm1.bias grad: -1.197640085592866e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.0437194002151955e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.679212442075368e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.991123321611667e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2189690323793911e-06
sam_encoder.blocks.4.norm2.weight grad: 1.0751834452094045e-05
sam_encoder.blocks.4.norm2.bias grad: 1.2820509255107027e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.5288757064554375e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.383493668072333e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.273556222258776e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.903763570178853e-07
sam_encoder.blocks.5.norm1.weight grad: -5.228731879469706e-06
sam_encoder.blocks.5.norm1.bias grad: -1.6503001461387612e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.675062549111317e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.805740112104104e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.644979758770205e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.901024228980532e-06
sam_encoder.blocks.5.norm2.weight grad: 8.932235687098e-06
sam_encoder.blocks.5.norm2.bias grad: 3.287305389676476e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.104297088109888e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.8043199361272855e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4161166745907394e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.334120250059641e-07
sam_encoder.blocks.6.norm1.weight grad: -8.970734597824048e-06
sam_encoder.blocks.6.norm1.bias grad: -2.5963752250390826e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.526795914396644e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.2543943032360403e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.178319047947298e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.347544523217948e-06
sam_encoder.blocks.6.norm2.weight grad: -2.8112917789258063e-06
sam_encoder.blocks.6.norm2.bias grad: -4.2536339606158435e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.392254820435483e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.932318789651617e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.154556568711996e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.561955956385646e-07
sam_encoder.blocks.7.norm1.weight grad: -6.198617484187707e-06
sam_encoder.blocks.7.norm1.bias grad: 1.198684003611561e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.511088602361269e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.4501596271875314e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.30937394007924e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1534727661910438e-07
sam_encoder.blocks.7.norm2.weight grad: -2.1263604139676318e-06
sam_encoder.blocks.7.norm2.bias grad: -4.846132014790783e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.119044999446487e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.652296289961669e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.279907048181485e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.851558621041477e-07
sam_encoder.blocks.8.norm1.weight grad: 1.037500987877138e-05
sam_encoder.blocks.8.norm1.bias grad: 1.9886865629814565e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2463417078834027e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.3770617089176085e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.542365559245809e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.66839628895832e-07
sam_encoder.blocks.8.norm2.weight grad: -1.6675397773724399e-06
sam_encoder.blocks.8.norm2.bias grad: 3.054083208553493e-09
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.337350557965692e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.8511183245427674e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.9551864599852706e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.404048005810182e-07
sam_encoder.blocks.9.norm1.weight grad: -4.653472387872171e-06
sam_encoder.blocks.9.norm1.bias grad: -1.4244509429772734e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.339562226756243e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.972950258277706e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.8269929569214582e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.2174833702592878e-06
sam_encoder.blocks.9.norm2.weight grad: -1.0970179573632777e-05
sam_encoder.blocks.9.norm2.bias grad: -2.761883933999343e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.0843271411431488e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.4258625823422335e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.0991818675829563e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.1662468750728294e-06
sam_encoder.blocks.10.norm1.weight grad: -4.663869276555488e-06
sam_encoder.blocks.10.norm1.bias grad: -3.0706003144587157e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.278190322613227e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.6340263755409978e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.0722262686613249e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.8328070672832837e-07
sam_encoder.blocks.10.norm2.weight grad: -1.659586632740684e-05
sam_encoder.blocks.10.norm2.bias grad: -3.726116119651124e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.0177769581787288e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.740095275541535e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.8321053378022043e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.3927028703619726e-06
sam_encoder.blocks.11.norm1.weight grad: -1.8663875380298123e-05
sam_encoder.blocks.11.norm1.bias grad: 1.2498246633185772e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0440353435114957e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.364289669771097e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.706943728815531e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.963396342347551e-07
sam_encoder.blocks.11.norm2.weight grad: -1.6003668861230835e-05
sam_encoder.blocks.11.norm2.bias grad: -5.7235338317696005e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.827482477296144e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.4166885143349646e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2279892871447373e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.915659760878043e-07
sam_encoder.neck.conv1.trainable_scale grad: -9.199284249916673e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.48510111507494e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.003697202075273e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.7071629776619375e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010420879698358476
mask_decoder.transformer.layers.0.norm1.bias grad: 9.52926347963512e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0035317386500537395
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00012285483535379171
mask_decoder.transformer.layers.0.norm3.weight grad: 7.271263893926516e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -7.3743576649576426e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -5.661389513988979e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.876995707396418e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 1.5702593373134732e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.274378054309636e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0003608479455579072
mask_decoder.transformer.layers.1.norm2.bias grad: 8.673168485984206e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.188038994674571e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.752867218689062e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00019749451894313097
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00015539396554231644
mask_decoder.transformer.norm_final_attn.weight grad: 1.0761133125924971e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.4853933256235905e-06
Text_Embedding_Affine.0.weight grad: -1.6770181163888731e-12
Text_Embedding_Affine.0.bias grad: 1.8944623647598746e-11
Text_Embedding_Affine.2.weight grad: 1.3054404779389017e-10
Text_Embedding_Affine.2.bias grad: -3.083290721406229e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07141293585300446

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07141293585300446

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07638835906982422

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2095501720905304

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07083463668823242

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07638835906982422

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.65329360961914
Max value: 89.18492126464844
Mean value: 65.34786987304688

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07069811224937439

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07069811224937439

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07069811224937439

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20125213265419006

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.753014087677002
Max value: 4.999995231628418
Mean value: 1.0108455419540405

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.65329360961914
Max value: 89.18492126464844
Mean value: 65.34786987304688

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.64434051513672
Max value: -65.64434051513672
Mean value: -65.64434051513672
sam_encoder.pos_embed grad: 4.604465246582645e-12
sam_encoder.blocks.0.norm1.weight grad: 6.529751317430055e-06
sam_encoder.blocks.0.norm1.bias grad: 1.3212224075687118e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.6263202269328758e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.154898647357186e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.7007546325185103e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.68733946440625e-07
sam_encoder.blocks.0.norm2.weight grad: 8.544109732611105e-06
sam_encoder.blocks.0.norm2.bias grad: -4.231938419252401e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.647739721505786e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.8550118713610573e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.2485541446949355e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.224344807989837e-07
sam_encoder.blocks.1.norm1.weight grad: 3.0545473350684915e-07
sam_encoder.blocks.1.norm1.bias grad: 6.123574621597072e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.5205638343759347e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.772653087708022e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.306231731898151e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.576746838822146e-07
sam_encoder.blocks.1.norm2.weight grad: 2.4933651729952544e-06
sam_encoder.blocks.1.norm2.bias grad: -3.140220997011056e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.4840928745106794e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7167573673759762e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.6125511542195454e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.923889148107264e-07
sam_encoder.blocks.2.norm1.weight grad: 7.257227480295114e-06
sam_encoder.blocks.2.norm1.bias grad: -9.442401278647594e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.7524996514548548e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.1470693834780832e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5618495297076151e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.7735458374422706e-08
sam_encoder.blocks.2.norm2.weight grad: -1.5939589275149046e-06
sam_encoder.blocks.2.norm2.bias grad: -4.597468432621099e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.735110330031603e-08
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.589924967352999e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7120502181787742e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0244870054521016e-06
sam_encoder.blocks.3.norm1.weight grad: -1.6765086456871359e-06
sam_encoder.blocks.3.norm1.bias grad: -3.536383701430168e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.2499216356663965e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.570108333406097e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.659532586018031e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.7933486990150413e-07
sam_encoder.blocks.3.norm2.weight grad: 5.7647685025585815e-06
sam_encoder.blocks.3.norm2.bias grad: 9.336874427390285e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.875951162830461e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.936621856657439e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.274900326592615e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.462332642811816e-07
sam_encoder.blocks.4.norm1.weight grad: -4.4753805923392065e-06
sam_encoder.blocks.4.norm1.bias grad: 1.2814359706680989e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.571165052562719e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1765805538743734e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.443594540745835e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.913603675049671e-07
sam_encoder.blocks.4.norm2.weight grad: -1.5022778825368732e-05
sam_encoder.blocks.4.norm2.bias grad: -5.472923476190772e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0289602869306691e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.1361787478090264e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.5529151369264582e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.2892905942862853e-06
sam_encoder.blocks.5.norm1.weight grad: -6.366100478771841e-06
sam_encoder.blocks.5.norm1.bias grad: -1.516559905212489e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.010222255601548e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.1391537100280402e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.6882133852268453e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.3152914561942453e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1837357305921614e-05
sam_encoder.blocks.5.norm2.bias grad: -1.8502795455788146e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.657489509758307e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.032496240644832e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.367122189956717e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.971004159415315e-07
sam_encoder.blocks.6.norm1.weight grad: 5.346727220967296e-07
sam_encoder.blocks.6.norm1.bias grad: 2.286154995090328e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.0652080106865469e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.6638240291940747e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.20390482658695e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.00435779271902e-08
sam_encoder.blocks.6.norm2.weight grad: -4.020409505756106e-06
sam_encoder.blocks.6.norm2.bias grad: 1.9068420442636125e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.2530539379440597e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.807383220395423e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.3319998376791773e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1092023299852372e-07
sam_encoder.blocks.7.norm1.weight grad: 1.632424186936987e-06
sam_encoder.blocks.7.norm1.bias grad: 1.62766127687064e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.3217277228250168e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.521195470872044e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.1947698794756434e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.019106647021545e-07
sam_encoder.blocks.7.norm2.weight grad: 1.0757469226518879e-07
sam_encoder.blocks.7.norm2.bias grad: 1.4664009313491988e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.820036968387285e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.610530944162747e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.7208315006864723e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.1499009739709436e-07
sam_encoder.blocks.8.norm1.weight grad: 3.24790471495362e-06
sam_encoder.blocks.8.norm1.bias grad: 9.127349471782509e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.759624865371734e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.732986659902963e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.4061549791222205e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.760380712312326e-07
sam_encoder.blocks.8.norm2.weight grad: -1.3845683497493155e-06
sam_encoder.blocks.8.norm2.bias grad: -7.754865691822488e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.717594043133431e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.941829618270276e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.6699365801287058e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.6765222805333906e-08
sam_encoder.blocks.9.norm1.weight grad: -1.3786288945993874e-06
sam_encoder.blocks.9.norm1.bias grad: -3.966134087818318e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.1275024007773027e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.5160915956566896e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.397439402557211e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.38120308546786e-07
sam_encoder.blocks.9.norm2.weight grad: -1.6645515188429272e-06
sam_encoder.blocks.9.norm2.bias grad: -1.6266116062979563e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.308285473873184e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.337535746250069e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5351399440532987e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.9894644626438094e-07
sam_encoder.blocks.10.norm1.weight grad: 2.54159931500908e-06
sam_encoder.blocks.10.norm1.bias grad: -7.886188768679858e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0316008431109367e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.656078994637937e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1058912150474498e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.410487109562382e-07
sam_encoder.blocks.10.norm2.weight grad: -4.837027972826036e-06
sam_encoder.blocks.10.norm2.bias grad: -3.200802439096151e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.1777104873544886e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.6757799130573403e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.977053423426696e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.168926691112574e-07
sam_encoder.blocks.11.norm1.weight grad: 2.2021308723196853e-06
sam_encoder.blocks.11.norm1.bias grad: 1.3231223761067668e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.695903044193983e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.048233108733257e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.710395273832546e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2884656541700679e-07
sam_encoder.blocks.11.norm2.weight grad: -3.101168431385304e-06
sam_encoder.blocks.11.norm2.bias grad: -2.4047287752182456e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.4087391870561987e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -9.89635168480163e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0914682206930593e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.3879407485292177e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.255769792711362e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2664658243011218e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.604661055258475e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.9756114852498285e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014692629338242114
mask_decoder.transformer.layers.0.norm1.bias grad: -3.084933268837631e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003973335027694702
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003223163657821715
mask_decoder.transformer.layers.0.norm3.weight grad: -4.457666364032775e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.4239692215342075e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.405283809523098e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.9528625822858885e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.233066960703582e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.850465196184814e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 5.6127777497749776e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00014352517609950155
mask_decoder.transformer.layers.1.norm3.weight grad: 6.556727748829871e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.114163599908352e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.888375092879869e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011355720926076174
mask_decoder.transformer.norm_final_attn.weight grad: 8.942155545810238e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.310973837273195e-06
Text_Embedding_Affine.0.weight grad: 3.072899140005303e-12
Text_Embedding_Affine.0.bias grad: 2.3476590116366935e-10
Text_Embedding_Affine.2.weight grad: 7.314841787842141e-11
Text_Embedding_Affine.2.bias grad: 3.3962878660531715e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07650194317102432

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07650194317102432

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08344268798828125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.24622058868408203

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07616138458251953

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08344268798828125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 58.42317581176758
Max value: 67.46636962890625
Mean value: 62.93538284301758

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.458399004759791e-39
Max value: 1.0
Mean value: 0.07503752410411835

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.458399004759791e-39
Max value: 1.0
Mean value: 0.07503752410411835

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.458399004759791e-39
Max value: 1.0
Mean value: 0.07503752410411835

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2245086133480072

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7126296162605286
Max value: 17.654417037963867
Mean value: 1.0435969829559326

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 58.42317581176758
Max value: 67.46636962890625
Mean value: 62.93538284301758

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.27843475341797
Max value: -63.27843475341797
Mean value: -63.27843475341797
sam_encoder.pos_embed grad: -9.92527304788382e-09
sam_encoder.blocks.0.norm1.weight grad: 7.202936103567481e-06
sam_encoder.blocks.0.norm1.bias grad: 4.7851528506726027e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.506219738686923e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.153898197107765e-09
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.287322094067349e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.935250276754232e-07
sam_encoder.blocks.0.norm2.weight grad: 6.211262189026456e-06
sam_encoder.blocks.0.norm2.bias grad: 4.4326290662866086e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.4501564692182e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.35862091560557e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.1215921151451766e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.108074325718917e-06
sam_encoder.blocks.1.norm1.weight grad: -8.001154128578492e-06
sam_encoder.blocks.1.norm1.bias grad: -2.5971537525038e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.559090252267197e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.937396973517025e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.368599547888152e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.974256974790478e-06
sam_encoder.blocks.1.norm2.weight grad: 1.3179999768908601e-05
sam_encoder.blocks.1.norm2.bias grad: -7.080689101712778e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.766361821064493e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.1198391095822444e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.805551270692376e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.84631731423724e-07
sam_encoder.blocks.2.norm1.weight grad: -1.2035258805553894e-05
sam_encoder.blocks.2.norm1.bias grad: -6.622602086281404e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.6082367336784955e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.6312012576236157e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.5602849897695705e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.1550389394396916e-06
sam_encoder.blocks.2.norm2.weight grad: -6.802074494771659e-06
sam_encoder.blocks.2.norm2.bias grad: -8.690871254657395e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.199864633847028e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.9895754778408445e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.4348140616202727e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.745337006146656e-08
sam_encoder.blocks.3.norm1.weight grad: 3.7274198803061154e-06
sam_encoder.blocks.3.norm1.bias grad: -9.302146281697787e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.2080209873820422e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.266232795340329e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.042796495516086e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.0003070656239288e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0196547918894794e-05
sam_encoder.blocks.3.norm2.bias grad: -2.9011348487983923e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.605401722481474e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2956166958465474e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.2946604733297136e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.873174930253299e-07
sam_encoder.blocks.4.norm1.weight grad: 1.3916649550083093e-05
sam_encoder.blocks.4.norm1.bias grad: 2.0458373910514638e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.615549642039696e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.6007070864106936e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.354551037977217e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.9691543659282615e-06
sam_encoder.blocks.4.norm2.weight grad: -3.415461833355948e-05
sam_encoder.blocks.4.norm2.bias grad: -2.9004178941249847e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.4007114916457795e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.861064998200163e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.849454515147954e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.958403784869006e-07
sam_encoder.blocks.5.norm1.weight grad: 8.449733286397532e-06
sam_encoder.blocks.5.norm1.bias grad: -2.3262350623554084e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.320865627960302e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.3365616641513043e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.693867140304064e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.9955006084492197e-06
sam_encoder.blocks.5.norm2.weight grad: -1.255632651009364e-05
sam_encoder.blocks.5.norm2.bias grad: -1.7722381016938016e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.4967291614739224e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.76716057973681e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8527252905187197e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.17534863572655e-07
sam_encoder.blocks.6.norm1.weight grad: 9.520035177956743e-07
sam_encoder.blocks.6.norm1.bias grad: 2.914089691330446e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.955439413199201e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.9613027524865174e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.5944433471304365e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.719334813467867e-07
sam_encoder.blocks.6.norm2.weight grad: -1.40546342208836e-06
sam_encoder.blocks.6.norm2.bias grad: -1.6179477597688674e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.8279424693901092e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.943274459241366e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.617927846898965e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0871463018702343e-07
sam_encoder.blocks.7.norm1.weight grad: -9.541175671756719e-08
sam_encoder.blocks.7.norm1.bias grad: 1.3043576245763688e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.986122922266077e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.393601771989779e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.329898383228283e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.4803214273561025e-06
sam_encoder.blocks.7.norm2.weight grad: 1.1911884939763695e-05
sam_encoder.blocks.7.norm2.bias grad: 1.3299321608428727e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 8.50537162477849e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.633657459227834e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.1309061537522211e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.402932241489907e-07
sam_encoder.blocks.8.norm1.weight grad: 1.1390503686925513e-06
sam_encoder.blocks.8.norm1.bias grad: -2.463839336996898e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.482068677840289e-08
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.671504487101629e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9301343147380976e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.7215735372010386e-06
sam_encoder.blocks.8.norm2.weight grad: 9.723311222842312e-07
sam_encoder.blocks.8.norm2.bias grad: -4.6992295210657176e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.1947532502508693e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.6847138201446796e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.5206691159619368e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.3119781669956865e-06
sam_encoder.blocks.9.norm1.weight grad: 7.37179902898788e-07
sam_encoder.blocks.9.norm1.bias grad: 7.553960017503414e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.7266834712900163e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.0706696684792405e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.157560043604462e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.599708169436781e-07
sam_encoder.blocks.9.norm2.weight grad: 4.460963737074053e-06
sam_encoder.blocks.9.norm2.bias grad: 6.659502105321735e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.668247816473013e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.821180017548613e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.86093017066014e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.668584428050963e-07
sam_encoder.blocks.10.norm1.weight grad: 7.896671377238818e-06
sam_encoder.blocks.10.norm1.bias grad: 1.217910948980716e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.946160970575875e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.7719443121677614e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.5262452254537493e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1432074416006799e-06
sam_encoder.blocks.10.norm2.weight grad: 3.9514170566690154e-06
sam_encoder.blocks.10.norm2.bias grad: -1.1883672641488374e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.037906364828814e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.0436592674523126e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.010868780023884e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.835496613646683e-07
sam_encoder.blocks.11.norm1.weight grad: 2.5034099962795153e-05
sam_encoder.blocks.11.norm1.bias grad: 3.1837257097322436e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.8520559024182148e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.650585646639229e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.491260486043757e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.671611244091764e-06
sam_encoder.blocks.11.norm2.weight grad: 3.1417889658769127e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2967964266863419e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.643782631319482e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.346227448579157e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.8427593886372051e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.525780342301005e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.2608113542664796e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.764745502441656e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.2155360309407115e-06
sam_encoder.neck.conv2.trainable_shift grad: 5.776598845841363e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00021401533740572631
mask_decoder.transformer.layers.0.norm1.bias grad: -4.79539085063152e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003135581035166979
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005932279163971543
mask_decoder.transformer.layers.0.norm3.weight grad: -6.534685962833464e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.2967207769397646e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011609942885115743
mask_decoder.transformer.layers.0.norm4.bias grad: 3.4594631870277226e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 3.1811941880732775e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 7.414055289700627e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00014249567175284028
mask_decoder.transformer.layers.1.norm2.bias grad: -5.3501862566918135e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.6240442568669096e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.553700894874055e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.75296656077262e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001541139354230836
mask_decoder.transformer.norm_final_attn.weight grad: 1.4430846931645647e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.1429499611258507e-05
Text_Embedding_Affine.0.weight grad: 4.154075521067835e-12
Text_Embedding_Affine.0.bias grad: 2.3201966736774438e-10
Text_Embedding_Affine.2.weight grad: 1.4176765317230888e-10
Text_Embedding_Affine.2.bias grad: 3.078013833146542e-05
Epoch 7 finished with average loss: -66.4344
Epoch 8/39
----------
Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, loss=-65.9]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-65.9]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-65.6]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-65.6]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-66.6]Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.30it/s, loss=-66.6]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08490344136953354

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08490344136953354

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08522987365722656

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19275611639022827

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08406257629394531

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08522987365722656

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 34.623043060302734
Max value: 88.17190551757812
Mean value: 65.88555908203125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08490344136953354

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08490344136953354

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08490344136953354

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19275611639022827

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 34.623043060302734
Max value: 88.17190551757812
Mean value: 65.88555908203125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.88599395751953
Max value: -65.88599395751953
Mean value: -65.88599395751953
sam_encoder.pos_embed grad: -6.8422223442610175e-09
sam_encoder.blocks.0.norm1.weight grad: 8.800001523923129e-05
sam_encoder.blocks.0.norm1.bias grad: 2.1973928596707992e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.307674993877299e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.3445089734887006e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.455052920908201e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.6390166592827882e-06
sam_encoder.blocks.0.norm2.weight grad: 1.3112929991621058e-05
sam_encoder.blocks.0.norm2.bias grad: 7.003988002907136e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.544113032054156e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.019648597226478e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.256711119727697e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.749187034278293e-07
sam_encoder.blocks.1.norm1.weight grad: 1.0870019195863279e-06
sam_encoder.blocks.1.norm1.bias grad: -1.6574598475926905e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.106626528890047e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1634989505182602e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.356915148193366e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.972948878887109e-07
sam_encoder.blocks.1.norm2.weight grad: 1.3926775864092633e-05
sam_encoder.blocks.1.norm2.bias grad: -9.655411759013077e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.734435492537159e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.3429413431586e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.921695679309778e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.8917016859631985e-06
sam_encoder.blocks.2.norm1.weight grad: -1.1743107279471587e-05
sam_encoder.blocks.2.norm1.bias grad: -7.845705113140866e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.033689144009259e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4888917121425038e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.81881566985976e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.385252163454425e-06
sam_encoder.blocks.2.norm2.weight grad: 1.5247739781898417e-07
sam_encoder.blocks.2.norm2.bias grad: -9.607442734704819e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.838263513804122e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.721682790252089e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.1236777431331575e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.126559466996696e-07
sam_encoder.blocks.3.norm1.weight grad: 1.3016916454944294e-05
sam_encoder.blocks.3.norm1.bias grad: -5.856976258655777e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4071474652155302e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 9.633572517486755e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.7310032894311007e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.4242799554485828e-06
sam_encoder.blocks.3.norm2.weight grad: 5.668223366228631e-06
sam_encoder.blocks.3.norm2.bias grad: -1.77389938471606e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.7267110453976784e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.206977344736515e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.645028406637721e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5107048056961503e-06
sam_encoder.blocks.4.norm1.weight grad: 1.554779737489298e-05
sam_encoder.blocks.4.norm1.bias grad: -9.046059858519584e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.228366717346944e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.880469183874084e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4636368632636731e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.48578226344398e-06
sam_encoder.blocks.4.norm2.weight grad: -4.008455289294943e-05
sam_encoder.blocks.4.norm2.bias grad: -1.8076534615829587e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.7164016501046717e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.95360369415721e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.806969400306116e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.465930025318812e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4825935068074614e-05
sam_encoder.blocks.5.norm1.bias grad: -1.2193973816465586e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.656382083747303e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.4751771004739567e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.150834105435933e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 9.36762432957039e-07
sam_encoder.blocks.5.norm2.weight grad: -1.1710558283084538e-05
sam_encoder.blocks.5.norm2.bias grad: -1.3267474969325121e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.268952008918859e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.1507446490431903e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4122427955953754e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.0780063891834288e-07
sam_encoder.blocks.6.norm1.weight grad: 8.49752268550219e-06
sam_encoder.blocks.6.norm1.bias grad: 5.327492544893175e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.179893832973903e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5418920611409703e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.0279758271281025e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.497819751733914e-07
sam_encoder.blocks.6.norm2.weight grad: -6.519015641970327e-06
sam_encoder.blocks.6.norm2.bias grad: -2.4930727704486344e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.572166512341937e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.719363237702055e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.9697823694950785e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.068590442329878e-07
sam_encoder.blocks.7.norm1.weight grad: 3.227449724363396e-06
sam_encoder.blocks.7.norm1.bias grad: -3.897991973644821e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.739817652283818e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.237172721692332e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.598006277476088e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.031973036144336e-07
sam_encoder.blocks.7.norm2.weight grad: -2.3346890429820633e-06
sam_encoder.blocks.7.norm2.bias grad: 1.16123908355803e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.4984049079866963e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1826580248452956e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.0010551199666224e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.1030111813379335e-07
sam_encoder.blocks.8.norm1.weight grad: 5.650061211781576e-06
sam_encoder.blocks.8.norm1.bias grad: -4.507101948547643e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.931207174900919e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.0570138329057954e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.4725214820573456e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.8964686887557036e-06
sam_encoder.blocks.8.norm2.weight grad: -4.342729880590923e-06
sam_encoder.blocks.8.norm2.bias grad: -1.8083669601764996e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.435914095462067e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.2803415074813529e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8771293071040418e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.088453700504033e-06
sam_encoder.blocks.9.norm1.weight grad: 2.5753586214705138e-06
sam_encoder.blocks.9.norm1.bias grad: 5.558082420975552e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.0590218835204723e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.536924910145899e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.816840947161836e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.2047878499288345e-06
sam_encoder.blocks.9.norm2.weight grad: -6.863277803859091e-07
sam_encoder.blocks.9.norm2.bias grad: -1.4931296732356714e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.613125490024686e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.558102884606342e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.431822268699761e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.991748335849479e-08
sam_encoder.blocks.10.norm1.weight grad: 5.09141682414338e-06
sam_encoder.blocks.10.norm1.bias grad: 2.1142561763554113e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.6326107470376883e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.647443342444603e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.929765620749095e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.521068022877444e-08
sam_encoder.blocks.10.norm2.weight grad: 7.429956895066425e-06
sam_encoder.blocks.10.norm2.bias grad: 1.92143534150091e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.8351612400001613e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.0406848761922447e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.611180664440326e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.0769441511656623e-07
sam_encoder.blocks.11.norm1.weight grad: 9.083262739295606e-06
sam_encoder.blocks.11.norm1.bias grad: 1.914442236738978e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.6407802831963636e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.047134645659753e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.6214453302818583e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.3416750966352993e-07
sam_encoder.blocks.11.norm2.weight grad: 5.992178103042534e-06
sam_encoder.blocks.11.norm2.bias grad: 9.251245387531526e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.9205613170925062e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.3439266695058905e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.2070722732460126e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.287927796691292e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.6220383258769289e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.6804037841211539e-06
sam_encoder.neck.conv2.trainable_scale grad: -2.2196400095708668e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.333325705374591e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010426990775158629
mask_decoder.transformer.layers.0.norm1.bias grad: -1.4947145245969296e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0029042495880275965
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00019568303832784295
mask_decoder.transformer.layers.0.norm3.weight grad: -3.725061833392829e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.6923487388994545e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.668551991926506e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.962826435279567e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -5.568006235989742e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.143360224086791e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0003197873884346336
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00021639921760652214
mask_decoder.transformer.layers.1.norm3.weight grad: -5.1977378461742774e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -8.580578287364915e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 8.240698662120849e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -4.913021984975785e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.6522524219908519e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.660068826633506e-06
Text_Embedding_Affine.0.weight grad: 1.192906884384115e-12
Text_Embedding_Affine.0.bias grad: 1.1989652326516165e-10
Text_Embedding_Affine.2.weight grad: 1.05740017436462e-11
Text_Embedding_Affine.2.bias grad: -2.2858839656692e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07933996617794037

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07933996617794037

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08318138122558594

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2178744375705719

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07894659042358398

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08318138122558594

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 58.921138763427734
Max value: 78.41374206542969
Mean value: 64.90899658203125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07934855669736862

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07934855669736862

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07934855669736862

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20949497818946838

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8112611174583435
Max value: 4.8899078369140625
Mean value: 1.0110511779785156

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 58.921138763427734
Max value: 78.41374206542969
Mean value: 64.90899658203125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.21633911132812
Max value: -65.21633911132812
Mean value: -65.21633911132812
sam_encoder.pos_embed grad: -1.8646717503401078e-09
sam_encoder.blocks.0.norm1.weight grad: -1.9556064216885716e-05
sam_encoder.blocks.0.norm1.bias grad: 5.803919975733152e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.3818777208362008e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.913301955231873e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.0578235531966129e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.003516783588566e-07
sam_encoder.blocks.0.norm2.weight grad: 2.508507895981893e-05
sam_encoder.blocks.0.norm2.bias grad: 5.326777454683906e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.192622898495756e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.7393313100910746e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.994663181103533e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.0587370979919797e-06
sam_encoder.blocks.1.norm1.weight grad: -2.9918200539214013e-07
sam_encoder.blocks.1.norm1.bias grad: 2.055309323623078e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.0372094720878522e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.864816211622383e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.239626261754893e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.330146990445428e-08
sam_encoder.blocks.1.norm2.weight grad: 3.312230091978563e-06
sam_encoder.blocks.1.norm2.bias grad: -2.8201866371091455e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.6600455385050736e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.403288696470554e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.424828042217996e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.9221374120425025e-07
sam_encoder.blocks.2.norm1.weight grad: 3.520827249303693e-06
sam_encoder.blocks.2.norm1.bias grad: -1.586135795150767e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.2210695078683784e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.0367233471697546e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2066475392202847e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.538531754860742e-07
sam_encoder.blocks.2.norm2.weight grad: -1.804926569093368e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2369850992399734e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0768284255391336e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.959286788012832e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.852096809481736e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.939659442650736e-07
sam_encoder.blocks.3.norm1.weight grad: -2.338545073143905e-07
sam_encoder.blocks.3.norm1.bias grad: -4.699142664321698e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.7973965213968768e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1304246072540991e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.4964688261898118e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.8049515183047333e-07
sam_encoder.blocks.3.norm2.weight grad: 1.4687947214042651e-06
sam_encoder.blocks.3.norm2.bias grad: 6.095209300838178e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.099868197547039e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 7.673901905036473e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.105188958827057e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7364168769518074e-08
sam_encoder.blocks.4.norm1.weight grad: -1.343812527920818e-06
sam_encoder.blocks.4.norm1.bias grad: 1.385729206049291e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.492261617386248e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.935398756813811e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.541578952441341e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.194335482068709e-06
sam_encoder.blocks.4.norm2.weight grad: -1.013526434689993e-05
sam_encoder.blocks.4.norm2.bias grad: -6.720663805026561e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.860830919526052e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.7068269901064923e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.9710238297629985e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.411943106992112e-07
sam_encoder.blocks.5.norm1.weight grad: -8.4038047134527e-06
sam_encoder.blocks.5.norm1.bias grad: -1.919180704135215e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.131590907898499e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.8676162198971724e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.309454257305333e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.96987364992674e-07
sam_encoder.blocks.5.norm2.weight grad: -7.466856004612055e-06
sam_encoder.blocks.5.norm2.bias grad: -3.232500603189692e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.9426906874286942e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.576694318027876e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -4.194572511551087e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.42068335107615e-07
sam_encoder.blocks.6.norm1.weight grad: -2.6968464226229116e-06
sam_encoder.blocks.6.norm1.bias grad: 1.7748559457686497e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.084861762341461e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.258328893527505e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.676360276789637e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.877732516841206e-07
sam_encoder.blocks.6.norm2.weight grad: -1.7752148551153368e-06
sam_encoder.blocks.6.norm2.bias grad: -1.9502128623116732e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.5177313268141006e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.1804631583345326e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.887203317593958e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1482151052177869e-07
sam_encoder.blocks.7.norm1.weight grad: -8.386493277612317e-07
sam_encoder.blocks.7.norm1.bias grad: 1.1114966582681518e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.258843884803355e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.328848994347936e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.5387717528246867e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.4938553931642673e-06
sam_encoder.blocks.7.norm2.weight grad: 4.162153800280066e-06
sam_encoder.blocks.7.norm2.bias grad: 3.700526463035203e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.9749141958745895e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.5122153627089574e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.024868071108358e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.012011795064609e-07
sam_encoder.blocks.8.norm1.weight grad: -6.174784630275099e-07
sam_encoder.blocks.8.norm1.bias grad: -2.7197620511287823e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.050150331138866e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.058464236957661e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.6278312386930338e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 7.976804567988438e-07
sam_encoder.blocks.8.norm2.weight grad: 6.707821285090176e-07
sam_encoder.blocks.8.norm2.bias grad: -4.027940576634137e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 8.549048970962758e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.7500925625645323e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.4298568607482594e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.670356818474829e-07
sam_encoder.blocks.9.norm1.weight grad: -1.4712431948282756e-06
sam_encoder.blocks.9.norm1.bias grad: 1.8219722619505774e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.479960567659873e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.027618961619737e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.6912191464798525e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0953403943858575e-06
sam_encoder.blocks.9.norm2.weight grad: 6.891042403367464e-07
sam_encoder.blocks.9.norm2.bias grad: -1.066265099325392e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0906203442573315e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.213021374103846e-09
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.654785582009936e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.906557364847686e-07
sam_encoder.blocks.10.norm1.weight grad: 1.7148652204923565e-06
sam_encoder.blocks.10.norm1.bias grad: -7.084849471539201e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.7198439081766992e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.879731475033623e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0576480917734443e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.980198463679699e-07
sam_encoder.blocks.10.norm2.weight grad: -1.6993388953778776e-06
sam_encoder.blocks.10.norm2.bias grad: -1.954876097443048e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.840119795015198e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.504420753117302e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0803676104842452e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.621367679646937e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0273793122905772e-05
sam_encoder.blocks.11.norm1.bias grad: -8.245698950304359e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.6869546470843488e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.284459803078789e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3119670256855898e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.55511371405737e-07
sam_encoder.blocks.11.norm2.weight grad: -5.745099542764365e-07
sam_encoder.blocks.11.norm2.bias grad: -6.171039785840549e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.3506889899872476e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.0873132434171566e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.273478574148612e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.052708959534357e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.3524262360297143e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1665419151540846e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.44432327337563e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.882576467934996e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017361565551254898
mask_decoder.transformer.layers.0.norm1.bias grad: -1.1258016456849873e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004090315196663141
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0004272772930562496
mask_decoder.transformer.layers.0.norm3.weight grad: -5.260001489659771e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.640169986989349e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.465631304308772e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.464858986670151e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.29778262716718e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.179049473255873e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 3.67377360817045e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010147110151592642
mask_decoder.transformer.layers.1.norm3.weight grad: 5.233435149420984e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.497693928191438e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.4534121874021366e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00012370399781502783
mask_decoder.transformer.norm_final_attn.weight grad: 7.703692062932532e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0513890629226808e-05
Text_Embedding_Affine.0.weight grad: 4.4782649810670705e-12
Text_Embedding_Affine.0.bias grad: 1.2066445065350706e-10
Text_Embedding_Affine.2.weight grad: 9.68465238559979e-11
Text_Embedding_Affine.2.bias grad: 2.143233359674923e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07904819399118423

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07904819399118423

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08204364776611328

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.23732736706733704

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0788259506225586

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08204364776611328

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 61.771480560302734
Max value: 78.4261245727539
Mean value: 68.47274017333984

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07807071506977081

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07807071506977081

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07807071506977081

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.21976834535598755

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7535661458969116
Max value: 17.008068084716797
Mean value: 1.0311248302459717

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 61.771480560302734
Max value: 78.4261245727539
Mean value: 68.47274017333984

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.83450317382812
Max value: -68.83450317382812
Mean value: -68.83450317382812
sam_encoder.pos_embed grad: 7.2534875883434324e-09
sam_encoder.blocks.0.norm1.weight grad: -3.886589183821343e-06
sam_encoder.blocks.0.norm1.bias grad: 2.5076788006117567e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.314898660595645e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.314699258931796e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.4157466214091983e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.460655180897447e-07
sam_encoder.blocks.0.norm2.weight grad: 1.4495057257590815e-05
sam_encoder.blocks.0.norm2.bias grad: 3.194187911503832e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.902706784079783e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.55935878562741e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.4121349067863775e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.7226941458357032e-06
sam_encoder.blocks.1.norm1.weight grad: 1.2890131984022446e-06
sam_encoder.blocks.1.norm1.bias grad: 1.064921889337711e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.6279144549334887e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.18696889837156e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.1119666346057784e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.1850523808097932e-06
sam_encoder.blocks.1.norm2.weight grad: 8.200846423278563e-06
sam_encoder.blocks.1.norm2.bias grad: -1.1071864491896122e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.519732770968403e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.18195975018898e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.817948244337458e-08
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.2233333279709768e-07
sam_encoder.blocks.2.norm1.weight grad: 5.654759206663584e-06
sam_encoder.blocks.2.norm1.bias grad: 2.1957318949716864e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.9140715014364105e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.4143610087558045e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1417685072956374e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.271146387211047e-07
sam_encoder.blocks.2.norm2.weight grad: 3.82611142413225e-06
sam_encoder.blocks.2.norm2.bias grad: -3.1373397177958395e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.491308689262951e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.353233281217399e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.453152087080525e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.7175256036571227e-06
sam_encoder.blocks.3.norm1.weight grad: -1.214810890814988e-05
sam_encoder.blocks.3.norm1.bias grad: -5.804563897982007e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.173617864784319e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.543193755234824e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.242024376959307e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.140562724496704e-07
sam_encoder.blocks.3.norm2.weight grad: 8.896136023395229e-06
sam_encoder.blocks.3.norm2.bias grad: 9.985451470129192e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.624738944083219e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.1303450214181794e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.641703642642824e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2731757124129217e-06
sam_encoder.blocks.4.norm1.weight grad: -1.6964695532806218e-05
sam_encoder.blocks.4.norm1.bias grad: -2.5555750653438736e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.014544704958098e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.606877842481481e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.7588165469060186e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.192162355640903e-06
sam_encoder.blocks.4.norm2.weight grad: -2.396593572484562e-06
sam_encoder.blocks.4.norm2.bias grad: 9.327466159447795e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.600722609713557e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.796854220032401e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.5239492086038808e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.256349358111038e-07
sam_encoder.blocks.5.norm1.weight grad: -1.2050785699102562e-05
sam_encoder.blocks.5.norm1.bias grad: -7.261361133714672e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.576604159316048e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.124083948729094e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.9806595850677695e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.826681444887072e-06
sam_encoder.blocks.5.norm2.weight grad: -6.025428774592001e-06
sam_encoder.blocks.5.norm2.bias grad: -7.737116902717389e-08
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.6423596156964777e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6786123069323367e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.539996206811338e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.830831249411858e-07
sam_encoder.blocks.6.norm1.weight grad: -6.4325354287575465e-06
sam_encoder.blocks.6.norm1.bias grad: -1.3755015970673412e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.51056564290775e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.216973598478944e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.9822537069558166e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.8331472801946802e-06
sam_encoder.blocks.6.norm2.weight grad: -8.307558232445444e-07
sam_encoder.blocks.6.norm2.bias grad: 1.1753288617910584e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.783643786116954e-08
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.623637022722505e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.5083303424034966e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.407000571722165e-07
sam_encoder.blocks.7.norm1.weight grad: -4.90126694785431e-09
sam_encoder.blocks.7.norm1.bias grad: 1.5943745665936149e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.315977205100353e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.519112621892418e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.699653123272583e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.64016671533318e-06
sam_encoder.blocks.7.norm2.weight grad: 3.0015834795449337e-07
sam_encoder.blocks.7.norm2.bias grad: 2.426104401820339e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.7059220428782282e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.4858036340447143e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.281214718408592e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.177794146656197e-07
sam_encoder.blocks.8.norm1.weight grad: 4.652721599995857e-06
sam_encoder.blocks.8.norm1.bias grad: 1.1921983968932182e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.129111857764656e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.185063183584134e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.0078672352829017e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.909752427309286e-06
sam_encoder.blocks.8.norm2.weight grad: -3.448077677603578e-06
sam_encoder.blocks.8.norm2.bias grad: -1.7328884496237151e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.3180072023242246e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0882698663626797e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.645981098785114e-09
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.4084846472760546e-07
sam_encoder.blocks.9.norm1.weight grad: -5.028684881835943e-06
sam_encoder.blocks.9.norm1.bias grad: -3.913146144896018e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.5549496715248097e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1273498330410803e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.943427474150667e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.0519917143246857e-06
sam_encoder.blocks.9.norm2.weight grad: -7.3407891250099055e-06
sam_encoder.blocks.9.norm2.bias grad: -3.5766188375419006e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.196252004679991e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.3596213597775204e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.652282549002848e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.083593456831295e-07
sam_encoder.blocks.10.norm1.weight grad: -3.0319046118165716e-07
sam_encoder.blocks.10.norm1.bias grad: -1.568984998812084e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1001623079209821e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3850430136130853e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.8574334010045277e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.35908759754966e-07
sam_encoder.blocks.10.norm2.weight grad: -1.2820473784813657e-05
sam_encoder.blocks.10.norm2.bias grad: -5.17989747095271e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.9396688811830245e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.140910732530756e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.5559409095876617e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.174156977867824e-06
sam_encoder.blocks.11.norm1.weight grad: -1.6369029935958679e-06
sam_encoder.blocks.11.norm1.bias grad: 9.563649427946075e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.6259382391581312e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.454758244624827e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.274221084202054e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.484410507961002e-07
sam_encoder.blocks.11.norm2.weight grad: -1.41097934829304e-05
sam_encoder.blocks.11.norm2.bias grad: -5.256226359051652e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.0659169826540165e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.8814781671826495e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.3156351289799204e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.098166628973559e-07
sam_encoder.neck.conv1.trainable_scale grad: -9.708201105240732e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.086919216206297e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1815318430308253e-06
sam_encoder.neck.conv2.trainable_shift grad: 3.5876968468073756e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002300332998856902
mask_decoder.transformer.layers.0.norm1.bias grad: 2.1443847799673676e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0016464509535580873
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003078075242228806
mask_decoder.transformer.layers.0.norm3.weight grad: -2.2414038539864123e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.1716935811564326e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.0518436435377225e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.377873094403185e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 8.446721767541021e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.811041435459629e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00016447732923552394
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001638674730202183
mask_decoder.transformer.layers.1.norm3.weight grad: 9.994111314881593e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 0.00010188924352405593
mask_decoder.transformer.layers.1.norm4.weight grad: 9.056950511876494e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -6.485013000201434e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.312290805799421e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.4798141819483135e-05
Text_Embedding_Affine.0.weight grad: -1.296280791041049e-11
Text_Embedding_Affine.0.bias grad: -2.7516330880494877e-10
Text_Embedding_Affine.2.weight grad: 6.645717309794463e-11
Text_Embedding_Affine.2.bias grad: -4.961933882441372e-06
Epoch 8 finished with average loss: -66.6456
Epoch 9/39
----------
Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.7]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-55.7]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-61.6]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-61.6]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-64.8]Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-64.8]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06894812732934952

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06894812732934952

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08023881912231445

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2333056777715683

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06767988204956055

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08023881912231445

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.66718292236328
Max value: 75.97517395019531
Mean value: 55.69196319580078

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06894812732934952

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06894812732934952

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06894812732934952

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2333056777715683

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.66718292236328
Max value: 75.97517395019531
Mean value: 55.69196319580078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.692420959472656
Max value: -55.692420959472656
Mean value: -55.692420959472656
sam_encoder.pos_embed grad: -3.8349212694299695e-09
sam_encoder.blocks.0.norm1.weight grad: -4.199436807539314e-05
sam_encoder.blocks.0.norm1.bias grad: -1.2049621545884293e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.792244913507602e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1125962373625953e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.971475836005993e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.920819603488781e-07
sam_encoder.blocks.0.norm2.weight grad: 7.562460723420372e-06
sam_encoder.blocks.0.norm2.bias grad: -5.428389340522699e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.5072408132255077e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.209088946387055e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.1240846763248555e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.191669177089352e-06
sam_encoder.blocks.1.norm1.weight grad: 4.691220510721905e-06
sam_encoder.blocks.1.norm1.bias grad: -3.624212695285678e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.916191184951458e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.372346880809346e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.3435463845089544e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.5578874581478885e-06
sam_encoder.blocks.1.norm2.weight grad: 7.889138032624032e-06
sam_encoder.blocks.1.norm2.bias grad: 7.1838967414805666e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.805747372913174e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.1528192064579343e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0557647530949907e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.778277672012337e-07
sam_encoder.blocks.2.norm1.weight grad: -5.570767370954854e-06
sam_encoder.blocks.2.norm1.bias grad: -8.013836122700013e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.124399881926365e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7242489036561892e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.5112598197883926e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.621433049578627e-07
sam_encoder.blocks.2.norm2.weight grad: 3.7994202557456447e-06
sam_encoder.blocks.2.norm2.bias grad: 2.8661074793490116e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.886832473654067e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.8108036076446297e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.629443431738764e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.2744675359499524e-06
sam_encoder.blocks.3.norm1.weight grad: 4.346973582869396e-06
sam_encoder.blocks.3.norm1.bias grad: -5.698924269381678e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.533984792942647e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6175426935660653e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.4834947655326687e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.7345425931125646e-06
sam_encoder.blocks.3.norm2.weight grad: -2.2644711862085387e-05
sam_encoder.blocks.3.norm2.bias grad: -1.1883135812240653e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.830879773478955e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.223315151350107e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.554127149778651e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.841107390049729e-07
sam_encoder.blocks.4.norm1.weight grad: -4.1951243474613875e-06
sam_encoder.blocks.4.norm1.bias grad: -6.8916770032956265e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.5980032155057415e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.9393539787415648e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.6447925566562844e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.79451580051682e-07
sam_encoder.blocks.4.norm2.weight grad: -2.5308672775281593e-05
sam_encoder.blocks.4.norm2.bias grad: -9.68592576100491e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.603237251401879e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.863518708792981e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.4710830100739258e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.443835556841805e-07
sam_encoder.blocks.5.norm1.weight grad: 9.60960278462153e-06
sam_encoder.blocks.5.norm1.bias grad: -6.298224434431177e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.80237235428649e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.092911134037422e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.028675569614279e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.338336220323981e-07
sam_encoder.blocks.5.norm2.weight grad: 8.348869755536725e-07
sam_encoder.blocks.5.norm2.bias grad: -1.5665227692807093e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.7633977904552012e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 8.318831987708108e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.807929038477596e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4463579134371685e-07
sam_encoder.blocks.6.norm1.weight grad: 1.2106900157959899e-06
sam_encoder.blocks.6.norm1.bias grad: -4.405771505844314e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.497978241284727e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.065372200377169e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.622856693003996e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.417716475771158e-06
sam_encoder.blocks.6.norm2.weight grad: -1.5241700566548388e-05
sam_encoder.blocks.6.norm2.bias grad: -3.610299927458982e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0140827725990675e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.6299420571594965e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.027546757853997e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0047706382465549e-06
sam_encoder.blocks.7.norm1.weight grad: 4.884593636234058e-06
sam_encoder.blocks.7.norm1.bias grad: -3.464047040324658e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.206354110967368e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.204369027618668e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4790474551773514e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.941682724776911e-07
sam_encoder.blocks.7.norm2.weight grad: -6.658862048425362e-07
sam_encoder.blocks.7.norm2.bias grad: -9.06493994534685e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.300229872773343e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.1638047087435552e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.1499710075877374e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.395274694004911e-06
sam_encoder.blocks.8.norm1.weight grad: 1.3824754205415957e-05
sam_encoder.blocks.8.norm1.bias grad: -3.2657621318321617e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.37497772811912e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.399022367986618e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.2660412949117017e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.717712050070986e-06
sam_encoder.blocks.8.norm2.weight grad: -5.145273007656215e-07
sam_encoder.blocks.8.norm2.bias grad: 1.7718004983180435e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.7998713701672386e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3879468951927265e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.647994155173365e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.134789127694603e-07
sam_encoder.blocks.9.norm1.weight grad: 2.4571470476075774e-06
sam_encoder.blocks.9.norm1.bias grad: -1.6153323656453722e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.004339744933532e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.962105381560832e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.101390807889402e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.363951226579957e-08
sam_encoder.blocks.9.norm2.weight grad: -3.839094461000059e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2296385420995648e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.6201968214299995e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2760359595631598e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.982345096024801e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.5441019008430885e-07
sam_encoder.blocks.10.norm1.weight grad: 4.35522997577209e-06
sam_encoder.blocks.10.norm1.bias grad: 5.143832595422282e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.8511776715968153e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.183370485108753e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.02726260012787e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.1508619713349617e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0235785339318682e-06
sam_encoder.blocks.10.norm2.bias grad: -2.272131268910016e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.524572881971835e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.6268291953310836e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.865073831046175e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.807506108292728e-08
sam_encoder.blocks.11.norm1.weight grad: -1.1040808658435708e-06
sam_encoder.blocks.11.norm1.bias grad: 1.7120064512710087e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.444741196290124e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.7165315802667465e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.4344227490000776e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.342014960911911e-07
sam_encoder.blocks.11.norm2.weight grad: 4.354653356131166e-06
sam_encoder.blocks.11.norm2.bias grad: -2.490345423211693e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.060592578345677e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.7006960812723264e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.583235871294164e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.800186393869808e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.219145921524614e-08
sam_encoder.neck.conv1.trainable_shift grad: 1.4732318959431723e-05
sam_encoder.neck.conv2.trainable_scale grad: 8.924507710617036e-08
sam_encoder.neck.conv2.trainable_shift grad: -3.178539191139862e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 7.616453513037413e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 7.698545232415199e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004488264210522175
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00046354340156540275
mask_decoder.transformer.layers.0.norm3.weight grad: -7.005316001595929e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.603988857823424e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.671712642651983e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 6.57921646052273e-07
mask_decoder.transformer.layers.1.norm1.weight grad: -6.212772859726101e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.282026333792601e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00017683295300230384
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00017992818902712315
mask_decoder.transformer.layers.1.norm3.weight grad: -4.476067260839045e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.0995385865680873e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 8.962449646787718e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 5.996692198095843e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.0916708055883646e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.3954100722912699e-05
Text_Embedding_Affine.0.weight grad: 8.407646323940754e-14
Text_Embedding_Affine.0.bias grad: 9.129350053704854e-12
Text_Embedding_Affine.2.weight grad: 1.579359559800153e-11
Text_Embedding_Affine.2.bias grad: 7.285998435690999e-07

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07488483190536499

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07488483190536499

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07489538192749023

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17655768990516663

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07403135299682617

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07489538192749023

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.81201934814453
Max value: 91.13145446777344
Mean value: 67.31185913085938

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07505028694868088

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07505028694868088

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07505028694868088

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.170302614569664

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8059903383255005
Max value: 5.662874221801758
Mean value: 1.0083894729614258

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.81201934814453
Max value: 91.13145446777344
Mean value: 67.31185913085938

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.54881286621094
Max value: -67.54881286621094
Mean value: -67.54881286621094
sam_encoder.pos_embed grad: -2.9302471560299637e-09
sam_encoder.blocks.0.norm1.weight grad: 2.3926462745293975e-05
sam_encoder.blocks.0.norm1.bias grad: 2.1140787794138305e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.9032507907468244e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.18707281571551e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.8731708425766556e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.856514005448844e-07
sam_encoder.blocks.0.norm2.weight grad: 2.8611391826416366e-05
sam_encoder.blocks.0.norm2.bias grad: 5.657938345393632e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.2988049295236124e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.039930566548719e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 6.890470103826374e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.283580766350497e-07
sam_encoder.blocks.1.norm1.weight grad: 3.464093197180773e-06
sam_encoder.blocks.1.norm1.bias grad: 6.555830623256043e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.9757674181164475e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.737509703365504e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.2806552806287073e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.408401418411813e-07
sam_encoder.blocks.1.norm2.weight grad: 1.1364350939402357e-05
sam_encoder.blocks.1.norm2.bias grad: 5.21607205428154e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.021930059636361e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6143080472375004e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.017796987274778e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.0449828096170677e-06
sam_encoder.blocks.2.norm1.weight grad: -2.75465436061495e-06
sam_encoder.blocks.2.norm1.bias grad: 6.12833900959231e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3752608083450468e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.1186775117930665e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.463543180259876e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.61077343566285e-06
sam_encoder.blocks.2.norm2.weight grad: -8.715342119103298e-06
sam_encoder.blocks.2.norm2.bias grad: 2.4158694031939376e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.5610979618213605e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.0334471173555357e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.575909310413408e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.33424303184438e-07
sam_encoder.blocks.3.norm1.weight grad: -6.4324231061618775e-06
sam_encoder.blocks.3.norm1.bias grad: -3.199015736754518e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.485489969534683e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.779274374617671e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0697287962102564e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.6974802242184523e-07
sam_encoder.blocks.3.norm2.weight grad: 3.611325837482582e-06
sam_encoder.blocks.3.norm2.bias grad: 3.449931455179467e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.106056621822063e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.8652119706530357e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.5946656048981822e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7004633434680727e-07
sam_encoder.blocks.4.norm1.weight grad: 5.157216946827248e-06
sam_encoder.blocks.4.norm1.bias grad: -9.411099881617702e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.5493232012886438e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.208868962356064e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.7641090153119876e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.168223090848187e-06
sam_encoder.blocks.4.norm2.weight grad: -1.1113990694866516e-05
sam_encoder.blocks.4.norm2.bias grad: -8.965386768977623e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.998608791443985e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.6575127069227165e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.325359436232247e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.3740521959989564e-07
sam_encoder.blocks.5.norm1.weight grad: -2.6321340556023642e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2999209957342828e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.317136699683033e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.1189239305385854e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.773074569035089e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.014736253386218e-07
sam_encoder.blocks.5.norm2.weight grad: -8.201413947972469e-06
sam_encoder.blocks.5.norm2.bias grad: -5.237758159637451e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.7309140477882465e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.048336894717067e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.57457292163599e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0403153964944067e-06
sam_encoder.blocks.6.norm1.weight grad: 1.7291129097429803e-06
sam_encoder.blocks.6.norm1.bias grad: 3.756050091396901e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.570793012386275e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.512447612294636e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.161865156973363e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.6182785834171227e-07
sam_encoder.blocks.6.norm2.weight grad: -2.0225593289069366e-06
sam_encoder.blocks.6.norm2.bias grad: -9.21982689305878e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.5405476005980745e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.42017653262883e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.6956236095211352e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.157069378787128e-07
sam_encoder.blocks.7.norm1.weight grad: 1.8622107518240227e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1760598681576084e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.6463740166727803e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.477157856148551e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.309704884988605e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.535436452599242e-08
sam_encoder.blocks.7.norm2.weight grad: 2.7020064408134203e-06
sam_encoder.blocks.7.norm2.bias grad: -1.5907532713299588e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.0359302652650513e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.853784834172984e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.313177335759974e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.915415156072413e-07
sam_encoder.blocks.8.norm1.weight grad: -1.2600293075593072e-06
sam_encoder.blocks.8.norm1.bias grad: -7.494296596632921e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.0832731024711393e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.0584205938357627e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.7015486264426727e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.1496217666717712e-06
sam_encoder.blocks.8.norm2.weight grad: 1.1637106354100979e-06
sam_encoder.blocks.8.norm2.bias grad: -8.15286512079183e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.5194709703791887e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.909586656751344e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.341067440487677e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.913472141903185e-07
sam_encoder.blocks.9.norm1.weight grad: -1.6225576473516412e-06
sam_encoder.blocks.9.norm1.bias grad: 3.280148916928738e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.2206862720631761e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.564924438454909e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.1606418581777689e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.953968068046379e-07
sam_encoder.blocks.9.norm2.weight grad: 1.4421337937164935e-06
sam_encoder.blocks.9.norm2.bias grad: -1.025706296786666e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.6083349692053162e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.954390533384867e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.5866241887561046e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.06884282710962e-07
sam_encoder.blocks.10.norm1.weight grad: 2.172440872527659e-06
sam_encoder.blocks.10.norm1.bias grad: -2.7311358508086414e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.055417553492589e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.269197451227228e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0550903652983834e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.307119176402921e-07
sam_encoder.blocks.10.norm2.weight grad: 2.143304271839952e-07
sam_encoder.blocks.10.norm2.bias grad: -1.674849727351102e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.0530993677093647e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.2730167970053117e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.400885237984767e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.8081302022874297e-07
sam_encoder.blocks.11.norm1.weight grad: 8.449893357465044e-06
sam_encoder.blocks.11.norm1.bias grad: -7.959373533594771e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -8.694025268596306e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.0652724685987778e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.638132271698851e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.730484993662685e-07
sam_encoder.blocks.11.norm2.weight grad: -9.424945233149629e-07
sam_encoder.blocks.11.norm2.bias grad: -1.243262886418961e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.0288971427362412e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.6578623507921293e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.1659443543976522e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.0184946808731183e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.1153118723304942e-07
sam_encoder.neck.conv1.trainable_shift grad: -8.92152456799522e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.57252712699119e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.846682764356956e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015417326358146966
mask_decoder.transformer.layers.0.norm1.bias grad: -1.768676156643778e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003806877415627241
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002999226562678814
mask_decoder.transformer.layers.0.norm3.weight grad: -6.328219023998827e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2618977052625269e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.74073671689257e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.4151807994931005e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.71688038285356e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0126753952354193e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -4.906922549707815e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.834464198211208e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.676069536595605e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.19159371429123e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.202920768468175e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013780899462290108
mask_decoder.transformer.norm_final_attn.weight grad: 6.890442818985321e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0094314347952604e-05
Text_Embedding_Affine.0.weight grad: 2.407472875567973e-12
Text_Embedding_Affine.0.bias grad: 4.492604899208885e-11
Text_Embedding_Affine.2.weight grad: 1.8184211081351265e-10
Text_Embedding_Affine.2.bias grad: 2.094500814564526e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10497984290122986

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10497984290122986

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10863590240478516

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.21646569669246674

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10441207885742188

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10863590240478516

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 59.036128997802734
Max value: 81.14616394042969
Mean value: 70.69818115234375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10402271151542664

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10402271151542664

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10402271151542664

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2029261738061905

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.684794008731842
Max value: 10.619630813598633
Mean value: 1.0222488641738892

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 59.036128997802734
Max value: 81.14616394042969
Mean value: 70.69818115234375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -71.02312469482422
Max value: -71.02312469482422
Mean value: -71.02312469482422
sam_encoder.pos_embed grad: 3.189723152274837e-09
sam_encoder.blocks.0.norm1.weight grad: -2.279503405588912e-06
sam_encoder.blocks.0.norm1.bias grad: -5.098166184325237e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.137617674539797e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.9540469509138347e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.8475515136960894e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.811077236714482e-07
sam_encoder.blocks.0.norm2.weight grad: 1.8260810975334607e-05
sam_encoder.blocks.0.norm2.bias grad: -1.2983843589609023e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.447532774065621e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.4470604128291598e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8788196030072868e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.416223873704439e-06
sam_encoder.blocks.1.norm1.weight grad: 7.69525740906829e-07
sam_encoder.blocks.1.norm1.bias grad: 7.833396011847071e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.1495735584030626e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.7832497860581498e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.322404492995702e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.706520490391995e-06
sam_encoder.blocks.1.norm2.weight grad: -6.509664217446698e-06
sam_encoder.blocks.1.norm2.bias grad: -1.3704263892577728e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.3349698469464784e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.754198101863949e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0539441973378416e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.423987777750881e-07
sam_encoder.blocks.2.norm1.weight grad: 7.616453331138473e-06
sam_encoder.blocks.2.norm1.bias grad: -6.511265382869169e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.296265615266748e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.235600848303875e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.072452099990187e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 4.095193162356736e-07
sam_encoder.blocks.2.norm2.weight grad: 4.117990556551376e-06
sam_encoder.blocks.2.norm2.bias grad: 5.085732482257299e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.7917463992489502e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.295114581192138e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.33719786896836e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.961582029252895e-06
sam_encoder.blocks.3.norm1.weight grad: 1.1963336419285042e-06
sam_encoder.blocks.3.norm1.bias grad: -6.711376045132056e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.951281648071017e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.157146223515156e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.399016921117436e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.813638618841651e-06
sam_encoder.blocks.3.norm2.weight grad: -3.7983525089657633e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0532434316701256e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.7624796555537614e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.0026436711996212e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.375377779477276e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5456984101547278e-06
sam_encoder.blocks.4.norm1.weight grad: -1.476538000133587e-05
sam_encoder.blocks.4.norm1.bias grad: -1.020229137793649e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.000577847473323e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.769165464793332e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.2456191547680646e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.51487779476156e-06
sam_encoder.blocks.4.norm2.weight grad: -1.0043626389233395e-05
sam_encoder.blocks.4.norm2.bias grad: 2.357734956603963e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.491299584216904e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.2785711735195946e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.3393105240975274e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.452544438507175e-06
sam_encoder.blocks.5.norm1.weight grad: -1.2372636774671264e-05
sam_encoder.blocks.5.norm1.bias grad: -8.581580004829448e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.0983799155801535e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.5076209908547753e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.797866495209746e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.379828161901969e-07
sam_encoder.blocks.5.norm2.weight grad: -9.952353138942271e-06
sam_encoder.blocks.5.norm2.bias grad: 1.030003659252543e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.1358891798590776e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5999088418539031e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.40682628727518e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.49424260800879e-07
sam_encoder.blocks.6.norm1.weight grad: -1.3343095588425058e-06
sam_encoder.blocks.6.norm1.bias grad: 5.408428478403948e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.1316321888443781e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.742786584050918e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.600694177905098e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.980353302627918e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0132617717317771e-05
sam_encoder.blocks.6.norm2.bias grad: 1.067126831344467e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.213143024069723e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.329864855710184e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4902207112754695e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.6821267934119533e-07
sam_encoder.blocks.7.norm1.weight grad: 2.900370418501552e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1464778708614176e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.696268100204179e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.280724503289093e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9534006696630968e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.1478560938703595e-06
sam_encoder.blocks.7.norm2.weight grad: -2.002109795284923e-06
sam_encoder.blocks.7.norm2.bias grad: 1.3801285376757733e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.5522989492164925e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.212333012925228e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.16596184449736e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.447876568112406e-08
sam_encoder.blocks.8.norm1.weight grad: 4.3189129428355955e-06
sam_encoder.blocks.8.norm1.bias grad: 1.658202904764039e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.707034804596333e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.4896307877497748e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.935762707551476e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.126760858180205e-08
sam_encoder.blocks.8.norm2.weight grad: -1.6352581724277115e-06
sam_encoder.blocks.8.norm2.bias grad: -4.703629201685544e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.8617437262946623e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3369757425607531e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4699402299811481e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.954965326462116e-07
sam_encoder.blocks.9.norm1.weight grad: -2.8696713343379088e-06
sam_encoder.blocks.9.norm1.bias grad: -9.82836034779666e-09
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.6185821297985967e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.799254030440352e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.799303496838547e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.033671186538413e-07
sam_encoder.blocks.9.norm2.weight grad: -2.465914349158993e-06
sam_encoder.blocks.9.norm2.bias grad: -1.3598940995507292e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.196940840804018e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.5364448699983768e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.655728614328837e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.978532845394511e-07
sam_encoder.blocks.10.norm1.weight grad: 1.615149244571512e-06
sam_encoder.blocks.10.norm1.bias grad: -2.1434248083096463e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.6197270724660484e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.6926473967469065e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.662090529767738e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0975682016578503e-06
sam_encoder.blocks.10.norm2.weight grad: -5.569003405980766e-06
sam_encoder.blocks.10.norm2.bias grad: -1.6351732483599335e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.5989519346912857e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.5666429337434238e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.143100452187355e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.7407272657219437e-07
sam_encoder.blocks.11.norm1.weight grad: -6.49690218779142e-06
sam_encoder.blocks.11.norm1.bias grad: -1.669826247052697e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.560588541200559e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.6397720514760294e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.861352742111194e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.245721581559337e-07
sam_encoder.blocks.11.norm2.weight grad: -1.270419829779712e-06
sam_encoder.blocks.11.norm2.bias grad: -3.5969885630038334e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.6788256946019828e-08
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -9.749001037562266e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.04321944813546e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.1691163826508273e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.094861990073696e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.09862695960328e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.011528163682669e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.597960575367324e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012504881306085736
mask_decoder.transformer.layers.0.norm1.bias grad: 4.67354038846679e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0007903770310804248
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00026465399423614144
mask_decoder.transformer.layers.0.norm3.weight grad: -3.6861027183476835e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.357060480397195e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -2.807205601129681e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.550323400413617e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 6.582080095540732e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.169612556230277e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00025299808476120234
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00026975528453476727
mask_decoder.transformer.layers.1.norm3.weight grad: 8.283265924546868e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.892655361909419e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.434601239860058e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -1.7728787497617304e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.696464985609055e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.688144367217319e-06
Text_Embedding_Affine.0.weight grad: -1.5753998799938884e-11
Text_Embedding_Affine.0.bias grad: -5.526884505613339e-10
Text_Embedding_Affine.2.weight grad: -1.5561209265602116e-10
Text_Embedding_Affine.2.bias grad: -3.859310527332127e-05
Epoch 9 finished with average loss: -64.7548
Epoch 10/39
----------
Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.4]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-58.4]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-65]  Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-65]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-62.3]Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-62.3]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06981703639030457

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06981703639030457

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07302188873291016

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1701362580060959

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06816291809082031

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07302188873291016

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.382118225097656
Max value: 77.79753112792969
Mean value: 58.44556427001953

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06981703639030457

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06981703639030457

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06981703639030457

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1701362580060959

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.382118225097656
Max value: 77.79753112792969
Mean value: 58.44556427001953

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.44606018066406
Max value: -58.44606018066406
Mean value: -58.44606018066406
sam_encoder.pos_embed grad: 1.597712406820051e-09
sam_encoder.blocks.0.norm1.weight grad: -5.609842992271297e-05
sam_encoder.blocks.0.norm1.bias grad: -2.9153503419365734e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.851805665064603e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.496520892236731e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.3597765448357677e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.8821104958988144e-06
sam_encoder.blocks.0.norm2.weight grad: -5.9044479712611064e-05
sam_encoder.blocks.0.norm2.bias grad: 2.0503386622294784e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.413623178654234e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -9.33450053253182e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.9605498639284633e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.823639301321236e-06
sam_encoder.blocks.1.norm1.weight grad: -4.369092494016513e-06
sam_encoder.blocks.1.norm1.bias grad: 9.37575168791227e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.60991565079894e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.90859951141465e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.287469437258551e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.9091176000074483e-06
sam_encoder.blocks.1.norm2.weight grad: 3.998982720077038e-05
sam_encoder.blocks.1.norm2.bias grad: 1.4665445178252412e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3531697732105386e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.4573650989623275e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 8.869290468282998e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.7038212263287278e-06
sam_encoder.blocks.2.norm1.weight grad: -1.113051075662952e-05
sam_encoder.blocks.2.norm1.bias grad: -1.083554707292933e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.318118923014481e-08
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.4724894842620415e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.8517370083136484e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.8107216419593897e-06
sam_encoder.blocks.2.norm2.weight grad: 1.4446845852944534e-05
sam_encoder.blocks.2.norm2.bias grad: 2.265029979753308e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.33994511392666e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.8173117243568413e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.7692312869476154e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7806275991461007e-06
sam_encoder.blocks.3.norm1.weight grad: 2.06452878046548e-05
sam_encoder.blocks.3.norm1.bias grad: -5.653419066220522e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 8.839559995976742e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.3536154003522824e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.195021003601141e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.637539182615001e-07
sam_encoder.blocks.3.norm2.weight grad: -1.0592329999781214e-05
sam_encoder.blocks.3.norm2.bias grad: -1.775865166564472e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.872348760429304e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.0496712497551925e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.763157169738406e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.834172942646546e-07
sam_encoder.blocks.4.norm1.weight grad: -7.685699529247358e-06
sam_encoder.blocks.4.norm1.bias grad: -1.4460090824286453e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.951196964000701e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.993751296453411e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.4392331826893496e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.6577749875068548e-06
sam_encoder.blocks.4.norm2.weight grad: 7.134194220270729e-06
sam_encoder.blocks.4.norm2.bias grad: -1.518849421699997e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.781274689477868e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.4336100093714776e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.0459536901616957e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.923429863381898e-06
sam_encoder.blocks.5.norm1.weight grad: -1.1641328455880284e-05
sam_encoder.blocks.5.norm1.bias grad: -2.8392154490575194e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.87499118107371e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.05929085900425e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.556476248282706e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1693582564475946e-06
sam_encoder.blocks.5.norm2.weight grad: 1.6278507246170193e-05
sam_encoder.blocks.5.norm2.bias grad: -4.666864242608426e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.0273764928570017e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.099736543139443e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.195308979935362e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.920119742266252e-07
sam_encoder.blocks.6.norm1.weight grad: -2.643465904839104e-06
sam_encoder.blocks.6.norm1.bias grad: -2.93185416921915e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.5925177194731077e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4186712178343441e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.363854143070057e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.279589125464554e-06
sam_encoder.blocks.6.norm2.weight grad: -1.2464381143217906e-05
sam_encoder.blocks.6.norm2.bias grad: -3.8965686144365463e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.741364010551479e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.434528818819672e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4182505765347742e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.795494597445213e-07
sam_encoder.blocks.7.norm1.weight grad: 6.879025022499263e-06
sam_encoder.blocks.7.norm1.bias grad: -3.152584895360633e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.830899004242383e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3669296095031314e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2144396350777242e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7827483134169597e-07
sam_encoder.blocks.7.norm2.weight grad: -1.6904657513805432e-06
sam_encoder.blocks.7.norm2.bias grad: -2.0667175704147667e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.3761983552740276e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5422917840623995e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.8110995370079763e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.370942411289434e-07
sam_encoder.blocks.8.norm1.weight grad: -1.3295888265929534e-06
sam_encoder.blocks.8.norm1.bias grad: -2.502905999790528e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.3309512496562093e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.764863324955513e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.2549057828437071e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.591481683746679e-07
sam_encoder.blocks.8.norm2.weight grad: -5.224973392614629e-06
sam_encoder.blocks.8.norm2.bias grad: -2.158091092496761e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.123892151459586e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.8862530143669574e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0260887393087614e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.975856088800356e-07
sam_encoder.blocks.9.norm1.weight grad: 2.480273906257935e-06
sam_encoder.blocks.9.norm1.bias grad: 2.170370407839073e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.948759174614679e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.904770894929243e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.343285248367465e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0871682434299146e-06
sam_encoder.blocks.9.norm2.weight grad: -5.486484496941557e-06
sam_encoder.blocks.9.norm2.bias grad: -3.2173261388379615e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.234576408634894e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.038032334894524e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3068301996099763e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.85973720540278e-07
sam_encoder.blocks.10.norm1.weight grad: -2.387806034676032e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1520751286298037e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.3139948502357583e-08
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.392871809002827e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.158231152156077e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.660732090793317e-07
sam_encoder.blocks.10.norm2.weight grad: -2.473964741511736e-06
sam_encoder.blocks.10.norm2.bias grad: -9.901134490064578e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.635879354784265e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.620590854960028e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.4142368627290125e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.899489500890922e-08
sam_encoder.blocks.11.norm1.weight grad: -1.0730586836871225e-06
sam_encoder.blocks.11.norm1.bias grad: 3.452205191933899e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.920803343746229e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.574637202381382e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.070088157779537e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.4346345968479e-08
sam_encoder.blocks.11.norm2.weight grad: -1.2277277505745587e-07
sam_encoder.blocks.11.norm2.bias grad: -3.0138689908199012e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.4682839239176246e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.7474053493060637e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.521568148949882e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.946790674395743e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.133409336442128e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.3990416846354492e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.920125214383006e-08
sam_encoder.neck.conv2.trainable_shift grad: -9.692593448562548e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00022967241238802671
mask_decoder.transformer.layers.0.norm1.bias grad: 2.200329618062824e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0013852810952812433
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0013854869175702333
mask_decoder.transformer.layers.0.norm3.weight grad: -5.552586662815884e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.680615529650822e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.029268767335452e-06
mask_decoder.transformer.layers.0.norm4.bias grad: -8.367917871510144e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -8.053015335462987e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.9663657440105453e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.660783012397587e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0001216372475028038
mask_decoder.transformer.layers.1.norm3.weight grad: -1.0786898201331496e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.486397326923907e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.3796222346136346e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 3.6533980164676905e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.642182718976983e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.950573490234092e-06
Text_Embedding_Affine.0.weight grad: -3.4348522290339467e-12
Text_Embedding_Affine.0.bias grad: -9.535061629151187e-11
Text_Embedding_Affine.2.weight grad: 5.968017746660337e-12
Text_Embedding_Affine.2.bias grad: -4.641143459593877e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09692241996526718

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09692241996526718

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10017538070678711

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1920776665210724

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09651422500610352

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10017538070678711

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.85232162475586
Max value: 90.06297302246094
Mean value: 71.32275390625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09679922461509705

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09679922461509705

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09679922461509705

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1861371099948883

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.867908239364624
Max value: 3.4998793601989746
Mean value: 1.0073572397232056

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.85232162475586
Max value: 90.06297302246094
Mean value: 71.32275390625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -71.60684204101562
Max value: -71.60684204101562
Mean value: -71.60684204101562
sam_encoder.pos_embed grad: -1.2940718496778914e-09
sam_encoder.blocks.0.norm1.weight grad: -1.7602380466996692e-05
sam_encoder.blocks.0.norm1.bias grad: 9.82274013949791e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.4425535255213617e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.974571877231938e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.2066176370572066e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.070414668902231e-06
sam_encoder.blocks.0.norm2.weight grad: 1.7569334886502475e-05
sam_encoder.blocks.0.norm2.bias grad: 4.899047780781984e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.57640963861195e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.6918703497358365e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.957826604368165e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.2629463981284061e-06
sam_encoder.blocks.1.norm1.weight grad: 2.7283576855552383e-06
sam_encoder.blocks.1.norm1.bias grad: -9.966024663299322e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.629349864946562e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1117226677015424e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.6925091586017516e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0940404990833485e-06
sam_encoder.blocks.1.norm2.weight grad: 9.080036761588417e-06
sam_encoder.blocks.1.norm2.bias grad: -9.892731895888573e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.4524815671611577e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.707328002950817e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.864428097382188e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.3151260108988936e-07
sam_encoder.blocks.2.norm1.weight grad: -1.858386156072811e-07
sam_encoder.blocks.2.norm1.bias grad: -1.1383433502487605e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.4897035498506739e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.496137483376515e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.987856977502815e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.2628145163471345e-07
sam_encoder.blocks.2.norm2.weight grad: -5.8448868003324606e-06
sam_encoder.blocks.2.norm2.bias grad: 1.3922581274528056e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.5623608053138014e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.402510272593645e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.509931497726939e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.6853457174856885e-08
sam_encoder.blocks.3.norm1.weight grad: -5.948411399003817e-06
sam_encoder.blocks.3.norm1.bias grad: -4.212988642393611e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.0684835817519343e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.218926363819264e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2036014140903717e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.730841838972992e-07
sam_encoder.blocks.3.norm2.weight grad: 5.68922496313462e-06
sam_encoder.blocks.3.norm2.bias grad: 7.18426781531889e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.3751314226246905e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.9952738057327224e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.0366677543061087e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.9077560864388943e-07
sam_encoder.blocks.4.norm1.weight grad: -1.5820800172150484e-06
sam_encoder.blocks.4.norm1.bias grad: 1.3481743508236832e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.916237124532927e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.9253234029292798e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.03620140584826e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.144502541857946e-07
sam_encoder.blocks.4.norm2.weight grad: -7.91284219303634e-06
sam_encoder.blocks.4.norm2.bias grad: -6.36532513453858e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.308722277026391e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.483321168256225e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.788954927586019e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.321548534695467e-07
sam_encoder.blocks.5.norm1.weight grad: -5.292671175993746e-06
sam_encoder.blocks.5.norm1.bias grad: -1.8220468973595416e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.861558525386499e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.6533489315406769e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.2269834687449475e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.043399369242252e-07
sam_encoder.blocks.5.norm2.weight grad: -4.536076630756725e-06
sam_encoder.blocks.5.norm2.bias grad: -3.958356046496192e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.154750841844361e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.5722385998960817e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.258621164713986e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.265444305128767e-07
sam_encoder.blocks.6.norm1.weight grad: -9.403797207596654e-07
sam_encoder.blocks.6.norm1.bias grad: 2.119490090990439e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.191202549463924e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.907020295126131e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.630206487694522e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.3324469705366937e-07
sam_encoder.blocks.6.norm2.weight grad: -4.694645667768782e-07
sam_encoder.blocks.6.norm2.bias grad: -7.222233762149699e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0173744158237241e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.750517751337611e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1131110113637988e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.9467787499015685e-07
sam_encoder.blocks.7.norm1.weight grad: 5.112594863021513e-07
sam_encoder.blocks.7.norm1.bias grad: 1.5004404758656165e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.969322718461626e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.304294626919727e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2468339036786347e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.2858442839133204e-07
sam_encoder.blocks.7.norm2.weight grad: 4.61844501842279e-06
sam_encoder.blocks.7.norm2.bias grad: -5.358708108360588e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.895854206348304e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.5272944438038394e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.923236242073472e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.014288942424173e-07
sam_encoder.blocks.8.norm1.weight grad: 1.4041813756193733e-06
sam_encoder.blocks.8.norm1.bias grad: -8.95873654371826e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.6114867094074725e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.459800943048322e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.258969516333309e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.4281197309173876e-06
sam_encoder.blocks.8.norm2.weight grad: 9.225426538250758e-07
sam_encoder.blocks.8.norm2.bias grad: -7.083104947014363e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.0758981261460576e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.01402224067715e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.084092885634163e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.824012418997881e-07
sam_encoder.blocks.9.norm1.weight grad: -2.655358002812136e-06
sam_encoder.blocks.9.norm1.bias grad: 9.613671636543586e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.854852030191978e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.484413303387555e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0680798823159421e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.045051001521642e-07
sam_encoder.blocks.9.norm2.weight grad: -3.386249716186285e-07
sam_encoder.blocks.9.norm2.bias grad: -1.3241731267044088e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.6875417208648287e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.735131031135097e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1888914741575718e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.203080597013468e-07
sam_encoder.blocks.10.norm1.weight grad: 1.3107060112815816e-06
sam_encoder.blocks.10.norm1.bias grad: -9.777436389413197e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.5928685570543166e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.353928594966419e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2611783404281596e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.683017315684992e-07
sam_encoder.blocks.10.norm2.weight grad: -3.5951675272372086e-06
sam_encoder.blocks.10.norm2.bias grad: -2.390846020716708e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.3991493119647203e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.0693546528273146e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5513967355218483e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.778293482057052e-07
sam_encoder.blocks.11.norm1.weight grad: 8.589853678131476e-06
sam_encoder.blocks.11.norm1.bias grad: -1.1234534440518473e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.842918421374634e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.320721013253205e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2149585018050857e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.336792128218804e-07
sam_encoder.blocks.11.norm2.weight grad: -4.983112376066856e-06
sam_encoder.blocks.11.norm2.bias grad: -9.916418548527872e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.5237933932185115e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.1288714176771464e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.0514548850769643e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.004602480265021e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.644254320533946e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.4099788131716195e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.750513759674504e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.0061622459907085e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018231722060590982
mask_decoder.transformer.layers.0.norm1.bias grad: -1.7477068467997015e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003980138339102268
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006335896905511618
mask_decoder.transformer.layers.0.norm3.weight grad: -8.754213922657073e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.6665911718737334e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.133972343988717e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.334368324838579e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.926776844309643e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.670021785888821e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -1.0508494597161189e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.087786020245403e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.024172423873097e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.328309296397492e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.346746259718202e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001491038128733635
mask_decoder.transformer.norm_final_attn.weight grad: 6.3709576352266595e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2497223906393629e-05
Text_Embedding_Affine.0.weight grad: 9.4867013550326e-12
Text_Embedding_Affine.0.bias grad: 3.1859354043817234e-10
Text_Embedding_Affine.2.weight grad: 2.4813162635695107e-10
Text_Embedding_Affine.2.bias grad: 3.5197605029679835e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.928924778135065e-29
Max value: 0.9999995231628418
Mean value: 0.06208929419517517

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.928924778135065e-29
Max value: 0.9999995231628418
Mean value: 0.06208929419517517

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07247447967529297

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15133705735206604

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.059798240661621094

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07247447967529297

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.4911003112793
Max value: 66.77912139892578
Mean value: 56.5626220703125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.222591422053497e-24
Max value: 0.9999960660934448
Mean value: 0.061132270842790604

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.222591422053497e-24
Max value: 0.9999960660934448
Mean value: 0.061132270842790604

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.222591422053497e-24
Max value: 0.9999960660934448
Mean value: 0.061132270842790604

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14022193849086761

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.729665219783783
Max value: 17.071020126342773
Mean value: 1.0212700366973877

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.4911003112793
Max value: 66.77912139892578
Mean value: 56.5626220703125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.72233581542969
Max value: -56.72233581542969
Mean value: -56.72233581542969
sam_encoder.pos_embed grad: 2.753010264200384e-09
sam_encoder.blocks.0.norm1.weight grad: 1.898832488222979e-05
sam_encoder.blocks.0.norm1.bias grad: 2.5942088541341946e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0759292763395933e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.5462462594514363e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.3241647138784174e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0260581575494143e-06
sam_encoder.blocks.0.norm2.weight grad: 8.874575541995e-06
sam_encoder.blocks.0.norm2.bias grad: 1.0511692380532622e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.1960062187863514e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2728690990115865e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.2996200666748337e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.8219317300681723e-06
sam_encoder.blocks.1.norm1.weight grad: -4.550054200080922e-06
sam_encoder.blocks.1.norm1.bias grad: 3.3889361930050654e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.992405931465328e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.079309334770187e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.3022759876312193e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.067337151994252e-07
sam_encoder.blocks.1.norm2.weight grad: -1.7946620118891587e-06
sam_encoder.blocks.1.norm2.bias grad: -2.9593018098239554e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.193178150060703e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.0738146961084567e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.2240059277246473e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.3813304273498943e-07
sam_encoder.blocks.2.norm1.weight grad: 4.268003976903856e-07
sam_encoder.blocks.2.norm1.bias grad: -1.506037165199814e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.772108349650807e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.927157750804326e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1618825510595343e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.693409654370043e-07
sam_encoder.blocks.2.norm2.weight grad: 1.4183464145389735e-06
sam_encoder.blocks.2.norm2.bias grad: -3.995180577476276e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.8111343251803191e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.699412414765902e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.1171597381908214e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.855763897168799e-07
sam_encoder.blocks.3.norm1.weight grad: -1.1360336884536082e-06
sam_encoder.blocks.3.norm1.bias grad: -1.373367922496982e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.973766736948164e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.8816447183999117e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2909556517115561e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.412697075575124e-07
sam_encoder.blocks.3.norm2.weight grad: 7.691951395827346e-06
sam_encoder.blocks.3.norm2.bias grad: 1.080614219972631e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.995442057203036e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.005842684928211e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.939923433586955e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.917198440234642e-07
sam_encoder.blocks.4.norm1.weight grad: -4.876395905739628e-06
sam_encoder.blocks.4.norm1.bias grad: -1.2761456673615612e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.741656655620318e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.789043022261467e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2431180493877036e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.325280400507836e-08
sam_encoder.blocks.4.norm2.weight grad: -2.507309091015486e-06
sam_encoder.blocks.4.norm2.bias grad: 9.459585044169216e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.4748068173939828e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.829607279243646e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.309510480496101e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.712609774695011e-07
sam_encoder.blocks.5.norm1.weight grad: -1.1890406312886626e-05
sam_encoder.blocks.5.norm1.bias grad: -9.469691576668993e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.266901775437873e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.4377995967151946e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.1593256203923374e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1046215604437748e-06
sam_encoder.blocks.5.norm2.weight grad: -3.3733540476532653e-06
sam_encoder.blocks.5.norm2.bias grad: -2.752182695076044e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.4325213442134554e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.0848588633270992e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.59111299480719e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.9697130205240683e-07
sam_encoder.blocks.6.norm1.weight grad: -4.652129064197652e-07
sam_encoder.blocks.6.norm1.bias grad: -8.836935876388452e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.159067531072651e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.616358743689489e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.811964681219251e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.7466359142636065e-07
sam_encoder.blocks.6.norm2.weight grad: -1.2957796116097597e-06
sam_encoder.blocks.6.norm2.bias grad: 4.967920972376305e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.4879107602137083e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.757680934133532e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.8116422729217447e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.9190902845784876e-08
sam_encoder.blocks.7.norm1.weight grad: -4.704601451521739e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4659497082902817e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.8789977477572393e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -9.072974762602826e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.1090451102500083e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.158073700935347e-06
sam_encoder.blocks.7.norm2.weight grad: 1.982018375201733e-06
sam_encoder.blocks.7.norm2.bias grad: 5.094642574476893e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.407896886325034e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.8659530926233856e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.7525438162665523e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.129038586597744e-07
sam_encoder.blocks.8.norm1.weight grad: -1.968927563211764e-06
sam_encoder.blocks.8.norm1.bias grad: 7.84057192504406e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.549041255406337e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.763751455058809e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.127596872014692e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.8252877604682e-07
sam_encoder.blocks.8.norm2.weight grad: -5.855296763002116e-07
sam_encoder.blocks.8.norm2.bias grad: -5.821481749990198e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.877532309270464e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.397181095962878e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4896750144544058e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.485521998276454e-08
sam_encoder.blocks.9.norm1.weight grad: -5.417802640295122e-06
sam_encoder.blocks.9.norm1.bias grad: 1.7571906596458575e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.416545380081516e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.0707631190598477e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.06483058113372e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4728224186910666e-06
sam_encoder.blocks.9.norm2.weight grad: -2.991165047205868e-06
sam_encoder.blocks.9.norm2.bias grad: -1.995139655264211e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.7355007457808824e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.4850078287054203e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.582213245565072e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.299387453305826e-07
sam_encoder.blocks.10.norm1.weight grad: -1.3367074416237301e-06
sam_encoder.blocks.10.norm1.bias grad: -1.2791097105946392e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.1307647440617075e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.278102659962315e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.7359091581711255e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.960949186421203e-07
sam_encoder.blocks.10.norm2.weight grad: -6.937099442438921e-06
sam_encoder.blocks.10.norm2.bias grad: -3.603151981224073e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.625700062708347e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.2024121335562086e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6805718132673064e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.57309408072615e-07
sam_encoder.blocks.11.norm1.weight grad: -5.977857995276281e-07
sam_encoder.blocks.11.norm1.bias grad: -6.067627396078024e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.9075302993296646e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.2438209157371602e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.6685622717413935e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7605559321509645e-07
sam_encoder.blocks.11.norm2.weight grad: -5.576840976573294e-06
sam_encoder.blocks.11.norm2.bias grad: -2.7647718070511473e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -8.058956382228644e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4520941249429598e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6333481198671507e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.5804171122654225e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.548992365016602e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.8538599761086516e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.980276339163538e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.4891514840419404e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019213807536289096
mask_decoder.transformer.layers.0.norm1.bias grad: 5.992042133584619e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0034393027890473604
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00048025295836851
mask_decoder.transformer.layers.0.norm3.weight grad: -9.33892879402265e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.4294454962946475e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.814182855421677e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.414215360768139e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.078781734686345e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.6364068617112935e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00019182145479135215
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00017050126916728914
mask_decoder.transformer.layers.1.norm3.weight grad: 8.473511115880683e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.002136019058526e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.984197999467142e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.864770981948823e-05
mask_decoder.transformer.norm_final_attn.weight grad: 8.727734893909656e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1297983292024583e-05
Text_Embedding_Affine.0.weight grad: 1.219120117357253e-11
Text_Embedding_Affine.0.bias grad: 4.5452383523603146e-10
Text_Embedding_Affine.2.weight grad: 4.35759067718422e-11
Text_Embedding_Affine.2.bias grad: 1.3436436347546987e-05
Epoch 10 finished with average loss: -62.2584
Epoch 11/39
----------
Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.7]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-64.7]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-61.2]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-61.2]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-61.3]Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-61.3]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.070635301878979e-33
Max value: 1.0
Mean value: 0.07691044360399246

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.070635301878979e-33
Max value: 1.0
Mean value: 0.07691044360399246

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07073545455932617

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14052100479602814

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07193374633789062

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07073545455932617

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.89922523498535
Max value: 92.94795989990234
Mean value: 64.67214965820312

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.070635301878979e-33
Max value: 1.0
Mean value: 0.07691044360399246

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.070635301878979e-33
Max value: 1.0
Mean value: 0.07691044360399246

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.070635301878979e-33
Max value: 1.0
Mean value: 0.07691044360399246

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14052100479602814

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.89922523498535
Max value: 92.94795989990234
Mean value: 64.67214965820312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.67282104492188
Max value: -64.67282104492188
Mean value: -64.67282104492188
sam_encoder.pos_embed grad: -5.323723240024947e-09
sam_encoder.blocks.0.norm1.weight grad: -3.515181333568762e-06
sam_encoder.blocks.0.norm1.bias grad: 4.024700956506422e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.0849412269162713e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.785743486645515e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.711027137702331e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.9685914998699445e-07
sam_encoder.blocks.0.norm2.weight grad: -8.261830771516543e-06
sam_encoder.blocks.0.norm2.bias grad: -1.399629945808556e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.687988959834911e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.6914804038824514e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.55066570895724e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.022199497441761e-07
sam_encoder.blocks.1.norm1.weight grad: -1.1246800113440258e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3472963473759592e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.018228992208606e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.6814668672159314e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.734718459076248e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.7719825084204786e-06
sam_encoder.blocks.1.norm2.weight grad: -5.489708200911991e-06
sam_encoder.blocks.1.norm2.bias grad: -4.270993940735934e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.586330189544242e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.047455372026889e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.8001916184148286e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.405668386832986e-07
sam_encoder.blocks.2.norm1.weight grad: 2.0138206480169174e-07
sam_encoder.blocks.2.norm1.bias grad: -1.6191855820579804e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.129104127059691e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.9858193809341174e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.320261152519379e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.7637960303982254e-06
sam_encoder.blocks.2.norm2.weight grad: 3.229331468901364e-06
sam_encoder.blocks.2.norm2.bias grad: -4.403234015626367e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.6074393392482307e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.738878658372414e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.1494939750919e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.07951836475695e-07
sam_encoder.blocks.3.norm1.weight grad: -1.1560238988295168e-07
sam_encoder.blocks.3.norm1.bias grad: -4.929606802761555e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.2770414034312125e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.59304419059481e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0188743999606231e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.883166760308086e-06
sam_encoder.blocks.3.norm2.weight grad: 1.370687641610857e-06
sam_encoder.blocks.3.norm2.bias grad: -4.657089448301122e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.44338940799571e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.820044914779828e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.658209713350516e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.4044215933827218e-06
sam_encoder.blocks.4.norm1.weight grad: 1.0949823263217695e-05
sam_encoder.blocks.4.norm1.bias grad: -9.801660780794919e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.073185315675801e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.5401036509720143e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.3217576199385803e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -8.801134754321538e-08
sam_encoder.blocks.4.norm2.weight grad: -2.4613042114651762e-05
sam_encoder.blocks.4.norm2.bias grad: -1.1805270332843065e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.4054921848583035e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.731802164315013e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.778862947001471e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.2943618230565335e-06
sam_encoder.blocks.5.norm1.weight grad: 2.1733962057624012e-05
sam_encoder.blocks.5.norm1.bias grad: -6.856618597339548e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.604544922884088e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.973479462933028e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.6808213483018335e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.3933828288136283e-06
sam_encoder.blocks.5.norm2.weight grad: -4.530120349954814e-06
sam_encoder.blocks.5.norm2.bias grad: -3.3720198189257644e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.923073109035613e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.237247829521948e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8521712945585023e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.1190909390279558e-06
sam_encoder.blocks.6.norm1.weight grad: 5.26694157088059e-06
sam_encoder.blocks.6.norm1.bias grad: 8.57745931170939e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.601070946184336e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.372589152510045e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.227685614452639e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.110161502372648e-07
sam_encoder.blocks.6.norm2.weight grad: -2.4752448553044815e-06
sam_encoder.blocks.6.norm2.bias grad: -3.5353691600903403e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.400459718250204e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.4117429145699134e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.959235987669672e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.780427384001086e-07
sam_encoder.blocks.7.norm1.weight grad: 3.402025413379306e-06
sam_encoder.blocks.7.norm1.bias grad: 9.187518656972316e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.4868866148608504e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.446362375645549e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.1315731853756006e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.3806038623442873e-06
sam_encoder.blocks.7.norm2.weight grad: -8.400855222134851e-06
sam_encoder.blocks.7.norm2.bias grad: 2.7150463211000897e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.175133760028984e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.047246991627617e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3971371970455948e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.4239650403833366e-07
sam_encoder.blocks.8.norm1.weight grad: 4.8299875743396115e-06
sam_encoder.blocks.8.norm1.bias grad: -3.8099631183285965e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.0140792003076058e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.1808492672571447e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -9.821995945458184e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.3927731263029273e-07
sam_encoder.blocks.8.norm2.weight grad: -1.6672842662046605e-07
sam_encoder.blocks.8.norm2.bias grad: -6.293436740634206e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.650064924926482e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.2999739119077276e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.859425879047194e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.058130790937867e-07
sam_encoder.blocks.9.norm1.weight grad: 6.688358553219587e-06
sam_encoder.blocks.9.norm1.bias grad: 2.6914790396403987e-09
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.661498223867966e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1124021739306045e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.915284297472681e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.7410411601304077e-06
sam_encoder.blocks.9.norm2.weight grad: 4.022770554001909e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6583953765803017e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8133423509425484e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.59451951731171e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.8261411014464102e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.705220473828376e-07
sam_encoder.blocks.10.norm1.weight grad: 5.529550435312558e-06
sam_encoder.blocks.10.norm1.bias grad: 1.349765852864948e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.4935661713243462e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.344078992195136e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.2087013462623872e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.563109415466897e-08
sam_encoder.blocks.10.norm2.weight grad: 1.0957701306324452e-05
sam_encoder.blocks.10.norm2.bias grad: 4.001725301350234e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.1911513360682875e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.836804696926265e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.533762426537578e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.968593879719265e-07
sam_encoder.blocks.11.norm1.weight grad: 2.276384975630208e-06
sam_encoder.blocks.11.norm1.bias grad: 3.6151320728095016e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.5958731220707705e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.010306386386219e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.987140300727333e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.459222501893237e-07
sam_encoder.blocks.11.norm2.weight grad: 6.513228981930297e-06
sam_encoder.blocks.11.norm2.bias grad: -6.513669177365955e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.2420581444748677e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.7249665233975975e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.7771920965969912e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.543745149021561e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.848855835210998e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.999310476705432e-08
sam_encoder.neck.conv2.trainable_scale grad: 6.434565875679255e-07
sam_encoder.neck.conv2.trainable_shift grad: -9.259652870241553e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0002447658043820411
mask_decoder.transformer.layers.0.norm1.bias grad: 2.533488441258669e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.001994788646697998
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0011987504549324512
mask_decoder.transformer.layers.0.norm3.weight grad: 6.219553324626759e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.0027870303019881e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.011290002381429e-07
mask_decoder.transformer.layers.0.norm4.bias grad: -1.2452874216251075e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.479162867530249e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.95751885662321e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.000172948362887837
mask_decoder.transformer.layers.1.norm2.bias grad: -7.598729280289263e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.7100726583739743e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.9837857912061736e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.367808964569122e-07
mask_decoder.transformer.layers.1.norm4.bias grad: -2.6625366444932297e-07
mask_decoder.transformer.norm_final_attn.weight grad: -4.420664936333196e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.8838297819456784e-06
Text_Embedding_Affine.0.weight grad: -1.3553657328413404e-11
Text_Embedding_Affine.0.bias grad: -4.2351233631165996e-10
Text_Embedding_Affine.2.weight grad: -5.3416528145167064e-11
Text_Embedding_Affine.2.bias grad: -5.62733766855672e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.941492054076809e-37
Max value: 1.0
Mean value: 0.07765530049800873

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.941492054076809e-37
Max value: 1.0
Mean value: 0.07765530049800873

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09288406372070312

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17516620457172394

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07514762878417969

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09288406372070312

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 26.006227493286133
Max value: 80.08525848388672
Mean value: 57.595726013183594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.382579520875677e-35
Max value: 1.0
Mean value: 0.07776356488466263

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.382579520875677e-35
Max value: 1.0
Mean value: 0.07776356488466263

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.382579520875677e-35
Max value: 1.0
Mean value: 0.07776356488466263

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1703902631998062

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8884263634681702
Max value: 3.053234100341797
Mean value: 1.0058093070983887

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 26.006227493286133
Max value: 80.08525848388672
Mean value: 57.595726013183594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.78281021118164
Max value: -57.78281021118164
Mean value: -57.78281021118164
sam_encoder.pos_embed grad: 5.291003191132404e-10
sam_encoder.blocks.0.norm1.weight grad: -3.83793558285106e-05
sam_encoder.blocks.0.norm1.bias grad: 3.0586510547436774e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.508981303137261e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3106941310070397e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.790705133927986e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.631250582562643e-07
sam_encoder.blocks.0.norm2.weight grad: 1.4678880688734353e-05
sam_encoder.blocks.0.norm2.bias grad: 1.3149765436537564e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.3988185249618255e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.351655441794719e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.196459197672084e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.409462351555703e-06
sam_encoder.blocks.1.norm1.weight grad: 1.0434716386953369e-05
sam_encoder.blocks.1.norm1.bias grad: 4.737406925414689e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.556900295137893e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.0679218525619945e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 7.237078534672037e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.8332800613716245e-06
sam_encoder.blocks.1.norm2.weight grad: 1.473893007641891e-06
sam_encoder.blocks.1.norm2.bias grad: 1.2332018286542734e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3995891094964463e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.393368489123532e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.672020961355884e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.105005923018325e-07
sam_encoder.blocks.2.norm1.weight grad: 6.690186182822799e-06
sam_encoder.blocks.2.norm1.bias grad: -2.576426368250395e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.3679937082051765e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.222071546180814e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.774845142994309e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 6.918553481227718e-07
sam_encoder.blocks.2.norm2.weight grad: -5.593703463091515e-06
sam_encoder.blocks.2.norm2.bias grad: -3.957443368562963e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.0532586404442554e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.6079978877314716e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.212051862850785e-08
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.96053894241777e-07
sam_encoder.blocks.3.norm1.weight grad: -1.021943134560388e-07
sam_encoder.blocks.3.norm1.bias grad: -1.7015712501233793e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.6294623012290685e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.479131803236669e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.3045616615036124e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.4506265415548114e-06
sam_encoder.blocks.3.norm2.weight grad: 3.212653155060252e-06
sam_encoder.blocks.3.norm2.bias grad: 5.357873305911198e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.7218520699534565e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.483425636361062e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.998468021241933e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.451333890960086e-07
sam_encoder.blocks.4.norm1.weight grad: 1.8714595171331894e-06
sam_encoder.blocks.4.norm1.bias grad: 6.813619165768614e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.7503257266944274e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3755263239545457e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.4999782744525874e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.2413702772137185e-07
sam_encoder.blocks.4.norm2.weight grad: -2.1568689589912537e-06
sam_encoder.blocks.4.norm2.bias grad: -2.16344869841123e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.0943809886375675e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.2235022950335406e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.780344064172823e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.573122952133417e-07
sam_encoder.blocks.5.norm1.weight grad: -5.438252628664486e-06
sam_encoder.blocks.5.norm1.bias grad: -3.2460736747452756e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.0977672647859436e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.099825453820813e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.0474802770186216e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.705849825839323e-07
sam_encoder.blocks.5.norm2.weight grad: -9.73006353888195e-06
sam_encoder.blocks.5.norm2.bias grad: -4.044323304697173e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.10122811445035e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5131048485272913e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.751465532606744e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.7896950162758e-07
sam_encoder.blocks.6.norm1.weight grad: 2.18084863945478e-07
sam_encoder.blocks.6.norm1.bias grad: 9.880454854283016e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.331911552275415e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.2918897829858906e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.185451972371084e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.0776118958565348e-07
sam_encoder.blocks.6.norm2.weight grad: 2.8121411332904245e-07
sam_encoder.blocks.6.norm2.bias grad: 5.385692816162191e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.3432903642751626e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.65252185222198e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.17540942218875e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.4019228444794862e-07
sam_encoder.blocks.7.norm1.weight grad: -2.3066197627485963e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3399270528680063e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.4694717265228974e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.7429330745908374e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.432179459470717e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.8276580249221297e-06
sam_encoder.blocks.7.norm2.weight grad: 5.573961971094832e-06
sam_encoder.blocks.7.norm2.bias grad: -4.2721831050585024e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.510468443186255e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.963006525329547e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.6040730694585363e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.88188794886446e-07
sam_encoder.blocks.8.norm1.weight grad: 8.831860753844012e-08
sam_encoder.blocks.8.norm1.bias grad: 1.1920292308786884e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0472471103639691e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.5384482576763503e-09
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.3579300432174932e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.2748421340802452e-06
sam_encoder.blocks.8.norm2.weight grad: 3.470421461315709e-08
sam_encoder.blocks.8.norm2.bias grad: -2.342863751891855e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.726137146666588e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.386096381063908e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.393357913722866e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.887149766043876e-07
sam_encoder.blocks.9.norm1.weight grad: -3.582164936233312e-06
sam_encoder.blocks.9.norm1.bias grad: 3.2922298487392254e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.660107838892145e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.859931550527108e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.139978268038249e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.483685991843231e-06
sam_encoder.blocks.9.norm2.weight grad: -1.8609571270644665e-06
sam_encoder.blocks.9.norm2.bias grad: -1.133315549850522e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.1954240259656217e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.939625217863068e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1595523119467543e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.874475957374671e-07
sam_encoder.blocks.10.norm1.weight grad: 3.9006201291158504e-07
sam_encoder.blocks.10.norm1.bias grad: -1.2698571936198277e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.143524504092056e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5760033988954092e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.945630156631523e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.152492465436808e-07
sam_encoder.blocks.10.norm2.weight grad: -6.851661510154372e-06
sam_encoder.blocks.10.norm2.bias grad: -3.553166607161984e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.109121399167634e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.0412721823959146e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.7605011635168921e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.85659790885984e-07
sam_encoder.blocks.11.norm1.weight grad: 8.148580491251778e-06
sam_encoder.blocks.11.norm1.bias grad: -1.5275339819709188e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.7613242562219966e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.298503633506698e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2919178971060319e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.969982564442034e-07
sam_encoder.blocks.11.norm2.weight grad: -5.539524408959551e-06
sam_encoder.blocks.11.norm2.bias grad: -1.05833839825209e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.415324047433387e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3550750281865476e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.1542937247431837e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.346808956754103e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.7009234549477696e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3562786080001388e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.967696440871805e-07
sam_encoder.neck.conv2.trainable_shift grad: 7.734843529760838e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002804537070915103
mask_decoder.transformer.layers.0.norm1.bias grad: -2.311397111043334e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00195158866699785
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0009785732254385948
mask_decoder.transformer.layers.0.norm3.weight grad: -4.39492505392991e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.123625720036216e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.683279596269131e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3675607988261618e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.044141314807348e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.2351014195010066e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 8.177556446753442e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010457060125190765
mask_decoder.transformer.layers.1.norm3.weight grad: 5.341548239812255e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.559160854318179e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.563739508332219e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011914387141587213
mask_decoder.transformer.norm_final_attn.weight grad: 7.301189725694712e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.940769814420491e-06
Text_Embedding_Affine.0.weight grad: 8.219622898986145e-12
Text_Embedding_Affine.0.bias grad: -1.337098487486088e-11
Text_Embedding_Affine.2.weight grad: -2.3901464141218298e-11
Text_Embedding_Affine.2.bias grad: 5.3117048082640395e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.3444223704926855e-19
Max value: 0.9998915195465088
Mean value: 0.09581629931926727

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.3444223704926855e-19
Max value: 0.9998915195465088
Mean value: 0.09581629931926727

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09146595001220703

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14935219287872314

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09413623809814453

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09146595001220703

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 55.99583435058594
Max value: 68.89570617675781
Mean value: 61.17780685424805

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1148562452158008e-17
Max value: 0.9996894598007202
Mean value: 0.09746838361024857

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1148562452158008e-17
Max value: 0.9996894598007202
Mean value: 0.09746838361024857

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1148562452158008e-17
Max value: 0.9996894598007202
Mean value: 0.09746838361024857

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14227811992168427

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7149284482002258
Max value: 18.15217399597168
Mean value: 1.0115617513656616

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 55.99583435058594
Max value: 68.89570617675781
Mean value: 61.17780685424805

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.33283233642578
Max value: -61.33283233642578
Mean value: -61.33283233642578
sam_encoder.pos_embed grad: -3.257996983307976e-09
sam_encoder.blocks.0.norm1.weight grad: 6.035573824192397e-05
sam_encoder.blocks.0.norm1.bias grad: 3.563579957699403e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.487234946282115e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.776124634034204e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.5666058718343265e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.934844911185792e-07
sam_encoder.blocks.0.norm2.weight grad: 2.01769798877649e-05
sam_encoder.blocks.0.norm2.bias grad: 1.1025025742128491e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.377759286304354e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.4218982136735576e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.075581157143461e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.7127275643579196e-06
sam_encoder.blocks.1.norm1.weight grad: -1.257417807210004e-05
sam_encoder.blocks.1.norm1.bias grad: -7.679711416130885e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.5553207504126476e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.396004318456107e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.466387271255371e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.3384183148446027e-06
sam_encoder.blocks.1.norm2.weight grad: 1.3097655028104782e-05
sam_encoder.blocks.1.norm2.bias grad: 3.3068317861761898e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.428245396567945e-08
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.505211623178184e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.185939128044993e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4125081381498603e-06
sam_encoder.blocks.2.norm1.weight grad: 4.3956183048976527e-07
sam_encoder.blocks.2.norm1.bias grad: -8.327641808136832e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.498661615391029e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.8759581027770764e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.6640706134203356e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.284728109065327e-06
sam_encoder.blocks.2.norm2.weight grad: -8.89112925506197e-06
sam_encoder.blocks.2.norm2.bias grad: -3.7766501463920576e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.8139992284413893e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.1765396266127937e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.147875642956933e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.9097692529612686e-06
sam_encoder.blocks.3.norm1.weight grad: -5.65825030207634e-06
sam_encoder.blocks.3.norm1.bias grad: -6.655678134848131e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.606067578715738e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5456806750080432e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.15320937463548e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8664331946638413e-06
sam_encoder.blocks.3.norm2.weight grad: 6.290309102041647e-06
sam_encoder.blocks.3.norm2.bias grad: -3.2606847071292577e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.1211178540834226e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.880402805909398e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.894393901442527e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.519616254583525e-07
sam_encoder.blocks.4.norm1.weight grad: 1.0504463716642931e-05
sam_encoder.blocks.4.norm1.bias grad: -4.207622623653151e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.4700805170141393e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.744023153260059e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.9667695596581325e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.3279560537048383e-06
sam_encoder.blocks.4.norm2.weight grad: -3.3291958970949054e-05
sam_encoder.blocks.4.norm2.bias grad: -2.263015448988881e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.3555043298983946e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.87148689798778e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 8.965536721916578e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.814526164409472e-07
sam_encoder.blocks.5.norm1.weight grad: 1.8074858587624476e-07
sam_encoder.blocks.5.norm1.bias grad: -1.5048695786390454e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.3693795558065176e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.2745660973887425e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.774847184307873e-09
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.82455117587233e-07
sam_encoder.blocks.5.norm2.weight grad: -1.597047594259493e-05
sam_encoder.blocks.5.norm2.bias grad: -1.2909815268358216e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.295624527614564e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.317474582014256e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.3154084399502608e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.693789272394497e-06
sam_encoder.blocks.6.norm1.weight grad: 2.9351256216614274e-06
sam_encoder.blocks.6.norm1.bias grad: 1.3888060266253888e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.792504346871283e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.3168824959138874e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.607004151082947e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.896403187463875e-07
sam_encoder.blocks.6.norm2.weight grad: -1.1292002454865724e-05
sam_encoder.blocks.6.norm2.bias grad: -3.2656821531418245e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.71049542183755e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.2237102206854615e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.8936771084554493e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.461538752475462e-07
sam_encoder.blocks.7.norm1.weight grad: 3.7899858398304787e-06
sam_encoder.blocks.7.norm1.bias grad: 3.279722022853093e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.8217178876511753e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0616290637699421e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.15908925030817e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2708745771305985e-06
sam_encoder.blocks.7.norm2.weight grad: 2.060783572233049e-06
sam_encoder.blocks.7.norm2.bias grad: 2.217542487414903e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.3081378256174503e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.319867674799752e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4187429542289465e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.953638257480634e-07
sam_encoder.blocks.8.norm1.weight grad: 2.2537101358466316e-06
sam_encoder.blocks.8.norm1.bias grad: -3.7848926695005503e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.006146360145067e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.5899963727861177e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.582759750817786e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.9270071334176464e-06
sam_encoder.blocks.8.norm2.weight grad: -4.815995453100186e-06
sam_encoder.blocks.8.norm2.bias grad: -1.7952613688976271e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.549059212877182e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.4780961211945396e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.6396386399719631e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2038360637234291e-06
sam_encoder.blocks.9.norm1.weight grad: -4.150761014898308e-06
sam_encoder.blocks.9.norm1.bias grad: 3.420768450723699e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.986356659879675e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.154215945272881e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.377607976697618e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.519451514781395e-07
sam_encoder.blocks.9.norm2.weight grad: -2.6886473278864287e-06
sam_encoder.blocks.9.norm2.bias grad: -1.5193930948953493e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.4432711143163033e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.61369132456457e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.7178945199702866e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.978452802286483e-07
sam_encoder.blocks.10.norm1.weight grad: 2.9487382562365383e-06
sam_encoder.blocks.10.norm1.bias grad: 6.841261779300112e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.9927410903619602e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.682835641593556e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7022078964146203e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0158863688047859e-06
sam_encoder.blocks.10.norm2.weight grad: -5.075095032225363e-06
sam_encoder.blocks.10.norm2.bias grad: -2.1981445570418146e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.0507061435637297e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.621157025510911e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.281306481359934e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.760697139427066e-07
sam_encoder.blocks.11.norm1.weight grad: 2.7166195195604814e-06
sam_encoder.blocks.11.norm1.bias grad: 1.2800753665942466e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.4642104108352214e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.450038997878437e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.099314087899984e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.280580345854105e-07
sam_encoder.blocks.11.norm2.weight grad: -4.755226655106526e-06
sam_encoder.blocks.11.norm2.bias grad: -3.7103363865753636e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.056387986864138e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.1903139238711447e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.395157695100352e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.381492312357295e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0378735169069842e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.7984739315579645e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.0729872883530334e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.066428457212169e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001595511712366715
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2078453437425196e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004251112230122089
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005091545172035694
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011465106945252046
mask_decoder.transformer.layers.0.norm3.bias grad: -9.971565305022523e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00015229915152303874
mask_decoder.transformer.layers.0.norm4.bias grad: -4.477457423490705e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.159846139373258e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.8552127585280687e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -9.772233897820115e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.318718881928362e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 7.046673272270709e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.3979576983256266e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.6371137462556362e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00023081964172888547
mask_decoder.transformer.norm_final_attn.weight grad: 8.960061677498743e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.4271375878015533e-05
Text_Embedding_Affine.0.weight grad: 8.806167600683423e-13
Text_Embedding_Affine.0.bias grad: 9.709713588712532e-11
Text_Embedding_Affine.2.weight grad: 5.770433436635969e-11
Text_Embedding_Affine.2.bias grad: 3.56166492565535e-05
Epoch 11 finished with average loss: -61.2628
Epoch 12/39
----------
Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.3]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-56.3]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-61.7]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-61.7]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-62.8]Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-62.8]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.15208966776485e-22
Max value: 0.9999985694885254
Mean value: 0.07687561213970184

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.15208966776485e-22
Max value: 0.9999985694885254
Mean value: 0.07687561213970184

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07888221740722656

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13262948393821716

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0694422721862793

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07888221740722656

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.192394256591797
Max value: 89.30380249023438
Mean value: 56.259437561035156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.15208966776485e-22
Max value: 0.9999985694885254
Mean value: 0.07687561213970184

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.15208966776485e-22
Max value: 0.9999985694885254
Mean value: 0.07687561213970184

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.15208966776485e-22
Max value: 0.9999985694885254
Mean value: 0.07687561213970184

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13262948393821716

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.192394256591797
Max value: 89.30380249023438
Mean value: 56.259437561035156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.26027297973633
Max value: -56.26027297973633
Mean value: -56.26027297973633
sam_encoder.pos_embed grad: 3.0415854279652876e-09
sam_encoder.blocks.0.norm1.weight grad: 4.6294648200273514e-05
sam_encoder.blocks.0.norm1.bias grad: -4.1280462028225884e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.228768249158747e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.400981256618252e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.575433755846461e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0739434941342552e-07
sam_encoder.blocks.0.norm2.weight grad: 2.9846924007870257e-05
sam_encoder.blocks.0.norm2.bias grad: -2.9077320505166426e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.7533395293867216e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.2498124963021837e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.6346282538725063e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.4075309081817977e-05
sam_encoder.blocks.1.norm1.weight grad: 1.4501585610560142e-05
sam_encoder.blocks.1.norm1.bias grad: 1.7709538951748982e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.317706265690504e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.9981943043821957e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.12716132006608e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.203329237701837e-06
sam_encoder.blocks.1.norm2.weight grad: -1.1706864825100638e-05
sam_encoder.blocks.1.norm2.bias grad: 5.238976882537827e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.227096259361133e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.116491032211343e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.578575756866485e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.378796110264375e-07
sam_encoder.blocks.2.norm1.weight grad: -3.2535349419049453e-06
sam_encoder.blocks.2.norm1.bias grad: -3.0180115118128015e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.156890099693555e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.839398630134383e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.0865053354791598e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 6.710895377182169e-07
sam_encoder.blocks.2.norm2.weight grad: -1.1793576049967669e-05
sam_encoder.blocks.2.norm2.bias grad: 1.126692040998023e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0891430065385066e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.990270099369809e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.853713213989977e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3426986242848216e-06
sam_encoder.blocks.3.norm1.weight grad: 1.3598136092696222e-06
sam_encoder.blocks.3.norm1.bias grad: -5.464850687530998e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.190392246528063e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.729872671305202e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.1944065363422851e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.1562270831054775e-06
sam_encoder.blocks.3.norm2.weight grad: -1.2375930054986384e-05
sam_encoder.blocks.3.norm2.bias grad: 1.3949595086160116e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.43927227833774e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.523901230233605e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.633781933691353e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.885570761980489e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0250098057440482e-05
sam_encoder.blocks.4.norm1.bias grad: -1.305273144680541e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.02333535021171e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1798272225860273e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.7522014534042682e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.3655908333021216e-06
sam_encoder.blocks.4.norm2.weight grad: 2.3894323021522723e-05
sam_encoder.blocks.4.norm2.bias grad: 1.2425594832166098e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.4903254850651138e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.627043719869107e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.541857035495923e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.1504882877488853e-06
sam_encoder.blocks.5.norm1.weight grad: -2.7362764285498997e-06
sam_encoder.blocks.5.norm1.bias grad: 1.211497760778002e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.1774088761740131e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.4539938294765307e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.9119908049324295e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.035321575836861e-07
sam_encoder.blocks.5.norm2.weight grad: 1.5799112588865682e-05
sam_encoder.blocks.5.norm2.bias grad: 6.139279776107287e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.434936610981822e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.2429705950344214e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.6759041702462127e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.9332010197103955e-06
sam_encoder.blocks.6.norm1.weight grad: -3.1008362384454813e-06
sam_encoder.blocks.6.norm1.bias grad: -3.001689037773758e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 9.068116924026981e-09
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.1251288469793508e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3446559705698746e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.7079419118745136e-07
sam_encoder.blocks.6.norm2.weight grad: 1.453810455132043e-06
sam_encoder.blocks.6.norm2.bias grad: 6.113288577580533e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.8718571936915396e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.8115112488412706e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.7044424655287003e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.3623837819286564e-07
sam_encoder.blocks.7.norm1.weight grad: -1.9325716493767686e-06
sam_encoder.blocks.7.norm1.bias grad: -2.0244260667823255e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.2479652014008025e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.756177862778713e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.081798982089822e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.269092642061878e-06
sam_encoder.blocks.7.norm2.weight grad: -4.379775418783538e-06
sam_encoder.blocks.7.norm2.bias grad: 7.307918963306292e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.004785857134266e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.3610487005498726e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.4558769123595994e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.646939081951132e-08
sam_encoder.blocks.8.norm1.weight grad: -3.1169863632385386e-06
sam_encoder.blocks.8.norm1.bias grad: 7.81830692631047e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.724502211203799e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.313778561026993e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.6923363495589e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.2590239698038204e-06
sam_encoder.blocks.8.norm2.weight grad: -1.4974066289141774e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4148540117275843e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.566700797819067e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.157620656362269e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.078229262129753e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.709586841679993e-07
sam_encoder.blocks.9.norm1.weight grad: 2.275604856549762e-06
sam_encoder.blocks.9.norm1.bias grad: -6.007280717312824e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.3547917205869453e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.094866193961934e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.105108241172275e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.916084427961323e-07
sam_encoder.blocks.9.norm2.weight grad: 2.7404411184761557e-07
sam_encoder.blocks.9.norm2.bias grad: 8.140797831401869e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.0075311769905966e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.231978103533038e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.676362881487876e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.319303444499383e-07
sam_encoder.blocks.10.norm1.weight grad: -4.1721577872522175e-06
sam_encoder.blocks.10.norm1.bias grad: -7.379832140941289e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.5311633180535864e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.0634984164425987e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4496762332782964e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.409815517192328e-07
sam_encoder.blocks.10.norm2.weight grad: -3.697311399264436e-07
sam_encoder.blocks.10.norm2.bias grad: 1.3615933767141541e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.4092604437319096e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.5610139598720707e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.457250816855776e-09
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.4325976606151016e-08
sam_encoder.blocks.11.norm1.weight grad: -2.1162826669751666e-05
sam_encoder.blocks.11.norm1.bias grad: -1.7488904404672212e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.6210942628022167e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.250825955092296e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1986608114966657e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.704945232944738e-07
sam_encoder.blocks.11.norm2.weight grad: 3.685267415676208e-07
sam_encoder.blocks.11.norm2.bias grad: -4.2382816900499165e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.169690997623547e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.8017592512696865e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.7385132196068298e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.593040886102244e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.568931662011892e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.3907927243271843e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0049847080372274e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.682131813955493e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00013885970111005008
mask_decoder.transformer.layers.0.norm1.bias grad: 8.104871085379273e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004682494327425957
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0009762663394212723
mask_decoder.transformer.layers.0.norm3.weight grad: 6.885633774800226e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.4290402001934126e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013739182031713426
mask_decoder.transformer.layers.0.norm4.bias grad: 1.573180634295568e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -6.328219569695648e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -7.3007840910577215e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00021566473878920078
mask_decoder.transformer.layers.1.norm2.bias grad: 6.140150071587414e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.776203680492472e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.465756880264962e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 4.704085222329013e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00020700876484625041
mask_decoder.transformer.norm_final_attn.weight grad: -1.15067666683899e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.11891868073144e-05
Text_Embedding_Affine.0.weight grad: -5.989156653257721e-13
Text_Embedding_Affine.0.bias grad: 1.2352135980719936e-10
Text_Embedding_Affine.2.weight grad: -2.7294494442386963e-10
Text_Embedding_Affine.2.bias grad: -5.70353222428821e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.634455633378891e-32
Max value: 1.0
Mean value: 0.08056779205799103

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.634455633378891e-32
Max value: 1.0
Mean value: 0.08056779205799103

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08608818054199219

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15457427501678467

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07837438583374023

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08608818054199219

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 58.273563385009766
Max value: 79.84586334228516
Mean value: 67.06195068359375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.98923191702241e-30
Max value: 1.0
Mean value: 0.08046011626720428

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.98923191702241e-30
Max value: 1.0
Mean value: 0.08046011626720428

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.98923191702241e-30
Max value: 1.0
Mean value: 0.08046011626720428

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1512467861175537

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.930654764175415
Max value: 2.6626031398773193
Mean value: 1.0039933919906616

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 58.273563385009766
Max value: 79.84586334228516
Mean value: 67.06195068359375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.23006439208984
Max value: -67.23006439208984
Mean value: -67.23006439208984
sam_encoder.pos_embed grad: -2.879207983141896e-09
sam_encoder.blocks.0.norm1.weight grad: 9.82476649369346e-06
sam_encoder.blocks.0.norm1.bias grad: 8.760893251746893e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -8.267276712103921e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.810349014088388e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.817933818732854e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.713188144795822e-08
sam_encoder.blocks.0.norm2.weight grad: -6.006975127093028e-06
sam_encoder.blocks.0.norm2.bias grad: -9.413521183887497e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.3907495031162398e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.277908480318729e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.466165849706158e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.0850878879864467e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2356787237877143e-06
sam_encoder.blocks.1.norm1.bias grad: 2.7048135962104425e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.4882286854553968e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.770400311026606e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.647925384735572e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1379628404029063e-06
sam_encoder.blocks.1.norm2.weight grad: -1.5584334960294655e-06
sam_encoder.blocks.1.norm2.bias grad: 2.488476184225874e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.5304433418350527e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.591743956756545e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.5866698883401114e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.4641752841271227e-06
sam_encoder.blocks.2.norm1.weight grad: 1.6349926227121614e-05
sam_encoder.blocks.2.norm1.bias grad: -4.0781687857816e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.043477823259309e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.8790555031955591e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.232327690559032e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 8.292824986710912e-07
sam_encoder.blocks.2.norm2.weight grad: -2.5199283300025854e-06
sam_encoder.blocks.2.norm2.bias grad: 1.2714708645944484e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.420283007926628e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.483170649407839e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2049604265484959e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.614732678324799e-07
sam_encoder.blocks.3.norm1.weight grad: -7.755606361570244e-07
sam_encoder.blocks.3.norm1.bias grad: -4.652285952033708e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1334308283039718e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.6312010226756684e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.472090490206028e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.6611511455266736e-07
sam_encoder.blocks.3.norm2.weight grad: 2.1114067294547567e-06
sam_encoder.blocks.3.norm2.bias grad: 2.6412715214974014e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.3627098951474181e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.0991009225544985e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.488280071906047e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.957803068667999e-07
sam_encoder.blocks.4.norm1.weight grad: 7.441529305651784e-06
sam_encoder.blocks.4.norm1.bias grad: -2.7904678745471756e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.1613105875294423e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0163512342842296e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.0089863685134333e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.47532625508029e-06
sam_encoder.blocks.4.norm2.weight grad: -1.798839912225958e-05
sam_encoder.blocks.4.norm2.bias grad: -9.579370271239895e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1743699360522442e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.6487524539552396e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.711356152460212e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.552154220822558e-07
sam_encoder.blocks.5.norm1.weight grad: 2.8191865908411273e-07
sam_encoder.blocks.5.norm1.bias grad: -2.447538008709671e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.876109743345296e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.580422334285686e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.0202343168639345e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.2107026325102197e-06
sam_encoder.blocks.5.norm2.weight grad: -1.3111661246512085e-05
sam_encoder.blocks.5.norm2.bias grad: -7.79798392613884e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.277706804918125e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2697312286036322e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.415097348304698e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.833404088662064e-07
sam_encoder.blocks.6.norm1.weight grad: 2.736324859142769e-06
sam_encoder.blocks.6.norm1.bias grad: 3.6281035136198625e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.60951326886061e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.69880147749791e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3593953553936444e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.1402448169283161e-07
sam_encoder.blocks.6.norm2.weight grad: -7.0369096647482365e-06
sam_encoder.blocks.6.norm2.bias grad: -1.7600202681933297e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.38641211783397e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.3999990642332705e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.034590688206663e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.578048565737845e-07
sam_encoder.blocks.7.norm1.weight grad: -1.4338633036459214e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4690758689539507e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.681510396650992e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.7668287095348205e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.706508308227058e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.4597511583124287e-08
sam_encoder.blocks.7.norm2.weight grad: 2.866959675884573e-06
sam_encoder.blocks.7.norm2.bias grad: 1.6799815512058558e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.233966370113194e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.0517441069168854e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.240789278104785e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.197326859411987e-07
sam_encoder.blocks.8.norm1.weight grad: -3.441712351559545e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0452816923134378e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.056132522440748e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.2447065930464305e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.829598184296628e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.068011528104762e-07
sam_encoder.blocks.8.norm2.weight grad: 6.703445478706271e-07
sam_encoder.blocks.8.norm2.bias grad: -7.000105028964754e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.0169163715545437e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.499235721297737e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.6101829437029664e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.358342214847653e-07
sam_encoder.blocks.9.norm1.weight grad: -4.41485963165178e-06
sam_encoder.blocks.9.norm1.bias grad: 5.581895266004722e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.265396000846522e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.87791009315697e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.692026323027676e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1719969279511133e-06
sam_encoder.blocks.9.norm2.weight grad: -8.637407518108375e-07
sam_encoder.blocks.9.norm2.bias grad: -1.2844642469644896e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.1063185562961735e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.479530275602883e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.1660343918483704e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.600490347504092e-07
sam_encoder.blocks.10.norm1.weight grad: 1.987653149626567e-06
sam_encoder.blocks.10.norm1.bias grad: -7.06817161244544e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 9.882271569949808e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.862563625669281e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2659446610996383e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.217390927711676e-07
sam_encoder.blocks.10.norm2.weight grad: -4.019784398678894e-07
sam_encoder.blocks.10.norm2.bias grad: -3.9543209595649387e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.2605540784279583e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.170959411771037e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.019979193501058e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.057180262861948e-07
sam_encoder.blocks.11.norm1.weight grad: 1.8923783500213176e-06
sam_encoder.blocks.11.norm1.bias grad: -1.414591110915353e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.0986601561598945e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.964504907751689e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.371649199834792e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.0718563248655073e-09
sam_encoder.blocks.11.norm2.weight grad: 1.5080125876920647e-06
sam_encoder.blocks.11.norm2.bias grad: -1.3938446272732108e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.8469580684031826e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.021115506067872e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7059176116163144e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.1390573817493532e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.1945273804012686e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.107159914681688e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.847474989830516e-07
sam_encoder.neck.conv2.trainable_shift grad: 7.8938919614302e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018627275130711496
mask_decoder.transformer.layers.0.norm1.bias grad: 4.0951999835669994e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00398441543802619
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005080575938336551
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011127578909508884
mask_decoder.transformer.layers.0.norm3.bias grad: -6.919563020346686e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.886629464337602e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.246282282518223e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.077573248650879e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.1323648979887366e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00012153286661487073
mask_decoder.transformer.layers.1.norm2.bias grad: 9.051903907675296e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.7518915380351245e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.5666958612855524e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.26873957621865e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018382308189757168
mask_decoder.transformer.norm_final_attn.weight grad: 7.423416718665976e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.3953434972791001e-05
Text_Embedding_Affine.0.weight grad: 1.0496568891849023e-11
Text_Embedding_Affine.0.bias grad: 3.224177036464937e-10
Text_Embedding_Affine.2.weight grad: 4.080040125198359e-11
Text_Embedding_Affine.2.bias grad: 3.072603067266755e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08528692275285721

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08528692275285721

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08905982971191406

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17205336689949036

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08493804931640625

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08905982971191406

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.715328216552734
Max value: 72.75235748291016
Mean value: 64.66241455078125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0978414524736663e-37
Max value: 0.9999998807907104
Mean value: 0.08523637056350708

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0978414524736663e-37
Max value: 0.9999998807907104
Mean value: 0.08523637056350708

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0978414524736663e-37
Max value: 0.9999998807907104
Mean value: 0.08523637056350708

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1635233759880066

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8685418963432312
Max value: 11.768847465515137
Mean value: 1.0138752460479736

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.715328216552734
Max value: 72.75235748291016
Mean value: 64.66241455078125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.87046813964844
Max value: -64.87046813964844
Mean value: -64.87046813964844
sam_encoder.pos_embed grad: -2.0997183991511292e-09
sam_encoder.blocks.0.norm1.weight grad: 1.955941115738824e-05
sam_encoder.blocks.0.norm1.bias grad: 2.11509432119783e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.8751313746179221e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.505199745428399e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.917318167623307e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.2194423959499545e-07
sam_encoder.blocks.0.norm2.weight grad: 4.509277641773224e-05
sam_encoder.blocks.0.norm2.bias grad: 2.0927220703015337e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.12951907896786e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.4297083339442906e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.190664059133269e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.6600706582466955e-07
sam_encoder.blocks.1.norm1.weight grad: -3.13228701998014e-06
sam_encoder.blocks.1.norm1.bias grad: 2.870989874281804e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.5337387771505746e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.9380037719638494e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.7451567348180106e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.1355311926308786e-06
sam_encoder.blocks.1.norm2.weight grad: 4.664905645768158e-06
sam_encoder.blocks.1.norm2.bias grad: 3.018696588696912e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.3335684343473986e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.999735724846687e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.70830774854403e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.2539743440574966e-06
sam_encoder.blocks.2.norm1.weight grad: -2.8510121410363354e-06
sam_encoder.blocks.2.norm1.bias grad: -7.594432531732309e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.994452759390697e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7153911358036567e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.346848072600551e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.9571917821158422e-06
sam_encoder.blocks.2.norm2.weight grad: -1.283944584429264e-06
sam_encoder.blocks.2.norm2.bias grad: -8.129772140819114e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.3041893680565408e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.144340313265275e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.5781947644863976e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4059914974495769e-06
sam_encoder.blocks.3.norm1.weight grad: 8.420590233981784e-07
sam_encoder.blocks.3.norm1.bias grad: -6.764119007129921e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.34085586675792e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.0472093663338455e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.124013008142356e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.4793202751661738e-07
sam_encoder.blocks.3.norm2.weight grad: 1.715099460852798e-05
sam_encoder.blocks.3.norm2.bias grad: 1.3412443422566867e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2224059901200235e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.777411504619522e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.582789981417591e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.499682854155253e-07
sam_encoder.blocks.4.norm1.weight grad: 1.3020722690271214e-05
sam_encoder.blocks.4.norm1.bias grad: -2.2234867174120154e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.440274773922283e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.3340282950812252e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.5970781532814726e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.6759203137771692e-06
sam_encoder.blocks.4.norm2.weight grad: -3.243410537834279e-05
sam_encoder.blocks.4.norm2.bias grad: -1.8973547412315384e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.3463730030925944e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.42698136693798e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.8794339666783344e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4278286926128203e-06
sam_encoder.blocks.5.norm1.weight grad: 6.148375177872367e-07
sam_encoder.blocks.5.norm1.bias grad: -1.5351928595919162e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.895663429735578e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.091512538361712e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.253117241314612e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.0583141829556553e-06
sam_encoder.blocks.5.norm2.weight grad: -1.4706742149428464e-05
sam_encoder.blocks.5.norm2.bias grad: -7.199651008704677e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.744587153661996e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.240218691440532e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.827793749333068e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.585576848763594e-07
sam_encoder.blocks.6.norm1.weight grad: -2.016798134718556e-06
sam_encoder.blocks.6.norm1.bias grad: 6.507791283638653e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.978845127989189e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.653817419850384e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.166813903973889e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.950719360545918e-07
sam_encoder.blocks.6.norm2.weight grad: -9.366227459395304e-06
sam_encoder.blocks.6.norm2.bias grad: -1.599051302036969e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.928826678631594e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.2057612315838924e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.004406832791574e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.9547140911745373e-07
sam_encoder.blocks.7.norm1.weight grad: -8.82695189829974e-07
sam_encoder.blocks.7.norm1.bias grad: 2.1283794922055677e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.5150193348745233e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.398574198674396e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.459366209630389e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.6382562080252683e-06
sam_encoder.blocks.7.norm2.weight grad: 4.141050339967478e-06
sam_encoder.blocks.7.norm2.bias grad: 1.1473139238660224e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.533061660869862e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.96391692195175e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.685266657451393e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.113776614327435e-08
sam_encoder.blocks.8.norm1.weight grad: 4.133009042561753e-06
sam_encoder.blocks.8.norm1.bias grad: -1.5117425391508732e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.2207099138759077e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.168554247982684e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.3102666116537875e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.306135903992981e-07
sam_encoder.blocks.8.norm2.weight grad: -3.0985463581600925e-06
sam_encoder.blocks.8.norm2.bias grad: -2.0369416233734228e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.1627666885469807e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.843753807406756e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.62867375164933e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.623604693028028e-07
sam_encoder.blocks.9.norm1.weight grad: -4.82430823467439e-06
sam_encoder.blocks.9.norm1.bias grad: 6.400977099474403e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.6701152314199135e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.5607363366143545e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.2150828752055531e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5508385331486352e-06
sam_encoder.blocks.9.norm2.weight grad: -3.9608776205568574e-06
sam_encoder.blocks.9.norm2.bias grad: -2.5579436169209657e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.994685019075405e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.24822542804759e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.757274715913809e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.628362712035596e-07
sam_encoder.blocks.10.norm1.weight grad: 1.855229811553727e-06
sam_encoder.blocks.10.norm1.bias grad: -3.1742317219141114e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1982597243331838e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.277799459690868e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.097586732612399e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.116444405459333e-07
sam_encoder.blocks.10.norm2.weight grad: -6.9188808993203565e-06
sam_encoder.blocks.10.norm2.bias grad: -3.1527251849183813e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.4479440980940126e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.1886485228606034e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3506305549526587e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.336880341630604e-07
sam_encoder.blocks.11.norm1.weight grad: 8.23172740638256e-06
sam_encoder.blocks.11.norm1.bias grad: -5.937231435382273e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.028842118306784e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.541877605239279e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.1272148842399474e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0756230039987713e-06
sam_encoder.blocks.11.norm2.weight grad: -4.434524726093514e-06
sam_encoder.blocks.11.norm2.bias grad: -3.7424792935780715e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.190340968714736e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4349047887662891e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.356810457764368e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.4271425281294796e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.600250112067442e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.090706791728735e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.050111889839172e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.8464080716948956e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002334571472601965
mask_decoder.transformer.layers.0.norm1.bias grad: 2.027663867920637e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0033819021191447973
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006821205606684089
mask_decoder.transformer.layers.0.norm3.weight grad: -7.938507769722492e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.688095239340328e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.928154031513259e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.145946488482878e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.540308534866199e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.4885102902771905e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001198515819851309
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011127427569590509
mask_decoder.transformer.layers.1.norm3.weight grad: 5.851172318216413e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.052861160947941e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.5258060961496085e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016223131387960166
mask_decoder.transformer.norm_final_attn.weight grad: 8.429706213064492e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.803527629817836e-05
Text_Embedding_Affine.0.weight grad: -1.6722972832894367e-12
Text_Embedding_Affine.0.bias grad: -1.3779097307597965e-10
Text_Embedding_Affine.2.weight grad: 1.4534487502437798e-10
Text_Embedding_Affine.2.bias grad: 4.316236299928278e-05
Epoch 12 finished with average loss: -62.7869
Epoch 13/39
----------
Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/3 [00:01<?, ?it/s, loss=-59.3]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-59.3]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-56.6]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-56.6]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-58.8]Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-58.8]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.053906453710582e-25
Max value: 0.9999994039535522
Mean value: 0.09409936517477036

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.053906453710582e-25
Max value: 0.9999994039535522
Mean value: 0.09409936517477036

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08904075622558594

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15163271129131317

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08637857437133789

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08904075622558594

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.757476806640625
Max value: 76.5275650024414
Mean value: 59.26495361328125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.053906453710582e-25
Max value: 0.9999994039535522
Mean value: 0.09409936517477036

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.053906453710582e-25
Max value: 0.9999994039535522
Mean value: 0.09409936517477036

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.053906453710582e-25
Max value: 0.9999994039535522
Mean value: 0.09409936517477036

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15163271129131317

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.757476806640625
Max value: 76.5275650024414
Mean value: 59.26495361328125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.26593780517578
Max value: -59.26593780517578
Mean value: -59.26593780517578
sam_encoder.pos_embed grad: 5.476686659733332e-09
sam_encoder.blocks.0.norm1.weight grad: -1.8348593584960327e-05
sam_encoder.blocks.0.norm1.bias grad: -3.3802749385358766e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.202287295309361e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.184794460433295e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.271415936178528e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.745489382505184e-06
sam_encoder.blocks.0.norm2.weight grad: -5.448543743113987e-05
sam_encoder.blocks.0.norm2.bias grad: 3.9479913539253175e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.915841706562787e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.381758233444998e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.673619044595398e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.834718427242478e-06
sam_encoder.blocks.1.norm1.weight grad: 4.531670128926635e-06
sam_encoder.blocks.1.norm1.bias grad: 9.75969851424452e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.655415412140428e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.3332586377146072e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.7411506380303763e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4202481679603807e-06
sam_encoder.blocks.1.norm2.weight grad: 1.9234885257901624e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0688230759114958e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.077932301996043e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.7364450236054836e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.2009429156023543e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.241396825615084e-06
sam_encoder.blocks.2.norm1.weight grad: -9.456153748033103e-06
sam_encoder.blocks.2.norm1.bias grad: 6.767503691662569e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.163147190818563e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.429267381870886e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.049822902947199e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.814409072016133e-06
sam_encoder.blocks.2.norm2.weight grad: 1.8595084839034826e-05
sam_encoder.blocks.2.norm2.bias grad: 1.0665112313290592e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.349475476483349e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.930404545826605e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.831570549868047e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.119176204156247e-06
sam_encoder.blocks.3.norm1.weight grad: 8.397636520385277e-06
sam_encoder.blocks.3.norm1.bias grad: -1.575758460603538e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.7568821931490675e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.226004082534928e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.614660146122333e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.914527042070404e-06
sam_encoder.blocks.3.norm2.weight grad: -1.773614712874405e-06
sam_encoder.blocks.3.norm2.bias grad: -6.641012987529393e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.4443861573454342e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.68840367931989e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.942918844288215e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.6452316913273535e-06
sam_encoder.blocks.4.norm1.weight grad: -1.9459992472548038e-05
sam_encoder.blocks.4.norm1.bias grad: -6.515289896924514e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.699257134343497e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.225983603755594e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.496362402685918e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.3196590720763197e-06
sam_encoder.blocks.4.norm2.weight grad: 4.933745367452502e-05
sam_encoder.blocks.4.norm2.bias grad: 2.2352644009515643e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.134778671665117e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.0090240721183363e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.5626893552253023e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.1623519640124869e-06
sam_encoder.blocks.5.norm1.weight grad: -8.176588380592875e-06
sam_encoder.blocks.5.norm1.bias grad: 2.1755108718934935e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.036248123564292e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.9686407881636114e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.644273526035249e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.691844762623077e-06
sam_encoder.blocks.5.norm2.weight grad: 3.3071723009925336e-05
sam_encoder.blocks.5.norm2.bias grad: 1.1822725355159491e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.1642509889497887e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.81256063519686e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.6013766475662123e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.019928388108383e-06
sam_encoder.blocks.6.norm1.weight grad: -2.538353783165803e-06
sam_encoder.blocks.6.norm1.bias grad: -5.7359020502190106e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.0851958904822823e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.6594843802740797e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.533826662125648e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.2535997484519612e-07
sam_encoder.blocks.6.norm2.weight grad: 1.9000721295014955e-05
sam_encoder.blocks.6.norm2.bias grad: 5.141578640177613e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.734723789733835e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.653063115256373e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7741662077241926e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0747938858912676e-06
sam_encoder.blocks.7.norm1.weight grad: -4.434792515439767e-07
sam_encoder.blocks.7.norm1.bias grad: -1.6611511455266736e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.032763066177722e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.40432779416733e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.727849957613216e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.368930947544868e-06
sam_encoder.blocks.7.norm2.weight grad: 3.6214623833075166e-06
sam_encoder.blocks.7.norm2.bias grad: -3.2621226182527607e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.06336312910571e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.550518729549367e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.7361589849970187e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.566111104191805e-07
sam_encoder.blocks.8.norm1.weight grad: -5.11958523929934e-06
sam_encoder.blocks.8.norm1.bias grad: 2.123520516761346e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.974325980176218e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.1706117675203132e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.3689802876324393e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.2461958906205837e-06
sam_encoder.blocks.8.norm2.weight grad: 3.773507160076406e-07
sam_encoder.blocks.8.norm2.bias grad: 1.5140689129111706e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.1648202164215036e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.656282103747799e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.1651976567227393e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.235769435785187e-07
sam_encoder.blocks.9.norm1.weight grad: 1.677835825830698e-06
sam_encoder.blocks.9.norm1.bias grad: -2.53082134804572e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.600286961751408e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.489309736120049e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.504165751015535e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.257869351131376e-07
sam_encoder.blocks.9.norm2.weight grad: 2.0034417502756696e-06
sam_encoder.blocks.9.norm2.bias grad: 2.8859662961622234e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.1297448711266043e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.4006669358841464e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.597934783603705e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.1864840604735036e-08
sam_encoder.blocks.10.norm1.weight grad: -5.298274118104018e-06
sam_encoder.blocks.10.norm1.bias grad: -5.111083822839646e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.010242724281852e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1092979548266158e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.5162589761530398e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.120186870044563e-07
sam_encoder.blocks.10.norm2.weight grad: 2.8633439796976745e-07
sam_encoder.blocks.10.norm2.bias grad: 2.5240906325052492e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.291825916880043e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -8.186338504856394e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.353737727389671e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.878702040718053e-07
sam_encoder.blocks.11.norm1.weight grad: -5.8145428738498595e-06
sam_encoder.blocks.11.norm1.bias grad: -7.318198527173081e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.189314727729652e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.0315611588303e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.3203883781898185e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.224825028766645e-07
sam_encoder.blocks.11.norm2.weight grad: -4.857324711338151e-06
sam_encoder.blocks.11.norm2.bias grad: 8.503740787091374e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.198442522669211e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -9.79778064902348e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.796869582904037e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.2164296587543504e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.280206434894353e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.154701178369578e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.119955413741991e-06
sam_encoder.neck.conv2.trainable_shift grad: 5.2909672376699746e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 8.0550838902127e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.125169314444065e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004958346951752901
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0006513211410492659
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00011139022535644472
mask_decoder.transformer.layers.0.norm3.bias grad: 3.772661148104817e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00014932279009371996
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2939852240378968e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.1280971850501373e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.1506057237274945e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.635647201212123e-06
mask_decoder.transformer.layers.1.norm2.bias grad: -6.887306517455727e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.2567087550414726e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.957246372010559e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00010382341861259192
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002559340209700167
mask_decoder.transformer.norm_final_attn.weight grad: 2.7988471629214473e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.5043258372315904e-06
Text_Embedding_Affine.0.weight grad: 3.113060156878511e-12
Text_Embedding_Affine.0.bias grad: 3.058239772535387e-11
Text_Embedding_Affine.2.weight grad: -6.88302609352931e-11
Text_Embedding_Affine.2.bias grad: -3.2596144592389464e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.453559678093198e-20
Max value: 0.9999911785125732
Mean value: 0.07117943465709686

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.453559678093198e-20
Max value: 0.9999911785125732
Mean value: 0.07117943465709686

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07458782196044922

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13900408148765564

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06717157363891602

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07458782196044922

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 32.04831314086914
Max value: 89.24054718017578
Mean value: 53.84251022338867

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.219484205865435e-19
Max value: 0.999983549118042
Mean value: 0.07136543840169907

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.219484205865435e-19
Max value: 0.999983549118042
Mean value: 0.07136543840169907

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.219484205865435e-19
Max value: 0.999983549118042
Mean value: 0.07136543840169907

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13672450184822083

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.900126576423645
Max value: 3.485084295272827
Mean value: 1.0028988122940063

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 32.04831314086914
Max value: 89.24054718017578
Mean value: 53.84251022338867

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.931766510009766
Max value: -53.931766510009766
Mean value: -53.931766510009766
sam_encoder.pos_embed grad: 3.141308990706193e-09
sam_encoder.blocks.0.norm1.weight grad: 1.75551886059111e-05
sam_encoder.blocks.0.norm1.bias grad: 3.6282759538153186e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.1156787422805792e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.9452334021916613e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.0394670008936373e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.405614385585068e-07
sam_encoder.blocks.0.norm2.weight grad: 1.3517385923478287e-05
sam_encoder.blocks.0.norm2.bias grad: 1.8649230696610175e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.75518492446281e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.130276465730276e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.449899046856444e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.4336577553185634e-06
sam_encoder.blocks.1.norm1.weight grad: 5.240116934146499e-06
sam_encoder.blocks.1.norm1.bias grad: 4.016280399810057e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.187756192346569e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1437176681283745e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.078116035088897e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.658474502619356e-06
sam_encoder.blocks.1.norm2.weight grad: 9.150329788099043e-06
sam_encoder.blocks.1.norm2.bias grad: 1.9224914638016344e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.7565062080393545e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.7636725146985555e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.303916961769573e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.537341843999457e-07
sam_encoder.blocks.2.norm1.weight grad: 6.095616754464572e-06
sam_encoder.blocks.2.norm1.bias grad: -1.7045181266439613e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.9275302040332463e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.538148227264173e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.254280495137209e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.8004858450003667e-06
sam_encoder.blocks.2.norm2.weight grad: -8.347727998625487e-06
sam_encoder.blocks.2.norm2.bias grad: -5.4382553571485914e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.4912376324646175e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.990651526284637e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.1567805106315063e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6045548818510724e-06
sam_encoder.blocks.3.norm1.weight grad: -7.201549578894628e-06
sam_encoder.blocks.3.norm1.bias grad: -5.063742264610482e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.0921275942528155e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.827199392020702e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.173858658556128e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.369761998328613e-07
sam_encoder.blocks.3.norm2.weight grad: 7.030770120763918e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1747752068913542e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.117635621194495e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.2898167319217464e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.4390086511848494e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2874145340902032e-06
sam_encoder.blocks.4.norm1.weight grad: 2.6468892428965773e-06
sam_encoder.blocks.4.norm1.bias grad: 8.407535460719373e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.9803990742038877e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4895834965500399e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.568412066419114e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.944660988963733e-07
sam_encoder.blocks.4.norm2.weight grad: -1.7875672710943036e-05
sam_encoder.blocks.4.norm2.bias grad: -1.2323623195698019e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.207556761073647e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.364437700132839e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.146506514895009e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1731880224251654e-06
sam_encoder.blocks.5.norm1.weight grad: -4.130500201426912e-06
sam_encoder.blocks.5.norm1.bias grad: 1.2373957360978238e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3480822619603714e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.2351728148350958e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.888231046606961e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.558851393696386e-07
sam_encoder.blocks.5.norm2.weight grad: -1.746696580084972e-05
sam_encoder.blocks.5.norm2.bias grad: -4.782334144692868e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.813267984602135e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.841798050212674e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.654706001223531e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.1512582887007738e-06
sam_encoder.blocks.6.norm1.weight grad: -1.0392068361397833e-06
sam_encoder.blocks.6.norm1.bias grad: 1.2966818303539185e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.204139814755763e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.920534924072854e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.847532626532484e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.471053110435605e-07
sam_encoder.blocks.6.norm2.weight grad: -3.5723758173844544e-06
sam_encoder.blocks.6.norm2.bias grad: -3.990221557614859e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4290583294496173e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.0306829280089e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.557889675041224e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.8107485288965108e-07
sam_encoder.blocks.7.norm1.weight grad: 2.498398714578798e-07
sam_encoder.blocks.7.norm1.bias grad: 1.7632049775784253e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.538708313044481e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.6729792302357964e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.225658838980962e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.5260089842049638e-06
sam_encoder.blocks.7.norm2.weight grad: -1.1987810921709752e-07
sam_encoder.blocks.7.norm2.bias grad: -7.97431255250558e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.3996206860156235e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.834064503076661e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0497727771507925e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.705249345235643e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0546867770244717e-06
sam_encoder.blocks.8.norm1.bias grad: -7.14759025299827e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.822196496614197e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.97438519334537e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.360280521112145e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.5491607402727823e-07
sam_encoder.blocks.8.norm2.weight grad: -4.446374987310264e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4754576795894536e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.9849807106074877e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.743007373988803e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8283935787621886e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0328719781682594e-06
sam_encoder.blocks.9.norm1.weight grad: -4.191162133793114e-06
sam_encoder.blocks.9.norm1.bias grad: -2.968191665786435e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.862196652131388e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.078406270011328e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.350019248202443e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.9419039745116606e-06
sam_encoder.blocks.9.norm2.weight grad: -3.789202764892252e-06
sam_encoder.blocks.9.norm2.bias grad: -2.5721553811308695e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.4043046121514635e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.4357190138980513e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.344200293526228e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.483567520059296e-07
sam_encoder.blocks.10.norm1.weight grad: 1.263755848412984e-06
sam_encoder.blocks.10.norm1.bias grad: -5.276885985949775e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.793132681399584e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.003620582196163e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1859410733450204e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.085047511485755e-07
sam_encoder.blocks.10.norm2.weight grad: -7.369336799456505e-06
sam_encoder.blocks.10.norm2.bias grad: -4.527927558228839e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.295512331329519e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8025527879217407e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3881469840271166e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.966627784597222e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0190062312176451e-05
sam_encoder.blocks.11.norm1.bias grad: -5.208579523241497e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.7934789765567984e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.09726283881173e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.006696831813315e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.651091659179656e-07
sam_encoder.blocks.11.norm2.weight grad: -6.810075774410507e-06
sam_encoder.blocks.11.norm2.bias grad: -7.42277734389063e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.468911136726092e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.613296490177163e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.055409822787624e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.962236961451708e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.757013473659754e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.805425876635127e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.1820673029869795e-07
sam_encoder.neck.conv2.trainable_shift grad: 0.00010377680882811546
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002644253836479038
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6053963918238878e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0009704820113256574
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0009921086020767689
mask_decoder.transformer.layers.0.norm3.weight grad: -1.8947015632875264e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.2706828531227075e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.996889715082943e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.2374360924004577e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.0736456867307425e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.648688213317655e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 7.474966696463525e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011700029426719993
mask_decoder.transformer.layers.1.norm3.weight grad: 6.641597428824753e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.0387043049559e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.120291901519522e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013023724022787064
mask_decoder.transformer.norm_final_attn.weight grad: 7.132694463507505e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.379820767208003e-06
Text_Embedding_Affine.0.weight grad: 6.445051523723544e-12
Text_Embedding_Affine.0.bias grad: 1.66719429928186e-10
Text_Embedding_Affine.2.weight grad: 5.956058563016953e-11
Text_Embedding_Affine.2.bias grad: 3.986206866102293e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.3084999697535269e-14
Max value: 0.9999798536300659
Mean value: 0.0791858658194542

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.3084999697535269e-14
Max value: 0.9999798536300659
Mean value: 0.0791858658194542

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09119415283203125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13323551416397095

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07545757293701172

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09119415283203125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 56.92735290527344
Max value: 77.07845306396484
Mean value: 63.15259552001953

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.92095752567434e-13
Max value: 0.9999291896820068
Mean value: 0.07859894633293152

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.92095752567434e-13
Max value: 0.9999291896820068
Mean value: 0.07859894633293152

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.92095752567434e-13
Max value: 0.9999291896820068
Mean value: 0.07859894633293152

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1297164261341095

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.871013343334198
Max value: 6.217701435089111
Mean value: 1.0053657293319702

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 56.92735290527344
Max value: 77.07845306396484
Mean value: 63.15259552001953

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.23675537109375
Max value: -63.23675537109375
Mean value: -63.23675537109375
sam_encoder.pos_embed grad: -2.3469559629063497e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00010514439782127738
sam_encoder.blocks.0.norm1.bias grad: -5.712135316571221e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.628391136269784e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.642978516742005e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2792228517355397e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.1205446500971448e-06
sam_encoder.blocks.0.norm2.weight grad: 1.126794632000383e-05
sam_encoder.blocks.0.norm2.bias grad: 9.284056432079524e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.745880793663673e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.2588999399886234e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.8286869564908557e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.468153863650514e-06
sam_encoder.blocks.1.norm1.weight grad: 1.0468329492141493e-07
sam_encoder.blocks.1.norm1.bias grad: 1.938225977937691e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.9791309568972792e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.0996909572422737e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.799370233537047e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.614362627668015e-07
sam_encoder.blocks.1.norm2.weight grad: 7.253618150571128e-06
sam_encoder.blocks.1.norm2.bias grad: 3.1805407161300536e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.9268902633484686e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.810652735111944e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.267313099466264e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.199472734469964e-07
sam_encoder.blocks.2.norm1.weight grad: 1.618025271454826e-05
sam_encoder.blocks.2.norm1.bias grad: -7.557183380413335e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.0377400030847639e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.2192635949759278e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.6187187763280235e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.705163180711679e-06
sam_encoder.blocks.2.norm2.weight grad: 9.203321496897843e-06
sam_encoder.blocks.2.norm2.bias grad: -2.9554666980402544e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.67578637553379e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.1564329724933486e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.665626652742503e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.0920937749433506e-07
sam_encoder.blocks.3.norm1.weight grad: 1.6083386071841232e-06
sam_encoder.blocks.3.norm1.bias grad: -6.956224297027802e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.1463201846927404e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.853673322533723e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.8447872207616456e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.95407414039073e-07
sam_encoder.blocks.3.norm2.weight grad: 1.5415886082337238e-05
sam_encoder.blocks.3.norm2.bias grad: 1.1506839655339718e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.285980579268653e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.03982528243796e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.4829854535491904e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.167240821421728e-07
sam_encoder.blocks.4.norm1.weight grad: 6.074677003198303e-06
sam_encoder.blocks.4.norm1.bias grad: -6.4073697103594895e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.114808118378278e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.0263261123764096e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.966449185099918e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.15572776546469e-06
sam_encoder.blocks.4.norm2.weight grad: -1.4677002582175191e-05
sam_encoder.blocks.4.norm2.bias grad: -1.629684993531555e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1514403013279662e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.330407591623953e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.2409984669357073e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.3025286307311035e-06
sam_encoder.blocks.5.norm1.weight grad: 1.7195877717313124e-06
sam_encoder.blocks.5.norm1.bias grad: -6.269661753321998e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.44018223031162e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.8394594007986598e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.9526061047799885e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.270070348866284e-06
sam_encoder.blocks.5.norm2.weight grad: -3.9291512621275615e-06
sam_encoder.blocks.5.norm2.bias grad: -8.86801444721641e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.93011212813144e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.4623846027461695e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.4774799385340884e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.938635349091783e-07
sam_encoder.blocks.6.norm1.weight grad: -7.1032100095180795e-06
sam_encoder.blocks.6.norm1.bias grad: 7.260227903316263e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.640441941068275e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.4985838535940275e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.483337529061828e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.5008444052000414e-06
sam_encoder.blocks.6.norm2.weight grad: -1.059974601957947e-05
sam_encoder.blocks.6.norm2.bias grad: -3.0989517654234078e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.434615897887852e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.6753782549349125e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.2142652394686593e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.6324181590098306e-07
sam_encoder.blocks.7.norm1.weight grad: -3.567380190361291e-06
sam_encoder.blocks.7.norm1.bias grad: -8.134396694003954e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.662954213723424e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.986596190472483e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.419609341421165e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.443913551061996e-07
sam_encoder.blocks.7.norm2.weight grad: -5.101636588733527e-07
sam_encoder.blocks.7.norm2.bias grad: 1.2138956435592263e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.2913917544210562e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.4074704896293042e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.3830423262770637e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.0133484213147312e-08
sam_encoder.blocks.8.norm1.weight grad: -7.967935744090937e-06
sam_encoder.blocks.8.norm1.bias grad: -2.5824597287282813e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -9.421400136488955e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.534707275321125e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.316873635914817e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5370882238130434e-06
sam_encoder.blocks.8.norm2.weight grad: -4.452413577382686e-06
sam_encoder.blocks.8.norm2.bias grad: -1.039372705236019e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.959730747737922e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.467989361321088e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.2912264913420586e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.6196669722367005e-08
sam_encoder.blocks.9.norm1.weight grad: -4.981752226740355e-06
sam_encoder.blocks.9.norm1.bias grad: -1.5019804777693935e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.790917384729255e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.0760671759489924e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.3237694247436593e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0379858395026531e-06
sam_encoder.blocks.9.norm2.weight grad: -1.2482568081395584e-06
sam_encoder.blocks.9.norm2.bias grad: -6.047398528608028e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.269578089908464e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.654510222389945e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.5581052770794486e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.024548492358008e-08
sam_encoder.blocks.10.norm1.weight grad: 2.7383528049540473e-06
sam_encoder.blocks.10.norm1.bias grad: -7.149400857997534e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.71660779719241e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2577355334997264e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.498589861323126e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.852708338556113e-07
sam_encoder.blocks.10.norm2.weight grad: -2.050106559181586e-06
sam_encoder.blocks.10.norm2.bias grad: -4.0608833273836353e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.7303558454150334e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.171448027700535e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.035216084550484e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.1591872584613157e-07
sam_encoder.blocks.11.norm1.weight grad: -7.769739568175282e-06
sam_encoder.blocks.11.norm1.bias grad: 1.4836385844319011e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.017506969626993e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.350395670371654e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.0488195673351584e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.476869329053443e-07
sam_encoder.blocks.11.norm2.weight grad: 2.5928807190211955e-06
sam_encoder.blocks.11.norm2.bias grad: -2.2299134343484184e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4573417956853518e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.0517093862461024e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.2905770745419431e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.380916713373153e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.006524250144139e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.562842488870956e-07
sam_encoder.neck.conv2.trainable_scale grad: 2.185770426876843e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.6589346311520785e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.710713932989165e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.6923877410590649e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005456799641251564
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00026829607668332756
mask_decoder.transformer.layers.0.norm3.weight grad: -2.382309321546927e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.5357108825119212e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011942268611164764
mask_decoder.transformer.layers.0.norm4.bias grad: -3.4241047615068965e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.389860598370433e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.55064024310559e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 5.472727934829891e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.38080489099957e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.888731589540839e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.815314266830683e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.029300518799573e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.000181433220859617
mask_decoder.transformer.norm_final_attn.weight grad: 1.126336064771749e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.3443993995897472e-05
Text_Embedding_Affine.0.weight grad: -1.724862787322312e-11
Text_Embedding_Affine.0.bias grad: 7.056334405675102e-10
Text_Embedding_Affine.2.weight grad: -1.35533832421042e-11
Text_Embedding_Affine.2.bias grad: 3.6413791804079665e-06
Epoch 13 finished with average loss: -58.8115
Epoch 14/39
----------
Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.8]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-56.8]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-63.3]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-63.3]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-60]  Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.38it/s, loss=-60]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.252126390598957e-28
Max value: 0.9999790191650391
Mean value: 0.07494986057281494

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.252126390598957e-28
Max value: 0.9999790191650391
Mean value: 0.07494986057281494

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0818333625793457

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13545270264148712

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07101869583129883

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0818333625793457

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.09584045410156
Max value: 81.45378112792969
Mean value: 56.793460845947266

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.252126390598957e-28
Max value: 0.9999790191650391
Mean value: 0.07494986057281494

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.252126390598957e-28
Max value: 0.9999790191650391
Mean value: 0.07494986057281494

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.252126390598957e-28
Max value: 0.9999790191650391
Mean value: 0.07494986057281494

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13545270264148712

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.09584045410156
Max value: 81.45378112792969
Mean value: 56.793460845947266

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.79426574707031
Max value: -56.79426574707031
Mean value: -56.79426574707031
sam_encoder.pos_embed grad: -8.187073241572307e-09
sam_encoder.blocks.0.norm1.weight grad: 5.664605851052329e-06
sam_encoder.blocks.0.norm1.bias grad: -7.115226026144228e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.889135536563117e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.858599543742457e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.647502697072923e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0770552307803882e-06
sam_encoder.blocks.0.norm2.weight grad: -1.0501650649530347e-05
sam_encoder.blocks.0.norm2.bias grad: 1.8000411728280596e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.005892489862163e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.883595920546213e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.696698286148603e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.147733180725481e-06
sam_encoder.blocks.1.norm1.weight grad: -5.156355655344669e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3116405170876533e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.143578270392027e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.790957627345051e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.6133114917902276e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.3580321339977672e-06
sam_encoder.blocks.1.norm2.weight grad: 2.9870414437027648e-05
sam_encoder.blocks.1.norm2.bias grad: 3.833355549431872e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.531914095830871e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4671411463496042e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.01962643081788e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.402462299272884e-07
sam_encoder.blocks.2.norm1.weight grad: -6.241801202122588e-06
sam_encoder.blocks.2.norm1.bias grad: -1.0001478585763834e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.5370962930537644e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3175884987504105e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7379346672896645e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.8528953660279512e-06
sam_encoder.blocks.2.norm2.weight grad: 8.874745617504232e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0288726116414182e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.5856102183752228e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.91412196829333e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.867158739012666e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.238737455532828e-07
sam_encoder.blocks.3.norm1.weight grad: 1.5170679944276344e-05
sam_encoder.blocks.3.norm1.bias grad: -6.938876140338834e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.0469606170081533e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.0516546353755984e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.473215077880013e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.265101539313036e-07
sam_encoder.blocks.3.norm2.weight grad: 1.0717334362198017e-06
sam_encoder.blocks.3.norm2.bias grad: -1.4906489923305344e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.716583473258652e-08
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.786639103329435e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.430420060292818e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.246063269874867e-07
sam_encoder.blocks.4.norm1.weight grad: 2.0626084733521566e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1461133908596821e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.2176607924629934e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.6049899588542758e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.898626346199308e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.3729043025232386e-06
sam_encoder.blocks.4.norm2.weight grad: -1.8328513760934584e-05
sam_encoder.blocks.4.norm2.bias grad: -3.191061841789633e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0761576049844734e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.867484221904306e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.1822513594524935e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.0770054359454662e-06
sam_encoder.blocks.5.norm1.weight grad: 1.00383958852035e-05
sam_encoder.blocks.5.norm1.bias grad: -1.9612321921158582e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.140297616890166e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.949418770498596e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.132797014084645e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.060536528209923e-06
sam_encoder.blocks.5.norm2.weight grad: -2.6430732305016136e-06
sam_encoder.blocks.5.norm2.bias grad: -1.1856811397592537e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.134587356929842e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.7554480652725033e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4963545709179016e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.252593702678496e-07
sam_encoder.blocks.6.norm1.weight grad: 5.551095227929181e-07
sam_encoder.blocks.6.norm1.bias grad: 1.569140636092925e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.7324801976646995e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.360042006126605e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.974799925454136e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.9157921542500844e-06
sam_encoder.blocks.6.norm2.weight grad: -1.6834928828757256e-05
sam_encoder.blocks.6.norm2.bias grad: -3.3954845548578305e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.2879742826044094e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.874431280972203e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.669352051678288e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.743134915472183e-07
sam_encoder.blocks.7.norm1.weight grad: 8.471497494610958e-06
sam_encoder.blocks.7.norm1.bias grad: -1.3935093647887697e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.2039800973725505e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5439185290233581e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.057087939050689e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.0293088804664876e-08
sam_encoder.blocks.7.norm2.weight grad: -3.193231805198593e-06
sam_encoder.blocks.7.norm2.bias grad: 1.942163180501666e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.6062140768299287e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5295609046006575e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.591591154072376e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.0052979721185693e-07
sam_encoder.blocks.8.norm1.weight grad: 3.28388068737695e-06
sam_encoder.blocks.8.norm1.bias grad: -3.929177182726562e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.130862180318218e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.303893213844276e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.485284767317353e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.381218433190952e-07
sam_encoder.blocks.8.norm2.weight grad: -4.886837814410683e-06
sam_encoder.blocks.8.norm2.bias grad: -1.8725995687418617e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.891680080414517e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.177554961235728e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.046007107826881e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.684331654265407e-07
sam_encoder.blocks.9.norm1.weight grad: 3.988852768088691e-06
sam_encoder.blocks.9.norm1.bias grad: 8.008671557035996e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.37962535720726e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.3250239128126395e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.271965157291561e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.4087216868574615e-06
sam_encoder.blocks.9.norm2.weight grad: -8.41363714698673e-07
sam_encoder.blocks.9.norm2.bias grad: 1.8438137772136542e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.135099622246344e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.2178943481776514e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.4516126611852087e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.5087432454238296e-07
sam_encoder.blocks.10.norm1.weight grad: 1.364808213111246e-06
sam_encoder.blocks.10.norm1.bias grad: 2.705254473767127e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.4436612850186066e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.587649016229989e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.1057782595999015e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0715844922515316e-07
sam_encoder.blocks.10.norm2.weight grad: 5.7147699408233166e-06
sam_encoder.blocks.10.norm2.bias grad: 1.1881647878908552e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.595686510176165e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.9455810615909286e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.8075762656953884e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.316703888842312e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1995465683867224e-05
sam_encoder.blocks.11.norm1.bias grad: 2.420975988570717e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.7752799408299325e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.780893393923179e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.9878370949300006e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.450237215929519e-07
sam_encoder.blocks.11.norm2.weight grad: 6.5769709181040525e-06
sam_encoder.blocks.11.norm2.bias grad: -1.7119640460805385e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.277140305930516e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2126047295168974e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.5639490104367724e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.560460062450147e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.130500433850102e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.1080953956698067e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.5538975023664534e-07
sam_encoder.neck.conv2.trainable_shift grad: -8.36388353491202e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00023331274860538542
mask_decoder.transformer.layers.0.norm1.bias grad: 9.92629793472588e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0017180480062961578
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0013467737007886171
mask_decoder.transformer.layers.0.norm3.weight grad: -2.617213613120839e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.246005745604634e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.2283969378331676e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.792931683070492e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.1640454835724086e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.566832442127634e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00026593857910484076
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0001590907631907612
mask_decoder.transformer.layers.1.norm3.weight grad: -5.045599755248986e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.501874304376543e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.729556920006871e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010162308171857148
mask_decoder.transformer.norm_final_attn.weight grad: -2.0393022168718744e-06
mask_decoder.transformer.norm_final_attn.bias grad: 4.127292413613759e-06
Text_Embedding_Affine.0.weight grad: -3.3677307904184106e-12
Text_Embedding_Affine.0.bias grad: -1.8587081873633338e-10
Text_Embedding_Affine.2.weight grad: -8.660095557333491e-11
Text_Embedding_Affine.2.bias grad: -2.8924971047672443e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.836622803371774e-23
Max value: 0.9999518394470215
Mean value: 0.08252289891242981

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.836622803371774e-23
Max value: 0.9999518394470215
Mean value: 0.08252289891242981

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08421182632446289

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11693507432937622

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07956981658935547

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08421182632446289

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 56.44081115722656
Max value: 93.28802490234375
Mean value: 69.65016174316406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2413442503136817e-21
Max value: 0.9999204874038696
Mean value: 0.08323119580745697

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2413442503136817e-21
Max value: 0.9999204874038696
Mean value: 0.08323119580745697

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2413442503136817e-21
Max value: 0.9999204874038696
Mean value: 0.08323119580745697

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11581006646156311

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9190345406532288
Max value: 2.868915557861328
Mean value: 1.0014216899871826

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 56.44081115722656
Max value: 93.28802490234375
Mean value: 69.65016174316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.71687316894531
Max value: -69.71687316894531
Mean value: -69.71687316894531
sam_encoder.pos_embed grad: -1.7349444103587075e-09
sam_encoder.blocks.0.norm1.weight grad: 5.912158485443797e-06
sam_encoder.blocks.0.norm1.bias grad: -1.291248509005527e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.86750980396755e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.4524862024245522e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.95186857974295e-08
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0911948038483388e-06
sam_encoder.blocks.0.norm2.weight grad: 4.417923719302053e-06
sam_encoder.blocks.0.norm2.bias grad: 4.297347004467156e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.395957951899618e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.7921709033762454e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -8.749722837819718e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.93186893335951e-07
sam_encoder.blocks.1.norm1.weight grad: 9.711069651530124e-06
sam_encoder.blocks.1.norm1.bias grad: 7.916773938632105e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.703764721445623e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.2504787011712324e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.2623086692874494e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.527804513074443e-08
sam_encoder.blocks.1.norm2.weight grad: 8.442541002295911e-06
sam_encoder.blocks.1.norm2.bias grad: -2.748715246525535e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.8671584030016675e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.8473076219579525e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.039871333181509e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.4054249315195193e-07
sam_encoder.blocks.2.norm1.weight grad: 5.504384716914501e-06
sam_encoder.blocks.2.norm1.bias grad: -4.806695869774558e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.510556209424976e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.016441274259705e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.656802492623683e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.873102963960264e-07
sam_encoder.blocks.2.norm2.weight grad: -6.701109668938443e-06
sam_encoder.blocks.2.norm2.bias grad: -2.990844905070844e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.752006705326494e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.366852984574507e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.865118176487158e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4661989098385675e-06
sam_encoder.blocks.3.norm1.weight grad: -6.5090571297332644e-06
sam_encoder.blocks.3.norm1.bias grad: -4.2628062146832235e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.069688995718025e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.812840744416462e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3188498542149318e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.3496446626959369e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0048947842733469e-05
sam_encoder.blocks.3.norm2.bias grad: 1.0728980669227894e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.2849870775826275e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.6891048037214205e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.260152420305531e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.621557998987555e-07
sam_encoder.blocks.4.norm1.weight grad: 4.3732427457143785e-07
sam_encoder.blocks.4.norm1.bias grad: -1.1661405778795597e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.748522309862892e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.1464438759721816e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.170612677015015e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.246587756526424e-07
sam_encoder.blocks.4.norm2.weight grad: -1.6792950191302225e-05
sam_encoder.blocks.4.norm2.bias grad: -6.338315870380029e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1163715498696547e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.895350801030872e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.532477752647537e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.957066259223211e-07
sam_encoder.blocks.5.norm1.weight grad: -2.053938715107506e-06
sam_encoder.blocks.5.norm1.bias grad: -4.171667569607962e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.019296953738376e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.3608287114693667e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.6299208027703571e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.23476097416642e-08
sam_encoder.blocks.5.norm2.weight grad: -1.0737230695667677e-05
sam_encoder.blocks.5.norm2.bias grad: -2.799414460241678e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.37834785063751e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.979122089323937e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.8226334930204757e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.944054232211784e-07
sam_encoder.blocks.6.norm1.weight grad: 1.2488212632888462e-06
sam_encoder.blocks.6.norm1.bias grad: 2.2071351395425154e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.848883344900969e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.6710620204539737e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3424096323433332e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.891541594697628e-07
sam_encoder.blocks.6.norm2.weight grad: -3.3632047689025057e-06
sam_encoder.blocks.6.norm2.bias grad: 6.229795417311834e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.2597971565119224e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.0118769750988577e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.566215352497238e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.5937955783206235e-08
sam_encoder.blocks.7.norm1.weight grad: 2.008200453929021e-06
sam_encoder.blocks.7.norm1.bias grad: 1.6506039628438884e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4284150893217884e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.030983753480541e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.583251446390932e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0890983048739145e-07
sam_encoder.blocks.7.norm2.weight grad: -1.2840849876738503e-06
sam_encoder.blocks.7.norm2.bias grad: 2.311558773726574e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.2032609220113955e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.3046907194366213e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.754608653456671e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.347469939602888e-07
sam_encoder.blocks.8.norm1.weight grad: 2.217824203398777e-06
sam_encoder.blocks.8.norm1.bias grad: -6.598887694053701e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.872604328440502e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.424326339678373e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.9160595456924057e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 6.595087143068668e-07
sam_encoder.blocks.8.norm2.weight grad: -4.1069932876780513e-07
sam_encoder.blocks.8.norm2.bias grad: -1.5820268117749947e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.14238365667552e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.9540903641373e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.966150749576627e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.500639043200863e-08
sam_encoder.blocks.9.norm1.weight grad: -2.3536281332781073e-06
sam_encoder.blocks.9.norm1.bias grad: 4.2106387354579056e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.132565668944153e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.6473929299063457e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.905844382894429e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.0303268633579137e-07
sam_encoder.blocks.9.norm2.weight grad: 1.767154316212327e-07
sam_encoder.blocks.9.norm2.bias grad: -2.0138249965384603e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.2190268989797914e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.0863920724423224e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.046579983376432e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.819057236067238e-08
sam_encoder.blocks.10.norm1.weight grad: 2.888638846343383e-06
sam_encoder.blocks.10.norm1.bias grad: -1.6223407328652684e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.98918587557273e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.726813121029409e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.103607019103947e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.271428330568597e-07
sam_encoder.blocks.10.norm2.weight grad: -1.2406142104737228e-06
sam_encoder.blocks.10.norm2.bias grad: -2.763865722954506e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.247813644222333e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.109688683864078e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.221864623512374e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.890923719358398e-07
sam_encoder.blocks.11.norm1.weight grad: 8.771774446358904e-06
sam_encoder.blocks.11.norm1.bias grad: -2.213134848716436e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.921561753690185e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.1848261389532126e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2944742593390401e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.0631468323226727e-07
sam_encoder.blocks.11.norm2.weight grad: 3.4704743256952497e-07
sam_encoder.blocks.11.norm2.bias grad: -2.6258228444930864e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.6159304979955778e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.2850028358334384e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.808704829883936e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.6863253904375597e-08
sam_encoder.neck.conv1.trainable_scale grad: -5.659967428073287e-08
sam_encoder.neck.conv1.trainable_shift grad: -8.945161425799597e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.4687248039990664e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.5122528768406482e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.000134383313707076
mask_decoder.transformer.layers.0.norm1.bias grad: 1.4774195733480155e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00432720547541976
mask_decoder.transformer.layers.0.norm2.bias grad: 9.733607294037938e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00010306744661647826
mask_decoder.transformer.layers.0.norm3.bias grad: 3.593995643313974e-07
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010289881902281195
mask_decoder.transformer.layers.0.norm4.bias grad: -7.165007446019445e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.799350088229403e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.6207668522838503e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.400263813091442e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.799603139981627e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.973731120117009e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.8284804506693035e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.006825449527241e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018046144396066666
mask_decoder.transformer.norm_final_attn.weight grad: 4.867591087531764e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.3489056982507464e-05
Text_Embedding_Affine.0.weight grad: -9.735210901307134e-12
Text_Embedding_Affine.0.bias grad: -2.968939538661175e-10
Text_Embedding_Affine.2.weight grad: 1.5198500791235858e-10
Text_Embedding_Affine.2.bias grad: 1.570638778503053e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.271732679207374e-19
Max value: 0.9999479055404663
Mean value: 0.07251258194446564

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.271732679207374e-19
Max value: 0.9999479055404663
Mean value: 0.07251258194446564

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.087158203125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15345695614814758

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.062465667724609375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.087158203125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 26.60594940185547
Max value: 67.50679779052734
Mean value: 53.42367935180664

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.021099178082112e-16
Max value: 0.9998002648353577
Mean value: 0.07605555653572083

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.021099178082112e-16
Max value: 0.9998002648353577
Mean value: 0.07605555653572083

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.021099178082112e-16
Max value: 0.9998002648353577
Mean value: 0.07605555653572083

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14771616458892822

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7843285202980042
Max value: 12.260409355163574
Mean value: 1.0092616081237793

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 26.60594940185547
Max value: 67.50679779052734
Mean value: 53.42367935180664

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.532371520996094
Max value: -53.532371520996094
Mean value: -53.532371520996094
sam_encoder.pos_embed grad: -2.0127735034236593e-09
sam_encoder.blocks.0.norm1.weight grad: -5.422710091806948e-05
sam_encoder.blocks.0.norm1.bias grad: -8.050919132074341e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.7108108067986905e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.1123802323709242e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.6274248991976492e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.5014472814509645e-06
sam_encoder.blocks.0.norm2.weight grad: 3.1460338504984975e-05
sam_encoder.blocks.0.norm2.bias grad: 4.771902968059294e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.025071287585888e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.4928722268668935e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.3003956812317483e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.5014270401443355e-06
sam_encoder.blocks.1.norm1.weight grad: -1.0258237125526648e-05
sam_encoder.blocks.1.norm1.bias grad: -3.7457189137057867e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.1474769053165801e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.827332875516731e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 9.51026231632568e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.006963303661905e-06
sam_encoder.blocks.1.norm2.weight grad: 2.5090097551583312e-05
sam_encoder.blocks.1.norm2.bias grad: 1.1709935279213823e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.8322220057598315e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.7285481084836647e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.30037822399754e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.5814456446605618e-06
sam_encoder.blocks.2.norm1.weight grad: -5.110847268952057e-06
sam_encoder.blocks.2.norm1.bias grad: -1.798300763766747e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.0521678127115592e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.437504561698006e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.360230039106682e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 6.022173693054356e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0494184607523493e-05
sam_encoder.blocks.2.norm2.bias grad: 1.853944741014857e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.227012398885563e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.119552957286942e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.747187969973311e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.991009288663918e-07
sam_encoder.blocks.3.norm1.weight grad: 3.119381290161982e-05
sam_encoder.blocks.3.norm1.bias grad: -1.534761759103276e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.2082968169124797e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 8.1016662534239e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.6171125025721267e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.563964454782024e-10
sam_encoder.blocks.3.norm2.weight grad: 9.452258382225409e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0169987945118919e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.0782681531272829e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 8.891710763236915e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.753195414901711e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.3648520962306065e-06
sam_encoder.blocks.4.norm1.weight grad: -3.0164283089106902e-06
sam_encoder.blocks.4.norm1.bias grad: -5.752523975388613e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.022790668997914e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.259586608488462e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.751542635654914e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.743044549584738e-06
sam_encoder.blocks.4.norm2.weight grad: 2.9449572593875928e-06
sam_encoder.blocks.4.norm2.bias grad: -1.1734355211956427e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.124309948063456e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.538079175134044e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.1877975794050144e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.605066679796437e-07
sam_encoder.blocks.5.norm1.weight grad: -2.071745620924048e-05
sam_encoder.blocks.5.norm1.bias grad: -3.4788696211762726e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.106067793443799e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.365409272897523e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.2516875257424545e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.015704224817455e-07
sam_encoder.blocks.5.norm2.weight grad: -6.5124731918331236e-06
sam_encoder.blocks.5.norm2.bias grad: -1.0266892786603421e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.7776296671363525e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.60683384820004e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.141373549122363e-09
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.5291859654098516e-06
sam_encoder.blocks.6.norm1.weight grad: -4.129835815547267e-06
sam_encoder.blocks.6.norm1.bias grad: -5.140562279848382e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.189415343105793e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.2161110589659074e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.805609586990613e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.339297892234754e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0287731129210442e-05
sam_encoder.blocks.6.norm2.bias grad: 5.750433956563938e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.296286639757454e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.3345768315484747e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -6.788975497329375e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.707057759238523e-07
sam_encoder.blocks.7.norm1.weight grad: 3.5861708056472708e-06
sam_encoder.blocks.7.norm1.bias grad: 9.513527174931369e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.912752041898784e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.3438862462608085e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.3279403649212327e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.196606823825277e-06
sam_encoder.blocks.7.norm2.weight grad: 1.274248552363133e-05
sam_encoder.blocks.7.norm2.bias grad: -2.518833639442164e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0739229765022174e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.8027332064084476e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.4723193544341484e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.739573972121434e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0111767551279627e-05
sam_encoder.blocks.8.norm1.bias grad: -2.142015546269249e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2478244570957031e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.516252490953775e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.7732365854026284e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 7.843688649700198e-07
sam_encoder.blocks.8.norm2.weight grad: 5.007581421523355e-06
sam_encoder.blocks.8.norm2.bias grad: 2.388679149589734e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.5475164875388145e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.291063065575145e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.8645732779987156e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.446593103082705e-07
sam_encoder.blocks.9.norm1.weight grad: -1.2905114772365778e-06
sam_encoder.blocks.9.norm1.bias grad: 1.224271500177565e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.720098670281004e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.8578722915663093e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.6233655603391526e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.169742228692485e-07
sam_encoder.blocks.9.norm2.weight grad: -4.150177119299769e-06
sam_encoder.blocks.9.norm2.bias grad: -2.2363428797689267e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.5333439427631674e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.4123835373757174e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.150982810344431e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.266219992947299e-07
sam_encoder.blocks.10.norm1.weight grad: -1.5175405678746756e-06
sam_encoder.blocks.10.norm1.bias grad: -1.0473584097780986e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.052804337741691e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.3536951466194296e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5596267530781915e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0027429198089521e-06
sam_encoder.blocks.10.norm2.weight grad: -1.3333707101992331e-05
sam_encoder.blocks.10.norm2.bias grad: -5.037029040977359e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.4671465982683003e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.6017803470022045e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.860239763118443e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.2363525456748903e-06
sam_encoder.blocks.11.norm1.weight grad: 8.581126166973263e-06
sam_encoder.blocks.11.norm1.bias grad: -7.968482691467216e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.63529897085391e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.1896341334249882e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.4243552161351545e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7257427771255607e-06
sam_encoder.blocks.11.norm2.weight grad: -3.648620804597158e-06
sam_encoder.blocks.11.norm2.bias grad: -9.926570783136413e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.709609579047537e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.150712134607602e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3455698990583187e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.546577514474848e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.1024912964785472e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.827084088290576e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.517266122798901e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.780948852887377e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00019427604274824262
mask_decoder.transformer.layers.0.norm1.bias grad: -3.3949618227779865e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003817908698692918
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0007740200962871313
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00018932591774500906
mask_decoder.transformer.layers.0.norm3.bias grad: 4.390467802295461e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.734154233825393e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.287196007790044e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.88544909178745e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.341639164020307e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002452395565342158
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011378306953702122
mask_decoder.transformer.layers.1.norm3.weight grad: 4.433047433849424e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.233526124153286e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.538190867402591e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014833235763944685
mask_decoder.transformer.norm_final_attn.weight grad: 1.1027663276763633e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.4639397452119738e-05
Text_Embedding_Affine.0.weight grad: 2.171152667373999e-11
Text_Embedding_Affine.0.bias grad: 1.3581714641830445e-09
Text_Embedding_Affine.2.weight grad: 8.783673788315127e-11
Text_Embedding_Affine.2.bias grad: 7.4832743848674e-05
Epoch 14 finished with average loss: -60.0145
Epoch 15/39
----------
Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.1]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-57.1]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-59.1]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-59.1]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-63.3]Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-63.3]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.781883543015304e-16
Max value: 0.9999140501022339
Mean value: 0.07419578731060028

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.781883543015304e-16
Max value: 0.9999140501022339
Mean value: 0.07419578731060028

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07489299774169922

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12005472183227539

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06637334823608398

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07489299774169922

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.36032485961914
Max value: 67.14918518066406
Mean value: 57.07012176513672

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.781883543015304e-16
Max value: 0.9999140501022339
Mean value: 0.07419578731060028

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.781883543015304e-16
Max value: 0.9999140501022339
Mean value: 0.07419578731060028

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.781883543015304e-16
Max value: 0.9999140501022339
Mean value: 0.07419578731060028

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12005472183227539

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.36032485961914
Max value: 67.14918518066406
Mean value: 57.07012176513672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.07110595703125
Max value: -57.07110595703125
Mean value: -57.07110595703125
sam_encoder.pos_embed grad: 1.54804546959042e-09
sam_encoder.blocks.0.norm1.weight grad: 6.8989734245406e-06
sam_encoder.blocks.0.norm1.bias grad: -2.2066833480494097e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.9238697152322857e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.205891728925053e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.5474589619989274e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.2951596179154876e-07
sam_encoder.blocks.0.norm2.weight grad: 9.842677172855474e-06
sam_encoder.blocks.0.norm2.bias grad: -1.5066963896970265e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.668820110964589e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.710088544219616e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.939213108125841e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0452463357069064e-06
sam_encoder.blocks.1.norm1.weight grad: -3.826705778919859e-06
sam_encoder.blocks.1.norm1.bias grad: 5.0185535656055436e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.7658180695434567e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2150430848123506e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.9852284367516404e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.83349857252324e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0367721188231371e-05
sam_encoder.blocks.1.norm2.bias grad: -9.492661661170132e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.253807674103882e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.149872539637727e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.1673348429612815e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.702397392175044e-07
sam_encoder.blocks.2.norm1.weight grad: -4.780907602253137e-06
sam_encoder.blocks.2.norm1.bias grad: 1.4727081634191563e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.371474915387807e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.220237421279307e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7242939520656364e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.192795480164932e-06
sam_encoder.blocks.2.norm2.weight grad: 6.073951226426288e-07
sam_encoder.blocks.2.norm2.bias grad: -7.414796527882572e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.7942018075700616e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.0968589094773051e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.2292735997762065e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.939665351841541e-07
sam_encoder.blocks.3.norm1.weight grad: 5.925871846557129e-06
sam_encoder.blocks.3.norm1.bias grad: 3.440799218878965e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.214831612145645e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.884055210321094e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.3605966816830914e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.396909394519753e-06
sam_encoder.blocks.3.norm2.weight grad: 3.6488040677795652e-06
sam_encoder.blocks.3.norm2.bias grad: -5.6116583380116936e-08
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.1656889493424387e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.931363607989624e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.729750920276274e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.375555135993636e-07
sam_encoder.blocks.4.norm1.weight grad: 3.4437005069776205e-06
sam_encoder.blocks.4.norm1.bias grad: 8.027764124562964e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.6970179785857908e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.2867230597967136e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.17409272713121e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5052813751026406e-06
sam_encoder.blocks.4.norm2.weight grad: -1.0040344022854697e-06
sam_encoder.blocks.4.norm2.bias grad: 8.0320405686507e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.277720566075004e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.944897338849842e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.855320980823308e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.0661470873383223e-07
sam_encoder.blocks.5.norm1.weight grad: 7.240461400215281e-06
sam_encoder.blocks.5.norm1.bias grad: -4.984285169484792e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.964378487988142e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.8663052969714045e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.524780360450677e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.507162210145907e-06
sam_encoder.blocks.5.norm2.weight grad: 2.711243269004626e-06
sam_encoder.blocks.5.norm2.bias grad: 5.78567733100499e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.318086320789007e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.5403343784091703e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1945879805352888e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.99232986739662e-07
sam_encoder.blocks.6.norm1.weight grad: 9.933492037816904e-07
sam_encoder.blocks.6.norm1.bias grad: -3.859810021822341e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.923410988842079e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.519075436197454e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.941686029269476e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.695994218513079e-07
sam_encoder.blocks.6.norm2.weight grad: 8.201528771678568e-07
sam_encoder.blocks.6.norm2.bias grad: 1.285182406718377e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.846681349590654e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.009925274634952e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6481633338116808e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.239946171466727e-07
sam_encoder.blocks.7.norm1.weight grad: -4.172473836661084e-06
sam_encoder.blocks.7.norm1.bias grad: -9.987602425098885e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.3907526812981814e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0430037491460098e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.0429952201084234e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.008162598736817e-06
sam_encoder.blocks.7.norm2.weight grad: -1.4234735772333806e-06
sam_encoder.blocks.7.norm2.bias grad: 1.8730277133727213e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.010361640714109e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.500358621342457e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.4995770243331208e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.236504752152541e-07
sam_encoder.blocks.8.norm1.weight grad: 3.8952927639002155e-07
sam_encoder.blocks.8.norm1.bias grad: 3.7635930993928923e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2305600876061362e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.892551133816596e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.032923930528341e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.379828063363675e-06
sam_encoder.blocks.8.norm2.weight grad: -1.238865820596402e-06
sam_encoder.blocks.8.norm2.bias grad: 1.2464096244002576e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.0442773802642478e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0062769888463663e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.608453304579598e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.135510375315789e-07
sam_encoder.blocks.9.norm1.weight grad: -3.4089305245288415e-07
sam_encoder.blocks.9.norm1.bias grad: -4.944159854858299e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.356990181506262e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.165345338449697e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.904121849198418e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9819424323941348e-07
sam_encoder.blocks.9.norm2.weight grad: -2.459378947605728e-06
sam_encoder.blocks.9.norm2.bias grad: 1.5548220062555629e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.4381135972362245e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.1676888789224904e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.811688078618317e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.3022754425692256e-07
sam_encoder.blocks.10.norm1.weight grad: -2.242557457066141e-06
sam_encoder.blocks.10.norm1.bias grad: 2.452666478802712e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.5143212951661553e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.141485293184815e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.0071491942653665e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.169284567178693e-07
sam_encoder.blocks.10.norm2.weight grad: -2.057792244158918e-06
sam_encoder.blocks.10.norm2.bias grad: 1.300722942687571e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.5958382846292807e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.094760465202853e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.896991292000166e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.3828346229493036e-07
sam_encoder.blocks.11.norm1.weight grad: -1.1857063327624928e-05
sam_encoder.blocks.11.norm1.bias grad: 1.0694809589040233e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.233199554917519e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.4672688841699255e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.389548908216966e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.214324925058463e-07
sam_encoder.blocks.11.norm2.weight grad: -7.842706395422283e-07
sam_encoder.blocks.11.norm2.bias grad: 5.715370932080077e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.6669036995153874e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.9421167962718755e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.015395789901959e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.7780159566882503e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4070064935367554e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.1150954378535971e-05
sam_encoder.neck.conv2.trainable_scale grad: 6.561922418768518e-07
sam_encoder.neck.conv2.trainable_shift grad: -5.010051972931251e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010560486407484859
mask_decoder.transformer.layers.0.norm1.bias grad: 1.202644853037782e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004434878937900066
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00012486911145970225
mask_decoder.transformer.layers.0.norm3.weight grad: 9.601358033251017e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.361349470447749e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.27868313738145e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.5711515162547585e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.3618315026396886e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.152125489374157e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00015432090731337667
mask_decoder.transformer.layers.1.norm2.bias grad: -1.0085419489769265e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.0610053979908116e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.491527564212447e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.0433258871198632e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00011840399383800104
mask_decoder.transformer.norm_final_attn.weight grad: -3.4206734653707827e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.0487914551049471e-05
Text_Embedding_Affine.0.weight grad: -1.6817280207304108e-11
Text_Embedding_Affine.0.bias grad: -4.639583994769936e-10
Text_Embedding_Affine.2.weight grad: 1.2954401440445906e-11
Text_Embedding_Affine.2.bias grad: -2.686045627342537e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.452681992170214e-24
Max value: 0.9999417066574097
Mean value: 0.07887803018093109

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.452681992170214e-24
Max value: 0.9999417066574097
Mean value: 0.07887803018093109

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08103132247924805

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12225454300642014

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07068681716918945

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08103132247924805

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.67025375366211
Max value: 92.79695129394531
Mean value: 61.15629577636719

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.448436972966832e-23
Max value: 0.9999102354049683
Mean value: 0.07959708571434021

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.448436972966832e-23
Max value: 0.9999102354049683
Mean value: 0.07959708571434021

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.448436972966832e-23
Max value: 0.9999102354049683
Mean value: 0.07959708571434021

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1213565543293953

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9321563839912415
Max value: 2.5632612705230713
Mean value: 1.0012303590774536

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.67025375366211
Max value: 92.79695129394531
Mean value: 61.15629577636719

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.20078659057617
Max value: -61.20078659057617
Mean value: -61.20078659057617
sam_encoder.pos_embed grad: -1.193576570912569e-09
sam_encoder.blocks.0.norm1.weight grad: 3.6045927117811516e-05
sam_encoder.blocks.0.norm1.bias grad: 2.585939182608854e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.461219537508441e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.341201921917673e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.997427716560196e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4354817494677263e-06
sam_encoder.blocks.0.norm2.weight grad: 3.417550033191219e-05
sam_encoder.blocks.0.norm2.bias grad: 9.382341659147642e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.8782277442805935e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.920394308603136e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.0246281817671843e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.102192279897281e-07
sam_encoder.blocks.1.norm1.weight grad: 4.438270025275415e-06
sam_encoder.blocks.1.norm1.bias grad: 1.8552364053903148e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.9720880522509106e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.23494258888968e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.0315193321730476e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 5.749409410782391e-07
sam_encoder.blocks.1.norm2.weight grad: 1.241465156454069e-06
sam_encoder.blocks.1.norm2.bias grad: 9.13358962861821e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.405617230280768e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.229166400662507e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.645266926672775e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4168107302102726e-06
sam_encoder.blocks.2.norm1.weight grad: 2.939823843917111e-06
sam_encoder.blocks.2.norm1.bias grad: -4.5793467506882735e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.6175489438173827e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.86902705335524e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.290961674589198e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.3111695099942153e-06
sam_encoder.blocks.2.norm2.weight grad: -3.298528099549003e-06
sam_encoder.blocks.2.norm2.bias grad: -1.1750520570785739e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.3306394016108243e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.0328179743955843e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.160182238090783e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.7646015041682404e-06
sam_encoder.blocks.3.norm1.weight grad: -3.7695804167015012e-06
sam_encoder.blocks.3.norm1.bias grad: -6.031422344676685e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.635855010652449e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8930788883153582e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.784562406712212e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.127246943928185e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0997029676218517e-05
sam_encoder.blocks.3.norm2.bias grad: 5.080622941022739e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.955057299113832e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.2456646295031533e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.403563030384248e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.246031685781418e-08
sam_encoder.blocks.4.norm1.weight grad: 1.0125646440428682e-05
sam_encoder.blocks.4.norm1.bias grad: 2.375339818172506e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.488775059347972e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.324684717474156e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2617273341675173e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3197034149925457e-06
sam_encoder.blocks.4.norm2.weight grad: -3.049406222999096e-05
sam_encoder.blocks.4.norm2.bias grad: -1.7434551409678534e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.2327214537654072e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.862159691285342e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.5720537450979464e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.6093872545752674e-06
sam_encoder.blocks.5.norm1.weight grad: 1.7450832956455997e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2110996976844035e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.852915367337118e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.680651042894169e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.4433657017652877e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.3116824650060153e-06
sam_encoder.blocks.5.norm2.weight grad: -1.8262860976392403e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0031281817646232e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.390257789869793e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.116314019280253e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.877238997229142e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.439272629497282e-07
sam_encoder.blocks.6.norm1.weight grad: -9.921639048116049e-07
sam_encoder.blocks.6.norm1.bias grad: -2.875672862501233e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -7.991743586899247e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.013711653286009e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.129628112219507e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.1378325477126054e-07
sam_encoder.blocks.6.norm2.weight grad: -8.539314876543358e-06
sam_encoder.blocks.6.norm2.bias grad: 1.5123107459658058e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.950578153919196e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.407569238333963e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1796699936894584e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.039210624450789e-08
sam_encoder.blocks.7.norm1.weight grad: -2.2895310394233093e-06
sam_encoder.blocks.7.norm1.bias grad: 1.867380774456251e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.0422129384533037e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.0291337199960253e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.4936139223209466e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.4278900784556754e-06
sam_encoder.blocks.7.norm2.weight grad: 4.049973085784586e-06
sam_encoder.blocks.7.norm2.bias grad: 2.3876118575572036e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.589037649158854e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.300386949462336e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.5469673182196857e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.870070853726702e-08
sam_encoder.blocks.8.norm1.weight grad: -4.543124759948114e-06
sam_encoder.blocks.8.norm1.bias grad: -1.6060237157944357e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.087256224418525e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.3728756534401327e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.796307848664583e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.189551070041489e-07
sam_encoder.blocks.8.norm2.weight grad: -4.394902134663425e-06
sam_encoder.blocks.8.norm2.bias grad: -1.7281849977734964e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.1502407839288935e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.317761754966341e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.4955730875954032e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.787707545503508e-07
sam_encoder.blocks.9.norm1.weight grad: -7.175487553467974e-06
sam_encoder.blocks.9.norm1.bias grad: 5.394773552325205e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.4250411924149375e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.1506045868591173e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.511026766820578e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.857912820923957e-06
sam_encoder.blocks.9.norm2.weight grad: -5.133205377205741e-06
sam_encoder.blocks.9.norm2.bias grad: -3.378133897058433e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.643588004502817e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.1706764528062195e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.481353575007233e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.419847977667814e-07
sam_encoder.blocks.10.norm1.weight grad: -2.738692614911997e-07
sam_encoder.blocks.10.norm1.bias grad: 8.717158550552995e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.774576266048825e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.8385081779779284e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.066430154940463e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.764594964650314e-07
sam_encoder.blocks.10.norm2.weight grad: -9.855881216935813e-06
sam_encoder.blocks.10.norm2.bias grad: -4.391099537315313e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.6812413125298917e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.5734880182426423e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.9285271264379844e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.0029443728853948e-06
sam_encoder.blocks.11.norm1.weight grad: 8.5177907749312e-06
sam_encoder.blocks.11.norm1.bias grad: -3.6656624047282094e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.887360440377961e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.475428217025183e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.420682903903071e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.23816585073655e-06
sam_encoder.blocks.11.norm2.weight grad: -3.113822003797395e-06
sam_encoder.blocks.11.norm2.bias grad: -1.954805384229985e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.604629447792831e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.1945753612963017e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2684656667261152e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.859610041625274e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.528481779037975e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2018670531688258e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.845657480880618e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.9634323911741376e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002961483260150999
mask_decoder.transformer.layers.0.norm1.bias grad: -8.672213880345225e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0024333337787538767
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0012256414629518986
mask_decoder.transformer.layers.0.norm3.weight grad: -4.985457781003788e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.919513670145534e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011790444114012644
mask_decoder.transformer.layers.0.norm4.bias grad: -6.610232958337292e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.3914719097083434e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.2670155885862187e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 8.062728011282161e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.400666800094768e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.064098149887286e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.615435318555683e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.2258613171288744e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018404392176307738
mask_decoder.transformer.norm_final_attn.weight grad: 6.7880955612054095e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.8147275113733485e-05
Text_Embedding_Affine.0.weight grad: 1.550886155610165e-13
Text_Embedding_Affine.0.bias grad: -4.82479750596454e-11
Text_Embedding_Affine.2.weight grad: 6.289460618980058e-11
Text_Embedding_Affine.2.bias grad: 6.662344094365835e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.973518914751957e-19
Max value: 0.9997854828834534
Mean value: 0.10527671128511429

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.973518914751957e-19
Max value: 0.9997854828834534
Mean value: 0.10527671128511429

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10764503479003906

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1409912109375

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10102176666259766

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10764503479003906

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 61.770286560058594
Max value: 79.0066909790039
Mean value: 71.77482604980469

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0661845905573234e-16
Max value: 0.9995228052139282
Mean value: 0.10826830565929413

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0661845905573234e-16
Max value: 0.9995228052139282
Mean value: 0.10826830565929413

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0661845905573234e-16
Max value: 0.9995228052139282
Mean value: 0.10826830565929413

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13905872404575348

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8871539831161499
Max value: 9.7758207321167
Mean value: 1.004244089126587

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 61.770286560058594
Max value: 79.0066909790039
Mean value: 71.77482604980469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -71.73761749267578
Max value: -71.73761749267578
Mean value: -71.73761749267578
sam_encoder.pos_embed grad: 6.154848186668005e-09
sam_encoder.blocks.0.norm1.weight grad: 5.568828055402264e-05
sam_encoder.blocks.0.norm1.bias grad: 2.988215237564873e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.5216093743219972e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.642336635806714e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.71135399745981e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.6797189295612043e-06
sam_encoder.blocks.0.norm2.weight grad: 3.209406713722274e-05
sam_encoder.blocks.0.norm2.bias grad: -1.5243969755829312e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0289291822118685e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.65470077667851e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.6412690456490964e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.902252269152086e-06
sam_encoder.blocks.1.norm1.weight grad: 5.712064648832893e-06
sam_encoder.blocks.1.norm1.bias grad: 7.988397555891424e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.140397767419927e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.981178451795131e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.038537321728654e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.948160615938832e-06
sam_encoder.blocks.1.norm2.weight grad: 1.657154643908143e-05
sam_encoder.blocks.1.norm2.bias grad: 4.0017080209509e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.563615781691624e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.696718186394719e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.919609520788072e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2069156127836322e-06
sam_encoder.blocks.2.norm1.weight grad: -1.1722210729203653e-05
sam_encoder.blocks.2.norm1.bias grad: 2.768176273093559e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.455798938986845e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.7298829081701115e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.2955310871329857e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.94653056396055e-06
sam_encoder.blocks.2.norm2.weight grad: 1.9328712369315326e-05
sam_encoder.blocks.2.norm2.bias grad: -7.909407941042446e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.610361874161754e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.6981515475199558e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.711687769391574e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.608263119123876e-06
sam_encoder.blocks.3.norm1.weight grad: -9.26932625588961e-06
sam_encoder.blocks.3.norm1.bias grad: 7.063411430863198e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.40730569709558e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.669450734378188e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.789262559119379e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.78155538480496e-06
sam_encoder.blocks.3.norm2.weight grad: -4.068687303515617e-06
sam_encoder.blocks.3.norm2.bias grad: -2.168892478948692e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.5485476271569496e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7463938775108545e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.998271833756007e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.7812438954933896e-06
sam_encoder.blocks.4.norm1.weight grad: -6.458614734583534e-06
sam_encoder.blocks.4.norm1.bias grad: -9.291119567933492e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.102606105036102e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2863854408351472e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.166229700786062e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.726770728462725e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5996582735388074e-06
sam_encoder.blocks.4.norm2.bias grad: 2.948443125205813e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.136567779118195e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.1221196056540066e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.5090828330576187e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.034598633661517e-07
sam_encoder.blocks.5.norm1.weight grad: 8.156311196216848e-06
sam_encoder.blocks.5.norm1.bias grad: -1.4142489817459136e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.074971224734327e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.932788897349383e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0104974990099436e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.542309165524784e-07
sam_encoder.blocks.5.norm2.weight grad: -1.0150640264328104e-05
sam_encoder.blocks.5.norm2.bias grad: -6.067484719096683e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0357829523854889e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.627677076816326e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.484883341618115e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.1282947904619505e-07
sam_encoder.blocks.6.norm1.weight grad: 6.177482191560557e-06
sam_encoder.blocks.6.norm1.bias grad: -1.2393063570925733e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.874905360135017e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.213627340097446e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.415588826603198e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.4120300875219982e-06
sam_encoder.blocks.6.norm2.weight grad: -3.6506662581814453e-06
sam_encoder.blocks.6.norm2.bias grad: 2.275087126690778e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.818822955916403e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.7565702137289918e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.3002315881749382e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.1236705859118956e-06
sam_encoder.blocks.7.norm1.weight grad: 7.627045761182671e-06
sam_encoder.blocks.7.norm1.bias grad: -5.906575779590639e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.674644858620013e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.268167792062741e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.134754807542777e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.8019685512626893e-06
sam_encoder.blocks.7.norm2.weight grad: -6.781212505302392e-06
sam_encoder.blocks.7.norm2.bias grad: 4.07225434173597e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.892456546367612e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.824523789968225e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.56328063289402e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1324749493724084e-06
sam_encoder.blocks.8.norm1.weight grad: 2.669671448529698e-05
sam_encoder.blocks.8.norm1.bias grad: -1.783713230452122e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.5122746592387557e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.71540248428937e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.3978275294211926e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.0176580619590823e-06
sam_encoder.blocks.8.norm2.weight grad: -2.1065156943222973e-06
sam_encoder.blocks.8.norm2.bias grad: 7.008485454207403e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.731001586653292e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.747068255208433e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.7740571820468176e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.767074521325412e-07
sam_encoder.blocks.9.norm1.weight grad: -3.9429532989743166e-06
sam_encoder.blocks.9.norm1.bias grad: 8.027666353882523e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.510586677497486e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.3497418624174315e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.2296939025400206e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0893188573390944e-06
sam_encoder.blocks.9.norm2.weight grad: -3.827612999884877e-06
sam_encoder.blocks.9.norm2.bias grad: 1.2045419452988426e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.945172920793993e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.394932476425311e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3878516256227158e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.659538934807642e-07
sam_encoder.blocks.10.norm1.weight grad: -7.877300589598235e-08
sam_encoder.blocks.10.norm1.bias grad: -1.6046905102484743e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0099979590449948e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.331176649609915e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6686929029674502e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.9149571762209234e-07
sam_encoder.blocks.10.norm2.weight grad: -7.854736395529471e-06
sam_encoder.blocks.10.norm2.bias grad: 1.095359380087757e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.062125066819135e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.1010453110648086e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.221143055678112e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.057352118839844e-08
sam_encoder.blocks.11.norm1.weight grad: 8.789047569734976e-06
sam_encoder.blocks.11.norm1.bias grad: 1.328080884377414e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.2201877527550096e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.646046025096439e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.8239646781003103e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7673049796940177e-06
sam_encoder.blocks.11.norm2.weight grad: -1.4252160326577723e-05
sam_encoder.blocks.11.norm2.bias grad: -4.4073940443922766e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.9084839045244735e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.2571152840100694e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.487398541641596e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.1553995449276044e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.759434422245249e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2262861673661973e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8296268535777926e-06
sam_encoder.neck.conv2.trainable_shift grad: -6.153801223263144e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00012566889927256852
mask_decoder.transformer.layers.0.norm1.bias grad: 7.633905624970794e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0024655694141983986
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005473015480674803
mask_decoder.transformer.layers.0.norm3.weight grad: 1.3550366929848678e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00013200270768720657
mask_decoder.transformer.layers.0.norm4.weight grad: -6.57890850561671e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.8565104255685583e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 5.503458669409156e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.282421453652205e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002687522501219064
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00024139319430105388
mask_decoder.transformer.layers.1.norm3.weight grad: 9.865558968158439e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.231282456312329e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.224565832875669e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 1.8222601283923723e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.615160378307337e-06
mask_decoder.transformer.norm_final_attn.bias grad: -2.6255509055772563e-06
Text_Embedding_Affine.0.weight grad: 2.516258555684825e-11
Text_Embedding_Affine.0.bias grad: 6.850739975305942e-10
Text_Embedding_Affine.2.weight grad: -2.1933907468074665e-10
Text_Embedding_Affine.2.bias grad: -9.420438436791301e-05
Epoch 15 finished with average loss: -63.3365
Epoch 16/39
----------
Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.1]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-57.1]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-57]  Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-57]Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-62.6]Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-62.6]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.520508430982202e-16
Max value: 0.9982548356056213
Mean value: 0.07561697065830231

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.520508430982202e-16
Max value: 0.9982548356056213
Mean value: 0.07561697065830231

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07380914688110352

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1099030002951622

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0688481330871582

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07380914688110352

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.6746826171875
Max value: 68.61711883544922
Mean value: 57.125648498535156

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.520508430982202e-16
Max value: 0.9982548356056213
Mean value: 0.07561697065830231

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.520508430982202e-16
Max value: 0.9982548356056213
Mean value: 0.07561697065830231

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.520508430982202e-16
Max value: 0.9982548356056213
Mean value: 0.07561697065830231

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1099030002951622

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.6746826171875
Max value: 68.61711883544922
Mean value: 57.125648498535156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.126625061035156
Max value: -57.126625061035156
Mean value: -57.126625061035156
sam_encoder.pos_embed grad: -2.921413777556836e-09
sam_encoder.blocks.0.norm1.weight grad: -1.2298976798774675e-05
sam_encoder.blocks.0.norm1.bias grad: -1.1914437891391572e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.128210199880414e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.5565769823951996e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.64877576228173e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.0526053390312882e-07
sam_encoder.blocks.0.norm2.weight grad: 2.4377008230658248e-05
sam_encoder.blocks.0.norm2.bias grad: -8.231849051298923e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0477356227056589e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.819689583106083e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.119893780327402e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.1336398933490273e-06
sam_encoder.blocks.1.norm1.weight grad: -3.417861989873927e-06
sam_encoder.blocks.1.norm1.bias grad: 4.57766736872145e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.2419466151623055e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.3425964198177098e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.4393927964847535e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.736297690513311e-06
sam_encoder.blocks.1.norm2.weight grad: -1.408806838298915e-05
sam_encoder.blocks.1.norm2.bias grad: -2.597716502350522e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.021278073196299e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.433036456750415e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.8463887247198727e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.59069360911235e-07
sam_encoder.blocks.2.norm1.weight grad: -3.4210243029519916e-06
sam_encoder.blocks.2.norm1.bias grad: -5.420800789579516e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.5734548216860276e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.812754342419794e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.737012654411956e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.705387641161906e-08
sam_encoder.blocks.2.norm2.weight grad: 7.43715645512566e-06
sam_encoder.blocks.2.norm2.bias grad: 2.1426119474199368e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.226607416057959e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.5295643152057892e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.266473171010148e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.0459913255544961e-06
sam_encoder.blocks.3.norm1.weight grad: 4.703747435996775e-06
sam_encoder.blocks.3.norm1.bias grad: 1.2747390201184317e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.556582553050248e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 9.155468205790385e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.0783762718347134e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.3602466424345039e-06
sam_encoder.blocks.3.norm2.weight grad: -8.410807822656352e-06
sam_encoder.blocks.3.norm2.bias grad: -6.174160716909682e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.986756827449426e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.123203325434588e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.7558402305439813e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.68478913767467e-07
sam_encoder.blocks.4.norm1.weight grad: -9.31562112782558e-07
sam_encoder.blocks.4.norm1.bias grad: -9.792705895961262e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.073581294505857e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.037338380338042e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.8709177968266886e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3742763371737965e-07
sam_encoder.blocks.4.norm2.weight grad: 9.728085387905594e-06
sam_encoder.blocks.4.norm2.bias grad: 1.1163128874613903e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.583834874618333e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.5693032057461096e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.3669798590854043e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.4497167057925253e-06
sam_encoder.blocks.5.norm1.weight grad: 9.014805073093157e-06
sam_encoder.blocks.5.norm1.bias grad: -2.4659934751980472e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.695454769418575e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.917493242828641e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.595945253844548e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.13891188550042e-07
sam_encoder.blocks.5.norm2.weight grad: 1.3357653187995311e-05
sam_encoder.blocks.5.norm2.bias grad: 3.0870883165334817e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.938565325574018e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.0212087292748038e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.020290139626013e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.5236298622767208e-06
sam_encoder.blocks.6.norm1.weight grad: -3.1149113510764437e-07
sam_encoder.blocks.6.norm1.bias grad: -6.08979178196023e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.1589941923139122e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.08973402652191e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0281037248205394e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.413484013341076e-07
sam_encoder.blocks.6.norm2.weight grad: -2.4413150612190293e-08
sam_encoder.blocks.6.norm2.bias grad: -6.120930038377992e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.5662793657611473e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.738013098583906e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.1445245579343464e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.2125503796341945e-07
sam_encoder.blocks.7.norm1.weight grad: 1.062331534740224e-06
sam_encoder.blocks.7.norm1.bias grad: 2.5559756977600046e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.99877580498287e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.4355785538100463e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.023778607617714e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.6786296984937508e-06
sam_encoder.blocks.7.norm2.weight grad: -7.087654694259982e-07
sam_encoder.blocks.7.norm2.bias grad: 6.615033498746925e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.815173502312973e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.120888767531142e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.823996277991682e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.358474706757988e-07
sam_encoder.blocks.8.norm1.weight grad: 6.98888015904231e-07
sam_encoder.blocks.8.norm1.bias grad: 1.4058572332942276e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.1577900497504743e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.789697648746369e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.3150578221684555e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.194104677590076e-08
sam_encoder.blocks.8.norm2.weight grad: 3.5540522276278352e-06
sam_encoder.blocks.8.norm2.bias grad: 2.3673244413657812e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.4233380625228165e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.481099484924925e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4907363947713748e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.972676480174414e-07
sam_encoder.blocks.9.norm1.weight grad: 4.2615629354259e-06
sam_encoder.blocks.9.norm1.bias grad: 3.204864924555295e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.734673898885376e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.298400201856566e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.36488710672711e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1544311746547464e-06
sam_encoder.blocks.9.norm2.weight grad: 5.008230800740421e-06
sam_encoder.blocks.9.norm2.bias grad: 3.243133505748119e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.6755279830249492e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.5505663668591296e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.071009460763889e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.094450206248439e-07
sam_encoder.blocks.10.norm1.weight grad: -4.620622462425672e-07
sam_encoder.blocks.10.norm1.bias grad: 2.275615997859859e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.484968141900026e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.4861731162673095e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.2380223779473454e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.229444468568545e-07
sam_encoder.blocks.10.norm2.weight grad: 7.660603841941338e-06
sam_encoder.blocks.10.norm2.bias grad: 4.306730261305347e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.495057287887903e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.4908513321643113e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.44512785027473e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.078230848695966e-07
sam_encoder.blocks.11.norm1.weight grad: -8.150901521730702e-06
sam_encoder.blocks.11.norm1.bias grad: 1.208513111805587e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.7654481325735105e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.818271802127128e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.8969485608977266e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.62399417655979e-07
sam_encoder.blocks.11.norm2.weight grad: 7.203464974736562e-06
sam_encoder.blocks.11.norm2.bias grad: 6.480944421127788e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.469541641403339e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.470804818382021e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.910002765725949e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.811662948777666e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0757612471934408e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.8733922590618022e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.1600332072703168e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.47249146620743e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00022364527103491127
mask_decoder.transformer.layers.0.norm1.bias grad: 3.101755282841623e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0033157721627503633
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0012474588584154844
mask_decoder.transformer.layers.0.norm3.weight grad: 4.3403753807069734e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.7216268538031727e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011974678636761382
mask_decoder.transformer.layers.0.norm4.bias grad: 9.853754818323068e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.6142974093090743e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.266750354669057e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -3.156039019813761e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -5.382432573242113e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.751847104169428e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.8844929804326966e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.1822434064233676e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001711666554911062
mask_decoder.transformer.norm_final_attn.weight grad: -2.0599100025719963e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3642514204548206e-05
Text_Embedding_Affine.0.weight grad: 8.805102480469174e-12
Text_Embedding_Affine.0.bias grad: 2.17507289956842e-10
Text_Embedding_Affine.2.weight grad: -1.1246177600288121e-10
Text_Embedding_Affine.2.bias grad: -6.830769416410476e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.1058002142856987e-19
Max value: 0.9999556541442871
Mean value: 0.08391150832176208

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.1058002142856987e-19
Max value: 0.9999556541442871
Mean value: 0.08391150832176208

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0742950439453125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12733367085456848

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07151651382446289

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0742950439453125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.602603912353516
Max value: 79.9179916381836
Mean value: 56.84064483642578

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.343939020865763e-19
Max value: 0.9999421834945679
Mean value: 0.08279161155223846

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.343939020865763e-19
Max value: 0.9999421834945679
Mean value: 0.08279161155223846

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.343939020865763e-19
Max value: 0.9999421834945679
Mean value: 0.08279161155223846

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12628485262393951

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8637115955352783
Max value: 1.6680556535720825
Mean value: 1.00112783908844

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.602603912353516
Max value: 79.9179916381836
Mean value: 56.84064483642578

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.89985656738281
Max value: -56.89985656738281
Mean value: -56.89985656738281
sam_encoder.pos_embed grad: 1.6744854391959052e-09
sam_encoder.blocks.0.norm1.weight grad: 7.656017260160297e-05
sam_encoder.blocks.0.norm1.bias grad: -1.3320607649802696e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.537396413681563e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.13934009454897e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.939132971529034e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.453469278407283e-06
sam_encoder.blocks.0.norm2.weight grad: -3.090654672632809e-06
sam_encoder.blocks.0.norm2.bias grad: -3.1777490221429616e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.300210988119943e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.0380949738173513e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.415614396042656e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.245684289751807e-07
sam_encoder.blocks.1.norm1.weight grad: -2.589013092801906e-06
sam_encoder.blocks.1.norm1.bias grad: -9.687802048574667e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.846469217525737e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.050769237233908e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.449584488000255e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 5.404012313192652e-07
sam_encoder.blocks.1.norm2.weight grad: -1.169590359495487e-05
sam_encoder.blocks.1.norm2.bias grad: -1.3950866559753194e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.481270131393103e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.8418103283911478e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.637977665173821e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.1098406957898987e-06
sam_encoder.blocks.2.norm1.weight grad: 5.287582098389976e-06
sam_encoder.blocks.2.norm1.bias grad: -1.3457551176543348e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.4501952035934664e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.174903089435247e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.4804189706628677e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.7270347143494291e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0349343028792646e-05
sam_encoder.blocks.2.norm2.bias grad: -4.9581376515561715e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.2198081094538793e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.6296379473933484e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.619785846036393e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.5208679542411119e-06
sam_encoder.blocks.3.norm1.weight grad: -4.9386158025299665e-06
sam_encoder.blocks.3.norm1.bias grad: 3.895287136401748e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.8568983907462098e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5218422504403861e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3245644367998466e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8579793277240242e-06
sam_encoder.blocks.3.norm2.weight grad: 1.1168954188178759e-05
sam_encoder.blocks.3.norm2.bias grad: 2.7667726953950478e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.6563326324976515e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.3490323403384537e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.89492492761201e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.578397814228083e-06
sam_encoder.blocks.4.norm1.weight grad: -8.421915481449105e-06
sam_encoder.blocks.4.norm1.bias grad: -1.9354454252606956e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.478639417968225e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.3074303499015514e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.136993655061815e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -8.078177415882237e-07
sam_encoder.blocks.4.norm2.weight grad: 1.1579453712329268e-05
sam_encoder.blocks.4.norm2.bias grad: 6.094944183132611e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.475725174619583e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.104869397750008e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.905214710670407e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.789541763893794e-07
sam_encoder.blocks.5.norm1.weight grad: -9.242477972293273e-06
sam_encoder.blocks.5.norm1.bias grad: -8.735670235182624e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.198033017630223e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.035358061737497e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.853761204984039e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.9665362742671277e-06
sam_encoder.blocks.5.norm2.weight grad: 1.4501305486191995e-05
sam_encoder.blocks.5.norm2.bias grad: -4.163824485203804e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.101766979962122e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.7702608349500224e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.2400286070478614e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.914076493558241e-07
sam_encoder.blocks.6.norm1.weight grad: -4.860014087171294e-06
sam_encoder.blocks.6.norm1.bias grad: -4.035019173898036e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.0800471247639507e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.35150649688876e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.330382001986436e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.6521546437361394e-07
sam_encoder.blocks.6.norm2.weight grad: 5.460847660287982e-06
sam_encoder.blocks.6.norm2.bias grad: 6.237054321900359e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.563840320770396e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.0638012756535318e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.431892997061368e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.4893957995809615e-06
sam_encoder.blocks.7.norm1.weight grad: -2.211917035310762e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4651399169451906e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.316753342616721e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.0524955718647107e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 7.990669246282778e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.9038036498386646e-06
sam_encoder.blocks.7.norm2.weight grad: -5.705643957298889e-07
sam_encoder.blocks.7.norm2.bias grad: 7.662605412406265e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.868629846692784e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.616733015907812e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3846942010786734e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.852223985883029e-07
sam_encoder.blocks.8.norm1.weight grad: 5.12131373398006e-06
sam_encoder.blocks.8.norm1.bias grad: -6.621767170145176e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.936282493872568e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.7888315798918484e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.777584657247644e-08
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5692761508034891e-06
sam_encoder.blocks.8.norm2.weight grad: 1.9596368474594783e-06
sam_encoder.blocks.8.norm2.bias grad: 1.7164402379421517e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.330393595519126e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.750038845533709e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.2273222788935527e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.906745516564115e-07
sam_encoder.blocks.9.norm1.weight grad: -1.627076073873468e-07
sam_encoder.blocks.9.norm1.bias grad: 8.237531687882438e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.9053763935517054e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.414438651816454e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.252933270114227e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.2172635024398915e-06
sam_encoder.blocks.9.norm2.weight grad: -7.33738488634117e-07
sam_encoder.blocks.9.norm2.bias grad: 2.0976681298634503e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.543129423633218e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2417081052262802e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.473699057896738e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.9948827773296216e-07
sam_encoder.blocks.10.norm1.weight grad: -2.7641212909657042e-06
sam_encoder.blocks.10.norm1.bias grad: -1.0856508652068442e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.248714736197144e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.720335363752383e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.223013204158633e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.2709116243599965e-09
sam_encoder.blocks.10.norm2.weight grad: -7.232215466501657e-06
sam_encoder.blocks.10.norm2.bias grad: -1.3471870943249087e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.2486112761253025e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.953991042886628e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.22330436372431e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.6786880021682e-07
sam_encoder.blocks.11.norm1.weight grad: -2.421006229269551e-06
sam_encoder.blocks.11.norm1.bias grad: 5.573486419052642e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.2002398079857812e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.3402559179430682e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.1444947978798155e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.989501682459377e-08
sam_encoder.blocks.11.norm2.weight grad: 1.6197993772948394e-06
sam_encoder.blocks.11.norm2.bias grad: -1.3005850405534147e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.132011840989435e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.619858936574019e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.8788647316323477e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.985947831912199e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.833150448277593e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.1185715013416484e-05
sam_encoder.neck.conv2.trainable_scale grad: 5.369256541598588e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.4363216905621812e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -5.9836325817741454e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 7.972681487444788e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003250732086598873
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0009115159627981484
mask_decoder.transformer.layers.0.norm3.weight grad: -3.661948721855879e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.575188071001321e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -3.613342414610088e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.140967914485373e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.7220775741152465e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.838363333372399e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00011030014138668776
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00012895953841507435
mask_decoder.transformer.layers.1.norm3.weight grad: 1.1014642950613052e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.637374902609736e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.08316554967314e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -4.6086621296126395e-05
mask_decoder.transformer.norm_final_attn.weight grad: 8.129287380143069e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2458326636988204e-05
Text_Embedding_Affine.0.weight grad: 7.898726811506052e-12
Text_Embedding_Affine.0.bias grad: 3.3926569886766345e-10
Text_Embedding_Affine.2.weight grad: -2.8423494460860788e-11
Text_Embedding_Affine.2.bias grad: -2.2313754016067833e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.337737085011865e-18
Max value: 0.9999401569366455
Mean value: 0.11552047729492188

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.337737085011865e-18
Max value: 0.9999401569366455
Mean value: 0.11552047729492188

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.12288665771484375

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15003249049186707

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11417007446289062

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.12288665771484375

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 57.47779083251953
Max value: 89.6415023803711
Mean value: 73.80862426757812

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.741336340528037e-17
Max value: 0.9999034404754639
Mean value: 0.11532307416200638

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.741336340528037e-17
Max value: 0.9999034404754639
Mean value: 0.11532307416200638

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.741336340528037e-17
Max value: 0.9999034404754639
Mean value: 0.11532307416200638

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14845333993434906

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8524637818336487
Max value: 3.5609729290008545
Mean value: 1.0021207332611084

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 57.47779083251953
Max value: 89.6415023803711
Mean value: 73.80862426757812

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -73.88072967529297
Max value: -73.88072967529297
Mean value: -73.88072967529297
sam_encoder.pos_embed grad: 6.260285623227446e-09
sam_encoder.blocks.0.norm1.weight grad: -9.613468864699826e-05
sam_encoder.blocks.0.norm1.bias grad: -3.264491851950879e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.091335186894867e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.298473979564733e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.63047659752192e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.889207386644557e-06
sam_encoder.blocks.0.norm2.weight grad: 9.800280531635508e-05
sam_encoder.blocks.0.norm2.bias grad: -5.837400385644287e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.4059681891230866e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.459898941102438e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.102054622810101e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.9819266273989342e-06
sam_encoder.blocks.1.norm1.weight grad: 1.5334400814026594e-05
sam_encoder.blocks.1.norm1.bias grad: 1.7034029951901175e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.67998062656261e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.6593002075969707e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.875914095871849e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.22660286858445e-06
sam_encoder.blocks.1.norm2.weight grad: -3.498943215163308e-06
sam_encoder.blocks.1.norm2.bias grad: -4.486161742534023e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.483790118887555e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.650646350361058e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.8752334401360713e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.4351421618339373e-06
sam_encoder.blocks.2.norm1.weight grad: 9.106041034101509e-06
sam_encoder.blocks.2.norm1.bias grad: 1.2246455298736691e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.478368620970286e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.1350505246809917e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.5352113627595827e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.221428753226064e-06
sam_encoder.blocks.2.norm2.weight grad: 1.8250897483085282e-05
sam_encoder.blocks.2.norm2.bias grad: -1.9243449060013518e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.81489449966466e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.6117559198391973e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.8436336176819168e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.7834533941349946e-06
sam_encoder.blocks.3.norm1.weight grad: 2.093467628583312e-06
sam_encoder.blocks.3.norm1.bias grad: 5.0189100875286385e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4605897376895882e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.616638190986123e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.1367732440703548e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.563557796354871e-06
sam_encoder.blocks.3.norm2.weight grad: -3.303147241240367e-05
sam_encoder.blocks.3.norm2.bias grad: 1.1210162483621389e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.4276625481434166e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.347379101294791e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.84978032647632e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.681348971440457e-06
sam_encoder.blocks.4.norm1.weight grad: -1.287717623199569e-06
sam_encoder.blocks.4.norm1.bias grad: -4.765188805322396e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.525403376945178e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2880922213298618e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3001854313188232e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.204963144933572e-06
sam_encoder.blocks.4.norm2.weight grad: -2.4183736968552694e-05
sam_encoder.blocks.4.norm2.bias grad: 9.485534974373877e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.1385436411947012e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.327906026446726e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.99593851499958e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.243134415242821e-06
sam_encoder.blocks.5.norm1.weight grad: -1.8835123682947597e-06
sam_encoder.blocks.5.norm1.bias grad: -1.7464617485529743e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.332541943265824e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.3256030797492713e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0354900581432958e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.5527206187471165e-06
sam_encoder.blocks.5.norm2.weight grad: -3.9351347368210554e-05
sam_encoder.blocks.5.norm2.bias grad: 3.338433089083992e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.283573485328816e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.207204816950252e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.0168918126728386e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.195053975308838e-07
sam_encoder.blocks.6.norm1.weight grad: -3.8751031752326526e-06
sam_encoder.blocks.6.norm1.bias grad: -6.469705112976953e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.982986865798011e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.249704362446209e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0764163107523927e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.2890284273889847e-06
sam_encoder.blocks.6.norm2.weight grad: -1.6429830793640576e-05
sam_encoder.blocks.6.norm2.bias grad: 6.133382612460991e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3334315553947818e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.554980816668831e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.505090146267321e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.5932419046293944e-06
sam_encoder.blocks.7.norm1.weight grad: 1.2483332056945073e-06
sam_encoder.blocks.7.norm1.bias grad: 2.9247094062156975e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.344857304909965e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.825629128570654e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.383697392360773e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.683682168935775e-06
sam_encoder.blocks.7.norm2.weight grad: -5.215553301241016e-06
sam_encoder.blocks.7.norm2.bias grad: 2.2857902877149172e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.139829565654509e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.4672818906547036e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.8258654108649353e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1573143865462043e-06
sam_encoder.blocks.8.norm1.weight grad: 2.074765507131815e-05
sam_encoder.blocks.8.norm1.bias grad: 2.5584047307347646e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.6263853467535228e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.8734804042615e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.262725047330605e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.815359261556296e-06
sam_encoder.blocks.8.norm2.weight grad: -5.3027433750685304e-06
sam_encoder.blocks.8.norm2.bias grad: 3.023246790689882e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.6248150031024124e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.487782578304177e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.0542272523016436e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.733528946118895e-07
sam_encoder.blocks.9.norm1.weight grad: -7.6633541539195e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0116020803252468e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.486607839586213e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.301321041566553e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.2163965190411545e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.5522638225083938e-06
sam_encoder.blocks.9.norm2.weight grad: -3.92710353480652e-06
sam_encoder.blocks.9.norm2.bias grad: -3.8792694567746366e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.4865715861087665e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.915617399907205e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.2146936064236797e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.7688242905933294e-06
sam_encoder.blocks.10.norm1.weight grad: -3.4052391129080206e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1698300106388615e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.583129455364542e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.0435834383315523e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.2209419512364548e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.396097660399391e-07
sam_encoder.blocks.10.norm2.weight grad: -1.540482116979547e-05
sam_encoder.blocks.10.norm2.bias grad: -5.287663952913135e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.713513696216978e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.4207922655914444e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.900127118569799e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.848426762762756e-07
sam_encoder.blocks.11.norm1.weight grad: -1.890429120976478e-05
sam_encoder.blocks.11.norm1.bias grad: 2.598723312985385e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.0506013242993504e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.916745979244297e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.841281795757823e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.46972058701067e-06
sam_encoder.blocks.11.norm2.weight grad: -1.5988416635082103e-05
sam_encoder.blocks.11.norm2.bias grad: -6.356979611155111e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.990250545233721e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.8887570806546137e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.405716928587935e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.078656949488504e-08
sam_encoder.neck.conv1.trainable_scale grad: 4.950006768922321e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.4418964383366983e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.773342076689005e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.1311294403858483e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 5.797558696940541e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.732697223313153e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0012892703525722027
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005490728071890771
mask_decoder.transformer.layers.0.norm3.weight grad: 7.765545160509646e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.027717998018488e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -6.63541941321455e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.003000296710525e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.806431338191032e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -9.824256267165765e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0004134860064368695
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00033381336834281683
mask_decoder.transformer.layers.1.norm3.weight grad: 8.856369822751731e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.972263069357723e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.1347445251885802e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.949744157376699e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.018896889756434e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.155676252703415e-07
Text_Embedding_Affine.0.weight grad: 3.2350983003581746e-11
Text_Embedding_Affine.0.bias grad: 7.745051266994096e-10
Text_Embedding_Affine.2.weight grad: -5.6862063668727814e-11
Text_Embedding_Affine.2.bias grad: -6.367074092850089e-05
Epoch 16 finished with average loss: -62.6357
Epoch 17/39
----------
Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.2]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-56.2]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-54.3]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-54.3]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-55.4]Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-55.4]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.5671575036303055e-15
Max value: 0.9999420642852783
Mean value: 0.06482173502445221

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.5671575036303055e-15
Max value: 0.9999420642852783
Mean value: 0.06482173502445221

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06896066665649414

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11403022706508636

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05664491653442383

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06896066665649414

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.08981704711914
Max value: 86.57233428955078
Mean value: 56.212066650390625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.5671575036303055e-15
Max value: 0.9999420642852783
Mean value: 0.06482173502445221

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.5671575036303055e-15
Max value: 0.9999420642852783
Mean value: 0.06482173502445221

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.5671575036303055e-15
Max value: 0.9999420642852783
Mean value: 0.06482173502445221

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11403022706508636

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.08981704711914
Max value: 86.57233428955078
Mean value: 56.212066650390625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.212928771972656
Max value: -56.212928771972656
Mean value: -56.212928771972656
sam_encoder.pos_embed grad: 2.8637225923944243e-09
sam_encoder.blocks.0.norm1.weight grad: -1.1138082300021779e-05
sam_encoder.blocks.0.norm1.bias grad: 1.546279054309707e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.6049860935017932e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.091870664524322e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -9.631435204937588e-08
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.974718758101517e-07
sam_encoder.blocks.0.norm2.weight grad: -8.792085282038897e-06
sam_encoder.blocks.0.norm2.bias grad: 2.187098652939312e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.749446477741003e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.1411825653340202e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.990790042327717e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.308793556148885e-06
sam_encoder.blocks.1.norm1.weight grad: -5.6330495681322645e-06
sam_encoder.blocks.1.norm1.bias grad: -2.852355009963503e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.740523541433504e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.071114514976216e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.1926563224260462e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.7866270809463458e-06
sam_encoder.blocks.1.norm2.weight grad: 1.9896930098184384e-05
sam_encoder.blocks.1.norm2.bias grad: -1.8383574342806241e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1928059393540025e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.781351895464468e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.1106064448540565e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.081222876564425e-06
sam_encoder.blocks.2.norm1.weight grad: 1.5635350791853853e-07
sam_encoder.blocks.2.norm1.bias grad: 3.045811126867193e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.7273423225105944e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.952209451403178e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 9.398066822541296e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 4.6788517238383065e-07
sam_encoder.blocks.2.norm2.weight grad: 6.458322786784265e-06
sam_encoder.blocks.2.norm2.bias grad: 6.619974556087982e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.874559742049314e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 8.638121471449267e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 6.979991212574532e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.778748572993209e-07
sam_encoder.blocks.3.norm1.weight grad: -3.979945176979527e-06
sam_encoder.blocks.3.norm1.bias grad: -7.61271962801402e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.051374046161072e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1656131846393691e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.72486850767018e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.37538040689833e-06
sam_encoder.blocks.3.norm2.weight grad: 1.7544640286359936e-05
sam_encoder.blocks.3.norm2.bias grad: 8.94822551344987e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.241288373421412e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.778115337307099e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.07295977108879e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.665755224981694e-07
sam_encoder.blocks.4.norm1.weight grad: 7.462646749445412e-07
sam_encoder.blocks.4.norm1.bias grad: 1.4936322259018198e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.192963165725814e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.575896070946328e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.1750952328147832e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.863067932907143e-07
sam_encoder.blocks.4.norm2.weight grad: -1.1760128472815268e-05
sam_encoder.blocks.4.norm2.bias grad: -1.6889816834009252e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.954907803446986e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.5369635043025482e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.6743900914661936e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.451396868418669e-07
sam_encoder.blocks.5.norm1.weight grad: -8.853416147758253e-06
sam_encoder.blocks.5.norm1.bias grad: -5.525333108380437e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.720523065770976e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.306573262307211e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.4349837985937484e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.8794187326420797e-06
sam_encoder.blocks.5.norm2.weight grad: -9.814209988689981e-06
sam_encoder.blocks.5.norm2.bias grad: -1.2009935744572431e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.981886609632056e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.540529622929171e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.473762480003643e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.1218174828827614e-07
sam_encoder.blocks.6.norm1.weight grad: -2.365896762057673e-06
sam_encoder.blocks.6.norm1.bias grad: 1.8524413007980911e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.401311010340578e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.8710130095532804e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.641418970801169e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.565748430555686e-07
sam_encoder.blocks.6.norm2.weight grad: -1.93853838936775e-06
sam_encoder.blocks.6.norm2.bias grad: 6.942326535863685e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.171440875528788e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.753457373216861e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.621747499797493e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.65911250305362e-07
sam_encoder.blocks.7.norm1.weight grad: 1.1769352568080649e-06
sam_encoder.blocks.7.norm1.bias grad: -7.953753424772003e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.7334928088530432e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.2870553973698406e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.662217290591798e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.9809090190392453e-06
sam_encoder.blocks.7.norm2.weight grad: 1.5800949313415913e-06
sam_encoder.blocks.7.norm2.bias grad: 2.75422223694477e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.302381173853064e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.372027836372581e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.008811688687274e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.344004870901699e-07
sam_encoder.blocks.8.norm1.weight grad: 6.437765023292741e-06
sam_encoder.blocks.8.norm1.bias grad: -2.0139805201324634e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.373007413960295e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.196731429648935e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.1058410482055478e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.345414137991611e-07
sam_encoder.blocks.8.norm2.weight grad: -5.969453923171386e-06
sam_encoder.blocks.8.norm2.bias grad: -1.7409429347026162e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.655424163502175e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.691962890821742e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.641298917500535e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.095702711812919e-06
sam_encoder.blocks.9.norm1.weight grad: -2.8460808607633226e-06
sam_encoder.blocks.9.norm1.bias grad: 1.8742041163477552e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.435059514027671e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.122572138636315e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.9528411005230737e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.9248450371378567e-06
sam_encoder.blocks.9.norm2.weight grad: -1.1291936061752494e-06
sam_encoder.blocks.9.norm2.bias grad: -2.6237098609271925e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.316615437957807e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.985245472103998e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.945519869650525e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.272041102623916e-07
sam_encoder.blocks.10.norm1.weight grad: 2.3382949621009175e-07
sam_encoder.blocks.10.norm1.bias grad: 1.193300249724416e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0092740012623835e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.794416159053071e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.3643706324728555e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.190488761603774e-07
sam_encoder.blocks.10.norm2.weight grad: -4.268512384442147e-06
sam_encoder.blocks.10.norm2.bias grad: -5.388788849813864e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.473025006111129e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.4387103419721825e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2172367860330269e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.930668175504252e-07
sam_encoder.blocks.11.norm1.weight grad: 5.568722372117918e-06
sam_encoder.blocks.11.norm1.bias grad: 1.9998965399281587e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.8106096604242339e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.884623538397136e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.030430323429755e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.0770920034228766e-07
sam_encoder.blocks.11.norm2.weight grad: -6.396310254785931e-06
sam_encoder.blocks.11.norm2.bias grad: -3.417947027628543e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.2883393739903113e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.7278839550272096e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5103453279152745e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.73993497457559e-07
sam_encoder.neck.conv1.trainable_scale grad: -9.395280358148739e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.0772742573171854e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.729701559990644e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.1627929779933766e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -9.886630141409114e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.3702850739937276e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0052140820771455765
mask_decoder.transformer.layers.0.norm2.bias grad: 2.8845664928667247e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -5.0397626182530075e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.890986696816981e-07
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011653413821477443
mask_decoder.transformer.layers.0.norm4.bias grad: -1.2687756679952145e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.0501210605725646e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.038709787186235e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.9055408958811313e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.4696801372338086e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.9125831942074e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.107366501353681e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.5835186786716804e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018511216330807656
mask_decoder.transformer.norm_final_attn.weight grad: 6.002063400956104e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.8670078134164214e-05
Text_Embedding_Affine.0.weight grad: 2.1009310610664578e-11
Text_Embedding_Affine.0.bias grad: 6.156725684824949e-10
Text_Embedding_Affine.2.weight grad: 2.3375751334597794e-10
Text_Embedding_Affine.2.bias grad: 3.195078897988424e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3776559747321043e-14
Max value: 0.9999508857727051
Mean value: 0.0839877799153328

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3776559747321043e-14
Max value: 0.9999508857727051
Mean value: 0.0839877799153328

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09026956558227539

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1372685730457306

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06841039657592773

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09026956558227539

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.919042587280273
Max value: 71.93907165527344
Mean value: 52.46397399902344

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.725734692147225e-14
Max value: 0.9999297857284546
Mean value: 0.08483274281024933

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.725734692147225e-14
Max value: 0.9999297857284546
Mean value: 0.08483274281024933

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.725734692147225e-14
Max value: 0.9999297857284546
Mean value: 0.08483274281024933

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13706837594509125

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9370569586753845
Max value: 2.0200653076171875
Mean value: 1.0003111362457275

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.919042587280273
Max value: 71.93907165527344
Mean value: 52.46397399902344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.47787857055664
Max value: -52.47787857055664
Mean value: -52.47787857055664
sam_encoder.pos_embed grad: -2.3988360187132685e-09
sam_encoder.blocks.0.norm1.weight grad: 1.5432755162692047e-06
sam_encoder.blocks.0.norm1.bias grad: 7.768747309455648e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0394018090664758e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.719819615838787e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.6030287497414974e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.0161110114713665e-07
sam_encoder.blocks.0.norm2.weight grad: 2.8048450985806994e-05
sam_encoder.blocks.0.norm2.bias grad: -7.691880455240607e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.217234163661487e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.898741058743326e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.73328304401366e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.186636589220143e-07
sam_encoder.blocks.1.norm1.weight grad: 6.724408649461111e-06
sam_encoder.blocks.1.norm1.bias grad: 7.774581717967521e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3877966011932585e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.881279664914473e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.6680713770256261e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.297268555499613e-07
sam_encoder.blocks.1.norm2.weight grad: 1.3251257769297808e-05
sam_encoder.blocks.1.norm2.bias grad: -1.6341844002454309e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.411789632285945e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0741448477347149e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.4904547924743383e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.165373858697421e-07
sam_encoder.blocks.2.norm1.weight grad: -1.4558281691279262e-07
sam_encoder.blocks.2.norm1.bias grad: 4.2689061956480145e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.485589771429659e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.213755684962962e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7093004771595588e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.144690600085596e-06
sam_encoder.blocks.2.norm2.weight grad: -6.362377007462783e-06
sam_encoder.blocks.2.norm2.bias grad: 4.3470635091580334e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.5857883631251752e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.6609814110779553e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.149602202436654e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.920713246927335e-08
sam_encoder.blocks.3.norm1.weight grad: -8.066666850936599e-06
sam_encoder.blocks.3.norm1.bias grad: -6.260240184019494e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.652360075851902e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.132476179729565e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2687742128036916e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.3691958972449356e-07
sam_encoder.blocks.3.norm2.weight grad: 3.0189373774192063e-06
sam_encoder.blocks.3.norm2.bias grad: 3.4364220482530072e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.493078565952601e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.355143467662856e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.790914154753409e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.3276874467655944e-08
sam_encoder.blocks.4.norm1.weight grad: -2.0267580111976713e-06
sam_encoder.blocks.4.norm1.bias grad: 6.532008001158829e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1183404922121554e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.731947869795476e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.70586519693461e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.217204150336329e-07
sam_encoder.blocks.4.norm2.weight grad: -1.1160511348862201e-05
sam_encoder.blocks.4.norm2.bias grad: -1.1081703632953577e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.469039246643661e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.865212081815116e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.953356670332141e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.967131417288329e-07
sam_encoder.blocks.5.norm1.weight grad: -9.587772183294874e-06
sam_encoder.blocks.5.norm1.bias grad: 2.666963837327785e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.557381417835131e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.740917918548803e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.797331704750832e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.7465629298385466e-06
sam_encoder.blocks.5.norm2.weight grad: -1.023434288072167e-05
sam_encoder.blocks.5.norm2.bias grad: -8.593141501478385e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.7960794543323573e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.234437377206632e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.107607999983884e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.567830036554369e-07
sam_encoder.blocks.6.norm1.weight grad: -8.680390237714164e-07
sam_encoder.blocks.6.norm1.bias grad: 2.7818869057227857e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.5481341506529134e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.2296366094233235e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.175301515057072e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.266769112997281e-07
sam_encoder.blocks.6.norm2.weight grad: -8.326924216817133e-07
sam_encoder.blocks.6.norm2.bias grad: -1.7985412341658957e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.731716328227776e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.139485554333078e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.7694284199242247e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.8805661028409304e-08
sam_encoder.blocks.7.norm1.weight grad: 2.803642928483896e-06
sam_encoder.blocks.7.norm1.bias grad: 1.2524626527010696e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.9182195956091164e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0929802556347568e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.7814480770539376e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.062085281475447e-07
sam_encoder.blocks.7.norm2.weight grad: 2.0704787857539486e-06
sam_encoder.blocks.7.norm2.bias grad: -4.679350240621716e-10
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.8695454855333082e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.951350309871486e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.04997705220012e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.831743123962951e-07
sam_encoder.blocks.8.norm1.weight grad: -2.325089525356816e-07
sam_encoder.blocks.8.norm1.bias grad: -6.431445740417985e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.047390353254741e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.950840767989575e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.100901499739848e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.378225616439522e-07
sam_encoder.blocks.8.norm2.weight grad: -1.0601466726711806e-07
sam_encoder.blocks.8.norm2.bias grad: -1.4654245887868456e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.2205705388623755e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.824698069365695e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.311478818408432e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.694105430440686e-07
sam_encoder.blocks.9.norm1.weight grad: 1.3102986429203156e-07
sam_encoder.blocks.9.norm1.bias grad: 2.1612788714264752e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.986192602198571e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.185828394540295e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.0653293353898334e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.398055750698404e-07
sam_encoder.blocks.9.norm2.weight grad: 3.1433543767889205e-07
sam_encoder.blocks.9.norm2.bias grad: -1.3792464415018912e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.152630476208287e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.1361209923707065e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.525264666379371e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.366832513369445e-07
sam_encoder.blocks.10.norm1.weight grad: 3.7755944504169747e-06
sam_encoder.blocks.10.norm1.bias grad: -6.77095158607699e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.7259636681264965e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.888081310942653e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.3945895034339628e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.684129397806828e-07
sam_encoder.blocks.10.norm2.weight grad: -1.2582202089106431e-06
sam_encoder.blocks.10.norm2.bias grad: -2.1395276235125493e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.3266770199370512e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.1294391078517947e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0404020258647506e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.647946181852603e-07
sam_encoder.blocks.11.norm1.weight grad: 6.328233212116174e-06
sam_encoder.blocks.11.norm1.bias grad: -1.015390580505482e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.41457030622405e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.071879852243001e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8115978264177102e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.688810796935286e-07
sam_encoder.blocks.11.norm2.weight grad: -1.952653292391915e-07
sam_encoder.blocks.11.norm2.bias grad: -1.105171577364672e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.6566966678510653e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.234172822885739e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.461475087846338e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.67926594688106e-07
sam_encoder.neck.conv1.trainable_scale grad: -9.471659723203629e-08
sam_encoder.neck.conv1.trainable_shift grad: -6.878281965327915e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.054215191397816e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.899108378391247e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012819693074561656
mask_decoder.transformer.layers.0.norm1.bias grad: 6.408627086784691e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00414125993847847
mask_decoder.transformer.layers.0.norm2.bias grad: 9.916891576722264e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -7.809328963048756e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.6188663721550256e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.28725314931944e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.084053438826231e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.1340103305410594e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.782393029425293e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.706314262468368e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 4.473654189496301e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.1364219214301556e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.277654468547553e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.1911287805996835e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014485909196082503
mask_decoder.transformer.norm_final_attn.weight grad: 3.7265810988174053e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.871391972003039e-06
Text_Embedding_Affine.0.weight grad: -7.460516579516074e-13
Text_Embedding_Affine.0.bias grad: -2.5065928499490298e-11
Text_Embedding_Affine.2.weight grad: 3.760170647071348e-11
Text_Embedding_Affine.2.bias grad: 2.1551692043431103e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.2779783661757156e-12
Max value: 0.9992415904998779
Mean value: 0.11481060087680817

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.2779783661757156e-12
Max value: 0.9992415904998779
Mean value: 0.11481060087680817

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09997844696044922

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.654799461364746
Max value: -1.1920928244535389e-07
Mean value: -0.1449430137872696

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09638595581054688

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09997844696044922

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 32.267635345458984
Max value: 76.46675872802734
Mean value: 57.39323425292969

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.1298471666875152e-11
Max value: 0.9987254738807678
Mean value: 0.11596338450908661

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.1298471666875152e-11
Max value: 0.9987254738807678
Mean value: 0.11596338450908661

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.1298471666875152e-11
Max value: 0.9987254738807678
Mean value: 0.11596338450908661

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.368324279785156
Max value: -1.1920928244535389e-07
Mean value: -0.1448068618774414

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7446045279502869
Max value: 3.620004177093506
Mean value: 1.000510334968567

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 32.267635345458984
Max value: 76.46675872802734
Mean value: 57.39323425292969

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.379478454589844
Max value: -57.379478454589844
Mean value: -57.379478454589844
sam_encoder.pos_embed grad: -1.7082014025504577e-08
sam_encoder.blocks.0.norm1.weight grad: -5.032859462517081e-06
sam_encoder.blocks.0.norm1.bias grad: -6.653810851275921e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.88525096848025e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.901323447687901e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.526469067262951e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.662855133119592e-07
sam_encoder.blocks.0.norm2.weight grad: 2.1993382688378915e-05
sam_encoder.blocks.0.norm2.bias grad: -3.256208947277628e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9888695533154532e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.502919288526755e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.082008333876729e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.81568701818469e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2933889593114145e-05
sam_encoder.blocks.1.norm1.bias grad: -2.011577453231439e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.596036423114128e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5325171009171754e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.148000127519481e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.543752882251283e-06
sam_encoder.blocks.1.norm2.weight grad: 1.6945463357842527e-05
sam_encoder.blocks.1.norm2.bias grad: 5.4088759497972205e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.094663502954063e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.175592493993463e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.2627644537133165e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.8182612393502495e-06
sam_encoder.blocks.2.norm1.weight grad: -1.2551117833936587e-05
sam_encoder.blocks.2.norm1.bias grad: -3.2853454285941552e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.765578978549456e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2010763157377369e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4982705579313915e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.466877600061707e-06
sam_encoder.blocks.2.norm2.weight grad: -4.554329734673956e-06
sam_encoder.blocks.2.norm2.bias grad: 1.1289858775853645e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.4797842595726252e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.0094747722178e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.82548000238603e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.622311399136379e-07
sam_encoder.blocks.3.norm1.weight grad: -6.570098776137456e-08
sam_encoder.blocks.3.norm1.bias grad: -1.5844723748159595e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.4688403022519196e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.992719707137439e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.99214332496922e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.6747545689431718e-06
sam_encoder.blocks.3.norm2.weight grad: -1.629571124794893e-05
sam_encoder.blocks.3.norm2.bias grad: -1.9717754184966907e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.982735718949698e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.3033906018099515e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.294139090343378e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.528624569706153e-06
sam_encoder.blocks.4.norm1.weight grad: 1.4478730008704588e-05
sam_encoder.blocks.4.norm1.bias grad: -1.7234928236575797e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.561563168361317e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.077154476864962e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.234155656173243e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.441323077728157e-07
sam_encoder.blocks.4.norm2.weight grad: -3.0067370971664786e-05
sam_encoder.blocks.4.norm2.bias grad: -3.115116555818531e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8033815649687313e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.053487140889047e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 8.083777174761053e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.0840120669163298e-06
sam_encoder.blocks.5.norm1.weight grad: 2.792822488117963e-05
sam_encoder.blocks.5.norm1.bias grad: -1.1254893252043985e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.3277802281663753e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.756648417649558e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.168647370126564e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.867931124863389e-07
sam_encoder.blocks.5.norm2.weight grad: 1.2075710401404649e-05
sam_encoder.blocks.5.norm2.bias grad: -4.147440449742135e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.2929589249542914e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.944367568285088e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.691021331382217e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.2058949323545676e-06
sam_encoder.blocks.6.norm1.weight grad: 1.046514262270648e-05
sam_encoder.blocks.6.norm1.bias grad: 3.3015380722645205e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.197756531240884e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.2231174625630956e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2529387731774477e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.302730197494384e-06
sam_encoder.blocks.6.norm2.weight grad: 2.7529993076313986e-06
sam_encoder.blocks.6.norm2.bias grad: -3.4376050734863384e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4475475609287969e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.077735305443639e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.3513750591064309e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1999722104860666e-08
sam_encoder.blocks.7.norm1.weight grad: 1.0708994523156434e-05
sam_encoder.blocks.7.norm1.bias grad: -1.3138031818016316e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.189117918140255e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.043286940534017e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.1569652492180467e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.5423494157148525e-06
sam_encoder.blocks.7.norm2.weight grad: 3.0378777182704653e-07
sam_encoder.blocks.7.norm2.bias grad: 1.6378003238060046e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.6296521582480636e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.1192777782962366e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.388978716931888e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.55546176126154e-08
sam_encoder.blocks.8.norm1.weight grad: 1.3594166148322984e-06
sam_encoder.blocks.8.norm1.bias grad: -1.274725832445256e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.9579865693231113e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.0003889201470884e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.4478330235288013e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.945411895576399e-06
sam_encoder.blocks.8.norm2.weight grad: 1.6189207599381916e-05
sam_encoder.blocks.8.norm2.bias grad: 4.4749202743332717e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.2052973033860326e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.731016012257896e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.947021236352157e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.6025782062788494e-06
sam_encoder.blocks.9.norm1.weight grad: 8.76395915838657e-06
sam_encoder.blocks.9.norm1.bias grad: 9.794082416192396e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.101684786903206e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.9885599158442346e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.155105903511867e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.243668632218032e-06
sam_encoder.blocks.9.norm2.weight grad: 2.1802909031976014e-05
sam_encoder.blocks.9.norm2.bias grad: 6.74046987114707e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.293011155212298e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.270256330433767e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.46169303561328e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.3544889700133353e-06
sam_encoder.blocks.10.norm1.weight grad: 5.897225491935387e-06
sam_encoder.blocks.10.norm1.bias grad: 4.045565219712444e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.8569596654269844e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.7005725112539949e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.193454282765742e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.3431354634340096e-07
sam_encoder.blocks.10.norm2.weight grad: 3.103678682236932e-05
sam_encoder.blocks.10.norm2.bias grad: 7.095798991940683e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.3942270015832037e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.721199497405905e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.8482343168434454e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.044112635412603e-07
sam_encoder.blocks.11.norm1.weight grad: -4.0053723751043435e-06
sam_encoder.blocks.11.norm1.bias grad: 3.641390776465414e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.4837859225735883e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.791117807049886e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.804234438575804e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.2198960348541732e-06
sam_encoder.blocks.11.norm2.weight grad: 2.546684663684573e-05
sam_encoder.blocks.11.norm2.bias grad: -1.0932420764220296e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.6353595128748566e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.3736052905151155e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.223764674155973e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.1551072677539196e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.6225967556238174e-06
sam_encoder.neck.conv1.trainable_shift grad: 5.970335769234225e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.6336634871549904e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.00018186704255640507
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00023217409034259617
mask_decoder.transformer.layers.0.norm1.bias grad: -2.7389178285375237e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 6.940215826034546e-06
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0013489320408552885
mask_decoder.transformer.layers.0.norm3.weight grad: -9.770643373485655e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00013982871314510703
mask_decoder.transformer.layers.0.norm4.weight grad: -1.993708428926766e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.4210672816261649e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.7987371140625328e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.678643330815248e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00016392910038121045
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00013597626821137965
mask_decoder.transformer.layers.1.norm3.weight grad: -4.426302984938957e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.5515047784429044e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.2827024774160236e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.3892358512966894e-05
mask_decoder.transformer.norm_final_attn.weight grad: -4.041778083774261e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3903389117331244e-05
Text_Embedding_Affine.0.weight grad: -1.3646157988322916e-11
Text_Embedding_Affine.0.bias grad: -5.798830859937709e-11
Text_Embedding_Affine.2.weight grad: -1.3095446949051848e-10
Text_Embedding_Affine.2.bias grad: -6.011240475345403e-05
Epoch 17 finished with average loss: -55.3568
Epoch 18/39
----------
Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.1]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-64.1]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-59.8]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-59.8]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-57.8]Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-57.8]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7521422003173234e-14
Max value: 0.9993301630020142
Mean value: 0.09342381358146667

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7521422003173234e-14
Max value: 0.9993301630020142
Mean value: 0.09342381358146667

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09313058853149414

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13361141085624695

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08342313766479492

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09313058853149414

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.400320053100586
Max value: 89.52925872802734
Mean value: 64.07588958740234

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7521422003173234e-14
Max value: 0.9993301630020142
Mean value: 0.09342381358146667

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7521422003173234e-14
Max value: 0.9993301630020142
Mean value: 0.09342381358146667

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7521422003173234e-14
Max value: 0.9993301630020142
Mean value: 0.09342381358146667

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13361141085624695

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.400320053100586
Max value: 89.52925872802734
Mean value: 64.07588958740234

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.07717895507812
Max value: -64.07717895507812
Mean value: -64.07717895507812
sam_encoder.pos_embed grad: 1.2749373778930817e-09
sam_encoder.blocks.0.norm1.weight grad: -2.6527026420808397e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0440942787681706e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.43729348422994e-08
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.09589802075061e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.5747576728463173e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.517492323609986e-08
sam_encoder.blocks.0.norm2.weight grad: 1.2435479220584966e-05
sam_encoder.blocks.0.norm2.bias grad: -1.881800699266023e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.136950443964452e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.899686817021575e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.983388069173088e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.914882196198732e-09
sam_encoder.blocks.1.norm1.weight grad: 1.7184523812829866e-06
sam_encoder.blocks.1.norm1.bias grad: 1.0724126696004532e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.958314315852476e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.535047656238021e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.877499340087525e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.666722818707058e-07
sam_encoder.blocks.1.norm2.weight grad: -6.7764040068141185e-06
sam_encoder.blocks.1.norm2.bias grad: 1.917411964313942e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.179561306547839e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.1673713490599766e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.016777216340415e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.5328949239738e-08
sam_encoder.blocks.2.norm1.weight grad: -3.3231185625481885e-06
sam_encoder.blocks.2.norm1.bias grad: 8.30578755994793e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.437342795426957e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.061564014700707e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.0722586551992208e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.918334171743481e-07
sam_encoder.blocks.2.norm2.weight grad: 2.0400523226271616e-06
sam_encoder.blocks.2.norm2.bias grad: -5.926937774347607e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.03965408015938e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.997429527975328e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.0691222744062543e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.2993520449053904e-07
sam_encoder.blocks.3.norm1.weight grad: 2.8109661798225716e-06
sam_encoder.blocks.3.norm1.bias grad: 8.787041224422865e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.040794010506943e-08
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.113045062898891e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.165519840171328e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.0358113488327945e-06
sam_encoder.blocks.3.norm2.weight grad: -6.635421414102893e-06
sam_encoder.blocks.3.norm2.bias grad: -4.285896466171835e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.225061613600701e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.3872826229999191e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.826797627785709e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.046463454367768e-07
sam_encoder.blocks.4.norm1.weight grad: 4.764912318933057e-06
sam_encoder.blocks.4.norm1.bias grad: -8.100901141006034e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.9876516691729194e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.65459698059567e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.793232051270024e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2257116850378225e-06
sam_encoder.blocks.4.norm2.weight grad: 7.749371434329078e-06
sam_encoder.blocks.4.norm2.bias grad: 4.084727606823435e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.615683337760856e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.6331049437212641e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.45919203129597e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.1653933635643625e-07
sam_encoder.blocks.5.norm1.weight grad: 3.842585556412814e-06
sam_encoder.blocks.5.norm1.bias grad: -1.746106136124581e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.103243438497884e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.589583007444162e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0122001867785002e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.5811194771231385e-06
sam_encoder.blocks.5.norm2.weight grad: 2.553972080931999e-06
sam_encoder.blocks.5.norm2.bias grad: 1.8168411770602688e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.3137794212525478e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.036229543340596e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.155579752776248e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.812342465105758e-07
sam_encoder.blocks.6.norm1.weight grad: 6.840718356215802e-07
sam_encoder.blocks.6.norm1.bias grad: -3.625579438448767e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.3682270036952104e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.7649961137067294e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.7839474253378285e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.769479992703054e-08
sam_encoder.blocks.6.norm2.weight grad: 1.7121650444096304e-06
sam_encoder.blocks.6.norm2.bias grad: 3.176052814524155e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.2713643116057938e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.761557655299839e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.082397696147382e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.702370688391966e-07
sam_encoder.blocks.7.norm1.weight grad: 2.8278151376071037e-07
sam_encoder.blocks.7.norm1.bias grad: -1.8599355371407e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.910342568109627e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.031076912269782e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.1136994544358458e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.830222787357343e-07
sam_encoder.blocks.7.norm2.weight grad: -3.347328856762033e-06
sam_encoder.blocks.7.norm2.bias grad: 1.2072167692167568e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.847070163625176e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7164436485472834e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.262579409441969e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.472148695342185e-07
sam_encoder.blocks.8.norm1.weight grad: 1.5701970141890342e-06
sam_encoder.blocks.8.norm1.bias grad: 9.265120297641261e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.4539563128200825e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.82608686020103e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.9815840914816363e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5497328149649547e-06
sam_encoder.blocks.8.norm2.weight grad: -2.4468206447636476e-06
sam_encoder.blocks.8.norm2.bias grad: 1.8547051467976416e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.450825261097634e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.6604242318862816e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.433448783762287e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.0930619015757657e-08
sam_encoder.blocks.9.norm1.weight grad: 1.0969233699142933e-06
sam_encoder.blocks.9.norm1.bias grad: -3.8925369949538435e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.041948725192924e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.329172836354701e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.004760233376146e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.194674545487942e-07
sam_encoder.blocks.9.norm2.weight grad: -1.048473905029823e-06
sam_encoder.blocks.9.norm2.bias grad: 1.634311388443166e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.005219357670285e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.4362531070873956e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.274076440604404e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.09174378496391e-07
sam_encoder.blocks.10.norm1.weight grad: -2.9346224437176716e-06
sam_encoder.blocks.10.norm1.bias grad: 4.667913060529827e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.4168400614144048e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.763989510247484e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3776898413198069e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.335996426467318e-07
sam_encoder.blocks.10.norm2.weight grad: -3.305055997770978e-06
sam_encoder.blocks.10.norm2.bias grad: 9.826887890085345e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.6200311822321964e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.864180477350601e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.1117721732698556e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.590676047020679e-07
sam_encoder.blocks.11.norm1.weight grad: -7.300894139916636e-06
sam_encoder.blocks.11.norm1.bias grad: 1.615217115613632e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.474261115523404e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.78063065859169e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.7309994291281328e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.520732197008329e-07
sam_encoder.blocks.11.norm2.weight grad: -2.841382183760288e-06
sam_encoder.blocks.11.norm2.bias grad: 8.1914777183556e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.533879296606756e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.2958149037986004e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.061991371097974e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.9781295651787332e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.1065701477928087e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.774957233166788e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.148157005256508e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.2534975869348273e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00012927909847348928
mask_decoder.transformer.layers.0.norm1.bias grad: -7.183589332271367e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004331602714955807
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00016661884728819132
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00012372247874736786
mask_decoder.transformer.layers.0.norm3.bias grad: 3.6769088183064014e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001013544388115406
mask_decoder.transformer.layers.0.norm4.bias grad: 9.17476700124098e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.1650526832672767e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.8853679648600519e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.553402711986564e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -4.318886203691363e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.523171471897513e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.444018900860101e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.031726348330267e-07
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001137147773988545
mask_decoder.transformer.norm_final_attn.weight grad: -1.6372953268728452e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2335989595158026e-05
Text_Embedding_Affine.0.weight grad: 1.0293418027662593e-11
Text_Embedding_Affine.0.bias grad: 3.134298098839139e-10
Text_Embedding_Affine.2.weight grad: -1.0973737196717792e-10
Text_Embedding_Affine.2.bias grad: -3.2103642297443e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.7218240562262324e-11
Max value: 0.9995818734169006
Mean value: 0.0785248726606369

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.7218240562262324e-11
Max value: 0.9995818734169006
Mean value: 0.0785248726606369

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08348989486694336

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12111993879079819

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07104635238647461

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08348989486694336

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 32.40065002441406
Max value: 80.08294677734375
Mean value: 55.60511016845703

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.478698661936065e-11
Max value: 0.9995636343955994
Mean value: 0.07856985926628113

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.478698661936065e-11
Max value: 0.9995636343955994
Mean value: 0.07856985926628113

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.478698661936065e-11
Max value: 0.9995636343955994
Mean value: 0.07856985926628113

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1211698055267334

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6762422919273376
Max value: 1.1930279731750488
Mean value: 0.9999650716781616

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 32.40065002441406
Max value: 80.08294677734375
Mean value: 55.60511016845703

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.60606384277344
Max value: -55.60606384277344
Mean value: -55.60606384277344
sam_encoder.pos_embed grad: -1.2457176623570376e-08
sam_encoder.blocks.0.norm1.weight grad: 5.8554487623041496e-05
sam_encoder.blocks.0.norm1.bias grad: 9.455338295083493e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.268646155949682e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.312465767317917e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.9158778741257265e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.8789054340450093e-06
sam_encoder.blocks.0.norm2.weight grad: 0.0001246692263521254
sam_encoder.blocks.0.norm2.bias grad: -5.876571231056005e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.088330362923443e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.100708899088204e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.3983962819329463e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.6444582797703333e-05
sam_encoder.blocks.1.norm1.weight grad: 3.826310421572998e-05
sam_encoder.blocks.1.norm1.bias grad: 2.0695921193691902e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.098978993421042e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.1680950794689124e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.0844145435839891e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.508882855385309e-06
sam_encoder.blocks.1.norm2.weight grad: -1.2880371286883019e-05
sam_encoder.blocks.1.norm2.bias grad: 1.736649574013427e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.1824738976429217e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.612425866274862e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.433126610412728e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.0167527711455477e-06
sam_encoder.blocks.2.norm1.weight grad: -1.4159296370053198e-05
sam_encoder.blocks.2.norm1.bias grad: 7.576457392133307e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1765216186176986e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.4995969144802075e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5512086974922568e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.1950309271924198e-05
sam_encoder.blocks.2.norm2.weight grad: -4.392070877656806e-06
sam_encoder.blocks.2.norm2.bias grad: -2.2098320187069476e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.143306670011953e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.0948336921501323e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.4356631254486274e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.6528513192024548e-06
sam_encoder.blocks.3.norm1.weight grad: -3.497855141176842e-05
sam_encoder.blocks.3.norm1.bias grad: 8.27459280117182e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.6260884624207392e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.021045919624157e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.704946256126277e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.70276710682083e-06
sam_encoder.blocks.3.norm2.weight grad: -6.814834250690183e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1203883332200348e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0070259122585412e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.7406053959566634e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.2806455742975231e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.3484644771087915e-06
sam_encoder.blocks.4.norm1.weight grad: 3.541936166584492e-08
sam_encoder.blocks.4.norm1.bias grad: -2.7068763301940635e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.055224169656867e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.6516391951881815e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 9.486187764196075e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.6468109151901444e-06
sam_encoder.blocks.4.norm2.weight grad: 2.8840472623414826e-06
sam_encoder.blocks.4.norm2.bias grad: 4.523947609413881e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8839367612599744e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.9524177332641557e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.5315412156269304e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.5326256743719568e-06
sam_encoder.blocks.5.norm1.weight grad: 1.2735922609863337e-05
sam_encoder.blocks.5.norm1.bias grad: -4.75648048450239e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.8224762243335135e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.3340679288376123e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.503173376084305e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.317143743217457e-06
sam_encoder.blocks.5.norm2.weight grad: 2.3045904526952654e-06
sam_encoder.blocks.5.norm2.bias grad: -2.626058630994521e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.6144571165787056e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2146571179982857e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.891289796025376e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.707727955770679e-07
sam_encoder.blocks.6.norm1.weight grad: 1.4707526133861393e-05
sam_encoder.blocks.6.norm1.bias grad: -1.4467628716374747e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.095578681997722e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.107681656430941e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.669157078751596e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.962950475193793e-06
sam_encoder.blocks.6.norm2.weight grad: -3.2478926641488215e-06
sam_encoder.blocks.6.norm2.bias grad: 7.210338935692562e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.192309567471966e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.5242369449406397e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.457313934835838e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0337649882785627e-06
sam_encoder.blocks.7.norm1.weight grad: 1.0702664440032095e-05
sam_encoder.blocks.7.norm1.bias grad: 1.2746239690386574e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.291285783139756e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.7913481466821395e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.964756393135758e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.1334699340513907e-06
sam_encoder.blocks.7.norm2.weight grad: 1.0176389878324699e-05
sam_encoder.blocks.7.norm2.bias grad: 5.540752226806944e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.533053237944841e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.2259536055789795e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.631547258464707e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.18557534278807e-06
sam_encoder.blocks.8.norm1.weight grad: -6.525958724523662e-06
sam_encoder.blocks.8.norm1.bias grad: -5.585654434980825e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.6396028260933235e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.0783628517383477e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.8895096875203308e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.064005002466729e-07
sam_encoder.blocks.8.norm2.weight grad: -1.6389740267186426e-06
sam_encoder.blocks.8.norm2.bias grad: -2.002336941586691e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.9030459245404927e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.54571532929549e-09
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.221090426246519e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1382534239601227e-06
sam_encoder.blocks.9.norm1.weight grad: -5.0864559852925595e-06
sam_encoder.blocks.9.norm1.bias grad: 4.034255653095897e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.333715529966867e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.13867633647169e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.7783380573964678e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.716391463764012e-06
sam_encoder.blocks.9.norm2.weight grad: 7.3952096499851905e-06
sam_encoder.blocks.9.norm2.bias grad: -8.542652807363993e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.8634767659241334e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.0446208256762475e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.8495112474047346e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.9616361441876506e-06
sam_encoder.blocks.10.norm1.weight grad: 3.2177422326640226e-06
sam_encoder.blocks.10.norm1.bias grad: 4.310955318942433e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.324406184721738e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.389956971972424e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.195273272169288e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.339563126151916e-07
sam_encoder.blocks.10.norm2.weight grad: 8.680543032824062e-06
sam_encoder.blocks.10.norm2.bias grad: -3.650733049198607e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.863758138322737e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.484199381404324e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.372564591103583e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.4652409769696533e-07
sam_encoder.blocks.11.norm1.weight grad: -1.998202787945047e-05
sam_encoder.blocks.11.norm1.bias grad: -1.0523093578740372e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.134029495617142e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.625832848934806e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1325466857670108e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7395193481206661e-06
sam_encoder.blocks.11.norm2.weight grad: -1.689256237114023e-06
sam_encoder.blocks.11.norm2.bias grad: -3.3643664210103452e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.398218490881845e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.319106210459722e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.396608351773466e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0307596767233917e-06
sam_encoder.neck.conv1.trainable_scale grad: -4.3441832531243563e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.473443055350799e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.1773518053814769e-06
sam_encoder.neck.conv2.trainable_shift grad: -8.152432201313786e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016730703646317124
mask_decoder.transformer.layers.0.norm1.bias grad: -5.774476449005306e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00010820361785590649
mask_decoder.transformer.layers.0.norm2.bias grad: -8.374662138521671e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -2.828821016009897e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.5661992771783844e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.412556492956355e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.722026905161329e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.78648039966356e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.824585969094187e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 6.944327469682321e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -9.719944500830024e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.179665898438543e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -7.599527634738479e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 2.6689092919696122e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -6.943939661141485e-05
mask_decoder.transformer.norm_final_attn.weight grad: 6.726809260726441e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.1379115676390938e-06
Text_Embedding_Affine.0.weight grad: -1.0102353675822684e-10
Text_Embedding_Affine.0.bias grad: -1.4979320006602848e-09
Text_Embedding_Affine.2.weight grad: 4.631477146244123e-11
Text_Embedding_Affine.2.bias grad: -2.272863275720738e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.679474681692277e-13
Max value: 0.9979569911956787
Mean value: 0.06308046728372574

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.679474681692277e-13
Max value: 0.9979569911956787
Mean value: 0.06308046728372574

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06470489501953125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10690987855195999

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05158519744873047

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06470489501953125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 30.35884666442871
Max value: 70.93174743652344
Mean value: 53.57707214355469

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.049738939314543e-13
Max value: 0.9981561303138733
Mean value: 0.06364038586616516

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.049738939314543e-13
Max value: 0.9981561303138733
Mean value: 0.06364038586616516

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.049738939314543e-13
Max value: 0.9981561303138733
Mean value: 0.06364038586616516

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10677723586559296

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8176119923591614
Max value: 1.141225814819336
Mean value: 1.0001509189605713

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 30.35884666442871
Max value: 70.93174743652344
Mean value: 53.57707214355469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.5890998840332
Max value: -53.5890998840332
Mean value: -53.5890998840332
sam_encoder.pos_embed grad: -6.251484219177428e-09
sam_encoder.blocks.0.norm1.weight grad: -4.9918395234271884e-05
sam_encoder.blocks.0.norm1.bias grad: -2.9069280572002754e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -8.172928573912941e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3923867072662688e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2845280252804514e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.96531640944886e-06
sam_encoder.blocks.0.norm2.weight grad: -1.3103417586535215e-06
sam_encoder.blocks.0.norm2.bias grad: 5.619285366265103e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.8382735308696283e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.136668839142658e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 6.062594820832601e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.582603651215322e-06
sam_encoder.blocks.1.norm1.weight grad: -1.356002712782356e-06
sam_encoder.blocks.1.norm1.bias grad: -1.4428980648517609e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.1606427910446655e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.5426820709762978e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.714453441716614e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.7107114419777645e-06
sam_encoder.blocks.1.norm2.weight grad: 3.567122621461749e-05
sam_encoder.blocks.1.norm2.bias grad: -2.7178128192417716e-08
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.2524184967332985e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.702336471178569e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.6696783859515563e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.679946409349213e-07
sam_encoder.blocks.2.norm1.weight grad: 1.228768360306276e-05
sam_encoder.blocks.2.norm1.bias grad: -2.9281582101248205e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 9.10710878088139e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.5352950413216604e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.206842269624758e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.090454410743405e-07
sam_encoder.blocks.2.norm2.weight grad: 2.6394936867291108e-06
sam_encoder.blocks.2.norm2.bias grad: 1.1484803508210462e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.347959818711388e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.848601626392337e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 9.859008059720509e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.1265336727083195e-06
sam_encoder.blocks.3.norm1.weight grad: -6.713037691952195e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0725473657657858e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.6513096145208692e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.0046089755633147e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.573621143004857e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.9052988591283793e-06
sam_encoder.blocks.3.norm2.weight grad: 1.931941915245261e-05
sam_encoder.blocks.3.norm2.bias grad: -2.2640033421339467e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.3108845450915396e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.404788680607453e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.429020009411033e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7029354921760387e-06
sam_encoder.blocks.4.norm1.weight grad: -2.842948333636741e-06
sam_encoder.blocks.4.norm1.bias grad: -3.387516471775598e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.4914273833710467e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1880986221513012e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.45663034345489e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8364056586506194e-06
sam_encoder.blocks.4.norm2.weight grad: 4.050423740409315e-06
sam_encoder.blocks.4.norm2.bias grad: -2.1420555640361272e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.557340394560015e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 8.774695459123905e-08
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.077843292790931e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.9613548829511274e-06
sam_encoder.blocks.5.norm1.weight grad: 1.3495884559233673e-05
sam_encoder.blocks.5.norm1.bias grad: 8.427744432992768e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.243581315677147e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.640854159442824e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.0020206673289067e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.2089982110173878e-07
sam_encoder.blocks.5.norm2.weight grad: 4.235067535773851e-06
sam_encoder.blocks.5.norm2.bias grad: -1.312462700298056e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.1651212591677904e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.1277307976342854e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.591105951272766e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.3347661226580385e-07
sam_encoder.blocks.6.norm1.weight grad: -2.6612792680680286e-06
sam_encoder.blocks.6.norm1.bias grad: 7.355480192927644e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.304990615215502e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.141158787111635e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.1561635346879484e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1261148529229104e-06
sam_encoder.blocks.6.norm2.weight grad: 7.654057299077976e-07
sam_encoder.blocks.6.norm2.bias grad: -9.662302318247384e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3515191312762909e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.560988907722276e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.437441690351989e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.111344658966118e-06
sam_encoder.blocks.7.norm1.weight grad: 1.1089223335147835e-06
sam_encoder.blocks.7.norm1.bias grad: 1.207653667734121e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.355359912253334e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.081137597225279e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.2100391561252763e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.7608203911077e-06
sam_encoder.blocks.7.norm2.weight grad: 1.189928298117593e-05
sam_encoder.blocks.7.norm2.bias grad: -2.6481425265956204e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.40526933845831e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.4703396067925496e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.8737503871288936e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.535420146112301e-07
sam_encoder.blocks.8.norm1.weight grad: 5.504852651938563e-06
sam_encoder.blocks.8.norm1.bias grad: 6.283661946326902e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.1238002975442214e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.760789912936161e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.1741789052166496e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.864652396463498e-07
sam_encoder.blocks.8.norm2.weight grad: 9.547980880597606e-06
sam_encoder.blocks.8.norm2.bias grad: 7.608003897985327e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.820025530236308e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.6436121010628995e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.171141192912728e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.665549795390689e-07
sam_encoder.blocks.9.norm1.weight grad: 6.414753670469509e-07
sam_encoder.blocks.9.norm1.bias grad: 1.5676134808018105e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.228609320009127e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.84977987172897e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.7110385164851323e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.114709438203136e-07
sam_encoder.blocks.9.norm2.weight grad: 5.856541065440979e-06
sam_encoder.blocks.9.norm2.bias grad: 2.2583571990253404e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7412661463822587e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.8624914446263574e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.001008397201076e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.150608437063056e-07
sam_encoder.blocks.10.norm1.weight grad: 4.225553766445955e-06
sam_encoder.blocks.10.norm1.bias grad: 1.6302510630339384e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.3580801098432858e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.1993674888799433e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.055784294607292e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.3340469113009021e-07
sam_encoder.blocks.10.norm2.weight grad: 5.991534180793678e-06
sam_encoder.blocks.10.norm2.bias grad: 9.26726443140069e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.126671683479799e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.7358196297864197e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2561051789816702e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.483830361503351e-07
sam_encoder.blocks.11.norm1.weight grad: 1.950600926647894e-05
sam_encoder.blocks.11.norm1.bias grad: -1.1011313745257212e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.4237070899980608e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.24788776551577e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8190564787801122e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.2808616146649e-07
sam_encoder.blocks.11.norm2.weight grad: 9.548861271468922e-06
sam_encoder.blocks.11.norm2.bias grad: 1.4929208873581956e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.0555989875865635e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.551121138429153e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.55832924014976e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.469020816102784e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.829836714430712e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.7608941561775282e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8520131561672315e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.8962473404826596e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -4.5837805373594165e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.5605550035834312e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0037700715474784374
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00018304953118786216
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011577113036764786
mask_decoder.transformer.layers.0.norm3.bias grad: -9.37088843784295e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013286707689985633
mask_decoder.transformer.layers.0.norm4.bias grad: -3.074762389587704e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.991596142644994e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 2.7606711228145286e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00028920540353283286
mask_decoder.transformer.layers.1.norm2.bias grad: -6.557849701493979e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.15986035275273e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.4812110495986417e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00010194440983468667
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00022592954337596893
mask_decoder.transformer.norm_final_attn.weight grad: 3.6829576401942177e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.493195542134345e-06
Text_Embedding_Affine.0.weight grad: -1.7437530586139616e-11
Text_Embedding_Affine.0.bias grad: -6.084671655415264e-10
Text_Embedding_Affine.2.weight grad: 4.418345203593965e-11
Text_Embedding_Affine.2.bias grad: 2.7500833311933093e-05
Epoch 18 finished with average loss: -57.7574
Epoch 19/39
----------
Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/3 [00:01<?, ?it/s, loss=-53.4]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-53.4]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-56.4]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.55it/s, loss=-56.4]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.55it/s, loss=-61]  Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.13it/s, loss=-61]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.797238163941253e-16
Max value: 0.9975161552429199
Mean value: 0.08099337667226791

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.797238163941253e-16
Max value: 0.9975161552429199
Mean value: 0.08099337667226791

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06871318817138672

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12237894535064697

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.060431480407714844

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06871318817138672

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.877803802490234
Max value: 77.34548950195312
Mean value: 53.36005401611328

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.797238163941253e-16
Max value: 0.9975161552429199
Mean value: 0.08099337667226791

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.797238163941253e-16
Max value: 0.9975161552429199
Mean value: 0.08099337667226791

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.797238163941253e-16
Max value: 0.9975161552429199
Mean value: 0.08099337667226791

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12237894535064697

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.877803802490234
Max value: 77.34548950195312
Mean value: 53.36005401611328

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.36141586303711
Max value: -53.36141586303711
Mean value: -53.36141586303711
sam_encoder.pos_embed grad: -7.733864215708763e-09
sam_encoder.blocks.0.norm1.weight grad: 5.332592991180718e-05
sam_encoder.blocks.0.norm1.bias grad: 4.035831443616189e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.6523795137763955e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.410579658222559e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.1447459655755665e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.84496194228268e-07
sam_encoder.blocks.0.norm2.weight grad: 3.8201305869733915e-05
sam_encoder.blocks.0.norm2.bias grad: 2.616249184939079e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.856774128507823e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.374237283220282e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.364784323726781e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.3952495666890172e-06
sam_encoder.blocks.1.norm1.weight grad: 3.126615411019884e-06
sam_encoder.blocks.1.norm1.bias grad: -1.6732340100134024e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.013967559832963e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.116863909890526e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.6553566335205687e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.7178836060338654e-06
sam_encoder.blocks.1.norm2.weight grad: 1.150686148321256e-05
sam_encoder.blocks.1.norm2.bias grad: 7.562462997157127e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.141663106973283e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.9185431432997575e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.2063326266797958e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4116864096868085e-06
sam_encoder.blocks.2.norm1.weight grad: -3.126958063148777e-06
sam_encoder.blocks.2.norm1.bias grad: -3.81356358047924e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.7367777900290093e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4443884310821886e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.252141479810234e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.072126790153561e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0156944881600793e-05
sam_encoder.blocks.2.norm2.bias grad: -6.735597253282322e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.23758308190736e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.7683263422441087e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.972576334694168e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.1512477072226375e-09
sam_encoder.blocks.3.norm1.weight grad: 4.786994850292103e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0570365702733397e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.0217589735693764e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.080166384781478e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.446328380756313e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.135663180524716e-06
sam_encoder.blocks.3.norm2.weight grad: 1.3093988400214585e-06
sam_encoder.blocks.3.norm2.bias grad: -2.2461379103333456e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.2879537482367596e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.8757292486479855e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.862275313324062e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3555188616010128e-06
sam_encoder.blocks.4.norm1.weight grad: 1.833574060583487e-05
sam_encoder.blocks.4.norm1.bias grad: 5.257928705759696e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.6343591242912225e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.245212595487828e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.655892553273588e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.352342335143476e-06
sam_encoder.blocks.4.norm2.weight grad: -2.97738442895934e-05
sam_encoder.blocks.4.norm2.bias grad: -1.6172800314961933e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.7038159057847224e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.264041076065041e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.7570986301507219e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0809858395077754e-06
sam_encoder.blocks.5.norm1.weight grad: 2.650116221047938e-05
sam_encoder.blocks.5.norm1.bias grad: 1.2550435712910257e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.716448059596587e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.442250545049319e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 7.3376809268665966e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.903910510416608e-06
sam_encoder.blocks.5.norm2.weight grad: -5.525322194444016e-06
sam_encoder.blocks.5.norm2.bias grad: -6.512188519991469e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2818117031420115e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.702368071069941e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8664526351130917e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.598939765150135e-07
sam_encoder.blocks.6.norm1.weight grad: -4.6425657274085097e-07
sam_encoder.blocks.6.norm1.bias grad: 2.0702827896457165e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.3382978067966178e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.3520683473398094e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.237048412709555e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1853359183078283e-06
sam_encoder.blocks.6.norm2.weight grad: 1.7482461771578528e-06
sam_encoder.blocks.6.norm2.bias grad: -3.485036756956106e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.694432386211702e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.4588788366818335e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.316363406862365e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0010247564196106e-07
sam_encoder.blocks.7.norm1.weight grad: 2.350020167796174e-06
sam_encoder.blocks.7.norm1.bias grad: 7.130576022973401e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.3253614926943555e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.4585828946947e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.9247625004936708e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.6516341929673217e-06
sam_encoder.blocks.7.norm2.weight grad: -4.083198632542917e-07
sam_encoder.blocks.7.norm2.bias grad: 2.1389212179201422e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.689545095170615e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.968483603486675e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.688633801677497e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.673465916013811e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0154602932743728e-05
sam_encoder.blocks.8.norm1.bias grad: -4.431237243807118e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.02200372365769e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.551311354181962e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.1548296444962034e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.1152249044243945e-06
sam_encoder.blocks.8.norm2.weight grad: 1.2080079159204615e-06
sam_encoder.blocks.8.norm2.bias grad: -1.0125336302735377e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.8551047509827185e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.4385186375420744e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.142128879422671e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.251166612652014e-07
sam_encoder.blocks.9.norm1.weight grad: 4.583383088174742e-06
sam_encoder.blocks.9.norm1.bias grad: 1.656886297496385e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.7449018489278387e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4044042018213077e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.357219604069542e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.165269041957799e-07
sam_encoder.blocks.9.norm2.weight grad: 5.382891686167568e-06
sam_encoder.blocks.9.norm2.bias grad: 7.516329674217559e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.057963451487012e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.5011081561387982e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1013224820999312e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.5350119042523147e-07
sam_encoder.blocks.10.norm1.weight grad: 3.5022253541683313e-06
sam_encoder.blocks.10.norm1.bias grad: 1.8692728644964518e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.9033204807783477e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.179313244392688e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.851861940049275e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.87298149714843e-07
sam_encoder.blocks.10.norm2.weight grad: 6.144139661046211e-06
sam_encoder.blocks.10.norm2.bias grad: 1.2278669601073489e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.454453573998762e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.722699380479753e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.451702461163222e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.617769716081966e-08
sam_encoder.blocks.11.norm1.weight grad: 2.3012709789327346e-05
sam_encoder.blocks.11.norm1.bias grad: 8.616156037533074e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.867267878376879e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.3041078545938944e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.9248491298640147e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.379822252711165e-07
sam_encoder.blocks.11.norm2.weight grad: 9.931374734151177e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2723764939437388e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.634625267703086e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.305867385781312e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.2246766800672049e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.961386821378255e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.660320650553331e-08
sam_encoder.neck.conv1.trainable_shift grad: -5.748151124862488e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.767448551021516e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.1170901416335255e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.515940185636282e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.343940311926417e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005865773651748896
mask_decoder.transformer.layers.0.norm2.bias grad: 4.939083009958267e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -6.93318506819196e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.286694143549539e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001176486475742422
mask_decoder.transformer.layers.0.norm4.bias grad: -4.371208888187539e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.4351215213537216e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.1272993510356173e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00011936645023524761
mask_decoder.transformer.layers.1.norm2.bias grad: 6.77266507409513e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -9.114781278185546e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -9.29639190871967e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00012043405149597675
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00027017068350687623
mask_decoder.transformer.norm_final_attn.weight grad: 7.11177199264057e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.6667770978529006e-05
Text_Embedding_Affine.0.weight grad: 1.3186739027115646e-13
Text_Embedding_Affine.0.bias grad: 8.760800418450287e-11
Text_Embedding_Affine.2.weight grad: 4.8230780480551516e-11
Text_Embedding_Affine.2.bias grad: 3.760788240469992e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.617622505007304e-11
Max value: 0.9989345669746399
Mean value: 0.09264080226421356

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.617622505007304e-11
Max value: 0.9989345669746399
Mean value: 0.09264080226421356

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09419488906860352

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12980522215366364

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08536481857299805

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09419488906860352

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.83027648925781
Max value: 76.5
Mean value: 59.47447967529297

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.139752149556202e-11
Max value: 0.998795747756958
Mean value: 0.09331519901752472

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.139752149556202e-11
Max value: 0.998795747756958
Mean value: 0.09331519901752472

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.139752149556202e-11
Max value: 0.998795747756958
Mean value: 0.09331519901752472

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12968571484088898

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9139663577079773
Max value: 1.762579083442688
Mean value: 1.0001652240753174

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.83027648925781
Max value: 76.5
Mean value: 59.47447967529297

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.481929779052734
Max value: -59.481929779052734
Mean value: -59.481929779052734
sam_encoder.pos_embed grad: 3.4728084852275742e-09
sam_encoder.blocks.0.norm1.weight grad: -1.4951404409657698e-05
sam_encoder.blocks.0.norm1.bias grad: -5.2607516408897936e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.2069826829683734e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.272445378068369e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.540028956194874e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.4382046629179968e-06
sam_encoder.blocks.0.norm2.weight grad: 3.190990537405014e-05
sam_encoder.blocks.0.norm2.bias grad: -5.7423230828135274e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.639837243303191e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.483793756866362e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.365456207888201e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.10199446984916e-06
sam_encoder.blocks.1.norm1.weight grad: 1.8221113350591622e-05
sam_encoder.blocks.1.norm1.bias grad: 5.13089144078549e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.1821313061518595e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.8704751002806006e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.710088539170101e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.89288959215628e-06
sam_encoder.blocks.1.norm2.weight grad: -1.4044766430743039e-05
sam_encoder.blocks.1.norm2.bias grad: -4.57244004792301e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0489823580428492e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.8689946702797897e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.582165689091198e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.146651463088347e-06
sam_encoder.blocks.2.norm1.weight grad: -4.901992269878974e-06
sam_encoder.blocks.2.norm1.bias grad: -3.8286697190415e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.635483259742614e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7796353404264664e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.79995651403442e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.193155059008859e-06
sam_encoder.blocks.2.norm2.weight grad: -1.2835294000979047e-05
sam_encoder.blocks.2.norm2.bias grad: -1.4424365872400813e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.719518180238083e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.8440875919623068e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.8150933101424016e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.538501798379002e-06
sam_encoder.blocks.3.norm1.weight grad: -9.695163498690818e-06
sam_encoder.blocks.3.norm1.bias grad: 2.837630518115475e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.286024689761689e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.780768681986956e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.614781108917668e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.482888693426503e-06
sam_encoder.blocks.3.norm2.weight grad: -9.637859875510912e-06
sam_encoder.blocks.3.norm2.bias grad: 7.378826467174804e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.322215540421894e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.2585634695815315e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.3597598897140415e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.796804079087451e-07
sam_encoder.blocks.4.norm1.weight grad: 9.99830626824405e-06
sam_encoder.blocks.4.norm1.bias grad: 2.619461611175211e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.966232730410411e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.1334340090106707e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.4276614592745318e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.621096311690053e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5384222681168467e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0037465472123586e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.898510890896432e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.133211627457058e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.7466246542171575e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.8602165710035479e-06
sam_encoder.blocks.5.norm1.weight grad: 8.410956070292741e-06
sam_encoder.blocks.5.norm1.bias grad: -5.941377366980305e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.073543656588299e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.047358513365907e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.3067819888165104e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.193768407072639e-06
sam_encoder.blocks.5.norm2.weight grad: -3.114259016001597e-05
sam_encoder.blocks.5.norm2.bias grad: -5.5788018471503165e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.029694223892875e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.235985322040506e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.6101671462820377e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.68510789789434e-07
sam_encoder.blocks.6.norm1.weight grad: 8.900025932234712e-06
sam_encoder.blocks.6.norm1.bias grad: -1.6487936136400094e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.8082542889460456e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.0841766854573507e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.675922931099194e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.1422623629187e-06
sam_encoder.blocks.6.norm2.weight grad: -3.738625991900335e-06
sam_encoder.blocks.6.norm2.bias grad: 8.390528591917246e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.073273314337712e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.1665223357558716e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.576843022936373e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.912326462796045e-07
sam_encoder.blocks.7.norm1.weight grad: -2.2341873773257248e-07
sam_encoder.blocks.7.norm1.bias grad: 1.2491693723859498e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.4918308579581208e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.679387519805459e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.238247690111166e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7380001509081922e-06
sam_encoder.blocks.7.norm2.weight grad: -1.0080790161737241e-05
sam_encoder.blocks.7.norm2.bias grad: 3.7625511595251737e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.1654215995804407e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.5455652727687266e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.052097443083767e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.307766801048274e-07
sam_encoder.blocks.8.norm1.weight grad: 7.1775848482502624e-06
sam_encoder.blocks.8.norm1.bias grad: 1.233861553373572e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.673181244172156e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.2819235709903296e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.818577500984247e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.2636425001110183e-06
sam_encoder.blocks.8.norm2.weight grad: -9.157549357041717e-06
sam_encoder.blocks.8.norm2.bias grad: -2.2561820856026316e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.0035819286713377e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.007139745634049e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.7877913478514529e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.240441502493923e-07
sam_encoder.blocks.9.norm1.weight grad: -6.250943442864809e-07
sam_encoder.blocks.9.norm1.bias grad: -3.4212905575259356e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.0580935142788803e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.49054153553152e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7522995676699793e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.7896834378916537e-06
sam_encoder.blocks.9.norm2.weight grad: -3.190436473232694e-06
sam_encoder.blocks.9.norm2.bias grad: -3.32562137828063e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.259717570676003e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.0657591903727734e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.2267034890101058e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.524126885982696e-07
sam_encoder.blocks.10.norm1.weight grad: 2.3750933451083256e-06
sam_encoder.blocks.10.norm1.bias grad: -1.7603983906155918e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.038980421228189e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.8773032429162413e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.672571200600942e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.422832494630711e-07
sam_encoder.blocks.10.norm2.weight grad: -9.295024938182905e-06
sam_encoder.blocks.10.norm2.bias grad: -3.338972192068468e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.6920198403531685e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.5301746973127592e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.960427991638426e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.770314797677202e-08
sam_encoder.blocks.11.norm1.weight grad: -7.674885637243278e-06
sam_encoder.blocks.11.norm1.bias grad: -5.580638458013709e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1559640370251145e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.4975130397942849e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.834524697296729e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.295634082358447e-07
sam_encoder.blocks.11.norm2.weight grad: -4.314497346058488e-06
sam_encoder.blocks.11.norm2.bias grad: -1.6911862985580228e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.905454039137112e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.5804935173946433e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.2104134106702986e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.6220869737444445e-08
sam_encoder.neck.conv1.trainable_scale grad: 8.736697054700926e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1391481166356243e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.478414899087511e-06
sam_encoder.neck.conv2.trainable_shift grad: -6.0869847402500454e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -8.139312558341771e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.113564500585198e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004484220407903194
mask_decoder.transformer.layers.0.norm2.bias grad: -9.026160114444792e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00022121969959698617
mask_decoder.transformer.layers.0.norm3.bias grad: 0.00012309252633713186
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001054171661962755
mask_decoder.transformer.layers.0.norm4.bias grad: 7.376606845355127e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.2962234147125855e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.014893187966663e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002759071940090507
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00012059237633366138
mask_decoder.transformer.layers.1.norm3.weight grad: 6.623741683142725e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 5.176529521122575e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.483673157868907e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.784452954074368e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.3763693611253984e-06
mask_decoder.transformer.norm_final_attn.bias grad: -2.1402021957328543e-05
Text_Embedding_Affine.0.weight grad: -2.0289816701768437e-11
Text_Embedding_Affine.0.bias grad: -7.817938518783762e-10
Text_Embedding_Affine.2.weight grad: -5.433578934010974e-12
Text_Embedding_Affine.2.bias grad: -1.6294241504510865e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.719706223066389e-11
Max value: 0.9983024597167969
Mean value: 0.08868125081062317

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.719706223066389e-11
Max value: 0.9983024597167969
Mean value: 0.08868125081062317

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09261322021484375

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.0345458984375
Max value: -1.1920928244535389e-07
Mean value: -0.10756506770849228

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08291053771972656

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09261322021484375

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 56.171424865722656
Max value: 89.50709533691406
Mean value: 70.17265319824219

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.245622075073953e-11
Max value: 0.9979910850524902
Mean value: 0.08983457088470459

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.245622075073953e-11
Max value: 0.9979910850524902
Mean value: 0.08983457088470459

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.245622075073953e-11
Max value: 0.9979910850524902
Mean value: 0.08983457088470459

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.87364387512207
Max value: -1.1920928244535389e-07
Mean value: -0.10755234956741333

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9524736404418945
Max value: 1.4293335676193237
Mean value: 1.0000741481781006

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 56.171424865722656
Max value: 89.50709533691406
Mean value: 70.17265319824219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.17367553710938
Max value: -70.17367553710938
Mean value: -70.17367553710938
sam_encoder.pos_embed grad: -5.954962745136072e-09
sam_encoder.blocks.0.norm1.weight grad: 5.569339464273071e-06
sam_encoder.blocks.0.norm1.bias grad: -5.695343133993447e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.2576208973769099e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.4203884524686146e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.258709850546438e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.9623321350081824e-06
sam_encoder.blocks.0.norm2.weight grad: 4.2277690226910636e-05
sam_encoder.blocks.0.norm2.bias grad: -6.57245036563836e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.1345603929366916e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.3778527318208944e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.115968519930902e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.6844227275214507e-06
sam_encoder.blocks.1.norm1.weight grad: 1.6557205526623875e-05
sam_encoder.blocks.1.norm1.bias grad: -2.424559716018848e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.372286745521706e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.357654350111261e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.11138288048096e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.6635540204297286e-06
sam_encoder.blocks.1.norm2.weight grad: 4.531473678071052e-06
sam_encoder.blocks.1.norm2.bias grad: 2.2077121684560552e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.3586798559117597e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5931618690956384e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.5941914170980453e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.247137445010594e-06
sam_encoder.blocks.2.norm1.weight grad: -3.7154728488530964e-05
sam_encoder.blocks.2.norm1.bias grad: -1.193293064716272e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.1875483071198687e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.766323283751262e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.3615162970381789e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.242386007215828e-06
sam_encoder.blocks.2.norm2.weight grad: -1.7171161744045094e-05
sam_encoder.blocks.2.norm2.bias grad: 9.539377060718834e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0891433703363873e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.172479751649803e-09
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.8970039137639105e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8541550161899067e-07
sam_encoder.blocks.3.norm1.weight grad: -1.9377801436348818e-05
sam_encoder.blocks.3.norm1.bias grad: -7.987367098394316e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.025719666358782e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.985935452670674e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.8086639101966284e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.663117922769743e-06
sam_encoder.blocks.3.norm2.weight grad: 3.5333028790773824e-05
sam_encoder.blocks.3.norm2.bias grad: -3.7579911804641597e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.2155058104544878e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.29060024645878e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.0649057912814897e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.448089384823106e-06
sam_encoder.blocks.4.norm1.weight grad: 2.1954610929242335e-05
sam_encoder.blocks.4.norm1.bias grad: -2.597054663056042e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.399873316491721e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.503456016711425e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2504632422860595e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.5602122402924579e-06
sam_encoder.blocks.4.norm2.weight grad: 4.9295595090370625e-06
sam_encoder.blocks.4.norm2.bias grad: 1.7292022675974295e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.813205679165549e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3676220760316937e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.0371995813329704e-05
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.895139682048466e-06
sam_encoder.blocks.5.norm1.weight grad: 1.4413737517315894e-05
sam_encoder.blocks.5.norm1.bias grad: -1.66220597748179e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.209629075077828e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.777524736709893e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.7554403863614425e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.213959644199349e-06
sam_encoder.blocks.5.norm2.weight grad: 2.1659692720277235e-05
sam_encoder.blocks.5.norm2.bias grad: 3.5353291423234623e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.495112466112005e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.8895026815689562e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.6476734496536665e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.9013077690033242e-07
sam_encoder.blocks.6.norm1.weight grad: 8.984532541944645e-06
sam_encoder.blocks.6.norm1.bias grad: -5.667668119713198e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 9.411181054019835e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.0682635850971565e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.311076630372554e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0221835822221692e-07
sam_encoder.blocks.6.norm2.weight grad: 2.38251595874317e-05
sam_encoder.blocks.6.norm2.bias grad: 9.534503988106735e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.469102117989678e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.7592241192687652e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.3583567124442197e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1489391908980906e-06
sam_encoder.blocks.7.norm1.weight grad: -6.839105026301695e-06
sam_encoder.blocks.7.norm1.bias grad: -2.6308280212106183e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.222241609066259e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.839799319393933e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.5040818602283252e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.4628724304420757e-07
sam_encoder.blocks.7.norm2.weight grad: 6.0463185036496725e-06
sam_encoder.blocks.7.norm2.bias grad: -3.419488166400697e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.897128013046313e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7104073322116164e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0229068720946088e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.8939192614197964e-06
sam_encoder.blocks.8.norm1.weight grad: 1.895345121738501e-05
sam_encoder.blocks.8.norm1.bias grad: -3.6345113585412037e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.190850500483066e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.303183105657808e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.421655724698212e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.98513577945414e-06
sam_encoder.blocks.8.norm2.weight grad: 7.440120498358738e-06
sam_encoder.blocks.8.norm2.bias grad: 3.990967343270313e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.4468585050053662e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.744767577198218e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.060649179242318e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1023963679690496e-06
sam_encoder.blocks.9.norm1.weight grad: 6.588784799532732e-06
sam_encoder.blocks.9.norm1.bias grad: 1.6602502910245676e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.35007450505509e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.386259994746069e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.843282219255343e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.088386392846587e-06
sam_encoder.blocks.9.norm2.weight grad: 9.179275366477668e-06
sam_encoder.blocks.9.norm2.bias grad: 6.279143235587981e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 8.712931958143599e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.6169326449453365e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.132377742076642e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.790574159116659e-07
sam_encoder.blocks.10.norm1.weight grad: -4.201514457236044e-06
sam_encoder.blocks.10.norm1.bias grad: 3.808498831858742e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.1853688849660102e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.73025486055667e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6228093500103569e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.756010518278345e-07
sam_encoder.blocks.10.norm2.weight grad: 4.332824119046563e-06
sam_encoder.blocks.10.norm2.bias grad: 4.116792752029141e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.6879708293090516e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1620968507486396e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.302980182226747e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.2868041444089613e-07
sam_encoder.blocks.11.norm1.weight grad: -2.5918863684637472e-05
sam_encoder.blocks.11.norm1.bias grad: 4.362558229331626e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.3663643585459795e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6836663689900888e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.213578682130901e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.930727648868924e-06
sam_encoder.blocks.11.norm2.weight grad: 9.191538993036374e-06
sam_encoder.blocks.11.norm2.bias grad: 2.100641722790897e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4019686886967975e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.466045867156936e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.1095547708682716e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.556789801630657e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.3512227421160787e-07
sam_encoder.neck.conv1.trainable_shift grad: 7.665290468139574e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.8820177249144763e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.00012023007730022073
mask_decoder.transformer.layers.0.norm1.weight grad: 6.0689013480441645e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.5912671592086554e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00022478046594187617
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00040741648990660906
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0001004720397759229
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00013895289157517254
mask_decoder.transformer.layers.0.norm4.weight grad: 7.468558760592714e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.728378058236558e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.954533895011991e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.9664646465098485e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0005476678488776088
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00018429814372211695
mask_decoder.transformer.layers.1.norm3.weight grad: -9.301880345446989e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -7.894635200500488e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.6963414711644873e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 6.779532122891396e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.8560100367467385e-06
mask_decoder.transformer.norm_final_attn.bias grad: -9.555382348480634e-06
Text_Embedding_Affine.0.weight grad: 2.0566394073884275e-11
Text_Embedding_Affine.0.bias grad: 4.665027808492539e-10
Text_Embedding_Affine.2.weight grad: -8.932958539542568e-13
Text_Embedding_Affine.2.bias grad: 4.783827534993179e-05
Epoch 19 finished with average loss: -61.0057
Epoch 20/39
----------
Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.5]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.14it/s, loss=-59.5]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.14it/s, loss=-59.3]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-59.3]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-60.1]Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-60.1]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2690479363978296e-13
Max value: 0.9999113082885742
Mean value: 0.08262373507022858

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2690479363978296e-13
Max value: 0.9999113082885742
Mean value: 0.08262373507022858

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0839686393737793

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12154341489076614

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0760040283203125

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0839686393737793

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.63490295410156
Max value: 91.54617309570312
Mean value: 59.478912353515625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2690479363978296e-13
Max value: 0.9999113082885742
Mean value: 0.08262373507022858

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2690479363978296e-13
Max value: 0.9999113082885742
Mean value: 0.08262373507022858

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2690479363978296e-13
Max value: 0.9999113082885742
Mean value: 0.08262373507022858

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12154341489076614

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.63490295410156
Max value: 91.54617309570312
Mean value: 59.478912353515625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.480003356933594
Max value: -59.480003356933594
Mean value: -59.480003356933594
sam_encoder.pos_embed grad: -3.315565377803864e-09
sam_encoder.blocks.0.norm1.weight grad: 2.8933591238455847e-06
sam_encoder.blocks.0.norm1.bias grad: 7.316351457120618e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0937617339077406e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.470427251770161e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.6884746350551723e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8951662923427648e-06
sam_encoder.blocks.0.norm2.weight grad: 1.2495729606598616e-05
sam_encoder.blocks.0.norm2.bias grad: 4.862896093982272e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.059697024174966e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.5093299882428255e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.3451378436002415e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.67345807919628e-06
sam_encoder.blocks.1.norm1.weight grad: 3.3973481095017632e-06
sam_encoder.blocks.1.norm1.bias grad: 1.7869033399620093e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.390945706400089e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.556103709139279e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.419261575909331e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.5280806969240075e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0886788004427217e-06
sam_encoder.blocks.1.norm2.bias grad: -4.384613021102268e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.078488367056707e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.752707915642532e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.083271495706867e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.840875468900776e-07
sam_encoder.blocks.2.norm1.weight grad: -1.1185486073372886e-05
sam_encoder.blocks.2.norm1.bias grad: 3.2867126265045954e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3084677448205184e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.5696508600958623e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.495608770113904e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.2005834731971845e-06
sam_encoder.blocks.2.norm2.weight grad: 6.241567007236881e-06
sam_encoder.blocks.2.norm2.bias grad: -8.338411134900525e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.784389819993521e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.6886082221390097e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.5549171570892213e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4370061762747355e-07
sam_encoder.blocks.3.norm1.weight grad: 4.127432021050481e-06
sam_encoder.blocks.3.norm1.bias grad: -8.158876880770549e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.5552847066355753e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8537632229254086e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2086155720680836e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.749591369090922e-07
sam_encoder.blocks.3.norm2.weight grad: 7.225025910884142e-08
sam_encoder.blocks.3.norm2.bias grad: -6.916062375239562e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3992275853524916e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.549819555497379e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.716176590591203e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.976488164245893e-07
sam_encoder.blocks.4.norm1.weight grad: 1.2247086260686046e-06
sam_encoder.blocks.4.norm1.bias grad: -7.770624506520107e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.7807313952289405e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.0121350157987763e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.7738741462380858e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -8.537136864106287e-07
sam_encoder.blocks.4.norm2.weight grad: 5.612239874608349e-06
sam_encoder.blocks.4.norm2.bias grad: 3.1228389616444474e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.1564630969805876e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.437418053588772e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.135494924004888e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4166016626404598e-07
sam_encoder.blocks.5.norm1.weight grad: 1.5263696695910767e-05
sam_encoder.blocks.5.norm1.bias grad: -9.782854249351658e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.0302890586899593e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.569977474806365e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.11617770371231e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1686097423080355e-08
sam_encoder.blocks.5.norm2.weight grad: 9.173298167297617e-06
sam_encoder.blocks.5.norm2.bias grad: 4.586613613355439e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.019881205545971e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.398423799211741e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.7372456656848954e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.993248208824298e-08
sam_encoder.blocks.6.norm1.weight grad: 2.6602910452311335e-07
sam_encoder.blocks.6.norm1.bias grad: -4.75999968330143e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.5152772903093137e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3495525763573823e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.042245685312082e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.7793456303679704e-08
sam_encoder.blocks.6.norm2.weight grad: 6.438849140977254e-06
sam_encoder.blocks.6.norm2.bias grad: 2.8958760367459035e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.8981334051204612e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.5199636272409407e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.0709649106720462e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.7643698647116253e-07
sam_encoder.blocks.7.norm1.weight grad: 2.679695853657904e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0509837693462032e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.6859534045797773e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.45968010656361e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -6.350716716951865e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.728219321099459e-08
sam_encoder.blocks.7.norm2.weight grad: 2.8102767828386277e-06
sam_encoder.blocks.7.norm2.bias grad: -1.2873983905592468e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.538148227264173e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.992807909800831e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.2220219787195674e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.2821750488001271e-06
sam_encoder.blocks.8.norm1.weight grad: 8.578299457440153e-06
sam_encoder.blocks.8.norm1.bias grad: 1.2050636541971471e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.674462151248008e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.251978680258617e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.6804764868538768e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.418352877015423e-07
sam_encoder.blocks.8.norm2.weight grad: 3.6942135466233594e-06
sam_encoder.blocks.8.norm2.bias grad: 2.895744728448335e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.2850579171063146e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.8467528661858523e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.595282803165901e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.4568896606069757e-07
sam_encoder.blocks.9.norm1.weight grad: 8.784318197285756e-07
sam_encoder.blocks.9.norm1.bias grad: 1.2387522474455182e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.340200080032446e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.359649435376923e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.669163318903884e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.1308553616327117e-07
sam_encoder.blocks.9.norm2.weight grad: 2.5656497655290877e-06
sam_encoder.blocks.9.norm2.bias grad: 2.3959883037605323e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.5582904211441928e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3248500181362033e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.151877975455136e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.9347134500312677e-07
sam_encoder.blocks.10.norm1.weight grad: -4.395636096887756e-06
sam_encoder.blocks.10.norm1.bias grad: 1.9839342257910175e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.497512352623744e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2741578530039988e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.5612303033994976e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.5948771761031821e-06
sam_encoder.blocks.10.norm2.weight grad: 6.452636625908781e-06
sam_encoder.blocks.10.norm2.bias grad: 1.6964329461188754e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.2590091905149166e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.8547632407717174e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.4288623333413852e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.848112429404864e-07
sam_encoder.blocks.11.norm1.weight grad: 4.341858584666625e-06
sam_encoder.blocks.11.norm1.bias grad: 1.892069462883228e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.201679869060172e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.651950338389724e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.9574122234189417e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.295810627918399e-07
sam_encoder.blocks.11.norm2.weight grad: 1.397092432853242e-06
sam_encoder.blocks.11.norm2.bias grad: 1.5666355466237292e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0662894283086644e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 6.066372861823766e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.5799694703418936e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.8006599589170946e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.3249427865957841e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.4304891919891816e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.672047801548615e-06
sam_encoder.neck.conv2.trainable_shift grad: 5.3574194680550136e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00022335669200401753
mask_decoder.transformer.layers.0.norm1.bias grad: -1.612228516023606e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002822273876518011
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0008145550964400172
mask_decoder.transformer.layers.0.norm3.weight grad: 2.8381975425872952e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.0700961613329127e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.000108058397017885
mask_decoder.transformer.layers.0.norm4.bias grad: 3.74645424017217e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.520585232763551e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.148368705296889e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.634020585101098e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -7.814951823092997e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -7.35789944883436e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.173870497150347e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.4791163266636431e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 5.314609006745741e-05
mask_decoder.transformer.norm_final_attn.weight grad: -2.838408363459166e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3332782145880628e-05
Text_Embedding_Affine.0.weight grad: -6.998245732914299e-12
Text_Embedding_Affine.0.bias grad: 5.062239516462341e-11
Text_Embedding_Affine.2.weight grad: -1.8268797585818675e-10
Text_Embedding_Affine.2.bias grad: -5.5659416830167174e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4519185550024294e-13
Max value: 0.9998661279678345
Mean value: 0.078499436378479

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4519185550024294e-13
Max value: 0.9998661279678345
Mean value: 0.078499436378479

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07837772369384766

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12875130772590637

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0706338882446289

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07837772369384766

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.87457275390625
Max value: 73.52171325683594
Mean value: 59.00397491455078

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.3164228781652474e-13
Max value: 0.999858021736145
Mean value: 0.07921890914440155

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3164228781652474e-13
Max value: 0.999858021736145
Mean value: 0.07921890914440155

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3164228781652474e-13
Max value: 0.999858021736145
Mean value: 0.07921890914440155

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12840580940246582

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9240756034851074
Max value: 1.512305498123169
Mean value: 1.0003809928894043

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.87457275390625
Max value: 73.52171325683594
Mean value: 59.00397491455078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.02284622192383
Max value: -59.02284622192383
Mean value: -59.02284622192383
sam_encoder.pos_embed grad: -3.862517417019262e-09
sam_encoder.blocks.0.norm1.weight grad: 4.38383431173861e-05
sam_encoder.blocks.0.norm1.bias grad: 6.095040589570999e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.082536063127918e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.187185709270125e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.548033757600933e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.784392887013382e-07
sam_encoder.blocks.0.norm2.weight grad: 7.69212783779949e-05
sam_encoder.blocks.0.norm2.bias grad: -1.7023781765601598e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.487334864388686e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.3495134680852061e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.0802215658477508e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.138300467573572e-05
sam_encoder.blocks.1.norm1.weight grad: 3.1242841942003e-05
sam_encoder.blocks.1.norm1.bias grad: 1.368107768939808e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2035387044306844e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.09232234233059e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.3309875612321775e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.168439201952424e-06
sam_encoder.blocks.1.norm2.weight grad: 4.498384441831149e-06
sam_encoder.blocks.1.norm2.bias grad: -1.93967207451351e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.4167985581443645e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.0310763798315747e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.054816134972498e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.3366692996896745e-07
sam_encoder.blocks.2.norm1.weight grad: -1.7769903934095055e-05
sam_encoder.blocks.2.norm1.bias grad: 1.0620324246701784e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.4200504665495828e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.431359229783993e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1286220797046553e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.299281267274637e-06
sam_encoder.blocks.2.norm2.weight grad: -2.0288956875447184e-05
sam_encoder.blocks.2.norm2.bias grad: 1.1240454114158638e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.784899359336123e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.06478227180196e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.015777110704221e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0318835848011076e-06
sam_encoder.blocks.3.norm1.weight grad: -2.2710239136358723e-05
sam_encoder.blocks.3.norm1.bias grad: -1.909770389829646e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.327911928063259e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5616326436429517e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.715358378845849e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.636939815507503e-07
sam_encoder.blocks.3.norm2.weight grad: 1.527803215140011e-05
sam_encoder.blocks.3.norm2.bias grad: 9.074281479115598e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.3555875739257317e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.792903721157927e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.477436959859915e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3827238376507012e-07
sam_encoder.blocks.4.norm1.weight grad: -2.0523779312497936e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1586460459511727e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.3047300853941124e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.375424401179771e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.5482514704199275e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.2346492844226304e-06
sam_encoder.blocks.4.norm2.weight grad: 9.108423910220154e-06
sam_encoder.blocks.4.norm2.bias grad: 4.571009412757121e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.893153345619794e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.334958369625383e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.763689503306523e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.6054007119237212e-06
sam_encoder.blocks.5.norm1.weight grad: -1.4247102626541164e-05
sam_encoder.blocks.5.norm1.bias grad: 2.1009267925364838e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.1080995136580896e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.3545729820616543e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.917583287853631e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.4626714346377412e-06
sam_encoder.blocks.5.norm2.weight grad: 1.3170601960155182e-05
sam_encoder.blocks.5.norm2.bias grad: -9.530851457384415e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.306080882088281e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.7749744074535556e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7770698832464404e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.9485903496606625e-07
sam_encoder.blocks.6.norm1.weight grad: 1.4084507711231709e-06
sam_encoder.blocks.6.norm1.bias grad: 2.4221139938163105e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.7226906265932485e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.2106340818718309e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.830361485299363e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.623768177225429e-07
sam_encoder.blocks.6.norm2.weight grad: 5.3997441682440694e-06
sam_encoder.blocks.6.norm2.bias grad: -2.373627012275392e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.9169743243073754e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.7481894449010724e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.4240730479286867e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.1841554459788313e-07
sam_encoder.blocks.7.norm1.weight grad: 4.991984951630002e-06
sam_encoder.blocks.7.norm1.bias grad: 5.395366997618112e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.820897629542742e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3972579608889646e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.765726776488009e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.2509033189853653e-06
sam_encoder.blocks.7.norm2.weight grad: 1.0619903150654864e-05
sam_encoder.blocks.7.norm2.bias grad: 1.0072881195810623e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 8.206709026126191e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.3091495222615777e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.1575879170777625e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.097835469314305e-07
sam_encoder.blocks.8.norm1.weight grad: -4.9866753215610515e-06
sam_encoder.blocks.8.norm1.bias grad: 8.042919716899632e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.81460972171044e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.7060427782998886e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3499433180186315e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.983181143979891e-07
sam_encoder.blocks.8.norm2.weight grad: 6.959910933801439e-06
sam_encoder.blocks.8.norm2.bias grad: -1.9841641005768906e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.163156624301337e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.612921773310518e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.5922478269203566e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.2658442472002207e-07
sam_encoder.blocks.9.norm1.weight grad: 1.66153853342621e-07
sam_encoder.blocks.9.norm1.bias grad: 1.334041144218645e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.2814266976165527e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.142781795555493e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.389969596260926e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.286598643763682e-08
sam_encoder.blocks.9.norm2.weight grad: 5.912142114539165e-06
sam_encoder.blocks.9.norm2.bias grad: -2.1008168005209882e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.288329248287482e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.7924866117245983e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.7751458847878894e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.599664981062233e-07
sam_encoder.blocks.10.norm1.weight grad: 2.9156224172766088e-06
sam_encoder.blocks.10.norm1.bias grad: 8.758260605645773e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.9931993594800588e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.789841007848736e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1255921208430664e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.415190334038925e-07
sam_encoder.blocks.10.norm2.weight grad: 9.226170732290484e-06
sam_encoder.blocks.10.norm2.bias grad: -5.2526655025531e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.741624590882566e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.666576165211154e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.0162297548486094e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.8538064472959377e-07
sam_encoder.blocks.11.norm1.weight grad: -4.909870767733082e-06
sam_encoder.blocks.11.norm1.bias grad: 5.111039058647293e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.320731482541305e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.451097884659248e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.134851913775492e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.0014546205638908e-06
sam_encoder.blocks.11.norm2.weight grad: -8.901158139451582e-07
sam_encoder.blocks.11.norm2.bias grad: -1.1412915768005405e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.759018338518217e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.125355476640834e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.568955879833084e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.9324456224676396e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.7272395780310035e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.6098103515105322e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.4204124454408884e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.5071707316092215e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 2.2297936084214598e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.6834535421803594e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0050810230895876884
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00018912332598119974
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00014653852849733084
mask_decoder.transformer.layers.0.norm3.bias grad: -1.0953204764518887e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.211310806567781e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.0865725168259814e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.514575605047867e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.3664764487184584e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00015839943080209196
mask_decoder.transformer.layers.1.norm2.bias grad: -9.532097465125844e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 2.7519621653482318e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.53074197442038e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.236978732777061e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.956440044334158e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.6846884086116916e-06
mask_decoder.transformer.norm_final_attn.bias grad: 4.4883299779030494e-06
Text_Embedding_Affine.0.weight grad: -2.806371237826233e-12
Text_Embedding_Affine.0.bias grad: -1.9130926010024751e-10
Text_Embedding_Affine.2.weight grad: 1.3629940925907746e-11
Text_Embedding_Affine.2.bias grad: -2.201405914092902e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.665153952032597e-08
Max value: 0.998754620552063
Mean value: 0.11464166641235352

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.665153952032597e-08
Max value: 0.998754620552063
Mean value: 0.11464166641235352

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09447765350341797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.731314659118652
Max value: -1.1920928244535389e-07
Mean value: -0.12784084677696228

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10051441192626953

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09447765350341797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 46.30707550048828
Max value: 74.65711975097656
Mean value: 61.81140899658203

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.599525027515483e-08
Max value: 0.9986496567726135
Mean value: 0.1154046431183815

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.599525027515483e-08
Max value: 0.9986496567726135
Mean value: 0.1154046431183815

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.599525027515483e-08
Max value: 0.9986496567726135
Mean value: 0.1154046431183815

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.914482116699219
Max value: -1.1920928244535389e-07
Mean value: -0.1280393898487091

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8326287269592285
Max value: 1.1855807304382324
Mean value: 0.9998196363449097

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 46.30707550048828
Max value: 74.65711975097656
Mean value: 61.81140899658203

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.804080963134766
Max value: -61.804080963134766
Mean value: -61.804080963134766
sam_encoder.pos_embed grad: -6.875051639099183e-09
sam_encoder.blocks.0.norm1.weight grad: 1.0905394447036088e-05
sam_encoder.blocks.0.norm1.bias grad: 1.280385163227038e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.347175040995353e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3405821164269582e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.360526756703621e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.3272277783471509e-06
sam_encoder.blocks.0.norm2.weight grad: 1.9748213162529282e-05
sam_encoder.blocks.0.norm2.bias grad: -2.306170699739596e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.37644485423516e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.1658383982648957e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.0788733056397177e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.4225793165678624e-06
sam_encoder.blocks.1.norm1.weight grad: 9.179615517496131e-06
sam_encoder.blocks.1.norm1.bias grad: 7.182746230682824e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.513978405564558e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.109942549097468e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.686605401118868e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.05869292560601e-07
sam_encoder.blocks.1.norm2.weight grad: 2.8393355933076236e-06
sam_encoder.blocks.1.norm2.bias grad: -4.831837031815667e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.7938239074719604e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.769307899252453e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.695600862054562e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.244796845247038e-08
sam_encoder.blocks.2.norm1.weight grad: -1.202128805743996e-05
sam_encoder.blocks.2.norm1.bias grad: -1.3158299907445326e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.326775292109232e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.9200756469217595e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.777603862748947e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.9602443899202626e-06
sam_encoder.blocks.2.norm2.weight grad: -6.468042101914762e-06
sam_encoder.blocks.2.norm2.bias grad: 1.8991235037901788e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.908858838665765e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.5250257092702668e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.370839749550214e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.0892648560911766e-06
sam_encoder.blocks.3.norm1.weight grad: 5.162291927263141e-09
sam_encoder.blocks.3.norm1.bias grad: -8.681037797941826e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 6.16262241237564e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.5509434660998522e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.574132617563009e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.268592652399093e-06
sam_encoder.blocks.3.norm2.weight grad: 7.351436579483561e-06
sam_encoder.blocks.3.norm2.bias grad: 1.2564400094561279e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.994200364511926e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4124741483101388e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.8853410210795118e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.0070230511446425e-07
sam_encoder.blocks.4.norm1.weight grad: -4.821058041670767e-07
sam_encoder.blocks.4.norm1.bias grad: -5.310475899023004e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.4588031262974255e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.807224958218285e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.237793867403525e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.306676722379052e-06
sam_encoder.blocks.4.norm2.weight grad: 5.60167791263666e-07
sam_encoder.blocks.4.norm2.bias grad: -1.8400533008389175e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.6600806418409775e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.2207725553234923e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.9422650439082645e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.9439950683117786e-07
sam_encoder.blocks.5.norm1.weight grad: -5.364977369026747e-07
sam_encoder.blocks.5.norm1.bias grad: -2.5846845801424934e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.2505558970588027e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2069505146428128e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.391812475048937e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.290032494391198e-07
sam_encoder.blocks.5.norm2.weight grad: 9.687650162959471e-06
sam_encoder.blocks.5.norm2.bias grad: -2.8281235699978424e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.528904123115353e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.7611472432909068e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.12381906092196e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.640683985395299e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7168649719678797e-06
sam_encoder.blocks.6.norm1.bias grad: 1.5683517631259747e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.328596444087452e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.109655040134385e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.860684950675932e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.917563837305352e-07
sam_encoder.blocks.6.norm2.weight grad: -1.173347982330597e-06
sam_encoder.blocks.6.norm2.bias grad: -2.615307948872214e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.74155091423745e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.15128134487486e-09
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.666124717303319e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.5736987885902636e-07
sam_encoder.blocks.7.norm1.weight grad: 1.119183934861212e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4464296782534802e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.800868062673544e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6152992543538858e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.7516034606378525e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.946069571407861e-06
sam_encoder.blocks.7.norm2.weight grad: 3.176908421664848e-06
sam_encoder.blocks.7.norm2.bias grad: -6.614154699491337e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.4518986896946444e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.40402538717899e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.388009066744416e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.744926844883594e-07
sam_encoder.blocks.8.norm1.weight grad: 2.305004272784572e-06
sam_encoder.blocks.8.norm1.bias grad: -6.239249046302575e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.9466499452391872e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.5314391172723845e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.3034161788236815e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.5724889383127447e-06
sam_encoder.blocks.8.norm2.weight grad: 6.961668532312615e-06
sam_encoder.blocks.8.norm2.bias grad: -9.993359526561107e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.8902349994459655e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.275291757949162e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.5765882583073108e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.049212508216442e-07
sam_encoder.blocks.9.norm1.weight grad: 1.2046584743075073e-06
sam_encoder.blocks.9.norm1.bias grad: 6.894086936881649e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.1326618505336228e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1127555126222433e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.467415343853645e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.401439011620823e-07
sam_encoder.blocks.9.norm2.weight grad: 6.429025233956054e-06
sam_encoder.blocks.9.norm2.bias grad: 4.974328362550295e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.673005605582148e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.8028487122355727e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.55602508048014e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.4155106953239738e-07
sam_encoder.blocks.10.norm1.weight grad: 4.293349320505513e-06
sam_encoder.blocks.10.norm1.bias grad: -7.387120604107622e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.506916527840076e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.406854380547884e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.3774896387985791e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.688542720847181e-07
sam_encoder.blocks.10.norm2.weight grad: 8.71183965500677e-06
sam_encoder.blocks.10.norm2.bias grad: 4.6364070271920355e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.0400221880408935e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.858505811469513e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.431661520560738e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.209841542504364e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2934480764670298e-05
sam_encoder.blocks.11.norm1.bias grad: -7.73735337133985e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.8411568589726812e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.749955557301291e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.344882434750616e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.7160813210211927e-07
sam_encoder.blocks.11.norm2.weight grad: 7.086069672368467e-06
sam_encoder.blocks.11.norm2.bias grad: -8.961134767559997e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.640434665110661e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.4708900835103123e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.086592409497825e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0421672413940541e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.6701960703358054e-08
sam_encoder.neck.conv1.trainable_shift grad: 1.5707350030425005e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.6504327504662797e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.2668947420024779e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.111351103754714e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6629019228275865e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0046153985895216465
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00017772457795217633
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00014776502212043852
mask_decoder.transformer.layers.0.norm3.bias grad: -1.6298708942485973e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 5.866069477633573e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.099532139254734e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 3.293454210506752e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.080078259808943e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.53473554039374e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.1680371244437993e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.643920586502645e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.5547993573127314e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.5223953343811445e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.182412420865148e-05
mask_decoder.transformer.norm_final_attn.weight grad: 6.147257408883888e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.252217073983047e-06
Text_Embedding_Affine.0.weight grad: 1.2834347300205717e-12
Text_Embedding_Affine.0.bias grad: -2.8978114352540274e-10
Text_Embedding_Affine.2.weight grad: 1.0140389916646342e-10
Text_Embedding_Affine.2.bias grad: 3.9219858081196435e-06
Epoch 20 finished with average loss: -60.1023
Epoch 21/39
----------
Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.9]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-61.9]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-59.8]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-59.8]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-59.2]Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-59.2]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.386931642544212e-14
Max value: 0.998190701007843
Mean value: 0.08153055608272552

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.386931642544212e-14
Max value: 0.998190701007843
Mean value: 0.08153055608272552

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07978343963623047

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11142066866159439

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0694570541381836

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07978343963623047

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.12584686279297
Max value: 88.48356628417969
Mean value: 61.906673431396484

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.386931642544212e-14
Max value: 0.998190701007843
Mean value: 0.08153055608272552

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.386931642544212e-14
Max value: 0.998190701007843
Mean value: 0.08153055608272552

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.386931642544212e-14
Max value: 0.998190701007843
Mean value: 0.08153055608272552

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11142066866159439

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.12584686279297
Max value: 88.48356628417969
Mean value: 61.906673431396484

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.90786361694336
Max value: -61.90786361694336
Mean value: -61.90786361694336
sam_encoder.pos_embed grad: 2.501390872211573e-09
sam_encoder.blocks.0.norm1.weight grad: -4.271314537618309e-07
sam_encoder.blocks.0.norm1.bias grad: -9.216106263920665e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.398392535331368e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.9276054287238367e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.552903298346791e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.15351950727927e-07
sam_encoder.blocks.0.norm2.weight grad: 8.4794191934634e-07
sam_encoder.blocks.0.norm2.bias grad: 1.242284088220913e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.762861743363601e-09
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2599865613083239e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.87201894732425e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.553767085890286e-06
sam_encoder.blocks.1.norm1.weight grad: 1.3652519328388735e-06
sam_encoder.blocks.1.norm1.bias grad: 9.035620678332634e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.324337952421047e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.583536797828856e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.05434501671698e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.54206599695317e-06
sam_encoder.blocks.1.norm2.weight grad: -5.269600478641223e-06
sam_encoder.blocks.1.norm2.bias grad: -1.7425163605366834e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.31688624000526e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.208957996823301e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.075432454759721e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.745591119601158e-07
sam_encoder.blocks.2.norm1.weight grad: -1.181846710096579e-05
sam_encoder.blocks.2.norm1.bias grad: 3.7277523006196134e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.259763828595169e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.9219419300497975e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.189569613619824e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.6356186733901268e-06
sam_encoder.blocks.2.norm2.weight grad: 4.0177887967729475e-06
sam_encoder.blocks.2.norm2.bias grad: -5.8286013882025145e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.213357212596748e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.2937566680193413e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.958296580705792e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6151359432114987e-06
sam_encoder.blocks.3.norm1.weight grad: -2.690928340598475e-06
sam_encoder.blocks.3.norm1.bias grad: 5.375862656364916e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4033784054845455e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.66589130560169e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2378745850583073e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.2742019609722774e-06
sam_encoder.blocks.3.norm2.weight grad: -1.4836503396509215e-05
sam_encoder.blocks.3.norm2.bias grad: -5.540841812035069e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0403843589301687e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.1594515803590184e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.946932793041924e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1337291425661533e-06
sam_encoder.blocks.4.norm1.weight grad: -4.22933180743712e-06
sam_encoder.blocks.4.norm1.bias grad: -3.927486432075966e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.740164518399979e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.968721433826431e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.402662175882142e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.715563596211723e-06
sam_encoder.blocks.4.norm2.weight grad: 2.2579577489523217e-05
sam_encoder.blocks.4.norm2.bias grad: 1.5979841919033788e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.2484473700169474e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.569124030240346e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.32014144785353e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.5531895769527182e-09
sam_encoder.blocks.5.norm1.weight grad: 6.768561320313893e-07
sam_encoder.blocks.5.norm1.bias grad: -5.793383934360463e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.727125320234336e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.1475420908245724e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.186515757784946e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.915934255222965e-07
sam_encoder.blocks.5.norm2.weight grad: 7.365387318714056e-06
sam_encoder.blocks.5.norm2.bias grad: 1.107641128328396e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.237953987740184e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.468213378710061e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.6743449293699086e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6896271404220897e-07
sam_encoder.blocks.6.norm1.weight grad: -1.163655042546452e-06
sam_encoder.blocks.6.norm1.bias grad: -5.373247404349968e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.911895186727634e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.704037443545531e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3605138065031497e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.238380016540759e-07
sam_encoder.blocks.6.norm2.weight grad: 1.0634276804921683e-05
sam_encoder.blocks.6.norm2.bias grad: 5.016380328015657e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.381359187595081e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.291513510499499e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.59424438001588e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.779578368172224e-07
sam_encoder.blocks.7.norm1.weight grad: -1.7475772438046988e-06
sam_encoder.blocks.7.norm1.bias grad: -6.836497732365387e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.8862000388253364e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.3014390560783795e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.6990105652657803e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.1372603694326244e-06
sam_encoder.blocks.7.norm2.weight grad: -2.044911525445059e-06
sam_encoder.blocks.7.norm2.bias grad: -5.115143721923232e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.922156909335172e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.537383695904282e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.591496225562878e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.447596198697283e-07
sam_encoder.blocks.8.norm1.weight grad: -1.4163733794703148e-06
sam_encoder.blocks.8.norm1.bias grad: 1.7362160633638268e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.2676651667552505e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.2732410798198543e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.579902113415301e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.1973098682792624e-06
sam_encoder.blocks.8.norm2.weight grad: -2.007378043344943e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5716636880824808e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.482637794149923e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.5682342109357705e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.1123111107735895e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.9241329596297874e-07
sam_encoder.blocks.9.norm1.weight grad: -1.025959022626921e-06
sam_encoder.blocks.9.norm1.bias grad: 1.2654925285460195e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.4177220464262064e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.2211801276862388e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.420230071555125e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9650618909849982e-08
sam_encoder.blocks.9.norm2.weight grad: -8.670380111652776e-07
sam_encoder.blocks.9.norm2.bias grad: 1.6000061577869928e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.554868842707947e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.474447218351997e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.5871262348809978e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.961753342693555e-07
sam_encoder.blocks.10.norm1.weight grad: -5.118241460877471e-06
sam_encoder.blocks.10.norm1.bias grad: 4.018993422505446e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.6382796224643243e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.4170805116009433e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.1309961084625684e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.755844985193107e-07
sam_encoder.blocks.10.norm2.weight grad: -4.022685970994644e-06
sam_encoder.blocks.10.norm2.bias grad: 9.186097713609342e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.196039870090317e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.0826743164216168e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.501354725216515e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.751438271137886e-07
sam_encoder.blocks.11.norm1.weight grad: -1.5892142982920632e-05
sam_encoder.blocks.11.norm1.bias grad: 6.035667752257723e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.2813010243917233e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.956920964919846e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.818234861479141e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.1834417819045484e-06
sam_encoder.blocks.11.norm2.weight grad: -4.922876087221084e-06
sam_encoder.blocks.11.norm2.bias grad: 1.1285741265965044e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.7210372738627484e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.707481017860118e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.835468535522523e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.184572581309112e-08
sam_encoder.neck.conv1.trainable_scale grad: 4.304147296352312e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.1220776286791079e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.110029400791973e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.3288799891597591e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.367997699882835e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.136628947686404e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00478334492072463
mask_decoder.transformer.layers.0.norm2.bias grad: 5.863516707904637e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 9.398179827257991e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.610571290366352e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013932821457274258
mask_decoder.transformer.layers.0.norm4.bias grad: 1.1385463949409313e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.6716283173300326e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.035430043179076e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.744621476973407e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -6.15503522567451e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.180449807085097e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.1498238968197256e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.3493866794742644e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016632858023513108
mask_decoder.transformer.norm_final_attn.weight grad: -6.63328592054313e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.2755457646562718e-05
Text_Embedding_Affine.0.weight grad: 2.228895887301796e-12
Text_Embedding_Affine.0.bias grad: 3.3630011969654205e-11
Text_Embedding_Affine.2.weight grad: 1.5915480738870613e-12
Text_Embedding_Affine.2.bias grad: -2.928070171037689e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.782894239687159e-14
Max value: 0.9995505213737488
Mean value: 0.08366578072309494

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.782894239687159e-14
Max value: 0.9995505213737488
Mean value: 0.08366578072309494

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08102035522460938

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12038713693618774

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0759587287902832

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08102035522460938

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.04612159729004
Max value: 69.81524658203125
Mean value: 57.60440444946289

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1474031123284104e-14
Max value: 0.999592125415802
Mean value: 0.08344189822673798

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1474031123284104e-14
Max value: 0.999592125415802
Mean value: 0.08344189822673798

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1474031123284104e-14
Max value: 0.999592125415802
Mean value: 0.08344189822673798

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12022419273853302

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7926161885261536
Max value: 1.0373189449310303
Mean value: 1.0001742839813232

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.04612159729004
Max value: 69.81524658203125
Mean value: 57.60440444946289

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.6142692565918
Max value: -57.6142692565918
Mean value: -57.6142692565918
sam_encoder.pos_embed grad: -6.241627215075596e-10
sam_encoder.blocks.0.norm1.weight grad: -8.733854883757886e-06
sam_encoder.blocks.0.norm1.bias grad: -7.252633622556459e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0484617263273321e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.0622203439634177e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.1603028724493925e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.97033852802997e-06
sam_encoder.blocks.0.norm2.weight grad: -1.2167870409030002e-05
sam_encoder.blocks.0.norm2.bias grad: -1.1618848475336563e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.456012099282816e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -9.135294931184035e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.236182237742469e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.993812581233215e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1143834854010493e-05
sam_encoder.blocks.1.norm1.bias grad: 1.946448173839599e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.7063807667436777e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.26402831219275e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.5166009461609065e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.6981617768105934e-07
sam_encoder.blocks.1.norm2.weight grad: -1.7710022802930325e-05
sam_encoder.blocks.1.norm2.bias grad: -2.0680436136899516e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.534778559493134e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.629686370411946e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.34886850498151e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.5592947875120444e-06
sam_encoder.blocks.2.norm1.weight grad: 7.049520263535669e-06
sam_encoder.blocks.2.norm1.bias grad: 2.4200276129704434e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.535432129974652e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.936648684226384e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.2383737839627429e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.480901788563642e-07
sam_encoder.blocks.2.norm2.weight grad: -1.0073117664433084e-05
sam_encoder.blocks.2.norm2.bias grad: -5.704614068235969e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.16741886510863e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.5896309832896804e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.605594201872009e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8188060835200304e-07
sam_encoder.blocks.3.norm1.weight grad: 9.160664262708451e-07
sam_encoder.blocks.3.norm1.bias grad: 2.956012394861318e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.914621861942578e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.517946419786313e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.7300857280133641e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.133593625330832e-06
sam_encoder.blocks.3.norm2.weight grad: -1.0261224815621972e-05
sam_encoder.blocks.3.norm2.bias grad: 2.848673830158077e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0962694432237186e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.077374796906952e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.482976229766791e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.738984552612237e-07
sam_encoder.blocks.4.norm1.weight grad: 9.51020592765417e-06
sam_encoder.blocks.4.norm1.bias grad: 4.9692725951899774e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.1364703570725396e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3331953141459962e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.1073435501884887e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.1670604180835653e-06
sam_encoder.blocks.4.norm2.weight grad: -9.11943061510101e-06
sam_encoder.blocks.4.norm2.bias grad: -4.198888746032026e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.2793320719501935e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.4097953453529044e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.461335715357563e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.623048083767344e-09
sam_encoder.blocks.5.norm1.weight grad: 1.1978669135714881e-05
sam_encoder.blocks.5.norm1.bias grad: -3.937167093681637e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.1963362339884043e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.1812264751351904e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.542309615222621e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.7649118692352204e-06
sam_encoder.blocks.5.norm2.weight grad: -2.795886530293501e-06
sam_encoder.blocks.5.norm2.bias grad: -2.3028205760056153e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.3000617400393821e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.471568667620886e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.25692551478096e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.4102627094180207e-07
sam_encoder.blocks.6.norm1.weight grad: 1.413502786817844e-06
sam_encoder.blocks.6.norm1.bias grad: -3.878104962495854e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.43744455272099e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4467443634202937e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.8280367675724847e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.5971865486317256e-07
sam_encoder.blocks.6.norm2.weight grad: -2.3059878913045395e-06
sam_encoder.blocks.6.norm2.bias grad: -6.603507927138708e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.382489926982089e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.359462301792519e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.178016522222606e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.8908417587226722e-07
sam_encoder.blocks.7.norm1.weight grad: 2.5385816115885973e-08
sam_encoder.blocks.7.norm1.bias grad: -1.3514770671463339e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.333546025416581e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.8365710729995044e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.797388323320774e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.0888319340883754e-07
sam_encoder.blocks.7.norm2.weight grad: -1.1631952929747058e-06
sam_encoder.blocks.7.norm2.bias grad: 1.4046516980670276e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.77385389230767e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5717153019068064e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.217650833496009e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.165463790035574e-07
sam_encoder.blocks.8.norm1.weight grad: 4.00362114305608e-06
sam_encoder.blocks.8.norm1.bias grad: -1.1998101854260312e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.127068106958177e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.1537975953833666e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5530163182120305e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.601423171848637e-08
sam_encoder.blocks.8.norm2.weight grad: -5.855422841705149e-06
sam_encoder.blocks.8.norm2.bias grad: 1.369508254356333e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.173089786898345e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.5447696973278653e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.2418712433136534e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.274498324884917e-07
sam_encoder.blocks.9.norm1.weight grad: 1.3871284636479686e-06
sam_encoder.blocks.9.norm1.bias grad: -7.650047564311535e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 9.92874447547365e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.0675867088139057e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.7468309465584753e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.9398923945555e-07
sam_encoder.blocks.9.norm2.weight grad: 8.627998795418534e-07
sam_encoder.blocks.9.norm2.bias grad: 8.87609246547072e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.282721637442592e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.263239242798591e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.155014026873687e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.064262490530382e-07
sam_encoder.blocks.10.norm1.weight grad: -1.2989364677196136e-06
sam_encoder.blocks.10.norm1.bias grad: 9.77874705654358e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.926802724483423e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.630837330907525e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.254926461224386e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.422208010306349e-07
sam_encoder.blocks.10.norm2.weight grad: 6.028053007867129e-07
sam_encoder.blocks.10.norm2.bias grad: 1.3459350611810805e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.336787237160024e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.688433937692025e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.824482296797214e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.052962587295042e-07
sam_encoder.blocks.11.norm1.weight grad: -2.6489458377909614e-06
sam_encoder.blocks.11.norm1.bias grad: 2.103214455928537e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0586313692328986e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.3616748901768005e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.6398366824432742e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.1129423000966199e-06
sam_encoder.blocks.11.norm2.weight grad: -2.3457073439203668e-07
sam_encoder.blocks.11.norm2.bias grad: 1.0359008228988387e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.244165787284146e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.5671062669753155e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.5161308409878984e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.889442261126533e-08
sam_encoder.neck.conv1.trainable_scale grad: 6.207110345712863e-07
sam_encoder.neck.conv1.trainable_shift grad: 6.826458047726192e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.1162392183905467e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.177260466851294e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010102435771841556
mask_decoder.transformer.layers.0.norm1.bias grad: 2.2928070393390954e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0051506925374269485
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002703330246731639
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00018107093637809157
mask_decoder.transformer.layers.0.norm3.bias grad: 3.5058517823927104e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001390287943650037
mask_decoder.transformer.layers.0.norm4.bias grad: 8.029848686419427e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.591709951753728e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0784300431841984e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00017891386232804507
mask_decoder.transformer.layers.1.norm2.bias grad: -6.42702798359096e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.0031975509482436e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.628178324608598e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 1.8446742615196854e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013824619236402214
mask_decoder.transformer.norm_final_attn.weight grad: -8.790507308731321e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.5155535947997123e-05
Text_Embedding_Affine.0.weight grad: 2.5007544646182822e-11
Text_Embedding_Affine.0.bias grad: 5.136479019896001e-10
Text_Embedding_Affine.2.weight grad: -2.0496497554756132e-10
Text_Embedding_Affine.2.bias grad: -2.0656032575061545e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.035796642374521e-09
Max value: 0.9964107871055603
Mean value: 0.11343681812286377

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.035796642374521e-09
Max value: 0.9964107871055603
Mean value: 0.11343681812286377

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09730243682861328

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.70157241821289
Max value: -1.1920928244535389e-07
Mean value: -0.1350560188293457

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1001577377319336

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09730243682861328

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 43.3783073425293
Max value: 68.83224487304688
Mean value: 58.07469177246094

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0811641582009202e-09
Max value: 0.9970279335975647
Mean value: 0.1109151691198349

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0811641582009202e-09
Max value: 0.9970279335975647
Mean value: 0.1109151691198349

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0811641582009202e-09
Max value: 0.9970279335975647
Mean value: 0.1109151691198349

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.274566650390625
Max value: -1.1920928244535389e-07
Mean value: -0.1334117352962494

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5585752129554749
Max value: 1.0694868564605713
Mean value: 1.0017592906951904

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 43.3783073425293
Max value: 68.83224487304688
Mean value: 58.07469177246094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.17544174194336
Max value: -58.17544174194336
Mean value: -58.17544174194336
sam_encoder.pos_embed grad: 3.5433966871778466e-10
sam_encoder.blocks.0.norm1.weight grad: 7.784962508594617e-05
sam_encoder.blocks.0.norm1.bias grad: 1.822941703721881e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.913832865189761e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.043461305196615e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.9161142265365925e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.501824272054364e-06
sam_encoder.blocks.0.norm2.weight grad: 3.0284125386970118e-05
sam_encoder.blocks.0.norm2.bias grad: -2.5808996724663302e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.685955102308071e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.761919404292712e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.002783149800962e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.711928785487544e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1346895007591229e-05
sam_encoder.blocks.1.norm1.bias grad: -2.337083060410805e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.2780542419932317e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.0722671959229046e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.6508794235269306e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.709003734315047e-07
sam_encoder.blocks.1.norm2.weight grad: -1.2321480426180642e-05
sam_encoder.blocks.1.norm2.bias grad: 7.344955292865052e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0940164429484867e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.05691344490333e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.276427590521052e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.052917127708497e-06
sam_encoder.blocks.2.norm1.weight grad: -1.0112315067090094e-05
sam_encoder.blocks.2.norm1.bias grad: -3.4596605473780073e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.754698461008957e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.5230472147086402e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.8196417335711885e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.409499873261666e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1891130270669237e-05
sam_encoder.blocks.2.norm2.bias grad: 1.8915004602604313e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.70458313531708e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.0731118891271763e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.765458809037227e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.888755367777776e-07
sam_encoder.blocks.3.norm1.weight grad: -7.417972483381163e-06
sam_encoder.blocks.3.norm1.bias grad: -2.2810218069935217e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.3992197409606888e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.358389880579125e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.1250586712540098e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.549216216924833e-06
sam_encoder.blocks.3.norm2.weight grad: -2.3459400836145505e-05
sam_encoder.blocks.3.norm2.bias grad: -5.8477589846006595e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.863131001300644e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.921787189639872e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.7445144041848835e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.681444008587277e-07
sam_encoder.blocks.4.norm1.weight grad: -6.622840373893268e-06
sam_encoder.blocks.4.norm1.bias grad: -5.916242571402108e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.178966825449606e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.4883004243747564e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.6769445210229605e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.372603603362222e-06
sam_encoder.blocks.4.norm2.weight grad: 1.4644574548583478e-05
sam_encoder.blocks.4.norm2.bias grad: 9.287519787903875e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.082739779842086e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.9498745536548086e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.950719585394836e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.8602880774997175e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4017557077750098e-05
sam_encoder.blocks.5.norm1.bias grad: 6.4410705817863345e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.3413688066066243e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.645126177318161e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.994690858799004e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.8524260667618364e-06
sam_encoder.blocks.5.norm2.weight grad: 1.7427235434297472e-05
sam_encoder.blocks.5.norm2.bias grad: 7.368284968833905e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.1608216254899162e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.829409228548684e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.2809635993326083e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.0311262030882062e-06
sam_encoder.blocks.6.norm1.weight grad: 1.9689482542162295e-06
sam_encoder.blocks.6.norm1.bias grad: -4.180832036126958e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.828559551446233e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.7958004668325884e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.053549898548226e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.01261684903875e-06
sam_encoder.blocks.6.norm2.weight grad: 1.107222033169819e-05
sam_encoder.blocks.6.norm2.bias grad: 4.632035597751383e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.8955940959131112e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.3557798790061497e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.573934570042184e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.531019956426462e-07
sam_encoder.blocks.7.norm1.weight grad: 1.3366965504246764e-05
sam_encoder.blocks.7.norm1.bias grad: 3.968010275912093e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.932693501468748e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.1590375328960363e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.4993928491312545e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.0637820600531995e-06
sam_encoder.blocks.7.norm2.weight grad: -4.786119461641647e-06
sam_encoder.blocks.7.norm2.bias grad: -1.0711655704653822e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.1292803366086446e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.0181486181390937e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.009132569786743e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.3416477884220512e-07
sam_encoder.blocks.8.norm1.weight grad: 1.3798051440971904e-05
sam_encoder.blocks.8.norm1.bias grad: 1.126571987697389e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.702135705272667e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.1688091338728555e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 7.601780680488446e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.5080350951611763e-07
sam_encoder.blocks.8.norm2.weight grad: 3.922321411664598e-06
sam_encoder.blocks.8.norm2.bias grad: 3.8735333873773925e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.490163157313873e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.562280201345857e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.210449292140765e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.394290832962724e-07
sam_encoder.blocks.9.norm1.weight grad: 9.9935605248902e-06
sam_encoder.blocks.9.norm1.bias grad: 4.388736556393269e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.90125647856621e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.4020664568524808e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.0850079661395284e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.8079460915032541e-06
sam_encoder.blocks.9.norm2.weight grad: 9.071985004993621e-06
sam_encoder.blocks.9.norm2.bias grad: 4.333351171226241e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.428876541671343e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.4252103685284965e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.0298011804698035e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.4192671642376808e-06
sam_encoder.blocks.10.norm1.weight grad: 1.1042660617022193e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1535389603523072e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.2135700444559916e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.122321115573868e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.7014885997923557e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.6332502872937766e-07
sam_encoder.blocks.10.norm2.weight grad: 1.776915269147139e-06
sam_encoder.blocks.10.norm2.bias grad: 3.3560534120624652e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.7856127669801936e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.492241608502809e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2944086620336748e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.2735008542440482e-08
sam_encoder.blocks.11.norm1.weight grad: -1.65468554769177e-05
sam_encoder.blocks.11.norm1.bias grad: 3.0947802542868885e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1581528269744013e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.401549785233328e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.2660735794488573e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.2634204722417053e-06
sam_encoder.blocks.11.norm2.weight grad: 2.493274223525077e-06
sam_encoder.blocks.11.norm2.bias grad: 2.892597876780201e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.8506968899600906e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.2193618204037193e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.568954641901655e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.1775833854699158e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.0106963347643614e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.9118101994972676e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.432133442198392e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.314446803415194e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001627759775146842
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2855452951043844e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004742309916764498
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00100227864459157
mask_decoder.transformer.layers.0.norm3.weight grad: -6.823334842920303e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 5.693138518836349e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -9.41766775213182e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.3332611160876695e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.320963151054457e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.3671842680196278e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00024559759185649455
mask_decoder.transformer.layers.1.norm2.bias grad: -0.0001386566727887839
mask_decoder.transformer.layers.1.norm3.weight grad: -9.721973037812859e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.0977294449694455e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.944998702034354e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002575328398961574
mask_decoder.transformer.norm_final_attn.weight grad: 6.539245987369213e-06
mask_decoder.transformer.norm_final_attn.bias grad: -3.2626144275127444e-06
Text_Embedding_Affine.0.weight grad: -2.237644097791147e-12
Text_Embedding_Affine.0.bias grad: -4.913438544917881e-10
Text_Embedding_Affine.2.weight grad: -5.2037162773244106e-11
Text_Embedding_Affine.2.bias grad: -3.5035613109357655e-05
Epoch 21 finished with average loss: -59.2325
Epoch 22/39
----------
Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.8]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-57.8]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-59.5]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-59.5]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-59.9]Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-59.9]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2636839274646205e-12
Max value: 0.9997881054878235
Mean value: 0.08449579030275345

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2636839274646205e-12
Max value: 0.9997881054878235
Mean value: 0.08449579030275345

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08240509033203125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13481692969799042

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07769775390625

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08240509033203125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 34.40544891357422
Max value: 83.60305786132812
Mean value: 57.77912139892578

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2636839274646205e-12
Max value: 0.9997881054878235
Mean value: 0.08449579030275345

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2636839274646205e-12
Max value: 0.9997881054878235
Mean value: 0.08449579030275345

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2636839274646205e-12
Max value: 0.9997881054878235
Mean value: 0.08449579030275345

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13481692969799042

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 34.40544891357422
Max value: 83.60305786132812
Mean value: 57.77912139892578

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.780216217041016
Max value: -57.780216217041016
Mean value: -57.780216217041016
sam_encoder.pos_embed grad: -3.934372827529842e-10
sam_encoder.blocks.0.norm1.weight grad: -2.5260912934754742e-06
sam_encoder.blocks.0.norm1.bias grad: -9.143104762188159e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.462139264025609e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.55381250883147e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.644864806228725e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.866654078090505e-07
sam_encoder.blocks.0.norm2.weight grad: 9.589680303179193e-06
sam_encoder.blocks.0.norm2.bias grad: -3.285531420260668e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.818268285409431e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.2826646929606795e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.036738078459166e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.788504262862261e-06
sam_encoder.blocks.1.norm1.weight grad: 1.4951367575122276e-06
sam_encoder.blocks.1.norm1.bias grad: 2.1421619749162346e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.458388502825983e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.298792065237649e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.790613391174702e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4841634765616618e-06
sam_encoder.blocks.1.norm2.weight grad: -1.7355080217384966e-06
sam_encoder.blocks.1.norm2.bias grad: 1.5056903066579252e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.070896011398872e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.823933406645665e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.240515409037471e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.466702870966401e-07
sam_encoder.blocks.2.norm1.weight grad: -4.627794169209665e-06
sam_encoder.blocks.2.norm1.bias grad: 3.4832796700356994e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.689045454142615e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.871764751143928e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.299801604356617e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.5753146815077343e-07
sam_encoder.blocks.2.norm2.weight grad: -3.1005383789306507e-06
sam_encoder.blocks.2.norm2.bias grad: 7.43393002267112e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.9697818061104044e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.949509270270937e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.4918060666532256e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.594493023229006e-07
sam_encoder.blocks.3.norm1.weight grad: -2.3502295789512573e-06
sam_encoder.blocks.3.norm1.bias grad: 3.820928213826846e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.3911605947214412e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.071665209906314e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.7608090274734423e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.2519644769781735e-06
sam_encoder.blocks.3.norm2.weight grad: -1.3375522030401044e-05
sam_encoder.blocks.3.norm2.bias grad: -4.383868144941516e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1186364645254798e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.7542663449130487e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.6510659811028745e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.6869105340665556e-07
sam_encoder.blocks.4.norm1.weight grad: -5.537781362363603e-06
sam_encoder.blocks.4.norm1.bias grad: -4.388877187011531e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.123176040593535e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.64835442371259e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.1330456547730137e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.614804543554783e-06
sam_encoder.blocks.4.norm2.weight grad: 2.3425662220688537e-05
sam_encoder.blocks.4.norm2.bias grad: 1.7454472981626168e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.3372817193157971e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.854296093981247e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.728730674396502e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.2594855434144847e-06
sam_encoder.blocks.5.norm1.weight grad: -2.678748387552332e-07
sam_encoder.blocks.5.norm1.bias grad: -2.6929226351057878e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.92028119272436e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.611548097775085e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.930942516992218e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.1536850169923127e-07
sam_encoder.blocks.5.norm2.weight grad: 1.4616436601500027e-05
sam_encoder.blocks.5.norm2.bias grad: 9.806113666854799e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.500772774918005e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.792125431165914e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.32711954847764e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.838464395921619e-07
sam_encoder.blocks.6.norm1.weight grad: 7.869506362112588e-07
sam_encoder.blocks.6.norm1.bias grad: -4.058777449245099e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.933358918104204e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5256446204148233e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.118236453607096e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.205588316428475e-07
sam_encoder.blocks.6.norm2.weight grad: 7.625759280927014e-06
sam_encoder.blocks.6.norm2.bias grad: 3.7543002235906897e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.99240741696849e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.487276884101448e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.123281247662817e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.119473141552589e-07
sam_encoder.blocks.7.norm1.weight grad: -5.852734375366708e-06
sam_encoder.blocks.7.norm1.bias grad: -4.340728878560185e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.761875970871188e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.9993244677607436e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.001934717554832e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.595619067984444e-07
sam_encoder.blocks.7.norm2.weight grad: -9.989658877884722e-08
sam_encoder.blocks.7.norm2.bias grad: -1.3873186617274769e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.608894081073231e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.811334737401921e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.5717224616528256e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.992221983637137e-07
sam_encoder.blocks.8.norm1.weight grad: -1.1837709052997525e-06
sam_encoder.blocks.8.norm1.bias grad: 1.6391859389841557e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.722500079878955e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.48289494367782e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.7500245778355747e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.444602614559699e-06
sam_encoder.blocks.8.norm2.weight grad: 2.9293200896063354e-06
sam_encoder.blocks.8.norm2.bias grad: 2.005894657486351e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.7131183461269757e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.4444522018238786e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.0912447951104696e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.036804170937103e-07
sam_encoder.blocks.9.norm1.weight grad: 6.35727758435678e-07
sam_encoder.blocks.9.norm1.bias grad: 5.447822672977054e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.008170091969077e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.019593345423345e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.031437997464309e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.33175773145922e-07
sam_encoder.blocks.9.norm2.weight grad: 3.159182142553618e-06
sam_encoder.blocks.9.norm2.bias grad: 1.998979996642447e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.526926602466119e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2186769708932843e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1649322004814167e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.0248500075249467e-06
sam_encoder.blocks.10.norm1.weight grad: -4.729224656330189e-06
sam_encoder.blocks.10.norm1.bias grad: 5.554942390517681e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.881786713260226e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.0137750905414578e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6074934592325008e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.470454536611214e-07
sam_encoder.blocks.10.norm2.weight grad: 5.831038834003266e-07
sam_encoder.blocks.10.norm2.bias grad: 1.6524616057722596e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.514498404110782e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.5328600966313388e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.504815447920919e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.5980013990410953e-07
sam_encoder.blocks.11.norm1.weight grad: -1.179165246867342e-05
sam_encoder.blocks.11.norm1.bias grad: 2.4379261276408215e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.3516872741092811e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.069108960422454e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.122896830769605e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.127260002765979e-07
sam_encoder.blocks.11.norm2.weight grad: -5.761321517638862e-07
sam_encoder.blocks.11.norm2.bias grad: 9.48042725212872e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.125167955251527e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3037845292274142e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.962691602690029e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.348787546679887e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.761175998486578e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.2688043827656657e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.362195901805535e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.200567779364064e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 8.414032345172018e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.308822099119425e-08
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005291296169161797
mask_decoder.transformer.layers.0.norm2.bias grad: 6.451009539887309e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 4.899674968328327e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -9.771996701601893e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001319550210610032
mask_decoder.transformer.layers.0.norm4.bias grad: 1.006283491733484e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.6907222238369286e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -9.605382729205303e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -3.287660001660697e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -8.837536006467417e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -7.603529957123101e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.729831562144682e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.4321951059391722e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001708418712951243
mask_decoder.transformer.norm_final_attn.weight grad: -5.377070237955195e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.232774775417056e-05
Text_Embedding_Affine.0.weight grad: 3.919605091884382e-12
Text_Embedding_Affine.0.bias grad: 2.1745727440958262e-10
Text_Embedding_Affine.2.weight grad: -5.761455201813703e-11
Text_Embedding_Affine.2.bias grad: -1.0500951248104684e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.38364675220204e-11
Max value: 0.9999200105667114
Mean value: 0.08797580748796463

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.38364675220204e-11
Max value: 0.9999200105667114
Mean value: 0.08797580748796463

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08555126190185547

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11943799257278442

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07855796813964844

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08555126190185547

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.24005126953125
Max value: 72.33808135986328
Mean value: 61.114768981933594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5679816819935688e-11
Max value: 0.9999308586120605
Mean value: 0.08718189597129822

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5679816819935688e-11
Max value: 0.9999308586120605
Mean value: 0.08718189597129822

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5679816819935688e-11
Max value: 0.9999308586120605
Mean value: 0.08718189597129822

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11929818987846375

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7344567179679871
Max value: 1.026482343673706
Mean value: 1.0001689195632935

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.24005126953125
Max value: 72.33808135986328
Mean value: 61.114768981933594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.12705612182617
Max value: -61.12705612182617
Mean value: -61.12705612182617
sam_encoder.pos_embed grad: -1.238913416301557e-09
sam_encoder.blocks.0.norm1.weight grad: -1.6035432054195553e-05
sam_encoder.blocks.0.norm1.bias grad: -7.2231609919981565e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.94484812002338e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.431684588889766e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.8193008953821845e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.59959066997817e-08
sam_encoder.blocks.0.norm2.weight grad: 3.844115053652786e-05
sam_encoder.blocks.0.norm2.bias grad: -8.782255463302135e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.756394552416168e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.31250759397517e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.65287381404778e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.3994248294911813e-06
sam_encoder.blocks.1.norm1.weight grad: 8.53361143526854e-06
sam_encoder.blocks.1.norm1.bias grad: 2.9234229259600397e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.8312816791876685e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.6327310820306593e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.914265223807888e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.96498875135876e-07
sam_encoder.blocks.1.norm2.weight grad: 7.544436812167987e-06
sam_encoder.blocks.1.norm2.bias grad: -2.4003252292459365e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.664460902858991e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3670749012817396e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.235199644928798e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.365398010326317e-07
sam_encoder.blocks.2.norm1.weight grad: 5.033907655160874e-07
sam_encoder.blocks.2.norm1.bias grad: 1.8121761513612e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.0415642464067787e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.593424354330637e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.417141331534367e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.6844873584886955e-07
sam_encoder.blocks.2.norm2.weight grad: -1.793326077859092e-06
sam_encoder.blocks.2.norm2.bias grad: 1.2522865290520713e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.266192950628465e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.887207402745844e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.034158913171268e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 4.7092993327169097e-07
sam_encoder.blocks.3.norm1.weight grad: -8.092843927443027e-06
sam_encoder.blocks.3.norm1.bias grad: -5.069171947980067e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.3501790969457943e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.56696101941634e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.0738770015450427e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.0167851627329583e-07
sam_encoder.blocks.3.norm2.weight grad: 7.995297892193776e-06
sam_encoder.blocks.3.norm2.bias grad: 3.3597102628846187e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.810149327269755e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.2310003916791175e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.252302460372448e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.3697612644136825e-07
sam_encoder.blocks.4.norm1.weight grad: -9.969735401682556e-06
sam_encoder.blocks.4.norm1.bias grad: -6.0225788729439955e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.090535291354172e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.6164253224815184e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2939715361426352e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.4763738199217187e-07
sam_encoder.blocks.4.norm2.weight grad: 1.1824811736005358e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3895703432353912e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.058865099272225e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.0217199815087952e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.405289135116618e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.236641764990054e-06
sam_encoder.blocks.5.norm1.weight grad: -1.1502210327307694e-05
sam_encoder.blocks.5.norm1.bias grad: -1.0817882412084145e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.0289909369021188e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.325904915778665e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.421259185008239e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.1471814761753194e-06
sam_encoder.blocks.5.norm2.weight grad: 5.566054824157618e-06
sam_encoder.blocks.5.norm2.bias grad: -6.258984285523184e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.594276677176822e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.0727432001876878e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.024918543014792e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.7154434317490086e-07
sam_encoder.blocks.6.norm1.weight grad: 5.095711799185665e-07
sam_encoder.blocks.6.norm1.bias grad: 3.854353053611703e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.8624527342581132e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.691267001064261e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.823188995331293e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.754873259571468e-07
sam_encoder.blocks.6.norm2.weight grad: -5.654708274960285e-07
sam_encoder.blocks.6.norm2.bias grad: -1.834860086091794e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.5653800384570786e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.896220732713118e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.5577438666223316e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.2044317827530904e-06
sam_encoder.blocks.7.norm1.weight grad: 1.2117461665184237e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0426933840790298e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.0310484412912047e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.5547661291748227e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.029994220720255e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.339906586712459e-06
sam_encoder.blocks.7.norm2.weight grad: 6.679871148662642e-06
sam_encoder.blocks.7.norm2.bias grad: -6.041342999196786e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.20004232384963e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.5502711196168093e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.8854459439317e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.758825357635942e-07
sam_encoder.blocks.8.norm1.weight grad: -3.358206413395237e-06
sam_encoder.blocks.8.norm1.bias grad: 5.413133976617246e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.7890074509050464e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.113706614181865e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.897938528207305e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3735959782934515e-06
sam_encoder.blocks.8.norm2.weight grad: 8.380000508623198e-06
sam_encoder.blocks.8.norm2.bias grad: 5.436888272924989e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.773751349304803e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.34746834798716e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.1864257203342277e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.8786317923513707e-07
sam_encoder.blocks.9.norm1.weight grad: -2.9249490580696147e-06
sam_encoder.blocks.9.norm1.bias grad: 8.576486720812682e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.5241979528800584e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.9162509324341954e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.614200577179872e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.344064331642585e-07
sam_encoder.blocks.9.norm2.weight grad: 1.7850824178822222e-06
sam_encoder.blocks.9.norm2.bias grad: 2.444489837216679e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.904563077914645e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.1824108696600888e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.481138363298669e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.0913778320827987e-07
sam_encoder.blocks.10.norm1.weight grad: 3.7451782191055827e-06
sam_encoder.blocks.10.norm1.bias grad: -1.5094692571437918e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.1029530873638578e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.129154611589911e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2424292208379484e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.281279176320822e-07
sam_encoder.blocks.10.norm2.weight grad: 2.4100834252749337e-06
sam_encoder.blocks.10.norm2.bias grad: 4.93817751134884e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.3294132941155112e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.375622957766609e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.865889983804664e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.0704092068845057e-07
sam_encoder.blocks.11.norm1.weight grad: 4.799135240318719e-06
sam_encoder.blocks.11.norm1.bias grad: -2.350629983993713e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.4693100587901426e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.421797482085822e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.4784776542219333e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.0688087210583035e-07
sam_encoder.blocks.11.norm2.weight grad: 5.732154022553004e-07
sam_encoder.blocks.11.norm2.bias grad: -1.252719812327996e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.9252538550063036e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.0212517054242198e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.874260058495565e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.3754917915775877e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.064857759862207e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.482687356561655e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.94834683497902e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.09461834654212e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -8.586303010815755e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -9.338109521195292e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003806843189522624
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00011172820813953876
mask_decoder.transformer.layers.0.norm3.weight grad: -0.000205503951292485
mask_decoder.transformer.layers.0.norm3.bias grad: -2.461571421008557e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.689249130431563e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.1200976334512234e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.073892366955988e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.0632811608957127e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.750476702814922e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 4.049064955324866e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.0487951840332244e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.5106079445104115e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.804891689971555e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.09090376808308e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.711159014434088e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.41393557493575e-06
Text_Embedding_Affine.0.weight grad: -1.454074013973461e-11
Text_Embedding_Affine.0.bias grad: -1.8368501164545137e-10
Text_Embedding_Affine.2.weight grad: 1.0399596114818443e-11
Text_Embedding_Affine.2.bias grad: 1.6661035260767676e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.85255453611611e-12
Max value: 0.9964753985404968
Mean value: 0.08478525280952454

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.85255453611611e-12
Max value: 0.9964753985404968
Mean value: 0.08478525280952454

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08196449279785156

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.065373420715332
Max value: -1.1920928244535389e-07
Mean value: -0.10397810488939285

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08123970031738281

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08196449279785156

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 50.154747009277344
Max value: 77.02542877197266
Mean value: 60.699615478515625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.81353976175447e-12
Max value: 0.9969565868377686
Mean value: 0.08356083929538727

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.81353976175447e-12
Max value: 0.9969565868377686
Mean value: 0.08356083929538727

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.81353976175447e-12
Max value: 0.9969565868377686
Mean value: 0.08356083929538727

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.666500091552734
Max value: -1.1920928244535389e-07
Mean value: -0.10392212867736816

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5275764465332031
Max value: 1.0680426359176636
Mean value: 1.0001680850982666

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 50.154747009277344
Max value: 77.02542877197266
Mean value: 60.699615478515625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.712406158447266
Max value: -60.712406158447266
Mean value: -60.712406158447266
sam_encoder.pos_embed grad: 6.766423865656179e-09
sam_encoder.blocks.0.norm1.weight grad: 5.9316338592907414e-05
sam_encoder.blocks.0.norm1.bias grad: 1.0880483387154527e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.283584646851523e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.8648872785197455e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.191800927510485e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.1832893253304064e-06
sam_encoder.blocks.0.norm2.weight grad: 5.361116927815601e-05
sam_encoder.blocks.0.norm2.bias grad: -2.764146302070003e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.48146152443951e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.808515642362181e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.8870210371678695e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.5361699954373762e-05
sam_encoder.blocks.1.norm1.weight grad: 8.063354471232742e-06
sam_encoder.blocks.1.norm1.bias grad: 1.9048260583076626e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.2673524654237553e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -6.445877716032555e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.2571946828975342e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.1846290362882428e-05
sam_encoder.blocks.1.norm2.weight grad: -2.1279927750583738e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0413332347525284e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.9789869838859886e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.769591558011598e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.269680746598169e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.672957402362954e-06
sam_encoder.blocks.2.norm1.weight grad: -2.266850060550496e-05
sam_encoder.blocks.2.norm1.bias grad: 8.172068191925064e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.2282212739810348e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.761836407851661e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4277665286499541e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.639316886023153e-06
sam_encoder.blocks.2.norm2.weight grad: -9.77585295913741e-06
sam_encoder.blocks.2.norm2.bias grad: -2.648333611432463e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -8.732940841582604e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.34059119875019e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.847017483669333e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.257444288668921e-06
sam_encoder.blocks.3.norm1.weight grad: 3.647987341537373e-06
sam_encoder.blocks.3.norm1.bias grad: 1.119773878599517e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0328781172574963e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6123534578582621e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.302097739942838e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.1126665968913585e-06
sam_encoder.blocks.3.norm2.weight grad: -3.821739937848179e-06
sam_encoder.blocks.3.norm2.bias grad: 1.6084013623185456e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.481955561961513e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.3077674288506387e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.584134436910972e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.708912797468656e-07
sam_encoder.blocks.4.norm1.weight grad: -3.8129899166960968e-06
sam_encoder.blocks.4.norm1.bias grad: -9.727761607791763e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.867568233952625e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.88230932407896e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.240054062800482e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.377201548777521e-06
sam_encoder.blocks.4.norm2.weight grad: 5.551838967221556e-06
sam_encoder.blocks.4.norm2.bias grad: 1.610131948837079e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.5959862998424796e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.0823965485305962e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.100842023850419e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.0763059183082078e-06
sam_encoder.blocks.5.norm1.weight grad: -9.624288850318408e-07
sam_encoder.blocks.5.norm1.bias grad: -1.2771072761097457e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.847049356409116e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.9674193936225493e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.790058821730781e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.207039637549315e-06
sam_encoder.blocks.5.norm2.weight grad: 4.064781478518853e-06
sam_encoder.blocks.5.norm2.bias grad: 8.759464435570408e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.6477619624311046e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.3294377860547684e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.713683084555669e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.6664590652435436e-07
sam_encoder.blocks.6.norm1.weight grad: -8.058484127104748e-06
sam_encoder.blocks.6.norm1.bias grad: -9.177785614156164e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.6240053304936737e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.5441871659713797e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.8460204955772497e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.013457444467349e-06
sam_encoder.blocks.6.norm2.weight grad: 8.919146239350084e-06
sam_encoder.blocks.6.norm2.bias grad: 5.788396720163291e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.967603333876468e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.7134320842160378e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.0102907001273707e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0201764527882915e-06
sam_encoder.blocks.7.norm1.weight grad: -4.166460257692961e-06
sam_encoder.blocks.7.norm1.bias grad: -4.1872658584907185e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.2256851884303614e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.5323621482821181e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.4656713978620246e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.9548250495281536e-06
sam_encoder.blocks.7.norm2.weight grad: 4.585338956530904e-06
sam_encoder.blocks.7.norm2.bias grad: 2.2037929738871753e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.8427899703965522e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.123587005888112e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.817853899410693e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.978889597216039e-07
sam_encoder.blocks.8.norm1.weight grad: 9.140093766291102e-07
sam_encoder.blocks.8.norm1.bias grad: -9.318770821664657e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.030319354977109e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.3604570742463693e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.7477888124849414e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.6348059236624977e-06
sam_encoder.blocks.8.norm2.weight grad: -2.9382313186943065e-06
sam_encoder.blocks.8.norm2.bias grad: 7.834437383280601e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.346125817595748e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.1703998502052855e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.4358636235556332e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.104037998331478e-09
sam_encoder.blocks.9.norm1.weight grad: -2.3094696643966017e-06
sam_encoder.blocks.9.norm1.bias grad: -3.969374517964752e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.1598292480339296e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.43404849950457e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1062203384426539e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.825624498356774e-07
sam_encoder.blocks.9.norm2.weight grad: -3.287122808615095e-06
sam_encoder.blocks.9.norm2.bias grad: 2.0389775272633415e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.642644737235969e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.085620963043766e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1615975381573662e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.9132261286358698e-07
sam_encoder.blocks.10.norm1.weight grad: -7.985741831362247e-06
sam_encoder.blocks.10.norm1.bias grad: -1.5198218079603976e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.219002105150139e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.0119402961427113e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.1690707399102394e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.930960919111385e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3986018529976718e-05
sam_encoder.blocks.10.norm2.bias grad: -4.972908982381341e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.96492076915456e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.586677732731914e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.309097908437252e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.170382332333247e-07
sam_encoder.blocks.11.norm1.weight grad: -1.572560540807899e-05
sam_encoder.blocks.11.norm1.bias grad: 1.5199218239558832e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1687111509672832e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0480420087333187e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.0294033927493729e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.0886982099455054e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3236988706921693e-05
sam_encoder.blocks.11.norm2.bias grad: -9.187723435388762e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.240061338758096e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.530980054871179e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.295552010560641e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.646517138302443e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.281184035586193e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.683085302938707e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.398411980830133e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.053027128567919e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010898959590122104
mask_decoder.transformer.layers.0.norm1.bias grad: 1.743559550959617e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0048430003225803375
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00022400252055376768
mask_decoder.transformer.layers.0.norm3.weight grad: -4.47428465122357e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 7.182517583714798e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.66705013322644e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.738059477764182e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.349751543486491e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.506863999471534e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002404990664217621
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00019924835942219943
mask_decoder.transformer.layers.1.norm3.weight grad: 3.219609061488882e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.4364845709642395e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.1618728826288134e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 8.893013728084043e-05
mask_decoder.transformer.norm_final_attn.weight grad: 6.041525011823978e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3847652553522494e-06
Text_Embedding_Affine.0.weight grad: -4.8880699834996655e-12
Text_Embedding_Affine.0.bias grad: 1.9187956779020965e-10
Text_Embedding_Affine.2.weight grad: -2.115531916313529e-10
Text_Embedding_Affine.2.bias grad: -7.600770186400041e-05
Epoch 22 finished with average loss: -59.8732
Epoch 23/39
----------
Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.3]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-64.3]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-61.5]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-61.5]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-62.9]Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-62.9]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.565757915994897e-14
Max value: 0.9989224672317505
Mean value: 0.08037994801998138

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.565757915994897e-14
Max value: 0.9989224672317505
Mean value: 0.08037994801998138

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08684206008911133

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11425381898880005

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07474565505981445

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08684206008911133

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 34.48445510864258
Max value: 80.49017333984375
Mean value: 64.2879867553711

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.565757915994897e-14
Max value: 0.9989224672317505
Mean value: 0.08037994801998138

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.565757915994897e-14
Max value: 0.9989224672317505
Mean value: 0.08037994801998138

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.565757915994897e-14
Max value: 0.9989224672317505
Mean value: 0.08037994801998138

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11425381898880005

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 34.48445510864258
Max value: 80.49017333984375
Mean value: 64.2879867553711

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.28900146484375
Max value: -64.28900146484375
Mean value: -64.28900146484375
sam_encoder.pos_embed grad: 7.454064032685892e-09
sam_encoder.blocks.0.norm1.weight grad: 3.395693056518212e-05
sam_encoder.blocks.0.norm1.bias grad: -2.881278305721935e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.426216375781223e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.9063339777858346e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.18151295586722e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.388471330050379e-06
sam_encoder.blocks.0.norm2.weight grad: 4.1685088945087045e-05
sam_encoder.blocks.0.norm2.bias grad: -1.407667468811269e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.3724995672819205e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.8041960124246543e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.5655422834679484e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.8339522284804843e-05
sam_encoder.blocks.1.norm1.weight grad: 1.0558023859630339e-05
sam_encoder.blocks.1.norm1.bias grad: 2.2350326617015526e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3711485735257156e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.6990074931964045e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.4531530723616015e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.817561709089205e-06
sam_encoder.blocks.1.norm2.weight grad: -1.7654649127507582e-05
sam_encoder.blocks.1.norm2.bias grad: -7.099374670360703e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.7203361494466662e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.219373300249572e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.9497409084578976e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.4483321137959138e-06
sam_encoder.blocks.2.norm1.weight grad: -2.650164969963953e-05
sam_encoder.blocks.2.norm1.bias grad: -4.628842816600809e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.574283669469878e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.182778527843766e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.488729013653938e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.812050065083895e-06
sam_encoder.blocks.2.norm2.weight grad: -7.609619842696702e-06
sam_encoder.blocks.2.norm2.bias grad: 7.710344789302326e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.321679277083604e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.114669304224662e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3199237400840502e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.9483388769003795e-06
sam_encoder.blocks.3.norm1.weight grad: 5.4007009566703346e-06
sam_encoder.blocks.3.norm1.bias grad: 2.3342242627677479e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.1652252800995484e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1735255611711182e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.528803977635107e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.6987363526131958e-06
sam_encoder.blocks.3.norm2.weight grad: -1.078242166840937e-05
sam_encoder.blocks.3.norm2.bias grad: 9.82064193522092e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.202440196531825e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.7366329504729947e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.2102089385734871e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.6327113573643146e-06
sam_encoder.blocks.4.norm1.weight grad: -6.699877985738567e-07
sam_encoder.blocks.4.norm1.bias grad: -6.965920874790754e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.8051975985144963e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.8081917687595706e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.781716597790364e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.333979970600922e-06
sam_encoder.blocks.4.norm2.weight grad: 2.641379069245886e-05
sam_encoder.blocks.4.norm2.bias grad: 1.1586314940359443e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.4201820704329293e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.899136456515407e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.6035293103632284e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.3606040738523006e-08
sam_encoder.blocks.5.norm1.weight grad: -5.136884283274412e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2862421499448828e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.841043962893309e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.905178106033418e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.537563189747743e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.672917384596076e-06
sam_encoder.blocks.5.norm2.weight grad: 4.779602932103444e-06
sam_encoder.blocks.5.norm2.bias grad: 4.416713636601344e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.321216359428945e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.7305534306142363e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -6.989558869463508e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6030773153374867e-08
sam_encoder.blocks.6.norm1.weight grad: -3.163754399793106e-06
sam_encoder.blocks.6.norm1.bias grad: -1.0108095011673868e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.655965651385486e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.7282694670939236e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.611765014786215e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.474636292186915e-06
sam_encoder.blocks.6.norm2.weight grad: 1.1443417861300986e-05
sam_encoder.blocks.6.norm2.bias grad: 4.739248652185779e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.6597464259102708e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.95479195403459e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.026074063607666e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.3136209418007638e-06
sam_encoder.blocks.7.norm1.weight grad: -1.1237671060371213e-05
sam_encoder.blocks.7.norm1.bias grad: 1.3096155271341559e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.393557098112069e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.0565443012164906e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.435473783814814e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.203747489053058e-07
sam_encoder.blocks.7.norm2.weight grad: 4.539342626230791e-06
sam_encoder.blocks.7.norm2.bias grad: -3.880384610965848e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.978070031327661e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.4229408407118171e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.913452706503449e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.8008010960766114e-07
sam_encoder.blocks.8.norm1.weight grad: -1.6997786360661848e-06
sam_encoder.blocks.8.norm1.bias grad: -3.157404933062935e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.0930729078827426e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.578644473620443e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.7298948377138e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.857584932935424e-06
sam_encoder.blocks.8.norm2.weight grad: -1.2728827414321131e-06
sam_encoder.blocks.8.norm2.bias grad: 2.276603026984958e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.4887502806668635e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.014128995142528e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.935391765073291e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.4509029117325554e-07
sam_encoder.blocks.9.norm1.weight grad: -4.792615982296411e-06
sam_encoder.blocks.9.norm1.bias grad: 1.2343123216851382e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.171231012151111e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.871613105526194e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.5028230109237484e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.7041433011399931e-06
sam_encoder.blocks.9.norm2.weight grad: -7.755853403068613e-06
sam_encoder.blocks.9.norm2.bias grad: 1.1410268143663416e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.0133990144822747e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.9359561014862265e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.802365543175256e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.6409775222855387e-07
sam_encoder.blocks.10.norm1.weight grad: -9.601721103535965e-06
sam_encoder.blocks.10.norm1.bias grad: -1.0967310117848683e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.729723397962516e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.230714017059654e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.200891231041169e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.302991904594819e-06
sam_encoder.blocks.10.norm2.weight grad: -1.883337063190993e-05
sam_encoder.blocks.10.norm2.bias grad: -1.764780677149247e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.1201880624867044e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.893618774483912e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.3359201552229933e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.92729531187797e-07
sam_encoder.blocks.11.norm1.weight grad: -2.5974468371714465e-05
sam_encoder.blocks.11.norm1.bias grad: 5.069902613286104e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.641295158260618e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.596502544198302e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.8928035387943964e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.588895070715807e-07
sam_encoder.blocks.11.norm2.weight grad: -2.5721394194988534e-05
sam_encoder.blocks.11.norm2.bias grad: -3.4822187444660813e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.0368725270382129e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.106717708258657e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.5210665626218542e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.214524657683796e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.9722286853939295e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.363708310644142e-05
sam_encoder.neck.conv2.trainable_scale grad: 5.818328645545989e-07
sam_encoder.neck.conv2.trainable_shift grad: 7.360117706411984e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -5.563200102187693e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.188622602261603e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0042660851031541824
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00022814606199972332
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0001908059639390558
mask_decoder.transformer.layers.0.norm3.bias grad: -3.9525912143290043e-07
mask_decoder.transformer.layers.0.norm4.weight grad: -9.379733091918752e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.812555511714891e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.511200182198081e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.633074008277617e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0003188324044458568
mask_decoder.transformer.layers.1.norm2.bias grad: -7.106538396328688e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.674601172562689e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.1569099772023037e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.914297748357058e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00023826802498660982
mask_decoder.transformer.norm_final_attn.weight grad: 1.4600259419239592e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.291522600397002e-06
Text_Embedding_Affine.0.weight grad: -9.72799445164707e-12
Text_Embedding_Affine.0.bias grad: 4.232870651210696e-11
Text_Embedding_Affine.2.weight grad: -1.3197988535385008e-10
Text_Embedding_Affine.2.bias grad: 3.659188951132819e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.607199920165581e-16
Max value: 0.9996881484985352
Mean value: 0.0772913321852684

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.607199920165581e-16
Max value: 0.9996881484985352
Mean value: 0.0772913321852684

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07428407669067383

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1165812611579895

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07046890258789062

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07428407669067383

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.10269546508789
Max value: 76.53376007080078
Mean value: 58.647193908691406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.1953346987377753e-16
Max value: 0.999710738658905
Mean value: 0.07661420106887817

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.1953346987377753e-16
Max value: 0.999710738658905
Mean value: 0.07661420106887817

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.1953346987377753e-16
Max value: 0.999710738658905
Mean value: 0.07661420106887817

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11653116345405579

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7796635627746582
Max value: 1.0277068614959717
Mean value: 1.0000650882720947

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.10269546508789
Max value: 76.53376007080078
Mean value: 58.647193908691406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.653541564941406
Max value: -58.653541564941406
Mean value: -58.653541564941406
sam_encoder.pos_embed grad: -6.558091847352898e-09
sam_encoder.blocks.0.norm1.weight grad: -3.2470338737766724e-06
sam_encoder.blocks.0.norm1.bias grad: 2.641863829921931e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.347221818079561e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1894707085957634e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.5853640888963128e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.809825769480085e-07
sam_encoder.blocks.0.norm2.weight grad: 2.443880475766491e-05
sam_encoder.blocks.0.norm2.bias grad: -7.933783194857824e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2048998314639903e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.566397582399077e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.1045718565583229e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.739858352171723e-06
sam_encoder.blocks.1.norm1.weight grad: 1.533776412543375e-07
sam_encoder.blocks.1.norm1.bias grad: -5.383456482377369e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.163106263556983e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.773130406945711e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.184013843972934e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.184700861107558e-06
sam_encoder.blocks.1.norm2.weight grad: 1.8855636881198734e-05
sam_encoder.blocks.1.norm2.bias grad: 8.822008567221928e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.396756245725555e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.2690695712080924e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.0370431482442655e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6373968492189306e-06
sam_encoder.blocks.2.norm1.weight grad: 5.9141093515791e-06
sam_encoder.blocks.2.norm1.bias grad: -2.710982471398893e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.8746147765778005e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.868880397334578e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.595939233491663e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.9582511160697322e-06
sam_encoder.blocks.2.norm2.weight grad: -1.3860497347195633e-05
sam_encoder.blocks.2.norm2.bias grad: 7.726500257376756e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.549793058889918e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.424471404083306e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.0786959592223866e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.661995032824052e-07
sam_encoder.blocks.3.norm1.weight grad: 7.407362772937631e-06
sam_encoder.blocks.3.norm1.bias grad: -9.922446224663872e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.3482067515724339e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.24642960233723e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.75506919126201e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1621428939179168e-06
sam_encoder.blocks.3.norm2.weight grad: 4.629891009244602e-06
sam_encoder.blocks.3.norm2.bias grad: -2.240850108137238e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.9601360438391566e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.301423809418338e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.575089628313435e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.718463636279921e-06
sam_encoder.blocks.4.norm1.weight grad: 2.0792307623196393e-05
sam_encoder.blocks.4.norm1.bias grad: 3.314753485028632e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 8.07290507509606e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.6981861108433804e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.553186954581179e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.868922703986755e-06
sam_encoder.blocks.4.norm2.weight grad: -3.94087728636805e-05
sam_encoder.blocks.4.norm2.bias grad: -2.1552168618654832e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.4944631149992347e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.645775207900442e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.012956883845618e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.7750070924194006e-07
sam_encoder.blocks.5.norm1.weight grad: 1.1941010598093271e-05
sam_encoder.blocks.5.norm1.bias grad: -6.608018793485826e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.608170108142076e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.601253848577016e-09
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.016399543615989e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.8579838726727758e-06
sam_encoder.blocks.5.norm2.weight grad: -1.5636531315976754e-05
sam_encoder.blocks.5.norm2.bias grad: -1.616558074601926e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.8427680162130855e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.619124416014529e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.174773569180616e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.3512890291167423e-06
sam_encoder.blocks.6.norm1.weight grad: 2.865537680918351e-06
sam_encoder.blocks.6.norm1.bias grad: 4.498301677813288e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.1728918656881433e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.327715430463286e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6798206843304797e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.363749882140837e-07
sam_encoder.blocks.6.norm2.weight grad: -5.599584255833179e-06
sam_encoder.blocks.6.norm2.bias grad: -1.526819687569514e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.1242183215217665e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.015382278841571e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.156386002156069e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.199300166073954e-07
sam_encoder.blocks.7.norm1.weight grad: 5.286888608679874e-06
sam_encoder.blocks.7.norm1.bias grad: 4.1821485297077743e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.754532255901722e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5558248378511053e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.1663631741830613e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.3254050372779602e-06
sam_encoder.blocks.7.norm2.weight grad: 1.6189412690437166e-06
sam_encoder.blocks.7.norm2.bias grad: 3.3934284147107974e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.59849764208775e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.7431763644235616e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.389073743979679e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.461189852620009e-07
sam_encoder.blocks.8.norm1.weight grad: 3.972637841798132e-06
sam_encoder.blocks.8.norm1.bias grad: -3.1956321890902473e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.281979156279704e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.457425014450564e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.519377060001716e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.368137984376517e-06
sam_encoder.blocks.8.norm2.weight grad: 5.218329306444502e-07
sam_encoder.blocks.8.norm2.bias grad: -2.5783191404116224e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.7044998230630881e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.278619366639759e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.367540534147338e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.389712320422404e-07
sam_encoder.blocks.9.norm1.weight grad: -2.180815954488935e-07
sam_encoder.blocks.9.norm1.bias grad: 3.9609980717614235e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.5494844041750184e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.825948849429551e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.898121801488742e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.274513093425412e-07
sam_encoder.blocks.9.norm2.weight grad: 2.6916691240330692e-06
sam_encoder.blocks.9.norm2.bias grad: -1.8787220312788122e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.7786852569988696e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3931526154919993e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.489250725077e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.1352177504450083e-07
sam_encoder.blocks.10.norm1.weight grad: 4.164214260526933e-06
sam_encoder.blocks.10.norm1.bias grad: 4.245248419465497e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.1329300327342935e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.329867473032209e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.850794774327369e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.520489250760875e-07
sam_encoder.blocks.10.norm2.weight grad: 1.4413910776056582e-06
sam_encoder.blocks.10.norm2.bias grad: -2.335832959943218e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.423509951971937e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 4.988390855942271e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.683524477717583e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.348886927298736e-07
sam_encoder.blocks.11.norm1.weight grad: 2.2934771550353616e-05
sam_encoder.blocks.11.norm1.bias grad: -3.301615834061522e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.175703341184999e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0670527217371273e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.7673412407457363e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4804015791014535e-06
sam_encoder.blocks.11.norm2.weight grad: 3.2064297101896955e-06
sam_encoder.blocks.11.norm2.bias grad: -2.036711975961225e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.810017682961188e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.941516292296001e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.96129928251321e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.079188081121174e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.882614691974595e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.303154466673732e-07
sam_encoder.neck.conv2.trainable_scale grad: -4.498569978750311e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.037653292878531e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001643901050556451
mask_decoder.transformer.layers.0.norm1.bias grad: -2.27244890993461e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003961919341236353
mask_decoder.transformer.layers.0.norm2.bias grad: 0.000494118663482368
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0001483034429838881
mask_decoder.transformer.layers.0.norm3.bias grad: -2.9961447580717504e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001742619788274169
mask_decoder.transformer.layers.0.norm4.bias grad: -1.388482723996276e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.3391377655789256e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.2602101782686077e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.97536563873291e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.8403301257640123e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.799774589831941e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.719459709827788e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.40365280257538e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00026912070461548865
mask_decoder.transformer.norm_final_attn.weight grad: 3.82468533643987e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.2621525204158388e-05
Text_Embedding_Affine.0.weight grad: 1.782906287883801e-12
Text_Embedding_Affine.0.bias grad: -1.4975194695399097e-10
Text_Embedding_Affine.2.weight grad: 5.172874281700324e-11
Text_Embedding_Affine.2.bias grad: 5.3311938245315105e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.337440137278879e-11
Max value: 0.9993951320648193
Mean value: 0.09483364969491959

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.337440137278879e-11
Max value: 0.9993951320648193
Mean value: 0.09483364969491959

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09744930267333984

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.095680236816406
Max value: -1.1920928244535389e-07
Mean value: -0.12275983393192291

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08825492858886719

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09744930267333984

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 42.52323913574219
Max value: 90.4632797241211
Mean value: 65.82975769042969

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1042653770554356e-11
Max value: 0.9994497895240784
Mean value: 0.09333527088165283

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1042653770554356e-11
Max value: 0.9994497895240784
Mean value: 0.09333527088165283

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1042653770554356e-11
Max value: 0.9994497895240784
Mean value: 0.09333527088165283

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.410236358642578
Max value: -1.1920928244535389e-07
Mean value: -0.12289106845855713

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7181046605110168
Max value: 1.0414828062057495
Mean value: 0.9999268651008606

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 42.52323913574219
Max value: 90.4632797241211
Mean value: 65.82975769042969

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.82730865478516
Max value: -65.82730865478516
Mean value: -65.82730865478516
sam_encoder.pos_embed grad: 1.5899535021901556e-09
sam_encoder.blocks.0.norm1.weight grad: -1.2469334251363762e-05
sam_encoder.blocks.0.norm1.bias grad: -1.0434631576572428e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.2578851144317014e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0029005892420173e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.557831279176753e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.204273125196778e-07
sam_encoder.blocks.0.norm2.weight grad: 9.408661753695924e-06
sam_encoder.blocks.0.norm2.bias grad: -1.6456155549349205e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.0482955278566806e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.0398520089438534e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.468065748777008e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.1191054909431841e-06
sam_encoder.blocks.1.norm1.weight grad: 6.977837074373383e-06
sam_encoder.blocks.1.norm1.bias grad: 6.117967132013291e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.1997543626639526e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.294186848914251e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.1687778851410258e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1029427469111397e-06
sam_encoder.blocks.1.norm2.weight grad: 4.572232228383655e-06
sam_encoder.blocks.1.norm2.bias grad: 8.835353355607367e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.178370884095784e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0900918141487637e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.639682063294458e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.927212782808056e-07
sam_encoder.blocks.2.norm1.weight grad: 2.408901764283655e-06
sam_encoder.blocks.2.norm1.bias grad: -6.301045686996076e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.057019057450816e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.373749551537912e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.6481981219840236e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.6145165773195913e-06
sam_encoder.blocks.2.norm2.weight grad: -3.7532045098487288e-06
sam_encoder.blocks.2.norm2.bias grad: -1.260924591406365e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.9749036255234387e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.5439288126326574e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.0668976503657177e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6053976398543455e-07
sam_encoder.blocks.3.norm1.weight grad: -5.7639020667465957e-08
sam_encoder.blocks.3.norm1.bias grad: -2.050353941740468e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.8049165646516485e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.112248461751733e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.0725889296736568e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.605421514090267e-07
sam_encoder.blocks.3.norm2.weight grad: 8.564168638258707e-06
sam_encoder.blocks.3.norm2.bias grad: 1.2658050764002837e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.535388365591643e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2735787297278875e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.4305204533447977e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.451656275885398e-08
sam_encoder.blocks.4.norm1.weight grad: -7.166221166698961e-06
sam_encoder.blocks.4.norm1.bias grad: 1.9463315936718573e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.3261376201116946e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.465845000187983e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3416788533504587e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.26506401190818e-07
sam_encoder.blocks.4.norm2.weight grad: 3.1167037377599627e-06
sam_encoder.blocks.4.norm2.bias grad: -1.5319556041504256e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.520458211729419e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.995320068701403e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.173677770173526e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.71109251773305e-07
sam_encoder.blocks.5.norm1.weight grad: -3.4621184568095487e-06
sam_encoder.blocks.5.norm1.bias grad: -4.917049409414176e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.002399916520517e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.4240615655580768e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.5630632788088406e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.0197416031587636e-06
sam_encoder.blocks.5.norm2.weight grad: 6.828961431892822e-07
sam_encoder.blocks.5.norm2.bias grad: -7.809511544110137e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.443213002668926e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.916817341107162e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1092330396422767e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.619637828298437e-07
sam_encoder.blocks.6.norm1.weight grad: 7.613007255713455e-07
sam_encoder.blocks.6.norm1.bias grad: 2.2690878722642083e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.247902769653592e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.725792166482279e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.57024303968501e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.898517537796579e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1664881185424747e-06
sam_encoder.blocks.6.norm2.bias grad: 2.0098093500564573e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.721124231669819e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.51346045590617e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.276482160203159e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.932968096696186e-08
sam_encoder.blocks.7.norm1.weight grad: 2.6364709810877685e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0602017255223473e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.7318474192506983e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.578682925668545e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4576756939277402e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.4407564776774962e-06
sam_encoder.blocks.7.norm2.weight grad: -3.215405740775168e-06
sam_encoder.blocks.7.norm2.bias grad: -5.612477593786025e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.058597485505743e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.418997953805956e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.384016059091664e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.0089557741303e-07
sam_encoder.blocks.8.norm1.weight grad: 9.147329365077894e-06
sam_encoder.blocks.8.norm1.bias grad: 1.8877472029998899e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.785773388808593e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.059521986870095e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.959894689207431e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.4808723360984e-07
sam_encoder.blocks.8.norm2.weight grad: 1.2148464065830922e-06
sam_encoder.blocks.8.norm2.bias grad: -7.93139278698618e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.405970462859841e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.559740437391156e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.843624878958508e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.3941962012941076e-07
sam_encoder.blocks.9.norm1.weight grad: -6.735550641678856e-07
sam_encoder.blocks.9.norm1.bias grad: 1.5809629871910147e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.383235924862674e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.57453848462319e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.386768471751566e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.17339399202865e-08
sam_encoder.blocks.9.norm2.weight grad: 6.87531326093449e-07
sam_encoder.blocks.9.norm2.bias grad: -6.591375267817057e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.4635414774820674e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.638308558289282e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.167363946791738e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.129414487077156e-08
sam_encoder.blocks.10.norm1.weight grad: 1.0006402817452908e-06
sam_encoder.blocks.10.norm1.bias grad: -1.162018634204287e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.816573426884133e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.7355698623287026e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.969798569869454e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.884709028374346e-07
sam_encoder.blocks.10.norm2.weight grad: -3.8270554796326905e-06
sam_encoder.blocks.10.norm2.bias grad: -2.2595152131543728e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.4797396943322383e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.58385580562026e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.916791688927333e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.480831077875337e-07
sam_encoder.blocks.11.norm1.weight grad: 6.802580173825845e-06
sam_encoder.blocks.11.norm1.bias grad: -1.530909571556549e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.3203432394657284e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.930576657599886e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.265287311180145e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.8124657092121197e-07
sam_encoder.blocks.11.norm2.weight grad: -3.079161956520693e-07
sam_encoder.blocks.11.norm2.bias grad: -1.3165124528313754e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.2334165830907295e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.565278348105494e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.601703941872984e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.414198511743962e-08
sam_encoder.neck.conv1.trainable_scale grad: 6.291784302447923e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.888787093979772e-06
sam_encoder.neck.conv2.trainable_scale grad: 8.796146175882313e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.9546510631917045e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010046861279988661
mask_decoder.transformer.layers.0.norm1.bias grad: 1.1249685485381633e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0033995916601270437
mask_decoder.transformer.layers.0.norm2.bias grad: -5.69014810025692e-06
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00014018498768564314
mask_decoder.transformer.layers.0.norm3.bias grad: 1.3512759323930368e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 2.978045813506469e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2566920304379892e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.0445411034161225e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.019261955865659e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 8.517783135175705e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00014656517305411398
mask_decoder.transformer.layers.1.norm3.weight grad: 2.8519007173599675e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.344439341570251e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.121022746199742e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.91717175161466e-05
mask_decoder.transformer.norm_final_attn.weight grad: 6.832457074779086e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.381949555769097e-06
Text_Embedding_Affine.0.weight grad: -1.6915205347523e-11
Text_Embedding_Affine.0.bias grad: -6.330236335116979e-10
Text_Embedding_Affine.2.weight grad: 4.953635418525337e-11
Text_Embedding_Affine.2.bias grad: -1.1749289114959538e-06
Epoch 23 finished with average loss: -62.9233
Epoch 24/39
----------
Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.7]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-55.7]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-62.8]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-62.8]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-61.9]Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.23it/s, loss=-61.9]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.5893441443726115e-15
Max value: 0.9993742108345032
Mean value: 0.061968766152858734

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.5893441443726115e-15
Max value: 0.9993742108345032
Mean value: 0.061968766152858734

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06444787979125977

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.0955900177359581

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05403947830200195

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06444787979125977

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.76702117919922
Max value: 65.53984069824219
Mean value: 55.71635818481445

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.5893441443726115e-15
Max value: 0.9993742108345032
Mean value: 0.061968766152858734

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.5893441443726115e-15
Max value: 0.9993742108345032
Mean value: 0.061968766152858734

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.5893441443726115e-15
Max value: 0.9993742108345032
Mean value: 0.061968766152858734

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.0955900177359581

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.76702117919922
Max value: 65.53984069824219
Mean value: 55.71635818481445

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.71725082397461
Max value: -55.71725082397461
Mean value: -55.71725082397461
sam_encoder.pos_embed grad: -3.002861515000177e-09
sam_encoder.blocks.0.norm1.weight grad: -3.862418088829145e-05
sam_encoder.blocks.0.norm1.bias grad: -1.1531799373187823e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.368504167156061e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.4288379424651794e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.714256086415844e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.293673209256667e-07
sam_encoder.blocks.0.norm2.weight grad: -2.283171306771692e-05
sam_encoder.blocks.0.norm2.bias grad: 2.6408843041281216e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.921057426254265e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.4788415114708187e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.279820116906194e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.715103492955677e-06
sam_encoder.blocks.1.norm1.weight grad: -2.0721865894302027e-06
sam_encoder.blocks.1.norm1.bias grad: -2.121046463798848e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.2922308087581769e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.1727138321002712e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 9.55750419961987e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.4707585402647965e-06
sam_encoder.blocks.1.norm2.weight grad: 5.705492185370531e-06
sam_encoder.blocks.1.norm2.bias grad: -4.320549123804085e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3376203241932672e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.5375645691383397e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.245026725082425e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.4622877415604307e-06
sam_encoder.blocks.2.norm1.weight grad: -3.5661860238178633e-06
sam_encoder.blocks.2.norm1.bias grad: -3.008739440701902e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.939009947222075e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.0783547824976267e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.836837999595446e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.2933924153912812e-07
sam_encoder.blocks.2.norm2.weight grad: 1.1742994274754892e-06
sam_encoder.blocks.2.norm2.bias grad: 2.0935503926011734e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.539440174587071e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.0983024739962275e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.814894964511041e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.0882093874897691e-06
sam_encoder.blocks.3.norm1.weight grad: -3.705315975821577e-06
sam_encoder.blocks.3.norm1.bias grad: -6.343045242829248e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.3691652586421696e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.975850024877218e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.127426114384434e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.551307359994098e-07
sam_encoder.blocks.3.norm2.weight grad: 9.628776751924306e-06
sam_encoder.blocks.3.norm2.bias grad: 8.671663636050653e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.6690654421108775e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.961687972761865e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.265904524596408e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.9692597561515868e-06
sam_encoder.blocks.4.norm1.weight grad: 5.832350211676385e-07
sam_encoder.blocks.4.norm1.bias grad: 3.4843765206460375e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.558060476891114e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.172799898085941e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.183230081864167e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.19961417921877e-07
sam_encoder.blocks.4.norm2.weight grad: -6.583862614206737e-06
sam_encoder.blocks.4.norm2.bias grad: -7.91289858170785e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.1280034161463846e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.1599968274822459e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.354605157961487e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.27749614068307e-07
sam_encoder.blocks.5.norm1.weight grad: 7.792197607159324e-07
sam_encoder.blocks.5.norm1.bias grad: 1.4539143649017205e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.279717364217504e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.257985670439666e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.3772909116814844e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.333728717640042e-07
sam_encoder.blocks.5.norm2.weight grad: 9.645218597142957e-06
sam_encoder.blocks.5.norm2.bias grad: -5.848265573149547e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.805070941278245e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.17762772081187e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4391696367965778e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.04707305329066e-07
sam_encoder.blocks.6.norm1.weight grad: 4.431459274201188e-06
sam_encoder.blocks.6.norm1.bias grad: 5.31646037416067e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.39636926582898e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.610807071818272e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9471124232950388e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.8094574443239253e-06
sam_encoder.blocks.6.norm2.weight grad: 4.805335720448056e-06
sam_encoder.blocks.6.norm2.bias grad: 3.674196022984688e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.4135725854866905e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.6428069784524268e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.8234604794997722e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1409314311094931e-06
sam_encoder.blocks.7.norm1.weight grad: 3.2488751458004117e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4411446045414777e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.789824404520914e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.2518837593233911e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.354808430027333e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1389297327468739e-07
sam_encoder.blocks.7.norm2.weight grad: 6.91044397171936e-06
sam_encoder.blocks.7.norm2.bias grad: 2.9068831963741104e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.480183633859269e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.52691768562363e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4164164667818113e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.3763071819994366e-06
sam_encoder.blocks.8.norm1.weight grad: -4.402884769660886e-06
sam_encoder.blocks.8.norm1.bias grad: -1.935105956363259e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.0840526455431245e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.808837962220423e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.205345701142505e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.735848963515309e-07
sam_encoder.blocks.8.norm2.weight grad: 5.485753263201332e-06
sam_encoder.blocks.8.norm2.bias grad: -6.649345323239686e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.152578069100855e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.4250947464897763e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.873735168890562e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.7892368475713738e-07
sam_encoder.blocks.9.norm1.weight grad: 7.616278594468895e-07
sam_encoder.blocks.9.norm1.bias grad: 4.7048877149791224e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.512098474966479e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1448113355072564e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.010703934109188e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.32929237301505e-08
sam_encoder.blocks.9.norm2.weight grad: 6.331571967166383e-06
sam_encoder.blocks.9.norm2.bias grad: -2.788769961625803e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.254143616184592e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.230497895856388e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.388776109313767e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.7148902298202984e-09
sam_encoder.blocks.10.norm1.weight grad: 5.2323134696052875e-06
sam_encoder.blocks.10.norm1.bias grad: 6.789811095586629e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.5683319765666965e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2558848538901657e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5522526837230544e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.572388547785522e-07
sam_encoder.blocks.10.norm2.weight grad: 5.9763856370409485e-06
sam_encoder.blocks.10.norm2.bias grad: -1.974012775463052e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.883237124886364e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.3193188124205335e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.1844259612844326e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.0433921221751916e-08
sam_encoder.blocks.11.norm1.weight grad: 1.739733124850318e-05
sam_encoder.blocks.11.norm1.bias grad: 1.374781277263537e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.957988610636676e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.007775836114888e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.6646953301678877e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.1713053709172527e-06
sam_encoder.blocks.11.norm2.weight grad: 3.6415801787370583e-06
sam_encoder.blocks.11.norm2.bias grad: -2.079957994283177e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.893629466096172e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.7139855041677947e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.16904992259515e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.138489076576661e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.6985982256301213e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.5910311049083248e-05
sam_encoder.neck.conv2.trainable_scale grad: 9.483678695687559e-07
sam_encoder.neck.conv2.trainable_shift grad: 7.772689059493132e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -4.401944897836074e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -6.632617441937327e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004896108992397785
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005711440462619066
mask_decoder.transformer.layers.0.norm3.weight grad: 3.660735092125833e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.938829129561782e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001300348376389593
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1689882740029134e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.2648396629374474e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.7340221297199605e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.3117100024828687e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.325363549171016e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.4903835108270869e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.4601409677416086e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.138266614172608e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001823526108637452
mask_decoder.transformer.norm_final_attn.weight grad: 6.872172093608242e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.4936658772057854e-05
Text_Embedding_Affine.0.weight grad: 3.320505112189287e-12
Text_Embedding_Affine.0.bias grad: 1.436085972361667e-11
Text_Embedding_Affine.2.weight grad: 2.71478325930552e-11
Text_Embedding_Affine.2.bias grad: 2.5904928406816907e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.473820959899916e-14
Max value: 0.9998934268951416
Mean value: 0.10301411896944046

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.473820959899916e-14
Max value: 0.9998934268951416
Mean value: 0.10301411896944046

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09674978256225586

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1265212595462799

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09437274932861328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09674978256225586

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.69511413574219
Max value: 90.7645492553711
Mean value: 69.89883422851562

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.443383579975352e-13
Max value: 0.9998869895935059
Mean value: 0.10368931293487549

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.443383579975352e-13
Max value: 0.9998869895935059
Mean value: 0.10368931293487549

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.443383579975352e-13
Max value: 0.9998869895935059
Mean value: 0.10368931293487549

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12671826779842377

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9685112833976746
Max value: 1.4655237197875977
Mean value: 0.9998204708099365

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.69511413574219
Max value: 90.7645492553711
Mean value: 69.89883422851562

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.89598083496094
Max value: -69.89598083496094
Mean value: -69.89598083496094
sam_encoder.pos_embed grad: -1.1915751052526957e-08
sam_encoder.blocks.0.norm1.weight grad: 2.7368030714569613e-05
sam_encoder.blocks.0.norm1.bias grad: -3.784265572903678e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.033524080819916e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.026170593831921e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.116606073192088e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.658728696289472e-06
sam_encoder.blocks.0.norm2.weight grad: -5.332546425051987e-05
sam_encoder.blocks.0.norm2.bias grad: 0.00010246573947370052
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.5930659830919467e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.279382559005171e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.663922481995542e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.765788046119269e-06
sam_encoder.blocks.1.norm1.weight grad: 1.8057120541925542e-05
sam_encoder.blocks.1.norm1.bias grad: 3.0412680644076318e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.747086445102468e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.998839813197264e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.9302406144561246e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.205329169806646e-07
sam_encoder.blocks.1.norm2.weight grad: 4.192544656689279e-05
sam_encoder.blocks.1.norm2.bias grad: 4.904012712358963e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.3358194084721617e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.087368092266843e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.0363067985963426e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.90390834279242e-07
sam_encoder.blocks.2.norm1.weight grad: -1.1145452845084947e-05
sam_encoder.blocks.2.norm1.bias grad: -1.3073135050944984e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0757848031062167e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.4771746918995632e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2763912309310399e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.676311724935658e-06
sam_encoder.blocks.2.norm2.weight grad: -2.0818333723582327e-05
sam_encoder.blocks.2.norm2.bias grad: 1.0336410014133435e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.3171388673072215e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.006769813713618e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.624325811164454e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.790972750219225e-07
sam_encoder.blocks.3.norm1.weight grad: 2.2674710635328665e-05
sam_encoder.blocks.3.norm1.bias grad: -2.834988117683679e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.5201865355484188e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.536884029628709e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.685032298672013e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.212895980046596e-06
sam_encoder.blocks.3.norm2.weight grad: -5.3643607316189446e-06
sam_encoder.blocks.3.norm2.bias grad: 4.189652372588171e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.610839485190809e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.4290612802578835e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.200373824569397e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.5657968762970995e-06
sam_encoder.blocks.4.norm1.weight grad: 1.9132303350488655e-05
sam_encoder.blocks.4.norm1.bias grad: -7.136585736589041e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.723092388303485e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.378122740599792e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.4384854643576546e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.760480351251317e-06
sam_encoder.blocks.4.norm2.weight grad: -4.674807860283181e-05
sam_encoder.blocks.4.norm2.bias grad: -2.41950256167911e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.716738345043268e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3075474271317944e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 8.218258699344005e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.434656943885784e-07
sam_encoder.blocks.5.norm1.weight grad: 3.877034760080278e-05
sam_encoder.blocks.5.norm1.bias grad: 3.301220885987277e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.92796812573215e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.1339710908941925e-05
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.782392226043157e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.7598368887993274e-06
sam_encoder.blocks.5.norm2.weight grad: -5.901545137021458e-06
sam_encoder.blocks.5.norm2.bias grad: -7.695038220845163e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.464441634714603e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.7055713164590998e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.744590391212114e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.029654635611223e-06
sam_encoder.blocks.6.norm1.weight grad: 1.6025702279875986e-05
sam_encoder.blocks.6.norm1.bias grad: 1.4909483070368879e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2937896826770157e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.568977940129116e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.605127626040485e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.0627644415944815e-06
sam_encoder.blocks.6.norm2.weight grad: 7.296337571460754e-06
sam_encoder.blocks.6.norm2.bias grad: 1.7657961279837764e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.7861686905671377e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.640622485865606e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.134374525070598e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.152103418979095e-07
sam_encoder.blocks.7.norm1.weight grad: 1.8209311747341417e-05
sam_encoder.blocks.7.norm1.bias grad: 2.4763180590525735e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.5258437997545116e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.1999586503370665e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.861714609840419e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.1560122048831545e-06
sam_encoder.blocks.7.norm2.weight grad: -2.358042365813162e-06
sam_encoder.blocks.7.norm2.bias grad: -2.970803279822576e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.956521140935365e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1833197959276731e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.134708554673125e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.960649680971983e-06
sam_encoder.blocks.8.norm1.weight grad: 2.1526269847527146e-05
sam_encoder.blocks.8.norm1.bias grad: 1.2484573517212993e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.4626944650663063e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.451999070122838e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.940277439251076e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.260426850232761e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0521025615162216e-05
sam_encoder.blocks.8.norm2.bias grad: 2.425723096166621e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.0036039384431206e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.523212843807414e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.410509973240551e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0534692762576015e-07
sam_encoder.blocks.9.norm1.weight grad: 1.3519465937861241e-05
sam_encoder.blocks.9.norm1.bias grad: 4.7199654318319517e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.388950022374047e-05
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.281217338255374e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.10224856750574e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.7691544346453156e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4091656339587644e-05
sam_encoder.blocks.9.norm2.bias grad: 2.6449415599927306e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0023035429185256e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.6537968450575136e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.7045204003807157e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.858340337752452e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4714543794980273e-05
sam_encoder.blocks.10.norm1.bias grad: 6.453180390053603e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1370396350685041e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.844873390335124e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.1576100809616037e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.82597045750299e-06
sam_encoder.blocks.10.norm2.weight grad: 2.024407331191469e-05
sam_encoder.blocks.10.norm2.bias grad: 3.5708005725609837e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.21195462270407e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.253009476291481e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.556191121693701e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.5752129911561497e-07
sam_encoder.blocks.11.norm1.weight grad: 3.5374083381611854e-05
sam_encoder.blocks.11.norm1.bias grad: 7.987581511770259e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.921988410293125e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.1526330985798268e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.530469141172944e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.17054001345241e-07
sam_encoder.blocks.11.norm2.weight grad: 2.3826651158742607e-05
sam_encoder.blocks.11.norm2.bias grad: 1.7879495999295614e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4493641174340155e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.514958502317313e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.901790321009685e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.4354482042763266e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.527219632815104e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.7791644242824987e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.6615110730053857e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.3160438356862869e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001165691064670682
mask_decoder.transformer.layers.0.norm1.bias grad: -7.70611222833395e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002983440412208438
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005315414164215326
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00013370029046200216
mask_decoder.transformer.layers.0.norm3.bias grad: -1.44107652886305e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001835190923884511
mask_decoder.transformer.layers.0.norm4.bias grad: 1.865194644778967e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 5.335290916264057e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.872252121567726e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0003155924496240914
mask_decoder.transformer.layers.1.norm2.bias grad: 5.088746547698975e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.0128805519780144e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.936452074209228e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00011162657756358385
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00021031101641710848
mask_decoder.transformer.norm_final_attn.weight grad: 1.1700727554853074e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.6077314285212196e-05
Text_Embedding_Affine.0.weight grad: 5.384686446729958e-11
Text_Embedding_Affine.0.bias grad: 1.1502396812801408e-09
Text_Embedding_Affine.2.weight grad: -5.987037948740337e-11
Text_Embedding_Affine.2.bias grad: -1.772824180079624e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.0760233729897344e-13
Max value: 0.9989315867424011
Mean value: 0.08834215253591537

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.0760233729897344e-13
Max value: 0.9989315867424011
Mean value: 0.08834215253591537

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09573650360107422

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14001725614070892

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0823202133178711

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09573650360107422

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.02044677734375
Max value: 72.82857513427734
Mean value: 59.88277053833008

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.694321525406056e-13
Max value: 0.9988299012184143
Mean value: 0.08931326866149902

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.694321525406056e-13
Max value: 0.9988299012184143
Mean value: 0.08931326866149902

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.694321525406056e-13
Max value: 0.9988299012184143
Mean value: 0.08931326866149902

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1390349268913269

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.933831512928009
Max value: 2.2095322608947754
Mean value: 1.001160979270935

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.02044677734375
Max value: 72.82857513427734
Mean value: 59.88277053833008

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.93719482421875
Max value: -59.93719482421875
Mean value: -59.93719482421875
sam_encoder.pos_embed grad: 6.789443451893362e-10
sam_encoder.blocks.0.norm1.weight grad: -6.478832801803946e-05
sam_encoder.blocks.0.norm1.bias grad: -2.2834354240330867e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.900845957919955e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.525556616703398e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.5192408682196401e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.1806076701032e-06
sam_encoder.blocks.0.norm2.weight grad: 9.913297617458738e-06
sam_encoder.blocks.0.norm2.bias grad: -7.923772500362247e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.052905958611518e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.152592358266702e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.3838034647051245e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.4712428461934905e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1345702660037205e-05
sam_encoder.blocks.1.norm1.bias grad: 2.0742189008160494e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.742021469108295e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.394309603914735e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.8915010160708334e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.3820087992353365e-06
sam_encoder.blocks.1.norm2.weight grad: -1.1874928532051854e-05
sam_encoder.blocks.1.norm2.bias grad: -3.703790298459353e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.3473264668136835e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.3506074121069105e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.3369488189928234e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.048817807713931e-06
sam_encoder.blocks.2.norm1.weight grad: -1.7787213437259197e-05
sam_encoder.blocks.2.norm1.bias grad: 1.6666272131260484e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1214465303055476e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.8075745578680653e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7037791621987708e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.296171032867278e-06
sam_encoder.blocks.2.norm2.weight grad: 1.6898160538403317e-05
sam_encoder.blocks.2.norm2.bias grad: -9.286991371482145e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.5670019466779195e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.126919636997627e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1664767953334376e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.35772266832646e-07
sam_encoder.blocks.3.norm1.weight grad: -1.4725165783602279e-05
sam_encoder.blocks.3.norm1.bias grad: 1.2250926374690607e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.29985981201753e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.673411583804409e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.141566245787544e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.22612560619018e-06
sam_encoder.blocks.3.norm2.weight grad: -1.996335049625486e-05
sam_encoder.blocks.3.norm2.bias grad: 9.498579856881406e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.558005351398606e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.443236437306041e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.47468436404597e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.760809936968144e-06
sam_encoder.blocks.4.norm1.weight grad: -1.0850611943169497e-05
sam_encoder.blocks.4.norm1.bias grad: -3.039750254174578e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.266963621077593e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.7276789751340402e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.800709120900137e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.241490154934581e-06
sam_encoder.blocks.4.norm2.weight grad: 1.3645889339386486e-05
sam_encoder.blocks.4.norm2.bias grad: 2.305802445334848e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.979625944339205e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.8326870708260685e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.1962489427096443e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.9271557622223554e-08
sam_encoder.blocks.5.norm1.weight grad: -3.5225536976213334e-06
sam_encoder.blocks.5.norm1.bias grad: -2.9416323741315864e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4066392850509146e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.670341589488089e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.2772648005920928e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.3243914054328343e-06
sam_encoder.blocks.5.norm2.weight grad: -7.588705102534732e-06
sam_encoder.blocks.5.norm2.bias grad: 7.717366315773688e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0046471288660541e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.190247298334725e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.752933702751761e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.832602477719774e-08
sam_encoder.blocks.6.norm1.weight grad: -5.483255790750263e-06
sam_encoder.blocks.6.norm1.bias grad: -4.334831828600727e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.7460488379583694e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.607671707570262e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.792642241431167e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.842251648071397e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1693357464537257e-06
sam_encoder.blocks.6.norm2.bias grad: 7.597347121190978e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.034290885916562e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.7191199453445734e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.987578219901479e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.152895710125449e-07
sam_encoder.blocks.7.norm1.weight grad: 9.987972759972763e-08
sam_encoder.blocks.7.norm1.bias grad: 6.9885862785668e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.3401397609413834e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.017250365810469e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.2539747988048475e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.141703357163351e-06
sam_encoder.blocks.7.norm2.weight grad: 5.334899014997063e-06
sam_encoder.blocks.7.norm2.bias grad: 1.278354261557979e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9649612568173325e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.105728402872046e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.048009476624429e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.797765195187822e-07
sam_encoder.blocks.8.norm1.weight grad: 1.1662122005873243e-06
sam_encoder.blocks.8.norm1.bias grad: 4.5194788071967196e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.545533442978922e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.410566015802033e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.270002252975246e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.403402272146195e-06
sam_encoder.blocks.8.norm2.weight grad: 8.245708613685565e-07
sam_encoder.blocks.8.norm2.bias grad: 4.2923907983549725e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.423928541858913e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.926860234874766e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.558610034015146e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.3148089073620213e-07
sam_encoder.blocks.9.norm1.weight grad: 5.235712592366326e-07
sam_encoder.blocks.9.norm1.bias grad: 5.101330771140056e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.912595035326376e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.837404953330406e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.346798171653063e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.178101570076251e-06
sam_encoder.blocks.9.norm2.weight grad: -2.7465400762594072e-06
sam_encoder.blocks.9.norm2.bias grad: -9.895074981614016e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.675470912232413e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.0228254723188002e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.574364649874042e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.769651352238725e-07
sam_encoder.blocks.10.norm1.weight grad: -1.6613402067378047e-06
sam_encoder.blocks.10.norm1.bias grad: 3.6485639043348783e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.063487954728771e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.011329449189361e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3849480637873057e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.792687147732067e-07
sam_encoder.blocks.10.norm2.weight grad: -9.0610983534134e-06
sam_encoder.blocks.10.norm2.bias grad: -4.876720595348161e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.7127171051688492e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.71337921731174e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.2814553801708826e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.151090138293512e-08
sam_encoder.blocks.11.norm1.weight grad: -1.7274818674195558e-05
sam_encoder.blocks.11.norm1.bias grad: 9.794189281819854e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.9192300391732715e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.2080553208070341e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1314523362671025e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.1980940800858662e-07
sam_encoder.blocks.11.norm2.weight grad: -5.017995135858655e-06
sam_encoder.blocks.11.norm2.bias grad: -2.2633887510892237e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.401130008271139e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.404517206538003e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.098523013837621e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.4965108618980594e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.7058634916320443e-07
sam_encoder.neck.conv1.trainable_shift grad: 9.330391549156047e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.528703230898827e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.5593970601912588e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.0902166296727955e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.8676946638152003e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004571824800223112
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006919639417901635
mask_decoder.transformer.layers.0.norm3.weight grad: 1.951441663550213e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 8.547453035134822e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00014010435552336276
mask_decoder.transformer.layers.0.norm4.bias grad: 2.8223967092344537e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -7.591079793201061e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.6350639927841257e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00030361564131453633
mask_decoder.transformer.layers.1.norm2.bias grad: 6.831633800175041e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.2611758393177297e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.6715004423749633e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.9226194126531482e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00011302558414172381
mask_decoder.transformer.norm_final_attn.weight grad: 7.35897174308775e-07
mask_decoder.transformer.norm_final_attn.bias grad: -2.518962219255627e-06
Text_Embedding_Affine.0.weight grad: 1.8744517656793525e-12
Text_Embedding_Affine.0.bias grad: -8.134323770114804e-11
Text_Embedding_Affine.2.weight grad: 2.363319956399934e-11
Text_Embedding_Affine.2.bias grad: -1.9940656784456223e-05
Epoch 24 finished with average loss: -61.8501
Epoch 25/39
----------
Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.7]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-60.7]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-62]  Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-62]Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-56.9]Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-56.9]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.2771428421044776e-15
Max value: 0.9977512955665588
Mean value: 0.07660973072052002

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.2771428421044776e-15
Max value: 0.9977512955665588
Mean value: 0.07660973072052002

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08138132095336914

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11286611109972

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07166814804077148

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08138132095336914

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.3028678894043
Max value: 79.3191909790039
Mean value: 60.70790481567383

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.2771428421044776e-15
Max value: 0.9977512955665588
Mean value: 0.07660973072052002

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.2771428421044776e-15
Max value: 0.9977512955665588
Mean value: 0.07660973072052002

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.2771428421044776e-15
Max value: 0.9977512955665588
Mean value: 0.07660973072052002

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11286611109972

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.3028678894043
Max value: 79.3191909790039
Mean value: 60.70790481567383

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.70884704589844
Max value: -60.70884704589844
Mean value: -60.70884704589844
sam_encoder.pos_embed grad: -4.4149559008666017e-10
sam_encoder.blocks.0.norm1.weight grad: 5.988574230286758e-06
sam_encoder.blocks.0.norm1.bias grad: 8.282580893137492e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.836358817148721e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.7150836129076197e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.6637186490697786e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.531634315047995e-07
sam_encoder.blocks.0.norm2.weight grad: -3.0507449992001057e-05
sam_encoder.blocks.0.norm2.bias grad: 1.2009225429210346e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.52068148762919e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.6780112446213025e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.615852726099547e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.6997123515902786e-06
sam_encoder.blocks.1.norm1.weight grad: -2.7123992367705796e-06
sam_encoder.blocks.1.norm1.bias grad: -6.649673650827026e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.068774731218582e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.74371118900308e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.75365152649465e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.730499889163184e-06
sam_encoder.blocks.1.norm2.weight grad: 7.0112755565787666e-06
sam_encoder.blocks.1.norm2.bias grad: 1.7185445813083788e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.109941073693335e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.313345804504934e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.6135401134961285e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.729488303681137e-07
sam_encoder.blocks.2.norm1.weight grad: 6.190180556586711e-06
sam_encoder.blocks.2.norm1.bias grad: -5.694645551557187e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.771459432755364e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.552082479378441e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.0342447467337479e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.083999318841961e-07
sam_encoder.blocks.2.norm2.weight grad: 4.220531536702765e-06
sam_encoder.blocks.2.norm2.bias grad: 4.14149184280177e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.173157776676817e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.404579729249235e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.485495653876569e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 7.183427328527614e-07
sam_encoder.blocks.3.norm1.weight grad: -3.2959559348455514e-07
sam_encoder.blocks.3.norm1.bias grad: -1.5221214653138304e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.32921775275463e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.183600026408385e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.1751467354770284e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.347782340933918e-07
sam_encoder.blocks.3.norm2.weight grad: 1.2640942259167787e-05
sam_encoder.blocks.3.norm2.bias grad: 8.770895874476992e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 9.646730177337304e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.1933172977005597e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.0158859115326777e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1375731219231966e-06
sam_encoder.blocks.4.norm1.weight grad: -1.1943209301534807e-06
sam_encoder.blocks.4.norm1.bias grad: 3.701066816574894e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.5659237533327541e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.751520231773611e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.5049106405484736e-09
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.0898536351742223e-07
sam_encoder.blocks.4.norm2.weight grad: -1.0031544661615044e-05
sam_encoder.blocks.4.norm2.bias grad: -6.389369445969351e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.266281732474454e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.002899236686062e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.066346607738524e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6505250616537523e-07
sam_encoder.blocks.5.norm1.weight grad: -2.906700046878541e-06
sam_encoder.blocks.5.norm1.bias grad: -2.26971451411373e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.166569397057174e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.9125463950331323e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.932067435627687e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.6188478184631094e-06
sam_encoder.blocks.5.norm2.weight grad: -3.3364901810273295e-06
sam_encoder.blocks.5.norm2.bias grad: -2.997749106725678e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.0289652624683185e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.861890256004699e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.873814643564401e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.6624572291875666e-07
sam_encoder.blocks.6.norm1.weight grad: 3.0311139198602177e-06
sam_encoder.blocks.6.norm1.bias grad: 1.3537727454604465e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.6134783815432456e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.356390827022551e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.1869728950841818e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.3305419770404114e-06
sam_encoder.blocks.6.norm2.weight grad: 3.542316733273765e-07
sam_encoder.blocks.6.norm2.bias grad: -8.664462143315177e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.5586700783387641e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.754426292194694e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.4916305935439595e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.5539197306679853e-07
sam_encoder.blocks.7.norm1.weight grad: 8.393179768972914e-07
sam_encoder.blocks.7.norm1.bias grad: 9.758271062310087e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.632562978367787e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.525999083351053e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.0482043535375851e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.831480282518896e-07
sam_encoder.blocks.7.norm2.weight grad: 9.032179377754801e-07
sam_encoder.blocks.7.norm2.bias grad: 3.520207769724948e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0748331078502815e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.896015977668867e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.443264161745901e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.09785603905766e-07
sam_encoder.blocks.8.norm1.weight grad: -5.1278675528010353e-08
sam_encoder.blocks.8.norm1.bias grad: -1.0381007768955897e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.3444581529474817e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.575111582496902e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.387478374061175e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.92374362895498e-07
sam_encoder.blocks.8.norm2.weight grad: -7.697561841268907e-07
sam_encoder.blocks.8.norm2.bias grad: -1.6583053366048262e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 8.804512390270247e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2631957702069485e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.954721468195203e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.9541291723944596e-07
sam_encoder.blocks.9.norm1.weight grad: -1.1033375812985469e-06
sam_encoder.blocks.9.norm1.bias grad: 4.551956749310193e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.213408609146427e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4963477212859289e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1344567951709905e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.6760594096231216e-07
sam_encoder.blocks.9.norm2.weight grad: 4.041609145133407e-07
sam_encoder.blocks.9.norm2.bias grad: -1.5492008742512553e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0580197340459563e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.743437097611604e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.5487656785116997e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.460494895080046e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4589061265724013e-06
sam_encoder.blocks.10.norm1.bias grad: 2.8064960133633576e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.390383072764962e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.244650142481987e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.661669769731816e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0822020612977212e-07
sam_encoder.blocks.10.norm2.weight grad: 9.424569498150959e-07
sam_encoder.blocks.10.norm2.bias grad: -1.8226244264951674e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.969762580411043e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.8088786646330846e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.7036247729483875e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.9483484215452336e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2436299584805965e-05
sam_encoder.blocks.11.norm1.bias grad: 5.49267667793174e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.852881013064689e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.60440708391252e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.1219021871511359e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.0517101972927776e-07
sam_encoder.blocks.11.norm2.weight grad: -1.6762230643507792e-06
sam_encoder.blocks.11.norm2.bias grad: -2.6359571165812667e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.100735289583099e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.6320647944212396e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.003948909783503e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.7665567497715529e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.657843864057213e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.3524648238671944e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.6638630263041705e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.4816526345384773e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -8.852728933561593e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -8.683455234859139e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004872382618486881
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00017301773186773062
mask_decoder.transformer.layers.0.norm3.weight grad: -3.5365887015359476e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.9842587537132204e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013843260239809752
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0259021109959576e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.562339745461941e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.693917511147447e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.08410152583383e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.558177119586617e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.454833469935693e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.67860084224958e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.945820521446876e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001820691250031814
mask_decoder.transformer.norm_final_attn.weight grad: 4.477741640585009e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4474429008259904e-05
Text_Embedding_Affine.0.weight grad: 2.5542053281452093e-12
Text_Embedding_Affine.0.bias grad: -9.84707801410245e-12
Text_Embedding_Affine.2.weight grad: 5.961279386790252e-11
Text_Embedding_Affine.2.bias grad: 1.529665314592421e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6481562005476492e-14
Max value: 0.999850869178772
Mean value: 0.08578009903430939

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6481562005476492e-14
Max value: 0.999850869178772
Mean value: 0.08578009903430939

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0903620719909668

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11852458119392395

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07802629470825195

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0903620719909668

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.62159729003906
Max value: 84.27228546142578
Mean value: 63.356082916259766

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.0385589024447693e-14
Max value: 0.9998273849487305
Mean value: 0.0866367518901825

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.0385589024447693e-14
Max value: 0.9998273849487305
Mean value: 0.0866367518901825

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.0385589024447693e-14
Max value: 0.9998273849487305
Mean value: 0.0866367518901825

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11820701509714127

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9597368240356445
Max value: 1.8043707609176636
Mean value: 1.0003862380981445

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.62159729003906
Max value: 84.27228546142578
Mean value: 63.356082916259766

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.378353118896484
Max value: -63.378353118896484
Mean value: -63.378353118896484
sam_encoder.pos_embed grad: -3.3521425635285595e-09
sam_encoder.blocks.0.norm1.weight grad: 1.4962715795263648e-05
sam_encoder.blocks.0.norm1.bias grad: 1.2024996067339089e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1134211490571033e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.732852806275332e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.3001239267396159e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.375706445600372e-07
sam_encoder.blocks.0.norm2.weight grad: 1.1713649428202189e-06
sam_encoder.blocks.0.norm2.bias grad: 1.9536892068572342e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.319293455206207e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.825876890710788e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.267341738450341e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.622482381615555e-06
sam_encoder.blocks.1.norm1.weight grad: -5.5098098528105766e-08
sam_encoder.blocks.1.norm1.bias grad: 4.918045306112617e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.0608292743418133e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.5827756644503097e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.3161427432351047e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.445795732024635e-07
sam_encoder.blocks.1.norm2.weight grad: 1.8705108004724025e-06
sam_encoder.blocks.1.norm2.bias grad: -1.708821741885913e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.5926790385710774e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.0658779337500164e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.931741024918665e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.148224328062497e-06
sam_encoder.blocks.2.norm1.weight grad: 6.392135219357442e-06
sam_encoder.blocks.2.norm1.bias grad: -3.817293872998562e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.272827370892628e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.60982527986198e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.801904651685618e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.455564059455355e-07
sam_encoder.blocks.2.norm2.weight grad: -3.669948910101084e-06
sam_encoder.blocks.2.norm2.bias grad: -6.640962510573445e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.2947493814863265e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.432487238162139e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 7.904599215180497e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.756389829362888e-08
sam_encoder.blocks.3.norm1.weight grad: -1.063974423232139e-06
sam_encoder.blocks.3.norm1.bias grad: -3.299607442386332e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.247916755659389e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.3390593639760482e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.4945304011889675e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.0881294656428508e-06
sam_encoder.blocks.3.norm2.weight grad: 7.712561455264222e-06
sam_encoder.blocks.3.norm2.bias grad: 2.3809768663340947e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.340387244563317e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.1062343219236936e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.2878315374109661e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.989529192149348e-07
sam_encoder.blocks.4.norm1.weight grad: 4.130360139242839e-06
sam_encoder.blocks.4.norm1.bias grad: -8.054519184952369e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.2007431371994244e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3999917314322374e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4450863545789616e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8056206272376585e-06
sam_encoder.blocks.4.norm2.weight grad: -1.8161166735808365e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3179214874980971e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.2272896128706634e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.817093213205226e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.039848242129665e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.907661713739799e-07
sam_encoder.blocks.5.norm1.weight grad: 2.6218785933451727e-06
sam_encoder.blocks.5.norm1.bias grad: -4.7674802772235125e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.579551149523468e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 8.277945653389907e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.323110604469548e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.866824714459653e-07
sam_encoder.blocks.5.norm2.weight grad: -7.972244020493235e-06
sam_encoder.blocks.5.norm2.bias grad: -8.849068763083778e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.4934847715485375e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.901152679958614e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2178531960671535e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.752512493018003e-07
sam_encoder.blocks.6.norm1.weight grad: -1.4615579857490957e-09
sam_encoder.blocks.6.norm1.bias grad: 3.1411527743330225e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.4360898603626993e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.501235366660694e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.669816224937676e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.91929313284345e-07
sam_encoder.blocks.6.norm2.weight grad: -3.816540811385494e-06
sam_encoder.blocks.6.norm2.bias grad: -2.9435941542033106e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.4549426598241553e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.0268813639413565e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.47044261211704e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.341325166024035e-07
sam_encoder.blocks.7.norm1.weight grad: 2.7594664970820304e-06
sam_encoder.blocks.7.norm1.bias grad: 1.96634255189565e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.8169329223383102e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0307026059308555e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3784168686470366e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.8440862226707395e-07
sam_encoder.blocks.7.norm2.weight grad: 8.685323109602905e-07
sam_encoder.blocks.7.norm2.bias grad: 1.760187160471105e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.147800669012213e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.4935699255147483e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5000957773736445e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0339343816667679e-06
sam_encoder.blocks.8.norm1.weight grad: 4.722634002973791e-06
sam_encoder.blocks.8.norm1.bias grad: -1.6606990129730548e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.934824806288816e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.2932359823025763e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9027928576397244e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.6086455616459716e-06
sam_encoder.blocks.8.norm2.weight grad: -3.4966916473422316e-07
sam_encoder.blocks.8.norm2.bias grad: -9.763887192093534e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.877225023847132e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.058924443801516e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.97339032740274e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.092303278937834e-07
sam_encoder.blocks.9.norm1.weight grad: -7.83699420026096e-07
sam_encoder.blocks.9.norm1.bias grad: 6.870556035210029e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.4212071164365625e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.4740476217411924e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.309031342269009e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.1124553717963863e-07
sam_encoder.blocks.9.norm2.weight grad: 6.438737045755261e-07
sam_encoder.blocks.9.norm2.bias grad: -9.709119694889523e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.668172894322197e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.3775575047911843e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.4596322961988335e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.571014867200574e-07
sam_encoder.blocks.10.norm1.weight grad: 2.8640704385907156e-06
sam_encoder.blocks.10.norm1.bias grad: -1.5797893127000862e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.6585122466494795e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.143847480823752e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.048114995683136e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.601773634429264e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3667920484294882e-07
sam_encoder.blocks.10.norm2.bias grad: -1.3976512036606437e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 8.097963473119307e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1644134190191835e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.969641728777788e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.309103698891704e-07
sam_encoder.blocks.11.norm1.weight grad: 1.7784823285182938e-05
sam_encoder.blocks.11.norm1.bias grad: -6.675506369901996e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.5288669601432048e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.825744887668407e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.233390205219621e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.530457418804872e-07
sam_encoder.blocks.11.norm2.weight grad: 1.6325905107805738e-06
sam_encoder.blocks.11.norm2.bias grad: -2.382253342148033e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.286803803348448e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.9110339621875028e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.495848540704174e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.709406470875365e-08
sam_encoder.neck.conv1.trainable_scale grad: 2.306514943484217e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.9198547458217945e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.9370327208889648e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.2842470823670737e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.000111579560325481
mask_decoder.transformer.layers.0.norm1.bias grad: 1.4982197171775624e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00452267425134778
mask_decoder.transformer.layers.0.norm2.bias grad: -0.000205694988835603
mask_decoder.transformer.layers.0.norm3.weight grad: -4.6681387175340205e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.995873728650622e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011627969070104882
mask_decoder.transformer.layers.0.norm4.bias grad: -6.302861493168166e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.9155275115044788e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.89120962913148e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -2.9968003218527883e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.265897875186056e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.208621637895703e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.9462806196534075e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.226970435818657e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001873727305792272
mask_decoder.transformer.norm_final_attn.weight grad: 3.9338897295237985e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4778222976019606e-05
Text_Embedding_Affine.0.weight grad: -4.584122144379865e-12
Text_Embedding_Affine.0.bias grad: -9.563408398527429e-11
Text_Embedding_Affine.2.weight grad: -3.387047586844716e-15
Text_Embedding_Affine.2.bias grad: 1.5711648302385584e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.4520932119808112e-12
Max value: 0.9966453909873962
Mean value: 0.06723925471305847

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.4520932119808112e-12
Max value: 0.9966453909873962
Mean value: 0.06723925471305847

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07499217987060547

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13318103551864624

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.056878089904785156

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07499217987060547

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 30.798662185668945
Max value: 55.25224685668945
Mean value: 46.427978515625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7732822155114292e-11
Max value: 0.9955600500106812
Mean value: 0.07028502225875854

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7732822155114292e-11
Max value: 0.9955600500106812
Mean value: 0.07028502225875854

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7732822155114292e-11
Max value: 0.9955600500106812
Mean value: 0.07028502225875854

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13080310821533203

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9150015711784363
Max value: 2.7315897941589355
Mean value: 1.0032347440719604

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 30.798662185668945
Max value: 55.25224685668945
Mean value: 46.427978515625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -46.47979736328125
Max value: -46.47979736328125
Mean value: -46.47979736328125
sam_encoder.pos_embed grad: -6.073482827773091e-10
sam_encoder.blocks.0.norm1.weight grad: -1.2295468877709936e-05
sam_encoder.blocks.0.norm1.bias grad: 1.7841965018305928e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.5803644259904104e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.5263833574863384e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.0776477615290787e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.707451009584474e-07
sam_encoder.blocks.0.norm2.weight grad: 6.699015557387611e-06
sam_encoder.blocks.0.norm2.bias grad: 1.0058456609840505e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2154960131738335e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.592619404775178e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.211113138007931e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.179342340648873e-06
sam_encoder.blocks.1.norm1.weight grad: 2.6523925953370053e-06
sam_encoder.blocks.1.norm1.bias grad: -4.813029477190867e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.598982508876361e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.331424300587969e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.554749466478825e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.6041492472140817e-06
sam_encoder.blocks.1.norm2.weight grad: 1.5087151041370817e-05
sam_encoder.blocks.1.norm2.bias grad: 1.2488819720601896e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.148851520672906e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4590934824809665e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.0345472623594105e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.558530406484351e-07
sam_encoder.blocks.2.norm1.weight grad: 6.1180498960311525e-06
sam_encoder.blocks.2.norm1.bias grad: -1.507032720837742e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.823082690563751e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.052459179452853e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.186903872025141e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0813366770889843e-06
sam_encoder.blocks.2.norm2.weight grad: -4.917109436064493e-06
sam_encoder.blocks.2.norm2.bias grad: 1.7825857412390178e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.296307457072544e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.1890477910346817e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.6053585006357025e-08
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7159981098302524e-06
sam_encoder.blocks.3.norm1.weight grad: 2.699457127164351e-06
sam_encoder.blocks.3.norm1.bias grad: -6.417094027710846e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.964512648555683e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.337034849617339e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.657509281169041e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.4525683127430966e-06
sam_encoder.blocks.3.norm2.weight grad: 7.43484815757256e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0876767646550434e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.354489192337496e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.33573394123232e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.214045348926447e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.7483206344622886e-07
sam_encoder.blocks.4.norm1.weight grad: -2.3737850369798252e-06
sam_encoder.blocks.4.norm1.bias grad: 1.2022137525491416e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0063236004498322e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.261103529439424e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.1382570594141725e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.249657200081856e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5124649255303666e-05
sam_encoder.blocks.4.norm2.bias grad: -1.6882031559362076e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5602176063111983e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.134646355349105e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.237545555151883e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.1230486052227207e-06
sam_encoder.blocks.5.norm1.weight grad: -1.5350451576523483e-07
sam_encoder.blocks.5.norm1.bias grad: -6.283814400376286e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.3287620959090418e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5048966588437906e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.834223605281295e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.114880583638296e-08
sam_encoder.blocks.5.norm2.weight grad: -1.0593571460049134e-05
sam_encoder.blocks.5.norm2.bias grad: -1.2524707926786505e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.8747344913426787e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.171032621045015e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.480217856122181e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.028641905686527e-07
sam_encoder.blocks.6.norm1.weight grad: 2.0063980628037825e-06
sam_encoder.blocks.6.norm1.bias grad: 4.037651706312317e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.112117200198554e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.931374289502855e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.805300596264715e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.4725925956990977e-07
sam_encoder.blocks.6.norm2.weight grad: -4.540173904388212e-06
sam_encoder.blocks.6.norm2.bias grad: -1.9828380573017057e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.407659050935763e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.2076237680958002e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.242846772394842e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.557343112945091e-07
sam_encoder.blocks.7.norm1.weight grad: 4.048160917591304e-06
sam_encoder.blocks.7.norm1.bias grad: 1.946545324926774e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.307172053406248e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6840907619553036e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.1499960237415507e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.306127046518668e-06
sam_encoder.blocks.7.norm2.weight grad: 1.889491585416181e-07
sam_encoder.blocks.7.norm2.bias grad: 7.38939604616462e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0220599051535828e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.271054158763945e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6610295006103115e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.1923424381166114e-06
sam_encoder.blocks.8.norm1.weight grad: 3.616293724917341e-06
sam_encoder.blocks.8.norm1.bias grad: -1.6320498161803698e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.3435399068839615e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.5634866673840406e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.99406893242849e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 7.0626299475407e-07
sam_encoder.blocks.8.norm2.weight grad: -1.0972348718496505e-06
sam_encoder.blocks.8.norm2.bias grad: -5.444293265099986e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.158096882951213e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.112208446509612e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.402656597652822e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.040114612915204e-07
sam_encoder.blocks.9.norm1.weight grad: -1.477972773500369e-06
sam_encoder.blocks.9.norm1.bias grad: -5.533958642445214e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.78851892593957e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.261527581344126e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7270426155846508e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.843297791827354e-07
sam_encoder.blocks.9.norm2.weight grad: -5.724552352148748e-07
sam_encoder.blocks.9.norm2.bias grad: -1.4666582046629628e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.534863672413849e-08
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.2378097475648246e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.512374449765048e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.118052968100528e-07
sam_encoder.blocks.10.norm1.weight grad: 4.600119609676767e-06
sam_encoder.blocks.10.norm1.bias grad: 4.3774952018793556e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.344597189425258e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.1238471415708773e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7514855699118925e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.140697562135756e-07
sam_encoder.blocks.10.norm2.weight grad: -1.6324945590895368e-06
sam_encoder.blocks.10.norm2.bias grad: -2.254803575851838e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.033747356719687e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.1647296932769677e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.6330138186713157e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.566224447444256e-07
sam_encoder.blocks.11.norm1.weight grad: 1.420881653757533e-05
sam_encoder.blocks.11.norm1.bias grad: 1.3875796867068857e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.1526884665945545e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.736287782085128e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.5378471946169157e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.562888756889151e-07
sam_encoder.blocks.11.norm2.weight grad: -2.577779014245607e-06
sam_encoder.blocks.11.norm2.bias grad: -2.5688659661682323e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 8.983588486444205e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.6255317442955857e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.932538099135854e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.848424003332184e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.514965207315981e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.1272437152219936e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.512944436399266e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.3737941268773284e-08
mask_decoder.transformer.layers.0.norm1.weight grad: -7.24107667338103e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.386805474292487e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005414677783846855
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003207186236977577
mask_decoder.transformer.layers.0.norm3.weight grad: -3.959517925977707e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.1382008930668235e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00014361139619722962
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3131544619682245e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.319064489915036e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.517906745604705e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.826369695365429e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.0907038308214396e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.5084212615620345e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.889386840048246e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.3064891138346866e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.000194541149539873
mask_decoder.transformer.norm_final_attn.weight grad: 4.35327001468977e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.152905477094464e-06
Text_Embedding_Affine.0.weight grad: 1.0964785503164709e-11
Text_Embedding_Affine.0.bias grad: 4.424301203176384e-10
Text_Embedding_Affine.2.weight grad: 1.6586705620103004e-10
Text_Embedding_Affine.2.bias grad: 2.2433203412219882e-05
Epoch 25 finished with average loss: -56.8557
Epoch 26/39
----------
Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.5]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-55.5]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-58.2]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-58.2]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-61.5]Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-61.5]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8317630940713203e-13
Max value: 0.9984027743339539
Mean value: 0.0810377448797226

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8317630940713203e-13
Max value: 0.9984027743339539
Mean value: 0.0810377448797226

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08157110214233398

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12164916098117828

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07051467895507812

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08157110214233398

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.662601470947266
Max value: 76.87020874023438
Mean value: 55.458404541015625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8317630940713203e-13
Max value: 0.9984027743339539
Mean value: 0.0810377448797226

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8317630940713203e-13
Max value: 0.9984027743339539
Mean value: 0.0810377448797226

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8317630940713203e-13
Max value: 0.9984027743339539
Mean value: 0.0810377448797226

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12164916098117828

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.662601470947266
Max value: 76.87020874023438
Mean value: 55.458404541015625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.45954513549805
Max value: -55.45954513549805
Mean value: -55.45954513549805
sam_encoder.pos_embed grad: 1.5299489453113324e-09
sam_encoder.blocks.0.norm1.weight grad: -1.0897978199864156e-06
sam_encoder.blocks.0.norm1.bias grad: 4.592999175656587e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.3375486054865178e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.780923745784094e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.4723090064071584e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.25893631472718e-08
sam_encoder.blocks.0.norm2.weight grad: -8.808177517494187e-05
sam_encoder.blocks.0.norm2.bias grad: 5.79333118366776e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2828076251025777e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.3790080275794026e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.4052076191292144e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.611243417049991e-06
sam_encoder.blocks.1.norm1.weight grad: -5.01716658618534e-06
sam_encoder.blocks.1.norm1.bias grad: -5.349785169528332e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.139259080053307e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.4919691011527902e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.404635991610121e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.256045940564945e-06
sam_encoder.blocks.1.norm2.weight grad: -2.3517952286056243e-05
sam_encoder.blocks.1.norm2.bias grad: 4.1029551312021795e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.83643782697618e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.358179120979912e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.1870619118781178e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.734315659035929e-07
sam_encoder.blocks.2.norm1.weight grad: 1.0055257007479668e-05
sam_encoder.blocks.2.norm1.bias grad: 4.394348252390046e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.414657269080635e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.497947768162703e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.811931830772664e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0242905545965186e-06
sam_encoder.blocks.2.norm2.weight grad: 1.3018321624258533e-05
sam_encoder.blocks.2.norm2.bias grad: -9.927669452736154e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.542105206288397e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.2432432185960351e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 7.255697482833057e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4061053832392645e-07
sam_encoder.blocks.3.norm1.weight grad: 9.20624916034285e-06
sam_encoder.blocks.3.norm1.bias grad: 7.1721333370078355e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0142056083850548e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.373352802147565e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.780893156450475e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.511506119797559e-07
sam_encoder.blocks.3.norm2.weight grad: -1.0402269253972918e-05
sam_encoder.blocks.3.norm2.bias grad: -7.554162039014045e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.111737856263062e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.920794253848726e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.94351614988409e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.43428131499968e-07
sam_encoder.blocks.4.norm1.weight grad: -4.727725354314316e-06
sam_encoder.blocks.4.norm1.bias grad: 4.67763402411947e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.701637413338176e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.8346248654997908e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.7237456379225478e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.5332038805790944e-06
sam_encoder.blocks.4.norm2.weight grad: -1.5625075775460573e-06
sam_encoder.blocks.4.norm2.bias grad: 1.0409888773210696e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.5104469639481977e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.3429456657831906e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.6193184769217623e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.308203748834785e-07
sam_encoder.blocks.5.norm1.weight grad: 2.5595898023311747e-06
sam_encoder.blocks.5.norm1.bias grad: -4.290336164558539e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.5880824472988024e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.594407078504446e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.2792951338269631e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.573577699484304e-07
sam_encoder.blocks.5.norm2.weight grad: 1.5343503037001938e-06
sam_encoder.blocks.5.norm2.bias grad: 6.083156222302932e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.2491740335462964e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.048004719450546e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.625798970257165e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.908403970053769e-07
sam_encoder.blocks.6.norm1.weight grad: -2.030650421147584e-06
sam_encoder.blocks.6.norm1.bias grad: -7.253844160004519e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.218105808220571e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.083534564524598e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0821329397003865e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.484403782114896e-07
sam_encoder.blocks.6.norm2.weight grad: 4.616361366061028e-06
sam_encoder.blocks.6.norm2.bias grad: 1.6378829741370282e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.0788825167983305e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.6702628613529669e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.285999577608891e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.8855879488910432e-06
sam_encoder.blocks.7.norm1.weight grad: 1.3304847001904818e-08
sam_encoder.blocks.7.norm1.bias grad: -3.6892623711537453e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.309250819758745e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.7305668481858447e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.2409017219615635e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.931904989760369e-06
sam_encoder.blocks.7.norm2.weight grad: -6.234694410522934e-06
sam_encoder.blocks.7.norm2.bias grad: -2.6008564191215555e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.598018105956726e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.9784036996716168e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.2752100246871123e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.833454441832146e-07
sam_encoder.blocks.8.norm1.weight grad: 1.5647381133021554e-06
sam_encoder.blocks.8.norm1.bias grad: 3.0819427365713636e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.4095645534980576e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.1054818211705424e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.928880803665379e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.347352048876928e-06
sam_encoder.blocks.8.norm2.weight grad: -6.237088200578e-06
sam_encoder.blocks.8.norm2.bias grad: 1.28652800412965e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.524307875428349e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.727576768142171e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.93361254586489e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.1877864380949177e-07
sam_encoder.blocks.9.norm1.weight grad: 4.4805515244661365e-06
sam_encoder.blocks.9.norm1.bias grad: -1.5025625543785281e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.045932317036204e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.530407171747356e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.6262008273315587e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.8483699193438952e-07
sam_encoder.blocks.9.norm2.weight grad: -1.7265114138353965e-06
sam_encoder.blocks.9.norm2.bias grad: 1.5988614450179739e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.02021669287933e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.3124381439411081e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.389856821442663e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.079673996988276e-07
sam_encoder.blocks.10.norm1.weight grad: -3.7145905480429064e-06
sam_encoder.blocks.10.norm1.bias grad: 3.00821511700633e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.315999492770061e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2734021765936632e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.5148589227464981e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.751307743499638e-07
sam_encoder.blocks.10.norm2.weight grad: -4.423169684741879e-06
sam_encoder.blocks.10.norm2.bias grad: 4.0557250713391113e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.041152695004712e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.4231370641937247e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.9433604115401977e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.126719588271044e-08
sam_encoder.blocks.11.norm1.weight grad: -2.0237062017258722e-06
sam_encoder.blocks.11.norm1.bias grad: 3.951194685214432e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.618456958065508e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.2561827961453673e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.5491552574076195e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.7683000780598377e-07
sam_encoder.blocks.11.norm2.weight grad: -1.4043794180906843e-06
sam_encoder.blocks.11.norm2.bias grad: 1.979347416636301e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.112294280072092e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.9558938408058566e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.3089872936689062e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.2417349043735157e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.04555532138329e-07
sam_encoder.neck.conv1.trainable_shift grad: 6.093255251471419e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.92806235444732e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.2547650840133429e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00019849790260195732
mask_decoder.transformer.layers.0.norm1.bias grad: 1.7335842130705714e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0013245781883597374
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0007667496101930737
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00024547838256694376
mask_decoder.transformer.layers.0.norm3.bias grad: -8.300224726554006e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -7.008048123680055e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.5160697987303138e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.565539009287022e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.3905519153922796e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.721941801719368e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -6.536251021316275e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.217462942004204e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.719974094768986e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.1058836611919105e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 8.348459232365713e-05
mask_decoder.transformer.norm_final_attn.weight grad: -5.281579433358274e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3129518265486695e-05
Text_Embedding_Affine.0.weight grad: -1.3739009929736312e-13
Text_Embedding_Affine.0.bias grad: -1.7709972377488725e-11
Text_Embedding_Affine.2.weight grad: -9.571243797523721e-11
Text_Embedding_Affine.2.bias grad: -2.3304237402044237e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.31242853336621e-16
Max value: 0.9995115995407104
Mean value: 0.09351766854524612

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.31242853336621e-16
Max value: 0.9995115995407104
Mean value: 0.09351766854524612

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08719444274902344

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11789561808109283

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08745718002319336

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08719444274902344

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.269752502441406
Max value: 74.52483367919922
Mean value: 60.974456787109375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.409393491546068e-16
Max value: 0.9993981122970581
Mean value: 0.0946769192814827

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.409393491546068e-16
Max value: 0.9993981122970581
Mean value: 0.0946769192814827

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.409393491546068e-16
Max value: 0.9993981122970581
Mean value: 0.0946769192814827

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1179603785276413

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9643396139144897
Max value: 1.7192189693450928
Mean value: 0.9999865293502808

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.269752502441406
Max value: 74.52483367919922
Mean value: 60.974456787109375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.97245407104492
Max value: -60.97245407104492
Mean value: -60.97245407104492
sam_encoder.pos_embed grad: 5.977470518558903e-09
sam_encoder.blocks.0.norm1.weight grad: 6.730036693625152e-05
sam_encoder.blocks.0.norm1.bias grad: 3.1292693165596575e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.482491360453423e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3237465736892773e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.75902231503278e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.594545946976723e-07
sam_encoder.blocks.0.norm2.weight grad: 3.2204123272094876e-05
sam_encoder.blocks.0.norm2.bias grad: -4.364159394754097e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.349916576349642e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.262274266395252e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.3575397790409625e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.2177348253317177e-05
sam_encoder.blocks.1.norm1.weight grad: 3.365537850186229e-05
sam_encoder.blocks.1.norm1.bias grad: 1.363221508654533e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.371544259309303e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.26054737342929e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.2827871614717878e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.428908480098471e-06
sam_encoder.blocks.1.norm2.weight grad: 2.2051242467568954e-06
sam_encoder.blocks.1.norm2.bias grad: -3.124664999631932e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.2579424037539866e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.904644588852534e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.406128962524235e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.974480361852329e-06
sam_encoder.blocks.2.norm1.weight grad: -1.604696808499284e-05
sam_encoder.blocks.2.norm1.bias grad: 6.014315204083687e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.272167355637066e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.6183623706165235e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2532203072623815e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.794149728899356e-06
sam_encoder.blocks.2.norm2.weight grad: -3.1346731702797115e-05
sam_encoder.blocks.2.norm2.bias grad: 5.348944796423893e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.421236058580689e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.068659331504023e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.0039875380462036e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.453422545542708e-06
sam_encoder.blocks.3.norm1.weight grad: -2.170881452911999e-05
sam_encoder.blocks.3.norm1.bias grad: -1.7606550954951672e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.851699926191941e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.125301984458929e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.1584872481762432e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.883177204348613e-06
sam_encoder.blocks.3.norm2.weight grad: -1.885094025055878e-05
sam_encoder.blocks.3.norm2.bias grad: 1.3157031162336352e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.061659744067583e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.485388664463244e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.769169663632056e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.7053674810085795e-06
sam_encoder.blocks.4.norm1.weight grad: -3.1365768791147275e-06
sam_encoder.blocks.4.norm1.bias grad: -5.677272838511271e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.2805464798002504e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.557870973556419e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.2349022426860756e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -9.494169717072509e-07
sam_encoder.blocks.4.norm2.weight grad: -2.428006519039627e-05
sam_encoder.blocks.4.norm2.bias grad: -1.9079188859905116e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8012728105532005e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.9500390559842344e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.979668225743808e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.8768570246029412e-06
sam_encoder.blocks.5.norm1.weight grad: -1.6425059584435076e-05
sam_encoder.blocks.5.norm1.bias grad: -1.7130078049376607e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5433148291776888e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.070575182093307e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.252827693562722e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.631068688671803e-06
sam_encoder.blocks.5.norm2.weight grad: -1.9115368559141643e-05
sam_encoder.blocks.5.norm2.bias grad: -9.70598375715781e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0233443390461616e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.007832103525288e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.5635341696906835e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.5021178114693612e-06
sam_encoder.blocks.6.norm1.weight grad: -3.355335593369091e-06
sam_encoder.blocks.6.norm1.bias grad: -7.983500836417079e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.1644189018843463e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.3406469153997023e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.0366683151660254e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.258368911294383e-06
sam_encoder.blocks.6.norm2.weight grad: 1.169139432022348e-05
sam_encoder.blocks.6.norm2.bias grad: 8.86612178874202e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.806722477544099e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.885655471298378e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.2251826976571465e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.276194082805887e-07
sam_encoder.blocks.7.norm1.weight grad: 4.733640707854647e-06
sam_encoder.blocks.7.norm1.bias grad: -4.584186896749998e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.7377377591619734e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0692261867006891e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.001994943157115e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.862968456924136e-07
sam_encoder.blocks.7.norm2.weight grad: -9.387364912072371e-07
sam_encoder.blocks.7.norm2.bias grad: 3.2544680834689643e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.678780550828378e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.428065274922119e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.3348392207699362e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.950775351313496e-07
sam_encoder.blocks.8.norm1.weight grad: 2.0906283680233173e-05
sam_encoder.blocks.8.norm1.bias grad: -4.170397915004287e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.602490374352783e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.7590411920973565e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.4719732632784144e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.2475796868093312e-07
sam_encoder.blocks.8.norm2.weight grad: -6.139124707260635e-06
sam_encoder.blocks.8.norm2.bias grad: -7.991388883965556e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.112723324098624e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.062190782860853e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.756174919544719e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.459448170266114e-07
sam_encoder.blocks.9.norm1.weight grad: -5.940491973888129e-06
sam_encoder.blocks.9.norm1.bias grad: 1.291271018999396e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.943218184256693e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.9811307083728025e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.7442169994174037e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.359971631449298e-06
sam_encoder.blocks.9.norm2.weight grad: 8.01443206910335e-07
sam_encoder.blocks.9.norm2.bias grad: -1.6865828911249992e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.5162838735705009e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.265573114840663e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.0847671748924768e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.0360147371102357e-06
sam_encoder.blocks.10.norm1.weight grad: -3.010537511727307e-06
sam_encoder.blocks.10.norm1.bias grad: 9.825602091950714e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.143546225852333e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.526613098387315e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.581324320606655e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.50600585522443e-08
sam_encoder.blocks.10.norm2.weight grad: -6.810521881561726e-06
sam_encoder.blocks.10.norm2.bias grad: -4.248823188390816e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.196146503294585e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.22858784077107e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.947918897523778e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.938739266435732e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2328644515946507e-05
sam_encoder.blocks.11.norm1.bias grad: 5.06825017509982e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.682804501499049e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.64030608277244e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -7.096572289810865e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.340766134371734e-08
sam_encoder.blocks.11.norm2.weight grad: -3.823256520263385e-06
sam_encoder.blocks.11.norm2.bias grad: -2.063668034679722e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.0264554930472514e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.9345220607647207e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.806885946592956e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.36116995008706e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.313225746154785e-10
sam_encoder.neck.conv1.trainable_shift grad: 4.9979466894001234e-06
sam_encoder.neck.conv2.trainable_scale grad: 6.982809281907976e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.619039827957749e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 6.472803943324834e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.5345361791551113e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002548494841903448
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004381702747195959
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0001105265473597683
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00010979601938743144
mask_decoder.transformer.layers.0.norm4.weight grad: 8.588086348026991e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.0273668016889133e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.8334601413225755e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.146057446836494e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00020677485736086965
mask_decoder.transformer.layers.1.norm2.bias grad: 8.19712076918222e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.669662692118436e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.603706525405869e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.8533700212137774e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.886198727646843e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0909570846706629e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.1868438377860002e-05
Text_Embedding_Affine.0.weight grad: -2.014498984292956e-11
Text_Embedding_Affine.0.bias grad: -7.202060614552863e-10
Text_Embedding_Affine.2.weight grad: -3.5100433844192924e-12
Text_Embedding_Affine.2.bias grad: -3.023775207111612e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.467576477010013e-10
Max value: 0.9989672899246216
Mean value: 0.07440736889839172

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.467576477010013e-10
Max value: 0.9989672899246216
Mean value: 0.07440736889839172

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08115482330322266

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.361339569091797
Max value: -1.1920928244535389e-07
Mean value: -0.10221325606107712

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0669097900390625

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08115482330322266

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.30784606933594
Max value: 90.5906753540039
Mean value: 68.01902770996094

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.295434203298697e-10
Max value: 0.9987971782684326
Mean value: 0.0756041556596756

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.295434203298697e-10
Max value: 0.9987971782684326
Mean value: 0.0756041556596756

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.295434203298697e-10
Max value: 0.9987971782684326
Mean value: 0.0756041556596756

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.803077697753906
Max value: -1.1920928244535389e-07
Mean value: -0.10193556547164917

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9597690105438232
Max value: 1.7476322650909424
Mean value: 1.0003811120986938

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.30784606933594
Max value: 90.5906753540039
Mean value: 68.01902770996094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.04003143310547
Max value: -68.04003143310547
Mean value: -68.04003143310547
sam_encoder.pos_embed grad: 1.417804762482433e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00014011467283125967
sam_encoder.blocks.0.norm1.bias grad: -4.5510892050515395e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.092372819286538e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0211791590108987e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.005615771049634e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.418389031954575e-07
sam_encoder.blocks.0.norm2.weight grad: 1.4324907169793732e-05
sam_encoder.blocks.0.norm2.bias grad: 1.6291767678922042e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.999549335276242e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.900036972481757e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.6922184992581606e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.783865056699142e-05
sam_encoder.blocks.1.norm1.weight grad: 2.251141268061474e-05
sam_encoder.blocks.1.norm1.bias grad: 2.1959698642604053e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.6893121937755495e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.005554612580454e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.4229188309400342e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.08858487996622e-06
sam_encoder.blocks.1.norm2.weight grad: -2.4888267944334075e-05
sam_encoder.blocks.1.norm2.bias grad: -9.335973118140828e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.8567096049082465e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.632374955486739e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1281170372967608e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.1185936727997614e-06
sam_encoder.blocks.2.norm1.weight grad: -1.7414808098692447e-05
sam_encoder.blocks.2.norm1.bias grad: -4.739985797641566e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3988397768116556e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8423850178805878e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.120609785080887e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.8956715166495997e-06
sam_encoder.blocks.2.norm2.weight grad: 1.4901647205078916e-07
sam_encoder.blocks.2.norm2.bias grad: -8.365142093680333e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.931099515990354e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.781526748345641e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.336291097686626e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.2409719804272754e-06
sam_encoder.blocks.3.norm1.weight grad: 1.948296585396747e-06
sam_encoder.blocks.3.norm1.bias grad: 2.486012817826122e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.249577048336505e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.6942273002059665e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2842319847550243e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.7286673710259493e-06
sam_encoder.blocks.3.norm2.weight grad: -1.5048087334434967e-05
sam_encoder.blocks.3.norm2.bias grad: -1.999980213440722e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.2864688869740348e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.745933892991161e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.3740083886659704e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5165618378887302e-06
sam_encoder.blocks.4.norm1.weight grad: -3.600993295549415e-05
sam_encoder.blocks.4.norm1.bias grad: -1.5040734979265835e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.5889079552143812e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.985275493003428e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.1868401998071931e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -9.535689969197847e-06
sam_encoder.blocks.4.norm2.weight grad: 5.993727972963825e-05
sam_encoder.blocks.4.norm2.bias grad: 4.183500277576968e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.1084280635695904e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.1912174159078859e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.43192175225704e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.873882168496493e-08
sam_encoder.blocks.5.norm1.weight grad: -6.558475433848798e-07
sam_encoder.blocks.5.norm1.bias grad: -9.72393809206551e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.9973514301673276e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.323839549324475e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.827148470416432e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.216509063960984e-06
sam_encoder.blocks.5.norm2.weight grad: 2.5289784389315173e-05
sam_encoder.blocks.5.norm2.bias grad: 2.4652492356835864e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.2894857870123815e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.3870372842793586e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.178982966455806e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.7403120839153416e-07
sam_encoder.blocks.6.norm1.weight grad: 1.0060603017336689e-06
sam_encoder.blocks.6.norm1.bias grad: -9.639294148655608e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.991006790078245e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5827599781914614e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.1843902569808051e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.27083488527569e-07
sam_encoder.blocks.6.norm2.weight grad: 2.4408187528024428e-05
sam_encoder.blocks.6.norm2.bias grad: 9.571607733960263e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.5906960470601916e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.18418334852322e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.3668142148380866e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.3796701498213224e-06
sam_encoder.blocks.7.norm1.weight grad: -7.861626727390103e-06
sam_encoder.blocks.7.norm1.bias grad: 2.3674353997193975e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.382758445193758e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.1187107651931e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.365195309219416e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.551986997583299e-06
sam_encoder.blocks.7.norm2.weight grad: 4.2071123971254565e-06
sam_encoder.blocks.7.norm2.bias grad: -5.121838739796658e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.5138558562030084e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.6257694142041146e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0675277906102565e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.034189136196801e-07
sam_encoder.blocks.8.norm1.weight grad: -7.4432532528589945e-06
sam_encoder.blocks.8.norm1.bias grad: 3.5536572795535903e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -6.636687430727761e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.475265869696159e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.079912054701708e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.8865026656130794e-06
sam_encoder.blocks.8.norm2.weight grad: 6.140919140307233e-06
sam_encoder.blocks.8.norm2.bias grad: 2.149130523321219e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.331171461060876e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.203140184064978e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.067579185284558e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.4529226746162749e-06
sam_encoder.blocks.9.norm1.weight grad: -3.1714489523437805e-06
sam_encoder.blocks.9.norm1.bias grad: 2.502758889022516e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.589693733374588e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1065739045079681e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.13778308131441e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.998135357756837e-07
sam_encoder.blocks.9.norm2.weight grad: 5.429153588920599e-06
sam_encoder.blocks.9.norm2.bias grad: 3.083486717514461e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 8.156689546012785e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.8923194602393778e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.289642845378694e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.1406066278141225e-06
sam_encoder.blocks.10.norm1.weight grad: -1.0441533049743157e-05
sam_encoder.blocks.10.norm1.bias grad: 9.350512755190721e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.416168162104441e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.270818640681682e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.316425818411517e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.328079633822199e-06
sam_encoder.blocks.10.norm2.weight grad: 1.129072529693076e-06
sam_encoder.blocks.10.norm2.bias grad: 1.0622877653077012e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.8729165276454296e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1375819894965389e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.8038344933302142e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.7170142641020902e-08
sam_encoder.blocks.11.norm1.weight grad: -2.5625389753258787e-05
sam_encoder.blocks.11.norm1.bias grad: 1.9631120267149527e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.972518127033254e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2462663789847284e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.878894742432749e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.3280326786334626e-06
sam_encoder.blocks.11.norm2.weight grad: 1.8215077943750657e-06
sam_encoder.blocks.11.norm2.bias grad: 4.857365638599731e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.2854251281169127e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.8573540450670407e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.180692591646221e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.3686880012974143e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4717406884301454e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.1383606255985796e-05
sam_encoder.neck.conv2.trainable_scale grad: 8.932383934734389e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.220023583911825e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 3.2808575269882567e-06
mask_decoder.transformer.layers.0.norm1.bias grad: -1.9757135305553675e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0045496271923184395
mask_decoder.transformer.layers.0.norm2.bias grad: 8.829531725496054e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 3.9361490053124726e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.930597424390726e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00020453750039450824
mask_decoder.transformer.layers.0.norm4.bias grad: 1.1927155355806462e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.85446946893353e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -4.421715402713744e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.23190727410838e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.7154459783341736e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -0.00011530640767887235
mask_decoder.transformer.layers.1.norm3.bias grad: -3.943404590245336e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.8990031094290316e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00019616968347691
mask_decoder.transformer.norm_final_attn.weight grad: 4.3749391807068605e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.0346083399781492e-05
Text_Embedding_Affine.0.weight grad: -7.647719263426112e-13
Text_Embedding_Affine.0.bias grad: 1.546119759998632e-10
Text_Embedding_Affine.2.weight grad: -1.210626737746523e-10
Text_Embedding_Affine.2.bias grad: -4.002562855021097e-05
Epoch 26 finished with average loss: -61.4907
Epoch 27/39
----------
Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.8]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-60.8]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-61.3]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-61.3]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-61.1]Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-61.1]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.068729645394619e-11
Max value: 0.9992579817771912
Mean value: 0.09582476317882538

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.068729645394619e-11
Max value: 0.9992579817771912
Mean value: 0.09582476317882538

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08978414535522461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.719757080078125
Max value: -1.1920928244535389e-07
Mean value: -0.12220858037471771

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08581781387329102

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08978414535522461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.19624328613281
Max value: 84.6921615600586
Mean value: 60.80731964111328

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.068729645394619e-11
Max value: 0.9992579817771912
Mean value: 0.09582476317882538

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.068729645394619e-11
Max value: 0.9992579817771912
Mean value: 0.09582476317882538

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.068729645394619e-11
Max value: 0.9992579817771912
Mean value: 0.09582476317882538

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.719757080078125
Max value: -1.1920928244535389e-07
Mean value: -0.12220858037471771

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.19624328613281
Max value: 84.6921615600586
Mean value: 60.80731964111328

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.80861282348633
Max value: -60.80861282348633
Mean value: -60.80861282348633
sam_encoder.pos_embed grad: -6.664144347467982e-09
sam_encoder.blocks.0.norm1.weight grad: -1.5629293557140045e-05
sam_encoder.blocks.0.norm1.bias grad: 1.725988113321364e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.474608759774128e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.61227363202488e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.3095543961489966e-08
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.956657058599376e-07
sam_encoder.blocks.0.norm2.weight grad: 2.2284064016275806e-06
sam_encoder.blocks.0.norm2.bias grad: 1.3523436791729182e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.848642336379271e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.213327545381617e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5696638001827523e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.480728527298197e-06
sam_encoder.blocks.1.norm1.weight grad: -4.809362508240156e-06
sam_encoder.blocks.1.norm1.bias grad: 5.0554708650452085e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.0061903594760224e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.3228031409416872e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.5056157280923799e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.129783850563399e-07
sam_encoder.blocks.1.norm2.weight grad: 6.159511940495577e-06
sam_encoder.blocks.1.norm2.bias grad: -8.082383828877937e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.850799870037008e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.874332949431846e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.917574304068694e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.877955236930575e-07
sam_encoder.blocks.2.norm1.weight grad: -1.550696288177278e-05
sam_encoder.blocks.2.norm1.bias grad: 7.082098363753175e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1071997505496256e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.231881009924109e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.932324943889398e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.2443823607100057e-06
sam_encoder.blocks.2.norm2.weight grad: 1.4713578821101692e-05
sam_encoder.blocks.2.norm2.bias grad: -9.997750566981267e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.917970495123882e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.5160065913732979e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.724338951855316e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.8622258102805063e-07
sam_encoder.blocks.3.norm1.weight grad: -3.127644959022291e-06
sam_encoder.blocks.3.norm1.bias grad: -4.420293407747522e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.0287112571822945e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6720991879992653e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.856226259013056e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.1184556569787674e-07
sam_encoder.blocks.3.norm2.weight grad: 9.595438314136118e-06
sam_encoder.blocks.3.norm2.bias grad: 3.989959168393398e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.581458935921546e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.9098009690642357e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.3394599086022936e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.0160193514584535e-07
sam_encoder.blocks.4.norm1.weight grad: -2.4063283490249887e-06
sam_encoder.blocks.4.norm1.bias grad: -3.019823225258733e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.8310287259737379e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.865837687859312e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.091008354909718e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.829574653645977e-07
sam_encoder.blocks.4.norm2.weight grad: -1.057405006577028e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0484771337360144e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.093948624969926e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.585165475466056e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.2195940800884273e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0462953241585637e-06
sam_encoder.blocks.5.norm1.weight grad: 7.80150276114e-06
sam_encoder.blocks.5.norm1.bias grad: -6.800569281040225e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.855744348082226e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.149418835666438e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.2359868125931825e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1629966678583514e-07
sam_encoder.blocks.5.norm2.weight grad: 1.98417660612904e-06
sam_encoder.blocks.5.norm2.bias grad: -4.070479917572811e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.906856025219895e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.1970184914389392e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.758338137544342e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.2511928793610423e-07
sam_encoder.blocks.6.norm1.weight grad: -3.1336728625319665e-06
sam_encoder.blocks.6.norm1.bias grad: -4.514843965353066e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.3142908958107e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.6472029074066086e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0585366680970765e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.8058369732898427e-06
sam_encoder.blocks.6.norm2.weight grad: -1.8486705357645405e-06
sam_encoder.blocks.6.norm2.bias grad: -4.230309968988877e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3271253465063637e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.816071488747184e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.507630582244019e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.265810815695659e-08
sam_encoder.blocks.7.norm1.weight grad: 7.398588422802277e-06
sam_encoder.blocks.7.norm1.bias grad: 8.505546134074393e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.1008428272325546e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.0371209049917525e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9297938251838787e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.884027677258928e-08
sam_encoder.blocks.7.norm2.weight grad: 2.915236791523057e-06
sam_encoder.blocks.7.norm2.bias grad: -1.6068755712694838e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.0554039110720623e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.761451913916972e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.10314634993847e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0902092384412754e-07
sam_encoder.blocks.8.norm1.weight grad: 1.2499290278356057e-05
sam_encoder.blocks.8.norm1.bias grad: -2.806370389407675e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.996194421546534e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.746930815395899e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.808951992643415e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.696689537311613e-06
sam_encoder.blocks.8.norm2.weight grad: 4.914754299534252e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5760085716465255e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.744580564874923e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.7143508961889893e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4430067949433578e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.5969481498577807e-07
sam_encoder.blocks.9.norm1.weight grad: 3.814118599620997e-06
sam_encoder.blocks.9.norm1.bias grad: 7.65712684369646e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.5733947950357106e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.2140412763983477e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.289970867901502e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9099408632428094e-07
sam_encoder.blocks.9.norm2.weight grad: 6.706333806505427e-06
sam_encoder.blocks.9.norm2.bias grad: 1.9834551494568586e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.3933829399757087e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.2454652227897896e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.683969218101993e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.6383762613259023e-07
sam_encoder.blocks.10.norm1.weight grad: 4.260754394636024e-06
sam_encoder.blocks.10.norm1.bias grad: 1.8908237962023122e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.4090029455692274e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.024969702091767e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.044896139201228e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.587509868590132e-07
sam_encoder.blocks.10.norm2.weight grad: 9.048336323758122e-06
sam_encoder.blocks.10.norm2.bias grad: 8.658063279654016e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.826535587199032e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.9532593543990515e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.02466185328376e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.389852617554425e-07
sam_encoder.blocks.11.norm1.weight grad: 8.455161150777712e-06
sam_encoder.blocks.11.norm1.bias grad: 3.845934315904742e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.095130523433909e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.8870859953021863e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.127172239052015e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.875853841847857e-08
sam_encoder.blocks.11.norm2.weight grad: 8.816696208668873e-06
sam_encoder.blocks.11.norm2.bias grad: 2.073229552479461e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.897222424915526e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.8361482716500177e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.640387593710329e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.1447175413413788e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.2060354492859915e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.2749572963221e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.3550179573940113e-06
sam_encoder.neck.conv2.trainable_shift grad: -6.4247569753206335e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00020171812502667308
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3482931535691023e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0027882936410605907
mask_decoder.transformer.layers.0.norm2.bias grad: -0.000608684029430151
mask_decoder.transformer.layers.0.norm3.weight grad: 2.270140976179391e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.4217198844999075e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.438317748485133e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.543404303258285e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.703779136936646e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.598503437591717e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -6.499078881461173e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -3.0092138331383467e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.327370334067382e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -2.6214598619844764e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.696587009471841e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011869403533637524
mask_decoder.transformer.norm_final_attn.weight grad: -5.723278263758402e-06
mask_decoder.transformer.norm_final_attn.bias grad: -6.796908564865589e-06
Text_Embedding_Affine.0.weight grad: -8.883348917576583e-12
Text_Embedding_Affine.0.bias grad: -2.547293764809666e-10
Text_Embedding_Affine.2.weight grad: 6.484379699855936e-11
Text_Embedding_Affine.2.bias grad: -1.9204035197617486e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.185553170733212e-13
Max value: 0.997189462184906
Mean value: 0.07371191680431366

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.185553170733212e-13
Max value: 0.997189462184906
Mean value: 0.07371191680431366

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07849836349487305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1130896508693695

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06587982177734375

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07849836349487305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 49.90192413330078
Max value: 77.789306640625
Mean value: 61.775020599365234

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5442006939640762e-13
Max value: 0.9974274039268494
Mean value: 0.07359432429075241

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5442006939640762e-13
Max value: 0.9974274039268494
Mean value: 0.07359432429075241

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5442006939640762e-13
Max value: 0.9974274039268494
Mean value: 0.07359432429075241

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11319907009601593

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7617689967155457
Max value: 1.0226037502288818
Mean value: 0.9999033212661743

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 49.90192413330078
Max value: 77.789306640625
Mean value: 61.775020599365234

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.77122116088867
Max value: -61.77122116088867
Mean value: -61.77122116088867
sam_encoder.pos_embed grad: 1.4865926267759733e-09
sam_encoder.blocks.0.norm1.weight grad: -2.4127118649630575e-06
sam_encoder.blocks.0.norm1.bias grad: -1.679795968811959e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.014057695821975e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1525060017447686e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.7533292268344667e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.659220505549456e-07
sam_encoder.blocks.0.norm2.weight grad: 1.6755702745285816e-05
sam_encoder.blocks.0.norm2.bias grad: -5.853356924490072e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.368809514853638e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.077922428929014e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.6542417142773047e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.095018190739211e-06
sam_encoder.blocks.1.norm1.weight grad: 3.1775011848367285e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4440469385590404e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.492071977641899e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.7912228713612421e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.366890945879277e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.8374579414958134e-06
sam_encoder.blocks.1.norm2.weight grad: -6.9526900006167125e-06
sam_encoder.blocks.1.norm2.bias grad: -6.723651949869236e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1617255495366408e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0512148946872912e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.355808288091794e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.009801805679672e-08
sam_encoder.blocks.2.norm1.weight grad: -1.6064353985711932e-05
sam_encoder.blocks.2.norm1.bias grad: 5.484629582497291e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1544439985300414e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.733836254265043e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.175347723707091e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.228786797786597e-06
sam_encoder.blocks.2.norm2.weight grad: -5.441308530862443e-06
sam_encoder.blocks.2.norm2.bias grad: -4.4090651840633655e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.976408945367439e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.129803864496353e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.577633601205889e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0949044053631951e-06
sam_encoder.blocks.3.norm1.weight grad: 4.143767000641674e-06
sam_encoder.blocks.3.norm1.bias grad: 1.0556566394370748e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.404011972132139e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.439301500904548e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.425687395974819e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.165451284483424e-07
sam_encoder.blocks.3.norm2.weight grad: -1.4044008821656462e-05
sam_encoder.blocks.3.norm2.bias grad: -3.6513424106487946e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.164223976957146e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.996946816187119e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.640592467490933e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.10611926074489e-07
sam_encoder.blocks.4.norm1.weight grad: -7.0413834691862576e-06
sam_encoder.blocks.4.norm1.bias grad: -3.880895746988244e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.4851570894243196e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.8888745216827374e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.7899757242266787e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.267712488901452e-06
sam_encoder.blocks.4.norm2.weight grad: 1.2563143172883429e-05
sam_encoder.blocks.4.norm2.bias grad: 1.3715905879507773e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.804624717915431e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.8528809252748033e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.3561707419285085e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.1679621820803732e-06
sam_encoder.blocks.5.norm1.weight grad: -6.5273052314296365e-06
sam_encoder.blocks.5.norm1.bias grad: 1.013011342365644e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.297143156392849e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.1518317225854844e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.7136451283004135e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.9559781776479213e-06
sam_encoder.blocks.5.norm2.weight grad: 9.91043634712696e-06
sam_encoder.blocks.5.norm2.bias grad: 7.632007509528194e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.4708687103848206e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.123539151303703e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.412695026687288e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.427971020959376e-07
sam_encoder.blocks.6.norm1.weight grad: 2.0091908936592517e-06
sam_encoder.blocks.6.norm1.bias grad: -1.7909377447722363e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.2240628823055886e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5093377214725479e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.7686656406112888e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.632212918271762e-08
sam_encoder.blocks.6.norm2.weight grad: 6.555058917001588e-06
sam_encoder.blocks.6.norm2.bias grad: 1.3695052984985523e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.7073336898174603e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.398734070789942e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.621749086363707e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.621689069812419e-08
sam_encoder.blocks.7.norm1.weight grad: -1.5170037386269541e-06
sam_encoder.blocks.7.norm1.bias grad: -7.864285862524412e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.4711715102275775e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.6366702482173423e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.301533742065658e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.466348286769062e-07
sam_encoder.blocks.7.norm2.weight grad: 2.5229448965546908e-06
sam_encoder.blocks.7.norm2.bias grad: -1.963203430932481e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.752564670227002e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.865787962491595e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.9310919558156456e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.844423942695357e-08
sam_encoder.blocks.8.norm1.weight grad: -7.411630917886214e-07
sam_encoder.blocks.8.norm1.bias grad: 1.7814758166423417e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.1222274451938574e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.774042837307206e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.3497977963415906e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.6869637420313666e-06
sam_encoder.blocks.8.norm2.weight grad: 3.0313667593873106e-06
sam_encoder.blocks.8.norm2.bias grad: 2.105577323163743e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 8.057993454713142e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.129101623424503e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.8672121743511525e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.485831712168874e-07
sam_encoder.blocks.9.norm1.weight grad: 1.8400960470899008e-06
sam_encoder.blocks.9.norm1.bias grad: -2.765123667813896e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.0295030935812974e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.229719365866913e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.6497663674927026e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.864791319254437e-07
sam_encoder.blocks.9.norm2.weight grad: 4.516040462476667e-06
sam_encoder.blocks.9.norm2.bias grad: 3.013715058841626e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 6.011149480400491e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.0340937706132536e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.479090875975089e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.6154636379469594e-07
sam_encoder.blocks.10.norm1.weight grad: -1.232225940839271e-06
sam_encoder.blocks.10.norm1.bias grad: 7.643097887921613e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.4492216488833947e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.296836095818435e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.696898478570802e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.8727705253240856e-07
sam_encoder.blocks.10.norm2.weight grad: 1.2064033398928586e-06
sam_encoder.blocks.10.norm2.bias grad: 9.413711268280167e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.564569001606287e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.1425765339699865e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.022761572741729e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.828508118251193e-07
sam_encoder.blocks.11.norm1.weight grad: -1.611093284736853e-05
sam_encoder.blocks.11.norm1.bias grad: 1.5868334912738646e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.832513008703245e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.647750415642804e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.1369646674429532e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.00942495718482e-07
sam_encoder.blocks.11.norm2.weight grad: 1.167907157650916e-06
sam_encoder.blocks.11.norm2.bias grad: 2.0616480469470844e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.286762411240488e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.0601422079380427e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.288433276793512e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.544775033034966e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.0773765097837895e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.3021108063403517e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.2826603779103607e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.3481360333098564e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 4.5997869165148586e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.243955921381712e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005256976932287216
mask_decoder.transformer.layers.0.norm2.bias grad: -1.9652681658044457e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 4.39265750173945e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -1.4938668755348772e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012635647726710886
mask_decoder.transformer.layers.0.norm4.bias grad: 1.4982669199525844e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.4346303689526394e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.6023690224974416e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.4659435692010447e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -4.872005229117349e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.488754322868772e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.9805929443682544e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.7663673942442983e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00022208970040082932
mask_decoder.transformer.norm_final_attn.weight grad: 4.908542905468494e-09
mask_decoder.transformer.norm_final_attn.bias grad: -1.1729040124919266e-05
Text_Embedding_Affine.0.weight grad: -1.9943751511375396e-12
Text_Embedding_Affine.0.bias grad: -2.447691216378445e-10
Text_Embedding_Affine.2.weight grad: -9.694120506331672e-11
Text_Embedding_Affine.2.bias grad: -3.2890678994590417e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.967907824543258e-12
Max value: 0.9981125593185425
Mean value: 0.07213081419467926

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.967907824543258e-12
Max value: 0.9981125593185425
Mean value: 0.07213081419467926

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08214092254638672

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11301511526107788

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06424713134765625

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08214092254638672

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 41.674163818359375
Max value: 81.96725463867188
Mean value: 60.79591369628906

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.9226330597033048e-12
Max value: 0.9980980753898621
Mean value: 0.07248522341251373

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9226330597033048e-12
Max value: 0.9980980753898621
Mean value: 0.07248522341251373

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9226330597033048e-12
Max value: 0.9980980753898621
Mean value: 0.07248522341251373

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1126917153596878

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9041047692298889
Max value: 1.0928813219070435
Mean value: 1.0003345012664795

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 41.674163818359375
Max value: 81.96725463867188
Mean value: 60.79591369628906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.81282043457031
Max value: -60.81282043457031
Mean value: -60.81282043457031
sam_encoder.pos_embed grad: -1.4858239083537228e-09
sam_encoder.blocks.0.norm1.weight grad: 1.4105490663496312e-05
sam_encoder.blocks.0.norm1.bias grad: 2.7248694095760584e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.46405045092979e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0206061915596365e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.18995977169834e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.7862256527223508e-06
sam_encoder.blocks.0.norm2.weight grad: 4.4608845200855285e-05
sam_encoder.blocks.0.norm2.bias grad: -2.3554684958071448e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.927105358845438e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.120405153822503e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.7200647562276572e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.1785117496619932e-06
sam_encoder.blocks.1.norm1.weight grad: -4.950184120389167e-06
sam_encoder.blocks.1.norm1.bias grad: 3.8218286135816015e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.253819032688625e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.622404624868068e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.938852609688183e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.1919111077295383e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0132770512427669e-05
sam_encoder.blocks.1.norm2.bias grad: -5.588755357166519e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.858907232119236e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.022126856601972e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.7348648877232336e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6582338275838993e-06
sam_encoder.blocks.2.norm1.weight grad: -1.262545174540719e-05
sam_encoder.blocks.2.norm1.bias grad: -1.4916040527168661e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.626698788953945e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.1851847148136585e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.914867637737188e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.337121936259791e-06
sam_encoder.blocks.2.norm2.weight grad: -5.3346375352703035e-06
sam_encoder.blocks.2.norm2.bias grad: -3.721402208611835e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.438774678623304e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.3722250287173665e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.451389607609599e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.3263604254661914e-08
sam_encoder.blocks.3.norm1.weight grad: -9.262643288820982e-06
sam_encoder.blocks.3.norm1.bias grad: -7.205507699836744e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.2708646762766875e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4358361113409046e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.633698709876626e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8556579561845865e-07
sam_encoder.blocks.3.norm2.weight grad: 1.581795368110761e-05
sam_encoder.blocks.3.norm2.bias grad: 2.9997622732480522e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.383588278258685e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.847909051226452e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.3330378553509945e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3671024134964682e-06
sam_encoder.blocks.4.norm1.weight grad: 4.008393261756282e-06
sam_encoder.blocks.4.norm1.bias grad: -3.856159310089424e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.9900320441811346e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.203986231412273e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.473288989473076e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.4154128368536476e-06
sam_encoder.blocks.4.norm2.weight grad: -1.783781044650823e-05
sam_encoder.blocks.4.norm2.bias grad: -7.313786227314267e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3692409083887469e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.218829755904153e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.688830301802227e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.871808864161721e-07
sam_encoder.blocks.5.norm1.weight grad: 6.130050223873695e-06
sam_encoder.blocks.5.norm1.bias grad: -9.58201962930616e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.1096011576228193e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2661521395784803e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.8773511101244367e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.0398753021218e-07
sam_encoder.blocks.5.norm2.weight grad: -6.919291308804532e-07
sam_encoder.blocks.5.norm2.bias grad: -2.105629164361744e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.188246528727177e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.043966997523967e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.7330581764981616e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.035715844314836e-07
sam_encoder.blocks.6.norm1.weight grad: -4.376280230644625e-06
sam_encoder.blocks.6.norm1.bias grad: 7.30312137875444e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.8474809166946216e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.013650472094014e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.977207931413432e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.3706064692087239e-06
sam_encoder.blocks.6.norm2.weight grad: -2.1817700144310948e-06
sam_encoder.blocks.6.norm2.bias grad: -4.663127981530124e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.9753026663238415e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.795976782494108e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.088304881908698e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0729203268056153e-06
sam_encoder.blocks.7.norm1.weight grad: -3.827068212558515e-06
sam_encoder.blocks.7.norm1.bias grad: 1.9550756746866682e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.1369123714976013e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.2819509720429778e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.4407466270304212e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.128432338911807e-07
sam_encoder.blocks.7.norm2.weight grad: 2.4894413854781305e-06
sam_encoder.blocks.7.norm2.bias grad: -3.737331439879199e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.631422375998227e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.492669394399854e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.852266783927917e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.138978617149405e-07
sam_encoder.blocks.8.norm1.weight grad: 2.3713910195510834e-06
sam_encoder.blocks.8.norm1.bias grad: -2.3499208055000054e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.930303824337898e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.9097571402635367e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.017711934371619e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5484224036299565e-07
sam_encoder.blocks.8.norm2.weight grad: 3.554302338670823e-06
sam_encoder.blocks.8.norm2.bias grad: 1.1386707399196894e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.845574610750191e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.124432739947224e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.781606422620825e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.8126988265976252e-07
sam_encoder.blocks.9.norm1.weight grad: -2.2251242626225576e-06
sam_encoder.blocks.9.norm1.bias grad: 6.613090022256074e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.0837410374952015e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.6990972540043003e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.747359293513e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.577947821526323e-07
sam_encoder.blocks.9.norm2.weight grad: -7.548622988906573e-07
sam_encoder.blocks.9.norm2.bias grad: -8.773846502663218e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.157996270099829e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.9126250094814168e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.370681143787806e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.221277999429731e-07
sam_encoder.blocks.10.norm1.weight grad: -4.865821665589465e-07
sam_encoder.blocks.10.norm1.bias grad: 6.745761993443011e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.32233944075233e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.3590612840962422e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.727245143636537e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.017241270863451e-08
sam_encoder.blocks.10.norm2.weight grad: -1.0554908840276767e-06
sam_encoder.blocks.10.norm2.bias grad: -1.4965687569201691e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.3444605428958312e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8350090158492094e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.867063919140492e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.186409228168486e-07
sam_encoder.blocks.11.norm1.weight grad: 2.1246587493806146e-06
sam_encoder.blocks.11.norm1.bias grad: -5.457515612761199e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.8415360020517255e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6798898627712333e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.254435801456566e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.735481292707846e-07
sam_encoder.blocks.11.norm2.weight grad: -2.039131231867941e-06
sam_encoder.blocks.11.norm2.bias grad: -2.669350351425237e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.7488890737004112e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.887148523062933e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.382854179610149e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.4475406235069386e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.0865809347014874e-07
sam_encoder.neck.conv1.trainable_shift grad: 8.548904588678852e-07
sam_encoder.neck.conv2.trainable_scale grad: -2.440724529151339e-07
sam_encoder.neck.conv2.trainable_shift grad: 9.371677151648328e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015210954006761312
mask_decoder.transformer.layers.0.norm1.bias grad: -1.288182829739526e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0036968342028558254
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006184797966852784
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00016228310414589942
mask_decoder.transformer.layers.0.norm3.bias grad: 1.7863349057734013e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00012082808825653046
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1182935850229114e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.4040374632459134e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 8.888791853678413e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -1.0254829248879105e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011972298671025783
mask_decoder.transformer.layers.1.norm3.weight grad: 3.871181979775429e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.560899494914338e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.619260678533465e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001744735345710069
mask_decoder.transformer.norm_final_attn.weight grad: 5.3151634347159415e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.642198913032189e-05
Text_Embedding_Affine.0.weight grad: 2.443479012875782e-12
Text_Embedding_Affine.0.bias grad: 3.2905389524273687e-10
Text_Embedding_Affine.2.weight grad: 2.109240282432978e-10
Text_Embedding_Affine.2.bias grad: 3.6026089219376445e-05
Epoch 27 finished with average loss: -61.1309
Epoch 28/39
----------
Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/3 [00:01<?, ?it/s, loss=-65.8]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-65.8]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-62.7]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-62.7]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-59.7]Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-59.7]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.3901011258516984e-12
Max value: 0.9995788931846619
Mean value: 0.08814813196659088

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.3901011258516984e-12
Max value: 0.9995788931846619
Mean value: 0.08814813196659088

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0885004997253418

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.749409675598145
Max value: -1.1920928244535389e-07
Mean value: -0.11406150460243225

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07888555526733398

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0885004997253418

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.176761627197266
Max value: 91.71953582763672
Mean value: 65.82585906982422

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.3901011258516984e-12
Max value: 0.9995788931846619
Mean value: 0.08814813196659088

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.3901011258516984e-12
Max value: 0.9995788931846619
Mean value: 0.08814813196659088

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.3901011258516984e-12
Max value: 0.9995788931846619
Mean value: 0.08814813196659088

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.749409675598145
Max value: -1.1920928244535389e-07
Mean value: -0.11406150460243225

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.176761627197266
Max value: 91.71953582763672
Mean value: 65.82585906982422

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.82708740234375
Max value: -65.82708740234375
Mean value: -65.82708740234375
sam_encoder.pos_embed grad: -3.036360274322192e-09
sam_encoder.blocks.0.norm1.weight grad: 1.6816575225675479e-06
sam_encoder.blocks.0.norm1.bias grad: 4.973327122570481e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.340179758510203e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1248555153997586e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.4953267206437886e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.807281008354039e-07
sam_encoder.blocks.0.norm2.weight grad: -2.5402202936675167e-06
sam_encoder.blocks.0.norm2.bias grad: -1.3362419849727303e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.563903530652169e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.819051799946465e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.5393381949688774e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.372782314021606e-06
sam_encoder.blocks.1.norm1.weight grad: 9.685099030320998e-06
sam_encoder.blocks.1.norm1.bias grad: 2.7941164262301754e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.5189339036587626e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.3796264966003946e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.3259824451524764e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.7736804238666082e-06
sam_encoder.blocks.1.norm2.weight grad: 1.4659241060144268e-05
sam_encoder.blocks.1.norm2.bias grad: 2.177395344915567e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.987093911448028e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4457439192483434e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.9481722119962797e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.472172001143917e-07
sam_encoder.blocks.2.norm1.weight grad: 6.991316240601009e-06
sam_encoder.blocks.2.norm1.bias grad: -6.329113233505268e-08
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.143905243836343e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.961995601770468e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4358423641169793e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.2105047062505037e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1844811524497345e-05
sam_encoder.blocks.2.norm2.bias grad: 5.440500899567269e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.658759280573577e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.0514323750830954e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.6681522083672462e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 9.762459285411751e-08
sam_encoder.blocks.3.norm1.weight grad: 1.9054366475756979e-06
sam_encoder.blocks.3.norm1.bias grad: -6.730005225108471e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.6169210539374035e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.805418024669052e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0494825346540892e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.642189139758557e-07
sam_encoder.blocks.3.norm2.weight grad: 1.785239305718278e-06
sam_encoder.blocks.3.norm2.bias grad: -1.582739741934347e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.331265692300803e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4738483855580853e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.879903372057015e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.0983135325659532e-06
sam_encoder.blocks.4.norm1.weight grad: 1.1406003977754153e-05
sam_encoder.blocks.4.norm1.bias grad: 7.071751497278456e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.3915282529051183e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 5.029158955949242e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.1874113826925168e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8992711829923792e-06
sam_encoder.blocks.4.norm2.weight grad: -2.7825306460727006e-05
sam_encoder.blocks.4.norm2.bias grad: -2.877818769775331e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.7548030882608145e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.1784138526709285e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.348438556509791e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.1582987724523264e-07
sam_encoder.blocks.5.norm1.weight grad: 8.429262379650027e-06
sam_encoder.blocks.5.norm1.bias grad: -2.0001657503598835e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.2104885576700326e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.4226277471607318e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.52310860560101e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.136897354735993e-07
sam_encoder.blocks.5.norm2.weight grad: -9.190529453917406e-06
sam_encoder.blocks.5.norm2.bias grad: -1.3763517017650884e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.8590223994106054e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.3528240287996596e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.85146243692725e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.077850222638517e-07
sam_encoder.blocks.6.norm1.weight grad: 2.829651180036308e-07
sam_encoder.blocks.6.norm1.bias grad: 3.3235914997931104e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.991149573172152e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.1372883313451894e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.209227419480158e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.157934434559138e-06
sam_encoder.blocks.6.norm2.weight grad: -4.615106718119932e-06
sam_encoder.blocks.6.norm2.bias grad: -8.146002983266953e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.7007428090873873e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5938676369842142e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.9892915759101015e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.937724492672714e-07
sam_encoder.blocks.7.norm1.weight grad: 9.884515748126432e-06
sam_encoder.blocks.7.norm1.bias grad: -4.307339622755535e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.719146313116653e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.5073563847399782e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.9481202545866836e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.273602603963809e-07
sam_encoder.blocks.7.norm2.weight grad: -8.341610282514011e-07
sam_encoder.blocks.7.norm2.bias grad: 2.3483910354116233e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.2484244962251978e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.7850310263820575e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.168370418890845e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.883867970624124e-07
sam_encoder.blocks.8.norm1.weight grad: 8.444852028333116e-06
sam_encoder.blocks.8.norm1.bias grad: -2.8618969736271538e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.85210886533605e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.3605700789630646e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.1619597393728327e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.884622972487705e-06
sam_encoder.blocks.8.norm2.weight grad: -2.1166356418689247e-06
sam_encoder.blocks.8.norm2.bias grad: -1.1793163139373064e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.810184226604179e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.1497841607451846e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.355560344672995e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.082806743914261e-07
sam_encoder.blocks.9.norm1.weight grad: 4.6373617124118027e-07
sam_encoder.blocks.9.norm1.bias grad: 1.8934778722723422e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.735413128287291e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.0504326054579e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.7395819302000746e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.292875589977484e-07
sam_encoder.blocks.9.norm2.weight grad: -6.779799832656863e-07
sam_encoder.blocks.9.norm2.bias grad: -1.3289929938764544e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.662977121621225e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.5374450867966516e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.89106020293184e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.139885388416587e-07
sam_encoder.blocks.10.norm1.weight grad: 2.6826819521375e-06
sam_encoder.blocks.10.norm1.bias grad: 7.004552458056423e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.5502340602324693e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.940008461242542e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.987376188291819e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.3172209984732035e-07
sam_encoder.blocks.10.norm2.weight grad: -5.6449913188316714e-08
sam_encoder.blocks.10.norm2.bias grad: -2.4622811451990856e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.172821933134401e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 3.1683734391663165e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.558611467724404e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.5431287415121915e-07
sam_encoder.blocks.11.norm1.weight grad: 2.0009763829875737e-05
sam_encoder.blocks.11.norm1.bias grad: 2.3897277046103227e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.6901869862049352e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.403001399732602e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.710238732106518e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0702354984459816e-06
sam_encoder.blocks.11.norm2.weight grad: -2.9723682928306516e-06
sam_encoder.blocks.11.norm2.bias grad: -2.7294688607071294e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.159712494176347e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.3786660108271462e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2548207450890914e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.869269218943373e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.6282683645840734e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2925787814310752e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.2254531611688435e-07
sam_encoder.neck.conv2.trainable_shift grad: 8.972333489509765e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -2.163250610465184e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.8860009731724858e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0049062687903642654
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00034679414238780737
mask_decoder.transformer.layers.0.norm3.weight grad: -5.2148774557281286e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.005527443950996e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001549870939925313
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3952493645774666e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.270023444201797e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.126451701973565e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.075830631540157e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.890776032581925e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 6.709793524350971e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.066886347369291e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.3625237594824284e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00020786018285434693
mask_decoder.transformer.norm_final_attn.weight grad: 1.9451849766483065e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1532465578056872e-05
Text_Embedding_Affine.0.weight grad: 3.1414497739246094e-13
Text_Embedding_Affine.0.bias grad: 1.9037264820109812e-10
Text_Embedding_Affine.2.weight grad: -2.2654336739869052e-11
Text_Embedding_Affine.2.bias grad: 1.0274944543198217e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.134334898024897e-13
Max value: 0.9994679093360901
Mean value: 0.08768497407436371

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.134334898024897e-13
Max value: 0.9994679093360901
Mean value: 0.08768497407436371

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08454132080078125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12098764628171921

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07763147354125977

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08454132080078125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.56179428100586
Max value: 78.8265151977539
Mean value: 59.54503631591797

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.348739672341509e-13
Max value: 0.9994565844535828
Mean value: 0.08806993067264557

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.348739672341509e-13
Max value: 0.9994565844535828
Mean value: 0.08806993067264557

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.348739672341509e-13
Max value: 0.9994565844535828
Mean value: 0.08806993067264557

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12092149257659912

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9488581418991089
Max value: 1.1083346605300903
Mean value: 1.0000706911087036

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.56179428100586
Max value: 78.8265151977539
Mean value: 59.54503631591797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.55104064941406
Max value: -59.55104064941406
Mean value: -59.55104064941406
sam_encoder.pos_embed grad: -6.888677406280408e-10
sam_encoder.blocks.0.norm1.weight grad: 2.2431527213484515e-06
sam_encoder.blocks.0.norm1.bias grad: -1.2280877399462042e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.184947440284304e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.215590590523789e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.1998440590541577e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.279852643980121e-07
sam_encoder.blocks.0.norm2.weight grad: 2.108010812662542e-05
sam_encoder.blocks.0.norm2.bias grad: -1.0709773050621152e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.999540684977546e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.163731995911803e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.296405783563387e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.529861482500564e-06
sam_encoder.blocks.1.norm1.weight grad: 9.100062015932053e-06
sam_encoder.blocks.1.norm1.bias grad: 1.5793790225870907e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.1421137615980115e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.444583742544637e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.707305485382676e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.5249822758487426e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0203621059190482e-06
sam_encoder.blocks.1.norm2.bias grad: -3.385237278052955e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.212858700862853e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.305966345124034e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.379213224747218e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.2438500479893264e-07
sam_encoder.blocks.2.norm1.weight grad: -9.046631021192297e-06
sam_encoder.blocks.2.norm1.bias grad: 6.077084435673896e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.36383457883494e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.377637883910211e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.390036560333101e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.8636480894638225e-06
sam_encoder.blocks.2.norm2.weight grad: -4.880245342064882e-06
sam_encoder.blocks.2.norm2.bias grad: -5.326236987457378e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.1698067434481345e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.498756732753463e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.646686531690648e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.724966740672244e-07
sam_encoder.blocks.3.norm1.weight grad: -6.617827239097096e-06
sam_encoder.blocks.3.norm1.bias grad: 2.76194145953923e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.687070941145066e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5982666354830144e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.058657628367655e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.697919171623653e-06
sam_encoder.blocks.3.norm2.weight grad: 8.470045713693253e-07
sam_encoder.blocks.3.norm2.bias grad: 1.4374260892680013e-08
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3847463833371876e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.4861685687938007e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.327770627947757e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.378807254099229e-07
sam_encoder.blocks.4.norm1.weight grad: -3.3706189697113587e-06
sam_encoder.blocks.4.norm1.bias grad: -7.043420737318229e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.440433596959338e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5066195828694617e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.4711135867837584e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.816479536704719e-06
sam_encoder.blocks.4.norm2.weight grad: -1.7437239421269624e-06
sam_encoder.blocks.4.norm2.bias grad: 2.4300416043843143e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.5853997815138428e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.8853513665817445e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.342911890693358e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.95038467154518e-07
sam_encoder.blocks.5.norm1.weight grad: 7.029745461295533e-07
sam_encoder.blocks.5.norm1.bias grad: -7.1223271334019955e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.568732038023882e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.0324043766304385e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7210217038154951e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.417266149583156e-07
sam_encoder.blocks.5.norm2.weight grad: 5.590973159996793e-06
sam_encoder.blocks.5.norm2.bias grad: 3.946704509871779e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.6093630367540754e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.3569997154027078e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.3583766051160637e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.314283945765055e-07
sam_encoder.blocks.6.norm1.weight grad: 8.180974759852688e-07
sam_encoder.blocks.6.norm1.bias grad: -3.3667936349957017e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.2424604796688072e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.969225988636026e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.9024269565525174e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.6654522028147767e-07
sam_encoder.blocks.6.norm2.weight grad: -2.8203128294990165e-06
sam_encoder.blocks.6.norm2.bias grad: 5.3754183682031e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.233191253253608e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.140396534538013e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.523438961878128e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.567185633661211e-08
sam_encoder.blocks.7.norm1.weight grad: 2.9075818019919097e-06
sam_encoder.blocks.7.norm1.bias grad: -4.820400363314548e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4455708878813311e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.528261345309147e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.88180545391515e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.5304828454864037e-07
sam_encoder.blocks.7.norm2.weight grad: -9.781545031728456e-07
sam_encoder.blocks.7.norm2.bias grad: -1.1526030903041828e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.1859898424736457e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.840378088985744e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.531566102945362e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.816725317548844e-07
sam_encoder.blocks.8.norm1.weight grad: 5.78433309783577e-06
sam_encoder.blocks.8.norm1.bias grad: -2.95103745884262e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.122466740838718e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.685898718686076e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.2932425761391642e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.498160481285595e-07
sam_encoder.blocks.8.norm2.weight grad: 6.073063332223683e-07
sam_encoder.blocks.8.norm2.bias grad: 2.0465477064135484e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.0233469889017215e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.668608539759589e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.339886115507397e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.0947013013028482e-07
sam_encoder.blocks.9.norm1.weight grad: 1.655010578360816e-06
sam_encoder.blocks.9.norm1.bias grad: 5.30033830159482e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.14911664090323e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.795053301786538e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.0684782953139802e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.070205245123361e-07
sam_encoder.blocks.9.norm2.weight grad: -2.1010093860240886e-06
sam_encoder.blocks.9.norm2.bias grad: 1.3689017350770882e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.3976544980541803e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.442011466679105e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.90013018558966e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.63629737876181e-07
sam_encoder.blocks.10.norm1.weight grad: 2.0929519450874068e-08
sam_encoder.blocks.10.norm1.bias grad: 5.143086809766828e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.381719686032739e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.313685337820061e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.35710591723182e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.7297457450004003e-07
sam_encoder.blocks.10.norm2.weight grad: -3.7069639802211896e-06
sam_encoder.blocks.10.norm2.bias grad: -2.171475443901727e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.922746595388162e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.1304057352390373e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.995996624122199e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.683209174847434e-07
sam_encoder.blocks.11.norm1.weight grad: -1.567282924952451e-05
sam_encoder.blocks.11.norm1.bias grad: 1.433156171515293e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.1621494283863285e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.802622808914748e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1743879895220743e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.221480705586146e-07
sam_encoder.blocks.11.norm2.weight grad: -1.2314537798374658e-06
sam_encoder.blocks.11.norm2.bias grad: 1.541182427899912e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.988024784324807e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.763337978554773e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.285031647872529e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.690930606760958e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.343382897786796e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.5606092347297817e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.1066022125305608e-06
sam_encoder.neck.conv2.trainable_shift grad: 6.8869385358993895e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 4.632918717106804e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.4615070540457964e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0049527189694345
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00041043528472073376
mask_decoder.transformer.layers.0.norm3.weight grad: -2.310525087523274e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.549339503981173e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010110207949765027
mask_decoder.transformer.layers.0.norm4.bias grad: 7.95644155004993e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -4.1084047552431e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.52125176100526e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -6.410005880752578e-06
mask_decoder.transformer.layers.1.norm2.bias grad: -6.002603186061606e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.551986446836963e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.150230986648239e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.3481246393639594e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013732447405345738
mask_decoder.transformer.norm_final_attn.weight grad: -3.4315621633140836e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.5205327144940384e-05
Text_Embedding_Affine.0.weight grad: -5.906299321151165e-12
Text_Embedding_Affine.0.bias grad: -1.7456119882908183e-10
Text_Embedding_Affine.2.weight grad: 3.9607575032241105e-12
Text_Embedding_Affine.2.bias grad: -1.1661950338748284e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.437090122746568e-13
Max value: 0.9974615573883057
Mean value: 0.07755270600318909

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.437090122746568e-13
Max value: 0.9974615573883057
Mean value: 0.07755270600318909

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.071075439453125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12691496312618256

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058609962463378906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.071075439453125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 26.842103958129883
Max value: 68.85227966308594
Mean value: 53.64351272583008

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.538798757068279e-13
Max value: 0.9976648092269897
Mean value: 0.07849819958209991

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.538798757068279e-13
Max value: 0.9976648092269897
Mean value: 0.07849819958209991

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.538798757068279e-13
Max value: 0.9976648092269897
Mean value: 0.07849819958209991

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12717513740062714

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8577199578285217
Max value: 1.108687162399292
Mean value: 0.9997556805610657

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 26.842103958129883
Max value: 68.85227966308594
Mean value: 53.64351272583008

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.63603973388672
Max value: -53.63603973388672
Mean value: -53.63603973388672
sam_encoder.pos_embed grad: 2.3062642906523934e-09
sam_encoder.blocks.0.norm1.weight grad: 2.411247987765819e-05
sam_encoder.blocks.0.norm1.bias grad: 4.457917748368345e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.498301455489127e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.2190030196943553e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.093213182291947e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.6467650968697853e-06
sam_encoder.blocks.0.norm2.weight grad: 4.8945068556349725e-05
sam_encoder.blocks.0.norm2.bias grad: -5.9193022025283426e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.3090781976643484e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.487370228569489e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.1153431589482352e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.4889563317410648e-05
sam_encoder.blocks.1.norm1.weight grad: 2.6528066882747225e-05
sam_encoder.blocks.1.norm1.bias grad: 1.9964896637247875e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.34257412457373e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.0752049749717116e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.45413126423955e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.274624305049656e-06
sam_encoder.blocks.1.norm2.weight grad: 7.87636872701114e-06
sam_encoder.blocks.1.norm2.bias grad: -8.876041647454258e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.488686843411415e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.457924779264431e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3282656254887115e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.562289177556522e-07
sam_encoder.blocks.2.norm1.weight grad: -1.9498009351082146e-05
sam_encoder.blocks.2.norm1.bias grad: 1.312989024881972e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2410448107402772e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.516322405834217e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.486332262691576e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.7666054645815166e-06
sam_encoder.blocks.2.norm2.weight grad: -3.606964310165495e-05
sam_encoder.blocks.2.norm2.bias grad: 1.4334931393022998e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.238488377770409e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.118471563037019e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.099623639485799e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.5936456040653866e-06
sam_encoder.blocks.3.norm1.weight grad: -9.29771067603724e-06
sam_encoder.blocks.3.norm1.bias grad: 4.8939000407699496e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.010271474428009e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8833734429790638e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.198101916903397e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.428523425303865e-06
sam_encoder.blocks.3.norm2.weight grad: -1.2745712410833221e-05
sam_encoder.blocks.3.norm2.bias grad: 1.132880788645707e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1153689229104202e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.9986108529556077e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.454386609926587e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.9940853235311806e-06
sam_encoder.blocks.4.norm1.weight grad: -1.6656915249768645e-05
sam_encoder.blocks.4.norm1.bias grad: -1.055344910128042e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1070535038015805e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.710461325885262e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -5.097462235426065e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.059325642127078e-06
sam_encoder.blocks.4.norm2.weight grad: -6.920212172190077e-07
sam_encoder.blocks.4.norm2.bias grad: 1.6489639165229164e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.458464445633581e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.921335860468389e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.5788650620816043e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.9204749150958378e-06
sam_encoder.blocks.5.norm1.weight grad: 1.3524320365831954e-06
sam_encoder.blocks.5.norm1.bias grad: 1.357944142910128e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.031263870274415e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2696181102000992e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.1271126772480784e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.1918374386586947e-06
sam_encoder.blocks.5.norm2.weight grad: 4.92599792778492e-06
sam_encoder.blocks.5.norm2.bias grad: 4.297078703530133e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.0216948541929014e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.24009260263847e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.756405595187971e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.220761067903368e-07
sam_encoder.blocks.6.norm1.weight grad: 3.6313645068730693e-06
sam_encoder.blocks.6.norm1.bias grad: -3.757300873985514e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.605714821082074e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.8424237825674936e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.147260703277425e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.630066652884125e-07
sam_encoder.blocks.6.norm2.weight grad: 7.07871004124172e-06
sam_encoder.blocks.6.norm2.bias grad: 5.352628704713425e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.120881961469422e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.3823448575276416e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6996636986732483e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.578690658898267e-07
sam_encoder.blocks.7.norm1.weight grad: 1.0529444125495502e-06
sam_encoder.blocks.7.norm1.bias grad: -1.390993247696315e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.7591299840423744e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.051304025168065e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.676294432381383e-09
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.1702408048440702e-06
sam_encoder.blocks.7.norm2.weight grad: 2.353604941163212e-06
sam_encoder.blocks.7.norm2.bias grad: -7.085721875910167e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.4013479585628374e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.1154907869913586e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.1098171626144904e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.7959143860935e-06
sam_encoder.blocks.8.norm1.weight grad: -2.7682503969117533e-06
sam_encoder.blocks.8.norm1.bias grad: 2.725173999351682e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.4578299669665284e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.382948539685458e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.825913609034615e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.632001036952715e-06
sam_encoder.blocks.8.norm2.weight grad: 1.2889804565929808e-06
sam_encoder.blocks.8.norm2.bias grad: -6.308798106147151e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.240811873363782e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.9427377512547537e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.5348323851612804e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.10532560881893e-07
sam_encoder.blocks.9.norm1.weight grad: 9.058546197593387e-07
sam_encoder.blocks.9.norm1.bias grad: -6.467332696047379e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.1651075055851834e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.2523651921346755e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.9457197570081917e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.5241364432513365e-07
sam_encoder.blocks.9.norm2.weight grad: 7.054089792291052e-07
sam_encoder.blocks.9.norm2.bias grad: 3.6798769542656373e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.355276246315043e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.662582225340884e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.7626636861223233e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.963075070918421e-07
sam_encoder.blocks.10.norm1.weight grad: -2.41423413172015e-06
sam_encoder.blocks.10.norm1.bias grad: 3.4579170460347086e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.3380974905885523e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.986998985463288e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.0812966593221063e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.282561457737756e-07
sam_encoder.blocks.10.norm2.weight grad: 1.088802378035325e-06
sam_encoder.blocks.10.norm2.bias grad: -1.3291019058669917e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.214378345248406e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.3308368213292852e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.408034636251614e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.049730589234969e-07
sam_encoder.blocks.11.norm1.weight grad: -6.527826826641103e-06
sam_encoder.blocks.11.norm1.bias grad: 7.733921734143223e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.6517849417141406e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.0483898904567468e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.6177771107759327e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.6662852431181818e-06
sam_encoder.blocks.11.norm2.weight grad: -7.813150659785606e-06
sam_encoder.blocks.11.norm2.bias grad: 1.1401989468140528e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.270909246566589e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.2735958989651408e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.6617569182672014e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.374192255658272e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.9233145798789337e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.6625079297227785e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.858731361106038e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.8961470889043994e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 2.6929152227239683e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.898945917375386e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005053960718214512
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00035791221307590604
mask_decoder.transformer.layers.0.norm3.weight grad: -5.912702181376517e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.056040284514893e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00014567543985322118
mask_decoder.transformer.layers.0.norm4.bias grad: 5.467139089887496e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.31809715135023e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.7417379391845316e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 6.81917299516499e-07
mask_decoder.transformer.layers.1.norm2.bias grad: -7.921020005596802e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.257779700215906e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.688372766599059e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.353921005735174e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017333653522655368
mask_decoder.transformer.norm_final_attn.weight grad: 9.506097171652073e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.1418321264500264e-05
Text_Embedding_Affine.0.weight grad: 1.1808750158270875e-11
Text_Embedding_Affine.0.bias grad: 3.002666171258994e-11
Text_Embedding_Affine.2.weight grad: -1.3544043490909541e-11
Text_Embedding_Affine.2.bias grad: -7.486293270630995e-06
Epoch 28 finished with average loss: -59.6714
Epoch 29/39
----------
Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.5]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.00it/s, loss=-58.5]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.00it/s, loss=-57.4]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-57.4]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-60.5]Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-60.5]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.671541873977006e-11
Max value: 0.9993919134140015
Mean value: 0.09340862184762955

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.671541873977006e-11
Max value: 0.9993919134140015
Mean value: 0.09340862184762955

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08936548233032227

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13286736607551575

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08640575408935547

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08936548233032227

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.99299240112305
Max value: 73.21016693115234
Mean value: 58.4492301940918

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.671541873977006e-11
Max value: 0.9993919134140015
Mean value: 0.09340862184762955

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.671541873977006e-11
Max value: 0.9993919134140015
Mean value: 0.09340862184762955

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.671541873977006e-11
Max value: 0.9993919134140015
Mean value: 0.09340862184762955

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13286736607551575

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.99299240112305
Max value: 73.21016693115234
Mean value: 58.4492301940918

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.4504508972168
Max value: -58.4504508972168
Mean value: -58.4504508972168
sam_encoder.pos_embed grad: 4.306626166794558e-09
sam_encoder.blocks.0.norm1.weight grad: -5.1639126468217e-06
sam_encoder.blocks.0.norm1.bias grad: 1.7263429981539957e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0886201329849428e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.232811541740375e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.1118198699477944e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.672108045473578e-07
sam_encoder.blocks.0.norm2.weight grad: 1.4932254089217167e-05
sam_encoder.blocks.0.norm2.bias grad: -4.857423391513294e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.213555257592816e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.2545359570358414e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5578056263620965e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.703689799294807e-07
sam_encoder.blocks.1.norm1.weight grad: 1.189937574963551e-05
sam_encoder.blocks.1.norm1.bias grad: 1.5006869034550618e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 7.3034839260799345e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1808268709501135e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.9068182811897714e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 9.870093435893068e-07
sam_encoder.blocks.1.norm2.weight grad: -9.629427950130776e-06
sam_encoder.blocks.1.norm2.bias grad: 8.301400384880253e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.3123046705441084e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.0373063307488337e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.334137313184328e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.5561449799861293e-06
sam_encoder.blocks.2.norm1.weight grad: -3.227650950066163e-06
sam_encoder.blocks.2.norm1.bias grad: -8.902685294742696e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.389426072113565e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.8345951957599027e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.575124480903469e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.37813672660559e-07
sam_encoder.blocks.2.norm2.weight grad: -1.281472941627726e-05
sam_encoder.blocks.2.norm2.bias grad: -7.991123993633664e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.2042923925910145e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.023560328889289e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7616520128503907e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0701032806537114e-06
sam_encoder.blocks.3.norm1.weight grad: 9.424858944839798e-06
sam_encoder.blocks.3.norm1.bias grad: -4.605795766110532e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.4351029423996806e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.421951491754953e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.270974957558792e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.6869903447513934e-06
sam_encoder.blocks.3.norm2.weight grad: 1.2063212125212885e-05
sam_encoder.blocks.3.norm2.bias grad: 1.882606557046529e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.132548828143626e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.3310437882173574e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.948918951366068e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.1821902385663634e-08
sam_encoder.blocks.4.norm1.weight grad: 3.934773303626571e-06
sam_encoder.blocks.4.norm1.bias grad: 5.852541562489932e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.190730922142393e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.214239659930172e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.840538043841661e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.6625940588710364e-06
sam_encoder.blocks.4.norm2.weight grad: -1.2441766557458322e-05
sam_encoder.blocks.4.norm2.bias grad: 1.5950439546941197e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.615055437781848e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.8514539280877216e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.691049758141162e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.2992452411708655e-06
sam_encoder.blocks.5.norm1.weight grad: 4.274371804058319e-06
sam_encoder.blocks.5.norm1.bias grad: -4.669470854423707e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.9683325162041e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.7182469491672236e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.106437139242189e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.3818920453777537e-06
sam_encoder.blocks.5.norm2.weight grad: -3.990110144513892e-07
sam_encoder.blocks.5.norm2.bias grad: 5.9566391428234056e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.919370770854584e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.200493996606383e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1863395431864774e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.8986922611929913e-07
sam_encoder.blocks.6.norm1.weight grad: -2.732436314545339e-06
sam_encoder.blocks.6.norm1.bias grad: -4.670892849389929e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.923769552078738e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.299575387747609e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.2709107244954794e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.550767667727996e-08
sam_encoder.blocks.6.norm2.weight grad: 1.6374995084333932e-06
sam_encoder.blocks.6.norm2.bias grad: 3.2987823033181485e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.9919039004889783e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.1775675545777631e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.3789137938147178e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.9361742665278143e-07
sam_encoder.blocks.7.norm1.weight grad: -7.067273600114277e-06
sam_encoder.blocks.7.norm1.bias grad: -1.86723511319542e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.2838388506206684e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.2071908486177563e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.183969839592464e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2673830269704922e-06
sam_encoder.blocks.7.norm2.weight grad: 9.157787417279906e-07
sam_encoder.blocks.7.norm2.bias grad: 3.0598016564908903e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.319216494266584e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1969045772275422e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.273451033512174e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.296165911910066e-07
sam_encoder.blocks.8.norm1.weight grad: 4.0160233538699686e-07
sam_encoder.blocks.8.norm1.bias grad: -2.6647589024264562e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.548010797909228e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.775868991506286e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 7.93614105987217e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.7348780779211666e-07
sam_encoder.blocks.8.norm2.weight grad: -2.402789959887741e-06
sam_encoder.blocks.8.norm2.bias grad: 9.20963771022798e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.4130493986594956e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.8794879679262522e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.981211638252717e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.53039910755615e-07
sam_encoder.blocks.9.norm1.weight grad: -3.246456572014722e-06
sam_encoder.blocks.9.norm1.bias grad: -2.2854780468151148e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.9205248210928403e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.6496495618412155e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.005641577961796e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1593468798309914e-06
sam_encoder.blocks.9.norm2.weight grad: -6.375193152052816e-06
sam_encoder.blocks.9.norm2.bias grad: -2.623260115797166e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.860320586885791e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.197654223185964e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6359383607778e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.691805533089791e-07
sam_encoder.blocks.10.norm1.weight grad: -3.964381448895438e-06
sam_encoder.blocks.10.norm1.bias grad: -1.1393357226552325e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.3626638469286263e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.186110694106901e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.757431272788381e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.280724503289093e-07
sam_encoder.blocks.10.norm2.weight grad: -8.999475539894775e-06
sam_encoder.blocks.10.norm2.bias grad: -2.1953446776024066e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.6309581901150523e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.9685229492315557e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.658806791572715e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.225932563414972e-07
sam_encoder.blocks.11.norm1.weight grad: -7.489395102311391e-06
sam_encoder.blocks.11.norm1.bias grad: -9.544332897348795e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.985026069130981e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.956984179851133e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3717713045480195e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0021901744039496e-06
sam_encoder.blocks.11.norm2.weight grad: -7.159610504459124e-06
sam_encoder.blocks.11.norm2.bias grad: -4.191100742900744e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.503355732296768e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.0849795419053407e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.714852816003258e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.1860572019249958e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.759065970778465e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.578258424066007e-07
sam_encoder.neck.conv2.trainable_scale grad: 2.7884925657417625e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.26909378397977e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016285781748592854
mask_decoder.transformer.layers.0.norm1.bias grad: 1.7921847756952047e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002490720944479108
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002657659351825714
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00013662120909430087
mask_decoder.transformer.layers.0.norm3.bias grad: 9.900396253215149e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -1.815419818740338e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.6979611245915294e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.6757693528197706e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.309037416940555e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00038253856473602355
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00023057468933984637
mask_decoder.transformer.layers.1.norm3.weight grad: 4.035028541693464e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.007832755334675e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.565166353946552e-07
mask_decoder.transformer.layers.1.norm4.bias grad: -2.3433916794601828e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.849848781101173e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.343606972019188e-06
Text_Embedding_Affine.0.weight grad: 1.0738918435060363e-11
Text_Embedding_Affine.0.bias grad: 3.7765343630091763e-10
Text_Embedding_Affine.2.weight grad: 2.309479343876042e-11
Text_Embedding_Affine.2.bias grad: 2.266317096655257e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.303935250387191e-11
Max value: 0.9957393407821655
Mean value: 0.08470958471298218

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.303935250387191e-11
Max value: 0.9957393407821655
Mean value: 0.08470958471298218

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07356500625610352

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11425283551216125

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06487703323364258

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07356500625610352

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.02925491333008
Max value: 76.18447875976562
Mean value: 56.39680099487305

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.7536734137644245e-11
Max value: 0.9957577586174011
Mean value: 0.08398094773292542

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.7536734137644245e-11
Max value: 0.9957577586174011
Mean value: 0.08398094773292542

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.7536734137644245e-11
Max value: 0.9957577586174011
Mean value: 0.08398094773292542

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11390619724988937

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9200745224952698
Max value: 1.1160573959350586
Mean value: 1.000354290008545

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.02925491333008
Max value: 76.18447875976562
Mean value: 56.39680099487305

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.414546966552734
Max value: -56.414546966552734
Mean value: -56.414546966552734
sam_encoder.pos_embed grad: -3.504895040862266e-09
sam_encoder.blocks.0.norm1.weight grad: -5.526912718778476e-05
sam_encoder.blocks.0.norm1.bias grad: -5.384307587519288e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.49327035312308e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.463423468019755e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2494968359533232e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.622781827696599e-06
sam_encoder.blocks.0.norm2.weight grad: 5.1019385864492506e-05
sam_encoder.blocks.0.norm2.bias grad: -5.131874786457047e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 8.853002327668946e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.640581316081807e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 3.809573172475211e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.487550889578415e-05
sam_encoder.blocks.1.norm1.weight grad: 3.4405173209961504e-05
sam_encoder.blocks.1.norm1.bias grad: 5.681263792212121e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.6272726497845724e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.2122032937186304e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.8558817828306928e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.077185495698359e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0183716767642181e-05
sam_encoder.blocks.1.norm2.bias grad: -2.4940145522123203e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.2390619303914718e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.374679519969504e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.8529037333792076e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.8647673627469885e-08
sam_encoder.blocks.2.norm1.weight grad: -4.601918044500053e-05
sam_encoder.blocks.2.norm1.bias grad: 1.7526075680507347e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.064010161324404e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.254376552940812e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.1001116692787036e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.801085980143398e-06
sam_encoder.blocks.2.norm2.weight grad: -1.9298830011393875e-05
sam_encoder.blocks.2.norm2.bias grad: 1.3709096492675599e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.154092726414092e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.472655407676939e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.077685156924417e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.2901427908218466e-06
sam_encoder.blocks.3.norm1.weight grad: -6.470566404459532e-06
sam_encoder.blocks.3.norm1.bias grad: -3.911845851689577e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.2694210454355925e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.7907467483601067e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.669294750987319e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.0281716811277875e-07
sam_encoder.blocks.3.norm2.weight grad: -7.224882210721262e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0231410669803154e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.006924660236109e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.87613044444879e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.815715773380361e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.7323434892423393e-07
sam_encoder.blocks.4.norm1.weight grad: -1.492443243478192e-05
sam_encoder.blocks.4.norm1.bias grad: -1.897609035950154e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0702206054702401e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.799483346891066e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.4522970508987783e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.08130870507739e-06
sam_encoder.blocks.4.norm2.weight grad: 1.799397068680264e-05
sam_encoder.blocks.4.norm2.bias grad: 1.565641832712572e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.8198163464549e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.5305074612115277e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.981514267565217e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.86178453481989e-06
sam_encoder.blocks.5.norm1.weight grad: -9.441426300327294e-06
sam_encoder.blocks.5.norm1.bias grad: 1.3848146409145556e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.666859578923322e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.923993067975971e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.711371613870142e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.929181497776881e-06
sam_encoder.blocks.5.norm2.weight grad: 2.3106562366592698e-05
sam_encoder.blocks.5.norm2.bias grad: 1.91299159268965e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.851481652527582e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.512612238409929e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7684567410469754e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.395134838996455e-07
sam_encoder.blocks.6.norm1.weight grad: 2.0104635041207075e-06
sam_encoder.blocks.6.norm1.bias grad: 7.156567789934343e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.01230636271066e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.502337110854569e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.594445843191352e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0797883760460536e-06
sam_encoder.blocks.6.norm2.weight grad: 5.787705504189944e-06
sam_encoder.blocks.6.norm2.bias grad: 4.825809583053342e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.421591943857493e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.378671527163533e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.4529903031361755e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.251131945740781e-06
sam_encoder.blocks.7.norm1.weight grad: 1.5911216166841768e-07
sam_encoder.blocks.7.norm1.bias grad: 1.6163543250513612e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.7021603727916954e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.279858553170925e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.750127573061036e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.419991561619099e-06
sam_encoder.blocks.7.norm2.weight grad: 9.416696229891386e-06
sam_encoder.blocks.7.norm2.bias grad: -5.05924208482611e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.791530045622494e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.3731921626458643e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2731386505038245e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.454096243644017e-07
sam_encoder.blocks.8.norm1.weight grad: -1.3611438589578029e-05
sam_encoder.blocks.8.norm1.bias grad: 3.377469511178788e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -9.848085028352216e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.987111085734796e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.031972255485016e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.5206276202661684e-06
sam_encoder.blocks.8.norm2.weight grad: 1.670886922511272e-05
sam_encoder.blocks.8.norm2.bias grad: 6.982103286645724e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.5103162695595529e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.434135452262126e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.944481704820646e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.9843932932417374e-06
sam_encoder.blocks.9.norm1.weight grad: 2.4024679987633135e-06
sam_encoder.blocks.9.norm1.bias grad: 9.817715636017965e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.174771336489357e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.1340264285972808e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.687644609977724e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1940328477066942e-06
sam_encoder.blocks.9.norm2.weight grad: 8.067268936429173e-06
sam_encoder.blocks.9.norm2.bias grad: 1.1056470157200238e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.632244210573845e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.0935780159779824e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.445907284709392e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.4632289924729776e-08
sam_encoder.blocks.10.norm1.weight grad: 6.300327186181676e-06
sam_encoder.blocks.10.norm1.bias grad: -1.000499310066516e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.716593477700371e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.08731580642052e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.4060454986974946e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.489046419730585e-07
sam_encoder.blocks.10.norm2.weight grad: 1.1673311746562831e-05
sam_encoder.blocks.10.norm2.bias grad: 1.2886982858617557e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.958872407063609e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.0761544874403626e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5677318287998787e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.9163351200622856e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3272838259581476e-05
sam_encoder.blocks.11.norm1.bias grad: -1.4431559058891708e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.53225766250398e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -9.94823267319589e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.5790275230974657e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7748434402165003e-06
sam_encoder.blocks.11.norm2.weight grad: 9.253749340132345e-06
sam_encoder.blocks.11.norm2.bias grad: 3.2135837955138413e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.054123670968693e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.322571162949316e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.6082021627808e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.5598885144972883e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.517904355656356e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.241984788677655e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.668715412961319e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.9854302081512287e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.855936226202175e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.330882802605629e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0011326398234814405
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00024195900186896324
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00026818367769010365
mask_decoder.transformer.layers.0.norm3.bias grad: 3.760830077226274e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -4.024790177936666e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.4128541554091498e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.487220576265827e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.553999027237296e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00011503002315293998
mask_decoder.transformer.layers.1.norm2.bias grad: 2.7502199372975156e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.2126492694951594e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.246417564805597e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 6.826059689046815e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00018026650650426745
mask_decoder.transformer.norm_final_attn.weight grad: 1.1494371392473113e-05
mask_decoder.transformer.norm_final_attn.bias grad: -1.2034402061544824e-06
Text_Embedding_Affine.0.weight grad: 1.1616969539107735e-11
Text_Embedding_Affine.0.bias grad: -1.443267727552211e-10
Text_Embedding_Affine.2.weight grad: -7.996574930002609e-11
Text_Embedding_Affine.2.bias grad: -2.585378388175741e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.2104856006445175e-10
Max value: 0.9983474016189575
Mean value: 0.10039491951465607

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.2104856006445175e-10
Max value: 0.9983474016189575
Mean value: 0.10039491951465607

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09308815002441406

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.810892105102539
Max value: -1.1920928244535389e-07
Mean value: -0.11425124853849411

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09267997741699219

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09308815002441406

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 44.43608856201172
Max value: 92.09130096435547
Mean value: 66.49565124511719

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.34783683950424e-11
Max value: 0.9987732768058777
Mean value: 0.09882493317127228

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.34783683950424e-11
Max value: 0.9987732768058777
Mean value: 0.09882493317127228

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.34783683950424e-11
Max value: 0.9987732768058777
Mean value: 0.09882493317127228

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.053156852722168
Max value: -1.1920928244535389e-07
Mean value: -0.11403794586658478

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7848483920097351
Max value: 1.074694037437439
Mean value: 1.0002694129943848

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 44.43608856201172
Max value: 92.09130096435547
Mean value: 66.49565124511719

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.50813293457031
Max value: -66.50813293457031
Mean value: -66.50813293457031
sam_encoder.pos_embed grad: 1.44400347235063e-09
sam_encoder.blocks.0.norm1.weight grad: 3.6970457585994154e-05
sam_encoder.blocks.0.norm1.bias grad: -4.650615665013902e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.414914888504427e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.2938290555885033e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.8332589206693228e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.876582918062923e-07
sam_encoder.blocks.0.norm2.weight grad: 3.083102342316124e-07
sam_encoder.blocks.0.norm2.bias grad: -1.479003913118504e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0572002793196589e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.1744936045943177e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.97693054562842e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.033493840121082e-06
sam_encoder.blocks.1.norm1.weight grad: 8.671670912008267e-06
sam_encoder.blocks.1.norm1.bias grad: 9.51696256379364e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3591355809694505e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2438711110007716e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.3760541100491537e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.9023000277229585e-06
sam_encoder.blocks.1.norm2.weight grad: -5.296717063174583e-06
sam_encoder.blocks.1.norm2.bias grad: -2.6211055228486657e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.381926828500582e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.987851068312011e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.579783752793446e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.167306310089771e-07
sam_encoder.blocks.2.norm1.weight grad: -3.104426014033379e-06
sam_encoder.blocks.2.norm1.bias grad: 1.6393141777371056e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.701289415403153e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.90867647487903e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.6287848438878427e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.764890822021698e-07
sam_encoder.blocks.2.norm2.weight grad: -4.507966878009029e-06
sam_encoder.blocks.2.norm2.bias grad: -2.1754051431344124e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.7295712900231592e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.540044252124062e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.8336160034523346e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.000924367479456e-07
sam_encoder.blocks.3.norm1.weight grad: -1.2201510344311828e-06
sam_encoder.blocks.3.norm1.bias grad: 2.62766639025358e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.2004434211121406e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1078613937343107e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.7372832391847624e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.0895995476166718e-06
sam_encoder.blocks.3.norm2.weight grad: -6.506307727249805e-06
sam_encoder.blocks.3.norm2.bias grad: -8.598896670264367e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.4065767471911386e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.044268856276176e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.2597154182003578e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.254408392829646e-07
sam_encoder.blocks.4.norm1.weight grad: 4.052467375004198e-06
sam_encoder.blocks.4.norm1.bias grad: 7.700806463617482e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.5680113796843216e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2385442005324876e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.027762775469455e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.8344657039269805e-06
sam_encoder.blocks.4.norm2.weight grad: -1.9976182557002176e-06
sam_encoder.blocks.4.norm2.bias grad: 4.467000508157071e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.2289169717405457e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.8749315700006264e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.046887630058336e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.057309747120598e-07
sam_encoder.blocks.5.norm1.weight grad: 4.752017957798671e-06
sam_encoder.blocks.5.norm1.bias grad: 6.267746357480064e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.241411261318717e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.232202293977025e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.1128290680062491e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.8684544279021793e-07
sam_encoder.blocks.5.norm2.weight grad: -1.944920541063766e-06
sam_encoder.blocks.5.norm2.bias grad: 4.109429937670939e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.880933607229963e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.655963483761298e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.149730774675845e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.8087966680013778e-07
sam_encoder.blocks.6.norm1.weight grad: 5.133892045705579e-06
sam_encoder.blocks.6.norm1.bias grad: -1.7369693523505703e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.5942061913374346e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.8146504316973733e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.66616039982182e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.399084557211609e-07
sam_encoder.blocks.6.norm2.weight grad: 3.432598077779403e-06
sam_encoder.blocks.6.norm2.bias grad: 1.7626479120735894e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.8997125152964145e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.022271817419096e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.3967050449537055e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.6657550001327763e-07
sam_encoder.blocks.7.norm1.weight grad: -1.466323624299548e-06
sam_encoder.blocks.7.norm1.bias grad: -8.49355728860246e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.4080418395678862e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.526861054429901e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.104888032292365e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.5691846278496087e-07
sam_encoder.blocks.7.norm2.weight grad: 2.6764575977722416e-07
sam_encoder.blocks.7.norm2.bias grad: 1.3045573155068269e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.9062777779672615e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.010264262888086e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.3059172349348955e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.3313735653118783e-07
sam_encoder.blocks.8.norm1.weight grad: 4.183355883924378e-07
sam_encoder.blocks.8.norm1.bias grad: 2.781291073006287e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2594534837262472e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.858590614276181e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.0030103112512734e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.704247077024775e-07
sam_encoder.blocks.8.norm2.weight grad: -6.121789510871167e-07
sam_encoder.blocks.8.norm2.bias grad: 1.5362040812760824e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.6082528873084811e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.951950351525738e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.503891091189871e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.6453233203938e-07
sam_encoder.blocks.9.norm1.weight grad: 1.1187978543603094e-06
sam_encoder.blocks.9.norm1.bias grad: -3.4852655517170206e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.064723265808425e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.2645056080582435e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.2240668329231994e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.2755505091918167e-07
sam_encoder.blocks.9.norm2.weight grad: 1.1876618373207748e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6266785678453743e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.482865172874881e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.7123957363196496e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.151093086577021e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.03616251485073e-07
sam_encoder.blocks.10.norm1.weight grad: -1.4070986935621477e-06
sam_encoder.blocks.10.norm1.bias grad: 5.709127890440868e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.6159563074324979e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.580280794172722e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -7.648290534234548e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.406306063880038e-07
sam_encoder.blocks.10.norm2.weight grad: -1.651754928388982e-06
sam_encoder.blocks.10.norm2.bias grad: 7.045692882456933e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.2920813787786756e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.991021569367149e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.976337433821755e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.4811403654421156e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0992515854013618e-05
sam_encoder.blocks.11.norm1.bias grad: 7.899807314970531e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.990669483755482e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.5685328586841933e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.079788820694375e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.195922021996921e-08
sam_encoder.blocks.11.norm2.weight grad: -8.891726110960008e-07
sam_encoder.blocks.11.norm2.bias grad: 1.596268589310057e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.3666449376614764e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.863950492899448e-09
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.873851023352472e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.5521199376044024e-08
sam_encoder.neck.conv1.trainable_scale grad: 4.327939677750692e-07
sam_encoder.neck.conv1.trainable_shift grad: 7.1051244958653115e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.588434295437764e-07
sam_encoder.neck.conv2.trainable_shift grad: -5.9750195759988856e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 2.5530793209327385e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.36178345605731e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005121301859617233
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003221408696845174
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00011421209637774155
mask_decoder.transformer.layers.0.norm3.bias grad: 1.0268726327922195e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010565009142737836
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0798974471981637e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.878533814509865e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.480273906257935e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 4.8967598559102044e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -6.668265268672258e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.8823451430071145e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.2298754882067442e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.946860720636323e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00014258695591706783
mask_decoder.transformer.norm_final_attn.weight grad: -1.7827933334046975e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3254648365546018e-05
Text_Embedding_Affine.0.weight grad: -8.176534102566357e-12
Text_Embedding_Affine.0.bias grad: -3.554260774585316e-10
Text_Embedding_Affine.2.weight grad: -5.719339238319243e-11
Text_Embedding_Affine.2.bias grad: -1.1551894203876145e-05
Epoch 29 finished with average loss: -60.4577
Epoch 30/39
----------
Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.6]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-61.6]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-63.5]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-63.5]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-61.9]Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-61.9]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1190651703907317e-11
Max value: 0.999574601650238
Mean value: 0.07363241165876389

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1190651703907317e-11
Max value: 0.999574601650238
Mean value: 0.07363241165876389

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07183027267456055

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10157503932714462

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06440401077270508

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07183027267456055

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.998634338378906
Max value: 92.80663299560547
Mean value: 61.60672378540039

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1190651703907317e-11
Max value: 0.999574601650238
Mean value: 0.07363241165876389

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1190651703907317e-11
Max value: 0.999574601650238
Mean value: 0.07363241165876389

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1190651703907317e-11
Max value: 0.999574601650238
Mean value: 0.07363241165876389

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10157503932714462

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.998634338378906
Max value: 92.80663299560547
Mean value: 61.60672378540039

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.60773468017578
Max value: -61.60773468017578
Mean value: -61.60773468017578
sam_encoder.pos_embed grad: 3.917340674064462e-09
sam_encoder.blocks.0.norm1.weight grad: -7.308139174710959e-05
sam_encoder.blocks.0.norm1.bias grad: -2.7630425392999314e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.976883580340655e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.692814054076734e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.762963600223884e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.93679420085391e-06
sam_encoder.blocks.0.norm2.weight grad: -2.3903849069029093e-05
sam_encoder.blocks.0.norm2.bias grad: -4.639301187125966e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.818606299115345e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.224782504839823e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 6.181760454637697e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.013377269349803e-07
sam_encoder.blocks.1.norm1.weight grad: -1.5090272427187301e-06
sam_encoder.blocks.1.norm1.bias grad: 3.5225493775215e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.706672479594999e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.2940636767998512e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.0095313882629853e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2734617484966293e-06
sam_encoder.blocks.1.norm2.weight grad: -8.603804417361971e-06
sam_encoder.blocks.1.norm2.bias grad: 4.284359420125838e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.049384420388378e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.0544465567363659e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.757495718076825e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3083820249448763e-06
sam_encoder.blocks.2.norm1.weight grad: -1.3061360732535832e-05
sam_encoder.blocks.2.norm1.bias grad: 4.785949386132415e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.068576789810322e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.383923174420488e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.174176986751263e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.434210379462456e-07
sam_encoder.blocks.2.norm2.weight grad: 2.2094436644692905e-06
sam_encoder.blocks.2.norm2.bias grad: -2.0222644252498867e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 9.100189117816626e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.2355482112980098e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.8280599053687183e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.1453990822474225e-07
sam_encoder.blocks.3.norm1.weight grad: 2.532838607294252e-06
sam_encoder.blocks.3.norm1.bias grad: 5.7537940847396385e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.7906192795180687e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.328712983195146e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.685987040735199e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.1600405943900114e-06
sam_encoder.blocks.3.norm2.weight grad: -1.7057969671441242e-05
sam_encoder.blocks.3.norm2.bias grad: -3.708404619828798e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.362917828373611e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.316312697483227e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.6492772323981626e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.9416252143855672e-06
sam_encoder.blocks.4.norm1.weight grad: 1.2239397619850934e-06
sam_encoder.blocks.4.norm1.bias grad: -7.011067282292061e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.3067018471701886e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.1570437525042507e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.1726866584212985e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.3196076906751841e-06
sam_encoder.blocks.4.norm2.weight grad: 1.1013926268788055e-05
sam_encoder.blocks.4.norm2.bias grad: 8.027629519347101e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.585952749243006e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.8804413432226283e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.0799072924783104e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.4611352128213184e-07
sam_encoder.blocks.5.norm1.weight grad: 5.070618044555886e-06
sam_encoder.blocks.5.norm1.bias grad: 2.1451182874443475e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.232380888424814e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.0583709126876784e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.8040486793324817e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.4524906621081755e-06
sam_encoder.blocks.5.norm2.weight grad: 5.784079803561326e-06
sam_encoder.blocks.5.norm2.bias grad: 4.4118482946942095e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.0379054603836266e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.011365156955435e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.6527764046259108e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.098566806642339e-07
sam_encoder.blocks.6.norm1.weight grad: -8.635808512735821e-07
sam_encoder.blocks.6.norm1.bias grad: -2.3989314286154695e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.7347574043924396e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.59731233806815e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0056409109893139e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.96819631937251e-07
sam_encoder.blocks.6.norm2.weight grad: 3.012227807630552e-06
sam_encoder.blocks.6.norm2.bias grad: 3.5480893529893365e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.97281290437968e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.9359648578974884e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.653035716728482e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.165681381593458e-07
sam_encoder.blocks.7.norm1.weight grad: -2.8305264549999265e-06
sam_encoder.blocks.7.norm1.bias grad: -1.4245670172385871e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.4193509489123244e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.3482703025147202e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.059824737443705e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.80373931977374e-07
sam_encoder.blocks.7.norm2.weight grad: 1.8419359548715875e-06
sam_encoder.blocks.7.norm2.bias grad: -6.628213213843992e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.7405870949005475e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.7276610719818564e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.4853756056254497e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.3664297284776694e-06
sam_encoder.blocks.8.norm1.weight grad: -4.7671601350884885e-06
sam_encoder.blocks.8.norm1.bias grad: 7.855660442146473e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.3483279366919305e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.746204341354314e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.116708623769227e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.75485706172185e-06
sam_encoder.blocks.8.norm2.weight grad: -1.780359980330104e-06
sam_encoder.blocks.8.norm2.bias grad: 2.138777972504613e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.2725106393627357e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.7461419474784634e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.1526725529620307e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.4401621228898875e-07
sam_encoder.blocks.9.norm1.weight grad: 6.922720103830216e-07
sam_encoder.blocks.9.norm1.bias grad: -8.04536682608159e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0729081623139791e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.146668394852895e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.657459152847878e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.7082277281588176e-07
sam_encoder.blocks.9.norm2.weight grad: -2.6191453343926696e-06
sam_encoder.blocks.9.norm2.bias grad: 1.3432502328214468e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.807729399341042e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.3713747648580465e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.284788701625075e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.1734878664101416e-07
sam_encoder.blocks.10.norm1.weight grad: -5.047888407716528e-06
sam_encoder.blocks.10.norm1.bias grad: -2.8028443921357393e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.2453081075800583e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.3932998399468488e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.7932304672285682e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.956365829566494e-07
sam_encoder.blocks.10.norm2.weight grad: -6.6522311499284115e-06
sam_encoder.blocks.10.norm2.bias grad: -1.6163767213583924e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.580225777317537e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.791075533219555e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.5150773075874895e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.1084442753126496e-07
sam_encoder.blocks.11.norm1.weight grad: -1.7649039364187047e-05
sam_encoder.blocks.11.norm1.bias grad: 4.740247163681488e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.514655195933301e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.108589675728581e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.7782638224161929e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.772454975769506e-07
sam_encoder.blocks.11.norm2.weight grad: -7.976645065355115e-06
sam_encoder.blocks.11.norm2.bias grad: -6.475142981798854e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.823229119210737e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.600616997166071e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.60525870443962e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.509834176744334e-08
sam_encoder.neck.conv1.trainable_scale grad: 5.127731128595769e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.853936505038291e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.058754151017638e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.2623157090274617e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001368540688417852
mask_decoder.transformer.layers.0.norm1.bias grad: -2.1878076950088143e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004032635595649481
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00034076557494699955
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00010883996583288535
mask_decoder.transformer.layers.0.norm3.bias grad: 9.608513209968805e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00015534313570242375
mask_decoder.transformer.layers.0.norm4.bias grad: 6.892891633469844e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.813580067595467e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.1910960893146694e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001649640907999128
mask_decoder.transformer.layers.1.norm2.bias grad: -3.58987927029375e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.650262781069614e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.286791979917325e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.0062103178352118e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001599600655026734
mask_decoder.transformer.norm_final_attn.weight grad: -2.4812975425447803e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.0823733646248002e-05
Text_Embedding_Affine.0.weight grad: -8.085634592425173e-12
Text_Embedding_Affine.0.bias grad: -1.760687151630691e-10
Text_Embedding_Affine.2.weight grad: -3.11878578518332e-11
Text_Embedding_Affine.2.bias grad: -3.0686594982398674e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.8111545791767159e-13
Max value: 0.9973759651184082
Mean value: 0.09609997272491455

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.8111545791767159e-13
Max value: 0.9973759651184082
Mean value: 0.09609997272491455

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09508132934570312

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1285305619239807

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0920724868774414

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09508132934570312

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.319515228271484
Max value: 78.697509765625
Mean value: 65.43013000488281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.38560996986066e-13
Max value: 0.9977546334266663
Mean value: 0.0947401374578476

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.38560996986066e-13
Max value: 0.9977546334266663
Mean value: 0.0947401374578476

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.38560996986066e-13
Max value: 0.9977546334266663
Mean value: 0.0947401374578476

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12857094407081604

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7207649946212769
Max value: 1.0763837099075317
Mean value: 1.00001859664917

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.319515228271484
Max value: 78.697509765625
Mean value: 65.43013000488281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.43376159667969
Max value: -65.43376159667969
Mean value: -65.43376159667969
sam_encoder.pos_embed grad: 4.819837862157783e-09
sam_encoder.blocks.0.norm1.weight grad: -9.216203761752695e-05
sam_encoder.blocks.0.norm1.bias grad: -5.785027678939514e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.6407170733145904e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.243471600304474e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.48420848645037e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.3999356219283072e-06
sam_encoder.blocks.0.norm2.weight grad: -6.0443388065323234e-05
sam_encoder.blocks.0.norm2.bias grad: -3.722077963175252e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.666905518504791e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.3100274145472213e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.92426957457792e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.561175152659416e-06
sam_encoder.blocks.1.norm1.weight grad: -1.6625339185338817e-06
sam_encoder.blocks.1.norm1.bias grad: 2.1106541680637747e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.097608995034534e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.4784499171582866e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.8744343606158509e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.7560657801805064e-06
sam_encoder.blocks.1.norm2.weight grad: -2.126542676705867e-05
sam_encoder.blocks.1.norm2.bias grad: -7.2155107773141935e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.5271350548573537e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.3019546208379325e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.8076251510356087e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.9288581825094298e-06
sam_encoder.blocks.2.norm1.weight grad: 7.776254278724082e-06
sam_encoder.blocks.2.norm1.bias grad: 6.38386973150773e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.7367614191243774e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.775473826157395e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.665868800657336e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.7177217159769498e-07
sam_encoder.blocks.2.norm2.weight grad: 6.900581411173334e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0011742688220693e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.138596967910416e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.870511128909129e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.89963269198779e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.8343569030985236e-07
sam_encoder.blocks.3.norm1.weight grad: -1.17210038297344e-06
sam_encoder.blocks.3.norm1.bias grad: 1.092744423658587e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.6778131945757195e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.702071237261407e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.2200023269979283e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.7995832258275186e-07
sam_encoder.blocks.3.norm2.weight grad: -1.1627234925981611e-05
sam_encoder.blocks.3.norm2.bias grad: 7.394001841021236e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1225989510421641e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.76753291170462e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.4308145182440057e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.185079893024522e-06
sam_encoder.blocks.4.norm1.weight grad: -1.986213646887336e-05
sam_encoder.blocks.4.norm1.bias grad: -6.180578566272743e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.8203278159489855e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.733634679927491e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.227548455062788e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.0017102795245592e-05
sam_encoder.blocks.4.norm2.weight grad: 4.446153616299853e-05
sam_encoder.blocks.4.norm2.bias grad: 1.8446477042743936e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.1317547836806625e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.1160754183947574e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.2400240595743526e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.775433702277951e-06
sam_encoder.blocks.5.norm1.weight grad: -6.294683316809824e-06
sam_encoder.blocks.5.norm1.bias grad: -6.4377904891443904e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.34843275595631e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.966266947623808e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.594226998553495e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.6037627069163136e-06
sam_encoder.blocks.5.norm2.weight grad: 3.706961069838144e-05
sam_encoder.blocks.5.norm2.bias grad: -6.651082912867423e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.074767169484403e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.634099584814976e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.314001216698671e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4325621577881975e-06
sam_encoder.blocks.6.norm1.weight grad: 5.245692591415718e-06
sam_encoder.blocks.6.norm1.bias grad: -6.790052339056274e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.480351324469666e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.8257774172525387e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.019801842034212e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.4748311514267698e-06
sam_encoder.blocks.6.norm2.weight grad: 1.6263093129964545e-05
sam_encoder.blocks.6.norm2.bias grad: 4.148295374761801e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.168071867141407e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.689891168003669e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.7050606402335688e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.345805326825939e-07
sam_encoder.blocks.7.norm1.weight grad: -1.8075310208587325e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4664231002825545e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.505844905608683e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.877702629826672e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.9170231502794195e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0203260671914904e-06
sam_encoder.blocks.7.norm2.weight grad: 1.372436872770777e-05
sam_encoder.blocks.7.norm2.bias grad: -4.497043391893385e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.926176062435843e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.166424325077969e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.3532265913672745e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2941054592374712e-06
sam_encoder.blocks.8.norm1.weight grad: 3.4074444101861445e-06
sam_encoder.blocks.8.norm1.bias grad: 7.102283916537999e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.439905635284958e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.324667533088359e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.691076919196348e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.227065801387653e-06
sam_encoder.blocks.8.norm2.weight grad: 3.5790267247648444e-06
sam_encoder.blocks.8.norm2.bias grad: 5.005739694752265e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.2737350466049975e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.8718046135290933e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.325952881525154e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.053098052736459e-07
sam_encoder.blocks.9.norm1.weight grad: 2.6701476940615976e-07
sam_encoder.blocks.9.norm1.bias grad: 3.995573479187442e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.3381884400587296e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.193166998651577e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.385933950994513e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.9471291327354265e-06
sam_encoder.blocks.9.norm2.weight grad: 7.912334694992751e-06
sam_encoder.blocks.9.norm2.bias grad: 4.264034942025319e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.513221367436927e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.5321579616720555e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.484263970676693e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.439000925529399e-06
sam_encoder.blocks.10.norm1.weight grad: -6.4826699599507265e-06
sam_encoder.blocks.10.norm1.bias grad: 8.403139304391516e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.128273758396972e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.065701894731319e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.201654620483168e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.198718895371712e-07
sam_encoder.blocks.10.norm2.weight grad: -2.023774868575856e-06
sam_encoder.blocks.10.norm2.bias grad: -8.10965445907641e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.1309283536320436e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.2956510292715393e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.4339411791297607e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.203540981961851e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3320459402166307e-06
sam_encoder.blocks.11.norm1.bias grad: -7.146597340579319e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.692526196478866e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.887304261406825e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.056017471360974e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.163765368048189e-07
sam_encoder.blocks.11.norm2.weight grad: 8.958601938502397e-06
sam_encoder.blocks.11.norm2.bias grad: 2.2919752495909052e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.386542402949999e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.251486274142735e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.304456756974105e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.4868904827380902e-06
sam_encoder.neck.conv1.trainable_scale grad: 4.173882189206779e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.73907751054503e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.5489774745656177e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.498219823290128e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010754591494332999
mask_decoder.transformer.layers.0.norm1.bias grad: 6.2222679844126105e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.001939093228429556
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004108005668967962
mask_decoder.transformer.layers.0.norm3.weight grad: 0.000176820409251377
mask_decoder.transformer.layers.0.norm3.bias grad: 7.29351449990645e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012533502012956887
mask_decoder.transformer.layers.0.norm4.bias grad: 2.6170164346694946e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.5283312677638605e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -8.400287697440945e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002686668303795159
mask_decoder.transformer.layers.1.norm2.bias grad: 7.070293213473633e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.316903404192999e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.0057992514921352e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.2721582000667695e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002543314185459167
mask_decoder.transformer.norm_final_attn.weight grad: 1.1351148714311421e-05
mask_decoder.transformer.norm_final_attn.bias grad: -1.4985744201112539e-06
Text_Embedding_Affine.0.weight grad: 1.586384842933164e-11
Text_Embedding_Affine.0.bias grad: 9.540118695028355e-11
Text_Embedding_Affine.2.weight grad: -7.688564368502071e-11
Text_Embedding_Affine.2.bias grad: 6.246058546821587e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.487596877960186e-10
Max value: 0.992931604385376
Mean value: 0.0892898440361023

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.487596877960186e-10
Max value: 0.992931604385376
Mean value: 0.0892898440361023

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08482074737548828

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.20228385925293
Max value: -1.1920928244535389e-07
Mean value: -0.11895869672298431

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07944774627685547

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08482074737548828

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 53.09596252441406
Max value: 66.84919738769531
Mean value: 58.76748275756836

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.6648193934543087e-10
Max value: 0.994419515132904
Mean value: 0.08589068055152893

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.6648193934543087e-10
Max value: 0.994419515132904
Mean value: 0.08589068055152893

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.6648193934543087e-10
Max value: 0.994419515132904
Mean value: 0.08589068055152893

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.604443550109863
Max value: -1.1920928244535389e-07
Mean value: -0.11851316690444946

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5597654581069946
Max value: 1.0912808179855347
Mean value: 1.000670075416565

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 53.09596252441406
Max value: 66.84919738769531
Mean value: 58.76748275756836

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.80783462524414
Max value: -58.80783462524414
Mean value: -58.80783462524414
sam_encoder.pos_embed grad: -4.568102784929806e-09
sam_encoder.blocks.0.norm1.weight grad: -3.009219653904438e-05
sam_encoder.blocks.0.norm1.bias grad: -4.45264668087475e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.160773520809016e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.990661737901974e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.085344128019642e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.425821308970626e-07
sam_encoder.blocks.0.norm2.weight grad: 4.2051877244375646e-05
sam_encoder.blocks.0.norm2.bias grad: 3.6681717574538197e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.867896721971192e-08
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.677172154605614e-08
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8549875676399097e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.965474989963695e-06
sam_encoder.blocks.1.norm1.weight grad: 3.124434078927152e-05
sam_encoder.blocks.1.norm1.bias grad: 3.457791899563745e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.1896458090632223e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.254468876752071e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.2651225915760733e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.203703040024266e-06
sam_encoder.blocks.1.norm2.weight grad: 1.751467789290473e-05
sam_encoder.blocks.1.norm2.bias grad: -9.053410394699313e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.8250076411495684e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7457685999033856e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.779499694355763e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.71511765959076e-07
sam_encoder.blocks.2.norm1.weight grad: -2.965709791169502e-05
sam_encoder.blocks.2.norm1.bias grad: 8.769498890615068e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.9736609829124063e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.835679530719062e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.0519578609091695e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.3108925688575255e-06
sam_encoder.blocks.2.norm2.weight grad: -1.9391065507079475e-05
sam_encoder.blocks.2.norm2.bias grad: 1.576725480845198e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.595636786078103e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.896533598890528e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.3168937584850937e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.562433441104076e-07
sam_encoder.blocks.3.norm1.weight grad: -1.8723414541454986e-05
sam_encoder.blocks.3.norm1.bias grad: 3.6084456951357424e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.256466693026596e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.131756779519492e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.720608558272943e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.812440804220387e-07
sam_encoder.blocks.3.norm2.weight grad: -4.149128926655976e-06
sam_encoder.blocks.3.norm2.bias grad: 1.4235547496355139e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.004981524805771e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.6393340018794333e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.0731964721344411e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.4148005789138551e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0278816262143664e-05
sam_encoder.blocks.4.norm1.bias grad: 1.346658518031063e-08
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0364774425397627e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.421485189392115e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.4017988329869695e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.2713476230128435e-06
sam_encoder.blocks.4.norm2.weight grad: 8.243388947448693e-06
sam_encoder.blocks.4.norm2.bias grad: 9.689529179013334e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.5350833564298227e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.299600166428718e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.4156785255181603e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.2718056647572666e-07
sam_encoder.blocks.5.norm1.weight grad: 5.486780537466984e-06
sam_encoder.blocks.5.norm1.bias grad: -2.5624535737733822e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.997507858206518e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.6111926015582867e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.0201939605613006e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.168481948203407e-06
sam_encoder.blocks.5.norm2.weight grad: 1.5806162991793826e-05
sam_encoder.blocks.5.norm2.bias grad: 1.7474598053013324e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.3831252039817628e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.288928039386519e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.6801972126122564e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.879867994603046e-07
sam_encoder.blocks.6.norm1.weight grad: 3.5105404094792902e-06
sam_encoder.blocks.6.norm1.bias grad: -2.584845560704707e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.222875188337639e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.81332756660413e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.165242451861559e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.550549293635413e-07
sam_encoder.blocks.6.norm2.weight grad: 1.2268311365914997e-05
sam_encoder.blocks.6.norm2.bias grad: 8.086590241873637e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.76275431032991e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.975206371047534e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.3594454887643224e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.2890717471236712e-06
sam_encoder.blocks.7.norm1.weight grad: 2.7320584194967523e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0112511290572002e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.3240355555317365e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6365802366635762e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.6436990740185138e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.024168790943804e-06
sam_encoder.blocks.7.norm2.weight grad: -4.767968562191527e-07
sam_encoder.blocks.7.norm2.bias grad: -1.7127888440882089e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0046171610156307e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.930678063734376e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.6417277493019355e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.470192157488782e-07
sam_encoder.blocks.8.norm1.weight grad: 6.09240441917791e-06
sam_encoder.blocks.8.norm1.bias grad: 3.162479970342247e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.277455551957246e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.531374548198073e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.209827473758196e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.225259513963465e-08
sam_encoder.blocks.8.norm2.weight grad: 4.1715170482348185e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4725835626450134e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.8386209578457056e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.418495230609551e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.0209954552919953e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.817148090476621e-08
sam_encoder.blocks.9.norm1.weight grad: 7.189771622506669e-06
sam_encoder.blocks.9.norm1.bias grad: 8.568517841922585e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.448771389637841e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.736695705607417e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.6659085986248101e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 8.289836728181399e-07
sam_encoder.blocks.9.norm2.weight grad: 5.605127626040485e-06
sam_encoder.blocks.9.norm2.bias grad: 1.0733368753790273e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.148844709561672e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.05408934764273e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.98823970013018e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.3168686286444427e-07
sam_encoder.blocks.10.norm1.weight grad: -2.464644239807967e-07
sam_encoder.blocks.10.norm1.bias grad: 1.2848363439843524e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1256863672315376e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.540304073292646e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.746236908521496e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.691121150950494e-07
sam_encoder.blocks.10.norm2.weight grad: 9.719324225443415e-07
sam_encoder.blocks.10.norm2.bias grad: -2.6074594643432647e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.5559934354314464e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.506772365355573e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.9550726594607113e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.4507438663713401e-06
sam_encoder.blocks.11.norm1.weight grad: 1.2394992154440843e-05
sam_encoder.blocks.11.norm1.bias grad: 2.8975446184631437e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.499705366673879e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.505598902440397e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2108625924156513e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.325585673039313e-07
sam_encoder.blocks.11.norm2.weight grad: -6.098118205954961e-07
sam_encoder.blocks.11.norm2.bias grad: -2.556402591835649e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.8474208900443045e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.5750017584869056e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3000355920667062e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.486795492335659e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.994381015421823e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.6773148420033976e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.1485902834683657e-07
sam_encoder.neck.conv2.trainable_shift grad: -6.518277223221958e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 7.179082604125142e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.0739167919382453e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0044192057102918625
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005465043941512704
mask_decoder.transformer.layers.0.norm3.weight grad: 4.390778485685587e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 7.657469541300088e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011386909318389371
mask_decoder.transformer.layers.0.norm4.bias grad: -1.6574495020904578e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 5.224431515671313e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.7366717151599005e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00015209961566142738
mask_decoder.transformer.layers.1.norm2.bias grad: 1.4182718587107956e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.1036073525901884e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -7.915235983091407e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -1.0725922038545832e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.359863229794428e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0972075870085973e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.7642072634771466e-05
Text_Embedding_Affine.0.weight grad: 6.189769183317928e-12
Text_Embedding_Affine.0.bias grad: 1.388073961328118e-10
Text_Embedding_Affine.2.weight grad: -3.106464391278152e-11
Text_Embedding_Affine.2.bias grad: 8.143231752910651e-06
Epoch 30 finished with average loss: -61.9498
Epoch 31/39
----------
Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.6]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-57.6]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-61.2]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-61.2]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-60.9]Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-60.9]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.502828874335731e-13
Max value: 0.9987943172454834
Mean value: 0.07000430673360825

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.502828874335731e-13
Max value: 0.9987943172454834
Mean value: 0.07000430673360825

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0727381706237793

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11003623902797699

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06173372268676758

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0727381706237793

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.93300247192383
Max value: 72.30631256103516
Mean value: 57.564239501953125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.502828874335731e-13
Max value: 0.9987943172454834
Mean value: 0.07000430673360825

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.502828874335731e-13
Max value: 0.9987943172454834
Mean value: 0.07000430673360825

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.502828874335731e-13
Max value: 0.9987943172454834
Mean value: 0.07000430673360825

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11003623902797699

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.93300247192383
Max value: 72.30631256103516
Mean value: 57.564239501953125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.565181732177734
Max value: -57.565181732177734
Mean value: -57.565181732177734
sam_encoder.pos_embed grad: 5.387329471417956e-10
sam_encoder.blocks.0.norm1.weight grad: -5.016497379983775e-05
sam_encoder.blocks.0.norm1.bias grad: -3.1605992262484506e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.968700639234157e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.099299306086323e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.279860839531466e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.542212875297992e-07
sam_encoder.blocks.0.norm2.weight grad: -2.1142948753549717e-05
sam_encoder.blocks.0.norm2.bias grad: -1.4847339116386138e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.804079359630123e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.815108241018606e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.35148205421865e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.3708531696465798e-06
sam_encoder.blocks.1.norm1.weight grad: -9.525399036647286e-06
sam_encoder.blocks.1.norm1.bias grad: 8.432218237430789e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.5241023397247773e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.676479872818163e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.026679339905968e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4079499806030071e-06
sam_encoder.blocks.1.norm2.weight grad: -1.532567330286838e-05
sam_encoder.blocks.1.norm2.bias grad: -4.405341769597726e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.479107123093854e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.370828593091574e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.687713837687625e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.431554063126896e-08
sam_encoder.blocks.2.norm1.weight grad: -6.402252893167315e-06
sam_encoder.blocks.2.norm1.bias grad: 1.1684051060001366e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.322115612216294e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3554057431974798e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 8.545729315301287e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.2640305158129195e-07
sam_encoder.blocks.2.norm2.weight grad: 6.850875251984689e-06
sam_encoder.blocks.2.norm2.bias grad: -9.145678347977082e-08
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.4317508834647015e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.135195245500654e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.4488454073434696e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.9939633943977242e-07
sam_encoder.blocks.3.norm1.weight grad: 4.534478193818359e-06
sam_encoder.blocks.3.norm1.bias grad: 4.0099466787069105e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.960854766977718e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 9.295566982814307e-09
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.507946975238156e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.2913275188329862e-07
sam_encoder.blocks.3.norm2.weight grad: -2.7093079552287236e-05
sam_encoder.blocks.3.norm2.bias grad: -1.0153084986086469e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.871268977993168e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.30560816716752e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.7372601582319476e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0507652632441022e-06
sam_encoder.blocks.4.norm1.weight grad: -5.571301699092146e-06
sam_encoder.blocks.4.norm1.bias grad: -6.923239084244415e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.439933379922877e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5857465314184083e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.4505639001072268e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.1507820494880434e-06
sam_encoder.blocks.4.norm2.weight grad: 2.2415413695853204e-05
sam_encoder.blocks.4.norm2.bias grad: 9.314543603977654e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.537036951049231e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 6.012561243551318e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.1236049835570157e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.058421260808245e-07
sam_encoder.blocks.5.norm1.weight grad: -1.1025852018065052e-06
sam_encoder.blocks.5.norm1.bias grad: 6.325129561446374e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.193897216784535e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.8585485577204963e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.721844682833762e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1076938335463637e-06
sam_encoder.blocks.5.norm2.weight grad: 1.356102256977465e-05
sam_encoder.blocks.5.norm2.bias grad: 6.9731813709950075e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.257148364355089e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.2386826711008325e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.81548489308625e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.0033561466116225e-06
sam_encoder.blocks.6.norm1.weight grad: -3.433588062762283e-06
sam_encoder.blocks.6.norm1.bias grad: -2.863057943613967e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.0775823966469034e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.375844799957122e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.8077657841786277e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.673426469205879e-07
sam_encoder.blocks.6.norm2.weight grad: 4.587433977576438e-06
sam_encoder.blocks.6.norm2.bias grad: 2.5687156721687643e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.4538903769789613e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.627925692257122e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.580118400099309e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0479187412547617e-07
sam_encoder.blocks.7.norm1.weight grad: 1.7612017018109327e-06
sam_encoder.blocks.7.norm1.bias grad: -1.1690649444062728e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.576016744475055e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.727486834279262e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.785804084254778e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.784395504335407e-07
sam_encoder.blocks.7.norm2.weight grad: -4.451928248272452e-07
sam_encoder.blocks.7.norm2.bias grad: -2.7702033094101353e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.4115069006948033e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.3283724911161698e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 8.171563194991904e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.913462928219815e-07
sam_encoder.blocks.8.norm1.weight grad: 3.580443888040463e-07
sam_encoder.blocks.8.norm1.bias grad: 3.5862326512869913e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.397780106861319e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.274227987683844e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.4075583243975416e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.073020823445404e-06
sam_encoder.blocks.8.norm2.weight grad: 8.351521501026582e-07
sam_encoder.blocks.8.norm2.bias grad: 1.7978071582547273e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.1209349395358004e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.3455697828467237e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.652793682500487e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.728027758777898e-07
sam_encoder.blocks.9.norm1.weight grad: 3.6479668779065832e-06
sam_encoder.blocks.9.norm1.bias grad: 1.7753717429513927e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.756096364464611e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1865647131514834e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.508891950332327e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.345587166833866e-07
sam_encoder.blocks.9.norm2.weight grad: 1.7935312826011796e-06
sam_encoder.blocks.9.norm2.bias grad: 1.7818047126638703e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.342000003518478e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.9889426994268433e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.069822226592805e-09
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.480339950736379e-07
sam_encoder.blocks.10.norm1.weight grad: -1.969253162314999e-06
sam_encoder.blocks.10.norm1.bias grad: 1.3246943808553624e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.5837698583709425e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.649326564911462e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6152191619767109e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.075986574505805e-06
sam_encoder.blocks.10.norm2.weight grad: 1.0464925708220107e-06
sam_encoder.blocks.10.norm2.bias grad: 4.680379674937285e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.223456926411018e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.9589543260044593e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.7139157405572405e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.1740392475730914e-07
sam_encoder.blocks.11.norm1.weight grad: -1.1568834452191368e-05
sam_encoder.blocks.11.norm1.bias grad: 8.85226313585008e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.4328107883775374e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.27478500644429e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4866020592307905e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.746657158553717e-07
sam_encoder.blocks.11.norm2.weight grad: 2.398503966105636e-06
sam_encoder.blocks.11.norm2.bias grad: 1.6384974514949135e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.1133398553938605e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.271201194365858e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.349204788122734e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.04342364643162e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.3049339031567797e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.2022606572136283e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.6608801161055453e-06
sam_encoder.neck.conv2.trainable_shift grad: -6.391755050572101e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001396683946950361
mask_decoder.transformer.layers.0.norm1.bias grad: 2.6433917810209095e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004135173745453358
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00038313085678964853
mask_decoder.transformer.layers.0.norm3.weight grad: 7.891803397797048e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.082949893316254e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00016775033145677298
mask_decoder.transformer.layers.0.norm4.bias grad: 1.1567546607693657e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -4.6996465243864805e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.277876435779035e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -3.1190720619633794e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00010599419329082593
mask_decoder.transformer.layers.1.norm3.weight grad: -6.909146759426221e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.558819637168199e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.062572068301961e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00020897440845146775
mask_decoder.transformer.norm_final_attn.weight grad: -2.410089791737846e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.5713654647697695e-05
Text_Embedding_Affine.0.weight grad: -3.0481901724943583e-12
Text_Embedding_Affine.0.bias grad: -9.821156388145624e-11
Text_Embedding_Affine.2.weight grad: -2.8636249621571963e-11
Text_Embedding_Affine.2.bias grad: -2.9379643819993362e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.161171291034495e-13
Max value: 0.9984532594680786
Mean value: 0.0868934765458107

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.161171291034495e-13
Max value: 0.9984532594680786
Mean value: 0.0868934765458107

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09334039688110352

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12195988744497299

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08162927627563477

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09334039688110352

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.634159088134766
Max value: 93.53402709960938
Mean value: 64.87791442871094

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.056956372748167e-13
Max value: 0.998529314994812
Mean value: 0.08596493303775787

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.056956372748167e-13
Max value: 0.998529314994812
Mean value: 0.08596493303775787

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.056956372748167e-13
Max value: 0.998529314994812
Mean value: 0.08596493303775787

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12216529995203018

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.765592634677887
Max value: 1.0474694967269897
Mean value: 0.9998231530189514

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.634159088134766
Max value: 93.53402709960938
Mean value: 64.87791442871094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.86918640136719
Max value: -64.86918640136719
Mean value: -64.86918640136719
sam_encoder.pos_embed grad: -1.1821529311006884e-09
sam_encoder.blocks.0.norm1.weight grad: 2.9156242817407474e-05
sam_encoder.blocks.0.norm1.bias grad: 1.3827989278070163e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.545801862652297e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.173968903842251e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.300332542086835e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.1802026165241841e-06
sam_encoder.blocks.0.norm2.weight grad: 8.978852747532073e-06
sam_encoder.blocks.0.norm2.bias grad: -1.7273216599278385e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0884090073659536e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.239026338836993e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.87391173717333e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.1350126669640304e-06
sam_encoder.blocks.1.norm1.weight grad: 3.4007805425062543e-06
sam_encoder.blocks.1.norm1.bias grad: -2.660947529875557e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.7562792840617476e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.483619816004648e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.9443118617346045e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 9.772991234058281e-07
sam_encoder.blocks.1.norm2.weight grad: 4.54741120847757e-06
sam_encoder.blocks.1.norm2.bias grad: 1.6933397546381457e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.6247896585118724e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.332082082531997e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0856036851691897e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.083046398292936e-07
sam_encoder.blocks.2.norm1.weight grad: 7.677124813199043e-06
sam_encoder.blocks.2.norm1.bias grad: -6.604549980693264e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.8323380471847486e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.2662785593420267e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.7150350686279126e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.3455426142172655e-06
sam_encoder.blocks.2.norm2.weight grad: -7.872689820942469e-06
sam_encoder.blocks.2.norm2.bias grad: -2.8654058041865937e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.179905772616621e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.5641962818335742e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.6142100776050938e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.17743375844293e-07
sam_encoder.blocks.3.norm1.weight grad: -5.365677111512923e-07
sam_encoder.blocks.3.norm1.bias grad: -3.088321591349086e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4955846836528508e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.171845944256347e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.736641360774229e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.219094643711287e-07
sam_encoder.blocks.3.norm2.weight grad: 3.894647306879051e-06
sam_encoder.blocks.3.norm2.bias grad: 4.8069887270685285e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.966201802541036e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.326154107227921e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.7572982358160516e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.761789954154665e-08
sam_encoder.blocks.4.norm1.weight grad: 9.068232316167268e-07
sam_encoder.blocks.4.norm1.bias grad: -7.659936045456561e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.4413662319821015e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.0271550005854806e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.7666995922336355e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.5381372122647008e-06
sam_encoder.blocks.4.norm2.weight grad: -7.077029295032844e-06
sam_encoder.blocks.4.norm2.bias grad: -2.5037527393578785e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.8488045649719425e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6188330391742056e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.1550960152817424e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.71496286738693e-07
sam_encoder.blocks.5.norm1.weight grad: 1.8395292045170208e-06
sam_encoder.blocks.5.norm1.bias grad: -4.316992090025451e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.3383352021919563e-08
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.881359695398714e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.1681571524823084e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2367604540486354e-07
sam_encoder.blocks.5.norm2.weight grad: -6.225821380212437e-06
sam_encoder.blocks.5.norm2.bias grad: -6.211953404999804e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.7537553276270046e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.154283257979841e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.78067305368313e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.910397243904299e-07
sam_encoder.blocks.6.norm1.weight grad: 1.1310979743939242e-06
sam_encoder.blocks.6.norm1.bias grad: 1.5054287132443278e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.286527647920593e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.816849130089395e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.56331394566223e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.017035001244949e-07
sam_encoder.blocks.6.norm2.weight grad: -3.4803576909325784e-06
sam_encoder.blocks.6.norm2.bias grad: -8.39742824609857e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.105523890350014e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.852638302414562e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.0606538580759661e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.292290529088859e-08
sam_encoder.blocks.7.norm1.weight grad: 1.6364617749786703e-06
sam_encoder.blocks.7.norm1.bias grad: 1.5491167459913413e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.6418173345300602e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.948021559262997e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5444151131305262e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.584347028772754e-07
sam_encoder.blocks.7.norm2.weight grad: 8.38557951965413e-08
sam_encoder.blocks.7.norm2.bias grad: 1.711557956696197e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.288530241567059e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.893133613379177e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.998167011966871e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.443951861001551e-07
sam_encoder.blocks.8.norm1.weight grad: 3.980236215284094e-06
sam_encoder.blocks.8.norm1.bias grad: -1.2920254448545165e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.2758766792539973e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.739910638018046e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.6551756491244305e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.56036981024954e-06
sam_encoder.blocks.8.norm2.weight grad: -5.98225255998841e-07
sam_encoder.blocks.8.norm2.bias grad: -8.007261840248248e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.7058302849764e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.224203161764308e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.857319251845183e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.795306255000469e-08
sam_encoder.blocks.9.norm1.weight grad: -9.466140795666433e-07
sam_encoder.blocks.9.norm1.bias grad: -4.7420353865845755e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.027991174851195e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.7183280931476475e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.2160837665505824e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.7501825406470743e-07
sam_encoder.blocks.9.norm2.weight grad: -1.6321928342222236e-07
sam_encoder.blocks.9.norm2.bias grad: -9.830678209254984e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.500909085436433e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.526431555656018e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.789988222204556e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.767957537093025e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4920915418770164e-06
sam_encoder.blocks.10.norm1.bias grad: -7.704783797635173e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.420793164987117e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.273326001362875e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.244329142646166e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.2330245264565747e-07
sam_encoder.blocks.10.norm2.weight grad: 3.153946295242349e-07
sam_encoder.blocks.10.norm2.bias grad: -1.132956185756484e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.911718284958624e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.6906141076542553e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.154623062888277e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.7468810748796386e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0892988029809203e-05
sam_encoder.blocks.11.norm1.bias grad: -4.784263865076355e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.0234883777447976e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.989321951143211e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.1794727470260113e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.255208973016124e-07
sam_encoder.blocks.11.norm2.weight grad: 2.4387409212067723e-06
sam_encoder.blocks.11.norm2.bias grad: -1.5122735703698709e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.351042439840967e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.166539882698999e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.323033925222262e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.912895393426879e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.2626303436700255e-08
sam_encoder.neck.conv1.trainable_shift grad: -3.0453174986178055e-06
sam_encoder.neck.conv2.trainable_scale grad: 6.94353730068542e-08
sam_encoder.neck.conv2.trainable_shift grad: 2.0447831047931686e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -7.03650075593032e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.018968760035932e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004576575942337513
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002835014893207699
mask_decoder.transformer.layers.0.norm3.weight grad: -6.669062713626772e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.5051391528686509e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 9.221040818374604e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -8.673585398355499e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.893403092864901e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.821355782449245e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 3.853298403555527e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0001558586081955582
mask_decoder.transformer.layers.1.norm3.weight grad: 5.38278000021819e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.6496555771445855e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.222087980248034e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001350451202597469
mask_decoder.transformer.norm_final_attn.weight grad: 3.6059336707694456e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0823338925547432e-05
Text_Embedding_Affine.0.weight grad: -6.289949464055589e-12
Text_Embedding_Affine.0.bias grad: -4.066640080235828e-11
Text_Embedding_Affine.2.weight grad: 2.045282346263555e-11
Text_Embedding_Affine.2.bias grad: 6.8564904722734354e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7004872512817355e-14
Max value: 0.9995021820068359
Mean value: 0.08479192852973938

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7004872512817355e-14
Max value: 0.9995021820068359
Mean value: 0.08479192852973938

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08664608001708984

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1378886103630066

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07587337493896484

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08664608001708984

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 40.011478424072266
Max value: 80.05400848388672
Mean value: 60.2928466796875

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.169953246966688e-14
Max value: 0.9995673298835754
Mean value: 0.08287990838289261

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.169953246966688e-14
Max value: 0.9995673298835754
Mean value: 0.08287990838289261

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.169953246966688e-14
Max value: 0.9995673298835754
Mean value: 0.08287990838289261

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1375853717327118

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7425867915153503
Max value: 1.0985941886901855
Mean value: 1.0003764629364014

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 40.011478424072266
Max value: 80.05400848388672
Mean value: 60.2928466796875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.30863952636719
Max value: -60.30863952636719
Mean value: -60.30863952636719
sam_encoder.pos_embed grad: -3.3846068170362287e-09
sam_encoder.blocks.0.norm1.weight grad: 1.7803047740017064e-05
sam_encoder.blocks.0.norm1.bias grad: 1.2382532986521255e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.5696623374169576e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.6762185118277557e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.2973927116254345e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0937318251080796e-07
sam_encoder.blocks.0.norm2.weight grad: -3.980799192504492e-06
sam_encoder.blocks.0.norm2.bias grad: 3.852495501632802e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.0139643563888967e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.127573447476607e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.446597242553253e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.192033652041573e-06
sam_encoder.blocks.1.norm1.weight grad: -1.1605156942096073e-06
sam_encoder.blocks.1.norm1.bias grad: -3.3292360512859887e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.0076550905941986e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.150880848399538e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.3393720261519775e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.719690655794693e-06
sam_encoder.blocks.1.norm2.weight grad: 1.5808444004505873e-05
sam_encoder.blocks.1.norm2.bias grad: 5.348069862520788e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.917717084637843e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8696989627642324e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 8.942121894506272e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.623925852267121e-09
sam_encoder.blocks.2.norm1.weight grad: 5.919064278714359e-06
sam_encoder.blocks.2.norm1.bias grad: -4.028130206279457e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.370274953340413e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.2079727791133337e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.1451137399708387e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0216889450020972e-06
sam_encoder.blocks.2.norm2.weight grad: 4.912371423415607e-06
sam_encoder.blocks.2.norm2.bias grad: -2.575748112576548e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.074717253388371e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.182214527441829e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.241204235062469e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.821106121104094e-07
sam_encoder.blocks.3.norm1.weight grad: -1.7119716630986659e-06
sam_encoder.blocks.3.norm1.bias grad: -6.621713509957772e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4860769397273543e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.1522048971055483e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 6.172463713483012e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.425101231689041e-06
sam_encoder.blocks.3.norm2.weight grad: 1.8285927581018768e-05
sam_encoder.blocks.3.norm2.bias grad: 3.815114723693114e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.3424521966953762e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.634378910850501e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.674755589599954e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1530084975674981e-06
sam_encoder.blocks.4.norm1.weight grad: 7.349393399636028e-06
sam_encoder.blocks.4.norm1.bias grad: -1.915301481858478e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.8331185148999793e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.397871175067849e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.4188175302697346e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.404072802164592e-06
sam_encoder.blocks.4.norm2.weight grad: -1.8315442503080703e-05
sam_encoder.blocks.4.norm2.bias grad: -1.4733852367498912e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0669587027223315e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.682910912379157e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.86029023250012e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.950436280319991e-07
sam_encoder.blocks.5.norm1.weight grad: 7.866429768910166e-06
sam_encoder.blocks.5.norm1.bias grad: -6.126219432189828e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.043111741542816e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2671905551542295e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.747075879800832e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.8894049844675465e-06
sam_encoder.blocks.5.norm2.weight grad: -5.320212949300185e-06
sam_encoder.blocks.5.norm2.bias grad: -9.45985630096402e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1501725794005324e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.439119601964194e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.5588986101988667e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.739057537037297e-07
sam_encoder.blocks.6.norm1.weight grad: 1.2298529554755078e-06
sam_encoder.blocks.6.norm1.bias grad: 2.9065690796414856e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.837010353890946e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.7499771110560687e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.53710696194321e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.909845294307161e-07
sam_encoder.blocks.6.norm2.weight grad: 3.2608039646220277e-07
sam_encoder.blocks.6.norm2.bias grad: -7.358252105404972e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.49624189716269e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.968993607690209e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1781185094150715e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.0951400731282774e-07
sam_encoder.blocks.7.norm1.weight grad: -1.9009046781093275e-08
sam_encoder.blocks.7.norm1.bias grad: 1.5657503809052287e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.0710261828280636e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.266032706505939e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.618240948024322e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.114651564028463e-07
sam_encoder.blocks.7.norm2.weight grad: 2.471469088050071e-06
sam_encoder.blocks.7.norm2.bias grad: 4.924402787764848e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.7424802030727733e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.2905668427265482e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.513816401820804e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.23397420188121e-07
sam_encoder.blocks.8.norm1.weight grad: 1.753620381350629e-06
sam_encoder.blocks.8.norm1.bias grad: -1.2933580819662893e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.314486427072552e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.023477681083023e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.725487777548551e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.104743089148542e-06
sam_encoder.blocks.8.norm2.weight grad: -4.57267105957726e-07
sam_encoder.blocks.8.norm2.bias grad: -2.7733739216273534e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.1740237368940143e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.283071568053856e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.80305581365792e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.123807452240726e-07
sam_encoder.blocks.9.norm1.weight grad: -3.1901251418275933e-07
sam_encoder.blocks.9.norm1.bias grad: 5.595533139057807e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.231666702660732e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.3057798393419944e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.023333571330113e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.3102984414435923e-07
sam_encoder.blocks.9.norm2.weight grad: 1.5532971247012028e-06
sam_encoder.blocks.9.norm2.bias grad: -1.9826470065709145e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.5157465895754285e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3091524806441157e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.6953900323387643e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.181137225918064e-07
sam_encoder.blocks.10.norm1.weight grad: 2.8020194804412313e-06
sam_encoder.blocks.10.norm1.bias grad: 4.452048756320437e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.950473688339116e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.674765012983698e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0274080750605208e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.8930736561960657e-07
sam_encoder.blocks.10.norm2.weight grad: 3.72810973203741e-06
sam_encoder.blocks.10.norm2.bias grad: -3.0856199373374693e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.488414565959829e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2624843748199055e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.1592541088466533e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.876642781757255e-07
sam_encoder.blocks.11.norm1.weight grad: 1.722613706078846e-05
sam_encoder.blocks.11.norm1.bias grad: 3.015914984416668e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.025280537054641e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.633229870407376e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.2518802325066645e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.238197324317298e-07
sam_encoder.blocks.11.norm2.weight grad: 4.140529199503362e-06
sam_encoder.blocks.11.norm2.bias grad: -5.254368034002255e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.843066224362701e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.768408292780805e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.974061423330568e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.894473366017337e-08
sam_encoder.neck.conv1.trainable_scale grad: 5.178590072318912e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.7773591025616042e-06
sam_encoder.neck.conv2.trainable_scale grad: 6.549453246407211e-08
sam_encoder.neck.conv2.trainable_shift grad: -2.449993644404458e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -5.613067332888022e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.843451850116253e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005418973974883556
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00015687750419601798
mask_decoder.transformer.layers.0.norm3.weight grad: -3.504104824969545e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.9878643797710538e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001788632507668808
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1632835594355129e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.646704888320528e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.346226432971889e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001753857941366732
mask_decoder.transformer.layers.1.norm2.bias grad: 3.192360236425884e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.332529740873724e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.069914833351504e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.919195195427164e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00022007808729540557
mask_decoder.transformer.norm_final_attn.weight grad: 3.182356977049494e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.0124318325542845e-05
Text_Embedding_Affine.0.weight grad: -2.3916428733283812e-12
Text_Embedding_Affine.0.bias grad: 1.7754454156859723e-11
Text_Embedding_Affine.2.weight grad: 3.872603626664528e-11
Text_Embedding_Affine.2.bias grad: 2.507060708012432e-05
Epoch 31 finished with average loss: -60.9143
Epoch 32/39
----------
Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.3]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-55.3]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-60.6]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-60.6]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-60.1]Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.37it/s, loss=-60.1]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.563698064262209e-12
Max value: 0.999512791633606
Mean value: 0.06851467490196228

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.563698064262209e-12
Max value: 0.999512791633606
Mean value: 0.06851467490196228

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07729339599609375

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11446190625429153

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05931234359741211

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07729339599609375

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 27.857393264770508
Max value: 91.49807739257812
Mean value: 55.34657669067383

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.563698064262209e-12
Max value: 0.999512791633606
Mean value: 0.06851467490196228

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.563698064262209e-12
Max value: 0.999512791633606
Mean value: 0.06851467490196228

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.563698064262209e-12
Max value: 0.999512791633606
Mean value: 0.06851467490196228

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11446190625429153

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 27.857393264770508
Max value: 91.49807739257812
Mean value: 55.34657669067383

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.347530364990234
Max value: -55.347530364990234
Mean value: -55.347530364990234
sam_encoder.pos_embed grad: 5.622594612120224e-10
sam_encoder.blocks.0.norm1.weight grad: 8.24186372483382e-06
sam_encoder.blocks.0.norm1.bias grad: 2.0247323845978826e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.6440512758417754e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.70556050358573e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.330790837528184e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.624894023028901e-06
sam_encoder.blocks.0.norm2.weight grad: 3.7360950955189764e-05
sam_encoder.blocks.0.norm2.bias grad: 1.0893962098634802e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.395725672016852e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.688189852051437e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.0395533334231e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.59511920780642e-06
sam_encoder.blocks.1.norm1.weight grad: 1.2397613318171352e-05
sam_encoder.blocks.1.norm1.bias grad: 1.4225861377781257e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.062679974798812e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -6.956667562008079e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.600785698334221e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.0832117115787696e-06
sam_encoder.blocks.1.norm2.weight grad: 1.5026274013507646e-05
sam_encoder.blocks.1.norm2.bias grad: -4.302010893297847e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.5054025627468945e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.2609187933776411e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.749169875140069e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.7072652553906664e-06
sam_encoder.blocks.2.norm1.weight grad: -1.4586099496227689e-05
sam_encoder.blocks.2.norm1.bias grad: 9.285689884563908e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.62326669448521e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.61202785623027e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.6590724852867424e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.88846001442289e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0626594303175807e-05
sam_encoder.blocks.2.norm2.bias grad: 5.875625902262982e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.732832273177337e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.4535372631362407e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.220399892394198e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.440881523099961e-08
sam_encoder.blocks.3.norm1.weight grad: -3.648204710771097e-06
sam_encoder.blocks.3.norm1.bias grad: 7.331188385251153e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.6778487810806837e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.4262817558119423e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.970190275344066e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.800024160227622e-06
sam_encoder.blocks.3.norm2.weight grad: -3.3193834951816825e-06
sam_encoder.blocks.3.norm2.bias grad: 4.319383151596412e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.180037199650542e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 7.158034236454114e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.9109057777532144e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.130400601658039e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0877738532144576e-05
sam_encoder.blocks.4.norm1.bias grad: 3.9781562009011395e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.359150807431433e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1504471331136301e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.6460710362007376e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.833346795545367e-07
sam_encoder.blocks.4.norm2.weight grad: 1.9609919036156498e-05
sam_encoder.blocks.4.norm2.bias grad: 3.017739345523296e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.2655730643018615e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.004866241302807e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.030861080333125e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.1644076494121691e-06
sam_encoder.blocks.5.norm1.weight grad: -8.951459676609375e-06
sam_encoder.blocks.5.norm1.bias grad: 5.838888682774268e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.993081115069799e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.0461880012589972e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 7.405883479805198e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1574933296287782e-06
sam_encoder.blocks.5.norm2.weight grad: 6.620935891987756e-06
sam_encoder.blocks.5.norm2.bias grad: -3.7610680010402575e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.420957222668221e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.077936869682162e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.433741315144289e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.180450095096603e-09
sam_encoder.blocks.6.norm1.weight grad: -6.4419396039738785e-06
sam_encoder.blocks.6.norm1.bias grad: 1.5812952369742561e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.227225872455165e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.2312201508611906e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.620805035912781e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.0436957609272213e-06
sam_encoder.blocks.6.norm2.weight grad: -3.264531187596731e-06
sam_encoder.blocks.6.norm2.bias grad: 1.115767872761353e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4557845133822411e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.946913006482646e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.7407331799622625e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1611733725658269e-06
sam_encoder.blocks.7.norm1.weight grad: 5.559693363466067e-07
sam_encoder.blocks.7.norm1.bias grad: 8.695693622939871e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.636067103547248e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.4890624672480044e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4257606153478264e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.6539100897716708e-06
sam_encoder.blocks.7.norm2.weight grad: 2.7490809770824853e-06
sam_encoder.blocks.7.norm2.bias grad: 1.27646757164257e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.1737841962021776e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.6978140138235176e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1960128176724538e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.954020363991731e-07
sam_encoder.blocks.8.norm1.weight grad: -7.617431947437581e-06
sam_encoder.blocks.8.norm1.bias grad: 2.046382860498852e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.699400157434866e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.562262918421766e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.9321366835356457e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.3209826192905894e-06
sam_encoder.blocks.8.norm2.weight grad: 2.3557870463264408e-06
sam_encoder.blocks.8.norm2.bias grad: -2.2883702968101716e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.497619107089122e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.4340766938403249e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.86365570648195e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.345664817468787e-07
sam_encoder.blocks.9.norm1.weight grad: -2.1739092517236713e-06
sam_encoder.blocks.9.norm1.bias grad: 2.2043298031348968e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.0808149656659225e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.5943080572687904e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.872543056284485e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.279614126469824e-07
sam_encoder.blocks.9.norm2.weight grad: 4.513381099968683e-07
sam_encoder.blocks.9.norm2.bias grad: -1.314945620833896e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.027093162520032e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3268974896618602e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.747238098294474e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.6701428623709944e-07
sam_encoder.blocks.10.norm1.weight grad: -7.446838878877315e-08
sam_encoder.blocks.10.norm1.bias grad: -1.1368242667231243e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.315865104828845e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.585631583926443e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3050083680354874e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.3040261137575726e-07
sam_encoder.blocks.10.norm2.weight grad: -2.4511821266059997e-06
sam_encoder.blocks.10.norm2.bias grad: -9.255785471395939e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.2425148270267528e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.200336090638302e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.4911460084476857e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.425497479587648e-07
sam_encoder.blocks.11.norm1.weight grad: 4.81676715935464e-06
sam_encoder.blocks.11.norm1.bias grad: -7.076760084601119e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.9748675842711236e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.505523065745365e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.502408377353277e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.2579225717199733e-07
sam_encoder.blocks.11.norm2.weight grad: -2.5395620468771085e-06
sam_encoder.blocks.11.norm2.bias grad: -9.805117997530033e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0465992090757936e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.3057900711573893e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.603150725619344e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.97899338319985e-09
sam_encoder.neck.conv1.trainable_scale grad: -4.86289536638651e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.0859423127840273e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.683918864931911e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.4468314475379884e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -3.876606933772564e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3959343050373718e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004819711670279503
mask_decoder.transformer.layers.0.norm2.bias grad: -9.822676656767726e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -9.024870087159798e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.6748344933148474e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.255693733692169e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.274799150356557e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.268540214980021e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.497439709259197e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.6947597032412887e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.706876203883439e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.3780059311538935e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.373732033651322e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.8826858649845235e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010408478556200862
mask_decoder.transformer.norm_final_attn.weight grad: 5.03741421198356e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.752568985277321e-06
Text_Embedding_Affine.0.weight grad: -5.6589815299046275e-12
Text_Embedding_Affine.0.bias grad: -4.3196460297600936e-10
Text_Embedding_Affine.2.weight grad: 4.014012039421644e-11
Text_Embedding_Affine.2.bias grad: 1.3381980352278333e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.3468045608492256e-14
Max value: 0.9997596144676208
Mean value: 0.08719323575496674

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3468045608492256e-14
Max value: 0.9997596144676208
Mean value: 0.08719323575496674

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0976858139038086

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12807193398475647

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08154726028442383

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0976858139038086

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.494632720947266
Max value: 80.07095336914062
Mean value: 65.83792877197266

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.861013342810332e-14
Max value: 0.9997362494468689
Mean value: 0.08754456043243408

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.861013342810332e-14
Max value: 0.9997362494468689
Mean value: 0.08754456043243408

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.861013342810332e-14
Max value: 0.9997362494468689
Mean value: 0.08754456043243408

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1277647316455841

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9690850377082825
Max value: 1.3119691610336304
Mean value: 1.0003304481506348

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.494632720947266
Max value: 80.07095336914062
Mean value: 65.83792877197266

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.85881042480469
Max value: -65.85881042480469
Mean value: -65.85881042480469
sam_encoder.pos_embed grad: -2.5088584543198067e-09
sam_encoder.blocks.0.norm1.weight grad: 3.0861330742482096e-05
sam_encoder.blocks.0.norm1.bias grad: 1.3122502423357219e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.3608705507504055e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.7580807682170416e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.968998276424827e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.468660214726697e-07
sam_encoder.blocks.0.norm2.weight grad: -1.359488487651106e-05
sam_encoder.blocks.0.norm2.bias grad: 2.1772231775685214e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2769998647854663e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.9978668862895574e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.15236524734064e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.899552550341468e-06
sam_encoder.blocks.1.norm1.weight grad: 2.0691099962277804e-06
sam_encoder.blocks.1.norm1.bias grad: 2.3783159122103825e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.153511559299659e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.9169988263456617e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.8938960693049012e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0927152516160277e-06
sam_encoder.blocks.1.norm2.weight grad: 1.054129097610712e-05
sam_encoder.blocks.1.norm2.bias grad: 8.774107840281431e-08
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.1445971469802316e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.679340008806321e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.5330659809696954e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2597325849128538e-06
sam_encoder.blocks.2.norm1.weight grad: 5.290494300425053e-07
sam_encoder.blocks.2.norm1.bias grad: -1.5561570307909278e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.35281129082432e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.5676809184128615e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.0476526262646075e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.264938641223125e-06
sam_encoder.blocks.2.norm2.weight grad: -3.4221309306303738e-06
sam_encoder.blocks.2.norm2.bias grad: -1.5060186342452653e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.8007560811383883e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.8013946601058706e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.899883841360861e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.74286661453516e-07
sam_encoder.blocks.3.norm1.weight grad: 1.6707110717106843e-07
sam_encoder.blocks.3.norm1.bias grad: -6.546156782860635e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.3586139857579838e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.3157400025629613e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.3804610666265944e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.2356658771750517e-06
sam_encoder.blocks.3.norm2.weight grad: 8.209498446376529e-06
sam_encoder.blocks.3.norm2.bias grad: -5.266614607535303e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.934199518582318e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.4953155843832064e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.1710803745663725e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1985717947027297e-06
sam_encoder.blocks.4.norm1.weight grad: 1.2439484635251574e-05
sam_encoder.blocks.4.norm1.bias grad: -1.9376989257580135e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.868357220606413e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.3046757178235566e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.987531272287015e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.644880507636117e-06
sam_encoder.blocks.4.norm2.weight grad: -1.8507895219954662e-05
sam_encoder.blocks.4.norm2.bias grad: -1.8060109141515568e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1176852240168955e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.851212906942237e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.3441366490951623e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.8729061796184396e-07
sam_encoder.blocks.5.norm1.weight grad: 1.0202638804912567e-05
sam_encoder.blocks.5.norm1.bias grad: -3.0059536584303714e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.22656694354373e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.5791390239883185e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.6840424399997573e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.4519250726152677e-06
sam_encoder.blocks.5.norm2.weight grad: -7.289882887562271e-06
sam_encoder.blocks.5.norm2.bias grad: -8.269542377092876e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.827266467254958e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.3136592492155614e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.928607459462e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.900913381788996e-07
sam_encoder.blocks.6.norm1.weight grad: -8.50545447406148e-08
sam_encoder.blocks.6.norm1.bias grad: 4.425954557518708e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.717739430925576e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.007808577924152e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.185784518995206e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.1329411004653593e-08
sam_encoder.blocks.6.norm2.weight grad: -5.530184353119694e-06
sam_encoder.blocks.6.norm2.bias grad: -1.8985285805683816e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.5961099911219208e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.591863338035182e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.9793545763823204e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.258813639055006e-07
sam_encoder.blocks.7.norm1.weight grad: 5.589728516497416e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3204173683334375e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.2924344850471243e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.4821711147305905e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.467278025302221e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.9055526934153022e-07
sam_encoder.blocks.7.norm2.weight grad: -1.0018836746894522e-06
sam_encoder.blocks.7.norm2.bias grad: 2.575272333160683e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.582448352470237e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.8317407791719234e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4623587958340067e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.318426125697442e-07
sam_encoder.blocks.8.norm1.weight grad: 4.326424004830187e-06
sam_encoder.blocks.8.norm1.bias grad: -2.192659849242773e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.3847076136007672e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.485166264586951e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.4288842723763082e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.711698814688134e-06
sam_encoder.blocks.8.norm2.weight grad: -4.416294174802715e-08
sam_encoder.blocks.8.norm2.bias grad: -1.4558844441125984e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.324480535913608e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.108074436880997e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.822648864115763e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.341819680395929e-07
sam_encoder.blocks.9.norm1.weight grad: -6.47085244054324e-07
sam_encoder.blocks.9.norm1.bias grad: 2.4545292376387806e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.654950996358821e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.562952374773886e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.900071181092926e-09
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4574465012628934e-07
sam_encoder.blocks.9.norm2.weight grad: -5.097673465570551e-07
sam_encoder.blocks.9.norm2.bias grad: -1.5259622614394175e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.349136304426793e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.8013525366077374e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.837217666889046e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.143503472027078e-07
sam_encoder.blocks.10.norm1.weight grad: 4.332606295065489e-06
sam_encoder.blocks.10.norm1.bias grad: 1.7494548387730902e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.9562343115685508e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0010573987528915e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2268938007764518e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.3145286099388613e-07
sam_encoder.blocks.10.norm2.weight grad: 2.087281472995528e-06
sam_encoder.blocks.10.norm2.bias grad: 8.262547623871797e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.054553536050662e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.728239547257544e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.6569417482514837e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.130172305214728e-07
sam_encoder.blocks.11.norm1.weight grad: 1.840739969338756e-05
sam_encoder.blocks.11.norm1.bias grad: 1.2453870112949517e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.633199983392842e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.733662753002136e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.946358452187269e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.802583362106816e-07
sam_encoder.blocks.11.norm2.weight grad: 3.911868020622933e-07
sam_encoder.blocks.11.norm2.bias grad: -3.6044019680048223e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.686832092673285e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.440591515551205e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.052187705383403e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0081102885806104e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.1696101864799857e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.0593939805403352e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.2745629141572863e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.949579306412488e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -1.1293184797978029e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.0633884812705219e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005713603924959898
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00045205431524664164
mask_decoder.transformer.layers.0.norm3.weight grad: -2.1992418623995036e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.589508560253307e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00015639980847481638
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0501991710043512e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.8473721613408998e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.737042788998224e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00017454527551308274
mask_decoder.transformer.layers.1.norm2.bias grad: 3.2230454962700605e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.189422932337038e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.7108457036083564e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -7.285872561624274e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00023580921697430313
mask_decoder.transformer.norm_final_attn.weight grad: 1.5163330999712343e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.5204655937850475e-05
Text_Embedding_Affine.0.weight grad: -3.773867503220618e-12
Text_Embedding_Affine.0.bias grad: -1.7680060193647762e-10
Text_Embedding_Affine.2.weight grad: -2.5218186913700258e-11
Text_Embedding_Affine.2.bias grad: 1.8524624465499073e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.841919829829845e-13
Max value: 0.9977537989616394
Mean value: 0.06768248975276947

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.841919829829845e-13
Max value: 0.9977537989616394
Mean value: 0.06768248975276947

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06891155242919922

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10367345809936523

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05849266052246094

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06891155242919922

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 55.250003814697266
Max value: 63.76692199707031
Mean value: 58.979522705078125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.4061455992642191e-12
Max value: 0.9973336458206177
Mean value: 0.06959763169288635

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.4061455992642191e-12
Max value: 0.9973336458206177
Mean value: 0.06959763169288635

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.4061455992642191e-12
Max value: 0.9973336458206177
Mean value: 0.06959763169288635

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10342635959386826

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9495888352394104
Max value: 2.5209765434265137
Mean value: 1.0004154443740845

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 55.250003814697266
Max value: 63.76692199707031
Mean value: 58.979522705078125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.99496078491211
Max value: -58.99496078491211
Mean value: -58.99496078491211
sam_encoder.pos_embed grad: -3.587858898868035e-09
sam_encoder.blocks.0.norm1.weight grad: -1.0997879144269973e-05
sam_encoder.blocks.0.norm1.bias grad: -3.4760373637254816e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.709371756282053e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.60091670820384e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.474641622844501e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.649779560215393e-07
sam_encoder.blocks.0.norm2.weight grad: -2.1389812900451943e-05
sam_encoder.blocks.0.norm2.bias grad: 8.544874617655296e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.1030384535552e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.360129085194785e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.9361503291293047e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.628770385461394e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1076506325480295e-06
sam_encoder.blocks.1.norm1.bias grad: -5.705310286430176e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.182406650623307e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.3488504464476136e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.587208422890399e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.9102894839306828e-06
sam_encoder.blocks.1.norm2.weight grad: 2.1953206669422798e-05
sam_encoder.blocks.1.norm2.bias grad: 7.965013537614141e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.0249375918647274e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.2891197204444325e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.138252163305879e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.511258732189162e-08
sam_encoder.blocks.2.norm1.weight grad: -1.1118786460428964e-06
sam_encoder.blocks.2.norm1.bias grad: -7.1737913458491676e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.4080250139159034e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.382946237526994e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.352105282938282e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3656585906574037e-06
sam_encoder.blocks.2.norm2.weight grad: -2.460106315993471e-06
sam_encoder.blocks.2.norm2.bias grad: 2.9524396722990787e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.9035118370425153e-08
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.506932545060408e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.497071015270194e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.1582717952005623e-07
sam_encoder.blocks.3.norm1.weight grad: 2.163913904951187e-06
sam_encoder.blocks.3.norm1.bias grad: -6.667932211712468e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.449154620393529e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.8216762498468597e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.7532247511553578e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.590300939824374e-06
sam_encoder.blocks.3.norm2.weight grad: 1.1315342817397323e-05
sam_encoder.blocks.3.norm2.bias grad: -2.001882819513412e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.842627721605822e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.866838258341886e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.607206392392982e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.458656116592465e-07
sam_encoder.blocks.4.norm1.weight grad: 1.0560775990597904e-05
sam_encoder.blocks.4.norm1.bias grad: 3.8152393244672567e-08
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.403223101689946e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.8294904293725267e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.471017407719046e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.672312232083641e-06
sam_encoder.blocks.4.norm2.weight grad: -2.1721256416640244e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3864361790183466e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3189825949666556e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.798944584967103e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.173362647932663e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0480509615717892e-07
sam_encoder.blocks.5.norm1.weight grad: 5.636019523080904e-06
sam_encoder.blocks.5.norm1.bias grad: -9.507719369139522e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.845407607310335e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.4408396964427084e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.633064468682278e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.740318450378254e-06
sam_encoder.blocks.5.norm2.weight grad: -4.774519311467884e-06
sam_encoder.blocks.5.norm2.bias grad: -1.003628312901128e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.413949904526817e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.0527632809953502e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.531720272396342e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.57459464087151e-07
sam_encoder.blocks.6.norm1.weight grad: -2.982914963922667e-07
sam_encoder.blocks.6.norm1.bias grad: 1.7628765363042476e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.1041652214771602e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.996503998379922e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3688685385204735e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.199648391382652e-07
sam_encoder.blocks.6.norm2.weight grad: -8.312954378197901e-06
sam_encoder.blocks.6.norm2.bias grad: -3.70903921975696e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.940003575233277e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.4277564989461098e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.862576249957783e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.864641596213914e-07
sam_encoder.blocks.7.norm1.weight grad: 6.436175226554042e-06
sam_encoder.blocks.7.norm1.bias grad: -6.335417310765479e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.2496485548326746e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.523826424294384e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.987715222639963e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.7880631730804453e-07
sam_encoder.blocks.7.norm2.weight grad: 3.245516495553602e-07
sam_encoder.blocks.7.norm2.bias grad: -3.517207005643286e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.0891529857181013e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.8783386341046935e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2144174661443685e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.147427610703744e-06
sam_encoder.blocks.8.norm1.weight grad: 6.229659447853919e-06
sam_encoder.blocks.8.norm1.bias grad: -3.294079533588956e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.324446647136938e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.9450546915322775e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.7853254778165137e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.424441163384472e-06
sam_encoder.blocks.8.norm2.weight grad: -2.362353370699566e-06
sam_encoder.blocks.8.norm2.bias grad: -1.210682626151538e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.8538321455707774e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.1307722616038518e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.850052957612206e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0658782230166253e-06
sam_encoder.blocks.9.norm1.weight grad: 1.1641388937277952e-06
sam_encoder.blocks.9.norm1.bias grad: -2.3647851321584312e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.0646263035596348e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.6051181950824684e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.1496417446087435e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.63969318123236e-07
sam_encoder.blocks.9.norm2.weight grad: 2.7198893803870305e-08
sam_encoder.blocks.9.norm2.bias grad: -9.258598083761171e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.512816195121559e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.814932772958855e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8359932596467843e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.508942303502408e-07
sam_encoder.blocks.10.norm1.weight grad: 5.248075012787012e-06
sam_encoder.blocks.10.norm1.bias grad: 5.193513743506628e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.313728484499734e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2565636779982015e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.8363746221439214e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.230989235220477e-07
sam_encoder.blocks.10.norm2.weight grad: 6.284827236413548e-07
sam_encoder.blocks.10.norm2.bias grad: -5.943858809587255e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.036778816247534e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.4744423992851807e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.6661496121960226e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.042813882027986e-07
sam_encoder.blocks.11.norm1.weight grad: 1.6016272638808005e-05
sam_encoder.blocks.11.norm1.bias grad: 1.8965936021686502e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.42309602072055e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.314355000038631e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.0622029498772463e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4025025620867382e-06
sam_encoder.blocks.11.norm2.weight grad: 2.3391369268210838e-06
sam_encoder.blocks.11.norm2.bias grad: -1.4260747320804512e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.03829961012525e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.404688703132706e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.181866526982049e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.418658919457812e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.2579555409029126e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.782370398170315e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.930475264089182e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.2828429134970065e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -8.614845864940435e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.6450940165668726e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005004039499908686
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00010917283361777663
mask_decoder.transformer.layers.0.norm3.weight grad: -5.487524322234094e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.338251063833013e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00017351935093756765
mask_decoder.transformer.layers.0.norm4.bias grad: -6.917960490682162e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.843447327904869e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.1670191421872005e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -9.001967555377632e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.8207047105534002e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.799199036322534e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.6636062102625147e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.7205114747630432e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00018652915605343878
mask_decoder.transformer.norm_final_attn.weight grad: 1.4535663694914547e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.1005866074119695e-05
Text_Embedding_Affine.0.weight grad: 1.6310631664739894e-11
Text_Embedding_Affine.0.bias grad: 5.199990438242708e-10
Text_Embedding_Affine.2.weight grad: 8.541608392809152e-11
Text_Embedding_Affine.2.bias grad: 1.7603160813450813e-05
Epoch 32 finished with average loss: -60.0671
Epoch 33/39
----------
Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.8]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-59.8]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-60.7]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-60.7]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-60.6]Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-60.6]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7089289510406613e-13
Max value: 0.9995526671409607
Mean value: 0.08900505304336548

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7089289510406613e-13
Max value: 0.9995526671409607
Mean value: 0.08900505304336548

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928489685058594

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12153378874063492

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08270549774169922

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08928489685058594

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.91579055786133
Max value: 90.31735229492188
Mean value: 59.8045654296875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7089289510406613e-13
Max value: 0.9995526671409607
Mean value: 0.08900505304336548

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7089289510406613e-13
Max value: 0.9995526671409607
Mean value: 0.08900505304336548

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7089289510406613e-13
Max value: 0.9995526671409607
Mean value: 0.08900505304336548

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12153378874063492

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.91579055786133
Max value: 90.31735229492188
Mean value: 59.8045654296875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.80562210083008
Max value: -59.80562210083008
Mean value: -59.80562210083008
sam_encoder.pos_embed grad: -3.6272103098866637e-09
sam_encoder.blocks.0.norm1.weight grad: 5.5119176977314055e-05
sam_encoder.blocks.0.norm1.bias grad: 1.8938546418212354e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.85770351588144e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.454523044230882e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.973892257316038e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.7906570519699017e-06
sam_encoder.blocks.0.norm2.weight grad: -6.263561954256147e-05
sam_encoder.blocks.0.norm2.bias grad: -1.2611844795173965e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.2140175133245066e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.615298732664087e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.722684939726605e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.4973230665636947e-06
sam_encoder.blocks.1.norm1.weight grad: -5.424939445219934e-06
sam_encoder.blocks.1.norm1.bias grad: -2.8066668164683506e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.5475136428431142e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.371706197048297e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.008866992284311e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.6251400413457304e-06
sam_encoder.blocks.1.norm2.weight grad: 1.2789799939127988e-06
sam_encoder.blocks.1.norm2.bias grad: 5.888390205655014e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.661963208083762e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.1976984524153522e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.032860018312931e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.886550990093383e-06
sam_encoder.blocks.2.norm1.weight grad: -4.0824988900567405e-07
sam_encoder.blocks.2.norm1.bias grad: -3.714404556376394e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.7486488559370628e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.845862223301083e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.7139807368948823e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.722090473776916e-06
sam_encoder.blocks.2.norm2.weight grad: 7.763214853184763e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2525309784905403e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.799098860530648e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.507535102973634e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.3080154935305472e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.0919739540659066e-07
sam_encoder.blocks.3.norm1.weight grad: -2.7156172563991277e-06
sam_encoder.blocks.3.norm1.bias grad: -3.8460921132355e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.64289824878506e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.0719644428245374e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.0750180738104973e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.960670013242634e-07
sam_encoder.blocks.3.norm2.weight grad: -1.2154489922977518e-05
sam_encoder.blocks.3.norm2.bias grad: -7.740571163594723e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.436683856416494e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.170959189446876e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.677959284686949e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.436533060925285e-07
sam_encoder.blocks.4.norm1.weight grad: -2.3885263544798363e-06
sam_encoder.blocks.4.norm1.bias grad: -3.200433127403812e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.107020115246996e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1798136938523385e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.455987992623704e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.1443122502896586e-06
sam_encoder.blocks.4.norm2.weight grad: 1.7080295947380364e-05
sam_encoder.blocks.4.norm2.bias grad: 7.3061833063547965e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.369159872410819e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.310687811288517e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.777736881398596e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.067974022196722e-07
sam_encoder.blocks.5.norm1.weight grad: 7.269031812029425e-06
sam_encoder.blocks.5.norm1.bias grad: 7.937796908663586e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.6641089334589196e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.154072378994897e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.917150135952397e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.596604306541849e-06
sam_encoder.blocks.5.norm2.weight grad: 1.898716072901152e-05
sam_encoder.blocks.5.norm2.bias grad: 2.572177209003712e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.978999176179059e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.3476921998953912e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.97581482300302e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.584221061231801e-07
sam_encoder.blocks.6.norm1.weight grad: 5.42012048754259e-06
sam_encoder.blocks.6.norm1.bias grad: 2.045600012934301e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.869527063216083e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5976055465216632e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.238851710804738e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.496249736504979e-07
sam_encoder.blocks.6.norm2.weight grad: 2.375470558035886e-06
sam_encoder.blocks.6.norm2.bias grad: -3.608815404732013e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.867606879903178e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0685743063731934e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.0279733234929154e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.2977300773163734e-07
sam_encoder.blocks.7.norm1.weight grad: 7.981891030794941e-06
sam_encoder.blocks.7.norm1.bias grad: -2.80807967101282e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.119904017192312e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5436773992405506e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.995364962378517e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.7305213759755134e-06
sam_encoder.blocks.7.norm2.weight grad: 1.760430563990667e-06
sam_encoder.blocks.7.norm2.bias grad: -2.2767603695683647e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.721547655772156e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.418532620955375e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.9883063941961154e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.805418817952159e-07
sam_encoder.blocks.8.norm1.weight grad: 4.89196645503398e-06
sam_encoder.blocks.8.norm1.bias grad: 1.010803202916577e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.346838522906182e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.2463463008316467e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.821709312518578e-08
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.7739350823831046e-06
sam_encoder.blocks.8.norm2.weight grad: 1.4729009762959322e-06
sam_encoder.blocks.8.norm2.bias grad: 4.5557121097772324e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.1141067943754024e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.7281697637372417e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.293202320899582e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.257913582885521e-07
sam_encoder.blocks.9.norm1.weight grad: 4.58250497104018e-06
sam_encoder.blocks.9.norm1.bias grad: -4.852427650803293e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.194459052087041e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1586168966459809e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.1771008341129345e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.90661419564276e-07
sam_encoder.blocks.9.norm2.weight grad: 5.9833228078787215e-06
sam_encoder.blocks.9.norm2.bias grad: 1.681621142779477e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.901785021298565e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.822990381901036e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.14727674574533e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.1782058209064417e-06
sam_encoder.blocks.10.norm1.weight grad: 2.9004976909163815e-07
sam_encoder.blocks.10.norm1.bias grad: 1.5336821661549038e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.2043646790971252e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.845573352620704e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.029263671625813e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.3007571548514534e-07
sam_encoder.blocks.10.norm2.weight grad: 7.89822661317885e-06
sam_encoder.blocks.10.norm2.bias grad: 2.6161787900491618e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.917005076596979e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.7065194697352126e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.4027185670784093e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.064462579364772e-07
sam_encoder.blocks.11.norm1.weight grad: 5.864568720426178e-06
sam_encoder.blocks.11.norm1.bias grad: 1.7365205167152453e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.189668066421291e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.952851970889242e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.377045350636763e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.973750939527235e-07
sam_encoder.blocks.11.norm2.weight grad: 1.1035374882339966e-05
sam_encoder.blocks.11.norm2.bias grad: 3.51494691130938e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.4456422781659057e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.3810459879314294e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.3357561076409183e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.614506335405167e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.433130819350481e-06
sam_encoder.neck.conv1.trainable_shift grad: 6.373282303684391e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.0367384675191715e-06
sam_encoder.neck.conv2.trainable_shift grad: 5.754588073614286e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001299327559536323
mask_decoder.transformer.layers.0.norm1.bias grad: -9.283176041208208e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002201494760811329
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003763544373214245
mask_decoder.transformer.layers.0.norm3.weight grad: 2.3006414267001674e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.316223880276084e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -6.312791083473712e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.4450877642957494e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -6.754482456017286e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.051433279528283e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00017872327589429915
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00023208430502563715
mask_decoder.transformer.layers.1.norm3.weight grad: -6.752469926141202e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -7.412096601910889e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.532164894044399e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 6.488259532488883e-05
mask_decoder.transformer.norm_final_attn.weight grad: -2.120807948813308e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.283086572191678e-06
Text_Embedding_Affine.0.weight grad: -1.821011397229455e-11
Text_Embedding_Affine.0.bias grad: -4.941035358640988e-10
Text_Embedding_Affine.2.weight grad: -5.581268780474602e-11
Text_Embedding_Affine.2.bias grad: -9.03860927792266e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.285107842842532e-12
Max value: 0.9997830986976624
Mean value: 0.07719163596630096

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.285107842842532e-12
Max value: 0.9997830986976624
Mean value: 0.07719163596630096

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0814671516418457

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.463926315307617
Max value: -1.1920928244535389e-07
Mean value: -0.11371239274740219

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06663751602172852

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0814671516418457

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.794986724853516
Max value: 75.65685272216797
Mean value: 61.67032241821289

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.733215654331488e-11
Max value: 0.9997451901435852
Mean value: 0.07847616076469421

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.733215654331488e-11
Max value: 0.9997451901435852
Mean value: 0.07847616076469421

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.733215654331488e-11
Max value: 0.9997451901435852
Mean value: 0.07847616076469421

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.144298553466797
Max value: -1.1920928244535389e-07
Mean value: -0.11351211369037628

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9629480838775635
Max value: 1.4313879013061523
Mean value: 1.000257968902588

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.794986724853516
Max value: 75.65685272216797
Mean value: 61.67032241821289

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.68873596191406
Max value: -61.68873596191406
Mean value: -61.68873596191406
sam_encoder.pos_embed grad: -2.0152999269384964e-09
sam_encoder.blocks.0.norm1.weight grad: 1.3699236660613678e-05
sam_encoder.blocks.0.norm1.bias grad: 4.3630567233776674e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.3304883168530068e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.28260591434082e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.590239489563828e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.154075329803163e-07
sam_encoder.blocks.0.norm2.weight grad: 2.8174446924822405e-05
sam_encoder.blocks.0.norm2.bias grad: -6.429888344428036e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6730172092138673e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.0592539183562621e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.5023745163489366e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.605811459943652e-06
sam_encoder.blocks.1.norm1.weight grad: 3.199946831955458e-06
sam_encoder.blocks.1.norm1.bias grad: -6.008119271427859e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.9459607756289188e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.7272591890105105e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.1229835763515439e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 5.247890726423066e-07
sam_encoder.blocks.1.norm2.weight grad: 2.9503185032808688e-06
sam_encoder.blocks.1.norm2.bias grad: 4.0111203816195484e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.912943844217807e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.633909717696952e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.790675068808923e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.017610528237128e-07
sam_encoder.blocks.2.norm1.weight grad: 5.794973731099162e-06
sam_encoder.blocks.2.norm1.bias grad: -9.184835107589606e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.537123004411114e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.070050512287708e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.3107469385431614e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.1197462299605832e-06
sam_encoder.blocks.2.norm2.weight grad: -4.644350156013388e-06
sam_encoder.blocks.2.norm2.bias grad: 7.19597937859362e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.5729536901053507e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.3001080080575775e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.156976279366063e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.576467962484458e-07
sam_encoder.blocks.3.norm1.weight grad: -9.37662844080478e-06
sam_encoder.blocks.3.norm1.bias grad: -4.000508852186613e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.500339961552527e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.3601014643427334e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.7166500987950712e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.797968138816941e-06
sam_encoder.blocks.3.norm2.weight grad: 1.149301533587277e-05
sam_encoder.blocks.3.norm2.bias grad: -3.918837023775268e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 9.046778359333985e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.001461209350964e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.6239157503150636e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.75359398580622e-07
sam_encoder.blocks.4.norm1.weight grad: 2.36330970437848e-06
sam_encoder.blocks.4.norm1.bias grad: -6.366517482092604e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.3448692470774404e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.01007306752399e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.201544108653252e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.103147024485224e-07
sam_encoder.blocks.4.norm2.weight grad: -2.8223534172866493e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0715370081015863e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.920163595059421e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.464509963028831e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.1107733775570523e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.662415343162138e-06
sam_encoder.blocks.5.norm1.weight grad: 5.287873136694543e-06
sam_encoder.blocks.5.norm1.bias grad: -7.644249308214057e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.2219493277807487e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.6083090486063156e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.3893056802771753e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.018823910380888e-07
sam_encoder.blocks.5.norm2.weight grad: -1.694108323135879e-05
sam_encoder.blocks.5.norm2.bias grad: -1.3563714674091898e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.3860733209585305e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.518984274502145e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.101919562846888e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.345536247754353e-06
sam_encoder.blocks.6.norm1.weight grad: 3.4374352253507823e-06
sam_encoder.blocks.6.norm1.bias grad: 3.3134990644612117e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.468730144755682e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5151826460169104e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3285489330883138e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.5543455939878186e-07
sam_encoder.blocks.6.norm2.weight grad: -7.894216651038732e-06
sam_encoder.blocks.6.norm2.bias grad: -2.276523446198553e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.215866505954182e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.3630007035535527e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.777088414200989e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.967462814420287e-07
sam_encoder.blocks.7.norm1.weight grad: 3.21061042996007e-06
sam_encoder.blocks.7.norm1.bias grad: 1.5058425333336345e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.6725589375710115e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.922105058038142e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 8.597108944741194e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0018788998422679e-06
sam_encoder.blocks.7.norm2.weight grad: 1.2481057183322264e-06
sam_encoder.blocks.7.norm2.bias grad: 2.374276846239809e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.2062458526761475e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.1761005680455128e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.1342048057704233e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.3396710301094572e-06
sam_encoder.blocks.8.norm1.weight grad: 2.2918720787856728e-06
sam_encoder.blocks.8.norm1.bias grad: -4.442051704245387e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.097793630033266e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.676375611888943e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.4796165689622285e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.648080438433681e-07
sam_encoder.blocks.8.norm2.weight grad: -2.8862873477919493e-06
sam_encoder.blocks.8.norm2.bias grad: -2.302361735928571e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.943926463354728e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0460283874635934e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.757709118370258e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.104699087292829e-07
sam_encoder.blocks.9.norm1.weight grad: -2.7386354304326233e-06
sam_encoder.blocks.9.norm1.bias grad: -2.472069979830849e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.0987808966310695e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.0057921069092117e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7320598999504e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.061054697667714e-07
sam_encoder.blocks.9.norm2.weight grad: -1.1598557421166333e-06
sam_encoder.blocks.9.norm2.bias grad: -2.38094617088791e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.728293442392896e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.361499688660842e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.848043471701203e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.015753004045109e-07
sam_encoder.blocks.10.norm1.weight grad: 3.4796964882843895e-06
sam_encoder.blocks.10.norm1.bias grad: -1.2667560440604575e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.081430238831672e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.310685188916977e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5981465821823804e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.821701496548485e-07
sam_encoder.blocks.10.norm2.weight grad: -2.6529128263064194e-06
sam_encoder.blocks.10.norm2.bias grad: -2.816486585288658e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.781605179639882e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.449714773116284e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0970519497277564e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.760255241213599e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2222726581967436e-05
sam_encoder.blocks.11.norm1.bias grad: -8.229885111177282e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.2631445517617976e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.152393888849474e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.318023462066776e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.2001150758515e-07
sam_encoder.blocks.11.norm2.weight grad: -3.789640686591156e-06
sam_encoder.blocks.11.norm2.bias grad: -2.992548388647265e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.172437565510336e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.2421108976923279e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.454483026464004e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.871380158670945e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.330366442038212e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.563209353771526e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.750927473651245e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.7527792553883046e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00020130109624005854
mask_decoder.transformer.layers.0.norm1.bias grad: 5.339697963790968e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003055735258385539
mask_decoder.transformer.layers.0.norm2.bias grad: 1.879280898720026e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -6.871501682326198e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.9891067495336756e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00012987393711227924
mask_decoder.transformer.layers.0.norm4.bias grad: -7.42835891287541e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.0443370128050447e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.97279587155208e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.929395850514993e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010840025788638741
mask_decoder.transformer.layers.1.norm3.weight grad: 5.558675911743194e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.69409821764566e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.4208380384370685e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015833694487810135
mask_decoder.transformer.norm_final_attn.weight grad: 6.9405696194735356e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.915374377858825e-05
Text_Embedding_Affine.0.weight grad: 4.49229585822164e-12
Text_Embedding_Affine.0.bias grad: 2.8302041266137223e-11
Text_Embedding_Affine.2.weight grad: 4.908910777867703e-11
Text_Embedding_Affine.2.bias grad: 2.242237314931117e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.412860926684357e-12
Max value: 0.997257649898529
Mean value: 0.07019379734992981

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.412860926684357e-12
Max value: 0.997257649898529
Mean value: 0.07019379734992981

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07697582244873047

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1098993793129921

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.062424659729003906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07697582244873047

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.856658935546875
Max value: 79.66632080078125
Mean value: 60.237491607666016

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0712261806766765e-11
Max value: 0.9969528913497925
Mean value: 0.07273001968860626

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0712261806766765e-11
Max value: 0.9969528913497925
Mean value: 0.07273001968860626

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0712261806766765e-11
Max value: 0.9969528913497925
Mean value: 0.07273001968860626

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1089167445898056

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9175395369529724
Max value: 2.430112361907959
Mean value: 1.0013625621795654

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.856658935546875
Max value: 79.66632080078125
Mean value: 60.237491607666016

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.2776985168457
Max value: -60.2776985168457
Mean value: -60.2776985168457
sam_encoder.pos_embed grad: -1.5421075527655148e-09
sam_encoder.blocks.0.norm1.weight grad: -4.3418385757831857e-05
sam_encoder.blocks.0.norm1.bias grad: -7.444989023497328e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1431424102047458e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.430356501776259e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.0082962944579776e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0855695791178732e-06
sam_encoder.blocks.0.norm2.weight grad: -3.7355410313466564e-05
sam_encoder.blocks.0.norm2.bias grad: 2.6905216145678423e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.5863141015870497e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.72060719403089e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.9904731743736193e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.5133477972995024e-05
sam_encoder.blocks.1.norm1.weight grad: -1.1306680789857637e-05
sam_encoder.blocks.1.norm1.bias grad: -2.8400767405400984e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.848501415224746e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.666430868383031e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.7560894775670022e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.653580152895302e-06
sam_encoder.blocks.1.norm2.weight grad: 2.0416051484062336e-05
sam_encoder.blocks.1.norm2.bias grad: 6.748865416739136e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3041480087849777e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.580152568043559e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.953550599864684e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.5903067378530977e-06
sam_encoder.blocks.2.norm1.weight grad: 8.789073035586625e-06
sam_encoder.blocks.2.norm1.bias grad: -1.216170312545728e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.2301032256800681e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.4182343167922227e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 6.387575922417454e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.8695767468889244e-06
sam_encoder.blocks.2.norm2.weight grad: -1.7084373382658669e-07
sam_encoder.blocks.2.norm2.bias grad: 2.638128307808074e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.8955489597137785e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.2917465710415854e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.2131756193412002e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.6246176528511569e-06
sam_encoder.blocks.3.norm1.weight grad: -2.9917136998847127e-06
sam_encoder.blocks.3.norm1.bias grad: -9.956947906175628e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.006407612498151e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.213327323057456e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.385291736572981e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.5093136173381936e-06
sam_encoder.blocks.3.norm2.weight grad: 3.996345185441896e-06
sam_encoder.blocks.3.norm2.bias grad: -1.9253475329605862e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2263842563697835e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.201732283741876e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.283774721145164e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.161125950005953e-07
sam_encoder.blocks.4.norm1.weight grad: 1.332796637143474e-05
sam_encoder.blocks.4.norm1.bias grad: 1.5633189605068765e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.8636718424386345e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.231792905149632e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.0758898143831175e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.4941092457738705e-06
sam_encoder.blocks.4.norm2.weight grad: -2.14360625250265e-05
sam_encoder.blocks.4.norm2.bias grad: -2.323632907064166e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.094993063423317e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.821256541414186e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.9418448573560454e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.0485882146203949e-07
sam_encoder.blocks.5.norm1.weight grad: 9.611807399778627e-06
sam_encoder.blocks.5.norm1.bias grad: -3.4661570680327713e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.510611572390189e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.2442578736227006e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.509538368642097e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.935688139084959e-06
sam_encoder.blocks.5.norm2.weight grad: -4.473823992157122e-06
sam_encoder.blocks.5.norm2.bias grad: -1.7428099454264157e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.2777700248989277e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.9375534066057298e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.082884738134453e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.057037004822632e-07
sam_encoder.blocks.6.norm1.weight grad: 9.30209523630765e-07
sam_encoder.blocks.6.norm1.bias grad: 2.6863399398280308e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.5419773262692615e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.097143684906769e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.0931892069929745e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.0328954519754916e-07
sam_encoder.blocks.6.norm2.weight grad: -1.1125288438051939e-05
sam_encoder.blocks.6.norm2.bias grad: -2.826183845172636e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.327342816803139e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.2226622604648583e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.111101255446556e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.5157527286646655e-06
sam_encoder.blocks.7.norm1.weight grad: 8.718045137356967e-06
sam_encoder.blocks.7.norm1.bias grad: -1.855905225056631e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.362512638384942e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.6648056064004777e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.5879071472445503e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.574476062975009e-07
sam_encoder.blocks.7.norm2.weight grad: -2.4744206257309997e-06
sam_encoder.blocks.7.norm2.bias grad: -5.594301910605282e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9967665139120072e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.1669416011272915e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.984191938703589e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0603882856230484e-06
sam_encoder.blocks.8.norm1.weight grad: 1.2344770766503643e-05
sam_encoder.blocks.8.norm1.bias grad: -2.4222010779340053e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0980580555042252e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.7947427244944265e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.007336545124417e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.3536026674264576e-06
sam_encoder.blocks.8.norm2.weight grad: -5.448907813843107e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4318538887891918e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.090843958692858e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.308654757143813e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.880859372249688e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.6194966292459867e-06
sam_encoder.blocks.9.norm1.weight grad: 2.210569846283761e-06
sam_encoder.blocks.9.norm1.bias grad: -5.764700290455949e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.815892005652131e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.344139708540752e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.6465539804121363e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1303166047582636e-07
sam_encoder.blocks.9.norm2.weight grad: -3.036012003576616e-06
sam_encoder.blocks.9.norm2.bias grad: -1.180629055852478e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.0436929187562782e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.215294270830782e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.4720795127896054e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.658321692360914e-07
sam_encoder.blocks.10.norm1.weight grad: 9.97289225779241e-06
sam_encoder.blocks.10.norm1.bias grad: 7.253367471093952e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.79308471060358e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.7852280507213436e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.3152329049480613e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0284027212037472e-06
sam_encoder.blocks.10.norm2.weight grad: -2.2749607069272315e-06
sam_encoder.blocks.10.norm2.bias grad: -1.1502529559948016e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.407592880146694e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.7172435917700568e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 7.689875474170549e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.4285855343132425e-07
sam_encoder.blocks.11.norm1.weight grad: 3.095026113442145e-05
sam_encoder.blocks.11.norm1.bias grad: 5.11893958332621e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.4839796323212795e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.2629259344976163e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.737001406989293e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4299603208201006e-06
sam_encoder.blocks.11.norm2.weight grad: 3.842710157186957e-06
sam_encoder.blocks.11.norm2.bias grad: 6.402615326805972e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.953226956175058e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 6.534029921567708e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.702648877559113e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.41491386279813e-08
sam_encoder.neck.conv1.trainable_scale grad: 6.97385985404253e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.5406039892695844e-05
sam_encoder.neck.conv2.trainable_scale grad: 8.478309609927237e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.506697678152705e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -2.138180934707634e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.179978426080197e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004981569480150938
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004221372364554554
mask_decoder.transformer.layers.0.norm3.weight grad: 1.3715929526370019e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -7.181355613283813e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001825180952437222
mask_decoder.transformer.layers.0.norm4.bias grad: -8.244287528214045e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.481503078248352e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.2286086429376155e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0002228759549325332
mask_decoder.transformer.layers.1.norm2.bias grad: -6.179841875564307e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.652700954466127e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.9776310839224607e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -6.453994865296409e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00020340189803391695
mask_decoder.transformer.norm_final_attn.weight grad: -1.6501523987244582e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4128090697340667e-05
Text_Embedding_Affine.0.weight grad: 4.206743460521967e-12
Text_Embedding_Affine.0.bias grad: 1.1531498672612273e-10
Text_Embedding_Affine.2.weight grad: -5.7307002893081105e-11
Text_Embedding_Affine.2.bias grad: 2.9393249860731885e-05
Epoch 33 finished with average loss: -60.5907
Epoch 34/39
----------
Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.6]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-58.6]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-64.1]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-64.1]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-60.5]Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-60.5]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.634460870622803e-11
Max value: 0.9918135404586792
Mean value: 0.07612039148807526

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.634460870622803e-11
Max value: 0.9918135404586792
Mean value: 0.07612039148807526

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07180547714233398

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10578019917011261

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06510305404663086

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07180547714233398

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 49.5035514831543
Max value: 73.77806091308594
Mean value: 58.57433319091797

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.634460870622803e-11
Max value: 0.9918135404586792
Mean value: 0.07612039148807526

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.634460870622803e-11
Max value: 0.9918135404586792
Mean value: 0.07612039148807526

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.634460870622803e-11
Max value: 0.9918135404586792
Mean value: 0.07612039148807526

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10578019917011261

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 49.5035514831543
Max value: 73.77806091308594
Mean value: 58.57433319091797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.57551956176758
Max value: -58.57551956176758
Mean value: -58.57551956176758
sam_encoder.pos_embed grad: 3.7851161094337726e-10
sam_encoder.blocks.0.norm1.weight grad: 4.0778624679660425e-05
sam_encoder.blocks.0.norm1.bias grad: 6.3804982346482575e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.6998320663551567e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.310492478978631e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.7549884837062564e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.2031868834583292e-07
sam_encoder.blocks.0.norm2.weight grad: -9.144545401795767e-06
sam_encoder.blocks.0.norm2.bias grad: -1.779820740921423e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.2502737162285484e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.0876957478321856e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.9287336928973673e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.029584268508188e-06
sam_encoder.blocks.1.norm1.weight grad: -1.1064008504035883e-05
sam_encoder.blocks.1.norm1.bias grad: -1.2074876394763123e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.150863439164823e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.679520189820323e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.265608998186508e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.7078347980259423e-07
sam_encoder.blocks.1.norm2.weight grad: -9.08895890461281e-06
sam_encoder.blocks.1.norm2.bias grad: -7.105919848982012e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.0419047359609976e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3728551948588574e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.862696419470012e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.9408518880936754e-07
sam_encoder.blocks.2.norm1.weight grad: 2.0005063561256975e-06
sam_encoder.blocks.2.norm1.bias grad: 3.5760053833655547e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.5222561816917732e-08
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.667961992614437e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.1354480850277469e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.0567766821623081e-06
sam_encoder.blocks.2.norm2.weight grad: 9.83678637567209e-06
sam_encoder.blocks.2.norm2.bias grad: -2.4494793251506053e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.656634129991289e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.0566326384141576e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.828495421970729e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.0460182642855216e-07
sam_encoder.blocks.3.norm1.weight grad: 2.5361532607348636e-06
sam_encoder.blocks.3.norm1.bias grad: 3.816233856923645e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.141815108800074e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.118557404173771e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.5800035220745485e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.7352316490359954e-06
sam_encoder.blocks.3.norm2.weight grad: -1.0119922080775723e-05
sam_encoder.blocks.3.norm2.bias grad: -1.2546453035611194e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.241092473326717e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.8770732569682878e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.098334334732499e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.014750286136405e-07
sam_encoder.blocks.4.norm1.weight grad: -6.70753070153296e-06
sam_encoder.blocks.4.norm1.bias grad: 2.103949100273894e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.920582796330564e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.433068175378139e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.6732868718681857e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.1993611173675163e-06
sam_encoder.blocks.4.norm2.weight grad: 8.123247425828595e-07
sam_encoder.blocks.4.norm2.bias grad: 4.634041033568792e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.0710419903480215e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.1250953068374656e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.7953602713969303e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.869021500373492e-07
sam_encoder.blocks.5.norm1.weight grad: -1.0276889952365309e-05
sam_encoder.blocks.5.norm1.bias grad: -5.946033638792869e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.279867531906348e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.480959213040478e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.075003860431025e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.0733421024488052e-06
sam_encoder.blocks.5.norm2.weight grad: 8.291323752018798e-07
sam_encoder.blocks.5.norm2.bias grad: -1.8414278883938096e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.6876969084478333e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.0235862646368332e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.153692654857878e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.573444923356874e-07
sam_encoder.blocks.6.norm1.weight grad: -4.4701705519401e-06
sam_encoder.blocks.6.norm1.bias grad: -2.59980583905417e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.156122718588449e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.5506540762544319e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.272698227694491e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.601694748387672e-06
sam_encoder.blocks.6.norm2.weight grad: -1.2302350569370901e-06
sam_encoder.blocks.6.norm2.bias grad: -3.12794190904242e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.313774747468415e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.05546416004654e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.028210807722644e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.657135998011654e-08
sam_encoder.blocks.7.norm1.weight grad: -6.258835583139444e-07
sam_encoder.blocks.7.norm1.bias grad: -1.3393669178185519e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.3289358093970804e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.720258400288003e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.0300218491465785e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.275794923269132e-07
sam_encoder.blocks.7.norm2.weight grad: 6.808219040976837e-06
sam_encoder.blocks.7.norm2.bias grad: -5.209010396356462e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.694108611147385e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.81903612883616e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.5872210497036576e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.151360250645666e-07
sam_encoder.blocks.8.norm1.weight grad: -6.504036491605802e-07
sam_encoder.blocks.8.norm1.bias grad: -5.645194391945552e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.173772716356325e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.354088846663217e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.6240293209411902e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.337692421860993e-06
sam_encoder.blocks.8.norm2.weight grad: 2.0519550503195205e-07
sam_encoder.blocks.8.norm2.bias grad: 1.9807234821200836e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.868301731330575e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.034363539380138e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.06261744198855e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.441237670491319e-08
sam_encoder.blocks.9.norm1.weight grad: -1.348608520856942e-06
sam_encoder.blocks.9.norm1.bias grad: -4.564242033211485e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.6507517557329265e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3856473515261314e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.301039323057921e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.082172324615385e-07
sam_encoder.blocks.9.norm2.weight grad: 1.1341035133227706e-07
sam_encoder.blocks.9.norm2.bias grad: 2.2243120838538744e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.3442022464005277e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.895408985319591e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8529003398271016e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.628798003139309e-07
sam_encoder.blocks.10.norm1.weight grad: -1.586749249327113e-06
sam_encoder.blocks.10.norm1.bias grad: 1.0072142231365433e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.8816866713677882e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.989410164555011e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.454681730858283e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.251774043950718e-07
sam_encoder.blocks.10.norm2.weight grad: -3.238586714360281e-06
sam_encoder.blocks.10.norm2.bias grad: 8.08976608368539e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.628849172964692e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.2384565479806042e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.31410092258011e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.11121385216029e-08
sam_encoder.blocks.11.norm1.weight grad: -6.122030299593462e-06
sam_encoder.blocks.11.norm1.bias grad: 2.3180493826657766e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.9645267457235605e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.858561825609286e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.0064526868045505e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.5436801820433175e-07
sam_encoder.blocks.11.norm2.weight grad: 3.117257392659667e-06
sam_encoder.blocks.11.norm2.bias grad: 3.1485967610933585e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.8950059888520627e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.0458519972853537e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.2127601394240628e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.4428735539695481e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.111435944447294e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.1703301424859092e-05
sam_encoder.neck.conv2.trainable_scale grad: 5.053534550825134e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.092969902558252e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00016302312724292278
mask_decoder.transformer.layers.0.norm1.bias grad: 4.5508204493671656e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0030878440011292696
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00013849616516381502
mask_decoder.transformer.layers.0.norm3.weight grad: 3.0430543120019138e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.9621867472305894e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.686202348442748e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.3718166630715132e-07
mask_decoder.transformer.layers.1.norm1.weight grad: -2.3535118089057505e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.362953975738492e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 4.169549356447533e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.882633897475898e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -1.9186500139767304e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.916393739520572e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.8334488888503984e-07
mask_decoder.transformer.layers.1.norm4.bias grad: 5.116597458254546e-05
mask_decoder.transformer.norm_final_attn.weight grad: -8.270069884019904e-06
mask_decoder.transformer.norm_final_attn.bias grad: -9.815991688810755e-06
Text_Embedding_Affine.0.weight grad: -1.200059322747915e-11
Text_Embedding_Affine.0.bias grad: -4.990065582965997e-10
Text_Embedding_Affine.2.weight grad: -9.501003456202639e-11
Text_Embedding_Affine.2.bias grad: -2.067520108539611e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.591467203806658e-11
Max value: 0.9978894591331482
Mean value: 0.1001272201538086

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.591467203806658e-11
Max value: 0.9978894591331482
Mean value: 0.1001272201538086

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10048437118530273

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.740251541137695
Max value: -1.1920928244535389e-07
Mean value: -0.12651434540748596

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0931239128112793

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10048437118530273

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 55.54950714111328
Max value: 84.75556945800781
Mean value: 69.55126190185547

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.60090193510743e-11
Max value: 0.9979156851768494
Mean value: 0.10080888122320175

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.60090193510743e-11
Max value: 0.9979156851768494
Mean value: 0.10080888122320175

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.60090193510743e-11
Max value: 0.9979156851768494
Mean value: 0.10080888122320175

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.707785606384277
Max value: -1.1920928244535389e-07
Mean value: -0.1264653205871582

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9191107153892517
Max value: 1.0913710594177246
Mean value: 1.0000580549240112

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 55.54950714111328
Max value: 84.75556945800781
Mean value: 69.55126190185547

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.55744934082031
Max value: -69.55744934082031
Mean value: -69.55744934082031
sam_encoder.pos_embed grad: -2.696302514593185e-09
sam_encoder.blocks.0.norm1.weight grad: 2.0662982933572493e-05
sam_encoder.blocks.0.norm1.bias grad: 5.545829026232241e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.050775691486706e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.755910130275879e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.3930194831555127e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.455858733213972e-07
sam_encoder.blocks.0.norm2.weight grad: 4.643715328711551e-06
sam_encoder.blocks.0.norm2.bias grad: -4.0318595893040765e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6153639990079682e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.7907068468048237e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.3161250535631552e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.6875500124297105e-06
sam_encoder.blocks.1.norm1.weight grad: 6.2185313254303765e-06
sam_encoder.blocks.1.norm1.bias grad: 9.43861323321471e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.050078809494153e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.23291021939076e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.4497056630207226e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.4801660149241798e-06
sam_encoder.blocks.1.norm2.weight grad: 9.91083652479574e-07
sam_encoder.blocks.1.norm2.bias grad: -1.1824516832348309e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.2116141634760424e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.441213548034284e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.89256103214575e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.641531236553419e-07
sam_encoder.blocks.2.norm1.weight grad: -1.5551082469755784e-05
sam_encoder.blocks.2.norm1.bias grad: 4.345824891061056e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0555496373854112e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.7439043606136693e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.604655027331319e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.43543603978469e-06
sam_encoder.blocks.2.norm2.weight grad: -7.343161087192129e-06
sam_encoder.blocks.2.norm2.bias grad: -3.46024853214999e-09
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.6291482906090096e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.899036412098212e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.3707583497744054e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.947450520376151e-07
sam_encoder.blocks.3.norm1.weight grad: -3.0809051168034784e-06
sam_encoder.blocks.3.norm1.bias grad: 4.575062121148221e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.402475277245685e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.018706481976551e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.1208441012277035e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.4050104912021197e-06
sam_encoder.blocks.3.norm2.weight grad: -9.660653631726746e-06
sam_encoder.blocks.3.norm2.bias grad: -5.619858711725101e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.269245881820098e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.627316007419722e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.1360252756276168e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.601997432018834e-07
sam_encoder.blocks.4.norm1.weight grad: -1.2451507700461661e-06
sam_encoder.blocks.4.norm1.bias grad: -5.1395104492257815e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.5063695829885546e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.946987802322838e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.2223657651920803e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.214619371443405e-06
sam_encoder.blocks.4.norm2.weight grad: 5.115861313242931e-06
sam_encoder.blocks.4.norm2.bias grad: 5.379995855037123e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.825161916713114e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 6.502882570202928e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.221884056387353e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.442010089813266e-07
sam_encoder.blocks.5.norm1.weight grad: 6.739501259289682e-06
sam_encoder.blocks.5.norm1.bias grad: -1.8847031242330559e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.679389687429648e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.2283237487717997e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.128843334503472e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.164206472978549e-07
sam_encoder.blocks.5.norm2.weight grad: 8.397470992349554e-06
sam_encoder.blocks.5.norm2.bias grad: 7.6079440987086855e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.2948567018611357e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.299280931263638e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.831586011277977e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.6477405867808557e-07
sam_encoder.blocks.6.norm1.weight grad: 5.226155735726934e-06
sam_encoder.blocks.6.norm1.bias grad: -3.226675744372187e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.092887138540391e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.3114603209251072e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.876892608583148e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.451624029868981e-07
sam_encoder.blocks.6.norm2.weight grad: 5.191433956497349e-06
sam_encoder.blocks.6.norm2.bias grad: 2.4372836833208567e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.142075572919566e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.193288299982669e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.483924153144471e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.224774272643117e-07
sam_encoder.blocks.7.norm1.weight grad: 5.740267852161196e-07
sam_encoder.blocks.7.norm1.bias grad: -7.16354065843916e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.491697384561121e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.5789542468810396e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.110832158701669e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7215090508670983e-07
sam_encoder.blocks.7.norm2.weight grad: 8.005587801562797e-07
sam_encoder.blocks.7.norm2.bias grad: -1.0250448667648016e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.8703846649259503e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.236270226305351e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.729532972509332e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.769634748910903e-07
sam_encoder.blocks.8.norm1.weight grad: -4.7405927716681617e-07
sam_encoder.blocks.8.norm1.bias grad: 9.368022801936604e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.143908078433014e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.782978173054289e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.595958449091995e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.0346598173782695e-06
sam_encoder.blocks.8.norm2.weight grad: 1.7549964468344115e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0754497452580836e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.5893483502368326e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.5935940445597225e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.9915192694952566e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.4098295625663013e-07
sam_encoder.blocks.9.norm1.weight grad: 3.744364221347496e-06
sam_encoder.blocks.9.norm1.bias grad: 3.176093628098897e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.263080998294754e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.292225857076119e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.113734798418591e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.515289783237677e-07
sam_encoder.blocks.9.norm2.weight grad: 2.4914772893680492e-06
sam_encoder.blocks.9.norm2.bias grad: 1.906267243612092e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.615116384025896e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 4.913854354526848e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.756088915451983e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.694058700100868e-07
sam_encoder.blocks.10.norm1.weight grad: -8.427429065704928e-08
sam_encoder.blocks.10.norm1.bias grad: 1.765602746672812e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.4470344922301592e-08
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.44557127063672e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.887991617077205e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.6426235422150057e-07
sam_encoder.blocks.10.norm2.weight grad: 5.006371793569997e-06
sam_encoder.blocks.10.norm2.bias grad: 1.3696194400836248e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.7713271063257707e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.431039416085696e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.643552185574663e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.076595582271693e-07
sam_encoder.blocks.11.norm1.weight grad: -9.999112990044523e-06
sam_encoder.blocks.11.norm1.bias grad: 1.9579538275138475e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.282361831224989e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.534598190275574e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.096531261486234e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.181529910354584e-06
sam_encoder.blocks.11.norm2.weight grad: 1.621357057501882e-07
sam_encoder.blocks.11.norm2.bias grad: 1.4530544376611942e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.827743455531163e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.7107649341596698e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.050787497244528e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.7158437748985307e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.488941390765831e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.6554404282942414e-05
sam_encoder.neck.conv2.trainable_scale grad: 4.856710802414455e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.5610312402714044e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010150526941288263
mask_decoder.transformer.layers.0.norm1.bias grad: -4.175795766059309e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004036875441670418
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002916196535807103
mask_decoder.transformer.layers.0.norm3.weight grad: -1.0369003575760871e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -3.667411147034727e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011609598732320592
mask_decoder.transformer.layers.0.norm4.bias grad: 9.692665116745047e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.750054383999668e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 7.224480214063078e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -8.509102190146223e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00014060383546166122
mask_decoder.transformer.layers.1.norm3.weight grad: -5.899214738747105e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.5455944675486535e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.458021481288597e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00014116954116616398
mask_decoder.transformer.norm_final_attn.weight grad: -2.2294534574029967e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.460295698052505e-05
Text_Embedding_Affine.0.weight grad: 6.618044220280117e-12
Text_Embedding_Affine.0.bias grad: 2.643645580224785e-10
Text_Embedding_Affine.2.weight grad: 5.307017846012396e-14
Text_Embedding_Affine.2.bias grad: -1.689748023636639e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.262860038237946e-11
Max value: 0.999213695526123
Mean value: 0.06877243518829346

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.262860038237946e-11
Max value: 0.999213695526123
Mean value: 0.06877243518829346

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0744791030883789

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.906250953674316
Max value: -1.1920928244535389e-07
Mean value: -0.10635215044021606

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05805015563964844

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0744791030883789

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 43.90309143066406
Max value: 60.11034393310547
Mean value: 53.26343536376953

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.7646177921659678e-11
Max value: 0.9991992115974426
Mean value: 0.0699317455291748

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7646177921659678e-11
Max value: 0.9991992115974426
Mean value: 0.0699317455291748

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.7646177921659678e-11
Max value: 0.9991992115974426
Mean value: 0.0699317455291748

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.112323760986328
Max value: -1.1920928244535389e-07
Mean value: -0.10612429678440094

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8137738704681396
Max value: 1.0926082134246826
Mean value: 1.0002549886703491

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 43.90309143066406
Max value: 60.11034393310547
Mean value: 53.26343536376953

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.277984619140625
Max value: -53.277984619140625
Mean value: -53.277984619140625
sam_encoder.pos_embed grad: 1.4328189745782538e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00011096338130300865
sam_encoder.blocks.0.norm1.bias grad: 5.241102917352691e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.763775071594864e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.152942321728915e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.4578627997252624e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8856351289286977e-06
sam_encoder.blocks.0.norm2.weight grad: -2.212093022535555e-05
sam_encoder.blocks.0.norm2.bias grad: -7.567999273305759e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6911488273763098e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.566132937114162e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.105006958823651e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.5434861779795028e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2648934898606967e-05
sam_encoder.blocks.1.norm1.bias grad: 1.3817893886880483e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.532731276820414e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.010717020719312e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.268782949016895e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.7962784012488555e-06
sam_encoder.blocks.1.norm2.weight grad: -8.222306860261597e-06
sam_encoder.blocks.1.norm2.bias grad: -1.2159553079982288e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.4369661585078575e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8951166111946804e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.721698365348857e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.2109937819768675e-06
sam_encoder.blocks.2.norm1.weight grad: -3.4211432648589835e-05
sam_encoder.blocks.2.norm1.bias grad: 1.594820605532732e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.955942570930347e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.430905730463564e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.73089936451288e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.758163181075361e-06
sam_encoder.blocks.2.norm2.weight grad: -5.155993676453363e-06
sam_encoder.blocks.2.norm2.bias grad: -1.6350331861758605e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.2158717405982316e-08
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.189817905673408e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.9788441932178102e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.539246103580808e-06
sam_encoder.blocks.3.norm1.weight grad: 1.5411786080221646e-05
sam_encoder.blocks.3.norm1.bias grad: 6.794052296754671e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.3257346836326178e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.2371759668167215e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.9005046649836e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.4322069849586114e-06
sam_encoder.blocks.3.norm2.weight grad: -6.0317885072436184e-05
sam_encoder.blocks.3.norm2.bias grad: -5.495926598086953e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.666838503908366e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.6671128832967952e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.197313945856877e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.520399215834914e-06
sam_encoder.blocks.4.norm1.weight grad: -5.253147719486151e-06
sam_encoder.blocks.4.norm1.bias grad: -3.436331894590694e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.780644525861135e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.5929845075297635e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.3689418614812894e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.9020065994700417e-06
sam_encoder.blocks.4.norm2.weight grad: -1.2246493497514166e-05
sam_encoder.blocks.4.norm2.bias grad: -2.988326014019549e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.042658696969738e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.4781320462352596e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.7537593066663248e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.1100227058923338e-06
sam_encoder.blocks.5.norm1.weight grad: -1.560752571094781e-05
sam_encoder.blocks.5.norm1.bias grad: -1.696859544608742e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.1706654731824528e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.663741366239265e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.8800981201347895e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.351443850391661e-07
sam_encoder.blocks.5.norm2.weight grad: -1.807750595617108e-05
sam_encoder.blocks.5.norm2.bias grad: -3.301494143670425e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.157219781423919e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9838798834825866e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.848442586080637e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4017909961694386e-06
sam_encoder.blocks.6.norm1.weight grad: -1.66545833053533e-05
sam_encoder.blocks.6.norm1.bias grad: -3.1338011012849165e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.159476015454857e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.6482719900068332e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.593801693568821e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.4757741812209133e-06
sam_encoder.blocks.6.norm2.weight grad: -1.1592715964070521e-05
sam_encoder.blocks.6.norm2.bias grad: 2.999141997861443e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.1242633263464086e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.4966886889596935e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6763606254244223e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.3338164990273071e-06
sam_encoder.blocks.7.norm1.weight grad: 1.94605891010724e-05
sam_encoder.blocks.7.norm1.bias grad: -4.14585792896105e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.2112918739148881e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.59265720564872e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.283283720316831e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.582168690423714e-06
sam_encoder.blocks.7.norm2.weight grad: 1.3484476767189335e-05
sam_encoder.blocks.7.norm2.bias grad: 7.040832770144334e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.1163580893480685e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.948371729871724e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.6905232769204304e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.267842094421212e-06
sam_encoder.blocks.8.norm1.weight grad: 1.1196054401807487e-05
sam_encoder.blocks.8.norm1.bias grad: -5.351927939045709e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0038753316621296e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.56227280665189e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.9492600788216805e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.953193183609983e-06
sam_encoder.blocks.8.norm2.weight grad: -6.519027920148801e-06
sam_encoder.blocks.8.norm2.bias grad: 7.429334800690413e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.17001671041362e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.531260740099242e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.7348737603460904e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.422046580046299e-06
sam_encoder.blocks.9.norm1.weight grad: -6.788758355469326e-07
sam_encoder.blocks.9.norm1.bias grad: -1.3398780538409483e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.822936941513035e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1735492080333643e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.3696596568024688e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.307018338702619e-07
sam_encoder.blocks.9.norm2.weight grad: -8.106617315206677e-06
sam_encoder.blocks.9.norm2.bias grad: -1.4055694919079542e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.949154678499326e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.760922365676379e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.287477738922462e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.289046498546668e-07
sam_encoder.blocks.10.norm1.weight grad: -6.086366965973866e-07
sam_encoder.blocks.10.norm1.bias grad: 1.4809113508817973e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.977645176040824e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.227286348803318e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.925552267806779e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.30651665131154e-06
sam_encoder.blocks.10.norm2.weight grad: -2.1860183551325463e-05
sam_encoder.blocks.10.norm2.bias grad: -4.47194543085061e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.865839845384471e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.941664767306065e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.7225265714369016e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.155509820222505e-07
sam_encoder.blocks.11.norm1.weight grad: -9.16924182092771e-06
sam_encoder.blocks.11.norm1.bias grad: 4.847180207434576e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.032518518215511e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.099996087665204e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.442635261308169e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.126948857039679e-06
sam_encoder.blocks.11.norm2.weight grad: 2.8228741939528845e-06
sam_encoder.blocks.11.norm2.bias grad: -1.106983177123766e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.214889462948122e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.93233175752539e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.7183688164077466e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.1293154734157724e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.3053795555606484e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.809527020668611e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8990904209204018e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.332694930373691e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00018497010751161724
mask_decoder.transformer.layers.0.norm1.bias grad: 5.0143280532211065e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0015943523030728102
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0006932509131729603
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00016605539713054895
mask_decoder.transformer.layers.0.norm3.bias grad: -6.270258745644242e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -3.329548053443432e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.5536177165340632e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.316538929240778e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.14789997698972e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0005712509737350047
mask_decoder.transformer.layers.1.norm2.bias grad: -6.006594048812985e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 9.65679791988805e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.5745448510861024e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00012063518079230562
mask_decoder.transformer.layers.1.norm4.bias grad: 4.6460641897283494e-05
mask_decoder.transformer.norm_final_attn.weight grad: -7.618542895215796e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2053224054398015e-06
Text_Embedding_Affine.0.weight grad: 1.1823375611896836e-11
Text_Embedding_Affine.0.bias grad: 7.913476540721831e-10
Text_Embedding_Affine.2.weight grad: 1.387287368315171e-10
Text_Embedding_Affine.2.bias grad: -4.271628858987242e-05
Epoch 34 finished with average loss: -60.4703
Epoch 35/39
----------
Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s, loss=-63.7]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.03it/s, loss=-63.7]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.03it/s, loss=-63.8]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-63.8]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-61.1]Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-61.1]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.664170686982885e-11
Max value: 0.9975100755691528
Mean value: 0.09900123625993729

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.664170686982885e-11
Max value: 0.9975100755691528
Mean value: 0.09900123625993729

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1007232666015625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.395853042602539
Max value: -1.1920928244535389e-07
Mean value: -0.1363048553466797

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08660268783569336

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1007232666015625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.301422119140625
Max value: 82.43684387207031
Mean value: 63.6561279296875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.664170686982885e-11
Max value: 0.9975100755691528
Mean value: 0.09900123625993729

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.664170686982885e-11
Max value: 0.9975100755691528
Mean value: 0.09900123625993729

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.664170686982885e-11
Max value: 0.9975100755691528
Mean value: 0.09900123625993729

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.395853042602539
Max value: -1.1920928244535389e-07
Mean value: -0.1363048553466797

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.301422119140625
Max value: 82.43684387207031
Mean value: 63.6561279296875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.657569885253906
Max value: -63.657569885253906
Mean value: -63.657569885253906
sam_encoder.pos_embed grad: -1.4924660618476082e-08
sam_encoder.blocks.0.norm1.weight grad: 4.561338573694229e-05
sam_encoder.blocks.0.norm1.bias grad: 2.6126317607122473e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.974239911665791e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.97677626501536e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.205922090884997e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.969796792574925e-07
sam_encoder.blocks.0.norm2.weight grad: 1.6486817912664264e-05
sam_encoder.blocks.0.norm2.bias grad: 3.112376725766808e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.4309098332887515e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.7774030993678025e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.443823020963464e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.196174813841935e-06
sam_encoder.blocks.1.norm1.weight grad: 3.066163117182441e-06
sam_encoder.blocks.1.norm1.bias grad: 2.236850832559867e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.027583402901655e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.59341140917968e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.473559319099877e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.587680566852214e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0669590665202122e-05
sam_encoder.blocks.1.norm2.bias grad: -7.64014657761436e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.511327334621456e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.0263445296441205e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.685725566057954e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.3798210097302217e-07
sam_encoder.blocks.2.norm1.weight grad: -1.5536863884335617e-06
sam_encoder.blocks.2.norm1.bias grad: -3.322490329082939e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.816179858200485e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8836693698176532e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.82310962677002e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.1975961317366455e-06
sam_encoder.blocks.2.norm2.weight grad: -2.2806611013947986e-05
sam_encoder.blocks.2.norm2.bias grad: -1.5926859759929357e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.00755878520431e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.541962880466599e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 8.969424015958793e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.597013008198701e-06
sam_encoder.blocks.3.norm1.weight grad: -1.2674072422669269e-05
sam_encoder.blocks.3.norm1.bias grad: -2.2376079868990928e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.340349839068949e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.532691212309146e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.1223991097940598e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.5100275706790853e-06
sam_encoder.blocks.3.norm2.weight grad: 7.844289029890206e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1872916729771532e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.83557516115252e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.922111318388488e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.4539119547407608e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.6921696846548002e-06
sam_encoder.blocks.4.norm1.weight grad: 2.2818850993644446e-05
sam_encoder.blocks.4.norm1.bias grad: 6.540081358252792e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 9.054175279743504e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.222724106104579e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 9.562101695337333e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.742458142776741e-06
sam_encoder.blocks.4.norm2.weight grad: -4.6722630941076204e-05
sam_encoder.blocks.4.norm2.bias grad: -3.275762719567865e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.7368805604055524e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.0121645573235583e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.433606591192074e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.459794227950624e-07
sam_encoder.blocks.5.norm1.weight grad: 3.1988769478630275e-05
sam_encoder.blocks.5.norm1.bias grad: 1.0659870895324275e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.875424277386628e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.689475306600798e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.350437721877825e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 5.438788775791181e-06
sam_encoder.blocks.5.norm2.weight grad: 1.0195183222094784e-06
sam_encoder.blocks.5.norm2.bias grad: -1.3917515389039181e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.441102406526625e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.543206947957515e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.271600922336802e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.599545043973194e-06
sam_encoder.blocks.6.norm1.weight grad: 2.947838311229134e-06
sam_encoder.blocks.6.norm1.bias grad: 5.425613380793948e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.834588942983828e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.1884358173119836e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.8665166123810195e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.696498988072562e-07
sam_encoder.blocks.6.norm2.weight grad: 1.1264177146586007e-06
sam_encoder.blocks.6.norm2.bias grad: -3.842702881229343e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.678562946646707e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.6646816309039423e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.5010676861493266e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.937447783959215e-07
sam_encoder.blocks.7.norm1.weight grad: 1.1094630281149875e-05
sam_encoder.blocks.7.norm1.bias grad: -1.9322246203046234e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.213743396685459e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.155193437327398e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.981438112532487e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.7392055724485544e-06
sam_encoder.blocks.7.norm2.weight grad: 3.0321953090606257e-06
sam_encoder.blocks.7.norm2.bias grad: 9.86366103461478e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.352785488961672e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.363437362073455e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.497697419647011e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.106886770685378e-06
sam_encoder.blocks.8.norm1.weight grad: 8.244430318882223e-06
sam_encoder.blocks.8.norm1.bias grad: -1.1406559679016937e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.216581490050885e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.106752602543565e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5448425756403594e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.963410563301295e-06
sam_encoder.blocks.8.norm2.weight grad: 7.371721494564554e-06
sam_encoder.blocks.8.norm2.bias grad: 7.449161785189062e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.326888407988008e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.507772129931254e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.2577942243297002e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.8974138760750066e-07
sam_encoder.blocks.9.norm1.weight grad: 1.0240189112664666e-05
sam_encoder.blocks.9.norm1.bias grad: 8.91675881575793e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 7.103912139427848e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.467671715246979e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.654765921761282e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6557950175410951e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4074677892494947e-05
sam_encoder.blocks.9.norm2.bias grad: 2.608818022054038e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.0024490620708093e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.894152764085447e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.302619676214817e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.2607196708813717e-07
sam_encoder.blocks.10.norm1.weight grad: 9.006300388136879e-06
sam_encoder.blocks.10.norm1.bias grad: 2.9938414627395105e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.728451131086331e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.164051011277479e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.376465093017032e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.2589895226919907e-07
sam_encoder.blocks.10.norm2.weight grad: 1.8780274331220426e-05
sam_encoder.blocks.10.norm2.bias grad: 1.687907342784456e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.1931331755477004e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.252935691009043e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.00797683444398e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.091088723929715e-07
sam_encoder.blocks.11.norm1.weight grad: 2.4743098038015887e-05
sam_encoder.blocks.11.norm1.bias grad: -3.847514449262235e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.391602371673798e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.497745736553043e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.667878561624093e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2615105049462727e-07
sam_encoder.blocks.11.norm2.weight grad: 2.1632708012475632e-05
sam_encoder.blocks.11.norm2.bias grad: 4.774821263708873e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.3517730621970259e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.1877183321048506e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.20908884027449e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.9666593686906708e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4603010640712455e-06
sam_encoder.neck.conv1.trainable_shift grad: 9.896604751702398e-06
sam_encoder.neck.conv2.trainable_scale grad: 6.517075235024095e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.5271982596896123e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 3.516394644975662e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.915210982086137e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005408620461821556
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00018020771676674485
mask_decoder.transformer.layers.0.norm3.weight grad: 1.9198407244402915e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.3797986765857786e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00020923971896991134
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1771157005568966e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 1.533119302621344e-07
mask_decoder.transformer.layers.1.norm1.bias grad: 1.1675687346723862e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00032435153843834996
mask_decoder.transformer.layers.1.norm2.bias grad: -3.7100588087923825e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.320288331247866e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.4143679183907807e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -0.00015100227028597146
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0004024901718366891
mask_decoder.transformer.norm_final_attn.weight grad: -3.8373200368369e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.966061285609612e-06
Text_Embedding_Affine.0.weight grad: -1.1642301706027425e-12
Text_Embedding_Affine.0.bias grad: -2.021227768489453e-10
Text_Embedding_Affine.2.weight grad: 1.0644649051094746e-10
Text_Embedding_Affine.2.bias grad: 2.8107702746638097e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.031163203064737e-13
Max value: 0.9994499087333679
Mean value: 0.08308786153793335

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.031163203064737e-13
Max value: 0.9994499087333679
Mean value: 0.08308786153793335

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08015727996826172

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11150604486465454

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07489299774169922

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08015727996826172

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.93680953979492
Max value: 87.9619140625
Mean value: 64.03215026855469

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.5277060135910365e-13
Max value: 0.9995061159133911
Mean value: 0.08406445384025574

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5277060135910365e-13
Max value: 0.9995061159133911
Mean value: 0.08406445384025574

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5277060135910365e-13
Max value: 0.9995061159133911
Mean value: 0.08406445384025574

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11169864237308502

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7172699570655823
Max value: 1.0968050956726074
Mean value: 0.9998399019241333

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.93680953979492
Max value: 87.9619140625
Mean value: 64.03215026855469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.02143096923828
Max value: -64.02143096923828
Mean value: -64.02143096923828
sam_encoder.pos_embed grad: -4.271414333345547e-09
sam_encoder.blocks.0.norm1.weight grad: 1.8189381080446765e-05
sam_encoder.blocks.0.norm1.bias grad: 5.883715402887901e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.763061042467598e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.6048574025262496e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.0682961146812886e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.0711683741155866e-08
sam_encoder.blocks.0.norm2.weight grad: 1.905338285723701e-05
sam_encoder.blocks.0.norm2.bias grad: -1.0032823411165737e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.587057446769904e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.792065404515597e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8246235413243994e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.815181455342099e-06
sam_encoder.blocks.1.norm1.weight grad: 5.0559597184474114e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3580985068983864e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.743213922774885e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.6187296953139594e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.20490037970012e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.5190827222540975e-06
sam_encoder.blocks.1.norm2.weight grad: 1.5789168173796497e-05
sam_encoder.blocks.1.norm2.bias grad: -4.78423316963017e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.7945275178353768e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5501321968258708e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.414063707576133e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.49530180237889e-07
sam_encoder.blocks.2.norm1.weight grad: -1.9122016965411603e-05
sam_encoder.blocks.2.norm1.bias grad: 6.729252163495403e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3591647075372748e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.3177107070514467e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1518534847709816e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.552773811563384e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0758580174297094e-05
sam_encoder.blocks.2.norm2.bias grad: 3.162338543916121e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.009749192046002e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.6281319403788075e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.5215863388439175e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.217067832243629e-07
sam_encoder.blocks.3.norm1.weight grad: -2.261278041260084e-06
sam_encoder.blocks.3.norm1.bias grad: -1.2089471965737175e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.06362312080455e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.3878173983102897e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2256435866220272e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.581095031928271e-06
sam_encoder.blocks.3.norm2.weight grad: -8.41765995573951e-06
sam_encoder.blocks.3.norm2.bias grad: -3.352074145368533e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.628869869018672e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.748938302625902e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.0087176128290594e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.035947256397776e-07
sam_encoder.blocks.4.norm1.weight grad: 8.208286999433767e-06
sam_encoder.blocks.4.norm1.bias grad: -3.1121571737458e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.0642559118423378e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.200827832955838e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.841122063226067e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.121775075167534e-07
sam_encoder.blocks.4.norm2.weight grad: -1.108899505197769e-05
sam_encoder.blocks.4.norm2.bias grad: -3.437252871663077e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -9.29596626519924e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.678677214542404e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.2868501875782385e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.367922651406843e-07
sam_encoder.blocks.5.norm1.weight grad: 8.313520993397105e-06
sam_encoder.blocks.5.norm1.bias grad: 1.2260751418580185e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.976984423090471e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.5762775496550603e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.984334272099659e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.5427531252498738e-07
sam_encoder.blocks.5.norm2.weight grad: 1.9986632651125547e-06
sam_encoder.blocks.5.norm2.bias grad: 2.21270852307498e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.197918092861073e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.182873105193721e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3497391364580835e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.724457245534722e-08
sam_encoder.blocks.6.norm1.weight grad: 5.811158985125076e-07
sam_encoder.blocks.6.norm1.bias grad: 9.090866797123454e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.1012878025649115e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.4639800813019974e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.2505888352952752e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.328288802455063e-07
sam_encoder.blocks.6.norm2.weight grad: -1.7167993746625143e-06
sam_encoder.blocks.6.norm2.bias grad: 6.51114859806512e-08
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.910899072754546e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.98047494754428e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.935347407008521e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.83004226275807e-07
sam_encoder.blocks.7.norm1.weight grad: 4.385864485811908e-06
sam_encoder.blocks.7.norm1.bias grad: -1.0378824981671642e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.706898496602662e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.098637979652267e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.799265411747911e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.893017143738689e-07
sam_encoder.blocks.7.norm2.weight grad: -1.555168637423776e-06
sam_encoder.blocks.7.norm2.bias grad: -5.860472924723581e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.651389330310394e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.934089025075082e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.815510111366166e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.329704203584697e-07
sam_encoder.blocks.8.norm1.weight grad: 4.208976861264091e-06
sam_encoder.blocks.8.norm1.bias grad: -1.483334415297577e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.445848728413694e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.942939318018034e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -8.360307219845708e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.081623157821014e-07
sam_encoder.blocks.8.norm2.weight grad: 5.497119673236739e-06
sam_encoder.blocks.8.norm2.bias grad: 2.253857473988319e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.035893536842195e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.4585295907163527e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.1235388228669763e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.1264607969205827e-07
sam_encoder.blocks.9.norm1.weight grad: 4.938512574881315e-06
sam_encoder.blocks.9.norm1.bias grad: -2.2547322942045867e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.951775397581514e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.6146955204021651e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.130349904902687e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.982606469638995e-07
sam_encoder.blocks.9.norm2.weight grad: 3.4793272334354697e-06
sam_encoder.blocks.9.norm2.bias grad: 2.3886063900135923e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7721729363984196e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.1394591865609982e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.9258293565703752e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.152069206815213e-07
sam_encoder.blocks.10.norm1.weight grad: 2.6920679374597967e-06
sam_encoder.blocks.10.norm1.bias grad: 1.255208417205722e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.9033617491004406e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.027360086591216e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.489531200604688e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.574912240850608e-08
sam_encoder.blocks.10.norm2.weight grad: 2.1042646949354094e-06
sam_encoder.blocks.10.norm2.bias grad: 1.3321663345777779e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.072232973659993e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.968282331039518e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.378356379675097e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.2260353205183492e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3935748938820325e-05
sam_encoder.blocks.11.norm1.bias grad: 2.211149649156141e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.942036533364444e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -9.774757927516475e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.1785618880821858e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.847663934830052e-07
sam_encoder.blocks.11.norm2.weight grad: 6.53543992257255e-08
sam_encoder.blocks.11.norm2.bias grad: 5.814746373289381e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.4449389002256794e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.90002946662571e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.093533440638566e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.82870143261971e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.6978599382564425e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.032711563515477e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.676826498936862e-07
sam_encoder.neck.conv2.trainable_shift grad: -5.435922503238544e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 2.3902153770904988e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.977995220338926e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00406989548355341
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006251751910895109
mask_decoder.transformer.layers.0.norm3.weight grad: -6.036921695340425e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.01770817511715e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -7.326123886741698e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.839926310116425e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.649408608907834e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.884825673594605e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.63413481763564e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00012300917296670377
mask_decoder.transformer.layers.1.norm3.weight grad: -2.8695638320641592e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.663951065391302e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 9.192196557705756e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 8.1869940913748e-05
mask_decoder.transformer.norm_final_attn.weight grad: -4.540794179774821e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2229483218106907e-05
Text_Embedding_Affine.0.weight grad: -8.27901636135664e-12
Text_Embedding_Affine.0.bias grad: -8.571766907383704e-11
Text_Embedding_Affine.2.weight grad: 2.9467147472095334e-11
Text_Embedding_Affine.2.bias grad: 8.774730304139666e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.082644721765561e-11
Max value: 0.9991750121116638
Mean value: 0.05767745524644852

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.082644721765561e-11
Max value: 0.9991750121116638
Mean value: 0.05767745524644852

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05670928955078125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.587416648864746
Max value: -1.1920928244535389e-07
Mean value: -0.08608990907669067

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04789924621582031

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05670928955078125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 45.302528381347656
Max value: 60.42387008666992
Mean value: 55.66526794433594

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.660451191629278e-11
Max value: 0.9992256164550781
Mean value: 0.0590897798538208

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.660451191629278e-11
Max value: 0.9992256164550781
Mean value: 0.0590897798538208

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.660451191629278e-11
Max value: 0.9992256164550781
Mean value: 0.0590897798538208

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.690729141235352
Max value: -1.1920928244535389e-07
Mean value: -0.0860760360956192

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8097234964370728
Max value: 1.1209717988967896
Mean value: 1.0000689029693604

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 45.302528381347656
Max value: 60.42387008666992
Mean value: 55.66526794433594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.66943359375
Max value: -55.66943359375
Mean value: -55.66943359375
sam_encoder.pos_embed grad: -4.672108033787481e-09
sam_encoder.blocks.0.norm1.weight grad: -4.373277988634072e-06
sam_encoder.blocks.0.norm1.bias grad: 7.0565176429227e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.10385726657114e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2135744782426627e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.4905690477462485e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.078530532249715e-07
sam_encoder.blocks.0.norm2.weight grad: 5.101448550703935e-05
sam_encoder.blocks.0.norm2.bias grad: -3.624827877501957e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6546195183764212e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.492340965749463e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.971629879146349e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.870590262522455e-06
sam_encoder.blocks.1.norm1.weight grad: -5.891531145607587e-06
sam_encoder.blocks.1.norm1.bias grad: -1.3571550880442373e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.925566711084684e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.670640131123946e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.200532202958129e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.847864710834983e-07
sam_encoder.blocks.1.norm2.weight grad: -4.474938032217324e-05
sam_encoder.blocks.1.norm2.bias grad: 2.0578618205036037e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.1101884410891216e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.1264221433957573e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.198359071480809e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.296998727364553e-07
sam_encoder.blocks.2.norm1.weight grad: -4.0933332456916105e-06
sam_encoder.blocks.2.norm1.bias grad: -1.5127921869861893e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.8016514786722837e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.1702943538693944e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.91683305578772e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.196461082348833e-06
sam_encoder.blocks.2.norm2.weight grad: -9.908649190037977e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0625177310430445e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.462632205104455e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.1064118957147002e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.471158030763036e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.378711982004461e-07
sam_encoder.blocks.3.norm1.weight grad: -1.047218574967701e-05
sam_encoder.blocks.3.norm1.bias grad: -2.9999059734109323e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.742396519461181e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.3214196314947912e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.10421068611322e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.0032936087518465e-06
sam_encoder.blocks.3.norm2.weight grad: 3.3926005471585086e-06
sam_encoder.blocks.3.norm2.bias grad: 4.773885393660748e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.386715997701685e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7309855593339307e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.1423146538145375e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.2911052016970643e-07
sam_encoder.blocks.4.norm1.weight grad: -5.462921762955375e-06
sam_encoder.blocks.4.norm1.bias grad: -7.003260975579906e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.004004484973848e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.428377112868475e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.313365030204295e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5003527096268954e-06
sam_encoder.blocks.4.norm2.weight grad: -3.4923621115012793e-06
sam_encoder.blocks.4.norm2.bias grad: 1.258504084944434e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.4357260574324755e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.506646867710515e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.591752025997266e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.1142581115564099e-06
sam_encoder.blocks.5.norm1.weight grad: 2.844413700131554e-07
sam_encoder.blocks.5.norm1.bias grad: -5.5881823755044024e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.407359483593609e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.698654604202602e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0037272204499459e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.3945407317805802e-06
sam_encoder.blocks.5.norm2.weight grad: 6.396941785169474e-07
sam_encoder.blocks.5.norm2.bias grad: -1.1170921425218694e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.40641088061966e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.739658017640977e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.1846981326234527e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.4704067413949815e-07
sam_encoder.blocks.6.norm1.weight grad: -1.581144601914275e-06
sam_encoder.blocks.6.norm1.bias grad: -1.5105000557014137e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.701002929621609e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.756048378520063e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.088020210067043e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.6222891190409428e-06
sam_encoder.blocks.6.norm2.weight grad: 1.03762772596383e-06
sam_encoder.blocks.6.norm2.bias grad: -8.305798473884352e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.7968844758797786e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 8.733240974834189e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1335645240251324e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.8359161180778756e-07
sam_encoder.blocks.7.norm1.weight grad: -2.803905545079033e-06
sam_encoder.blocks.7.norm1.bias grad: -9.911348115565488e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.2047112250002101e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.176032242256042e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.2052272186101618e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.614342520246282e-07
sam_encoder.blocks.7.norm2.weight grad: 1.1988489859504625e-05
sam_encoder.blocks.7.norm2.bias grad: -1.0289334113622317e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.486331585620064e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.4423652575933374e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.608052227515145e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.01667205854028e-06
sam_encoder.blocks.8.norm1.weight grad: -4.823349399885046e-07
sam_encoder.blocks.8.norm1.bias grad: -4.596083272190299e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.6780244322944782e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.180183145128467e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.5004830440120713e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.9108027774782386e-06
sam_encoder.blocks.8.norm2.weight grad: 5.354726454243064e-06
sam_encoder.blocks.8.norm2.bias grad: -1.3269890359879355e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.004009729716927e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.1024582136087702e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0737493312262814e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.834527089769836e-07
sam_encoder.blocks.9.norm1.weight grad: -4.073269337823149e-06
sam_encoder.blocks.9.norm1.bias grad: 1.5569041806884343e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.9004970605892595e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.58047521381377e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.724806442231056e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.118308763485402e-07
sam_encoder.blocks.9.norm2.weight grad: 4.077910034538945e-06
sam_encoder.blocks.9.norm2.bias grad: -1.9884737412212417e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.6814998338741134e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.865236284487764e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.374068432369313e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.4432824830000754e-07
sam_encoder.blocks.10.norm1.weight grad: -2.723395937209716e-06
sam_encoder.blocks.10.norm1.bias grad: -8.640330406706198e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.2475531952513848e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1888892004208174e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.380133364316862e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.998242151392333e-07
sam_encoder.blocks.10.norm2.weight grad: 3.1046397452882957e-06
sam_encoder.blocks.10.norm2.bias grad: -8.151197903316643e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.0067758466902887e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.052390982498764e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.5810810433977167e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.74794394069977e-07
sam_encoder.blocks.11.norm1.weight grad: -1.028441602102248e-05
sam_encoder.blocks.11.norm1.bias grad: -1.0117908004758647e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.025525413453579e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.028222300192283e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -8.687360377734876e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.1393355470754614e-07
sam_encoder.blocks.11.norm2.weight grad: -2.128297182935057e-06
sam_encoder.blocks.11.norm2.bias grad: -2.4344735720660537e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.6511543776687176e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.4065043362497818e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3790353250442422e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.8382910127456853e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.933930075727403e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.6214152967440896e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.9581420929171145e-08
sam_encoder.neck.conv2.trainable_shift grad: 6.61500816931948e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002730656124185771
mask_decoder.transformer.layers.0.norm1.bias grad: 2.8190333978272974e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0024938846472650766
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006114724092185497
mask_decoder.transformer.layers.0.norm3.weight grad: -3.059676237171516e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.53717972151935e-07
mask_decoder.transformer.layers.0.norm4.weight grad: -6.729405868100002e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.984163751942106e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.7434709409135394e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.164031896740198e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00025292730424553156
mask_decoder.transformer.layers.1.norm2.bias grad: 6.98547373758629e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.2808632163796574e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 4.557268039206974e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.3088032321538776e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 3.799068508669734e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0103387467097491e-05
mask_decoder.transformer.norm_final_attn.bias grad: 8.346081813215278e-06
Text_Embedding_Affine.0.weight grad: -2.6104670508564354e-11
Text_Embedding_Affine.0.bias grad: -6.794304008295171e-10
Text_Embedding_Affine.2.weight grad: 3.0054635863363544e-11
Text_Embedding_Affine.2.bias grad: 1.7757934983819723e-05
Epoch 35 finished with average loss: -61.1161
Epoch 36/39
----------
Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.7]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.00it/s, loss=-59.7]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.00it/s, loss=-60.1]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-60.1]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-63.3]Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-63.3]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.2538271596261872e-11
Max value: 0.9991957545280457
Mean value: 0.09167228639125824

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2538271596261872e-11
Max value: 0.9991957545280457
Mean value: 0.09167228639125824

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08367395401000977

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.010893821716309
Max value: -1.1920928244535389e-07
Mean value: -0.11848777532577515

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08091497421264648

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08367395401000977

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.06493377685547
Max value: 75.37255096435547
Mean value: 59.68151092529297

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.2538271596261872e-11
Max value: 0.9991957545280457
Mean value: 0.09167228639125824

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2538271596261872e-11
Max value: 0.9991957545280457
Mean value: 0.09167228639125824

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.2538271596261872e-11
Max value: 0.9991957545280457
Mean value: 0.09167228639125824

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.010893821716309
Max value: -1.1920928244535389e-07
Mean value: -0.11848777532577515

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.06493377685547
Max value: 75.37255096435547
Mean value: 59.68151092529297

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.68282699584961
Max value: -59.68282699584961
Mean value: -59.68282699584961
sam_encoder.pos_embed grad: 4.539558950966693e-09
sam_encoder.blocks.0.norm1.weight grad: -4.461831849766895e-05
sam_encoder.blocks.0.norm1.bias grad: 0.00011050191824324429
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.684828910394572e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.2261816664249636e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.2225289285415784e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.088919796340633e-06
sam_encoder.blocks.0.norm2.weight grad: 0.00011622846068348736
sam_encoder.blocks.0.norm2.bias grad: -8.923774294089526e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.593730358872563e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.7552760255057365e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.18691779486835e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.441494406317361e-06
sam_encoder.blocks.1.norm1.weight grad: -1.3187327567720786e-06
sam_encoder.blocks.1.norm1.bias grad: 1.7586196918273345e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.1222349460003898e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.509646366088418e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.5659446691861376e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.530903136881534e-05
sam_encoder.blocks.1.norm2.weight grad: -2.6254085241816938e-05
sam_encoder.blocks.1.norm2.bias grad: -3.4973181755049154e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.2188545699464157e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.897577698808163e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.323245957493782e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.993812126485864e-06
sam_encoder.blocks.2.norm1.weight grad: -4.239035115460865e-05
sam_encoder.blocks.2.norm1.bias grad: 7.788059519953094e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.149888289044611e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.009097655303776e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.0693153853935655e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.1867208488401957e-06
sam_encoder.blocks.2.norm2.weight grad: -3.09115021082107e-05
sam_encoder.blocks.2.norm2.bias grad: -1.3089864296489395e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.6894671716727316e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.2217559489945415e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3746488548349589e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.422792815399589e-06
sam_encoder.blocks.3.norm1.weight grad: -1.1242516848142259e-05
sam_encoder.blocks.3.norm1.bias grad: -3.907972768502077e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.708610034256708e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.153353079847875e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.261327143874951e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.345054210512899e-06
sam_encoder.blocks.3.norm2.weight grad: 1.7877220670925453e-05
sam_encoder.blocks.3.norm2.bias grad: 1.1724480827979278e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.4894437299517449e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.6487347137590405e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.057911039330065e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.922117689900915e-06
sam_encoder.blocks.4.norm1.weight grad: -1.8295781046617776e-05
sam_encoder.blocks.4.norm1.bias grad: 7.184356945799664e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.660719686304219e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.755034296977101e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.941814273071941e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.2106949018052546e-06
sam_encoder.blocks.4.norm2.weight grad: -2.933751602540724e-05
sam_encoder.blocks.4.norm2.bias grad: -1.714697282295674e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.2333812012220733e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.389620011759689e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.168801519379485e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.9817360882589128e-06
sam_encoder.blocks.5.norm1.weight grad: -1.7736914742272347e-05
sam_encoder.blocks.5.norm1.bias grad: 3.52380629919935e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.513967259204946e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.7852443054143805e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.86014050693484e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.003774840086407e-07
sam_encoder.blocks.5.norm2.weight grad: 2.4320517695741728e-05
sam_encoder.blocks.5.norm2.bias grad: 6.694492185488343e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 7.548820121883182e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.3726884137431625e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.487964128609747e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.7993787625746336e-06
sam_encoder.blocks.6.norm1.weight grad: -2.769990351225715e-05
sam_encoder.blocks.6.norm1.bias grad: -1.4706379261042457e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.1148934390803333e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.629363381056464e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.86764281251817e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.820044629625045e-06
sam_encoder.blocks.6.norm2.weight grad: 2.0509523892542347e-05
sam_encoder.blocks.6.norm2.bias grad: 6.0390048020053655e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.854229236021638e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.2168076156958705e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.289758973958669e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.5190425983746536e-06
sam_encoder.blocks.7.norm1.weight grad: -1.6105491340567823e-07
sam_encoder.blocks.7.norm1.bias grad: -2.347544523217948e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.4453605672315462e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.031130854149524e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.959096946142381e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.5498525246803183e-06
sam_encoder.blocks.7.norm2.weight grad: 1.8024891687673517e-05
sam_encoder.blocks.7.norm2.bias grad: 4.469645773497177e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.907614988449495e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.081554046322708e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.2779283881391166e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.245016948014381e-07
sam_encoder.blocks.8.norm1.weight grad: 1.1531106792972423e-05
sam_encoder.blocks.8.norm1.bias grad: -3.140896978948149e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.57481518323766e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.561789642641088e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.263392944878433e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.6532284108689055e-06
sam_encoder.blocks.8.norm2.weight grad: 7.601373908983078e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0784515325212851e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.8732581540680258e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.83240842691157e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.6906762994040037e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.390830087354971e-09
sam_encoder.blocks.9.norm1.weight grad: 1.2131861240050057e-06
sam_encoder.blocks.9.norm1.bias grad: -1.6835072074172786e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.277028094496927e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.53041468012816e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.8078391639828624e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.4925240066077095e-06
sam_encoder.blocks.9.norm2.weight grad: 1.0122375897481106e-05
sam_encoder.blocks.9.norm2.bias grad: 5.067536221758928e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.2817991925403476e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.6758551686943974e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.133070433454122e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.8186549368692795e-06
sam_encoder.blocks.10.norm1.weight grad: -8.58851126395166e-06
sam_encoder.blocks.10.norm1.bias grad: -9.756029157870216e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.561393780022627e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.3013827810937073e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4512846746583818e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.5676682702833205e-07
sam_encoder.blocks.10.norm2.weight grad: -7.232065399875864e-06
sam_encoder.blocks.10.norm2.bias grad: -1.6945373317867052e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.356977332368842e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8006521713687107e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.5123787306947634e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 6.75734440847009e-07
sam_encoder.blocks.11.norm1.weight grad: -1.7730897525325418e-05
sam_encoder.blocks.11.norm1.bias grad: 3.003808160428889e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.1726859813497867e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.093977506476222e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4974115174481994e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.709431043967925e-07
sam_encoder.blocks.11.norm2.weight grad: 1.0147920875169802e-05
sam_encoder.blocks.11.norm2.bias grad: 3.6878154787700623e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.713811343506677e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.1964773111449176e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.3720158449359587e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.291153340498568e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.402359187835827e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.805918590340298e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.8116179489879869e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.5092247597058304e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001298920251429081
mask_decoder.transformer.layers.0.norm1.bias grad: -2.9225193429738283e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0023887779098004103
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00013091927394270897
mask_decoder.transformer.layers.0.norm3.weight grad: 4.5224915083963424e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -0.00013300011050887406
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012984553177375346
mask_decoder.transformer.layers.0.norm4.bias grad: 7.831673428881913e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.986820204067044e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.841578968102112e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0003519354504533112
mask_decoder.transformer.layers.1.norm2.bias grad: 0.0002617402351461351
mask_decoder.transformer.layers.1.norm3.weight grad: 2.725329431996215e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.385948705021292e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00025100819766521454
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016008128295652568
mask_decoder.transformer.norm_final_attn.weight grad: 7.985672709764913e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.752232674334664e-05
Text_Embedding_Affine.0.weight grad: -2.019321342083824e-12
Text_Embedding_Affine.0.bias grad: 1.2185465136926865e-10
Text_Embedding_Affine.2.weight grad: -2.6417999732242237e-12
Text_Embedding_Affine.2.bias grad: -5.251395123195834e-07

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2826719721081847e-11
Max value: 0.9982602000236511
Mean value: 0.09552361816167831

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2826719721081847e-11
Max value: 0.9982602000236511
Mean value: 0.09552361816167831

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08823871612548828

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.838796615600586
Max value: -1.1920928244535389e-07
Mean value: -0.12246111780405045

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08715438842773438

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08823871612548828

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 50.45490646362305
Max value: 71.04881286621094
Mean value: 60.469703674316406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.893163990995266e-12
Max value: 0.9984561204910278
Mean value: 0.09526941925287247

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.893163990995266e-12
Max value: 0.9984561204910278
Mean value: 0.09526941925287247

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.893163990995266e-12
Max value: 0.9984561204910278
Mean value: 0.09526941925287247

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.143026351928711
Max value: -1.1920928244535389e-07
Mean value: -0.12241644412279129

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6558992266654968
Max value: 1.02510404586792
Mean value: 1.000060796737671

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 50.45490646362305
Max value: 71.04881286621094
Mean value: 60.469703674316406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.47480010986328
Max value: -60.47480010986328
Mean value: -60.47480010986328
sam_encoder.pos_embed grad: 1.766840340700071e-09
sam_encoder.blocks.0.norm1.weight grad: 1.0826304787769914e-05
sam_encoder.blocks.0.norm1.bias grad: 1.6257969036814757e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.244287753062963e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.7629005810704257e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.789479473605752e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.456715825857827e-07
sam_encoder.blocks.0.norm2.weight grad: 2.160650910809636e-05
sam_encoder.blocks.0.norm2.bias grad: -2.5375658879056573e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.3610190762847196e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.2955448457651073e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.0962765372823924e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.541015864058863e-06
sam_encoder.blocks.1.norm1.weight grad: -4.918776426166005e-07
sam_encoder.blocks.1.norm1.bias grad: 4.959755187883275e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.914522262173705e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.7300934587183292e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.802081432193518e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.8972008294658735e-06
sam_encoder.blocks.1.norm2.weight grad: -9.190775017486885e-06
sam_encoder.blocks.1.norm2.bias grad: 2.049710019491613e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.18942136093392e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.771340348317608e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1404040378693026e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.798664114488929e-07
sam_encoder.blocks.2.norm1.weight grad: -9.91080560197588e-06
sam_encoder.blocks.2.norm1.bias grad: 6.508410933747655e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.25519385014195e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.5820124847086845e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.487759840936633e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3290252809383674e-06
sam_encoder.blocks.2.norm2.weight grad: -2.910045111548243e-07
sam_encoder.blocks.2.norm2.bias grad: -3.7667857668566285e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.1603156003257027e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.4574804885778576e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.541021321027074e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0263756848871708e-06
sam_encoder.blocks.3.norm1.weight grad: -5.182116183277685e-06
sam_encoder.blocks.3.norm1.bias grad: 7.049434771033702e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.889220013457816e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1889119377883617e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.947006921909633e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.6252273528371006e-06
sam_encoder.blocks.3.norm2.weight grad: -1.8664368326426484e-05
sam_encoder.blocks.3.norm2.bias grad: -6.177297109388746e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.4122930224402808e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.6613272388640326e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.158715799145284e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.434148526248464e-07
sam_encoder.blocks.4.norm1.weight grad: -2.703004611248616e-06
sam_encoder.blocks.4.norm1.bias grad: -1.7485406260675518e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.5706249314462184e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.678540896449704e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.247880845767213e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.1653722797054797e-06
sam_encoder.blocks.4.norm2.weight grad: 1.673130645940546e-05
sam_encoder.blocks.4.norm2.bias grad: 1.31340348161757e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.088037586479913e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.395507858134806e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.523371105984552e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.684370070317527e-07
sam_encoder.blocks.5.norm1.weight grad: -2.329766175535042e-06
sam_encoder.blocks.5.norm1.bias grad: 7.432809070451185e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.248238003716324e-08
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.200546411288087e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.239293280581478e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.186966281049536e-07
sam_encoder.blocks.5.norm2.weight grad: 9.503097317065112e-06
sam_encoder.blocks.5.norm2.bias grad: 6.07915899308864e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.277700332342647e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 8.312675845445483e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.149670879385667e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.709733722549572e-07
sam_encoder.blocks.6.norm1.weight grad: -3.5766552173299715e-06
sam_encoder.blocks.6.norm1.bias grad: -2.0972481706849067e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.5528001995335217e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.7232740390227264e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.8029162447419367e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.95526968127524e-06
sam_encoder.blocks.6.norm2.weight grad: 5.182358108868357e-06
sam_encoder.blocks.6.norm2.bias grad: 2.991988367284648e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.2470542287701392e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.272065320445108e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.418921951630182e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.616798155941069e-07
sam_encoder.blocks.7.norm1.weight grad: -5.871224857401103e-07
sam_encoder.blocks.7.norm1.bias grad: -1.178531192636001e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.817091626639012e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.2170086089754477e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.526706440330599e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.999696562255849e-07
sam_encoder.blocks.7.norm2.weight grad: 1.0908490821748273e-06
sam_encoder.blocks.7.norm2.bias grad: -3.270527884069452e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.4970662221003295e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.411773832340259e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.594854428636609e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.532646234016283e-07
sam_encoder.blocks.8.norm1.weight grad: -4.777220965479501e-07
sam_encoder.blocks.8.norm1.bias grad: 1.4478107459581224e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.756625788919337e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.755878191848751e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.0271683044702513e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.9363086468947586e-06
sam_encoder.blocks.8.norm2.weight grad: 2.525707031963975e-06
sam_encoder.blocks.8.norm2.bias grad: 2.477632506270311e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.3032173973879253e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.796469604187223e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.70407507286086e-09
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.1732077938359e-07
sam_encoder.blocks.9.norm1.weight grad: 1.7273991943511646e-06
sam_encoder.blocks.9.norm1.bias grad: 2.1589926291198935e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.1615693438216113e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.9782214621955063e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.9232970771554392e-10
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.941876679571578e-07
sam_encoder.blocks.9.norm2.weight grad: 2.5388915219082264e-06
sam_encoder.blocks.9.norm2.bias grad: 2.6108862130058696e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.2702797391739296e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 7.122564511519158e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.202390861493768e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.54349025303236e-07
sam_encoder.blocks.10.norm1.weight grad: -4.202255695417989e-06
sam_encoder.blocks.10.norm1.bias grad: 5.698242944163212e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.7601358851825353e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.047682283380709e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6427018181275344e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.308766842266778e-07
sam_encoder.blocks.10.norm2.weight grad: -3.96023779103416e-07
sam_encoder.blocks.10.norm2.bias grad: 1.3418903108686209e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.159089475157089e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.34278058239579e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.340092113532592e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.441423240881704e-07
sam_encoder.blocks.11.norm1.weight grad: -1.4124756489763968e-05
sam_encoder.blocks.11.norm1.bias grad: 8.027586773096118e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.581024887149397e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.190856313674885e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.203160192948417e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.362938726553693e-07
sam_encoder.blocks.11.norm2.weight grad: 1.175630018224183e-06
sam_encoder.blocks.11.norm2.bias grad: 2.1645846572937444e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.2919057326143957e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.263727196805121e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.3923079222877277e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.691254105182452e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.836661097826436e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.62677897606045e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.0321246008970775e-06
sam_encoder.neck.conv2.trainable_shift grad: -6.501789357571397e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001432018616469577
mask_decoder.transformer.layers.0.norm1.bias grad: -6.253685569390655e-08
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0045985025353729725
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00012319348752498627
mask_decoder.transformer.layers.0.norm3.weight grad: 3.0321565645863302e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.4737204764969647e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001576019130880013
mask_decoder.transformer.layers.0.norm4.bias grad: 7.833891686459538e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.616940011852421e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.8553614609118085e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00010181110701523721
mask_decoder.transformer.layers.1.norm2.bias grad: -5.386689372244291e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.38753263046965e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.6693531001219526e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.3129453842993826e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001981645473279059
mask_decoder.transformer.norm_final_attn.weight grad: -1.4873921827529557e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3209404642111622e-05
Text_Embedding_Affine.0.weight grad: 1.231507951171551e-11
Text_Embedding_Affine.0.bias grad: 2.1115464932108807e-10
Text_Embedding_Affine.2.weight grad: -5.962917659640965e-11
Text_Embedding_Affine.2.bias grad: -3.7601261283271015e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.727731777431297e-13
Max value: 0.9988676309585571
Mean value: 0.07519951462745667

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.727731777431297e-13
Max value: 0.9988676309585571
Mean value: 0.07519951462745667

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07512950897216797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09420735388994217

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07197856903076172

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07512950897216797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 54.46112060546875
Max value: 89.22979736328125
Mean value: 69.84291076660156

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.27306059887349e-14
Max value: 0.9990804195404053
Mean value: 0.07379132509231567

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.27306059887349e-14
Max value: 0.9990804195404053
Mean value: 0.07379132509231567

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.27306059887349e-14
Max value: 0.9990804195404053
Mean value: 0.07379132509231567

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09437505900859833

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.48356932401657104
Max value: 1.0480923652648926
Mean value: 0.9999885559082031

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 54.46112060546875
Max value: 89.22979736328125
Mean value: 69.84291076660156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.83992767333984
Max value: -69.83992767333984
Mean value: -69.83992767333984
sam_encoder.pos_embed grad: 5.86063464425024e-09
sam_encoder.blocks.0.norm1.weight grad: 2.1642568754032254e-05
sam_encoder.blocks.0.norm1.bias grad: -1.163783781521488e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.4041833057708573e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.266681680244801e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.346999387256801e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0613595122777042e-06
sam_encoder.blocks.0.norm2.weight grad: 1.44631412695162e-05
sam_encoder.blocks.0.norm2.bias grad: -2.151043008780107e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.0910499592428096e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.4428946946718497e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.440954929421423e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.2909496945212595e-05
sam_encoder.blocks.1.norm1.weight grad: 6.745836799382232e-06
sam_encoder.blocks.1.norm1.bias grad: -7.620328688062727e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.1798197091557086e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2190081406515674e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.2110696085728705e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.414000846329145e-06
sam_encoder.blocks.1.norm2.weight grad: -1.7532973288325593e-05
sam_encoder.blocks.1.norm2.bias grad: -5.1729230108321644e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.2281359280168545e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.8144182831747457e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.229232440091437e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.93440528670908e-07
sam_encoder.blocks.2.norm1.weight grad: -1.1373249435564503e-05
sam_encoder.blocks.2.norm1.bias grad: -6.192235559865367e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.177933639468392e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.5974376310623484e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.03735555462481e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.733816811291035e-08
sam_encoder.blocks.2.norm2.weight grad: -7.348477993218694e-06
sam_encoder.blocks.2.norm2.bias grad: 5.328095539880451e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.692263584933244e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.27322202465075e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.42367808218114e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0742933227447793e-06
sam_encoder.blocks.3.norm1.weight grad: -6.929098162800074e-06
sam_encoder.blocks.3.norm1.bias grad: 3.5203781862946926e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.2843766695787053e-08
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.090925808166503e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.0421974770433735e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.3339399578835582e-06
sam_encoder.blocks.3.norm2.weight grad: -4.302455636207014e-06
sam_encoder.blocks.3.norm2.bias grad: 3.902831849700306e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.160108685231535e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.848218173312489e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.97565735410899e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2043201422784477e-06
sam_encoder.blocks.4.norm1.weight grad: -2.7620551918516867e-05
sam_encoder.blocks.4.norm1.bias grad: -1.4126193264019093e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.8584301869850606e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.356805104383966e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.958688340499066e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -7.268812623806298e-06
sam_encoder.blocks.4.norm2.weight grad: 2.291681812494062e-05
sam_encoder.blocks.4.norm2.bias grad: 2.5270912374253385e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.1020661986549385e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.311518179951236e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.0212152119493112e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.5543432141384983e-07
sam_encoder.blocks.5.norm1.weight grad: -7.333699159062235e-06
sam_encoder.blocks.5.norm1.bias grad: 2.7122837309434544e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.7831224542751443e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.097152446367545e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.6544624890666455e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.092782430438092e-06
sam_encoder.blocks.5.norm2.weight grad: 1.2855205568484962e-05
sam_encoder.blocks.5.norm2.bias grad: 8.773929948802106e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.739547077610041e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.381368740562607e-09
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2196983334433753e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.59692011847801e-07
sam_encoder.blocks.6.norm1.weight grad: -2.0067095647391398e-06
sam_encoder.blocks.6.norm1.bias grad: -3.729683612618828e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.507729383680271e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 8.111633178486954e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.202393360079441e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.9501114201812015e-07
sam_encoder.blocks.6.norm2.weight grad: 1.3710159691981971e-05
sam_encoder.blocks.6.norm2.bias grad: 5.307995706971269e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.291886271967087e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.034987341583474e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.997276275593322e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0981027571688173e-06
sam_encoder.blocks.7.norm1.weight grad: -3.988215667050099e-06
sam_encoder.blocks.7.norm1.bias grad: -3.826373244919523e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.040209437836893e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.4628707276642672e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.3888163721276214e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.120793957757996e-07
sam_encoder.blocks.7.norm2.weight grad: 1.52550157395126e-07
sam_encoder.blocks.7.norm2.bias grad: -1.7109227883338463e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.670286448847037e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5741677543701371e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.784267275681486e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.0388406457859674e-07
sam_encoder.blocks.8.norm1.weight grad: 4.3484442358021624e-06
sam_encoder.blocks.8.norm1.bias grad: 2.8659094368777005e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.2847149163426366e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.371554501223727e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.4762209704931593e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.2202939362614416e-06
sam_encoder.blocks.8.norm2.weight grad: 2.5189392545144074e-06
sam_encoder.blocks.8.norm2.bias grad: 1.946006022990332e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.885566333243332e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.871171993021562e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.804476307323057e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.023927206413646e-07
sam_encoder.blocks.9.norm1.weight grad: 1.4257324210120714e-07
sam_encoder.blocks.9.norm1.bias grad: 3.919981281796936e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.17729825888091e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.2671257460824563e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.712588920734561e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.274191501783207e-08
sam_encoder.blocks.9.norm2.weight grad: 3.885734258801676e-06
sam_encoder.blocks.9.norm2.bias grad: 2.9460047699103598e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.106108015846985e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 7.896584293121123e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.341383702121675e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.7141172621632e-07
sam_encoder.blocks.10.norm1.weight grad: -3.4945803690789035e-06
sam_encoder.blocks.10.norm1.bias grad: 4.2416374412823643e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.6458933487228933e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.894257242289314e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3368817235459574e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.961844529636437e-07
sam_encoder.blocks.10.norm2.weight grad: -2.286128164996626e-06
sam_encoder.blocks.10.norm2.bias grad: -2.2166088342601142e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.4174889858841198e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.3101247279555537e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.0057830170117086e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.7536460695264395e-07
sam_encoder.blocks.11.norm1.weight grad: -7.38924336474156e-06
sam_encoder.blocks.11.norm1.bias grad: 9.580217010807246e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.221074487835267e-09
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.895911267041811e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.4190781005017925e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.642723514640238e-07
sam_encoder.blocks.11.norm2.weight grad: 6.572339771082625e-06
sam_encoder.blocks.11.norm2.bias grad: 2.8216967962180206e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.4651905075879768e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.225896183626901e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.5324073956435313e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.914638793707127e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.26759322383441e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.7270380087429658e-05
sam_encoder.neck.conv2.trainable_scale grad: 8.92206799107953e-07
sam_encoder.neck.conv2.trainable_shift grad: -9.230099749402143e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -7.461811765097082e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.918656486552209e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005847088526934385
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002740300842560828
mask_decoder.transformer.layers.0.norm3.weight grad: 3.047133213840425e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.5112222172319889e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00014675504644401371
mask_decoder.transformer.layers.0.norm4.bias grad: 1.1993210137006827e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -5.55100996280089e-07
mask_decoder.transformer.layers.1.norm1.bias grad: -3.062751602556091e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 6.737231160514057e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.645736018777825e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.2779502362245694e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.6788846551207826e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 6.38673736830242e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002323613443877548
mask_decoder.transformer.norm_final_attn.weight grad: 6.852138540125452e-06
mask_decoder.transformer.norm_final_attn.bias grad: -7.014481525402516e-06
Text_Embedding_Affine.0.weight grad: 3.305894186872438e-12
Text_Embedding_Affine.0.bias grad: -4.1871450751074235e-11
Text_Embedding_Affine.2.weight grad: 1.8399025358828425e-11
Text_Embedding_Affine.2.bias grad: -2.612065691209864e-05
Epoch 36 finished with average loss: -63.3325
Epoch 37/39
----------
Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/3 [00:01<?, ?it/s, loss=-62]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-62]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-63]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-63]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-63.5]Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.20it/s, loss=-63.5]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.351357614012247e-14
Max value: 0.9996170997619629
Mean value: 0.0856732428073883

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.351357614012247e-14
Max value: 0.9996170997619629
Mean value: 0.0856732428073883

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08436203002929688

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11321178078651428

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07896614074707031

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08436203002929688

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.47225570678711
Max value: 72.48216247558594
Mean value: 62.04216766357422

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.351357614012247e-14
Max value: 0.9996170997619629
Mean value: 0.0856732428073883

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.351357614012247e-14
Max value: 0.9996170997619629
Mean value: 0.0856732428073883

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.351357614012247e-14
Max value: 0.9996170997619629
Mean value: 0.0856732428073883

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11321178078651428

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.47225570678711
Max value: 72.48216247558594
Mean value: 62.04216766357422

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.04322814941406
Max value: -62.04322814941406
Mean value: -62.04322814941406
sam_encoder.pos_embed grad: -2.3318631470203854e-09
sam_encoder.blocks.0.norm1.weight grad: -5.9891939599765465e-05
sam_encoder.blocks.0.norm1.bias grad: -7.7751865319442e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.6910114431520924e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.677758849742531e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.017125765036326e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4278751905294484e-06
sam_encoder.blocks.0.norm2.weight grad: -4.1710358345881104e-05
sam_encoder.blocks.0.norm2.bias grad: -3.1615811167284846e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.96353082882706e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.9060965996686718e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.1683271168294596e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.2432927835325245e-06
sam_encoder.blocks.1.norm1.weight grad: 1.6713103832444176e-05
sam_encoder.blocks.1.norm1.bias grad: 9.330376997240819e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 7.828011803212576e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.640048013650812e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.0498487174336333e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.400685732733109e-06
sam_encoder.blocks.1.norm2.weight grad: 1.4113809356786078e-06
sam_encoder.blocks.1.norm2.bias grad: -2.9729176276305225e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.319858251416008e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.2483371847338276e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.8362652554060332e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.5770626709563658e-06
sam_encoder.blocks.2.norm1.weight grad: 1.2870827049482614e-05
sam_encoder.blocks.2.norm1.bias grad: -1.979122134798672e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.244096195790917e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.687481572953402e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.989796252630185e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.9170078050810844e-06
sam_encoder.blocks.2.norm2.weight grad: 1.2362424968159758e-05
sam_encoder.blocks.2.norm2.bias grad: 1.6122314264066517e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.988348781713285e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.7673581851340714e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3038350061833626e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.26101565456338e-06
sam_encoder.blocks.3.norm1.weight grad: -1.0515904250496533e-05
sam_encoder.blocks.3.norm1.bias grad: -4.830285888601793e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.7110172595712356e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4039069355931133e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.6437683143522008e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.3327684175455943e-06
sam_encoder.blocks.3.norm2.weight grad: 3.717961590155028e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1529411494848318e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.524660870534717e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -8.40772372612264e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.0101455245603574e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.9108201740891673e-06
sam_encoder.blocks.4.norm1.weight grad: -4.683411589212483e-06
sam_encoder.blocks.4.norm1.bias grad: -1.0382139407738578e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.837784323783126e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.5308258955192287e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.320379048294853e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.709285687771626e-06
sam_encoder.blocks.4.norm2.weight grad: 1.4529525287798606e-05
sam_encoder.blocks.4.norm2.bias grad: 1.087777127395384e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.784325134707615e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.247436896141153e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.704756980165257e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.08397578819131e-07
sam_encoder.blocks.5.norm1.weight grad: -1.5925415937090293e-05
sam_encoder.blocks.5.norm1.bias grad: -9.291674359701574e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.79720926907612e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.161341737722978e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.103287771315081e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.216470875282539e-06
sam_encoder.blocks.5.norm2.weight grad: -8.765316295011871e-08
sam_encoder.blocks.5.norm2.bias grad: -1.0103537988470634e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.268065706331981e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.0917387953668367e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.4198445771617116e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.2645471088035265e-06
sam_encoder.blocks.6.norm1.weight grad: 1.1638580872386228e-05
sam_encoder.blocks.6.norm1.bias grad: 1.0195193311801631e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.025900569919031e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.510304966563126e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.430594228528207e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.666784661822021e-06
sam_encoder.blocks.6.norm2.weight grad: 5.342496478988323e-06
sam_encoder.blocks.6.norm2.bias grad: 1.9795395189703413e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.1535249692969956e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.3051800326356897e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.6073475964949466e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.7791489881346934e-07
sam_encoder.blocks.7.norm1.weight grad: -1.982479716389207e-06
sam_encoder.blocks.7.norm1.bias grad: 2.401913661742583e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.257945415200084e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.53695770122431e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.163870815114933e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.0288291580072837e-06
sam_encoder.blocks.7.norm2.weight grad: 9.567873348714784e-06
sam_encoder.blocks.7.norm2.bias grad: -2.2185638215432846e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.826373580930522e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.251609086873941e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5337541015014722e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.857819024233322e-07
sam_encoder.blocks.8.norm1.weight grad: -1.1016119970008731e-05
sam_encoder.blocks.8.norm1.bias grad: 1.1942784112761728e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.0181024663324933e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.210946942999726e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.1561574448678584e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.710051939582627e-07
sam_encoder.blocks.8.norm2.weight grad: 4.505990091274725e-06
sam_encoder.blocks.8.norm2.bias grad: -3.1518638365923834e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.930202754214406e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.2505068955069873e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.103715577410185e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.90790998999546e-07
sam_encoder.blocks.9.norm1.weight grad: -2.2641484065388795e-06
sam_encoder.blocks.9.norm1.bias grad: 1.8790897229337133e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.2298917176376563e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.141143664237461e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.2794392862124369e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.932534013983968e-07
sam_encoder.blocks.9.norm2.weight grad: 4.406441348692169e-06
sam_encoder.blocks.9.norm2.bias grad: -2.37114520018622e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.3537882043456193e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.0368131597715546e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.2140468420038815e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.963684988179011e-08
sam_encoder.blocks.10.norm1.weight grad: 4.028536750411149e-06
sam_encoder.blocks.10.norm1.bias grad: 3.5933209119320964e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.3089478443362168e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.269108325795969e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0729820587584982e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.14434510578576e-06
sam_encoder.blocks.10.norm2.weight grad: -1.6842232071212493e-06
sam_encoder.blocks.10.norm2.bias grad: -2.840456090780208e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.039250264511793e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8330578086533933e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.8672903934202623e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.502317949572898e-07
sam_encoder.blocks.11.norm1.weight grad: -2.0323852368164808e-05
sam_encoder.blocks.11.norm1.bias grad: -7.132150017241656e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.397861974008265e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.3164302572477027e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.687704636628041e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.307280730448838e-07
sam_encoder.blocks.11.norm2.weight grad: 4.47309957962716e-06
sam_encoder.blocks.11.norm2.bias grad: -2.57520014201873e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.86151020595571e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.0795831428822567e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0292540082446067e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.4766604294891295e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.0964325813110918e-06
sam_encoder.neck.conv1.trainable_shift grad: 3.675611878861673e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.9536328181857243e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.1765323506551795e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017040077364072204
mask_decoder.transformer.layers.0.norm1.bias grad: 3.084627678617835e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0013461490161716938
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00033365318085998297
mask_decoder.transformer.layers.0.norm3.weight grad: -1.2369884643703699e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.0874515030300245e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.361863830126822e-06
mask_decoder.transformer.layers.0.norm4.bias grad: -7.48783986637136e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.743516208487563e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.749289579805918e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00024308174033649266
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00016993725148495287
mask_decoder.transformer.layers.1.norm3.weight grad: 3.93959999200888e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.66273369663395e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.539215635508299e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 2.9420489227049984e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.214402790443273e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.4182221396768e-06
Text_Embedding_Affine.0.weight grad: -1.569096241826884e-11
Text_Embedding_Affine.0.bias grad: -6.733468227437811e-10
Text_Embedding_Affine.2.weight grad: 1.1036008218390236e-10
Text_Embedding_Affine.2.bias grad: 1.829201210057363e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7838007546761014e-12
Max value: 0.9980552196502686
Mean value: 0.08566813915967941

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7838007546761014e-12
Max value: 0.9980552196502686
Mean value: 0.08566813915967941

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08421850204467773

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11947621405124664

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07835197448730469

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08421850204467773

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 58.59947967529297
Max value: 81.17841339111328
Mean value: 64.01785278320312

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.398671976848842e-12
Max value: 0.9979002475738525
Mean value: 0.08508707582950592

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.398671976848842e-12
Max value: 0.9979002475738525
Mean value: 0.08508707582950592

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.398671976848842e-12
Max value: 0.9979002475738525
Mean value: 0.08508707582950592

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11941789835691452

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8563737869262695
Max value: 1.1877344846725464
Mean value: 1.000070571899414

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 58.59947967529297
Max value: 81.17841339111328
Mean value: 64.01785278320312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.0235824584961
Max value: -64.0235824584961
Mean value: -64.0235824584961
sam_encoder.pos_embed grad: -1.7288523945779843e-09
sam_encoder.blocks.0.norm1.weight grad: 7.2654693212825805e-06
sam_encoder.blocks.0.norm1.bias grad: 2.3883074391051196e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.59897443963564e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.5648577661741e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.921059710090049e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.2239640909683658e-06
sam_encoder.blocks.0.norm2.weight grad: 1.652223727433011e-05
sam_encoder.blocks.0.norm2.bias grad: 1.3262710126582533e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.931959781766636e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.1936276678170543e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.4146881919004954e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.87121872336138e-06
sam_encoder.blocks.1.norm1.weight grad: 1.6684678485034965e-05
sam_encoder.blocks.1.norm1.bias grad: 8.499919204041362e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.990326381928753e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.4591799646932486e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.4957035432416887e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.044715519237798e-07
sam_encoder.blocks.1.norm2.weight grad: -5.86473925068276e-06
sam_encoder.blocks.1.norm2.bias grad: -7.117285349522717e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0617904990795068e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.4508796059308224e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.012114125842345e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.0647890746895428e-07
sam_encoder.blocks.2.norm1.weight grad: 9.070657824850059e-07
sam_encoder.blocks.2.norm1.bias grad: -1.6479974874528125e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 9.615857834432973e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.07726002247e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.2141892916115467e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.4854383557103574e-06
sam_encoder.blocks.2.norm2.weight grad: 7.520308145103627e-07
sam_encoder.blocks.2.norm2.bias grad: -2.7749738364946097e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.6666899682604708e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.5868720311118523e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.350226951530203e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.52429117608699e-08
sam_encoder.blocks.3.norm1.weight grad: -6.7957857936562505e-06
sam_encoder.blocks.3.norm1.bias grad: -5.054091161582619e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.3171199952921597e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.3308144843904302e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.0137107153695979e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1093657121818978e-06
sam_encoder.blocks.3.norm2.weight grad: 5.827117092849221e-06
sam_encoder.blocks.3.norm2.bias grad: 3.1339473025582265e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.481035037111724e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.632369948216365e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.6854253317433177e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.044538854941493e-07
sam_encoder.blocks.4.norm1.weight grad: -1.6136826161528006e-05
sam_encoder.blocks.4.norm1.bias grad: -7.605572136526462e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.418269948771922e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.3588355563551886e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.472495675145183e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.9655634534719866e-06
sam_encoder.blocks.4.norm2.weight grad: -4.940718099533115e-06
sam_encoder.blocks.4.norm2.bias grad: 3.961059064749861e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.216559086169582e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.0283740670711268e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.757093966465618e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.1567710771487327e-06
sam_encoder.blocks.5.norm1.weight grad: -5.097974280943163e-06
sam_encoder.blocks.5.norm1.bias grad: -5.482497272168985e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.2540034478879534e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.137847099627834e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.9876492274306656e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.761030479334295e-06
sam_encoder.blocks.5.norm2.weight grad: 6.632062195421895e-06
sam_encoder.blocks.5.norm2.bias grad: -6.162517820484936e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.3923350883924286e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.0757121060578356e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.1088611649465747e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.8882883523474447e-07
sam_encoder.blocks.6.norm1.weight grad: 4.686615284299478e-06
sam_encoder.blocks.6.norm1.bias grad: -2.6971745228365762e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.896418209274998e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.462771011683799e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.5651905869162874e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.8575182139102253e-06
sam_encoder.blocks.6.norm2.weight grad: 1.037762103806017e-05
sam_encoder.blocks.6.norm2.bias grad: 4.602027274813736e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.4328072514617816e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.126883140997961e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.3897063126933062e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.329091312793025e-07
sam_encoder.blocks.7.norm1.weight grad: 2.374608811805956e-06
sam_encoder.blocks.7.norm1.bias grad: 2.9231730422907276e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.961400241474621e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3772844340564916e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9815011000900995e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.035691522905836e-06
sam_encoder.blocks.7.norm2.weight grad: 3.6612286180570663e-07
sam_encoder.blocks.7.norm2.bias grad: -2.0379807210701983e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.2665468602790497e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.0943704182864167e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.271755874971859e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.5078881006047595e-06
sam_encoder.blocks.8.norm1.weight grad: 2.87377588392701e-06
sam_encoder.blocks.8.norm1.bias grad: 1.1851328736156574e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.8431865100865252e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.0003573152062017e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.1219275393159478e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.887485036102589e-07
sam_encoder.blocks.8.norm2.weight grad: 1.1023485058103688e-06
sam_encoder.blocks.8.norm2.bias grad: -7.078746193656116e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.1629781511146575e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.1789969676101464e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.220598270876508e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.838440462317521e-08
sam_encoder.blocks.9.norm1.weight grad: -2.1590039978036657e-06
sam_encoder.blocks.9.norm1.bias grad: 1.9518211047397926e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0675539670046419e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.0536085710555199e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.640871059611527e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4322995411930606e-07
sam_encoder.blocks.9.norm2.weight grad: 9.221776963386219e-06
sam_encoder.blocks.9.norm2.bias grad: 8.148772394633852e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.619153514795471e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.5216507967561483e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.6266862985503394e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.3524460718581395e-07
sam_encoder.blocks.10.norm1.weight grad: 3.857000592688564e-06
sam_encoder.blocks.10.norm1.bias grad: 1.7778996834749705e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.0021969905646984e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3307001154316822e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2797216868420946e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2093363466192386e-06
sam_encoder.blocks.10.norm2.weight grad: 7.537029432569398e-06
sam_encoder.blocks.10.norm2.bias grad: -1.611685775060323e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.7931680506299017e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.437705776652365e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.605705506335653e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.6305066803142836e-07
sam_encoder.blocks.11.norm1.weight grad: 1.485058237449266e-05
sam_encoder.blocks.11.norm1.bias grad: 1.7011792579069152e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.108679382217815e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.410924661779063e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -6.985323466324189e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.699745315723703e-07
sam_encoder.blocks.11.norm2.weight grad: 1.1665938473015558e-05
sam_encoder.blocks.11.norm2.bias grad: -1.1229666370127234e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.853847596881678e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2938999134348705e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.85460497859458e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.706858701159945e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.6820504242787138e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.0138711988693103e-05
sam_encoder.neck.conv2.trainable_scale grad: 4.0815939428284764e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.2182954378658906e-07
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002734211157076061
mask_decoder.transformer.layers.0.norm1.bias grad: -8.155220712069422e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0030765184201300144
mask_decoder.transformer.layers.0.norm2.bias grad: 9.697047062218189e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -8.670645183883607e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.599832103238441e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.247476944234222e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.030407581012696e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.9196389732533135e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.4837272576405667e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00024205681984312832
mask_decoder.transformer.layers.1.norm2.bias grad: 1.515881740488112e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.770105882314965e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.904764177306788e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.7038945669773966e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.10288654267788e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.1611939044087194e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.277026214869693e-05
Text_Embedding_Affine.0.weight grad: -3.091438216529241e-11
Text_Embedding_Affine.0.bias grad: -7.884194408447343e-10
Text_Embedding_Affine.2.weight grad: 6.40573150079149e-11
Text_Embedding_Affine.2.bias grad: 2.4180464606615715e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.177564973979365e-11
Max value: 0.999099612236023
Mean value: 0.07680467516183853

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.177564973979365e-11
Max value: 0.999099612236023
Mean value: 0.07680467516183853

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08116531372070312

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09983156621456146

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0727071762084961

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08116531372070312

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.089927673339844
Max value: 89.30850982666016
Mean value: 64.40636444091797

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.587681343292687e-11
Max value: 0.998862624168396
Mean value: 0.07599261403083801

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.587681343292687e-11
Max value: 0.998862624168396
Mean value: 0.07599261403083801

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.587681343292687e-11
Max value: 0.998862624168396
Mean value: 0.07599261403083801

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09973742067813873

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8954851031303406
Max value: 1.4225138425827026
Mean value: 1.000128984451294

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.089927673339844
Max value: 89.30850982666016
Mean value: 64.40636444091797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.41577911376953
Max value: -64.41577911376953
Mean value: -64.41577911376953
sam_encoder.pos_embed grad: 1.1863144910861934e-09
sam_encoder.blocks.0.norm1.weight grad: 1.1587582775973715e-05
sam_encoder.blocks.0.norm1.bias grad: 5.754391168011352e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.88904481951613e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.3746589994952956e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.3984904297976755e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.713338282475888e-07
sam_encoder.blocks.0.norm2.weight grad: -9.330904504167847e-06
sam_encoder.blocks.0.norm2.bias grad: 1.158812938228948e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.191996933717746e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.3033926481730305e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2873361811216455e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.185626494290773e-06
sam_encoder.blocks.1.norm1.weight grad: 1.1683629054459743e-05
sam_encoder.blocks.1.norm1.bias grad: -3.994220605818555e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.377892310003517e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.72253237451514e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.415303126530489e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.7831189325079322e-06
sam_encoder.blocks.1.norm2.weight grad: 1.1196017112524714e-05
sam_encoder.blocks.1.norm2.bias grad: 4.9877808123710565e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.297649300293415e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.9342027712809795e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.502524335402995e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.2236345103010535e-06
sam_encoder.blocks.2.norm1.weight grad: 8.134405788950971e-07
sam_encoder.blocks.2.norm1.bias grad: -1.085508665710222e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.4024566326042986e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.832886351228808e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 6.921977160345705e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.60967771182186e-07
sam_encoder.blocks.2.norm2.weight grad: -6.058676262910012e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0326154551876243e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.9679064280353487e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.0826460434573164e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.219001999037573e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.5616267268778756e-07
sam_encoder.blocks.3.norm1.weight grad: -6.555507638950075e-07
sam_encoder.blocks.3.norm1.bias grad: -4.568819804262603e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.603103095883853e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 8.03244972757966e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.7072617285739398e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.712087608524598e-07
sam_encoder.blocks.3.norm2.weight grad: 9.87068415270187e-06
sam_encoder.blocks.3.norm2.bias grad: 1.393140155414585e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.220251063699834e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2464291760115884e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.237610144424252e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1518958444867167e-06
sam_encoder.blocks.4.norm1.weight grad: -1.2693240933003835e-05
sam_encoder.blocks.4.norm1.bias grad: 5.765035894000903e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.600309229223058e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.39937548940361e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.163337507634424e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.55242082150653e-06
sam_encoder.blocks.4.norm2.weight grad: 9.667872291174717e-06
sam_encoder.blocks.4.norm2.bias grad: 7.617974915774539e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.124426701921038e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.5073314898472745e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.49581931308785e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.441011043823437e-08
sam_encoder.blocks.5.norm1.weight grad: -3.913552063750103e-06
sam_encoder.blocks.5.norm1.bias grad: -6.019824638769933e-08
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.6890242022782331e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.1687852747854777e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5732941111300534e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.662284487087163e-06
sam_encoder.blocks.5.norm2.weight grad: 9.225974281434901e-06
sam_encoder.blocks.5.norm2.bias grad: 1.021742946250015e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.5708718567329925e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 7.859331958570692e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1536064903339138e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.277278773974103e-07
sam_encoder.blocks.6.norm1.weight grad: 3.0133919608488213e-06
sam_encoder.blocks.6.norm1.bias grad: -3.763278755286592e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.9986563276906963e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3276070376377902e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.7069241948775016e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.2288531908998266e-06
sam_encoder.blocks.6.norm2.weight grad: 9.895511539070867e-06
sam_encoder.blocks.6.norm2.bias grad: 3.752506017917767e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.847805707366206e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.167533577652648e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4159644479150302e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.403900437770062e-07
sam_encoder.blocks.7.norm1.weight grad: 8.003347602425492e-07
sam_encoder.blocks.7.norm1.bias grad: 1.3195138990340638e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.2491967683890834e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.54220946469286e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5792433032402187e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.836607440163789e-07
sam_encoder.blocks.7.norm2.weight grad: 5.485076144395862e-07
sam_encoder.blocks.7.norm2.bias grad: -9.371539988478617e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0491905868548201e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.374294111490599e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0429164376546396e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.09310883544822e-06
sam_encoder.blocks.8.norm1.weight grad: -1.2241403055668343e-06
sam_encoder.blocks.8.norm1.bias grad: 1.7129359548562206e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.8427454051561654e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.3399383078649407e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 6.596422963411896e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.4324761821171705e-07
sam_encoder.blocks.8.norm2.weight grad: 1.1919266853510635e-06
sam_encoder.blocks.8.norm2.bias grad: -1.1415025937822065e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.4292395462689456e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.691410140367225e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.1838845277197834e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.132922188342491e-08
sam_encoder.blocks.9.norm1.weight grad: -2.5686421167847584e-07
sam_encoder.blocks.9.norm1.bias grad: 1.6113671108541894e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.854558142142196e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.986746600683546e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.402053535723098e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.739941630305111e-07
sam_encoder.blocks.9.norm2.weight grad: 1.8325035853195004e-06
sam_encoder.blocks.9.norm2.bias grad: 6.724292234139284e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.9822300600935705e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.176756313725491e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -8.826816610962851e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.393587917344121e-07
sam_encoder.blocks.10.norm1.weight grad: -2.239153218397405e-06
sam_encoder.blocks.10.norm1.bias grad: -9.346475593474679e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.218966190208448e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.6086971754702972e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.6450156787614105e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.8032652582842275e-07
sam_encoder.blocks.10.norm2.weight grad: -8.372903721465264e-07
sam_encoder.blocks.10.norm2.bias grad: -2.7614128157438245e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.947202114635729e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -8.169979537342442e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.2982167138252407e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.681219583195343e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0300649591954425e-05
sam_encoder.blocks.11.norm1.bias grad: -1.3109632845953456e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.22466359345708e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.6899928123592645e-09
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.583266897701833e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4557433303252765e-07
sam_encoder.blocks.11.norm2.weight grad: -1.222679202328436e-06
sam_encoder.blocks.11.norm2.bias grad: -2.9979335067764623e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0241448080705595e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.562209253184847e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.666518755882862e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.731417829224483e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.7244201444555074e-07
sam_encoder.neck.conv1.trainable_shift grad: 8.01445003162371e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.907794158905745e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.3945891623734497e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015055194671731442
mask_decoder.transformer.layers.0.norm1.bias grad: -2.490851329639554e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003187027759850025
mask_decoder.transformer.layers.0.norm2.bias grad: 2.8122332878410816e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -3.781053237617016e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 3.104830102529377e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011211073433514684
mask_decoder.transformer.layers.0.norm4.bias grad: -7.5858988566324115e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.353936649044044e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.54463588539511e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.487967428052798e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.520998719381168e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.971624806174077e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.17104817845393e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.205117172910832e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.500443800585344e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.338316885987297e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.94194981304463e-05
Text_Embedding_Affine.0.weight grad: -1.859858621278132e-12
Text_Embedding_Affine.0.bias grad: 1.450126407842589e-10
Text_Embedding_Affine.2.weight grad: 6.217193426749645e-11
Text_Embedding_Affine.2.bias grad: 2.103884435200598e-05
Epoch 37 finished with average loss: -63.4942
Epoch 38/39
----------
Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s, loss=-62.8]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-62.8]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-65.2]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-65.2]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-60.2]Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-60.2]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.097829489612461e-13
Max value: 0.9987668991088867
Mean value: 0.08585028350353241

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.097829489612461e-13
Max value: 0.9987668991088867
Mean value: 0.08585028350353241

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08503866195678711

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12069176137447357

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08015966415405273

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08503866195678711

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.05791091918945
Max value: 74.00310516357422
Mean value: 62.83540344238281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.097829489612461e-13
Max value: 0.9987668991088867
Mean value: 0.08585028350353241

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.097829489612461e-13
Max value: 0.9987668991088867
Mean value: 0.08585028350353241

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.097829489612461e-13
Max value: 0.9987668991088867
Mean value: 0.08585028350353241

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12069176137447357

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.05791091918945
Max value: 74.00310516357422
Mean value: 62.83540344238281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.836490631103516
Max value: -62.836490631103516
Mean value: -62.836490631103516
sam_encoder.pos_embed grad: -5.3515476494681025e-09
sam_encoder.blocks.0.norm1.weight grad: -1.3126105841365643e-05
sam_encoder.blocks.0.norm1.bias grad: -1.3817762010148726e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.4696086054755142e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.596416023465281e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.3248913091956638e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.291088882586337e-07
sam_encoder.blocks.0.norm2.weight grad: -9.68422227742849e-06
sam_encoder.blocks.0.norm2.bias grad: 8.884965609468054e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.3596709070261568e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.16973523190245e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.830585567106027e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.005049959232565e-06
sam_encoder.blocks.1.norm1.weight grad: 9.051516826730222e-06
sam_encoder.blocks.1.norm1.bias grad: 1.821661862777546e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.6028388927225024e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0098856364493258e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.411520866502542e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.2680523013841594e-06
sam_encoder.blocks.1.norm2.weight grad: 9.859914825938176e-06
sam_encoder.blocks.1.norm2.bias grad: -5.9610811149468645e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.003298949508462e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6366266208933666e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 7.134710244827147e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.2910322766401805e-07
sam_encoder.blocks.2.norm1.weight grad: 7.679116606595926e-06
sam_encoder.blocks.2.norm1.bias grad: -2.5735675990290474e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.8067737528326688e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.0313592611055356e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.014081928791711e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.2346322364464868e-07
sam_encoder.blocks.2.norm2.weight grad: -3.4425297599227633e-06
sam_encoder.blocks.2.norm2.bias grad: -6.786348194509628e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.0771388992434368e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.069876700261375e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.1480773284565657e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 7.32365492694953e-07
sam_encoder.blocks.3.norm1.weight grad: -1.623886646484607e-06
sam_encoder.blocks.3.norm1.bias grad: -9.58290183916688e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.504980198471458e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.436567273089167e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.418964075128315e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.9037000811295002e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0600738278299104e-05
sam_encoder.blocks.3.norm2.bias grad: -3.1302060961024836e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.864399776735809e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.3828722532925894e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.680196414279635e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.977013198484201e-06
sam_encoder.blocks.4.norm1.weight grad: 4.832822014577687e-06
sam_encoder.blocks.4.norm1.bias grad: -7.359381470450899e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0575521400824073e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.4230824945116183e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.4939361082942924e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.3034649530018214e-06
sam_encoder.blocks.4.norm2.weight grad: -2.3728634914732538e-05
sam_encoder.blocks.4.norm2.bias grad: -8.307055395562202e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6731268260627985e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.126544576545712e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.202506822068244e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.285181714498322e-07
sam_encoder.blocks.5.norm1.weight grad: 9.904686521622352e-06
sam_encoder.blocks.5.norm1.bias grad: -2.19359458242252e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.120431630231906e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.975792424171232e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.958019755780697e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.0161294312638347e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1910982721019536e-05
sam_encoder.blocks.5.norm2.bias grad: -8.066779628279619e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.863802471139934e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.2870340217195917e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.9274000351288123e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.6606481949565932e-06
sam_encoder.blocks.6.norm1.weight grad: -9.568566383677535e-09
sam_encoder.blocks.6.norm1.bias grad: 9.606166713638231e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.130764743124018e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.991841251467122e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9675760540849296e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.891358334039978e-07
sam_encoder.blocks.6.norm2.weight grad: -3.7322995467548026e-06
sam_encoder.blocks.6.norm2.bias grad: -3.17616184020153e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.6556759874220006e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.82419261263567e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.347972779010888e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.5780500461914926e-06
sam_encoder.blocks.7.norm1.weight grad: 2.375390067754779e-06
sam_encoder.blocks.7.norm1.bias grad: 2.5375099994562333e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.1743751429094118e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.907519261607376e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.7082323893191642e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.727968416773365e-07
sam_encoder.blocks.7.norm2.weight grad: 1.589718522154726e-06
sam_encoder.blocks.7.norm2.bias grad: 6.09555499408998e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.246076974188327e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.13444434646226e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5728699054307071e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.6918570509005804e-06
sam_encoder.blocks.8.norm1.weight grad: -3.685518095153384e-07
sam_encoder.blocks.8.norm1.bias grad: 3.340768159887375e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.1426253005738545e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.614549998725124e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.7283607525750995e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.5181052478728816e-06
sam_encoder.blocks.8.norm2.weight grad: 5.24343113283976e-06
sam_encoder.blocks.8.norm2.bias grad: 4.811603275811649e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 6.725004823238123e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.9530068534077145e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.8810947040037718e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.6886279985992587e-07
sam_encoder.blocks.9.norm1.weight grad: -9.531478895041801e-07
sam_encoder.blocks.9.norm1.bias grad: 7.732304396768086e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.729371193614497e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 7.02200395608088e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.885081696353154e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.334944717105827e-07
sam_encoder.blocks.9.norm2.weight grad: -1.4397369341168087e-06
sam_encoder.blocks.9.norm2.bias grad: -1.1307337217658642e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.996592330528074e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.4018962701811688e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.0797078832401894e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.3427764997686609e-06
sam_encoder.blocks.10.norm1.weight grad: 7.651684427401051e-06
sam_encoder.blocks.10.norm1.bias grad: -1.998918577328368e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.605426056514261e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.77930883182853e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.4655846573296003e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.474507922073826e-07
sam_encoder.blocks.10.norm2.weight grad: 1.2676813412326737e-06
sam_encoder.blocks.10.norm2.bias grad: -1.1740801255655242e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.117331627639942e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.5145744214350998e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0096734968101373e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.151920726755634e-07
sam_encoder.blocks.11.norm1.weight grad: 1.5614959920640104e-05
sam_encoder.blocks.11.norm1.bias grad: -8.657860917082871e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.3546799639007077e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.628791192677454e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.912231477443129e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.6991168649838073e-06
sam_encoder.blocks.11.norm2.weight grad: 5.16400996275479e-06
sam_encoder.blocks.11.norm2.bias grad: -6.810136028434499e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.107464625732973e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.1403836879253504e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.142025098488375e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.290579459440778e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.699025784153491e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.3668312021763995e-05
sam_encoder.neck.conv2.trainable_scale grad: 9.168666110781487e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.1861175153171644e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017947705055121332
mask_decoder.transformer.layers.0.norm1.bias grad: -8.144488674588501e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0036914669908583164
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001322285970672965
mask_decoder.transformer.layers.0.norm3.weight grad: -6.93633483024314e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.2807660065591335e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 0.000178734480869025
mask_decoder.transformer.layers.0.norm4.bias grad: -6.472728273365647e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.384461499284953e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.718222044175491e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.3172455257736146e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011450501915533096
mask_decoder.transformer.layers.1.norm3.weight grad: 5.9672056522686034e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.334091110853478e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -0.0001196673620142974
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00027976781711913645
mask_decoder.transformer.norm_final_attn.weight grad: -3.946315700886771e-07
mask_decoder.transformer.norm_final_attn.bias grad: 2.0815750758629292e-05
Text_Embedding_Affine.0.weight grad: 1.9243669158175436e-12
Text_Embedding_Affine.0.bias grad: 1.221980017174218e-10
Text_Embedding_Affine.2.weight grad: 6.123224843834763e-11
Text_Embedding_Affine.2.bias grad: 2.855023012671154e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.969565120000908e-12
Max value: 0.9991371035575867
Mean value: 0.09345036000013351

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.969565120000908e-12
Max value: 0.9991371035575867
Mean value: 0.09345036000013351

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.093414306640625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11577189713716507

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08625173568725586

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.093414306640625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.20584487915039
Max value: 85.40914916992188
Mean value: 67.56434631347656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2603820764844897e-11
Max value: 0.9989892840385437
Mean value: 0.09371635317802429

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2603820764844897e-11
Max value: 0.9989892840385437
Mean value: 0.09371635317802429

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2603820764844897e-11
Max value: 0.9989892840385437
Mean value: 0.09371635317802429

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.772741317749023
Max value: -1.1920928244535389e-07
Mean value: -0.11581370234489441

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9585092663764954
Max value: 1.8344255685806274
Mean value: 1.0000206232070923

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.20584487915039
Max value: 85.40914916992188
Mean value: 67.56434631347656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.5623550415039
Max value: -67.5623550415039
Mean value: -67.5623550415039
sam_encoder.pos_embed grad: -6.081865011609011e-10
sam_encoder.blocks.0.norm1.weight grad: 5.5512127801193856e-06
sam_encoder.blocks.0.norm1.bias grad: 1.9659334782318183e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.9909766706405208e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.9333081979766575e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.541828275250737e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.929244260485575e-07
sam_encoder.blocks.0.norm2.weight grad: 1.9040697225136682e-05
sam_encoder.blocks.0.norm2.bias grad: 2.8021426260238513e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.496328867593547e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.6391293229389703e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.1345367713365704e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.2650177438899846e-07
sam_encoder.blocks.1.norm1.weight grad: 8.004131814232096e-06
sam_encoder.blocks.1.norm1.bias grad: -2.4786540961940773e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.3452835092903115e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.625430286367191e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.7683146274503088e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.062378825939959e-06
sam_encoder.blocks.1.norm2.weight grad: 1.3342651072889566e-05
sam_encoder.blocks.1.norm2.bias grad: 2.2364074538927525e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.148461579869036e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.282077257921628e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.1576109904563054e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.868119157843466e-07
sam_encoder.blocks.2.norm1.weight grad: -1.7991228560276795e-06
sam_encoder.blocks.2.norm1.bias grad: -5.337838956620544e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.71532540966291e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.5164476963036577e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.58877565279181e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.048128966540389e-07
sam_encoder.blocks.2.norm2.weight grad: -1.424719812348485e-05
sam_encoder.blocks.2.norm2.bias grad: 2.4885212042136118e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.020687684824225e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.571774530224502e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.1890380139666377e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5188292081802501e-06
sam_encoder.blocks.3.norm1.weight grad: 3.4093079648300773e-06
sam_encoder.blocks.3.norm1.bias grad: -4.609625648299698e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.2190439520054497e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.2845414327530307e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.4099382497079205e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 8.499598038724798e-07
sam_encoder.blocks.3.norm2.weight grad: 4.669633199227974e-06
sam_encoder.blocks.3.norm2.bias grad: 5.281629455566872e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.898310751537792e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.397520804857777e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.4892001445332426e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.288307877686748e-07
sam_encoder.blocks.4.norm1.weight grad: 4.566601091937628e-06
sam_encoder.blocks.4.norm1.bias grad: 9.913600251820753e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.4155621101963334e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1495611573764108e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.37583411844389e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.2019737596347113e-06
sam_encoder.blocks.4.norm2.weight grad: -4.756145699502667e-06
sam_encoder.blocks.4.norm2.bias grad: -3.003341362273204e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.7215394261002075e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.3624911591468845e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.596274377239752e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.089826456445735e-07
sam_encoder.blocks.5.norm1.weight grad: 4.1798439269769005e-06
sam_encoder.blocks.5.norm1.bias grad: -2.552679461587104e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.946923000825336e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -7.278261904275496e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.747301894283737e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.313815912202699e-07
sam_encoder.blocks.5.norm2.weight grad: -4.025952875963412e-06
sam_encoder.blocks.5.norm2.bias grad: -5.125174993736437e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.75811110745417e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.6474936021259055e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.215007258309925e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.4127371034410316e-07
sam_encoder.blocks.6.norm1.weight grad: 3.7136720720809535e-07
sam_encoder.blocks.6.norm1.bias grad: -3.06426954921335e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.1434367479523644e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.0205737289179524e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.425647711694182e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.7638012650422752e-07
sam_encoder.blocks.6.norm2.weight grad: 1.8292737422598293e-06
sam_encoder.blocks.6.norm2.bias grad: 2.451707132422598e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 6.274029829000938e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.8955480502190767e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.451800812901638e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.480802276584654e-08
sam_encoder.blocks.7.norm1.weight grad: -4.152187784711714e-07
sam_encoder.blocks.7.norm1.bias grad: 1.1471551033537253e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.617624315666035e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.7883877490021405e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.907111931766849e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.7532925628293015e-07
sam_encoder.blocks.7.norm2.weight grad: -6.035429578332696e-07
sam_encoder.blocks.7.norm2.bias grad: 6.984272431509453e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.1658926268864889e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.737801416216826e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0468229447724298e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.418520115403226e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0338333140680334e-06
sam_encoder.blocks.8.norm1.bias grad: -1.3776974583379342e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.330610631266609e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.350423180061625e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5440535889865714e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.133909628644687e-08
sam_encoder.blocks.8.norm2.weight grad: -2.4441546884190757e-06
sam_encoder.blocks.8.norm2.bias grad: -1.4714046301378403e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.598449555080151e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.6416863672930049e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.853905236108403e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.7181197260215413e-07
sam_encoder.blocks.9.norm1.weight grad: -3.1133404263528064e-06
sam_encoder.blocks.9.norm1.bias grad: 6.990733254497172e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.889305051212432e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.483107194479089e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.678187105535471e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.519426503677096e-07
sam_encoder.blocks.9.norm2.weight grad: -1.0975808208968374e-06
sam_encoder.blocks.9.norm2.bias grad: -1.6506741076227627e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.93591584119713e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.575584734491713e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.2202736715826177e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.9215007063830853e-07
sam_encoder.blocks.10.norm1.weight grad: -7.864534268264833e-07
sam_encoder.blocks.10.norm1.bias grad: -4.0492022890248336e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.539960514193808e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.238242799052387e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.950841917481739e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.626682077926489e-08
sam_encoder.blocks.10.norm2.weight grad: -8.071865522651933e-07
sam_encoder.blocks.10.norm2.bias grad: -1.2641794455703348e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.035459604281641e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -7.58623173169326e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0003201396102668e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.529869895326556e-07
sam_encoder.blocks.11.norm1.weight grad: 1.336042259936221e-05
sam_encoder.blocks.11.norm1.bias grad: -2.214956566604087e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1763481779780705e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.215353209881869e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.7876923266157974e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.979933004913619e-07
sam_encoder.blocks.11.norm2.weight grad: 1.0549820217420347e-07
sam_encoder.blocks.11.norm2.bias grad: -2.2232611627259757e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.526321041950723e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.111781433697615e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.889053333405172e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.786778948888241e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.7993140722392127e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1144707059429493e-06
sam_encoder.neck.conv2.trainable_scale grad: 4.197045200271532e-08
sam_encoder.neck.conv2.trainable_shift grad: 2.835765917552635e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001374656130792573
mask_decoder.transformer.layers.0.norm1.bias grad: 1.3344852050067857e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003739411011338234
mask_decoder.transformer.layers.0.norm2.bias grad: -1.53288128785789e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -2.3831755243008956e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.1805608412250876e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 9.590297122485936e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.686641765758395e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.1351421057479456e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.6978137864498422e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.905370977008715e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.22524564480409e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.2876341972732916e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.0400584364542738e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.162597153685056e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001478897756896913
mask_decoder.transformer.norm_final_attn.weight grad: 6.73522208671784e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.69537088368088e-05
Text_Embedding_Affine.0.weight grad: -7.242916336136496e-12
Text_Embedding_Affine.0.bias grad: -1.8094443998695198e-10
Text_Embedding_Affine.2.weight grad: 7.304351568038214e-11
Text_Embedding_Affine.2.bias grad: 2.2497266400023364e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.8026926265911634e-11
Max value: 0.998781144618988
Mean value: 0.058678485453128815

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.8026926265911634e-11
Max value: 0.998781144618988
Mean value: 0.058678485453128815

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06174755096435547

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09414927661418915

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04715251922607422

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06174755096435547

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 43.78718948364258
Max value: 62.454750061035156
Mean value: 50.072654724121094

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.413184814954789e-11
Max value: 0.9985577464103699
Mean value: 0.06006505340337753

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.413184814954789e-11
Max value: 0.9985577464103699
Mean value: 0.06006505340337753

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.413184814954789e-11
Max value: 0.9985577464103699
Mean value: 0.06006505340337753

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.09413813054561615

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9359187483787537
Max value: 2.463404893875122
Mean value: 1.0001630783081055

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 43.78718948364258
Max value: 62.454750061035156
Mean value: 50.072654724121094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.06643295288086
Max value: -50.06643295288086
Mean value: -50.06643295288086
sam_encoder.pos_embed grad: 8.770468795660236e-10
sam_encoder.blocks.0.norm1.weight grad: -4.490578703553183e-06
sam_encoder.blocks.0.norm1.bias grad: 3.4522606711107073e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.6026295952542569e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.8113641431227734e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.271644916618243e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.66307688687084e-06
sam_encoder.blocks.0.norm2.weight grad: 4.502197407418862e-05
sam_encoder.blocks.0.norm2.bias grad: -5.557876193051925e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2280251212359872e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.259607638028683e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.0871837477898225e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.457184892700752e-06
sam_encoder.blocks.1.norm1.weight grad: -1.5132799262573826e-06
sam_encoder.blocks.1.norm1.bias grad: 4.0147651816369034e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.254595402628183e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.090831912937574e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.205120255093789e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.3954897844523657e-06
sam_encoder.blocks.1.norm2.weight grad: -4.018996548893483e-07
sam_encoder.blocks.1.norm2.bias grad: 4.049299150210572e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.567220912576886e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.8971836602286203e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.076039916370064e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2785931176040322e-06
sam_encoder.blocks.2.norm1.weight grad: -1.927525590872392e-05
sam_encoder.blocks.2.norm1.bias grad: -3.586595767046674e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1899649507540744e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.036808266188018e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.623130270279944e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.370834969653515e-06
sam_encoder.blocks.2.norm2.weight grad: -8.308464202855248e-06
sam_encoder.blocks.2.norm2.bias grad: -3.947743607568555e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.76291017245967e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.9471599443932064e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.970159574848367e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7490719983470626e-06
sam_encoder.blocks.3.norm1.weight grad: -4.914247710985364e-07
sam_encoder.blocks.3.norm1.bias grad: -1.2086763945262646e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0366608194090077e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.8680423131154384e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.6203488232567906e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.5947936137526995e-06
sam_encoder.blocks.3.norm2.weight grad: -5.2358063840074465e-06
sam_encoder.blocks.3.norm2.bias grad: -8.86394082044717e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.0306971439131303e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.166908868479368e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.613812158524524e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.1840272640693e-08
sam_encoder.blocks.4.norm1.weight grad: 6.959047595955781e-07
sam_encoder.blocks.4.norm1.bias grad: -9.503270121058449e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.9208429168647854e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.579059004252485e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.017391580011463e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -9.257425972464262e-07
sam_encoder.blocks.4.norm2.weight grad: -6.376475994329667e-06
sam_encoder.blocks.4.norm2.bias grad: -2.048387614195235e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.16121155367e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.9813036235282198e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.383779590469203e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.732292424591833e-08
sam_encoder.blocks.5.norm1.weight grad: 7.888545951573178e-06
sam_encoder.blocks.5.norm1.bias grad: -1.1680894203891512e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.181596629379783e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.6929511679772986e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.566201816189277e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 5.811627943330677e-07
sam_encoder.blocks.5.norm2.weight grad: 1.6432186384918168e-06
sam_encoder.blocks.5.norm2.bias grad: 3.6708934203488752e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.8863105399068445e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.0546900739427656e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1954338080831803e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.928224595663778e-07
sam_encoder.blocks.6.norm1.weight grad: -1.3689589195564622e-06
sam_encoder.blocks.6.norm1.bias grad: -1.773475901245547e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.993893192775431e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0580533853499219e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2297847433728748e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.951274139690213e-07
sam_encoder.blocks.6.norm2.weight grad: 1.7553084035171196e-06
sam_encoder.blocks.6.norm2.bias grad: 1.5190996691671899e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.38620223930775e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.308605300844647e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.504055025085108e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0499813463127339e-08
sam_encoder.blocks.7.norm1.weight grad: 6.789678081986494e-07
sam_encoder.blocks.7.norm1.bias grad: -6.721852514601778e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.1582083554203564e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.478014024149161e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.6202566257561557e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.637852674070018e-07
sam_encoder.blocks.7.norm2.weight grad: -2.3416546355292667e-06
sam_encoder.blocks.7.norm2.bias grad: -1.0139108326256974e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.022343551288941e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.5526755987593788e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.750729077495635e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.790243224306323e-08
sam_encoder.blocks.8.norm1.weight grad: 6.231953648239141e-06
sam_encoder.blocks.8.norm1.bias grad: -1.422035893483553e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.417536835419014e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.21328298014123e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.6267529190372443e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.100517791513994e-07
sam_encoder.blocks.8.norm2.weight grad: -1.8720978687269962e-06
sam_encoder.blocks.8.norm2.bias grad: 1.383318476655404e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.2724899483582703e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.6302326457662275e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8364808056503534e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.648761541327985e-08
sam_encoder.blocks.9.norm1.weight grad: 1.2033581242576474e-06
sam_encoder.blocks.9.norm1.bias grad: 2.995705017383443e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.236564331629779e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.8587314737649194e-09
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.2191311422357103e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.508410367838223e-07
sam_encoder.blocks.9.norm2.weight grad: -6.350177841341065e-07
sam_encoder.blocks.9.norm2.bias grad: 1.9421352135395864e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.7005651190847857e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.989448249645648e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.2892516565443657e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.144067927176366e-07
sam_encoder.blocks.10.norm1.weight grad: -2.2677222659694962e-06
sam_encoder.blocks.10.norm1.bias grad: 1.3424103144643595e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.878735361060535e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.000785444688518e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1850880810015951e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.013707209400309e-07
sam_encoder.blocks.10.norm2.weight grad: -2.8745830604748335e-06
sam_encoder.blocks.10.norm2.bias grad: 1.0254850622004597e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.2724188966094516e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.409611152477737e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.014322598777653e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.8420473679725546e-07
sam_encoder.blocks.11.norm1.weight grad: -1.3812903489451855e-05
sam_encoder.blocks.11.norm1.bias grad: 1.604916064934514e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.9446498501783935e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.396191452040512e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.2028552848496474e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.243078258994501e-06
sam_encoder.blocks.11.norm2.weight grad: 2.6843622435990255e-07
sam_encoder.blocks.11.norm2.bias grad: 1.4106465187069261e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 9.269557210700441e-08
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.7373352291278934e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.3341242183505528e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2678098926244274e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.2224145393702202e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.0790310625452548e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.581327524036169e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.3230746592162177e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010445203952258453
mask_decoder.transformer.layers.0.norm1.bias grad: -2.875189238693565e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004139005206525326
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00026171334320679307
mask_decoder.transformer.layers.0.norm3.weight grad: -1.8232825823361054e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.6865644031204283e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001126657152781263
mask_decoder.transformer.layers.0.norm4.bias grad: 1.133619934989838e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.7028959923190996e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.431872417218983e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -8.037201769184321e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -8.587489719502628e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -5.661812247126363e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.5209115342004225e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.860078090336174e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017187926277983934
mask_decoder.transformer.norm_final_attn.weight grad: 4.782241376233287e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.3444975593301933e-05
Text_Embedding_Affine.0.weight grad: -2.3754737760173228e-11
Text_Embedding_Affine.0.bias grad: -8.378975846490277e-10
Text_Embedding_Affine.2.weight grad: -1.8349766151004587e-11
Text_Embedding_Affine.2.bias grad: -2.3356700694421306e-05
Epoch 38 finished with average loss: -60.1551
Epoch 39/39
----------
Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s, loss=-50.9]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-50.9]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-58]  Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-58]Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-62]Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-62]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.55251331024742e-11
Max value: 0.9981604218482971
Mean value: 0.08155995607376099

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.55251331024742e-11
Max value: 0.9981604218482971
Mean value: 0.08155995607376099

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06824398040771484

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12722355127334595

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06618022918701172

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06824398040771484

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 26.61478614807129
Max value: 66.73369598388672
Mean value: 50.924835205078125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.55251331024742e-11
Max value: 0.9981604218482971
Mean value: 0.08155995607376099

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.55251331024742e-11
Max value: 0.9981604218482971
Mean value: 0.08155995607376099

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.55251331024742e-11
Max value: 0.9981604218482971
Mean value: 0.08155995607376099

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12722355127334595

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 26.61478614807129
Max value: 66.73369598388672
Mean value: 50.924835205078125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.926063537597656
Max value: -50.926063537597656
Mean value: -50.926063537597656
sam_encoder.pos_embed grad: -4.038342715784182e-10
sam_encoder.blocks.0.norm1.weight grad: 8.38373089209199e-05
sam_encoder.blocks.0.norm1.bias grad: 2.2201209503691643e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.854084636463085e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.324557256855769e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.828539987211116e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.547486590425251e-06
sam_encoder.blocks.0.norm2.weight grad: 1.2006719771306962e-05
sam_encoder.blocks.0.norm2.bias grad: -3.7664758565369993e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.400529254169669e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.529330546645724e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.254405656771269e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.5400024646369275e-06
sam_encoder.blocks.1.norm1.weight grad: 5.7623924476502e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4775556337554008e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.032096280250698e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.579501142463414e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.638076567673124e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.817918241111329e-06
sam_encoder.blocks.1.norm2.weight grad: -4.7098556024138816e-06
sam_encoder.blocks.1.norm2.bias grad: -2.459338247717824e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.7011801547778305e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.333658918971196e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.2344032256805804e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.084277866742923e-06
sam_encoder.blocks.2.norm1.weight grad: -2.5593835744075477e-05
sam_encoder.blocks.2.norm1.bias grad: 5.678222350979922e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.5797128071426414e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.6778606045118067e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.159304681816138e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.968530447513331e-06
sam_encoder.blocks.2.norm2.weight grad: -1.8459621742294985e-06
sam_encoder.blocks.2.norm2.bias grad: -4.5583346945932135e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.4276223484775983e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.399160775074961e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.1349979963124497e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.7147395914871595e-07
sam_encoder.blocks.3.norm1.weight grad: -1.1079237083322369e-08
sam_encoder.blocks.3.norm1.bias grad: 5.282466645439854e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.2945097245828947e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.80665573074657e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.495901182759553e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.4709368062758585e-06
sam_encoder.blocks.3.norm2.weight grad: -9.799375220609363e-06
sam_encoder.blocks.3.norm2.bias grad: -6.2436884036287665e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.005509127746336e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.6729467208497226e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.661001598715302e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.374613418647641e-07
sam_encoder.blocks.4.norm1.weight grad: 6.249770194699522e-06
sam_encoder.blocks.4.norm1.bias grad: -7.296347348528798e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.8902243204574916e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.393715246602369e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.3381423375212762e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.6519315977348015e-06
sam_encoder.blocks.4.norm2.weight grad: -4.800290753337322e-06
sam_encoder.blocks.4.norm2.bias grad: -2.838374484781525e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.812304152641445e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.0890260000451235e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.7016309357131831e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.603252475339104e-07
sam_encoder.blocks.5.norm1.weight grad: 2.5311094304925064e-06
sam_encoder.blocks.5.norm1.bias grad: 3.7595532376144547e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.136397085905628e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.1800019567308482e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.4175347118339232e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.97911456579459e-07
sam_encoder.blocks.5.norm2.weight grad: -5.080529263068456e-06
sam_encoder.blocks.5.norm2.bias grad: -1.630394990570494e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.980866262689233e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.041350398940267e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.533873839638545e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.4285267247469164e-07
sam_encoder.blocks.6.norm1.weight grad: 2.1566333430200757e-07
sam_encoder.blocks.6.norm1.bias grad: 2.080554821759506e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.302677431653137e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.693403626442887e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.076442567362392e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.2689632740148227e-06
sam_encoder.blocks.6.norm2.weight grad: 1.471569703426212e-06
sam_encoder.blocks.6.norm2.bias grad: 2.0753732314915396e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.2009495498641627e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.4825197897371254e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.916882237968821e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.8791824863437796e-07
sam_encoder.blocks.7.norm1.weight grad: 5.759942723670974e-06
sam_encoder.blocks.7.norm1.bias grad: -6.710376965202158e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.9650890408229316e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.589534548429583e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.333389540533972e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0011165159085067e-06
sam_encoder.blocks.7.norm2.weight grad: 2.2236022232391406e-06
sam_encoder.blocks.7.norm2.bias grad: 1.369382516713813e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.623586397021427e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.1422200902065924e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.776025891966128e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.442840003728634e-07
sam_encoder.blocks.8.norm1.weight grad: 3.6426022234081756e-06
sam_encoder.blocks.8.norm1.bias grad: 1.2493312624428654e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.303819539723918e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.2062580481142504e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.1411877949285554e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.2581666624100762e-06
sam_encoder.blocks.8.norm2.weight grad: 3.0615510695497505e-06
sam_encoder.blocks.8.norm2.bias grad: 1.8033887272395077e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.0281306686010794e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.103225258702878e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.348380974126485e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.734747622274881e-07
sam_encoder.blocks.9.norm1.weight grad: 3.1712704640085576e-06
sam_encoder.blocks.9.norm1.bias grad: -7.758026185911149e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.2135859580885153e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.9586936395608063e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.7985144040721934e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.190101776657684e-07
sam_encoder.blocks.9.norm2.weight grad: 2.357775429118192e-06
sam_encoder.blocks.9.norm2.bias grad: 2.1497342004295206e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 8.541868510292261e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 7.106442581061856e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.208154784166254e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.754487801823416e-07
sam_encoder.blocks.10.norm1.weight grad: -7.74386705870711e-07
sam_encoder.blocks.10.norm1.bias grad: 2.802175913529936e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.907696044640034e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.6735394221286697e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.60694364948722e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.6283824777474365e-07
sam_encoder.blocks.10.norm2.weight grad: -2.553928197812638e-07
sam_encoder.blocks.10.norm2.bias grad: 8.097528052530834e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.622191613317227e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.1022410357527406e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.281871947066975e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.836906330434431e-07
sam_encoder.blocks.11.norm1.weight grad: 3.93935397369205e-06
sam_encoder.blocks.11.norm1.bias grad: 2.2151320990815293e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0482622201379854e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.0039342391319224e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.270499865313468e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.389652185134764e-07
sam_encoder.blocks.11.norm2.weight grad: 1.6709711871953914e-06
sam_encoder.blocks.11.norm2.bias grad: 1.6327667253790423e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.173519752015409e-09
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.441439157038985e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.956923013807682e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.998248174878597e-10
sam_encoder.neck.conv1.trainable_scale grad: 5.576121111516841e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.404473318369128e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.866494110610802e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.6046384189394303e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.000137682247441262
mask_decoder.transformer.layers.0.norm1.bias grad: -3.8208600017242134e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0032329517416656017
mask_decoder.transformer.layers.0.norm2.bias grad: -7.134213228709996e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 1.891273495857604e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.413668284541927e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.329086606157944e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0505264981475193e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.3649178981722798e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.130912879598327e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 7.319388532778248e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.4657328797038645e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.4827648303471506e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.984612208616454e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.5053762985626236e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 6.48273344268091e-05
mask_decoder.transformer.norm_final_attn.weight grad: -4.7023459046613425e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.466690628149081e-05
Text_Embedding_Affine.0.weight grad: 9.862888283862503e-12
Text_Embedding_Affine.0.bias grad: 2.7782132150377947e-10
Text_Embedding_Affine.2.weight grad: -1.5807882780549676e-10
Text_Embedding_Affine.2.bias grad: -3.52833594661206e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6789033704944778e-11
Max value: 0.9995680451393127
Mean value: 0.100089430809021

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6789033704944778e-11
Max value: 0.9995680451393127
Mean value: 0.100089430809021

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09953451156616211

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.015933990478516
Max value: -1.1920928244535389e-07
Mean value: -0.12501727044582367

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09178733825683594

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09953451156616211

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.581111907958984
Max value: 80.06520080566406
Mean value: 65.16221618652344

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.5117425500598145e-11
Max value: 0.9995627999305725
Mean value: 0.09982465207576752

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.5117425500598145e-11
Max value: 0.9995627999305725
Mean value: 0.09982465207576752

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.5117425500598145e-11
Max value: 0.9995627999305725
Mean value: 0.09982465207576752

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.817545890808105
Max value: -1.1920928244535389e-07
Mean value: -0.12503856420516968

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9386690855026245
Max value: 1.2851954698562622
Mean value: 0.9999932050704956

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.581111907958984
Max value: 80.06520080566406
Mean value: 65.16221618652344

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.16297149658203
Max value: -65.16297149658203
Mean value: -65.16297149658203
sam_encoder.pos_embed grad: -8.313745247789939e-10
sam_encoder.blocks.0.norm1.weight grad: -3.5566794394981116e-05
sam_encoder.blocks.0.norm1.bias grad: 3.9907780546855065e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.755109552614158e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.780798003092059e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.7389631870610174e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.608671820780728e-07
sam_encoder.blocks.0.norm2.weight grad: 6.630978168686852e-05
sam_encoder.blocks.0.norm2.bias grad: -6.613958248635754e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.99875316361431e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2552281077660155e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.385274274274707e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.679732233445975e-06
sam_encoder.blocks.1.norm1.weight grad: 2.943294748547487e-05
sam_encoder.blocks.1.norm1.bias grad: 4.466685641091317e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.628844524428132e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.195422894146759e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.713606232253369e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.767622496932745e-06
sam_encoder.blocks.1.norm2.weight grad: -2.388874054304324e-05
sam_encoder.blocks.1.norm2.bias grad: -9.332939953310415e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.242868948902469e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.587208751327125e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0646686607506126e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.8463368734228425e-06
sam_encoder.blocks.2.norm1.weight grad: 5.790852810605429e-06
sam_encoder.blocks.2.norm1.bias grad: 1.0365409252699465e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.750024688997655e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7852423752628965e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.5243856473243795e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.363361985175288e-07
sam_encoder.blocks.2.norm2.weight grad: -1.9421557226451114e-05
sam_encoder.blocks.2.norm2.bias grad: 8.766864993958734e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.1007932698703371e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.1469561438134406e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.264941475819796e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.1368450714144274e-06
sam_encoder.blocks.3.norm1.weight grad: -1.3048871551291086e-05
sam_encoder.blocks.3.norm1.bias grad: -3.332787628096412e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.703836905013304e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.104438969283365e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.602159606292844e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.79728896607412e-06
sam_encoder.blocks.3.norm2.weight grad: 1.3373548426898196e-05
sam_encoder.blocks.3.norm2.bias grad: 1.0647425369825214e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.386381973134121e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.894600119267125e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.4302839847223368e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7638453186918923e-07
sam_encoder.blocks.4.norm1.weight grad: -6.49003322905628e-06
sam_encoder.blocks.4.norm1.bias grad: -2.550829549363698e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.4455971470160875e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.385159115827264e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.4516534747599508e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.809212446663878e-06
sam_encoder.blocks.4.norm2.weight grad: -1.3736903383687604e-06
sam_encoder.blocks.4.norm2.bias grad: -3.328868388052797e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.166564172512153e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 7.022767931630369e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.7001705145958113e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.389802251760557e-07
sam_encoder.blocks.5.norm1.weight grad: 1.5092849025677424e-05
sam_encoder.blocks.5.norm1.bias grad: 1.3876269804313779e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.851727680943441e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.332597983302549e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.7908844205958303e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.2061768706626026e-06
sam_encoder.blocks.5.norm2.weight grad: -6.1160112636571284e-06
sam_encoder.blocks.5.norm2.bias grad: -7.984285730344709e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.8441305655869655e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.0153810308111133e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.091714006586699e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.7281057580476045e-06
sam_encoder.blocks.6.norm1.weight grad: -4.091387381777167e-06
sam_encoder.blocks.6.norm1.bias grad: -1.35857675331863e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.7326922261418076e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.3400946247420507e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.332031254416506e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.035232900103438e-07
sam_encoder.blocks.6.norm2.weight grad: -9.156599844573066e-06
sam_encoder.blocks.6.norm2.bias grad: 1.475491444580257e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.752289664291311e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.981085799547145e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.8069844120182097e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.791294021648355e-07
sam_encoder.blocks.7.norm1.weight grad: -1.3740044778387528e-05
sam_encoder.blocks.7.norm1.bias grad: 1.5593384432577295e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.990540663944557e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.049322342325468e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3537882637137955e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.5199301515167463e-06
sam_encoder.blocks.7.norm2.weight grad: 1.0650954209268093e-05
sam_encoder.blocks.7.norm2.bias grad: 3.6449116578296525e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.105878815607866e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.9614299162640236e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.1590699361695442e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.5066509579119156e-07
sam_encoder.blocks.8.norm1.weight grad: -7.689807716815267e-06
sam_encoder.blocks.8.norm1.bias grad: 8.553906809538603e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.229721970565151e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.6241543714131694e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.52122321803472e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.7116102526415489e-06
sam_encoder.blocks.8.norm2.weight grad: 3.2427749374619452e-06
sam_encoder.blocks.8.norm2.bias grad: -1.3942705834324443e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.3780222565837903e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.13516250369139e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.3163469247956527e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.459911113168346e-08
sam_encoder.blocks.9.norm1.weight grad: -4.490920218813699e-06
sam_encoder.blocks.9.norm1.bias grad: 6.260192435547651e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.179320967523381e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.824551863042871e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.3768947698954435e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.744142974137503e-07
sam_encoder.blocks.9.norm2.weight grad: -9.176125104204402e-07
sam_encoder.blocks.9.norm2.bias grad: -6.140527375464444e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.485707106345217e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.114111207964015e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.3502381079888437e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.567447705194354e-07
sam_encoder.blocks.10.norm1.weight grad: -8.726666465008748e-07
sam_encoder.blocks.10.norm1.bias grad: -1.6342607978003798e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.2752284419548232e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.021726774297349e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.6758863214126904e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0539938557485584e-06
sam_encoder.blocks.10.norm2.weight grad: 5.324900484993123e-07
sam_encoder.blocks.10.norm2.bias grad: -6.18200829194393e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.834211265209888e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.9809401641832665e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.35874755516852e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.314634622915037e-07
sam_encoder.blocks.11.norm1.weight grad: 1.6975734524748987e-06
sam_encoder.blocks.11.norm1.bias grad: -1.4345727095133043e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.705731721012853e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.722925943198788e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.3504430828324985e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.195014291028201e-07
sam_encoder.blocks.11.norm2.weight grad: 2.5426347747270484e-06
sam_encoder.blocks.11.norm2.bias grad: -4.463117875275202e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.178411356610013e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.0542302081594244e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.745291200450083e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.7240503780158178e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.36196831590496e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1260372957622167e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.9206891010981053e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.2705002265865915e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -9.223364031640813e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.2979005482047796e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0021455460228025913
mask_decoder.transformer.layers.0.norm2.bias grad: -2.1035782992839813e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 4.017996252514422e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.628349440987222e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 1.9016049918718636e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.556428732234053e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.39321912988089e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.3904107618145645e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00037488597445189953
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010008896060753614
mask_decoder.transformer.layers.1.norm3.weight grad: 2.7005946321878582e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.768049934180453e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.3606847611954436e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.949181599542499e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.6071153368102387e-05
mask_decoder.transformer.norm_final_attn.bias grad: 8.0342979345005e-06
Text_Embedding_Affine.0.weight grad: 9.364941981615527e-12
Text_Embedding_Affine.0.bias grad: 2.765307705043796e-10
Text_Embedding_Affine.2.weight grad: 7.111598115949747e-11
Text_Embedding_Affine.2.bias grad: -8.328539479407482e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.474734885550617e-11
Max value: 0.9991011619567871
Mean value: 0.08489664644002914

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.474734885550617e-11
Max value: 0.9991011619567871
Mean value: 0.08489664644002914

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08338451385498047

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.31768798828125
Max value: -1.1920928244535389e-07
Mean value: -0.10815655440092087

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07812118530273438

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08338451385498047

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.80863571166992
Max value: 93.412841796875
Mean value: 69.99604797363281

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1215894185623299e-10
Max value: 0.9990009665489197
Mean value: 0.08336924761533737

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1215894185623299e-10
Max value: 0.9990009665489197
Mean value: 0.08336924761533737

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1215894185623299e-10
Max value: 0.9990009665489197
Mean value: 0.08336924761533737

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.137551307678223
Max value: -1.1920928244535389e-07
Mean value: -0.10809125006198883

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8731535077095032
Max value: 1.3987925052642822
Mean value: 1.000129222869873

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.80863571166992
Max value: 93.412841796875
Mean value: 69.99604797363281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.00270080566406
Max value: -70.00270080566406
Mean value: -70.00270080566406
sam_encoder.pos_embed grad: -4.144329324162754e-09
sam_encoder.blocks.0.norm1.weight grad: -1.4115012163529173e-05
sam_encoder.blocks.0.norm1.bias grad: 9.806168236536905e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.7364471861801576e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3184873637328565e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.802825060323812e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.4373907788467477e-06
sam_encoder.blocks.0.norm2.weight grad: 4.401533442432992e-05
sam_encoder.blocks.0.norm2.bias grad: -2.6087616788572632e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.551858258608263e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.562225396715803e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.528590453555807e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.017464900447521e-06
sam_encoder.blocks.1.norm1.weight grad: -1.949708803294925e-06
sam_encoder.blocks.1.norm1.bias grad: -4.808537141798297e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.554463430395117e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2543848697532667e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.828158125746995e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.806118573062122e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0790595297294203e-06
sam_encoder.blocks.1.norm2.bias grad: 3.896730049746111e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.510517896960664e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.363866886094911e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.653597433294635e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.066656285634963e-07
sam_encoder.blocks.2.norm1.weight grad: -1.395318304275861e-05
sam_encoder.blocks.2.norm1.bias grad: -3.0333894756040536e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.807555448380299e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.6465793325769482e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.255759555846453e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.631766842067009e-06
sam_encoder.blocks.2.norm2.weight grad: -5.45172588317655e-06
sam_encoder.blocks.2.norm2.bias grad: 3.1274025786842685e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.243842446769122e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.648541001486592e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.055324774933979e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.991651275711774e-07
sam_encoder.blocks.3.norm1.weight grad: -3.058145011891611e-06
sam_encoder.blocks.3.norm1.bias grad: -9.951661468221573e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.115380539180478e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.267497726890724e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.204273980372818e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.6142189401289215e-06
sam_encoder.blocks.3.norm2.weight grad: -1.645024894969538e-05
sam_encoder.blocks.3.norm2.bias grad: -1.2783943020622246e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1886324500665069e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.690619789471384e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.059488108192454e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.0059391115646577e-06
sam_encoder.blocks.4.norm1.weight grad: 1.162638568530383e-06
sam_encoder.blocks.4.norm1.bias grad: -3.8002215205779066e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.0199911432428053e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4444810858549317e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.57885163188621e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.611561287973018e-06
sam_encoder.blocks.4.norm2.weight grad: -1.2376622180454433e-05
sam_encoder.blocks.4.norm2.bias grad: 2.355937567699584e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.866829946578946e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.0155907805019524e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.6599386728776153e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.9313545724107826e-07
sam_encoder.blocks.5.norm1.weight grad: 1.2034811334160622e-05
sam_encoder.blocks.5.norm1.bias grad: 9.136447260971181e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.226052497979254e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.319347342767287e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.572299879626371e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.499917925064437e-08
sam_encoder.blocks.5.norm2.weight grad: 4.1487436419629375e-07
sam_encoder.blocks.5.norm2.bias grad: 1.1696865840349346e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.22297603613697e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1166437161591602e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.589159617462428e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.940101198755656e-08
sam_encoder.blocks.6.norm1.weight grad: 2.3959755708347075e-06
sam_encoder.blocks.6.norm1.bias grad: -1.3741137081524357e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.653060391821782e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0159225212191814e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.6043843465449754e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.5811740183835354e-07
sam_encoder.blocks.6.norm2.weight grad: 5.1533525038394146e-06
sam_encoder.blocks.6.norm2.bias grad: 4.180966243438888e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.7297674023429863e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.310820152866654e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.11259042166057e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.9849818500006222e-07
sam_encoder.blocks.7.norm1.weight grad: 2.9328998607525136e-07
sam_encoder.blocks.7.norm1.bias grad: 4.979829100193456e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.2285862567296135e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.878792078168772e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.961736408404249e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.6821169285540236e-08
sam_encoder.blocks.7.norm2.weight grad: 1.6696676539140753e-06
sam_encoder.blocks.7.norm2.bias grad: 2.106571855620132e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.019241709509515e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.78162387859993e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0667042715795105e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.33866757071155e-07
sam_encoder.blocks.8.norm1.weight grad: -4.614103090716526e-06
sam_encoder.blocks.8.norm1.bias grad: 2.557972038630396e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.980128894909285e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.953148284883355e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.7244927878200542e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.417336645521573e-06
sam_encoder.blocks.8.norm2.weight grad: 3.804195785050979e-06
sam_encoder.blocks.8.norm2.bias grad: 6.275058694882318e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.0983378615492256e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 9.96995822788449e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0714870057881853e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.284446338762791e-07
sam_encoder.blocks.9.norm1.weight grad: 1.5903910934866872e-06
sam_encoder.blocks.9.norm1.bias grad: 2.2158414481054933e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.347498937320779e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.94342066556419e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.7300599703703483e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.197667718448429e-08
sam_encoder.blocks.9.norm2.weight grad: 5.532570412469795e-06
sam_encoder.blocks.9.norm2.bias grad: 1.576207296238863e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.9091920623613987e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.1844675757165533e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.17571050850529e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.82202243701613e-07
sam_encoder.blocks.10.norm1.weight grad: -1.6679499594829394e-06
sam_encoder.blocks.10.norm1.bias grad: 1.0786419579744688e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.0104203056471306e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -3.831954131783277e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.0194225978921168e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.460385068545293e-07
sam_encoder.blocks.10.norm2.weight grad: 6.042727818567073e-06
sam_encoder.blocks.10.norm2.bias grad: 1.0472633675817633e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.130040568066761e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.3732087609241717e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.442219740965811e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.698604468307167e-07
sam_encoder.blocks.11.norm1.weight grad: -5.3990111155144405e-06
sam_encoder.blocks.11.norm1.bias grad: 1.963371687452309e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.3586377178853581e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -9.394135247475788e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4280165032687364e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.0305491286999313e-06
sam_encoder.blocks.11.norm2.weight grad: 6.285686595219886e-06
sam_encoder.blocks.11.norm2.bias grad: 2.366073658777168e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.065731107199099e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0422284049127484e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.2490359040384647e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.3377884278706915e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.2268028513062745e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.8488120733527467e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.012335815175902e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.3789241570048034e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00012708245776593685
mask_decoder.transformer.layers.0.norm1.bias grad: -4.7993307816796005e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003959902562201023
mask_decoder.transformer.layers.0.norm2.bias grad: 1.960890949703753e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 2.08753135666484e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.1033079721964896e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.0001044499222189188
mask_decoder.transformer.layers.0.norm4.bias grad: 5.387547389545944e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.62845603376627e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.4062659324263223e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.36448128009215e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -6.318273517536e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.604717731941491e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.600402098731138e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.3613420125911944e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001114441329264082
mask_decoder.transformer.norm_final_attn.weight grad: -1.1571313507374725e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.242513917532051e-05
Text_Embedding_Affine.0.weight grad: -1.7660074791425728e-11
Text_Embedding_Affine.0.bias grad: -3.776361445773091e-10
Text_Embedding_Affine.2.weight grad: -5.058593127715838e-11
Text_Embedding_Affine.2.bias grad: -2.0717950974358246e-05
Epoch 39 finished with average loss: -62.0306
Final Validation
Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, Loss=0.69, Dice=0.312]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.75it/s, Loss=0.69, Dice=0.312]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.75it/s, Loss=0.692, Dice=0.268]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                         
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.0589732394359084e-27
Max value: 0.9986910223960876
Mean value: 0.026525013148784637

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.0589732394359084e-27
Max value: 0.9986910223960876
Mean value: 0.026525013148784637

Debugging images:
Shape: torch.Size([8, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 0.8622043132781982

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06422805786132812

Debugging predicted segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.01428079605102539

Debugging Raw model output:
Shape: torch.Size([2, 512, 512])
Contains NaN: False
Min value: 2.4421149482693714e-22
Max value: 0.9961163997650146
Mean value: 0.028830409049987793

Debugging Processed model output:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 2.4421149482693714e-22
Max value: 0.9961163997650146
Mean value: 0.028830409049987793

Debugging images:
Shape: torch.Size([2, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 0.8142521381378174

Debugging Ground truth:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07422256469726562

Debugging predicted segs:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.013559341430664062
Validation completed for Epoch 1:
Average Loss: 0.6915, Average Dice: 0.2685
